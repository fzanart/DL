 # # # # # # # # # # # # # # # # # # # #
 Repository: ccampbell/rainbow, index: 2780, word count: 4634 
 # # # # # # # # # # # # # # # # # # # #

:book: For those who wanna learn Bashbash-handbook This document is written for those who want to learn Bash without diving in too deeply. Tip: Try learnyoubash an interactive workshopper based on this handbook! Node Packaged Manuscript You can install this handbook using npm. Just run: You should be able to run bash-handbook at the command line now. This will open the manual in your selected $PAGER. Otherwise, you may continue reading on here. The source is available here: https://github.com/denysdovhan/bash-handbook Translations Currently, there are these translations of bash-handbook: Portugus (Brasil) () () Request another translation Table of Contents Introduction Shells and modes Interactive mode Non-interactive mode Exit codes Comments Variables Local variables Environment variables Positional parameters Shell expansions Brace expansion Command substitution Arithmetic expansion Double and single quotes Arrays Array declaration Array expansion Array slice Adding elements into an array Deleting elements from an array Streams, pipes and lists Streams Pipes Lists of commands Conditional statements Primary and combining expressions Using an if statement Using a case statement Loops for loop while loop until loop select loop Loop control Functions Debugging Afterword Want to learn more? Other resources License Introduction If you are a developer, then you know the value of time. Optimizing your work process is one of the most important aspects of the job. In that path towards efficiency and productivity, we are often posed with actions that must be repeated over and over again, like: taking a screenshot and uploading it to a server processing text that may come in many shapes and forms converting files between different formats parsing a program's output Enter Bash, our savior. Bash is a Unix shell written by Brian Fox for the GNU Project as a free software replacement for the Bourne shell. It was released in 1989 and has been distributed as the Linux and macOS default shell for a long time. So why do we need to learn something that was written more than 30 years ago? The answer is simple: this something is today one of the most powerful and portable tools for writing efficient scripts for all Unix-based systems. And that's why you should learn bash. Period. In this handbook, I'm going to describe the most important concepts in bash with examples. I hope this compendium will be helpful to you. Shells and modes The user bash shell can work in two modes - interactive and non-interactive. Interactive mode If you are working on Ubuntu, you have seven virtual terminals available to you. The desktop environment takes place in the seventh virtual terminal, so you can return to a friendly GUI using the Ctrl-Alt-F7 keybinding. You can open the shell using the Ctrl-Alt-F1 keybinding. After that, the familiar GUI will disappear and one of the virtual terminals will be shown. If you see something like this, then you are working in interactive mode: user@host:~$ Here you can enter a variety of Unix commands, such as ls, grep, cd, mkdir, rm and see the result of their execution. We call this shell interactive because it interacts directly with the user. Using a virtual terminal is not really convenient. For example, if you want to edit a document and execute another command at the same time, you are better off using virtual terminal emulators like: GNOME Terminal Terminator iTerm2 ConEmu Non-interactive mode In non-interactive mode, the shell reads commands from a file or a pipe and executes them. When the interpreter reaches the end of the file, the shell process terminates the session and returns to the parent process. Use the following commands for running the shell in non-interactive mode: sh /path/to/script.sh bash /path/to/script.sh In the example above, script.sh is just a regular text file that consists of commands the shell interpreter can evaluate and sh or bash is the shell's interpreter program. You can create script.sh using your preferred text editor (e.g. vim, nano, Sublime Text, Atom, etc). You can also simplify invoking the script by making it an executable file using the chmod command: chmod +x /path/to/script.sh Additionally, the first line in the script must indicate which program it should use to run the file, like so: Or if you prefer to use sh instead of bash, change #!/bin/bash to #!/bin/sh. This #! character sequence is known as the shebang. Now you can run the script like this: /path/to/script.sh A handy trick we used above is using echo to print text to the terminal screen. Another way to use the shebang line is as follows: The advantage of this shebang line is it will search for the program (in this case bash) based on the PATH environment variable. This is often preferred over the first method shown above, as the location of a program on a filesystem cannot always be assumed. This is also useful if the PATH variable on a system has been configured to point to an alternate version of the program. For instance, one might install a newer version of bash while preserving the original version and insert the location of the newer version into the PATH variable. The use of #!/bin/bash would result in using the original bash, while #!/usr/bin/env bash would make use of the newer version. Exit codes Every command returns an exit code (return status or exit status). A successful command always returns 0 (zero-code), and a command that has failed returns a non-zero value (error code). Failure codes must be positive integers between 1 and 255. Another handy command we can use when writing a script is exit. This command is used to terminate the current execution and deliver an exit code to the shell. Running an exit code without any arguments, will terminate the running script and return the exit code of the last command executed before exit. When a program terminates, the shell assigns its exit code to the $? environment variable. The $? variable is how we usually test whether a script has succeeded or not in its execution. In the same way we can use exit to terminate a script, we can use the return command to exit a function and return an exit code to the caller. You can use exit inside a function too and this will exit the function and terminate the program. Comments Scripts may contain comments. Comments are special statements ignored by the shell interpreter. They begin with a # symbol and continue on to the end of the line. For example: Tip: Use comments to explain what your script does and why. Variables Like in most programming languages, you can also create variables in bash. Bash knows no data types. Variables can contain only numbers or a string of one or more characters. There are three kinds of variables you can create: local variables, environment variables and variables as positional parameters. Local variables Local variables are variables that exist only within a single script. They are inaccessible to other programs and scripts. A local variable can be declared using = sign (as a rule, there should not be any spaces between a variable's name, = and its value) and its value can be retrieved using the $ sign. For example: We can also declare a variable local to a single function using the local keyword. Doing so causes the variable to disappear when the function exits. Environment variables Environment variables are variables accessible to any program or script running in current shell session. They are created just like local variables, but using the keyword export instead. There are a lot of global variables in bash. You will meet these variables fairly often, so here is a quick lookup table with the most practical ones: | Variable | Description | | :----------- | :------------------------------------------------------------ | | $HOME | The current user's home directory. | | $PATH | A colon-separated list of directories in which the shell looks for commands. | | $PWD | The current working directory. | | $RANDOM | Random integer between 0 and 32767. | | $UID | The numeric, real user ID of the current user. | | $PS1 | The primary prompt string. | | $PS2 | The secondary prompt string. | Follow this link to see an extended list of environment variables in Bash. Positional parameters Positional parameters are variables allocated when a function is evaluated and are given positionally. The following table lists positional parameter variables and other special variables and their meanings when you are inside a function. | Parameter | Description | | :------------- | :---------------------------------------------------------- | | $0 | Script's name. | | $1 $9 | The parameter list elements from 1 to 9. | | ${10} ${N} | The parameter list elements from 10 to N. | | $* or $@ | All positional parameters except $0. | | $# | The number of parameters, not counting $0. | | $FUNCNAME | The function name (has a value only inside a function). | In the example below, the positional parameters will be $0='./script.sh', $1='foo' and $2='bar': ./script.sh foo bar Variables may also have default values. We can define as such using the following syntax: Shell expansions Expansions are performed on the command line after it has been split into tokens. In other words, these expansions are a mechanism to calculate arithmetical operations, to save results of commands' executions and so on. If you are interested, you can read more about shell expansions. Brace expansion Brace expansion allows us to generate arbitrary strings. It's similar to filename expansion. For example: Also brace expansions may be used for creating ranges, which are iterated over in loops. Command substitution Command substitution allow us to evaluate a command and substitute its value into another command or variable assignment. Command substitution is performed when a command is enclosed by or $(). For example, we can use it as follows: Arithmetic expansion In bash we are free to do any arithmetical operations. But the expression must enclosed by $(( )) The format for arithmetic expansions is: Within arithmetic expansions, variables should generally be used without a $ prefix: Double and single quotes There is an important difference between double and single quotes. Inside double quotes variables or command substitutions are expanded. Inside single quotes they are not. For example: Take care to expand local variables and environment variables within quotes if they could contain whitespace. As an innocuous example, consider using echo to print some user input: The first echo is invoked with 5 separate arguments $INPUT is split into separate words, echo prints a single space character between each. In the second case, echo is invoked with a single argument (the entire $INPUT value, including whitespace). Now consider a more serious example: While the issue in this example could be resolved by renaming FILE to Favorite-Things.txt, consider input coming from an environment variable, a positional parameter, or the output of another command (find, cat, etc). If the input might contain whitespace, take care to wrap the expansion in quotes. Arrays Like in other programming languages, an array in bash is a variable that allows you to refer to multiple values. In bash, arrays are also zero-based, that is, the first element in an array has index 0. When dealing with arrays, we should be aware of the special environment variable IFS. IFS, or Input Field Separator, is the character that separates elements in an array. The default value is an empty space IFS=' '. Array declaration In bash you create an array by simply assigning a value to an index in the array variable: Array variables can also be created using compound assignments such as: Array expansion Individual array elements are expanded similar to other variables: The entire array can be expanded by using * or @ in place of the numeric index: There is an important (and subtle) difference between the two lines above: consider an array element containing whitespace: We want to print each element of the array on a separate line, so we try to use the printf builtin: Why were Desert and fig printed on separate lines? Let's try to use quoting: Now everything is on one line that's not what we wanted! Here's where ${fruits[@]} comes into play: Within double quotes, ${fruits[@]} expands to a separate argument for each element in the array; whitespace in the array elements is preserved. Array slice Besides, we can extract a slice of array using the slice operators: In the example above, ${fruits[@]} expands to the entire contents of the array, and :0:2 extracts the slice of length 2, that starts at index 0. Adding elements into an array Adding elements into an array is quite simple too. Compound assignments are specially useful in this case. We can use them like this: The example above, ${fruits[@]} expands to the entire contents of the array and substitutes it into the compound assignment, then assigns the new value into the fruits array mutating its original value. Deleting elements from an array To delete an element from an array, use the unset command: Streams, pipes and lists Bash has powerful tools for working with other programs and their outputs. Using streams we can send the output of a program into another program or file and thereby write logs or whatever we want. Pipes give us opportunity to create conveyors and control the execution of commands. It is paramount we understand how to use this powerful and sophisticated tool. Streams Bash receives input and sends output as sequences or streams of characters. These streams may be redirected into files or one into another. There are three descriptors: | Code | Descriptor | Description | | :--: | :--------: | :------------------- | | 0 | stdin | The standard input. | | 1 | stdout | The standard output. | | 2 | stderr | The errors output. | Redirection makes it possible to control where the output of a command goes to, and where the input of a command comes from. For redirecting streams these operators are used: | Operator | Description | | :------: | :------------------------------------------- | | > | Redirecting output | | &> | Redirecting output and error output | | &>> | Appending redirected output and error output | | < | Redirecting input | | << | Here documents syntax | | <<< | Here strings | Here are few examples of using redirections: Pipes We could redirect standard streams not only in files, but also to other programs. Pipes let us use the output of a program as the input of another. In the example below, command1 sends its output to command2, which then passes it on to the input of command3: command1 | command2 | command3 Constructions like this are called pipelines. In practice, this can be used to process data through several programs. For example, here the output of ls -l is sent to the grep program, which prints only files with a .md extension, and this output is finally sent to the less program: ls -l | grep .md$ | less The exit status of a pipeline is normally the exit status of the last command in the pipeline. The shell will not return a status until all the commands in the pipeline have completed. If you want your pipelines to be considered a failure if any of the commands in the pipeline fail, you should set the pipefail option with: set -o pipefail Lists of commands A list of commands is a sequence of one or more pipelines separated by ;, &, && or || operator. If a command is terminated by the control operator &, the shell executes the command asynchronously in a subshell. In other words, this command will be executed in the background. Commands separated by a ; are executed sequentially: one after another. The shell waits for the finish of each command. Lists separated by && and || are called AND and OR lists, respectively. The AND-list looks like this: The OR-list has the form: The return code of an AND or OR list is the exit status of the last executed command. Conditional statements Like in other languages, Bash conditionals let us decide to perform an action or not. The result is determined by evaluating an expression, which should be enclosed in [[ ]]. Conditional expression may contain && and || operators, which are AND and OR accordingly. Besides this, there many other handy expressions. There are two different conditional statements: if statement and case statement. Primary and combining expressions Expressions enclosed inside [[ ]] (or [ ] for sh) are called test commands or primaries. These expressions help us to indicate results of a conditional. In the tables below, we are using [ ], because it works for sh too. Here is an answer about the difference between double and single square brackets in bash. Working with the file system: | Primary | Meaning | | :-----------: | :----------------------------------------------------------- | | [ -e FILE ] | True if FILE exists. | | [ -f FILE ] | True if FILE exists and is a regular file. | | [ -d FILE ] | True if FILE exists and is a directory. | | [ -s FILE ] | True if FILE exists and not empty (size more than 0). | | [ -r FILE ] | True if FILE exists and is readable. | | [ -w FILE ] | True if FILE exists and is writable. | | [ -x FILE ] | True if FILE exists and is executable. | | [ -L FILE ] | True if FILE exists and is symbolic link. | | [ FILE1 -nt FILE2 ] | FILE1 is newer than FILE2. | | [ FILE1 -ot FILE2 ] | FILE1 is older than FILE2. | Working with strings: | Primary | Meaning | | :------------: | :---------------------------------------------------------- | | [ -z STR ] | STR is empty (the length is zero). | | [ -n STR ] |STR is not empty (the length is non-zero). | | [ STR1 == STR2 ] | STR1 and STR2 are equal. | | [ STR1 != STR2 ] | STR1 and STR2 are not equal. | Arithmetic binary operators: | Primary | Meaning | | :-----------------: | :----------------------------------------------------- | | [ ARG1 -eq ARG2 ] | ARG1 is equal to ARG2. | | [ ARG1 -ne ARG2 ] | ARG1 is not equal to ARG2. | | [ ARG1 -lt ARG2 ] | ARG1 is less than ARG2. | | [ ARG1 -le ARG2 ] | ARG1 is less than or equal to ARG2. | | [ ARG1 -gt ARG2 ] | ARG1 is greater than ARG2. | | [ ARG1 -ge ARG2 ] | ARG1 is greater than or equal to ARG2. | Conditions may be combined using these combining expressions: | Operation | Effect | | :------------: | :---------------------------------------------------------- | | [ ! EXPR ] | True if EXPR is false. | | [ (EXPR) ] | Returns the value of EXPR. | | [ EXPR1 -a EXPR2 ] | Logical AND. True if EXPR1 and EXPR2 are true. | | [ EXPR1 -o EXPR2 ] | Logical OR. True if EXPR1 or EXPR2 are true.| Sure, there are more useful primaries and you can easily find them in the Bash man pages. Using an if statement if statements work the same as in other programming languages. If the expression within the braces is true, the code between then and fi is executed. fi indicates the end of the conditionally executed code. Likewise, we could use an if..else statement such as: Sometimes if..else statements are not enough to do what we want to do. In this case we shouldn't forget about the existence of if..elif..else statements, which always come in handy. Look at the example below: Using a case statement If you are confronted with a couple of different possible actions to take, then using a case statement may be more useful than nested if statements. For more complex conditions use case like below: Each case is an expression matching a pattern. The | sign is used for separating multiple patterns, and the ) operator terminates a pattern list. The commands for the first match are executed. * is the pattern for anything else that doesn't match the defined patterns. Each block of commands should be divided with the ;; operator. Loops Here we won't be surprised. As in any programming language, a loop in bash is a block of code that iterates as long as the control conditional is true. There are four types of loops in Bash: for, while, until and select. for loop The for is very similar to its sibling in C. It looks like this: During each pass through the loop, arg takes on the value from elem1 to elemN. Values may also be wildcards or brace expansions. Also, we can write for loop in one line, but in this case there needs to be a semicolon before do, like below: By the way, if for..in..do seems a little bit weird to you, you can also write for in C-like style such as: for is handy when we want to do the same operation over each file in a directory. For example, if we need to move all .bash files into the script folder and then give them execute permissions, our script would look like this: while loop The while loop tests a condition and loops over a sequence of commands so long as that condition is true. A condition is nothing more than a primary as used in if..then conditions. So a while loop looks like this: Just like in the case of the for loop, if we want to write do and condition in the same line, then we must use a semicolon before do. A working example might look like this: until loop The until loop is the exact opposite of the while loop. Like a while it checks a test condition, but it keeps looping as long as this condition is false: select loop The select loop helps us to organize a user menu. It has almost the same syntax as the for loop: The select prints all elem1..elemN on the screen with their sequence numbers, after that it prompts the user. Usually it looks like $? (PS3 variable). The answer will be saved in answer. If answer is the number between 1..N, then statements will execute and select will go to the next iteration that's because we should use the break statement. A working example might look like this: This example, asks the user what package manager {s,he} would like to use. Then, it will ask what package we want to install and finally proceed to install it. If we run this, we will get: Loop control There are situations when we need to stop a loop before its normal ending or step over an iteration. In these cases, we can use the shell built-in break and continue statements. Both of these work with every kind of loop. The break statement is used to exit the current loop before its ending. We have already met with it. The continue statement steps over one iteration. We can use it as such: If we run the example above, it will print all odd numbers from 0 through 9. Functions In scripts we have the ability to define and call functions. As in any programming language, functions in bash are chunks of code, but there are differences. In bash, functions are a sequence of commands grouped under a single name, that is the name of the function. Calling a function is the same as calling any other program, you just write the name and the function will be invoked. We can declare our own function this way: We must declare functions before we can invoke them. Functions can take on arguments and return a result exit code. Arguments, within functions, are treated in the same manner as arguments given to the script in non-interactive mode using positional parameters. A result code can be returned using the return command. Below is a function that takes a name and returns 0, indicating successful execution. We already discussed exit codes. The return command without any arguments returns the exit code of the last executed command. Above, return 0 will return a successful exit code. 0. Debugging The shell gives us tools for debugging scripts. If we want to run a script in debug mode, we use a special option in our script's shebang: These options are settings that change shell behavior. The following table is a list of options which might be useful to you: | Short | Name | Description | | :---: | :---------- | :----------------------------------------------------- | | -f | noglob | Disable filename expansion (globbing). | | -i | interactive | Script runs in interactive mode. | | -n | noexec | Read commands, but don't execute them (syntax check). | | | pipefail | Make pipelines fail if any commands fail, not just if the final command fail. | | -t | | Exit after first command. | | -v | verbose | Print each command to stderr before executing it. | | -x | xtrace | Print each command and its expanded arguments to stderr before executing it. | For example, we have script with -x option such as: This will print the value of the variables to stdout along with other useful information: Sometimes we need to debug a part of a script. In this case using the set command is convenient. This command can enable and disable options. Options are turned on using - and turned off using +: Afterword I hope this small handbook was interesting and helpful. To be honest, I wrote this handbook for myself so as to not forget the bash basics. I tried to write concisely but meaningfully, and I hope you will appreciate that. This handbook narrates my own experience with Bash. It does not purport to be comprehensive, so if you still want more, please run man bash and start there. Contributions are absolutely welcome and I will be grateful for any corrections or questions you can send my way. For all of that create a new issue. Thanks for reading this handbook! Want to learn more? Here's a list of other literature covering Bash: Bash man page. In many environments that you can run Bash, the help system man can display information about Bash, by running the command man bash. For more information on the man command, see the web page "The man Command" hosted at The Linux Information Project. "Bourne-Again SHell manual" in many formats, including HTML, Info, TeX, PDF, and Texinfo. Hosted at https://www.gnu.org/. As of 2016/01, this covers version 4.3, last updated 2015/02/02. "Bash Shell Script" to learn how to write scripts using bash. It is hosted at https://www.gnu.org/. Other resources awesome-bash is a curated list of Bash scripts and resources awesome-shell is another curated list of shell resources bash-it provides a solid framework for using, developing and maintaining shell scripts and custom commands for your daily work. Bash Guide for Beginners a good resource between the HOWTO and the Bash Scripting guide. dotfiles.github.io is a good source of pointers to the various dotfiles collections and shell frameworks available for bash and other shells. learnyoubash helps you write your first bash script shellcheck is a static analysis tool for shell scripts. You can either use it from a web page at www.shellcheck.net or run it from the command line. Installation instructions are on the koalaman/shellcheck github repository page. Finally, Stack Overflow has many questions that are tagged as bash that you can learn from and is a good place to ask if you're stuck. License Denys Dovhan

 # # # # # # # # # # # # # # # # # # # #
 Repository: flyerhzm/bullet, index: 1299, word count: 4676 
 # # # # # # # # # # # # # # # # # # # #

Track changes to your rails modelsPaperTrail Track changes to your models, for auditing or versioning. See how a model looked at any stage in its lifecycle, revert it to any version, or restore it after it has been destroyed. Documentation This is the user guide. See also, the API reference. Choose version: Unreleased, 12.0, 11.1, 10.3, 9.2, 8.1, 7.1, 6.0, 5.2, 4.2, 3.0, 2.7, 1.6 Table of Contents 1. Introduction 1.a. Compatibility 1.b. Installation 1.c. Basic Usage 1.d. API Summary 1.e. Configuration 2. Limiting What is Versioned, and When 2.a. Choosing Lifecycle Events To Monitor 2.b. Choosing When To Save New Versions 2.c. Choosing Attributes To Monitor 2.d. Turning PaperTrail Off 2.e. Limiting the Number of Versions Created 3. Working With Versions 3.a. Reverting And Undeleting A Model 3.b. Navigating Versions 3.c. Diffing Versions 3.d. Deleting Old Versions 3.e. Queries 3.f. Defunct item_ids 4. Saving More Information About Versions 4.a. Finding Out Who Was Responsible For A Change 4.b. Associations 4.c. Storing Metadata 5. ActiveRecord 5.a. Single Table Inheritance (STI) 5.b. Configuring the versions Association 5.c. Generators 5.d. Protected Attributes 6. Extensibility 6.a. Custom Version Classes 6.b. Custom Serializer 6.c. Custom Object Changes 7. Testing 7.a. Minitest 7.b. RSpec 7.c. Cucumber 7.d. Spork 7.e. Zeus or Spring 8. PaperTrail Plugins 9. Integration with Other Libraries 10. Related Libraries and Ports Articles Problems Contributors Contributing Inspirations Intellectual Property 1. Introduction 1.a. Compatibility | paper_trail | branch | ruby | activerecord | | -------------- | ---------- | -------- | ------------- | | unreleased | master | >= 2.5.0 | >= 5.2, < 6.2 | | 12 | 12-stable | >= 2.5.0 | >= 5.2, < 6.2 | | 11 | 11-stable | >= 2.4.0 | >= 5.2, < 6.1 | | 10 | 10-stable | >= 2.3.0 | >= 4.2, < 6.1 | | 9 | 9-stable | >= 2.3.0 | >= 4.2, < 5.3 | | 8 | 8-stable | >= 2.2.0 | >= 4.2, < 5.2 | | 7 | 7-stable | >= 2.1.0 | >= 4.0, < 5.2 | | 6 | 6-stable | >= 1.9.3 | >= 4.0, < 5.2 | | 5 | 5-stable | >= 1.9.3 | >= 3.0, < 5.1 | | 4 | 4-stable | >= 1.8.7 | >= 3.0, < 5.1 | | 3 | 3.0-stable | >= 1.8.7 | >= 3.0, < 5 | | 2 | 2.7-stable | >= 1.8.7 | >= 3.0, < 4 | | 1 | rails2 | >= 1.8.7 | >= 2.3, < 3 | Experts: to install incompatible versions of activerecord, see paper_trail/compatibility.rb. 1.b. Installation Add PaperTrail to your Gemfile. gem 'paper_trail' Add a versions table to your database: See section 5.c. Generators for details. Add has_paper_trail to the models you want to track. If your controllers have a current_user method, you can easily track who is responsible for changes by adding a controller callback. 1.c. Basic Usage Your models now have a versions method which returns the "paper trail" of changes to your model. Once you have a version, you can find out what happened: PaperTrail stores the pre-change version of the model, unlike some other auditing/versioning plugins, so you can retrieve the original version. This is useful when you start keeping a paper trail for models that already have records in the database. This also means that PaperTrail does not waste space storing a version of the object as it currently stands. The versions method gives you previous versions; to get the current one just call a finder on your Widget model as usual. Here's a helpful table showing what PaperTrail stores: | Event | create | update | destroy | | -------------- | -------- | -------- | --------- | | Model Before | nil | widget | widget | | Model After | widget | widget | nil | PaperTrail stores the values in the Model Before row. Most other auditing/versioning plugins store the After row. 1.d. API Summary An introductory sample of common features. When you declare has_paper_trail in your model, you get these methods: And a PaperTrail::Version instance (which is just an ordinary ActiveRecord instance, with all the usual methods) has methods such as: This is just a sample of common features. Keep reading for more. 1.e. Configuration Many aspects of PaperTrail are configurable for individual models; typically this is achieved by passing options to the has_paper_trail method within a given model. Some aspects of PaperTrail are configured globally for all models. These settings are assigned directly on the PaperTrail.config object. A common place to put these settings is in a Rails initializer file such as config/initializers/paper_trail.rb or in an environment-specific configuration file such as config/environments/test.rb. 1.e.1 Global Global configuration options affect all threads. association_reify_error_behaviour enabled has_paper_trail_defaults object_changes_adapter serializer version_limit Syntax example: (options described in detail later) ` These options are intended to be set only once, during app initialization (eg. in config/initializers). It is unsafe to change them while the app is running. In contrast, PaperTrail.request has various options that only apply to a single HTTP request and thus are safe to use while the app is running. 2. Limiting What is Versioned, and When 2.a. Choosing Lifecycle Events To Monitor You can choose which events to track with the on option. For example, if you only want to track update events: has_paper_trail installs callbacks for the specified lifecycle events. There are four potential callbacks, and the default is to install all four, ie. on: [:create, :destroy, :touch, :update]. The versions.event Column Your versions table has an event column with three possible values: | event | callback | | ------- | ------------- | | create | create | | destroy | destroy | | update | touch, update | You may also have the PaperTrail::Version model save a custom string in its event field instead of the typical create, update, destroy. PaperTrail adds an attr_accessor to your model named paper_trail_event, and will insert it, if present, in the event column. Controlling the Order of AR Callbacks If there are other callbacks in your model, their order relative to those installed by has_paper_trail may matter. If you need to control their order, use the paper_trail_on_* methods. The paper_trail.on_destroy method can be further configured to happen :before or :after the destroy event. In PaperTrail 4, the default is :after. In PaperTrail 5, the default will be :before, to support ActiveRecord 5. (see https://github.com/paper-trail-gem/paper_trail/pull/683) 2.b. Choosing When To Save New Versions You can choose the conditions when to add new versions with the if and unless options. For example, to save versions only for US non-draft translations: Choosing Based on Changed Attributes Starting with PaperTrail 4.0, versions are saved during an after-callback. If you decide whether to save a new version based on changed attributes, use attribute_name_was instead of attribute_name. Saving a New Version Manually You may want to save a new version regardless of options like :on, :if, or :unless. Or, in rare situations, you may want to save a new version even if the record has not changed. 2.c. Choosing Attributes To Monitor Ignore You can ignore changes to certain attributes: Changes to just the title or rating will not create a version record. Changes to other attributes will create a version record. The :ignore option can also accept Hash arguments that we are considering deprecating. Only Or, you can specify a list of the only attributes you care about: Only changes to the title will create a version record. The :only option can also accept Hash arguments that we are considering deprecating. If the title is not blank, then only changes to the title will create a version record. Configuring both :ignore and :only is not recommended, but it should work as expected. Passing both :ignore and :only options will result in the article being saved if a changed attribute is included in :only but not in :ignore. Skip You can skip attributes completely with the :skip option. As with :ignore, updates to these attributes will not create a version record. In addition, if a version record is created for some other reason, these attributes will not be persisted. 2.d. Turning PaperTrail Off PaperTrail is on by default, but sometimes you don't want to record versions. Per Process Turn PaperTrail off for all threads in a ruby process. Do not use this in production unless you have a good understanding of threads vs. processes. A legitimate use case is to speed up tests. See Testing below. Per HTTP Request or, Per Class In the rare case that you need to disable versioning for one model while keeping versioning enabled for other models, use: This setting, as with all PaperTrail.request settings, affects only the current request, not all threads. For this rare use case, there is no convenient way to pass a block. In a Rails Controller Callback (Not Recommended) PaperTrail installs a callback in your rails controllers. The installed callback will call paper_trail_enabled_for_controller, which you can override. Because you are unable to control the order of callback execution, this technique is not recommended, but is preserved for backwards compatibility. It would be better to install your own callback and use PaperTrail.request.enabled= as you see fit. Per Method (Removed) The widget.paper_trail.without_versioning method was removed in v10, without an exact replacement. To disable versioning, use the Per Class or Per HTTP Request methods. 2.e. Limiting the Number of Versions Created Configure version_limit to cap the number of versions saved per record. This does not apply to create events. 2.e.1 Per-model limit Models can override the global PaperTrail.config.version_limit setting. Example: To use a per-model limit, your versions table must have an item_subtype column. See Section 4.b.1. 3. Working With Versions 3.a. Reverting And Undeleting A Model PaperTrail makes reverting to a previous version easy: Alternatively you can find the version at a given time: Note version_at gives you the object, not a version, so you don't need to call reify. Undeleting is just as simple: You could even use PaperTrail to implement an undo system; Ryan Bates has! If your model uses optimistic locking don't forget to increment your lock_version before saving or you'll get a StaleObjectError. 3.b. Navigating Versions You can call previous_version and next_version on an item to get it as it was/became. Note that these methods reify the item for you. If instead you have a particular version of an item you can navigate to the previous and next versions. You can find out which of an item's versions yours is: If you got an item by reifying one of its versions, you can navigate back to the version it came from: You can find out whether a model instance is the current, live one -- or whether it came instead from a previous version -- with live?: See also: Section 3.e. Queries 3.c. Diffing Versions There are two scenarios: diffing adjacent versions and diffing non-adjacent versions. The best way to diff adjacent versions is to get PaperTrail to do it for you. If you add an object_changes column to your versions table, PaperTrail will store the changes diff in each version. Ignored attributes are omitted. Prior to 10.0.0, the object_changes were only stored for create and update events. As of 10.0.0, they are stored for all three events. PaperTrail doesn't use diffs internally. When I designed PaperTrail I wanted simplicity and robustness so I decided to make each version of an object self-contained. A version stores all of its object's data, not a diff from the previous version. This means you can delete any version without affecting any other. -Andy To diff non-adjacent versions you'll have to write your own code. These libraries may help: For diffing two strings: htmldiff: expects but doesn't require HTML input and produces HTML output. Works very well but slows down significantly on large (e.g. 5,000 word) inputs. differ: expects plain text input and produces plain text/coloured/HTML/any output. Can do character-wise, word-wise, line-wise, or arbitrary-boundary-string-wise diffs. Works very well on non-HTML input. diff-lcs: old-school, line-wise diffs. For diffing two ActiveRecord objects: Jeremy Weiskotten's PaperTrail fork: uses ActiveSupport's diff to return an array of hashes of the changes. activerecord-diff: rather like ActiveRecord::Dirty but also allows you to specify which columns to compare. 3.d. Deleting Old Versions Over time your versions table will grow to an unwieldy size. Because each version is self-contained (see the Diffing section above for more) you can simply delete any records you don't want any more. For example: 3.e. Queries You can query records in the versions table based on their object or object_changes columns. See also: where_object_changes_from where_object_changes_to where_attribute_changes Only where_object supports text columns. Your object_changes column should be a json or jsonb column if possible. If you must use a text column, you'll have to write a custom object_changes_adapter. 3.f. Defunct item_ids The item_ids in your versions table can become defunct over time, potentially causing application errors when ids in the foreign table are reused. id reuse can be an explicit choice of the application, or implicitly caused by sequence cycling. The chance of id reuse is reduced (but not eliminated) with bigint ids or uuids, no cycle sequences, and/or when versions are periodically deleted. Ideally, a Foreign Key Constraint (FKC) would set item_id to null when an item is deleted. However, items is a polymorphic relationship. A partial FKC (e.g. an FKC with a where clause) is possible, but only in Postgres, and it is impractical to maintain FKCs for every versioned table unless the number of such tables is very small. If per-table Version classes are used, then a partial FKC is no longer needed. So, a normal FKC can be written in any RDBMS, but it remains impractical to maintain so many FKCs. Some applications choose to handle this problem by "soft-deleting" versioned records, i.e. marking them as deleted instead of actually deleting them. This completely prevents id reuse, but adds complexity to the application. In most applications, this is the only known practical solution to the id reuse problem. 4. Saving More Information About Versions 4.a. Finding Out Who Was Responsible For A Change Set PaperTrail.request.whodunnit=, and that value will be stored in the version's whodunnit column. Setting whodunnit to a Proc whodunnit= also accepts a Proc, in the rare case that lazy evaluation is required. Because lazy evaluation can be hard to troubleshoot, this is not recommended for common use. Setting whodunnit Temporarily To set whodunnit temporarily, for the duration of a block, use PaperTrail.request: Setting whodunnit with a controller callback If your controller has a current_user method, PaperTrail provides a callback that will assign current_user.id to whodunnit. You may want set_paper_trail_whodunnit to call a different method to find out who is responsible. To do so, override the user_for_paper_trail method in your controller like this: See also: Setting whodunnit in the rails console Terminator and Originator A version's whodunnit column tells us who changed the object, causing the version to be stored. Because a version stores the object as it looked before the change (see the table above), whodunnit tells us who stopped the object looking like this -- not who made it look like this. Hence whodunnit is aliased as terminator. To find out who made a version's object look that way, use version.paper_trail_originator. And to find out who made a "live" object look like it does, call paper_trail_originator on the object. Storing an ActiveRecord globalid in whodunnit If you would like whodunnit to return an ActiveRecord object instead of a string, please try the paper_trail-globalid gem. 4.b. Associations To track and reify associations, use paper_trail-association_tracking (PT-AT). From 2014 to 2018, association tracking was an experimental feature, but many issues were discovered. To attract new volunteers to address these issues, PT-AT was extracted (see https://github.com/paper-trail-gem/paper_trail/issues/1070). Even though it had always been an experimental feature, we didn't want the extraction of PT-AT to be a breaking change, so great care was taken to remove it slowly. In PT 9, PT-AT was kept as a runtime dependency. In PT 10, it became a development dependency (If you use it you must add it to your own Gemfile) and we kept running all of its tests. In PT 11, it will no longer be a development dependency, and it is responsible for its own tests. 4.b.1 The optional item_subtype column As of PT 10, users may add an item_subtype column to their versions table. When storing versions for STI models, rails stores the base class in item_type (that's just how polymorphic associations like item work) In addition, PT will now store the subclass in item_subtype. If this column is present PT-AT will use it to fix a rare issue with reification of STI subclasses. So, if you use PT-AT and STI, the addition of this column is recommended. https://github.com/paper-trail-gem/paper_trail/issues/594 https://github.com/paper-trail-gem/paper_trail/pull/1143 https://github.com/westonganger/paper_trail-association_tracking/pull/5 4.c. Storing Metadata You can add your own custom columns to your versions table. Values can be given using Model Metadata or Controller Metadata. Model Metadata You can specify metadata in the model using has_paper_trail(meta:). Metadata from Controllers You can also store any information you like from your controller. Override the info_for_paper_trail method in your controller to return a hash whose keys correspond to columns in your versions table. Advantages of Metadata Why would you do this? In this example, author_id is an attribute of Article and PaperTrail will store it anyway in a serialized form in the object column of the version record. But let's say you wanted to pull out all versions for a particular author; without the metadata you would have to deserialize (reify) each version object to see if belonged to the author in question. Clearly this is inefficient. Using the metadata you can find just those versions you want: Metadata can Override PaperTrail Columns Experts only. Metadata will override the normal values that PT would have inserted into its own columns. | PT Column | How bad of an idea? | Alternative | | -------------- | --------------------- | ----------------------------- | | item_type | terrible idea | | | item_id | terrible idea | | | event | meh | paper_trail_event | | whodunnit | meh | PaperTrail.request.whodunnit= | | object | a little dangerous | | | object_changes | a little dangerous | | 5. ActiveRecord 5.a. Single Table Inheritance (STI) PaperTrail supports Single Table Inheritance, and even supports an un-versioned base model, as of 23ffbdc7e1. However, there is a known issue when reifying associations, see https://github.com/paper-trail-gem/paper_trail/issues/594 5.b. Configuring the versions Association 5.b.1. versions association You may configure the name of the versions association by passing a different name (default is :versions) in the versions: options hash: You may pass a scope to the versions association with the scope: option: Any other options supported by has_many can be passed along to the has_many macro via the versions: options hash. Overriding (instead of configuring) the versions method is not supported. Overriding associations is not recommended in general. 5.b.2. item association A PaperTrail::Version object belongs_to an item, the relevant record. The item association is first defined in PaperTrail::VersionConcern, but associations can be redefined. Example: adding a counter_cache to item association When redefining an association, its options are replaced not merged, so don't forget to specify the options from PaperTrail::VersionConcern, like polymorphic. Be advised that redefining an association is an undocumented feature of Rails. 5.c. Generators PaperTrail has one generator, paper_trail:install. It writes, but does not run, a migration file. The migration creates the versions table. Reference The most up-to-date documentation for this generator can be found by running rails generate paper_trail:install --help, but a copy is included here for convenience. 5.d. Protected Attributes As of version 6, PT no longer supports rails 3 or the protected_attributes gem. If you are still using them, you may use PT 5 or lower. We recommend upgrading to strong_parameters as soon as possible. If you must use protected_attributes for now, and want to use PT > 5, you can reopen PaperTrail::Version and add the following attr_accessible fields: This unsupported workaround has been tested with protected_attributes 1.0.9 / rails 4.2.8 / paper_trail 7.0.3. 6. Extensibility 6.a. Custom Version Classes You can specify custom version subclasses with the :class_name option: Unlike ActiveRecord's class_name, you'll have to supply the complete module path to the class (e.g. Foo::BarVersion if your class is inside the module Foo). Advantages For models which have a lot of versions, storing each model's versions in a separate table can improve the performance of certain database queries. Store different version metadata for different models. Configuration If you are using Postgres, you should also define the sequence that your custom version class will use: If you only use custom version classes and don't have a versions table, you must let ActiveRecord know that the PaperTrail::Version class is an abstract_class. You can also specify custom names for the versions and version associations. This is useful if you already have versions or/and version methods on your model. For example: 6.b. Custom Serializer By default, PaperTrail stores your changes as a YAML dump. You can override this with the serializer config option: A valid serializer is a module (or class) that defines a load and dump method. These serializers are included in the gem for your convenience: PaperTrail::Serializers::YAML - Default PaperTrail::Serializers::JSON PostgreSQL JSON column type support If you use PostgreSQL, and would like to store your object (and/or object_changes) data in a column of type json or type jsonb, specify json instead of text for these columns in your migration: If you use the PostgreSQL json or jsonb column type, you do not need to specify a PaperTrail.serializer. Convert existing YAML data to JSON If you've been using PaperTrail for a while with the default YAML serializer and you want to switch to JSON or JSONB, you're in a bit of a bind because there's no automatic way to migrate your data. The first (slow) option is to loop over every record and parse it in Ruby, then write to a temporary column: This technique can be very slow if you have a lot of data. Though slow, it is safe in databases where transactions are protected against DDL, such as Postgres. In databases without such protection, such as MySQL, a table lock may be necessary. If the above technique is too slow for your needs, and you're okay doing without PaperTrail data temporarily, you can create the new column without converting the data. After that migration, your historical data still exists as YAML, and new data will be stored as JSON. Next, convert records from YAML to JSON using a background script. Finally, in another migration, remove the old column. If you use the optional object_changes column, don't forget to convert it also, using the same technique. Convert a Column from Text to JSON If your object column already contains JSON data, and you want to change its data type to json or jsonb, you can use the following DDL. Of course, if your object column contains YAML, you must first convert the data to JSON (see above) before you can change the column type. Using SQL: Using ActiveRecord: 6.c. Custom Object Changes To fully control the contents of their object_changes column, expert users can write an adapter. You should only use this feature if you are comfortable reading PT's source to see exactly how the adapter is used. For example, see how diff is used by reading ::PaperTrail::Events::Base#recordable_object_changes. An adapter can implement any or all of the following methods: diff: Returns the changeset in the desired format given the changeset in the original format load_changeset: Returns the changeset for a given version object where_object_changes: Returns the records resulting from the given hash of attributes. where_object_changes_from: Returns the records resulting from the given hash of attributes where the attributes changed from the provided value(s). where_object_changes_to: Returns the records resulting from the given hash of attributes where the attributes changed to the provided value(s). where_attribute_changes: Returns the records where the attribute changed to or from any value. Depending on your needs, you may choose to implement only a subset of these methods. Known Adapters paper_trail-hashdiff 6.d. Excluding the Object Column The object column ends up storing a lot of duplicate data if you have models that have many columns, and that are updated many times. You can save ~50% of storage space by removing the column from the versions table. It's important to note that this will disable reify and where_object. 7. Testing You may want to turn PaperTrail off to speed up your tests. See Turning PaperTrail Off above. 7.a. Minitest First, disable PT for the entire ruby process. Then, to enable PT for specific tests, you can add a with_versioning test helper method. Then, use the helper in your tests. 7.b. RSpec PaperTrail provides a helper, paper_trail/frameworks/rspec.rb, that works with RSpec to make it easier to control when PaperTrail is enabled during testing. With the helper loaded, PaperTrail will be turned off for all tests by default. To enable PaperTrail for a test you can either wrap the test in a with_versioning block, or pass in versioning: true option to a spec block. The helper will also reset whodunnit to nil before each test to help prevent data spillover between tests. If you are using PaperTrail with Rails, the helper will automatically set the PaperTrail.request.controller_info value to {} as well, again, to help prevent data spillover between tests. There is also a be_versioned matcher provided by PaperTrail's RSpec helper which can be leveraged like so: Matchers The have_a_version_with matcher makes assertions about versions using where_object, based on the object column. The have_a_version_with_changes matcher makes assertions about versions using where_object_changes, based on the optional object_changes column. For more examples of the RSpec matchers, see the Widget spec 7.c. Cucumber PaperTrail provides a helper for Cucumber that works similar to the RSpec helper. If you want to use the helper, you will need to require in your cucumber helper like so: When the helper is loaded, PaperTrail will be turned off for all scenarios by a before hook added by the helper by default. When you want to enable PaperTrail for a scenario, you can wrap code in a with_versioning block in a step, like so: The helper will also reset the whodunnit value to nil before each test to help prevent data spillover between tests. If you are using PaperTrail with Rails, the helper will automatically set the PaperTrail.request.controller_info value to {} as well, again, to help prevent data spillover between tests. 7.d. Spork If you want to use the RSpec or Cucumber helpers with Spork, you will need to manually require the helper(s) in your prefork block on your test helper, like so: 7.e. Zeus or Spring If you want to use the RSpec or Cucumber helpers with Zeus or Spring, you will need to manually require the helper(s) in your test helper, like so: 8. PaperTrail Plugins paper_trail-association_tracking - track and reify associations paper_trail-globalid - enhances whodunnit by adding an actor 9. Integration with Other Libraries ActiveAdmin paper_trail_manager - Browse, subscribe, view and revert changes to records with rails and paper_trail rails_admin_history_rollback - History rollback for rails_admin with PT Sinatra - paper_trail-sinatra globalize - globalize-versioning solidus_papertrail - PT integration for Solidus method to instances of PaperTrail::Version that returns the ActiveRecord object who was responsible for change 10. Related Libraries and Ports izelnakri/paper_trail - An Ecto library, inspired by PT. sequelize-paper-trail - A JS library, inspired by PT. A sequelize plugin for tracking revision history of model instances. Articles PaperTrail Gem Tutorial, 20th April 2020. Jutsu #8 - Version your RoR models with PaperTrail, Thibault, 29th September 2014 Versioning with PaperTrail, Ilya Bodrov, 10th April 2014 Using PaperTrail to track stack traces, T James Corcoran's blog, 1st October 2013. RailsCast #255 - Undo with PaperTrail, 28th February 2011. Keep a Paper Trail with PaperTrail, Linux Magazine, 16th September 2009. Problems Please use GitHub's issue tracker. Contributors Created by Andy Stewart in 2010, maintained since 2012 by Ben Atkins, since 2015 by Jared Beck, with contributions by over 150 people. https://github.com/paper-trail-gem/paper_trail/graphs/contributors Contributing See our contribution guidelines Inspirations Simply Versioned Acts As Audited Intellectual Property Copyright (c) 2011 Andy Stewart (boss@airbladesoftware.com). Released under the MIT licence.

 # # # # # # # # # # # # # # # # # # # #
 Repository: ecomfe/echarts, index: 130, word count: 42063 
 # # # # # # # # # # # # # # # # # # # #

 Amazon Web Services a practical guideThe Open Guide to Amazon Web Services Join us! Credits Contributing guidelines Table of Contents Purpose Why an Open Guide? Scope Legend AWS in General General Information Learning and Career Development Managing AWS Managing Servers and Applications | Specific AWS Services | Basics | Tips | Gotchas | |---------------------------------------|--------------------------------|-------------------------------|------------------------------------------------| | ALB | | | | | AMIs | | | | | API Gateway | | | | | Auto Scaling | | | | | Batch | | | | Certificate Manager | | | | | CLB (ELB) | | | | | CloudFront | | | | | CloudFormation | | | | | CloudWatch | | | | | Device Farm | | | | | DirectConnect | | | | | DynamoDB | | | | | EBS | | | | | EC2 | | | | | ECS | | | | | EKS | | | | | EFS | | | | | Elastic Beanstalk | | | | | Elastic IPs | | | | | ElastiCache | | | | | EMR | | | | | Fargate | | | | | Glacier | | | | | IoT | | | | | Kinesis Firehose | | | | | Kinesis Streams | | | | | KMS | | | | | Lambda | | | | | Load Balancers | | | | | Mobile Hub | | | | | OpsWorks | | | | | RDS | | | | | RDS Aurora | | | | | RDS Aurora MySQL | | | | | RDS Aurora PostgreSQL | | | | | RDS MySQL and MariaDB | | | | | RDS PostgreSQL | | | | | RDS SQL Server | | | | | Redshift | | | | | Route 53 | | | | | S3 | | | | | Security and IAM | | | | | SES | | | | | SNS | | | | | SQS | | | | | Step Functions | | | | | WAF | | | | | VPCs, Network Security, and Security Groups | | | | Special Topics High Availability Billing and Cost Management Further Reading Legal Disclaimer License Figures and Tables Figure: Tools and Services Market Landscape: A selection of third-party companies/products Figure: AWS Data Transfer Costs: Visual overview of data transfer costs Table: Service Matrix: How AWS services compare to alternatives Table: AWS Product Maturity and Releases: AWS product releases Table: Storage Durability, Availability, and Price: A quantitative comparison Why an Open Guide? A lot of information on AWS is already written. Most people learn AWS by reading a blog or a getting started guide and referring to the standard AWS references. Nonetheless, trustworthy and practical information and recommendations arent easy to come by. AWSs own documentation is a great but sprawling resource few have time to read fully, and it doesnt include anything but official facts, so omits experiences of engineers. The information in blogs or Stack Overflow is also not consistently up to date. This guide is by and for engineers who use AWS. It aims to be a useful, living reference that consolidates links, tips, gotchas, and best practices. It arose from discussion and editing over beers by several engineers who have used AWS extensively. Before using the guide, please read the license and disclaimer. Back to top :arrow_up: Please help! This is an early in-progress draft! Its our first attempt at assembling this information, so is far from comprehensive still, and likely to have omissions or errors. Please help by joining the Slack channel(we like to talk about AWS in general, even if you only have questions discussion helps the community and guides improvements) and contributing to the guide. This guide is open to contributions, so unlike a blog, it can keep improving. Like any open source effort, we combine efforts but also review to ensure high quality. Scope Currently, this guide covers selected core services, such as EC2, S3, Load Balancers, EBS, and IAM, and partial details and tips around other services. We expect it to expand. It is not a tutorial, but rather a collection of information you can read and return to. It is for both beginners and the experienced. The goal of this guide is to be: Brief: Keep it dense and use links Practical: Basic facts, concrete details, advice, gotchas, and other folk knowledge Current: We can keep updating it, and anyone can contribute improvements Thoughtful: The goal is to be helpful rather than present dry facts. Thoughtful opinion with rationale is welcome. Suggestions, notes, and opinions based on real experience can be extremely valuable. (We believe this is both possible with a guide of this format, unlike in some other venues.) This guide is not sponsored by AWS or AWS-affiliated vendors. It is written by and for engineers who use AWS. Legend Marks standard/official AWS pages and docs Important or often overlooked tip Serious gotcha (used where risks or time or resource costs are significant: critical security risks, mistakes with significant financial cost, or poor architectural choices that are fundamentally difficult to correct) Regular gotcha, limitation, or quirk (used where consequences are things not working, breaking, or not scaling gracefully) Undocumented feature (folklore) Relatively new (and perhaps immature) services or features Performance discussions Lock-in: Products or decisions that are likely to tie you to AWS in a new or significant way that is, later moving to a non-AWS alternative would be costly in terms of engineering effort Alternative non-AWS options Cost issues, discussion, and gotchas A mild warning attached to full solution or opinionated frameworks that may take significant time to understand and/or might not fit your needs exactly; the opposite of a point solution (the cathedral is a nod to Raymonds metaphor) Colors indicate basics, tips, and gotchas, respectively. Areas where correction or improvement are needed (possibly with link to an issue do help!) General Information When to Use AWS AWS is the dominant public cloud computing provider. In general, cloud computing can refer to one of three types of cloud: public, private, and hybrid. AWS is a public cloud provider, since anyone can use it. Private clouds are within a single (usually large) organization. Many companies use a hybrid of private and public clouds. The core features of AWS are infrastructure-as-a-service (IaaS) that is, virtual machines and supporting infrastructure. Other cloud service models include platform-as-a-service (PaaS), which typically are more fully managed services that deploy customers applications, or software-as-a-service (SaaS), which are cloud-based applications. AWS does offer a few products that fit into these other models, too. In business terms, with infrastructure-as-a-service you have a variable cost model it is OpEx, not CapEx (though some pre-purchased contracts are still CapEx). AWSs TTM revenue was $37.549 billion as of Q1 2020 according to their earnings results (slide 14 in the linked deck), or roughly 14% of Amazon.coms total revenue (slide 11 in the same deck) for the same TTM period. Main reasons to use AWS: If your company is building systems or products that may need to scale and you have technical know-how and you want the most flexible tools and youre not significantly tied into different infrastructure already and you dont have internal, regulatory, or compliance reasons you cant use a public cloud-based solution and youre not on a Microsoft-first tech stack and you dont have a specific reason to use Google Cloud and you can afford, manage, or negotiate its somewhat higher costs ... then AWS is likely a good option for your company. Each of those reasons above might point to situations where other services are preferable. In practice, many, if not most, tech startups as well as a number of modern large companies can or already do benefit from using AWS. Many large enterprises are partly migrating internal infrastructure to Azure, Google Cloud, and AWS. Costs: Billing and cost management are such big topics that we have an entire section on this. EC2 vs. other services: Most users of AWS are most familiar with EC2, AWS flagship virtual server product, and possibly a few others like S3 and CLBs. But AWS products now extend far beyond basic IaaS, and often companies do not properly understand or appreciate all the many AWS services and how they can be applied, due to the sharply growing number of services, their novelty and complexity, branding confusion, and fear of lock-in to proprietary AWS technology. Although a bit daunting, its important for technical decision-makers in companies to understand the breadth of the AWS services and make informed decisions. (We hope this guide will help.) AWS vs. other cloud providers: While AWS is the dominant IaaS provider (31% market share in this 2016 estimate), there is significant competition and alternatives that are better suited to some companies. This Gartner report has a good overview of the major cloud players : Google Cloud Platform. GCP arrived later to market than AWS, but has vast resources and is now used widely by many companies, including a few large ones. It is gaining market share. Not all AWS services have similar or analogous services in GCP. And vice versa: In particular, GCP offers some more advanced machine learning-based services like the Vision, Speech, and Natural Language APIs. Its not common to switch once youre up and running, but it does happen: Spotify migrated from AWS to Google Cloud. There is more discussion on Quora about relative benefits. Of particular note is that VPCs in GCP are global by default with subnetworks per region, while AWS VPCs have to live within a particular region. This gives GCP an edge if youre designing applications with geo-replication from the beginning. Its also possible to share one GCP VPC between multiple projects (roughly analogous to AWS accounts), while in AWS youd have to peer them. Its also possible to peer GCP VPCs in a similar manner to how its done in AWS. Microsoft Azure is the de facto choice for companies and teams that are focused on a Microsoft stack, and it has now placed significant emphasis on Linux as well In China, AWS footprint is relatively small. The market is dominated by Alibabas Alibaba Cloud, formerly called Aliyun. Companies at (very) large scale may want to reduce costs by managing their own infrastructure. For example, Dropbox migrated to their own infrastructure. Other cloud providers such as Digital Ocean offer similar services, sometimes with greater ease of use, more personalized support, or lower cost. However, none of these match the breadth of products, mind-share, and market domination AWS now enjoys. Traditional managed hosting providers such as Rackspace offer cloud solutions as well. AWS vs. PaaS: If your goal is just to put up a single service that does something relatively simple, and youre trying to minimize time managing operations engineering, consider a platform-as-a-service such as Heroku. The AWS approach to PaaS, Elastic Beanstalk, is arguably more complex, especially for simple use cases. AWS vs. web hosting: If your main goal is to host a website or blog, and you dont expect to be building an app or more complex service, you may wish consider one of the myriad web hosting services. AWS vs. managed hosting: Traditionally, many companies pay managed hosting providers to maintain physical servers for them, then build and deploy their software on top of the rented hardware. This makes sense for businesses who want direct control over hardware, due to legacy, performance, or special compliance constraints, but is usually considered old fashioned or unnecessary by many developer-centric startups and younger tech companies. Complexity: AWS will let you build and scale systems to the size of the largest companies, but the complexity of the services when used at scale requires significant depth of knowledge and experience. Even very simple use cases often require more knowledge to do right in AWS than in a simpler environment like Heroku or Digital Ocean. (This guide may help!) Geographic locations: AWS has data centers in over a dozen geographic locations, known as regions, in Europe, East Asia, North and South America, and now Australia and India. It also has many more edge locations globally for reduced latency of services like CloudFront. See the current list of regions and edge locations, including upcoming ones. If your infrastructure needs to be in close physical proximity to another service for latency or throughput reasons (for example, latency to an ad exchange), viability of AWS may depend on the location. Lock-in: As you use AWS, its important to be aware when you are depending on AWS services that do not have equivalents elsewhere. Lock-in may be completely fine for your company, or a significant risk. Its important from a business perspective to make this choice explicitly, and consider the cost, operational, business continuity, and competitive risks of being tied to AWS. AWS is such a dominant and reliable vendor, many companies are comfortable with using AWS to its full extent. Others can tell stories about the dangers of cloud jail when costs spiral. Generally, the more AWS services you use, the more lock-in you have to AWS that is, the more engineering resources (time and money) it will take to change to other providers in the future. Basic services like virtual servers and standard databases are usually easy to migrate to other providers or on premises. Others like load balancers and IAM are specific to AWS but have close equivalents from other providers. The key thing to consider is whether engineers are architecting systems around specific AWS services that are not open source or relatively interchangeable. For example, Lambda, API Gateway, Kinesis, Redshift, and DynamoDB do not have substantially equivalent open source or commercial service equivalents, while EC2, RDS (MySQL or Postgres), EMR, and ElastiCache more or less do. (See more below, where these are noted with .) Combining AWS and other cloud providers: Many customers combine AWS with other non-AWS services. For example, legacy systems or secure data might be in a managed hosting provider, while other systems are AWS. Or a company might only use S3 with another provider doing everything else. However small startups or projects starting fresh will typically stick to AWS or Google Cloud only. Hybrid cloud: In larger enterprises, it is common to have hybrid deployments encompassing private cloud or on-premises servers and AWS or other enterprise cloud providers like IBM/Bluemix, Microsoft/Azure, NetApp, or EMC. Major customers: Who uses AWS and Google Cloud? AWSs list of customers includes large numbers of mainstream online properties and major brands, such as Netflix, Pinterest, Spotify (moving to Google Cloud), Airbnb, Expedia, Yelp, Zynga, Comcast, Nokia, and Bristol-Myers Squibb. Azures list of customers includes companies such as NBC Universal, 3M and Honeywell Inc. Google Clouds list of customers is large as well, and includes a few mainstream sites, such as Snapchat, Best Buy, Dominos, and Sony Music. Back to top :arrow_up: Which Services to Use AWS offers a lot of different services about a hundred at last count. Most customers use a few services heavily, a few services lightly, and the rest not at all. What services youll use depends on your use cases. Choices differ substantially from company to company. Immature and unpopular services: Just because AWS has a service that sounds promising, it doesnt mean you should use it. Some services are very narrow in use case, not mature, are overly opinionated, or have limitations, so building your own solution may be better. We try to give a sense for this by breaking products into categories. Must-know infrastructure: Most typical small to medium-size users will focus on the following services first. If you manage use of AWS systems, you likely need to know at least a little about all of these. (Even if you dont use them, you should learn enough to make that choice intelligently.) IAM: User accounts and identities (you need to think about accounts early on!) EC2: Virtual servers and associated components, including: AMIs: Machine Images Load Balancers: CLBs and ALBs Autoscaling: Capacity scaling (adding and removing servers based on load) EBS: Network-attached disks Elastic IPs: Assigned IP addresses S3: Storage of files Route 53: DNS and domain registration VPC: Virtual networking, network security, and co-location; you automatically use CloudFront: CDN for hosting content CloudWatch: Alerts, paging, monitoring Managed services: Existing software solutions you could run on your own, but with managed deployment: RDS: Managed relational databases (managed MySQL, Postgres, and Amazons own Aurora database) EMR: Managed Hadoop Elasticsearch: Managed Elasticsearch ElastiCache: Managed Redis and Memcached Optional but important infrastructure: These are key and useful infrastructure components that are less widely known and used. You may have legitimate reasons to prefer alternatives, so evaluate with care to be sure they fit your needs: Lambda: Running small, fully managed tasks serverless CloudTrail: AWS API logging and audit (often neglected but important) CloudFormation: Templatized configuration of collections of AWS resources Elastic Beanstalk: Fully managed (PaaS) deployment of packaged Java, .NET, PHP, Node.js, Python, Ruby, Go, and Docker applications EFS: Network filesystem compatible with NFSv4.1 ECS: Docker container/cluster management (note Docker can also be used directly, without ECS) EKS: Kubernetes (K8) Docker Container/Cluster management ECR: Hosted private Docker registry Config: AWS configuration inventory, history, change notifications X-Ray: Trace analysis and debugging for distributed applications such as microservices. Special-purpose infrastructure: These services are focused on specific use cases and should be evaluated if they apply to your situation. Many also are proprietary architectures, so tend to tie you to AWS. DynamoDB: Low-latency NoSQL key-value store Glacier: Slow and cheap alternative to S3 Kinesis: Streaming (distributed log) service SQS: Message queueing service Redshift: Data warehouse QuickSight: Business intelligence service SES: Send and receive e-mail for marketing or transactions API Gateway: Proxy, manage, and secure API calls IoT: Manage bidirectional communication over HTTP, WebSockets, and MQTT between AWS and clients (often but not necessarily things like appliances or sensors) WAF: Web firewall for CloudFront to deflect attacks KMS: Store and manage encryption keys securely Inspector: Security audit Trusted Advisor: Automated tips on reducing cost or making improvements Certificate Manager: Manage SSL/TLS certificates for AWS services Fargate: Docker containers management, backend for ECS and EKS Compound services: These are similarly specific, but are full-blown services that tackle complex problems and may tie you in. Usefulness depends on your requirements. If you have large or significant need, you may have these already managed by in-house systems and engineering teams. Machine Learning: Machine learning model training and classification Lex: Automatic speech recognition (ASR) and natural language understanding (NLU) Polly: Text-to-speech engine in the cloud Rekognition: Service for image recognition Data Pipeline: Managed ETL service SWF: Managed state tracker for distributed polyglot job workflow Lumberyard: 3D game engine Mobile/app development: SNS: Manage app push notifications and other end-user notifications Cognito: User authentication via Facebook, Twitter, etc. Device Farm: Cloud-based device testing Mobile Analytics: Analytics solution for app usage Mobile Hub: Comprehensive, managed mobile app framework Enterprise services: These are relevant if you have significant corporate cloud-based or hybrid needs. Many smaller companies and startups use other solutions, like Google Apps or Box. Larger companies may also have their own non-AWS IT solutions. AppStream: Windows apps in the cloud, with access from many devices Workspaces: Windows desktop in the cloud, with access from many devices WorkDocs (formerly Zocalo): Enterprise document sharing WorkMail: Enterprise managed e-mail and calendaring service Directory Service: Microsoft Active Directory in the cloud Direct Connect: Dedicated network connection between office or data center and AWS Storage Gateway: Bridge between on-premises IT and cloud storage Service Catalog: IT service approval and compliance Probably-don't-need-to-know services: Bottom line, our informal polling indicates these services are just not broadly used and often for good reasons: Snowball: If you want to ship petabytes of data into or out of Amazon using a physical appliance, read on. Snowmobile: Appliances are great, but if you've got exabyte scale data to get into Amazon, nothing beats a tractor trailer full of drives. CodeCommit: Git service. Youre probably already using GitHub or your own solution (Stackshare has informal stats). CodePipeline: Continuous integration. You likely have another solution already. CodeDeploy: Deployment of code to EC2 servers. Again, you likely have another solution. OpsWorks: Management of your deployments using Chef or (as of November 2017) Puppet Enterprise. AWS in Plain English offers more friendly explanation of what all the other different services are. Back to top :arrow_up: Tools and Services Market Landscape There are now enough cloud and big data enterprise companies and products that few can keep up with the market landscape. Weve assembled a landscape of a few of the services. This is far from complete, but tries to emphasize services that are popular with AWS practitioners services that specifically help with AWS, or a complementary, or tools almost anyone using AWS must learn. Suggestions to improve this figure? Please file an issue. Back to top :arrow_up: Common Concepts The AWS General Reference covers a bunch of common concepts that are relevant for multiple services. AWS allows deployments in regions, which are isolated geographic locations that help you reduce latency or offer additional redundancy. Regions contain availability zones(AZs), which are typically the first tool of choice for high availability). AZs are physically separate from one another even within the same region, and may span multiple physical data centers. While they are connected via low latency links, natural disasters afflicting one should not affect others. Each service has API endpoints for each region. Endpoints differ from service to service and not all services are available in each region, as listed in these tables. Amazon Resource Names (ARNs) are specially formatted identifiers for identifying resources. They start with 'arn:' and are used in many services, and in particular for IAM policies. Back to top :arrow_up: Service Matrix Many services within AWS can at least be compared with Google Cloud offerings or with internal Google services. And often times you could assemble the same thing yourself with open source software. This table is an effort at listing these rough correspondences. (Remember that this table is imperfect as in almost every case there are subtle differences of features!) | Service | AWS | Google Cloud | Google Internal | Microsoft Azure | Other providers | Open source build your own | Openstack | |-------------------------------|------------------------------------------------------------------------------|------------------------------|-----------------|------------------------------------|-----------------------------------|------------------------------------------------------------|------------------------------------------------------------| | Virtual server | EC2 | Compute Engine (GCE) | | Virtual Machine | DigitalOcean | OpenStack | Nova | | PaaS | Elastic Beanstalk | App Engine | App Engine | Web Apps | Heroku, AppFog, OpenShift | Meteor, AppScale, Cloud Foundry, Convox | | Serverless, microservices | Lambda, API Gateway | Functions | | Function Apps | PubNub Blocks, Auth0 Webtask | Kong, Tyk | Qinling | | Container, cluster manager | ECS, EKS, Fargate | Container Engine, Kubernetes | Borg or Omega | Container Service | | Kubernetes, Mesos, Aurora | Zun | | Object storage | S3 | Cloud Storage | GFS | Storage Account | DigitalOcean Spaces | Swift, HDFS, Minio | Swift | | Block storage | EBS | Persistent Disk | | Storage Account | DigitalOcean Volumes | NFS | Cinder | | SQL datastore | RDS | Cloud SQL | | SQL Database | | MySQL, PostgreSQL | Trove (stores NoSQL as well) | | Sharded RDBMS | | Cloud Spanner | F1, Spanner | Azure Database for PostgreSQL - Hyperscale (Citus) | | Crate.io, CockroachDB | | Bigtable | | Cloud Bigtable | Bigtable | | | HBase | | Key-value store, column store | DynamoDB | Cloud Datastore | Megastore | Tables, DocumentDB | | Cassandra, CouchDB, RethinkDB, Redis | | Memory cache | ElastiCache | App Engine Memcache | | Redis Cache | | Memcached, Redis | | Search | CloudSearch, Elasticsearch (managed) | | | Search | Algolia, QBox, Elastic Cloud | Elasticsearch, Solr | | Data warehouse | Redshift | BigQuery | Dremel | SQL Data Warehouse | Oracle, IBM, SAP, HP, many others | Greenplum | | Business intelligence | QuickSight | Data Studio 360 | | Power BI | Tableau | | | Lock manager | DynamoDB (weak) | | Chubby | Lease blobs in Storage Account | | ZooKeeper, Etcd, Consul | | Message broker | SQS, SNS, IoT | Pub/Sub | PubSub2 | Service Bus | | RabbitMQ, Kafka, 0MQ | | Streaming, distributed log | Kinesis | Dataflow | PubSub2 | Event Hubs | | Kafka Streams, Apex, Flink, Spark Streaming, Storm | | MapReduce | EMR | Dataproc | MapReduce | HDInsight, DataLake Analytics | Qubole | Hadoop | | Monitoring | CloudWatch | Stackdriver Monitoring | Borgmon | Monitor | | Prometheus(?) | | Tracing | X-Ray | Stackdriver Trace | | Monitor (Application Insights) | DataDog, New Relic, Epsagon | Zipkin, Jaeger, Appdash | Metric management | | | Borgmon, TSDB | Application Insights | | Graphite, InfluxDB, OpenTSDB, Grafana, Riemann, Prometheus | | CDN | CloudFront | Cloud CDN | | CDN | Akamai, Fastly, Cloudflare, Limelight Networks | Apache Traffic Server | | Load balancer | CLB/ALB | Load Balancing | GFE | Load Balancer, Application Gateway | | nginx, HAProxy, Apache Traffic Server | | DNS | Route53 | DNS | | DNS | | bind | | Email | SES | | | | Sendgrid, Mandrill, Postmark | | | Git hosting | CodeCommit | Cloud Source Repositories | | Visual Studio Team Services | GitHub, BitBucket | GitLab | | User authentication | Cognito | Firebase Authentication | | Azure Active Directory | | oauth.io | | Mobile app analytics | Mobile Analytics | Firebase Analytics | | HockeyApp | Mixpanel | | | Mobile app testing | Device Farm | Firebase Test Lab | | Xamarin Test Cloud | BrowserStack, Sauce Labs, Testdroid | | Managing SSL/TLS certificates | Certificate Manager | | | | Let's Encrypt, Comodo, Symantec, GlobalSign | | Automatic speech recognition and natural language understanding | Transcribe (ASR), Lex (NLU) | Cloud Speech API, Natural Language API | | Cognitive services | AYLIEN Text Analysis API, Ambiverse Natural Language Understanding API |Stanford's Core NLP Suite, Apache OpenNLP, Apache UIMA, spaCy | | Text-to-speech engine in the cloud | Polly | | | |Nuance, Vocalware, IBM | Mimic, eSpeak, MaryTTS | | Image recognition | Rekognition | Vision API | |Cognitive services | IBM Watson, Clarifai |TensorFlow, OpenCV | | OCR (Text recognition) | Textract (documents), Rekognition (photographs) | Cloud Vision API | | Computer Vision API | | Tesseract | | Language Translation | Translate | Translate | | Translator Text API | | Apertium | | File Share and Sync | WorkDocs | Google Docs | |OneDrive | Dropbox, Box, Citrix File Share |ownCloud | | Machine Learning | SageMaker, DeepLens, ML | ML Engine, Auto ML | |ML Studio | Watson ML | | | Data Loss Prevention | Macie | Cloud Data Loss Prevention | | Azure Information Protection | | | Please help fill this table in. Selected resources with more detail on this chart: Google internal: MapReduce, Bigtable, Spanner, F1 vs Spanner, Bigtable vs Megastore Back to top :arrow_up: AWS Product Maturity and Releases Its important to know the maturity of each AWS product. Here is a mostly complete list of first release date, with links to the release notes. Most recently released services are first. Not all services are available in all regions; see this table. | Service | Original release | Availability | CLI Support | HIPAA Compliant | PCI-DSS Compliant | |------------------------------------------------------------------------------------------------------------|------------------|-------------------------------------------------------------------------------|:-----------:|:---------------:|:-----------------:| | X-Ray | 2016-12 | General | | | | | Lex | 2016-11 | Preview | | | | | Polly | 2016-11 | General | | | | | Rekognition | 2016-11 | General | | | | | Athena | 2016-11 | General | | | | | Batch | 2016-11 | General | | | | | Database Migration Service | 2016-03 | General | | | | | Certificate Manager | 2016-01 | General | | | | | IoT | 2015-08 | General | | |13 | | WAF | 2015-10 | General | | | | | Data Pipeline | 2015-10 | General | | | | | Elasticsearch | 2015-10 | General | | | | | Aurora | 2015-07 | General | | 3 | 3 | | Service Catalog | 2015-07 | General | | | | | Device Farm | 2015-07 | General | | | | | CodePipeline | 2015-07 | General | | | | | CodeCommit | 2015-07 | General | | | | | API Gateway | 2015-07 | General | | 1 | | | Config | 2015-06 | General | | | | | EFS | 2015-05 | General | | | | | Machine Learning | 2015-04 | General | | | | | Lambda | 2014-11 | General | | | | | ECS | 2014-11 | General | | | | | EKS | 2018-06 | General | 12 | | | | KMS | 2014-11 | General | | | | | CodeDeploy | 2014-11 | General | | | | | Kinesis | 2013-12 | General | | | 11 | | CloudTrail | 2013-11 | General | | | | | AppStream | 2013-11 | Preview | | | | | CloudHSM | 2013-03 | General | | | | | Silk | 2013-03 | Obsolete? | | | | | OpsWorks | 2013-02 | General | | | | | Redshift | 2013-02 | General | | | | | Elastic Transcoder | 2013-01 | General | | | | | Glacier | 2012-08 | General | | | | | CloudSearch | 2012-04 | General | | | | | SWF | 2012-02 | General | | | | | Storage Gateway | 2012-01 | General | | | | | DynamoDB | 2012-01 | General | | | | | DirectConnect | 2011-08 | General | | | | | ElastiCache | 2011-08 | General | |14 |14 | | CloudFormation | 2011-04 | General | | | | | SES | 2011-01 | General | | | | | Elastic Beanstalk | 2010-12 | General | | | | | Route 53 | 2010-10 | General | | | | | IAM | 2010-09 | General | | | | | SNS | 2010-04 | General | | | | | EMR | 2010-04 | General | | | | | RDS | 2009-12 | General | |2 |9 | | VPC | 2009-08 | General | | | | | Snowball | 2015-10 | General | | |15 | | Snowmobile | 2016-11 | General | | | | | CloudWatch | 2009-05 | General | | | | | CloudFront | 2008-11 | General | | 4 | | | Fulfillment Web Service | 2008-03 | Obsolete? | | | | | SimpleDB | 2007-12 | Nearly obsolete | | | | | DevPay | 2007-12 | General | | | | | Flexible Payments Service | 2007-08 | Retired | | | | | EC2 | 2006-08 | General | | 5,6,7 | 6,7,10 | | SQS | 2006-07 | General | | | | | S3 | 2006-03 | General | | 8 | | | Alexa Top Sites | 2006-01 | General HTTP-only | | | | | Alexa Web Information Service | 2005-10 | General HTTP-only | | | | Back to top :arrow_up: Footnotes 1: Excludes use of Amazon API Gateway caching 2: RDS MySQL, Oracle, and PostgreSQL engines only 3: MySQL-compatible Aurora edition only 4: Excludes Lambda@Edge 5: Includes EC2 Systems Manager 6: Includes Elastic Block Storage (EBS) 7: Includes Elastic Load Balancing 8: Includes S3 Transfer Acceleration 9: Includes RDS MySQL, Oracle, PostgreSQL, SQL Server, and MariaDB 10: Includes Auto-Scaling 11: Data Analytics, Streams, Video Streams and Firehose 12: Kubernetes uses a custom CLI for Pod/Service management called kubectl. AWS CLI only handles Kubernetes Master concerns 13: IoT Core (includes Device Management) and Greengrass 14: ElastiCache for Redis only 15: Snowball and Snowball Edge Compliance Many applications have strict requirements around reliability, security, or data privacy. The AWS Compliance page has details about AWSs certifications, which include PCI DSS Level 1, SOC 1,2, and 3, HIPAA, and ISO 9001. Security in the cloud is a complex topic, based on a shared responsibility model, where some elements of compliance are provided by AWS, and some are provided by your company. Several third-party vendors offer assistance with compliance, security, and auditing on AWS. If you have substantial needs in these areas, assistance is a good idea. From inside China, AWS services outside China are generally accessible, though there are at times breakages in service. There are also AWS services inside China. Getting Help and Support Forums: For many problems, its worth searching or asking for help in the discussion forums to see if its a known issue. Premium support: AWS offers several levels of premium support. The first tier, called "Developer support" lets you file support tickets with 12 to 24 hour turnaround time, it starts at $29 but once your monthly spend reaches around $1000 it changes to a 3% surcharge on your bill. The higher-level support services are quite expensive and increase your bill by up to 10%. Many large and effective companies never pay for this level of support. They are usually more helpful for midsize or larger companies needing rapid turnaround on deeper or more perplexing problems. Keep in mind, a flexible architecture can reduce need for support. You shouldnt be relying on AWS to solve your problems often. For example, if you can easily re-provision a new server, it may not be urgent to solve a rare kernel-level issue unique to one EC2 instance. If your EBS volumes have recent snapshots, you may be able to restore a volume before support can rectify the issue with the old volume. If your services have an issue in one availability zone, you should in any case be able to rely on a redundant zone or migrate services to another zone. Larger customers also get access to AWS Enterprise support, with dedicated technical account managers (TAMs) and shorter response time SLAs. There is definitely some controversy about how useful the paid support is. The support staff dont always seem to have the information and authority to solve the problems that are brought to their attention. Often your ability to have a problem solved may depend on your relationship with your account rep. Account manager: If you are at significant levels of spend (thousands of US dollars plus per month), you may be assigned (or may wish to ask for) a dedicated account manager. These are a great resource, even if youre not paying for premium support. Build a good relationship with them and make use of them, for questions, problems, and guidance. Assign a single point of contact on your companys side, to avoid confusing or overwhelming them. Contact: The main web contact point for AWS is here. Many technical requests can be made via these channels. Consulting and managed services: For more hands-on assistance, AWS has established relationships with many consulting partners and managed service partners. The big consultants wont be cheap, but depending on your needs, may save you costs long term by helping you set up your architecture more effectively, or offering specific expertise, e.g. security. Managed service providers provide longer-term full-service management of cloud resources. AWS Professional Services: AWS provides consulting services alone or in combination with partners. Restrictions and Other Notes Lots of resources in Amazon have limits on them. This is actually helpful, so you dont incur large costs accidentally. You have to request that quotas be increased by opening support tickets. Some limits are easy to raise, and some are not. (Some of these are noted in sections below.) Additionally, not all service limits are published. Obtaining Current Limits and Usage: Limit information for a service may be available from the service API, Trusted Advisor, both or neither (in which case you'll need to contact Support). This page from the awslimitchecker tool's documentation provides a nice summary of available retrieval options for each limit. The tool itself is also valuable for automating limit checks. AWS terms of service are extensive. Much is expected boilerplate, but it does contain important notes and restrictions on each service. In particular, there are restrictions against using many AWS services in safety-critical systems. (Those appreciative of legal humor may wish to review clause 42.10.) Related Topics OpenStack is a private cloud alternative to AWS used by large companies that wish to avoid public cloud offerings. Learning and Career Development Certifications Certifications: AWS offers certifications for IT professionals who want to demonstrate their knowledge. Certified Cloud Practitioner Certified Solutions Architect Associate Certified Developer Associate Certified SysOps Administrator Associate Certified Solutions Architect Professional Certified DevOps Engineer Professional Certified Security Specialty Certified Big Data Specialty Certified Advanced Networking Specialty Certified Machine Learning Specialty Certified Alexa Skill Builder Specialty Certified Data Analytics Specialty Certified Database Specialty Associate level certifications were once required as pre-requisites to taking the Professional examinations - this is no longer the case. Getting certified: If youre interested in studying for and getting certifications, this practical overview tells you a lot of what you need to know. The official page is here and there is an FAQ. Training for certifications: Training is offered by AWS themselves (mainly instructor-led and on-site) and various third-party companies (usually as video-based training) such as A Cloud Guru, CloudAcademy and Linux Academy. Do you need a certification? Especially in consulting companies or when working in key tech roles in large non-tech companies, certifications are important credentials. In others, including in many tech companies and startups, certifications are not common or considered necessary. (In fact, fairly or not, some Silicon Valley hiring managers and engineers see them as a negative signal on a resume.) Certifications are required to access certificate lounges at official AWS events such as Summits and re:Invent. Lounges typically provide power charging points, seats and relatively better coffee. Managing AWS Managing Infrastructure State and Change A great challenge in using AWS to build complex systems (and with DevOps in general) is to manage infrastructure state effectively over time. In general, this boils down to three broad goals for the state of your infrastructure: Visibility: Do you know the state of your infrastructure (what services you are using, and exactly how)? Do you also know when you and anyone on your team make changes? Can you detect misconfigurations, problems, and incidents with your service? Automation: Can you reconfigure your infrastructure to reproduce past configurations or scale up existing ones without a lot of extra manual work, or requiring knowledge thats only in someones head? Can you respond to incidents easily or automatically? Flexibility: Can you improve your configurations and scale up in new ways without significant effort? Can you add more complexity using the same tools? Do you share, review, and improve your configurations within your team? Much of what we discuss below is really about how to improve the answers to these questions. There are several approaches to deploying infrastructure with AWS, from the console to complex automation tools, to third-party services, all of which attempt to help achieve visibility, automation, and flexibility. AWS Configuration Management The first way most people experiment with AWS is via its web interface, the AWS Console. But using the Console is a highly manual process, and often works against automation or flexibility. So if youre not going to manage your AWS configurations manually, what should you do? Sadly, there are no simple, universal answers each approach has pros and cons, and the approaches taken by different companies vary widely, and include directly using APIs (and building tooling on top yourself), using command-line tools, and using third-party tools and services. AWS Console The AWS Console lets you control much (but not all) functionality of AWS via a web interface. Ideally, you should only use the AWS Console in a few specific situations: Its great for read-only usage. If youre trying to understand the state of your system, logging in and browsing it is very helpful. It is also reasonably workable for very small systems and teams (for example, one engineer setting up one server that doesnt change often). It can be useful for operations youre only going to do rarely, like less than once a month (for example, a one-time VPC setup you probably wont revisit for a year). In this case using the console can be the simplest approach. Think before you use the console: The AWS Console is convenient, but also the enemy of automation, reproducibility, and team communication. If youre likely to be making the same change multiple times, avoid the console. Favor some sort of automation, or at least have a path toward automation, as discussed next. Not only does using the console preclude automation, which wastes time later, but it prevents documentation, clarity, and standardization around processes for yourself and your team. Command-Line tools The aws command-line interface (CLI), used via the aws command, is the most basic way to save and automate AWS operations. Dont underestimate its power. It also has the advantage of being well-maintained it covers a large proportion of all AWS services, and is up to date. In general, whenever you can, prefer the command line to the AWS Console for performing operations. Even in the absence of fancier tools, you can write simple Bash scripts that invoke aws with specific arguments, and check these into Git. This is a primitive but effective way to document operations youve performed. It improves automation, allows code review and sharing on a team, and gives others a starting point for future work. For use that is primarily interactive (not scripted), consider instead using the aws-shell tool from AWS. It is easier to use, with auto-completion and a colorful UI, but still works on the command line. If youre using SAWS, a previous version of the program, you should migrate to aws-shell. APIs and SDKs SDKs for using AWS APIs are available in most major languages, with Go, iOS, Java, JavaScript, Python, Ruby, and PHP being most heavily used. AWS maintains a short list, but the awesome-aws list is the most comprehensive and current. Note support for C++ is still new. Retry logic: An important aspect to consider whenever using SDKs is error handling; under heavy use, a wide variety of failures, from programming errors to throttling to AWS-related outages or failures, can be expected to occur. SDKs typically implement exponential backoff to address this, but this may need to be understood and adjusted over time for some applications. For example, it is often helpful to alert on some error codes and not on others. Dont use APIs directly. Although AWS documentation includes lots of API details, its better to use the SDKs for your preferred language to access APIs. SDKs are more mature, robust, and well-maintained than something youd write yourself. Boto A good way to automate operations in a custom way is Boto3, also known as the Amazon SDK for Python. Boto2, the previous version of this library, has been in wide use for years, but now there is a newer version with official support from Amazon, so prefer Boto3 for new projects. Boto3 contains a variety of APIs that operate at either a high level or a low level, here some explanation of both: The low level APIs (Client APIs) are mapped to AWS Cloud service-specific APIs, and all service operations are supported by clients. Clients are generated from a JSON service definition file. The high level option, Resource APIs, allows you to avoid calling the network at the low level and instead provide an object-oriented way to interact with AWS Cloud services. Boto3 has a lot of helpful features like waiters, which provide a structure that allows for code to wait for changes to occur in the cloud, for example, when you are creating an EC2 instance and need wait until the instance is running in order to perform another task. If you find yourself writing a Bash script with more than one or two CLI commands, youre probably doing it wrong. Stop, and consider writing a Boto script instead. This has the advantages that you can: Check return codes easily so success of each step depends on success of past steps. Grab interesting bits of data from responses, like instance ids or DNS names. Add useful environment information (for example, tag your instances with git revisions, or inject the latest build identifier into your initialization script). Back to top :arrow_up: General Visibility Tagging resources is an essential practice, especially as organizations grow, to better understand your resource usage. For example, through automation or convention, you can add tags: For the org or developer that owns that resource For the product that resource supports To label lifecycles, such as temporary resources or one that should be deprovisioned in the future To distinguish production-critical infrastructure (e.g. serving systems vs backend pipelines) To distinguish resources with special security or compliance requirements To (once enabled) allocate cost. Note that cost allocation tags only apply on a forward-looking basis; you can't retroactively apply them to items already billed. For many years, there was a notorious 10 tag limit per resource, which could not be raised and caused many companies significant pain. As of 2016, this was raised to 50 tags per resource. In 2017, AWS introduced the ability to enforce tagging on instance and volume creation, deprecating portions of third party tools such as Cloud Custodian. Tags are case sensitive; 'environment' and 'Environment' are two different tags. Automation in setting tags is likely the only sensible option at significant scale. There is a bug in the ASG console where spaces after tag names are preserved. So if you type "Name " with a space at the end you will not get the expected behavior. This is probably true in other locations and SDKs also. Be sure you do not add trailing spaces to tag keys unless you really mean it. (As of Jul 2018) Managing Servers and Applications Back to top :arrow_up: AWS vs Server Configuration This guide is about AWS, not DevOps or server configuration management in general. But before getting into AWS in detail, its worth noting that in addition to the configuration management for your AWS resources, there is the long-standing problem of configuration management for servers themselves. Back to top :arrow_up: Philosophy Herokus Twelve-Factor App principles list some established general best practices for deploying applications. Pets vs cattle: Treat servers like cattle, not pets. That is, design systems so infrastructure is disposable. It should be minimally worrisome if a server is unexpectedly destroyed. The concept of immutable infrastructure is an extension of this idea. Minimize application state on EC2 instances. In general, instances should be able to be killed or die unexpectedly with minimal impact. State that is in your application should quickly move to RDS, S3, DynamoDB, EFS, or other data stores not on that instance. EBS is also an option, though it generally should not be the bootable volume, and EBS will require manual or automated re-mounting. Back to top :arrow_up: Server Configuration Management There is a large set of open source tools for managing configuration of server instances. These are generally not dependent on any particular cloud infrastructure, and work with any variety of Linux (or in many cases, a variety of operating systems). Leading configuration management tools are Puppet, Chef, Ansible, and Saltstack. These arent the focus of this guide, but we may mention them as they relate to AWS. Back to top :arrow_up: Containers and AWS Docker and the containerization trend are changing the way many servers and services are deployed in general. Containers are designed as a way to package up your application(s) and all of their dependencies in a known way. When you build a container, you are including every library or binary your application needs, outside of the kernel. A big advantage of this approach is that its easy to test and validate a container locally without worrying about some difference between your computer and the servers you deploy on. A consequence of this is that you need fewer AMIs and boot scripts; for most deployments, the only boot script you need is a template that fetches an exported docker image and runs it. Companies that are embracing microservice architectures will often turn to container-based deployments. AWS launched ECS as a service to manage clusters via Docker in late 2014, though many people still deploy Docker directly themselves. See the ECS section for more details. AWS launched EKS as a service to manage Kubernetes Clusters mid 2018, though many people still deploy ECS or use Docker directly themselves. See the EKS section for more details. Back to top :arrow_up: Visibility Store and track instance metadata (such as instance id, availability zone, etc.) and deployment info (application build id, Git revision, etc.) in your logs or reports. The instance metadata service can help collect some of the AWS data youll need. Use log management services: Be sure to set up a way to view and manage logs externally from servers. Cloud-based services such as Sumo Logic, Splunk Cloud, Scalyr, LogDNA, and Loggly are the easiest to set up and use (and also the most expensive, which may be a factor depending on how much log data you have). Major open source alternatives include Elasticsearch, Logstash, and Kibana (the Elastic Stack) and Graylog. If you can afford it (you have little data or lots of money) and dont have special needs, it makes sense to use hosted services whenever possible, since setting up your own scalable log processing systems is notoriously time consuming. Track and graph metrics: The AWS Console can show you simple graphs from CloudWatch, you typically will want to track and graph many kinds of metrics, from CloudWatch and your applications. Collect and export helpful metrics everywhere you can (and as long as volume is manageable enough you can afford it). Services like Librato, KeenIO, and Datadog have fancier features or better user interfaces that can save a lot of time. (A more detailed comparison is here.) Use Prometheus or Graphite as timeseries databases for your metrics (both are open source). Grafana can visualize with dashboards the stored metrics of both timeseries databases (also open source). Back to top :arrow_up: Tips for Managing Servers Timezone settings on servers: unless absolutely necessary, always set the timezone on servers to UTC (see instructions for your distribution, such as Ubuntu, CentOS or Amazon Linux). Numerous distributed systems rely on time for synchronization and coordination and UTC provides the universal reference plane: it is not subject to daylight savings changes and adjustments in local time. It will also save you a lot of headache debugging elusive timezone issues and provide coherent timeline of events in your logging and audit systems. NTP and accurate time: If you are not using Amazon Linux (which comes preconfigured), you should confirm your servers configure NTP correctly, to avoid insidious time drift (which can then cause all sorts of issues, from breaking API calls to misleading logs). This should be part of your automatic configuration for every server. If time has already drifted substantially (generally >1000 seconds), remember NTP wont shift it back, so you may need to remediate manually (for example, like this on Ubuntu). Testing immutable infrastructure: If you want to be proactive about testing your services ability to cope with instance termination or failure, it can be helpful to introduce random instance termination during business hours, which will expose any such issues at a time when engineers are available to identify and fix them. Netflixs Simian Army (specifically, Chaos Monkey) is a popular tool for this. Alternatively, chaos-lambda by the BBC is a lightweight option which runs on AWS Lambda. Security and IAM We cover security basics first, since configuring user accounts is something you usually have to do early on when setting up your system. Security and IAM Basics IAM Homepage User guide FAQ The AWS Security Blog is one of the best sources of news and information on AWS security. IAM is the service you use to manage accounts and permissioning for AWS. Managing security and access control with AWS is critical, so every AWS administrator needs to use and understand IAM, at least at a basic level. IAM identities include users (people or services that are using AWS), groups (containers for sets of users and their permissions), and roles (containers for permissions assigned to AWS service instances). Permissions for these identities are governed by policies You can use AWS pre-defined policies or custom policies that you create. IAM manages various kinds of authentication, for both users and for software services that may need to authenticate with AWS, including: Passwords to log into the console. These are a username and password for real users. Access keys, which you may use with command-line tools. These are two strings, one the id, which is an upper-case alphabetic string of the form 'AXXXXXXXXXXXXXXXXXXX', and the other is the secret, which is a 40-character mixed-case base64-style string. These are often set up for services, not just users. Access keys that start with AKIA are normal keys. Access keys that start with ASIA are session/temporary keys from STS, and will require an additional "SessionToken" parameter to be sent along with the id and secret. See the documentation for a complete list of access key prefixes. Multi-factor authentication (MFA), which is the highly recommended practice of using a keychain fob or smartphone app as a second layer of protection for user authentication. IAM allows complex and fine-grained control of permissions, dividing users into groups, assigning permissions to roles, and so on. There is a policy language that can be used to customize security policies in a fine-grained way. An excellent high level overview of IAM policy concepts lives at IAM Policies In A Nutshell. The policy language has a complex and error-prone JSON syntax thats quite confusing, so unless you are an expert, it is wise to base yours off trusted examples or AWS own pre-defined managed policies. At the beginning, IAM policy may be very simple, but for large systems, it will grow in complexity, and need to be managed with care. Make sure one person (perhaps with a backup) in your organization is formally assigned ownership of managing IAM policies, make sure every administrator works with that person to have changes reviewed. This goes a long way to avoiding accidental and serious misconfigurations. It is best to give each user or service the minimum privileges needed to perform their duties. This is the principle of least privilege, one of the foundations of good security. Organize all IAM users and groups according to levels of access they need. IAM has the permission hierarchy of: Explicit deny: The most restrictive policy wins. Explicit allow: Access permissions to any resource has to be explicitly given. Implicit deny: All permissions are implicitly denied by default. You can test policy permissions via the AWS IAM policy simulator tool. This is particularly useful if you write custom policies. Back to top :arrow_up: Security and IAM Tips Use IAM to create individual user accounts and use IAM accounts for all users from the beginning. This is slightly more work, but not that much. That way, you define different users, and groups with different levels of privilege (if you want, choose from Amazons default suggestions, of administrator, power user, etc.). This allows credential revocation, which is critical in some situations. If an employee leaves, or a key is compromised, you can revoke credentials with little effort. You can set up Active Directory federation to use organizational accounts in AWS. Enable MFA on your account. You should always use MFA, and the sooner the better enabling it when you already have many users is extra work. Unfortunately it cant be enforced in software, so an administrative policy has to be established. Most users can use the Google Authenticator app (on iOS or Android) to support two-factor authentication. For the root account, consider a hardware fob. Restrict use of significant IAM credentials as much as possible. Remember that in the cloud, loss of a highly capable IAM credential could essentially mean game over, for your deployment, your users, or your whole company. Do NOT use the Root User account other than when you initially create your account. Create custom IAM users and/or roles and use those for your applications instead. Lock up access and use of the root credentials as much as possible. Ideally they should be effectively offline. For critical deployments, this means attached to an actual MFA device, physically secured and rarely used. Turn on CloudTrail: One of the first things you should do is enable CloudTrail. Even if you are not a security hawk, there is little reason not to do this from the beginning, so you have data on what has been happening in your AWS account should you need that information. Youll likely also want to set up a log management service to search and access these logs. Use IAM roles for EC2: Rather than assign IAM users to applications like services and then sharing the sensitive credentials, define and assign roles to EC2 instances and have applications retrieve credentials from the instance metadata. Assign IAM roles by realm for example, to development, staging, and production. If youre setting up a role, it should be tied to a specific realm so you have clean separation. This prevents, for example, a development instance from connecting to a production database. Best practices: AWS list of best practices is worth reading in full up front. IAM Reference: This interactive reference for all IAM actions, effects, and resources is great to have open while writing new or trying to understand existing IAM policies. Multiple accounts: Decide on whether you want to use multiple AWS accounts and research how to organize access across them. Factors to consider: Number of users Importance of isolation Resource Limits Permission granularity Security API Limits Regulatory issues Workload Size of infrastructure Cost of multi-account overhead: Internal AWS service management tools may need to be custom built or adapted. It can help to use separate AWS accounts for independent parts of your infrastructure if you expect a high rate of AWS API calls, since AWS throttles calls at the AWS account level. Inspector is an automated security assessment service from AWS that helps identify common security risks. This allows validation that you adhere to certain security practices and may help with compliance. Trusted Advisor addresses a variety of best practices, but also offers some basic security checks around IAM usage, security group configurations, and MFA. At paid support tiers, Trusted Advisor exposes additional checks around other areas, such as reserved instance optimization. Use KMS for managing keys: AWS offers KMS for securely managing encryption keys, which is usually a far better option than handling key security yourself. See below. AWS WAF is a web application firewall to help you protect your applications from common attack patterns. Security auditing: Security Monkey is an open source tool that is designed to assist with security audits. Scout2 is an open source tool that uses AWS APIs to assess an environments security posture. Scout2 is stable and actively maintained. Export and audit security settings: You can audit security policies simply by exporting settings using AWS APIs, e.g. using a Boto script like SecConfig.py (from this 2013 talk) and then reviewing and monitoring changes manually or automatically. Back to top :arrow_up: Security and IAM Gotchas and Limitations Dont share user credentials: Its remarkably common for first-time AWS users to create one account and one set of credentials (access key or password), and then use them for a while, sharing among engineers and others within a company. This is easy. But dont do this. This is an insecure practice for many reasons, but in particular, if you do, you will have reduced ability to revoke credentials on a per-user or per-service basis (for example, if an employee leaves or a key is compromised), which can lead to serious complications. Instance metadata throttling: The instance metadata service has rate limiting on API calls. If you deploy IAM roles widely (as you should!) and have lots of services, you may hit global account limits easily. One solution is to have code or scripts cache and reuse the credentials locally for a short period (say 2 minutes). For example, they can be put into the ~/.aws/credentials file but must also be refreshed automatically. But be careful not to cache credentials for too long, as they expire. (Note the other dynamic metadata also changes over time and should not be cached a long time, either.) Some IAM operations are slower than other API calls (many seconds), since AWS needs to propagate these globally across regions. The uptime of IAMs API has historically been lower than that of the instance metadata API. Be wary of incorporating a dependency on IAMs API into critical paths or subsystems for example, if you validate a users IAM group membership when they log into an instance and arent careful about precaching group membership or maintaining a back door, you might end up locking users out altogether when the API isnt available. Don't check in AWS credentials or secrets to a git repository. There are bots that scan GitHub looking for credentials. Use scripts or tools, such as git-secrets to prevent anyone on your team from checking in sensitive information to your git repositories. S3 S3 Basics Homepage Developer guide FAQ Pricing S3 (Simple Storage Service) is AWS standard cloud storage service, offering file (opaque blob) storage of arbitrary numbers of files of almost any size, from 0 to 5TB. (Prior to 2011 the maximum size was 5 GB; larger sizes are now well supported via multipart support.) Items, or objects, are placed into named buckets stored with names which are usually called keys. The main content is the value. Objects are created, deleted, or updated. Large objects can be streamed, but you cannot modify parts of a value; you need to update the whole object. Partial data access can work via S3 Select. Every object also has metadata, which includes arbitrary key-value pairs, and is used in a way similar to HTTP headers. Some metadata is system-defined, some are significant when serving HTTP content from buckets or CloudFront, and you can also define arbitrary metadata for your own use. S3 URIs: Although often bucket and key names are provided in APIs individually, its also common practice to write an S3 location in the form 's3://bucket-name/path/to/key' (where the key here is 'path/to/key'). (Youll also see 's3n://' and 's3a://' prefixes in Hadoop systems.) S3 vs Glacier, EBS, and EFS: AWS offers many storage services, and several besides S3 offer file-type abstractions. Glacier is for cheaper and infrequently accessed archival storage. EBS, unlike S3, allows random access to file contents via a traditional filesystem, but can only be attached to one EC2 instance at a time. EFS is a network filesystem many instances can connect to, but at higher cost. See the comparison table. Back to top :arrow_up: S3 Tips For most practical purposes, you can consider S3 capacity unlimited, both in total size of files and number of objects. The number of objects in a bucket is essentially also unlimited. Customers routinely have millions of objects. Permissions: If you're storing business data on Amazon S3, its important to manage permissions sensibly. In 2017 companies like Dow Jones and Verizon saw data breaches due to poorly-chosen S3 configuration for sensitive data. Fixing this later can be a difficult task if you have a lot of assets and internal users. There are 3 different ways to grant permissions to access Amazon S3 content in your buckets. IAM policies use the familiar Identity and Authentication Management permission scheme to control access to specific operations. Bucket policies grant or deny permissions to an entire bucket. You might use this when hosting a website in S3, to make the bucket publicly readable, or to restrict access to a bucket by IP address. Amazon's sample bucket policies show a number of use cases where these policies come in handy. Access Control Lists (ACLs) can also be applied to every bucket and object stored in S3. ACLs grant additional permissions beyond those specified in IAM or bucket policies. ACLs can be used to grant access to another AWS user, or to predefined groups like the general public. This is powerful but can be dangerous, because you need to inspect every object to see who has access. AWS' predefined access control groups allow access that may not be what you'd expect from their names: "All Users", or "Everyone", grants permission to the general public, not only to users defined in your own AWS account. If an object is available to All Users, then it can be retrieved with a simple HTTP request of the form http://s3.amazonaws.com/bucket-name/filename. No authorization or signature is required to access data in this category. "Authenticated Users" grants permissions to anyone with an AWS account, again not limited to your own users. Because anyone can sign up for AWS, for all intents and purposes this is also open to the general public. "Log Delivery" group is used by AWS to write logs to buckets and should be safe to enable on the buckets that need it. A typical use case of this ACL is used in conjunction with the requester pays functionality of S3. Bucket permissions and object permissions are two different things and independent of each other. A private object in a public bucket can be seen when listing the bucket, but not downloaded. At the same time, a public object in a private bucket won't be seen because the bucket contents can't be listed, but can still be downloaded by anyone who knows its exact key. Users that don't have access to set bucket permissions can still make objects public if they have s3:PutObjectAcl or s3:PutObjectVersionAcl permissions. In August 2017, AWS added AWS Config rules to ensure your S3 buckets are secure. These AWS Config rules only check the security of your bucket policy and bucket-level ACLs. You can still create object ACLs that grant additional permissions, including opening files to the whole world. Do create new buckets if you have different types of data with different sensitivity levels. This is much less error prone than complex permissions rules. For example, if data is for administrators only, like log data, put it in a new bucket that only administrators can access. For more guidance, see: How to Secure an Amazon S3 Bucket Deep dive into S3 access controls. How do S3 permissions work?. Bucket naming: Buckets are chosen from a global namespace (across all regions, even though S3 itself stores data in whichever S3 region you select), so youll find many bucket names are already taken. Creating a bucket means taking ownership of the name until you delete it. Bucket names have a few restrictions on them. Bucket names can be used as part of the hostname when accessing the bucket or its contents, like <bucket_name>.s3-us-east-1.amazonaws.com, as long as the name is DNS compliant. A common practice is to use the company name acronym or abbreviation to prefix (or suffix, if you prefer DNS-style hierarchy) all bucket names (but please, dont use a check on this as a security measure this is highly insecure and easily circumvented!). Bucket names with '.' (periods) in them can cause certificate mismatches when used with SSL. Use '-' instead, since this then conforms with both SSL expectations and is DNS compliant. Versioning: S3 has optional versioning support, so that all versions of objects are preserved on a bucket. This is mostly useful if you want an archive of changes or the ability to back out mistakes (caution: it lacks the featureset of full version control systems like Git). Durability: Durability of S3 is extremely high, since internally it keeps several replicas. If you dont delete it by accident, you can count on S3 not losing your data. (AWS offers the seemingly improbable durability rate of 99.999999999%, but this is a mathematical calculation based on independent failure rates and levels of replication not a true probability estimate. Either way, S3 has had a very good record of durability.) Note this is much higher durability than EBS! S3 pricing depends on storage, requests, and transfer. For transfer, putting data into AWS is free, but youll pay on the way out. Transfer from S3 to EC2 in the same region is free. Transfer to other regions or the Internet in general is not free. Deletes are free. S3 Reduced Redundancy and Infrequent Access: Most people use the Standard storage class in S3, but there are other storage classes with lower cost: Reduced Redundancy Storage (RRS) has been effectively deprecated, and has lower durability (99.99%, so just four nines) than standard S3. Note that it no longer participates in S3 price reductions, so it offers worse redundancy for more money than standard S3. As a result, there's no reason to use it. Infrequent Access (IA) lets you get cheaper storage in exchange for more expensive access. This is great for archives like logs you already processed, but might want to look at later. To get an idea of the cost savings when using Infrequent Access (IA), you can use this S3 Infrequent Access Calculator. S3 - Intelligent Tiering storage class is designed to optimize costs by automatically moving data to the most cost-effective access tier, without performance impact or operational overhead. S3 - One Zone - IA is for data that is accessed less frequently, but requires rapid access when needed. Unlike other S3 Storage Classes which store data in a minimum of three Availability Zones (AZs), S3 One Zone-IA stores data in a single AZ and costs 20% less than S3 Standard-IA. Glacier is a third alternative discussed as a separate product. See the comparison table. Performance: Maximizing S3 performance means improving overall throughput in terms of bandwidth and number of operations per second. S3 is highly scalable, so in principle you can get arbitrarily high throughput. (A good example of this is S3DistCp.) But usually you are constrained by the pipe between the source and S3 and/or the level of concurrency of operations. Throughput is of course highest from within AWS to S3, and between EC2 instances and S3 buckets that are in the same region. Bandwidth from EC2 depends on instance type. See the Network Performance column at ec2instances.info. Throughput of many objects is extremely high when data is accessed in a distributed way, from many EC2 instances. Its possible to read or write objects from S3 from hundreds or thousands of instances at once. However, throughput is very limited when objects accessed sequentially from a single instance. Individual operations take many milliseconds, and bandwidth to and from instances is limited. Therefore, to perform large numbers of operations, its necessary to use multiple worker threads and connections on individual instances, and for larger jobs, multiple EC2 instances as well. Multi-part uploads: For large objects you want to take advantage of the multi-part uploading capabilities (starting with minimum chunk sizes of 5 MB). Large downloads: Also you can download chunks of a single large object in parallel by exploiting the HTTP GET range-header capability. List pagination: Listing contents happens at 1000 responses per request, so for buckets with many millions of objects listings will take time. Key prefixes: Previously randomness in the beginning of key names was necessary in order to avoid hot spots, but that is no longer necessary as of July, 2018. For data outside AWS, DirectConnect and S3 Transfer Acceleration can help. For S3 Transfer Acceleration, you pay about the equivalent of 1-2 months of storage for the transfer in either direction for using nearer endpoints. Command-line applications: There are a few ways to use S3 from the command line: Originally, s3cmd was the best tool for the job. Its still used heavily by many. The regular aws command-line interface now supports S3 well, and is useful for most situations. s4cmd is a replacement, with greater emphasis on performance via multi-threading, which is helpful for large files and large sets of files, and also offers Unix-like globbing support. GUI applications: You may prefer a GUI, or wish to support GUI access for less technical users. Some options: The AWS Console does offer a graphical way to use S3. Use caution telling non-technical people to use it, however, since without tight permissions, it offers access to many other AWS features. Transmit is a good option on macOS for most use cases. Cyberduck is a good option on macOS and Windows with support for multipart uploads, ACLs, versioning, lifecycle configuration, storage classes and server side encryption (SSE-S3 and SSE-KMS). S3 and CloudFront: S3 is tightly integrated with the CloudFront CDN. See the CloudFront section for more information, as well as S3 transfer acceleration. Static website hosting: S3 has a static website hosting option that is simply a setting that enables configurable HTTP index and error pages and HTTP redirect support to public content in S3. Its a simple way to host static assets or a fully static website. Consider using CloudFront in front of most or all assets: Like any CDN, CloudFront improves performance significantly. SSL is only supported on the built-in amazonaws.com domain for S3. S3 supports serving these sites through a custom domain, but not over SSL on a custom domain. However, CloudFront allows you to serve a custom domain over https. Amazon provides free SNI SSL/TLS certificates via Amazon Certificate Manager. SNI does not work on very outdated browsers/operating systems. Alternatively, you can provide your own certificate to use on CloudFront to support all browsers/operating systems for a fee. If you are including resources across domains, such as fonts inside CSS files, you may need to configure CORS for the bucket serving those resources. Since pretty much everything is moving to SSL nowadays, and you likely want control over the domain, you probably want to set up CloudFront with your own certificate in front of S3 (and to ignore the AWS example on this as it is non-SSL only). That said, if you do, youll need to think through invalidation or updates on CloudFront. You may wish to include versions or hashes in filenames so invalidation is not necessary. Data lifecycles: When managing data, the understanding the lifecycle of the data is as important as understanding the data itself. When putting data into a bucket, think about its lifecycle its end of life, not just its beginning. In general, data with different expiration policies should be stored under separate prefixes at the top level. For example, some voluminous logs might need to be deleted automatically monthly, while other data is critical and should never be deleted. Having the former in a separate bucket or at least a separate folder is wise. Thinking about this up front will save you pain. Its very hard to clean up large collections of files created by many engineers with varying lifecycles and no coherent organization. Alternatively you can set a lifecycle policy to archive old data to Glacier. Be careful with archiving large numbers of small objects to Glacier, since it may actually cost more. There is also a storage class called Infrequent Access that has the same durability as Standard S3, but is discounted per GB. It is suitable for objects that are infrequently accessed. Data consistency: Understanding data consistency is critical for any use of S3 where there are multiple producers and consumers of data. Creation and updates to individual objects in S3 are atomic, in that youll never upload a new object or change an object and have another client see only part half the change. The uncertainty lies with when your clients and other clients see updates. New objects: If you create a new object, youll be able to read it instantly, which is called read-after-write consistency. Well, with the additional caveat that if you do a read on an object before it exists, then create it, you get eventual consistency (not read-after-write). This does not apply to any list operations; newly created objects are not guaranteed to appear in a list operation right away Updates to objects: If you overwrite or delete an object, youre only guaranteed eventual consistency, i.e. the change will happen but you have no guarantee of when. For many use cases, treating S3 objects as immutable (i.e. deciding by convention they will be created or deleted but not updated) can greatly simplify the code that uses them, avoiding complex state management. Note that until 2015, 'us-standard' region had had a weaker eventual consistency model, and the other (newer) regions were read-after-write. This was finally corrected but watch for many old blogs mentioning this! Slow updates: In practice, eventual consistency usually means within seconds, but expect rare cases of minutes or hours. S3 as a filesystem: In general S3s APIs have inherent limitations that make S3 hard to use directly as a POSIX-style filesystem while still preserving S3s own object format. For example, appending to a file requires rewriting, which cripples performance, and atomic rename of directories, mutual exclusion on opening files, and hardlinks are impossible. s3fs is a FUSE filesystem that goes ahead and tries anyway, but it has performance limitations and surprises for these reasons. Riofs (C) and Goofys (Go) are more recent efforts that attempt adopt a different data storage format to address those issues, and so are likely improvements on s3fs. S3QL (discussion) is a Python implementation that offers data de-duplication, snap-shotting, and encryption, but only one client at a time. ObjectiveFS (discussion) is a commercial solution that supports filesystem features and concurrent clients. If you are primarily using a VPC, consider setting up a VPC Endpoint for S3 in order to allow your VPC-hosted resources to easily access it without the need for extra network configuration or hops. Cross-region replication: S3 has a feature for replicating a bucket between one region and another. Note that S3 is already highly replicated within one region, so usually this isnt necessary for durability, but it could be useful for compliance (geographically distributed data storage), lower latency, or as a strategy to reduce region-to-region bandwidth costs by mirroring heavily used data in a second region. IPv4 vs IPv6: For a long time S3 only supported IPv4 at the default endpoint https://BUCKET.s3.amazonaws.com. However, as of Aug 11, 2016 it now supports both IPv4 & IPv6! To use both, you have to enable dualstack either in your preferred API client or by directly using this url scheme https://BUCKET.s3.dualstack.REGION.amazonaws.com. This extends to S3 Transfer Acceleration as well. S3 event notifications: S3 can be configured to send an SNS notification, SQS message, or AWS Lambda function on bucket events. Limit your individual users (or IAM roles) to the minimal required S3 locations, and catalog the approved locations. Otherwise, S3 tends to become the dumping ground where people put data to random locations that are not cleaned up for years, costing you big bucks. If a bucket is deleted in S3, it can take up to 10 hours before a bucket with the same name can be created again. (discussion) Back to top :arrow_up: S3 Gotchas and Limitations S3 buckets sit outside the VPC and can be accessed from anywhere in the world if bucket policies are not set to deny it. Read the permissions section above carefully, there are countless cases of buckets exposed to the public. For many years, there was a notorious 100-bucket limit per account, which could not be raised and caused many companies significant pain. As of 2015, you can request increases. You can ask to increase the limit, but it will still be capped (generally below ~1000 per account). Be careful not to make implicit assumptions about transactionality or sequencing of updates to objects. Never assume that if you modify a sequence of objects, the clients will see the same modifications in the same sequence, or if you upload a whole bunch of files, that they will all appear at once to all clients. S3 has an SLA with 99.9% uptime. If you use S3 heavily, youll inevitably see occasional error accessing or storing data as disks or other infrastructure fail. Availability is usually restored in seconds or minutes. Although availability is not extremely high, as mentioned above, durability is excellent. After uploading, any change that you make to the object causes a full rewrite of the object, so avoid appending-like behavior with regular files. Eventual data consistency, as discussed above, can be surprising sometimes. If S3 suffers from internal replication issues, an object may be visible from a subset of the machines, depending on which S3 endpoint they hit. Those usually resolve within seconds; however, weve seen isolated cases when the issue lingered for 20-30 hours. MD5s and multi-part uploads: In S3, the ETag header in S3 is a hash on the object. And in many cases, it is the MD5 hash. However, this is not the case in general when you use multi-part uploads. One workaround is to compute MD5s yourself and put them in a custom header (such as is done by s4cmd). Incomplete multi-part upload costs: Incomplete multi-part uploads accrue storage charges even if the upload fails and no S3 object is created. Amazon (and others) recommend using a lifecycle policy to clean up incomplete uploads and save on storage costs. Note that if you have many of these, it may be worth investigating whatever's failing regularly. US Standard region: Previously, the us-east-1 region (also known as the US Standard region) was replicated across coasts, which led to greater variability of latency. Effective Jun 19, 2015 this is no longer the case. All Amazon S3 regions now support read-after-write consistency. Amazon S3 also renamed the US Standard region to the US East (N. Virginia) region to be consistent with AWS regional naming conventions. S3 authentication versions and regions: In newer regions, S3 only supports the latest authentication. If an S3 file operation using CLI or SDK doesn't work in one region, but works correctly in another region, make sure you are using the latest authentication signature. Back to top :arrow_up: Storage Durability, Availability, and Price As an illustration of comparative features and price, the table below gives S3 Standard, RRS, IA, in comparison with Glacier, EBS, EFS, and EC2 d2.xlarge instance store using Virginia region as of Sept 2017. | | Durability (per year) | Availability designed | Availability SLA | Storage (per TB per month) | GET or retrieve (per million) | Write or archive (per million) | |-----------------|------------------------|-------------------------|------------------|--------------------------------------------------------------------------------------------------------------------------|-------------------------------|--------------------------------| | Glacier | Eleven 9s | Sloooow | | $4 | $50 | $50 | | S3 IA | Eleven 9s | 99.9% | 99% | $12.50 | $1 | $10 | | ~~S3 RRS~~ | ~~99.99%~~ | ~~99.99%~~ | ~~99.9%~~ | ~~$24 (first TB)~~ | ~~$0.40~~ | ~~$5~~ | | S3 Standard | Eleven 9s | 99.99% | 99.9% | $23 | $0.40 | $5 | | EBS | 99.8% | Unstated | 99.99% | $25/$45/$100/$125+ (sc1/st1/gp2/io1) | | | | EFS | High | High | | $300 | | | | EC2 d2.xlarge instance store | Unstated | Unstated | | $25.44 | $0 | $0 | Especially notable items are in boldface. Sources: S3 pricing, S3 SLA, S3 FAQ, RRS info (note that this is considered deprecated), Glacier pricing, EBS availability and durability, EBS pricing, EFS pricing, EC2 SLA EC2 EC2 Basics Homepage Documentation FAQ Pricing (see also ec2instances.info) EC2 (Elastic Compute Cloud) is AWS offering of the most fundamental piece of cloud computing: A virtual private server. These instances can run most Linux, BSD, and Windows operating systems. Internally, they've used a heavily modified Xen virtualization. That said, new instance classes are being introduced with a KVM derived hypervisor instead, called Nitro. So far, this is limited to the C5 and M5 instance types. Lastly, there's a "bare metal hypervisor" available for i3.metal instances The term EC2 is sometimes used to refer to the servers themselves, but technically refers more broadly to a whole collection of supporting services, too, like load balancing (CLBs/ALBs/NLBs), IP addresses (EIPs), bootable images (AMIs), security groups, and network drives (EBS) (which we discuss individually in this guide). EC2 pricing and cost management is a complicated topic. It can range from free (on the AWS free tier) to a lot, depending on your usage. Pricing is by instance type, by second or hour, and changes depending on AWS region and whether you are purchasing your instances On-Demand, on the Spot market or pre-purchasing (Reserved Instances). Network Performance: For some instance types, AWS uses general terms like Low, Medium, and High to refer to network performance. Users have done benchmarking to provide expectations for what these terms can mean. Back to top :arrow_up: EC2 Alternatives and Lock-In Running EC2 is akin to running a set of physical servers, as long as you dont do automatic scaling or tooled cluster setup. If you just run a set of static instances, migrating to another VPS or dedicated server provider should not be too hard. Alternatives to EC2: The direct alternatives are Google Cloud, Microsoft Azure, Rackspace, DigitalOcean, AWS's own Lightsail offering, and other VPS providers, some of which offer similar APIs for setting up and removing instances. (See the comparisons above.) Should you use Amazon Linux? AWS encourages use of their own Amazon Linux, which is evolved from Red Hat Enterprise Linux (RHEL) and CentOS. Its used by many, but others are skeptical. Whatever you do, think this decision through carefully. Its true Amazon Linux is heavily tested and better supported in the unlikely event you have deeper issues with OS and virtualization on EC2. But in general, many companies do just fine using a standard, non-Amazon Linux distribution, such as Ubuntu or CentOS. Using a standard Linux distribution means you have an exactly replicable environment should you use another hosting provider instead of (or in addition to) AWS. Its also helpful if you wish to test deployments on local developer machines running the same standard Linux distribution (a practice thats getting more common with Docker, too. Amazon now supports an official Amazon Linux Docker image, aimed at assisting with local development on a comparable environment, though this is new enough that it should be considered experimental). Note that the currently-in-testing Amazon Linux 2 supports on-premise deployments explicitly. EC2 costs: See the section on this. Back to top :arrow_up: EC2 Tips Picking regions: When you first set up, consider which regions you want to use first. Many people in North America just automatically set up in the us-east-1 (N. Virginia) region, which is the default, but its worth considering if this is best up front. You'll want to evaluate service availability (some services are not available in all regions), costing (baseline costs also vary by region by up to 10-30% (generally lowest in us-east-1 for comparison purposes)), and compliance (various countries have differing regulations with regard to data privacy, for example). Instance types: EC2 instances come in many types, corresponding to the capabilities of the virtual machine in CPU architecture and speed, RAM, disk sizes and types (SSD or magnetic), and network bandwidth. Selecting instance types is complex since there are so many types. Additionally there are different generations, released over the years. Use the list at ec2instances.info to review costs and features. Amazons own list of instance types is hard to use, and doesnt list features and price together, which makes it doubly difficult. Prices vary a lot, so use ec2instances.info to determine the set of machines that meet your needs and ec2price.com to find the cheapest type in the region youre working in. Depending on the timing and region, it might be much cheaper to rent an instance with more memory or CPU than the bare minimum. Turn off your instances when they arent in use. For many situations such as testing or staging resources, you may not need your instances on 24/7, and you wont need to pay EC2 running costs when they are suspended. Given that costs are calculated based on usage, this is a simple mechanism for cost savings. This can be achieved using Lambda and CloudWatch, an open source option like cloudcycler, or a SaaS provider like GorillaStack. (Note: if you turn off instances with an ephemeral root volume, any state will be lost when the instance is turned off. Therefore, for stateful applications it is safer to turn off EBS backed instances). Dedicated instances and dedicated hosts are assigned hardware, instead of usual virtual instances. They are more expensive than virtual instances but can be preferable for performance, compliance, financial modeling, or licensing reasons. 32 bit vs 64 bit: A few micro, small, and medium instances are still available to use as 32-bit architecture. Youll be using 64-bit EC2 (amd64) instances nowadays, though smaller instances still support 32 bit (i386). Use 64 bit unless you have legacy constraints or other good reasons to use 32. HVM vs PV: There are two kinds of virtualization technology used by EC2, hardware virtual machine (HVM) and paravirtual (PV). Historically, PV was the usual type, but now HVM is becoming the standard. If you want to use the newest instance types, you must use HVM. See the instance type matrix for details. Operating system: To use EC2, youll need to pick a base operating system. It can be Windows or Linux, such as Ubuntu or Amazon Linux. You do this with AMIs, which are covered in more detail in their own section below. Limits: You cant create arbitrary numbers of instances. Default limits on numbers of EC2 instances per account vary by instance type, as described in this list. Use termination protection: For any instances that are important and long-lived (in particular, aren't part of auto-scaling), enable termination protection. This is an important line of defense against user mistakes, such as accidentally terminating many instances instead of just one due to human error. SSH key management: When you start an instance, you need to have at least one ssh key pair set up, to bootstrap, i.e., allow you to ssh in the first time. Aside from bootstrapping, you should manage keys yourself on the instances, assigning individual keys to individual users or services as appropriate. Avoid reusing the original boot keys except by administrators when creating new instances. Avoid sharing keys and add individual ssh keys for individual users. GPU support: You can rent GPU-enabled instances on EC2 for use in machine learning or graphics rendering workloads. There are three types of GPU-enabled instances currently available: The P3 series offers NVIDIA Tesla V100 GPUs in 1, 4 and 8 GPU configurations targeting machine learning, scientific workloads, and other high performance computing applications. The P2 series offers NVIDIA Tesla K80 GPUs in 1, 8 and 16 GPU configurations targeting machine learning, scientific workloads, and other high performance computing applications. The G3 series offers NVIDIA Tesla M60 GPUs in 1, 2, or 4 GPU configurations targeting graphics and video encoding. AWS offers two different AMIs that are targeted to GPU applications. In particular, they target deep learning workloads, but also provide access to more stripped-down driver-only base images. AWS offers both an Amazon Linux Deep Learning AMI (based on Amazon Linux) as well as an Ubuntu Deep Learning AMI. Both come with most NVIDIA drivers and ancillary software (CUDA, CUBLAS, CuDNN, TensorFlow, PyTorch, etc.) installed to lower the barrier to usage. Note that using these AMIs can lead to lock in due to the fact that you have no direct access to software configuration or versioning. The compendium of frameworks included can lead to long instance startup times and difficult-to-reason-about environments. As with any expensive EC2 instance types, Spot instances can offer significant savings with GPU workloads when interruptions are tolerable. All current EC2 instance types can take advantage of IPv6 addressing, so long as they are launched in a subnet with an allocated CIDR range in an IPv6-enabled VPC. Back to top :arrow_up: EC2 Gotchas and Limitations Never use ssh passwords. Just dont do it; they are too insecure, and consequences of compromise too severe. Use keys instead. Read up on this and fully disable ssh password access to your ssh server by making sure 'PasswordAuthentication no' is in your /etc/ssh/sshd_config file. If youre careful about managing ssh private keys everywhere they are stored, it is a major improvement on security over password-based authentication. For all newer instance types, when selecting the AMI to use, be sure you select the HVM AMI, or it just wont work. When creating an instance and using a new ssh key pair, make sure the ssh key permissions are correct. Sometimes certain EC2 instances can get scheduled for retirement by AWS due to detected degradation of the underlying hardware, in which case you are given a couple of weeks to migrate to a new instance If your instance root device is an EBS volume, you can typically stop and then start the instance which moves it to healthy host hardware, giving you control over timing of this event. Note however that you will lose any instance store volume data (ephemeral drives) if your instance type has instance store volumes. The instance public IP (if it has one) will likely change unless you're using Elastic IPs. This could be a problem if other systems depend on the IP address. Periodically you may find that your server or load balancer is receiving traffic for (presumably) a previous EC2 server that was running at the same IP address that you are handed out now (this may not matter, or it can be fixed by migrating to another new instance). If the EC2 API itself is a critical dependency of your infrastructure (e.g. for automated server replacement, custom scaling algorithms, etc.) and you are running at a large scale or making many EC2 API calls, make sure that you understand when they might fail (calls to it are rate limited and the limits are not published and subject to change) and code and test against that possibility. Many newer EC2 instance types are either EBS-only, or backed by local NVMe disks assigned to the instance. Make sure to factor in EBS performance and costs when planning to use them. If you're operating at significant scale, you may wish to break apart API calls that enumerate all of your resources, and instead operate either on individual resources, or a subset of the entire list. EC2 APIs will time out! Consider using filters to restrict what gets returned. Instances come in two types: Fixed Performance Instances (e.g. M3, C3, and R3) and Burstable Performance Instances (e.g. T2). A T2 instance receives CPU credits continuously, the rate of which depends on the instance size. T2 instances accrue CPU credits when they are idle, and use CPU credits when they are active. However, once an instance runs out of credits, you'll notice a severe degradation in performance. If you need consistently high CPU performance for applications such as video encoding, high volume websites or HPC applications, it is recommended to use Fixed Performance Instances. Instance user-data is limited to 16 KB. (This limit applies to the data in raw form, not base64-encoded form.) If more data is needed, it can be downloaded from S3 by a user-data script. Very new accounts may not be able to launch some instance types, such as GPU instances, because of an initially imposed soft limit of zero. This limit can be raised by making a support request. See AWS Service Limits for the method to make the support request. Note that this limit of zero is not currently documented. Since multiple AWS instances all run on the same physical hardware, early cloud adopters encountered what became known as the Noisy Neighbor problem. This feeling of not getting what you are paying for led to user frustration, however "steal" may not be the best word to describe what's actually happening based on a detailed explanation of how the kernel determine steal time. Avoiding having CPU steal affect your application in the cloud may be best handled by properly designing your cloud architecture. AWS introduced Dedicated Tenancy in 2011. This allows customers to have all resources from a single server. Some saw this as a way to solve the noisy neighbor problem since only that customer uses the CPU. This approach comes with a significant risk if that physical system needed any type of maintenance. If a customer had 20 instances running using shared tenancy and one underlying server needed maintenance, only the instance on that server would go offline. If that customer had 20 instances running using dedicated tenancy, when the underlying server needs maintenance, all 20 instances would go offline. Only i3.metal type instances providing an ability to run Android x86 emulators on AWS at the moment. CloudWatch CloudWatch Basics Homepage Documentation FAQ Pricing CloudWatch monitors resources and applications, captures logs, and sends events. CloudWatch monitoring is the standard mechanism for keeping tabs on AWS resources. A wide range of metrics and dimensions are available via CloudWatch, allowing you to create time based graphs, alarms, and dashboards. Alarms are the most practical use of CloudWatch, allowing you to trigger notifications from any given metric. Alarms can trigger SNS notifications, Auto Scaling actions, or EC2 actions. Alarms also support alerting when any M out of N datapoints cross the alarm threshold. Publish and share graphs of metrics by creating customizable dashboard views. Monitor and report on EC2 instance system check failure alarms. Using CloudWatch Events: Events create a mechanism to automate actions in various services on AWS. You can create event rules from instance states, AWS APIs, Auto Scaling, Run commands, deployments or time-based schedules (think Cron). Triggered events can invoke Lambda functions, send SNS/SQS/Kinesis messages, or perform instance actions (terminate, restart, stop, or snapshot volumes). Custom payloads can be sent to targets in JSON format, this is especially useful when triggering Lambdas. Using CloudWatch Logs: CloudWatch Logs is a streaming log storage system. By storing logs within AWS you have access to unlimited paid storage, but you also have the option of streaming logs directly to ElasticSearch or custom Lambdas. A log agent installed on your servers will process logs over time and send them to CloudWatch Logs. You can export logged data to S3 or stream results to other AWS services. CloudWatch Logs can be encrypted using keys managed through KMS. Detailed monitoring: Detailed monitoring for EC2 instances must be enabled to get granular metrics, and is billed under CloudWatch. Back to top :arrow_up: CloudWatch Alternatives and Lock-In CloudWatch offers fairly basic functionality that doesn't create significant (additional) AWS lock-in. Most of the metrics provided by the service can be obtained through APIs that can be imported into other aggregation or visualization tools or services (many specifically provide CloudWatch data import services). Alternatives to CloudWatch monitoring services include NewRelic, Datadog, Sumo Logic, Zabbix, Nagios, Ruxit, Elastic Stack, open source options such as StatsD or collectd with Graphite, and many others. CloudWatch Log alternatives include Splunk, Sumo Logic, Loggly, LogDNA, Logstash, Papertrail, Elastic Stack, and other centralized logging solutions. Back to top :arrow_up: CloudWatch Tips Some very common use cases for CloudWatch are billing alarms, instance or load balancer up/down alarms, and disk usage alerts. You can use EC2Config to monitor watch memory and disk metrics on Windows platform instances. For Linux, there are example scripts that do the same thing. You can publish your own metrics using the AWS API. Incurs additional cost. You can stream directly from CloudWatch Logs to a Lambda or ElasticSearch cluster by creating subscriptions on Log Groups. Don't forget to take advantage of the CloudWatch non-expiring free tier. Back to top :arrow_up: CloudWatch Gotchas and Limitations Metrics in CloudWatch originate on the hypervisor. The hypervisor doesn't have access to OS information, so certain metrics (most notably memory utilization) are not available unless pushed to CloudWatch from inside the instance. You can not use more than one metric for an alarm. Notifications you receive from alarms will not have any contextual detail; they have only the specifics of the threshold, alarm state, and timing. By default, CloudWatch metric resolution is 1 minute. If you send multiple values of a metric within the same minute, they will be aggregated into minimum, maximum, average and total (sum) per minute. In July 2017, a new high-resolution option was added for CloudWatch metrics and alarms. This feature allows you to record metrics with 1-second resolution, and to evaluate CloudWatch alarms every 10 seconds. The blog post introducing this feature describes how to publish a high-resolution metric to CloudWatch. Note that when calling the PutMetricData API, StorageResolution is an attribute of each item you send in the MetricData array, not a direct parameter of the PutMetricData API call. Data about metrics is kept in CloudWatch for 15 months, starting November 2016 (used to be 14 days). Minimum granularity increases after 15 days. AMIs AMI Basics User guide AMIs (Amazon Machine Images) are immutable images that are used to launch preconfigured EC2 instances. They come in both public and private flavors. Access to public AMIs is either freely available (shared/community AMIs) or bought and sold in the AWS Marketplace. Many operating system vendors publish ready-to-use base AMIs. For Ubuntu, see the Ubuntu AMI Finder. Amazon of course has AMIs for Amazon Linux. Back to top :arrow_up: AMI Tips AMIs are built independently based on how they will be deployed. You must select AMIs that match your deployment when using them or creating them: EBS or instance store PV or HVM virtualization types 32 bit (i386) vs 64 bit (amd64) architecture As discussed above, modern deployments will usually be with 64-bit EBS-backed HVM. You can create your own custom AMI by snapshotting the state of an EC2 instance that you have modified. AMIs backed by EBS storage have the necessary image data loaded into the EBS volume itself and dont require an extra pull from S3, which results in EBS-backed instances coming up much faster than instance storage-backed ones. AMIs are per region, so you must look up AMIs in your region, or copy your AMIs between regions with the AMI Copy feature. As with other AWS resources, its wise to use tags to version AMIs and manage their lifecycle. If you create your own AMIs, there is always some tension in choosing how much installation and configuration you want to bake into them. Baking less into your AMIs (for example, just a configuration management client that downloads, installs, and configures software on new EC2 instances when they are launched) allows you to minimize time spent automating AMI creation and managing the AMI lifecycle (you will likely be able to use fewer AMIs and will probably not need to update them as frequently), but results in longer waits before new instances are ready for use and results in a higher chance of launch-time installation or configuration failures. Baking more into your AMIs (for example, pre-installing but not fully configuring common software along with a configuration management client that loads configuration settings at launch time) results in a faster launch time and fewer opportunities for your software installation and configuration to break at instance launch time but increases the need for you to create and manage a robust AMI creation pipeline. Baking even more into your AMIs (for example, installing all required software as well and potentially also environment-specific configuration information) results in fast launch times and a much lower chance of instance launch-time failures but (without additional re-deployment and re-configuration considerations) can require time consuming AMI updates in order to update software or configuration as well as more complex AMI creation automation processes. Which option you favor depends on how quickly you need to scale up capacity, and size and maturity of your team and product. When instances boot fast, auto-scaled services require less spare capacity built in and can more quickly scale up in response to sudden increases in load. When setting up a service with autoscaling, consider baking more into your AMIs and backing them with the EBS storage option. As systems become larger, it common to have more complex AMI management, such as a multi-stage AMI creation process in which few (ideally one) common base AMIs are infrequently regenerated when components that are common to all deployed services are updated and then a more frequently run service-level AMI generation process that includes installation and possibly configuration of application-specific software. More thinking on AMI creation strategies here. Use tools like Packer to simplify and automate AMI creation. If you use RHEL instances and happen to have existing RHEL on-premise Red Hat subscriptions, then you could leverage Red Hat's Cloud Access program to migrate a portion of your subscriptions to AWS, and thereby not having AWS charge you for RHEL subscriptions a second time. You can either use your own self-created RHEL AMI's or Red Hat provided Gold Images that will be added to your private AMI's once you sign up for Red Hat Cloud Access. Back to top :arrow_up: AMI Gotchas and Limitations Amazon Linux package versions: By default, instances based on Amazon Linux AMIs are configured point to the latest versions of packages in Amazons package repository. This means that the package versions that get installed are not locked and it is possible for changes, including breaking ones, to appear when applying updates in the future. If you bake your AMIs with updates already applied, this is unlikely to cause problems in running services whose instances are based on those AMIs breaks will appear at the earlier AMI-baking stage of your build process, and will need to be fixed or worked around before new AMIs can be generated. There is a lock on launch feature that allows you to configure Amazon Linux instances to target the repository of a particular major version of the Amazon Linux AMI, reducing the likelihood that breaks caused by Amazon-initiated package version changes will occur at package install time but at the cost of not having updated packages get automatically installed by future update runs. Pairing use of the lock on launch feature with a process to advance the Amazon Linux AMI at your discretion can give you tighter control over update behaviors and timings. Cloud-Init Defaults: Oftentimes users create AMIs after performing customizations (albeit manually or via some tool such as Packer or Ansible). If you're not careful to alter cloud-init settings that correspond to the system service (e.g. sshd, etc.) you've customized, you may find that your changes are no longer in effect after booting your new AMI for the first time, as cloud-init has overwritten them. Some distros have different files than others, but all are generally located in /etc/cloud/, regardless of distro. You will want to review these files carefully for your chosen distro before rolling your own AMIs. A complete reference to cloud-init is available on the cloud-init site. This is an advanced configuration mechanism, so test any changes made to these files in a sandbox prior to any serious usage. Auto Scaling Auto Scaling Basics Homepage User guide FAQ Pricing at no additional charge Auto Scaling Groups (ASGs) are used to control the number of instances in a service, reducing manual effort to provision or deprovision EC2 instances. They can be configured through Scaling Policies to automatically increase or decrease instance counts based on metrics like CPU utilization, or based on a schedule. There are three common ways of using ASGs - dynamic (automatically adjust instance count based on metrics for things like CPU utilization), static (maintain a specific instance count at all times), scheduled (maintain different instance counts at different times of day or on days of the week). ASGs have no additional charge themselves; you pay for underlying EC2 and CloudWatch services. Back to top :arrow_up: Auto Scaling Tips Better matching your cluster size to your current resource requirements through use of ASGs can result in significant cost savings for many types of workloads. Pairing ASGs with CLBs is a common pattern used to deal with changes in the amount of traffic a service receives. Dynamic Auto Scaling is easiest to use with stateless, horizontally scalable services. Even if you are not using ASGs to dynamically increase or decrease instance counts, you should seriously consider maintaining all instances inside of ASGs given a target instance count, the ASG will work to ensure that number of instances running is equal to that target, replacing instances for you if they die or are marked as being unhealthy. This results in consistent capacity and better stability for your service. Autoscalers can be configured to terminate instances that a CLB or ALB has marked as being unhealthy. Back to top :arrow_up: Auto Scaling Gotchas and Limitations ReplaceUnhealthy setting: By default, ASGs will kill instances that the EC2 instance manager considers to be unresponsive. It is possible for instances whose CPU is completely saturated for minutes at a time to appear to be unresponsive, causing an ASG with the default ReplaceUnhealthy setting turned on to replace them. When instances that are managed by ASGs are expected to consistently run with very high CPU, consider deactivating this setting. If you do so, however, detecting and killing unhealthy nodes will become your responsibility. EBS EBS Basics Homepage User guide FAQ Pricing EBS (Elastic Block Store) provides block level storage. That is, it offers storage volumes that can be attached as filesystems, like traditional network drives. EBS volumes can only be attached to one EC2 instance at a time. In contrast, EFS can be shared but has a much higher price point (a comparison). Back to top :arrow_up: EBS Tips RAID: Use RAID drives for increased performance. A worthy read is AWS post on EBS IO characteristics as well as their performance tips. One can provision IOPS (that is, pay for a specific level of I/O operations per second) to ensure a particular level of performance for a disk. A single gp2 EBS volume allows 16k IOPS max To get the maximum performance out of a gp2 EBS volume, it has to be of a maximum size and attached to an EBS-optimized EC2 instance. Standard and gp2 EBS volumes improve IOPS with size. It may make sense for you to simply enlarge a volume instead of paying for better performance explicitly. This can in many cases reduce costs by 2/3. A standard block size for an EBS volume is 16kb. Back to top :arrow_up: EBS Gotchas and Limitations EBS durability is reasonably good for a regular hardware drive (annual failure rate of between 0.1% - 0.2%). On the other hand, that is very poor if you dont have backups! By contrast, S3 durability is extremely high. If you care about your data, back it up to S3 with snapshots. EBS has an SLA with 99.99% uptime. See notes on high availability below. EBS volumes have a volume type indicating the physical storage type. The types called standard (st1 or sc1) are actually old spinning-platter disks, which deliver only hundreds of IOPS not what you want unless youre really trying to cut costs. Modern SSD-based gp2 or io1 are typically the options you want. When restoring a snapshot to create an EBS volume, blocks are lazily read from S3 the first time they're referenced. To avoid an initial period of high latency, you may wish to use dd or fio as per the official documentation. EFS EFS Basics Homepage User guide FAQ Pricing EFS is Amazons network filesystem. Its presented as an NFSv4.1 server. Any compatible NFSv4 client can mount it. It is designed to be highly available and durable and each EFS file system object is redundantly stored across multiple availability zones. EFS is designed to be used as a shared network drive and it can automatically scale up to petabytes of stored data and thousands of instances attached to it. EFS can offer higher throughput (multiple gigabytes per second) and better durability and availability than EBS (see the comparison table), but with higher latency. EFS is priced based on the volume of data stored, and costs much more than EBS; it's in the ballpark of three times as much compared to general purpose gp2 EBS volumes. Performance is dependent on the volume of data stored, as is the price: Like EBS, EFS uses a credit based system. Credits are earned at a rate of 50 KiB/s per GiB of storage and consumed in bursts during reading/writing files or metadata. Unlike EBS, operations on metadata (file size, owner, date, etc.) also consume credits. The BurstCreditBalance metric in CloudWatch should be monitored to make sure the file system doesn't run out of credits. Throughput capacity during bursts is also dependent on size. Under 1 TiB, throughput can go up to 100 MiB/s. Above that, 100 MiB/s is added for each stored TiB. For instance, a file system storing 5 TiB would be able to burst at a rate of 500 MiB/s. Maximum throughput per EC2 instance is 250 MiB/s. EFS has two performance modes that can only be set when a file system is created. One is "General Purpose", the other is "Max I/O". Max I/O scales higher, but at the cost of higher latency. When in doubt, use General Purpose, which is also the default. If the PercentIOLimit metric in CloudWatch hovers around 100%, Max I/O is recommended. Changing performance mode means creating a new EFS and migrating data. High availability is achieved by having mount targets in different subnets / availability zones. Back to top :arrow_up: EFS Tips With EFS being based on NFSv4.1, any directory on the EFS can be mounted directly, it doesn't have to be the root directory. One application could mount fs-12345678:/prog1, another fs-12345678:/prog2. User and group level permissions can be used to control access to certain directories on the EFS file system. Sharing EFS filesystems: One EFS filesystem can be used for multiple applications or services, but it should be considered carefully: Pros: - Because performance is based on total size of stored files, having everything on one drive will increase performance for everyone. One application consuming credits faster than it can accumulate might be offset by another application that just stores files on EFS and rarely accesses them. Cons: - Since credits are shared, if one application over-consumes them, it will affect the others. - A compromise is made with regards to security: all clients will have to have network access to the drive. Someone with root access on one client instance can mount any directory on the EFS and they have read-write access to all files on the drive, even if they don't have access to the applications hosted on other clients. There isn't a no-root-squash equivalent for EFS. Back to top :arrow_up: EFS Gotchas and Limitations A number of NFSv4.1 features are not supported and there are some limits to the service. As of 2017-08, EFS offers disk level encryption for new drives. For file systems created before that date, encryption can only be achieved by moving the data to a new EFS volume. An EFS file system can be mounted on premises over Direct Connect. An EFS file system can NOT be mounted over VPC peering or VPN, even if the VPN is running on top of Direct Connect. Using an EFS volume on Windows is not supported. When a file is uploaded to EFS, it can take hours for EFS to update the details for billing and burst credit purposes. Metadata operations can be costly in terms of burst credit consumption. Recursively traversing a tree containing thousands of files can easily ramp up to tens or even hundreds of megabytes of burst credits being consumed, even if no file is being touched. Commands like or can have an adverse impact on performance. Load Balancers Load Balancer Basics AWS has 3 load balancing products - Classic Load Balancers (CLBs), Application Load Balancers (ALBs), and "Network Load Balancers" (NLB). Before the introduction of ALBs, Classic Load Balancers were known as Elastic Load Balancers (ELBs), so older documentation, tooling, and blog posts may still reference ELBs. CLBs have been around since 2009, ALBs in 2016, NLBs were added in 2017 to AWS. CLBs support TCP and HTTP load balancing. ALBs support HTTP load balancing only. NLBs support TCP layer 4 load balancing. CLBs and ALBs can optionally handle termination for a single SSL certificate. All can optionally perform active health checks of instances and remove them from the destination pool if they become unhealthy. CLBs don't support complex / rule-based routing. ALBs support a (currently small) set of rule-based routing features. NLBs have most extensive routing options. CLBs can only forward traffic to a single globally configured port on destination instances, while ALBs can forward to ports that are configured on a per-instance basis, better supporting routing to services on shared clusters with dynamic port assignment (like ECS or Mesos). NLBs support multiple ports on same IP; registering targets by IP address, including targets outside the VPC for the load balancer; ECS can select unused port for scheduling a task then register a target group using this port. CLBs are supported in EC2 Classic as well as in VPCs while ALBs are supported in VPCs only. ALBs can target groups of instances and IP based targets in the RFC1918 ranges allowing you to use on premise destinations via VPN or Direct Connect. Back to top :arrow_up: Load Balancer Tips If you dont have opinions on your load balancing up front, and dont have complex load balancing needs like application-specific routing of requests, its reasonable just to use a CLB or ALB for load balancing instead. Even if you dont want to think about load balancing at all, because your architecture is so simple (say, just one server), put a load balancer in front of it anyway. This gives you more flexibility when upgrading, since you wont have to change any DNS settings that will be slow to propagate, and also it lets you do a few things like terminate SSL more easily. CLBs and ALBs have many IPs: Internally, an AWS load balancer is simply a collection of individual software load balancers hosted within EC2, with DNS load balancing traffic among them. The pool can contain many IPs, at least one per availability zone, and depending on traffic levels. They also support SSL termination, which is very convenient. Scaling: CLBs and ALBs can scale to very high throughput, but scaling up is not instantaneous. If youre expecting to be hit with a lot of traffic suddenly, it can make sense to load test them so they scale up in advance. You can also contact Amazon and have them pre-warm the load balancer. Client IPs: In general, if servers want to know true client IP addresses, load balancers must forward this information somehow. CLBs add the standard X-Forwarded-For header. When using a CLB as an HTTP load balancer, its possible to get the clients IP address from this. Using load balancers when deploying: One common pattern is to swap instances in the load balancer after spinning up a new stack with your latest version, keep old stack running for one or two hours, and either flip back to old stack in case of problems or tear it down. Rotating Certificates while retaining ARN: Rotating IAM Server Certificates can be difficult as the standard practice is to upload a new one then update all resources with the new ARN. You can however retain the same ARN using the update-certificate call with the following process: Upload a new IAM Server Certificate with a unique name (e.g fuzzy.com.new) Rename the existing IAM Server Certificate (e.g fuzzy.com to fuzzy.com.expired) Rename the new IAM Server Certificate to the name of the previously existing certificate (e.g fuzzy.com.new to fuzzy.com) Jiggle the CLB/ALB Listener to pick up the change: ALB: Invoke modify-listener with the existing details for the ALB Listener CLB: Invoke create-load-balancer-listeners with the existing details for the CLB listener Back to top :arrow_up: Load Balancer Gotchas and Limitations CLBs and ALBs have no fixed external IP that all clients see. For most consumer apps this doesnt matter, but enterprise customers of yours may want this. IPs will be different for each user, and will vary unpredictably for a single client over time (within the standard EC2 IP ranges). And similarly, never resolve a CLB name to an IP and put it as the value of an A record it will work for a while, then break! Some web clients or reverse proxies cache DNS lookups for a long time, which is problematic for CLBs and ALBs, since they change their IPs. This means after a few minutes, hours, or days, your client will stop working, unless you disable DNS caching. Watch out for Javas settings and be sure to adjust them properly. Another example is nginx as a reverse proxy, which normally resolves backends only at start-up (although there is a way to get around this). Its not unheard of for IPs to be recycled between customers without a long cool-off period. So as a client, if you cache an IP and are not using SSL (to verify the server), you might get not just errors, but responses from completely different services or companies! As an operator of a service behind a CLB or ALB, the latter phenomenon means you can also see puzzling or erroneous requests by clients of other companies. This is most common with clients using back-end APIs (since web browsers typically cache for a limited period). CLBs and ALBs take time to scale up, it does not handle sudden spikes in traffic well. Therefore, if you anticipate a spike, you need to pre-warm the load balancer by gradually sending an increasing amount of traffic. Tune your healthchecks carefully if you are too aggressive about deciding when to remove an instance and conservative about adding it back into the pool, the service that your load balancer is fronting may become inaccessible for seconds or minutes at a time. Be extra careful about this when an autoscaler is configured to terminate instances that are marked as being unhealthy by a managed load balancer. CLB HTTPS listeners don't support Server Name Indication (SNI). If you need SNI, you can work around this limitation by either providing a certificate with Subject Alternative Names (SANs) or by using TCP listeners and terminating SSL at your backend. There is a limit on the number of ALBs, CLBs and NLBs per region (separately). As of late 2017, the default limit for each is 20 per region. These limits can be easily raised for ALB and CLB, but AWS is quite reluctant to raise the limit on NLBs. If using a Network Load Balancer (NLB) then EC2 clients cannot connect to an NLB that resides in another VPC (VPC Peering) or AWS managed VPN unless the EC2 client is a C5, i3.metal or M5 instance type. For VPC peering, both VPCs must be in the same region. See Troubleshooting. CLB CLB Basics Homepage User guide FAQ Pricing Classic Load Balancers, formerly known as Elastic Load Balancers, are HTTP and TCP load balancers that are managed and scaled for you by Amazon. Back to top :arrow_up: CLB Tips Best practices: This article is a must-read if you use CLBs heavily, and has a lot more detail. Back to top :arrow_up: CLB Gotchas and Limitations In general, CLBs are not as smart as some load balancers, and dont have fancy features or fine-grained control a traditional hardware load balancer would offer. For most common cases involving sessionless apps or cookie-based sessions over HTTP, or SSL termination, they work well. By default, CLBs will refuse to route traffic from a load balancer in one Availability Zone (AZ) to a backend instance in another. This will cause 503s if the last instance in an AZ becomes unavailable, even if there are healthy instances in other zones. If youre running fewer than two backend instances per AZ, you almost certainly want to enable cross-zone load balancing. Complex rules for directing traffic are not supported. For example, you cant direct traffic based on a regular expression in the URL, like HAProxy offers. Apex DNS names: Once upon a time, you couldnt assign a CLB to an apex DNS record (i.e. example.com instead of foo.example.com) because it needed to be an A record instead of a CNAME. This is now possible with a Route 53 alias record directly pointing to the load balancer. CLBs use HTTP keep-alives on the internal side. This can cause an unexpected side effect: Requests from different clients, each in their own TCP connection on the external side, can end up on the same TCP connection on the internal side. Never assume that multiple requests on the same TCP connection are from the same client! Traffic between CLBs and back-end instances in the same subnet will have Network ACL rules evaluated (EC2 to EC2 traffic in the same subnet would not have Network ACL rules evaluated). If the default '0.0.0.0/0 ALLOW' rule is removed from the Network ACL applied to the subnet, a rule that allows traffic on both the health check port and any listener port must be added. As of December 2016, CLBs launched in VPCs do not support IPv6 addressing. CLBs launched in EC2-Classic support both IPv4 and IPv6 with the "dualstack" DNS name. ALB ALB Basics Homepage User guide FAQ Pricing Websockets and HTTP/2 are now supported. Internet Protocol Version 6 (IPv6) is now supported. Load Balancing via IP is now supported. Prior to the Application Load Balancer, you were advised to use TCP instead of HTTP as the protocol to make it work (as described here) and use the obscure but useful Proxy Protocol (more on this) to pass client IPs over a TCP load balancer. Back to top :arrow_up: ALB Tips Use ALBs to route to services that are hosted on shared clusters with dynamic port assignment (like ECS or Mesos). ALBs support HTTP host-based routing (send HTTP requests for api.mydomain.com -> {target-group-1}, blog.mydomain.com -> {target group 2}) as well as HTTP path-based routing (send HTTP requests for /api/* -> {target-group-1}, /blog/* -> {target group 2}). Back to top :arrow_up: ALB Gotchas and Limitations ALBs only support HTTP/2 over HTTPS (no plain-text HTTP/2). ALBs only support HTTP/2 to external clients and not to internal resources (instances/containers). ALBs support HTTP routing but not port-based TCP routing. Instances in the ALBs target groups have to either have a single, fixed healthcheck port (EC2 instance-level healthcheck) or the healthcheck port for a target has to be the same as its application port (Application instance-level healthcheck) - you can't configure a per-target healthcheck port that is different than the application port. ALBs are VPC-only (they are not available in EC2 Classic) In a target group, if there is no healthy target, all requests are routed to all targets. For example, if you point a listener at a target group containing a single service that has a long initialization phase (during which the health checks would fail), requests will reach the service while it is still starting up. Although ALBs now support SNI, they only support 25 HTTPS certificates per Load Balancer. This limitation is not described here, so it might be subject to change. Elastic Beanstalk Elastic Beanstalk Basics Homepage Developer guide FAQ Pricing EB (Elastic Beanstalk) is a PaaS (Platform as a Service) that helps developers create, deploy and scale web applications EB handles deployment, configuration, provisioning, load balancing, auto-scaling, monitoring, and logging EB creates AWS resources on your behalf but you retain full access and control of the underlying resources There is no cost to use EB but you will still be charged the full cost of the underlying AWS resources created by EB Back to top :arrow_up: Elastic Beanstalk Tips To speed up deployment before launch or in a dev stage, turn off health checks and set the Deployment policy to All at once If you have a configuration you want to re-use for multiple EB apps, you can save the current configuration using eb config save --cfg myEBConfig By default, EB doesn't have any alarms. You'll need to add them yourself on metrics that you're monitoring. By default, EB doesn't enable managed platform updates. Enable them in configuration to have EB automatically apply updates during a pre-specified maintenance window Back to top :arrow_up: Elastic Beanstalk Gotchas and Limitations Don't edit [apache|nginx] conf files manually on ec2 instances as they will be re-written on each deployment (use ebextensions instead) After creating an EB environment, it's no longer possible to change the Name tag EB will sometimes quarantine instances that cause multiple deployment issues. Despite being quarantined, EB will still deploy to them on subsequent deployments. To prevent this behavior, said instances will need to be terminated (or the underlying issue fixed) File uploads are capped at 10MB for most default eb configurations - update nginx config to change If you edit .elasticbeanstalk/saved_configs/, be aware that this is not kept in sync with the EB environment config. You'll need to manually fetch and save for changes to take effect Elastic IPs Elastic IP Basics Documentation FAQ Pricing Elastic IPs are static IP addresses you can rent from AWS to assign to EC2 instances. Back to top :arrow_up: Elastic IP Tips Prefer load balancers to elastic IPs: For single-instance deployments, you could just assign elastic IP to an instance, give that IP a DNS name, and consider that your deployment. Most of the time, you should provision a load balancer instead: Its easy to add and remove instances from load balancers. Its also quicker to add or remove instances from a load balancer than to reassign an elastic IP. Its more convenient to point DNS records to load balancers, instead of pointing them to specific IPs you manage manually. They can also be Route 53 aliases, which are easier to change and manage. But in some situations, you do need to manage and fix IP addresses of EC2 instances, for example if a customer needs a fixed IP. These situations require elastic IPs. Elastic IPs are limited to 5 per account. Its possible to request more. If an Elastic IP is not attached to an active resource there is a small hourly fee. Elastic IPs are no extra charge as long as youre using them. They have a (small) cost when not in use, which is a mechanism to prevent people from squatting on excessive numbers of IP addresses. Back to top :arrow_up: Elastic IP Gotchas and Limitations There is officially no way to allocate a contiguous block of IP addresses, something you may desire when giving IPs to external users. Though when allocating at once, you may get lucky and have some be part of the same CIDR block. If this is important to you, you may want to bring your own IP, which is more involved than this guide will go into. Glacier Glacier Basics Homepage Developer guide FAQ Pricing Glacier is a lower-cost alternative to S3 when data is infrequently accessed, such as for archival purposes. Its only useful for data that is rarely accessed. It generally takes 3-5 hours to fulfill a retrieval request. AWS has not officially revealed the storage media used by Glacier; it may be low-spin hard drives or even tapes. AWS has released an even more cost effective storate tier called Glacier Deep Archive that offers ~12 hour retrieval latencies, but costs roughly a thousand dollars per month per petabyte. Back to top :arrow_up: Glacier Tips You can physically ship your data to Amazon to put on Glacier on a USB or eSATA HDD. Back to top :arrow_up: Glacier Gotchas and Limitations Getting files off Glacier is glacially slow (typically 3-5 hours or more). Due to a fixed overhead per file (you pay per PUT or GET operation), uploading and downloading many small files on/to Glacier might be very expensive. There is also a 32k storage overhead per file. Hence its a good idea is to archive files before upload. Be aware of the per-object costs of archiving S3 data to Glacier. It costs $0.05 per 1,000 requests. If you have large numbers of S3 objects of relatively small size, it will take time to reach a break-even point (initial archiving cost versus lower storage pricing). RDS RDS Basics Homepage User guide FAQ Pricing (see also ec2instances.info/rds/) RDS is a managed relational database service, allowing you to deploy and scale databases more easily. It supports Oracle, Microsoft SQL Server, PostgreSQL, MySQL, MariaDB, and Amazons own Aurora. RDS offers out of the box support for high availability and failover for your databases. Back to top :arrow_up: RDS Tips If you're looking for the managed convenience of RDS for other data stores such as MongoDB or Cassandra, you may wish to consider third-party services from providers such as [Compose, or InstaClustr. Make sure to create a new parameter group and option group for your database since the default parameter group does not allow dynamic configuration changes. RDS instances start with a default timezone of UTC. If necessary, this can be changed to a different timezone. Back to top :arrow_up: RDS Gotchas and Limitations RDS instances run on EBS volumes (either general-purpose or provisioned IOPS), and hence are constrained by EBS performance. Verify what database features you need, as not everything you might want is available on RDS. For example, if you are using Postgres, check the list of supported features and extensions. If the features you need aren't supported by RDS, you'll have to deploy your database yourself. If you use the failover support offered by RDS, keep in mind that it is based on DNS changes, and make sure that your client reacts to these changes appropriately. This is particularly important for Java, given how its DNS resolvers TTL is configured by default. DB migration to RDS: While importing your database into RDS ensure you take into consideration the maintenance window settings. If a backup is running at the same time, your import can take a considerably longer time than you would have expected. Database sizes are limited to 6TB for all database engines except for SQL Server which has a 4TB limit and Aurora which supports up to 64TB databases. RDS MySQL and MariaDB RDS MySQL and MariaDB Basics RDS offers MySQL versions 5.5, 5.6, 5.7 and 5.8. RDS offers MariaDB versions 10.0, 10.1, 10.2 and 10.3. Back to top :arrow_up: RDS MySQL and MariaDB Tips MySQL RDS allows access to binary logs. Multi-AZ instances of MySQL transparently replicate data across AZs using DRBD. Automated backups of multi-AZ instances run off the backup instance to reduce latency spikes on the primary. Performance Schema: While Performance Schema is enabled by default in MySQL 5.6.6 and later, it is disabled by default in all versions of RDS. If you wish to enable Performance Schema, a reboot of the RDS instance will be required. MySQL vs MariaDB vs Aurora: If you prefer a MySQL-style database but are starting something new, you probably should consider Aurora and MariaDB as well. Aurora has increased availability and is the next-generation solution. That said, Aurora may not be that much faster than MySQL for certain workloads. MariaDB, the modern community fork of MySQL, likely now has the edge over MySQL for many purposes and is supported by RDS. Back to top :arrow_up: RDS MySQL and MariaDB Gotchas and Limitations No SUPER privileges. RDS provides some stored procedures to perform some tasks that require SUPER privileges such as starting or stopping replication. You can replicate to non-RDS instances of MySQL, but replication to these instances will break during AZ failovers. There is no ability to manually CHANGE MASTER on replicas, so they must all be rebuilt after a failover of the master. Most global options are exposed only via DB parameter groups. Some variables that were introduced in later MySQL dot releases such as avoid_temporal_upgrade in MySQL 5.6.24 are not made available in RDS's 5.6.x parameter group and making use of them requires an upgrade to MySQL 5.7.x. RDS features such as Point-In-Time restore and snapshot restore are not supported on MyISAM tables. Ensure you lock and flush each MyISAM table before executing a snapshot or backup operation to ensure consistency. RDS PostgreSQL RDS PostgreSQL Basics RDS offers PostgreSQL 9.3, 9.4, 9.5, 9.6, and 10. Back to top :arrow_up: RDS PostgreSQL Tips Recently Logical Replication is being supported, both as subscriber and publisher. Supports a relatively large range of native extensions. RDS PostgreSQL 10 Supports native partitioning and most of the major features and tunables. Supports connections over SSL. Supports multi A-Z and Point-in-time recovery. Back to top :arrow_up: RDS PostgreSQL Gotchas and Limitations No superuser privileges. RDS provides a role rds_superuser that can do most of the needed operations but there are some limitations. Some major features are delayed compared to open source PostgreSQL. By default RDS is specd with general purpose SSD , if you need better performance you have to spec provisioned IOPS SSD. You can't use RDS as a replica outside RDS without using logical replication. There are settings that cannot be changed and most of the settings that can change can only be changed using database parameter groups. Its harder to troubleshoot performance problems since you have no access to the host. Be sure to verify that all the extensions you need are available. If you are using an extension not listed there, you will need to come up with a work around, or deploy your own database in EC2. Many Postgres utilities and maintenance items expect command line access, that can usually be satisfied by using an external ec2 server. RDS SQL Server RDS SQL Server Basics RDS offers SQL Server 2008 R2, 2012, 2014, 2016 and 2017 including Express, Web, Standard and Enterprise. Back to top :arrow_up: RDS SQL Server Tips Recently added support for backup and restore to/from S3 which may make it an attractive DR option for on-premises installations. Back to top :arrow_up: RDS SQL Server Gotchas and Limitations The user is granted only db_owner privileges for each database on the instance. Storage cannot be expanded for existing databases. If you need more space, you must restore your database on a new instance with larger storage. There is a 16TB database size limit for non-Express editions. There is also a minimum storage size, 20GB for Web and Express, 200GB for Standard and Enterprise. Limited to 30 databases per instance RDS Aurora RDS Aurora Basics Aurora is a cloud only database service designed to provide a distributed, fault-tolerant relational database with self-healing storage and auto-scaling up to 64TB per instance. It currently comes in two versions, a MySQL compatible system, and a PostgreSQL compatible system. RDS Aurora MySQL RDS Aurora MySQL Basics Amazons proprietary fork of MySQL intended to scale up for high concurrency workloads. Generally speaking, individual query performance under Aurora is not expected to improve significantly relative to MySQL or MariaDB, but Aurora is intended to maintain performance while executing many more queries concurrently than an equivalent MySQL or MariaDB server could handle. Notable new features include: Log-structured storage instead of B-trees to improve write performance. Out-of-process buffer pool so that databases instances can be restarted without clearing the buffer pool. The underlying physical storage is a specialized SSD array that automatically maintains 6 copies of your data across 3 AZs. Aurora read replicas share the storage layer with the write master which significantly reduces replica lag, eliminates the need for the master to write and distribute the binary log for replication, and allows for zero-data-loss failovers from the master to a replica. The master and all the read replicas that share storage are known collectively as an Aurora cluster. Read replicas can span up to 5 regions. Back to top :arrow_up: RDS Aurora MySQL Tips In order to take advantage of Auroras higher concurrency, applications should be configured with large database connection pools and should execute as many queries concurrently as possible. For example, Aurora servers have been tested to produce increasing performance on some OLTP workloads with up to 5,000 connections. Aurora scales well with multiple CPUs and may require a large instance class for optimal performance. The easiest migration path to Aurora is restoring a database snapshot from MySQL 5.6 or 5.7. The next easiest method is restoring a dump from a MySQL-compatible database such as MariaDB. For low-downtime migrations from other MySQL-compatible databases, you can set up an Aurora instance as a replica of your existing database. If none of those methods are options, Amazon offers a fee-based data migration service. You can replicate from an Aurora cluster to MySQL or to another Aurora cluster. This requires binary logging to be enabled and is not as performant as native Aurora replication. Because Aurora read replicas are the equivalent of a multi-AZ backup and they can be configured as zero-data-loss failover targets, there are fewer scenarios in which the creation of a multi-AZ Aurora instance is required. Back to top :arrow_up: RDS Aurora MySQL Gotchas and Limitations Aurora 1.x is based on MySQL 5.6.x with some cherry-picking of later MySQL features. It is missing most 5.7 features as well as some online DDL features introduced in 5.6.17. Aurora 2.x is based on MySQL 5.7.x Aurora does not support GTID transactions in either the 5.6/Aurora 1.x or the 5.7/Aurora 2.x release lines. Aurora maximum cluster size is 64 TB RDS Aurora PostgreSQL RDS Aurora PostgreSQL Basics Amazons proprietary fork of PostgreSQL, intended to scale up for high concurrency workloads while maintaining ease of use. Currently based on PostgreSQL 9.6. Higher throughput (up to 3x with similar hardware). Automatic storage scale in 10GB increments up to 64TB. Low latency read replicas that share the storage layer with the master which significantly reduces replica lag. Point in time recovery. Fast database snapshots. Back to top :arrow_up: RDS Aurora PostgreSQL Tips Aurora Postgres by default is supposed to utilize high connection rates and for this reason connection pooling must be configured accordingly. Because Aurora is based on PostgreSQL 9.6, it lacks features like declarative partitioning or logical replication. Back to top :arrow_up: RDS Aurora PostgreSQL Gotchas and Limitations Aurora PostgreSQL falls behind normal RDS when it comes to available versions, so if you need features from the latest PostgreSQL version you might be better off with plain RDS. Patching and bug fixing is separate from open source PostgreSQL. ElastiCache ElastiCache Basics Homepage User guide for Redis User guide for Memcached FAQ Pricing ElastiCache is a managed in-memory cache service, that can be used to store temporary data in a fast in-memory cache, typically in order to avoid repeating the same computation multiple times when it could be reused. It supports both the Memcached and Redis open source in-memory cache software and exposes them both using their native access APIs. The main benefit is that AWS takes care of running, patching and optimizing the cache nodes for you, so you just need to launch a cluster and configure its endpoint in your application, while AWS will take of most of the operational work of running the cache nodes. Back to top :arrow_up: ElastiCache Tips Choose the engine, clustering configuration and instance type carefully based on your application needs. The documentation explains in detail the pros, cons and limitations of each engine in order to help you choose the best fit for your application. In a nutshell, Redis is preferable for storing more complex data structures, while Memcached is just a plain key/value store. The simplicity of Memcached allows it to be slightly faster and allows it to scale out if needed, but Redis has more features which you may use in your application. For Memcached AWS provides enhanced SDKs for certain programming languages which implement auto-discovery, a feature not available in the normal memcached client libraries. Back to top :arrow_up: ElastiCache Gotchas and Limitations Since in some cases changing the cache clusters may have some restrictions, like for scaling purposes, it may become a problem if they were launched using CloudFormation in a stack that also contains other resources and you really need to change the cache. In order to avoid getting your CloudFormation stacks in a non-updateable state, it is recommended to launch ElastiCache clusters (just like any other resource with similar constraints) in dedicated stacks which can be replaced entirely with new stacks having the desired configuration. DynamoDB DynamoDB Basics Homepage Developer guide FAQ Pricing DynamoDB is a NoSQL database with focuses on speed, flexibility, and scalability. DynamoDB is priced on a combination of throughput and storage. Back to top :arrow_up: DynamoDB Alternatives and Lock-in Unlike the technologies behind many other Amazon products, DynamoDB is a proprietary AWS product with no interface-compatible alternative available as an open source project. If you tightly couple your application to its API and featureset, it will take significant effort to replace. The most commonly used alternative to DynamoDB is Cassandra. Back to top :arrow_up: DynamoDB Tips There is a local version of DynamoDB provided for developer use. DynamoDB Streams provides an ordered stream of changes to a table. Use it to replicate, back up, or drive events off of data DynamoDB can be used as a simple locking service. DynamoDB indexing can include primary keys, which can either be a single-attribute hash key or a composite hash-key range. You can also query non-primary key attributes using secondary indexes. Data Types: DynamoDB supports three data types number, string, and binary in both scalar and multi-valued sets. DynamoDB can also support JSON. As of late 2017, DynamoDB supports both global tables and backup / restore functionality. Back to top :arrow_up: DynamoDB Gotchas and Limitations DynamoDB doesnt provide an easy way to bulk-load data (it is possible through Data Pipeline) and this has some unfortunate consequences. Since you need to use the regular service APIs to update existing or create new rows, it is common to temporarily turn up a destination tables write throughput to speed import. But when the tables write capacity is increased, DynamoDB may do an irreversible split of the partitions underlying the table, spreading the total table capacity evenly across the new generation of tables. Later, if the capacity is reduced, the capacity for each partition is also reduced but the total number of partitions is not, leaving less capacity for each partition. This leaves the table in a state where it much easier for hotspots to overwhelm individual partitions. It is important to make sure that DynamoDB resource limits are compatible with your dataset and workload. For example, the maximum size value that can be added to a DynamoDB table is 400 KB (larger items can be stored in S3 and a URL stored in DynamoDB). Dealing with time series data in DynamoDB can be challenging. A global secondary index together with down sampling timestamps can be a possible solution as explained here. DynamoDB does not allow an empty string as a valid attribute value. The most common work-around is to use a substitute value instead of leaving the field empty. When setting up fine grained policies for access to DynamoDB tables, be sure to include their secondary indices in the policy document as well. ECS ECS Basics Homepage Developer guide FAQ Pricing ECS (EC2 Container Service) is a relatively new service (launched end of 2014) that manages clusters of services deployed via Docker. See the Containers and AWS section for more context on containers. ECS is growing in adoption, especially for companies that embrace microservices. Deploying Docker directly in EC2 yourself is another common approach to using Docker on AWS. Using ECS is not required, and ECS does not (yet) seem to be the predominant way many companies are using Docker on AWS. Its also possible to use Elastic Beanstalk with Docker, which is reasonable if youre already using Elastic Beanstalk. Using Docker may change the way your services are deployed within EC2 or Elastic Beanstalk, but it does not radically change how most other services are used. ECR (EC2 Container Registry) is Amazons managed Docker registry service. While simpler than running your own registry, it is missing some features that might be desired by some users: Doesnt support cross-region replication of images. If you want fast fleet-wide pulls of large images, youll need to push your image into a region-local registry. Doesnt support custom domains / certificates. A containers health is monitored via CLB or ALB. Those can also be used to address a containerized service. When using an ALB you do not need to handle port contention (i.e. services exposing the same port on the same host) since an ALBs target groups can be associated with ECS-based services directly. The Hitchhikers Guide to AWS ECS and Docker by J. Cole Morrison is an excellent article for Introduction to AWS ECS concepts. Back to top :arrow_up: ECS Tips Log drivers: ECS supports multiple log drivers (awslogs, splunk, fluentd, syslog, json, ... ). Use awslogs for CloudWatch (make sure a group is made for the logs first). Drivers such as fluentd are not enabled by default. You can, install the agent and enable the driver by adding ECS_AVAILABLE_LOGGING_DRIVERS='["awslogs","fluentd"]' to /etc/ecs/ecs.config. This blog from Convox (and commentary) lists a number of common challenges with ECS as of early 2016. It is possible to optimize disk clean up on ECS. By default, the unused containers are deleted after 3 hours and the unused images after 30 minutes. These settings can be changed by adding ECS_ENGINE_TASK_CLEANUP_WAIT_DURATION=10m and ECS_IMAGE_CLEANUP_INTERVAL=10m to /etc/ecs/ecs.config. More information on optimizing ECS disk cleanup. Back to top :arrow_up: ECS Alternatives and Lock-in Kubernetes: Extensive container platform. Available as a hosted solution on Google Cloud (https://cloud.google.com/container-engine/) and AWS (https://tectonic.com/). AWS has a Kubernetes Quickstart (https://aws.amazon.com/quickstart/architecture/heptio-kubernetes/) developed in collaboration with Heptio. Nomad: Orchestrator/Scheduler, tightly integrated in the HashiCorp stack (Consul, Vault, etc). Please help expand this incomplete section. EKS EKS Basics Homepage User guide FAQ Pricing EKS (Elastic Kubernetes Service) is a new service (launched June 2018) that provides managed Kubernetes Masters in a Highly Available pair to deploy K8s Services and Pods on top of EC2 based Kubernetes nodes. See the Containers and AWS section for more context on containers. EKS is AWS's solution to hosting Kubernetes natively on AWS. It is not a replacement for ECS directly but is in response to the large market dominance of Kubernetes. EKS does not launch EC2 nodes and would have to be configured and setup either manually or via Cloudformation (or other automation solution) EKS management is done through a utility called kubectl, and with Kube configuration files. These files will need to be configured to speak with the K8s Master with a certificate and URL. The AWS CLI can autogenerate the configuration file that kubect requires for communicating with the cluster.1 EKS authentication is integrated with IAM roles/permissions. The AWS CLI has an integrated sub-command for generating authentication tokens.2 This was formerly done via a custom plugin for kubectl called aws-iam-authenticator (formerly heptio-authenticator-aws). EKS provides Calico from Tigera for securing workloads within a cluster using Kubernetes network policy. Back to top :arrow_up: EKS Tips Multiple clusters can be supported by using different kubeconfig files. AWS has a Kubernetes Quickstart developed in collaboration with Heptio. Back to top :arrow_up: EKS Alternatives and Lock-in ECS: Amazon's native Container Scheduled platform released in 2014. If you don't utilise containers today and are looking to get started, ECS is an excellent product. Kubernetes: Extensive container platform. Available as a hosted solution on Google Cloud, AWS, Digital Ocean and Azure. Nomad: Orchestrator/Scheduler, tightly integrated in the HashiCorp stack (Consul, Vault, etc). Back to top :arrow_up: EKS Gotchas and Limitations Pods and Service configurations can rapidly consume IP addresses inside a VPC. Proper care and maintenance should be applied to ensure IP exhaustion does not occur. There is currently no integrated monitoring in CloudWatch for EKS pods or services, you will need to deploy a monitoring system that supports Kubernetes such as Prometheus. Autoscaling based off CPU/Memory of a node is limited as you will not be aware of pending Services/Pods that cannot start. Using cluster-autoscaler can be useful for scaling based on Node resource usage and unschedulable Pods. Prometheus is a very popular monitoring solution for K8s, metrics and alerts can be used to send events to Lambda, SQS or other solutions to take autoscaling actions. Back to top :arrow_up: Footnotes 1: https://docs.aws.amazon.com/eks/latest/userguide/create-kubeconfig.html 2: https://aws.amazon.com/about-aws/whats-new/2019/05/amazon-eks-simplifies-kubernetes-cluster-authentication/ Fargate Fargate Basics Homepage FAQ Pricing Fargate allows you to manage and deploy containers without having to worry about running the underlying compute infrastructure Fargate serves as a new backend (in addition to the legacy EC2 backend) on which ECS and EKS tasks can be run Fargate and EC2 backends are called "Launch Types" Fargate allows you to treat containers as fundamental building blocks of your infrastructure Back to top :arrow_up: Fargate Tips Fargate follows a similar mindset to Lambda, which lets you focus on applications, instead of dealing with underlying infrastructure Fargate is supported by CloudFormation, aws-cli and ecs-cli Fargate tasks can be launched alongside tasks that use EC2 Launch Type Before creating a large Fargate deployment, make sure to estimate costs and compare them against alternative solution that uses traditional EC2 deployment - Fargate prices can be several times those of equivalently-sized EC2 instances. To evaluate both solutions based on potential costs, refer to pricing for EC2 and Fargate. Back to top :arrow_up: Fargate Alternatives and Lock-in Azure Container Instances: Available on Microsoft Azure in preview version, allows to run applications in containers without having to manage virtual machines Back to top :arrow_up: Fargate Gotchas and Limitations As of April 2018, Fargate is available in multiple regions: us-east-1, us-east-2, us-west-2, and eu-west-1 As of January 2019, Fargate can only be used with ECS. Support for EKS was originally planned for 2018, but has yet to launch. The smallest resource values that can be configured for an ECS Task that uses Fargate is 0.25 vCPU and 0.5 GB of memory Task storage is ephemeral. After a Fargate task stops, the storage is deleted. Lambda Lambda Basics Homepage Developer guide FAQ Pricing Lambda is AWS' serverless compute offering, allowing users to define Lambda functions in a selection of runtimes that can be invoked via a variety of triggers, including SNS notifications and API Gateway invocations. Lambda is the key service that enables 'serverless' architecture on AWS, alongside AWS API Gateway, AWS Batch, and AWS DynamoDB. Back to top :arrow_up: Lambda Tips The idea behind 'serverless' is that users don't manage provisioning, scaling, or maintenance of the physical machines that host their application code. With Lambda, the machine that actually executes the user-defined function is abstracted as a 'container'. When defining a Lambda function, users are able to declare the amount of memory available to the function, which directly affects the physical hardware specification of the Lambda container. Changing the amount of memory available to your Lambda functions also affects the amount of CPU power available to it. While AWS does not offer hard guarantees around container reuse, in general it can be expected that an unaltered Lambda function will reuse a warm (previously used) container if called shortly after another invocation. Users can use this as a way to optimize their functions by smartly caching application data on initialization. A Lambda that hasn't been invoked in some time may not have any warm containers left. In this case, the Lambda system will have to load and initialize the Lambda code in a 'cold start' scenario, which can add significant latency to Lambda invocations. Lambda cold start performance has improved significantly over the 2018-2019 timeframe and is now typically in the range of 200-500 ms for a simple function depending on the language runtime. Lambda functions running insides of VPCs have also seen recent improvements to cold start times. Previously these VPC-hosted functions would have cold starts of ~15 seconds; now those same functions cold start in < 1 second. There are a few strategies to avoiding or mitigating cold starts. Provisioned concurrency was announced at re:invent 2019 and is an effective means to eliminating cold starts. Other techniques include keeping containers warm by periodic triggering and favoring lightweight runtimes such as Node as opposed to Java. Lambda is integrated with AWS CloudWatch and provides a logger at runtime that publishes CloudWatch events. Lambda offers out-of-the-box opt-in support for AWS X-Ray. X-Ray can help users diagnose Lambda issues by offering in-depth analysis of their Lambda's execution flow. This is especially useful when investigating issues calling other AWS services as X-Ray gives you a detailed and easy-to-parse visualization of the call graph. Using timed CloudWatch events, users can use Lambda to run periodic jobs in a cron-like manner. Events sent to Lambda that fail processing can be managed using a Dead Letter Queue (DLQ) in SQS. More on serverless: Martin Fowler's thoughts. AWS Serverless Application Model (SAM), a simplification built on top of CloudFormation that can help to define, manage, and deploy serverless applications using Lambda. Serverless, one of the most popular frameworks for building serverless applications using AWS Lambda and other serverless compute options. Other helpful frameworks. Back to top :arrow_up: Lambda Alternatives and Lock-in Other clouds offer similar services with different names, including Google Cloud Functions, Azure Functions, and IBM OpenWhisk. Also if you are running Kubernetes another Lambda alternative is OpenFaaS Back to top :arrow_up: Lambda Gotchas and Limitations Testing Lambdas, locally and remotely, can be a challenge. Several tools are available to make this easier, including the officially supported SAM Local. Managing lots of Lambda functions is a workflow challenge, and tooling to manage Lambda deployments is still immature. AWS official workflow around managing function versioning and aliases is painful. One option is to avoid Lambda versioning by abstracting your deployment workflow outside of Lambda. One way this can be accomplished is by deploying your application in successive stages, with a distinct AWS account per stage, where each account only needs to be aware of the latest version, and rollbacks and updates are handled by external tooling. While adding/removing S3 buckets as triggers for Lambda function, this error may occur: "There was an error creating the trigger: Configuration is ambiguously defined. Cannot have overlapping suffixes in two rules if the prefixes are overlapping for the same event type." In this case, you can manually remove the Lambda event in the "Events" tab in the "Properties" section of the S3 bucket. Managing the size of your deployment artifact can be a challenge, especially if using Java. Options to mitigate this include proguard and loading dependencies at runtime into /tmp. When using DynamoDB as a trigger for your Lambda functions, this error may occur: "PROBLEM: internal Lambda error. Please contact Lambda customer support." This usually just means that Lambda can't detect anything in the DynamoDB stream within the last 48 hours. If the issue persists, deleting and recreating your trigger may help. If your lambda needs access to resources in a VPC (for example ElastiCache or RDS), it will need to be deployed within it. This will increase cold-start times as an Elastic Network Interface (ENI) will have to be registered within the VPC for each concurrent function. AWS also has a relatively low initial limit (350) on the number ENI's that can be created within an VPC, however this can be increased to the 1000s if a good case is made to AWS support. If your lambda is in a VPC and needs access to resources outside VPC such outbound internet access, it will need a NAT gateway associated even if it is in public subnet. Lambdas won't be assigned a public IP irrespective of subnet. If it is accessing AWS services (for example S3), you may use VPC endpoints. Lambda has several resource limits as of 2017-06: A 6MB request or response payload size. A 50 MB limit on the compressed .zip/.jar file deployment package size. A 250 MB limit on the code/dependencies in the package before compression. A 500 MB limit on local storage in /tmp. Back to top :arrow_up: Lambda Code Samples Fan-out is an example of using Lambda to fan-out or copy data from one service, in this case Kinesis, to multiple other AWS data services. Destinations for fan-out data in the sample include IoT, SQS and more. This AWS limit monitor using Lambdas shows use of multiple Lambdas for monitoring. This Lambda ECS Worker Pattern shows use of Lambda in a workflow where data from S3 is picked up by the Lambda, pushed to a queue, then sent to ECS for more processing. The Secure Pet Store is a sample Java application which uses Lambda and API Gateway with Cognito (for user identity). aws-lambda-list is a list of "hopefully useful AWS lambdas and lambda-related resources". Quite a few code samples here; as usual, not guaranteed tested. Caveat Emptor. Please help expand this incomplete section. API Gateway API Gateway Basics Homepage Developer guide FAQ Pricing API Gateway provides a scalable, secured front-end for service APIs, and can work with Lambda, Elastic Beanstalk, or regular EC2 services. It allows serverless deployment of applications built with Lambda. Switching over deployments after upgrades can be tricky. There are no built-in mechanisms to have a single domain name migrate from one API gateway to another one. So it may be necessary to build an additional layer in front (even another API Gateway) to allow smooth migration from one deployment to another. Back to top :arrow_up: API Gateway Alternatives and Lock-In Kong is an open-source, on-premises API and microservices gateway built on nginx with Lua. Kong is extensible through plugins. Tyk is an open-source API gateway implemented in Go and available in the cloud, on-premises or hybrid. Back to top :arrow_up: API Gateway Tips Prior to 2016-11, you could only send and receive plain text data (so people would base64-encode binary data), but binary data is now supported. API Gateway supports the OpenApi specification (aka Swagger). This allows you to describe your API in a language-agnostic way and use various tools to generate code supporting your API. Generating clients is extremely easy, either through the AWS console or using the get-sdk API. API Gateway integrates with CloudWatch out-of-the-box, allowing for easy logging of requests and responses. Note that if your request or response are too large, CloudWatch will truncate the log. For full request/reply logging, make sure to do so in your integration (e.g. Lambda). A good practice when calling API Gateway APIs is to log the request ID on the client. You can later refer to these request IDs in CloudWatch for easier tracing and debugging. There are multiple ways to secure your API, including built-in support for AWS Cognito. For most use-cases, Cognito is the easiest and simplest way to authenticate users. Although you can roll your own solution using a custom authorizer, which is basically a Lambda you define that determines if a request is acceptable or not. While API Gateway lends itself well to REST-style development, it's perfectly reasonable to implement an RPC-style API in API Gateway as well. Depending on your use-case, this can often lead to a much simpler API structure and smoother client experience. RPC-style APIs are particularly useful when designing services that sit deeper in the stack and don't serve content directly to users. Back to top :arrow_up: API Gateway Gotchas and Limitations API Gateway only supports encrypted (https) endpoints, and does not support unencrypted HTTP. (This is probably a good thing.) API Gateway doesnt support multi-region deployments for high availability. It is a service that is deployed in a single region but comes with a global endpoint that is served from AWS edge locations (similar to a CloudFront distribution). You cannot have multiple API Gateways with the same hostname in different AWS regions and use Route 53 to distribute the traffic. More in this forum post. Integration timeout: All of the various integration types (eg: Lambda, HTTP) for API Gateway have timeouts, as described here. Unlike some limits, these timeouts can't be increased. API Gateway returns a 504 status code for any network or low level transport related issue. When this happens, you may see a message in the CloudWatch logs for the request that includes the message: Execution failed due to an internal error. One possible reason for this error is that even though your backend server is up and running, it may be doing something outside of the HTTP specification (like not sending well-formed chunked messages). You can test by hitting your backend directly with the curl --raw -S -i <backend-endpoint-url> and seeing if it complains. AWS X-Ray support exists but cumbersome to use. If you have other AWS services calling API Gateway, your trace will seemingly end there. API Gateway will also not appear as a node in your service map. More here. Be careful using the export feature. The resulting Swagger template is often incomplete and doesn't integrate well with the Swagger extensions for things such as CORS. Many changes to API Gateway resources need to be 'deployed' via console or API call. Unfortunately, API Gateway is terrible about notifying the user when changes are staged for deployment and what changes require deployment. If you've changed something about your API and it's not taking effect, there's a decent chance you just need to deploy it. In particular, when deploying an API Gateway as part of a CloudFormation stack, changes will not automatically deploy unless the deployment resource itself was changed. You can change work around this by always changing the deployment resource on a CloudFormation update, or running a custom resource that ensures the deployment is made. Alternatively, by using the Serverless Application Model definition for an API Gateway resource, you can always expect the API to be deployed on a stack update since SAM will generate a new deployment every time. API Gateway does not support nested query parameters on method requests. API Gateway limits number of resources to 300, as described here. This is something to be considered when you start using API Gateway as a platform where your team/organization deploys to the same API Gateway. Please help expand this incomplete section. Step Functions Step Functions Basics Homepage Developer guide FAQ Pricing Step Functions is AWS way to create state machines that manage a serverless workflow. Back to top :arrow_up: Step Functions Tips A variety of structures are supported including branching, parallel operations and waits Tasks represent the real work nodes and are frequently Lambda functions, but can be Activities which are externally driven tasks implemented any way you like. State machines have data that "flows" through the steps and can be modified and added to as the state machine executes. It's best if your tasks are idempotent, in part because you may want to re-run the state machine with the same input data during debugging The AWS Console facilitates your examining the execution state at various steps. The console lets you do this with a few steps: select the "input" tab from the failed execution copy the input data (JSON) select the state machine name in the breadcrumbs start a new execution, pasting the input data you copied previously Back to top :arrow_up: Step Functions Gotchas and Limitations Step Functions are free tier eligible up to an initial 4000 transitions per month. Thereafter, the charge is $0.025 per 1000 state transitions. You can have many, simultaneous, executions, but be aware of lambda throttling limits. This has been per-account, pre-region, but recently became settable per-lambda. Step Function executions are limited to 25,000 events. Each step creates multiple events. This means that iterating a loop using Lambda is limited to an iteration count of around 3000 before needing to continue as a new execution. Route 53 Route 53 Basics Homepage Developer guide FAQ Pricing Route 53 is AWS DNS service. Back to top :arrow_up: Route 53 Alternatives and Lock-In Historically, AWS was slow to penetrate the DNS market (as it is often driven by perceived reliability and long-term vendor relationships) but Route 53 has matured and is becoming the standard option for many companies. Route 53 is cheap by historic DNS standards, as it has a fairly large global network with geographic DNS and other formerly premium features. Its convenient if you are already using AWS. Generally you dont get locked into a DNS provider for simple use cases, but increasingly become tied in once you use specific features like geographic routing or Route 53s alias records. Many alternative DNS providers exist, ranging from long-standing premium brands like UltraDNS and Dyn to less well known, more modestly priced brands like DNSMadeEasy. Most DNS experts will tell you that the market is opaque enough that reliability and performance dont really correlate well with price. Route 53 is usually somewhere in the middle of the pack on performance tests, e.g. the SolveDNS reports. Back to top :arrow_up: Route 53 Tips Know about Route 53s alias records: Route 53 supports all the standard DNS record types, but note that alias resource record sets are not standard part of DNS, but a specific Route 53 feature. (Its available from other DNS providers too, but each provider has a different name for it.) Aliases are like an internal name (a bit like a CNAME) that is resolved internally on the server side. For example, traditionally you could have a CNAME to the DNS name of a CLB or ALB, but its often better to make an alias to the same load balancer. The effect is the same, but in the latter case, externally, all a client sees is the target the record points to. Its often wise to use alias record as an alternative to CNAMEs, since they can be updated instantly with an API call, without worrying about DNS propagation. You can use them for CLBs/ALBs or any other resource where AWS supports it. Somewhat confusingly, you can have CNAME and A aliases, depending on the type of the target. Because aliases are extensions to regular DNS records, if exported, the output zone file will have additional non-standard ALIAS lines in it. Latency-based routing allows users around the globe to be automatically directed to the nearest AWS region where you are running, so that latency is reduced. Understand that domain registration and DNS management (hosted zones) are two separate Route 53 services. When you buy/transfer a domain, Route 53 automatically assigns four name servers to it (e.g. ns-2.awsdns-00.com). Route 53 also offers to automatically create a hosted zone for DNS management, but you are not required do your DNS management in the same account or even in Route 53; you just need to create an NS record pointing to the servers assigned to your domain in Route 53. One use case would be to put your domain registration (very mission critical) in a bastion account while managing the hosted zones within another account which is accessible by your applications. Back to top :arrow_up: Route 53 Gotchas and Limitations Private Hosted Zone will only respond to DNS queries that originate from within a VPC. As a result Route53 will not respond to request made via a VPN or Direct connect. To get around this you will need to implement Hybrid Cloud DNS Solutions or use the Simple AD provided IP addresses to query the hosted zone. CloudFormation CloudFormation Basics Homepage Developer guide FAQ Pricing at no additional charge CloudFormation allows you to manage sets of resources from other AWS services grouped into stacks. CloudFormation allows you to define these stacks in a template using JSON or YAML. CloudFormation is one of the major services underpinning AWS' infrastructure as code capabilities and is crucial in enabling repeatable and consistent deployments of infrastructure. CloudFormation itself has no additional charge; you pay for the underlying resources. Back to top :arrow_up: CloudFormation Alternatives and Lock-In HashiCorps Terraform is a third-party alternative that can support other cloud platforms/providers including Azure and OpenStack. Some AWS features may not be available in Terraform (e.g. multi-AZ ElastiCache using Redis), and you may have to resort to embedded CloudFormation templates. Pulumi enables teams to define and deliver Cloud Native Infrastructure as Code on any cloud, with any language. From containers to serverless to Kubernetes to infrastructure. Back to top :arrow_up: CloudFormation Tips Validate your stack in a different AWS account! CloudFormation truly shines when making multiple deployments of the same stack to different accounts and regions. A common practice is to deploy stacks in successive stages ending in a production rollout. Avoid potentially time-consuming syntax errors from eating into your deployment time by running validate-template. CloudFormation is sometimes slow to update what resources (and new features on old services) a user is able to define in the template. If you need to deploy a resource or feature that isn't supported by the template, CloudFormation allows running arbitrary code (using Lambda) on a stack create or update via custom resources. Custom resources make CloudFormation into a truly powerful tool, as you can do all sorts of neat things quite easily such as sanity tests, initial configuration of Dynamo tables or S3 buckets, cleaning up old CloudWatch logs, etc. For writing Custom Resources in Javascript, AWS provides a good reference in the documentation. CloudFormation offers a visual template designer that can be useful when getting up to speed with the template syntax. By using StackSets, users can define and deploy an entire production application consisting of multiple stacks (one service per stack) in a single CloudFormation template. If you're developing a serverless application (i.e., using Lambda, API Gateway) CloudFormation offers a simplified template format called SAM. Use a restrictive stack policy! Without one, you can inadvertently delete live production resources, probably causing a severe outage. Turn on termination protection on all of your stacks to avoid costly accidents! The CloudFormation template reference is indispensable when discovering what is and isn't possible in a CloudFormation template. Troposphere is a Python library that makes it much easier to create CloudFormation templates. Currently supports AWS and OpenStack resource types. Troposphere attempts to support all resources types that can be described in CloudFormation templates. Built in error checking. A recommended soft dependency is awacs, which allows you to generate AWS access policy in JSON by writing Python code. stacker is a Python application that makes it easy to define, configure, orchestrate and manage dependencies for CloudFormation stacks across multiple user-defined environments. If you are building different stacks with similar layers, it may be useful to build separate templates for each layer that you can reuse using AWS::CloudFormation::Stack. Avoid hardcoding resource parameters that can potentially change. Use stack parameters as much as you can, and resort to default parameter values. Until 2016, CloudFormation used only an awkward JSON format that makes both reading and debugging difficult. To use it effectively typically involved building additional tooling, including converting it to YAML, but now this is supported directly. Wherever possible, export relevant physical IDs from your Stacks by defining Outputs in your CloudFormation Templates. These are the actual names assigned to the resources being created. Outputs can be returned from DescribeStack API calls, and get imported to other Stacks as part of the recent addition of cross-stack references. -Note that importing outputs in a stack from another stack creates a hard dependency that is tracked by CloudFormation. You will not be able to delete the stack with the outputs until there are no importing stacks. CloudFormation can be set up to send SNS notifications upon state changes, enabling programmatic handling of situations where stacks fail to build, or simple email alerts so the appropriate people are informed. CloudFormation allows the use of conditionals when creating a stack. One common way to leverage this capability is in support of multi-environment CloudFormation templates by configuring them to use if-else statements on the value of a parameter passed in (e.g. env), environment-specific values for things like VPC IDs, SecurityGroup IDs, and AMI names can be passed into reusable generic templates. Version control your CloudFormation templates! In the Cloud, an application is the combination of the code written and the infrastructure it runs on. By version controlling both, it is easy to roll back to known good states. Avoid naming your resources explicitly (e.g. DynamoDB tables). When deploying multiple stacks to the same AWS account, these names can come into conflict, potentially slowing down your testing. Prefer using resource references instead. For things that shouldn't ever be deleted, you can set an explicit DeletionPolicy on the resource that will prevent the resource from being deleted even if the CloudFormation stack itself is deleted. This is useful for anything that can maintain expensive-to-rebuild state, such as DynamoDB tables, and things that are exposed to the outside world, such as API Gateway APIs. Back to top :arrow_up: CloudFormation Gotchas and Limitations A given CloudFormation stack can end up in a wide variety of states. Error reporting is generally weak, and often times multiple observe-tweak-redeploy cycles are needed to get a working template. The internal state machine for all the varying states is extremely opaque. Some cross-region operations are not possible in CloudFormation without using a custom resource, such as cross-region SNS subscriptions. While having hand-made resources live alongside CloudFormation-created resources is inadvisable, it's sometimes unavoidable. If at all possible, leave ALL resource management up to a CloudFormation template and only provide read-only access to the console. Modifications to stack resources made outside CloudFormation can potentially lead to stacks stuck in UPDATE_ROLLBACK_FAILED mode. Stacks in this state can be recovered using the continue-update-rollback command. This command can be initiated in the console or in the CLI. The --resources-to-skip parameter usable in the CLI can be useful if the continue-update-rollback command fails. New feature Drift Detection can be used to detect outside changes made to stack. CloudFormation is useful but complex and with a variety of pain points. Many companies find alternate solutions, and many companies use it, but only with significant additional tooling. CloudFormation can be very slow, especially for items like CloudFront distributions and Route53 CNAME entries. Its hard to assemble good CloudFormation configurations from existing state. AWS does offer a trick to do this, but its very clumsy. CloudFormer also hasn't been updated in ages (as of Oct 2017), doesn't support templatizing many new services, and won't fully define even existing services that have since been updated. For example, Dynamo tables defined through CloudFormer won't contain TTL definitions or auto-scaling configuration. There is a third-party version of the tool with more supported resources called Former2. Many users dont use CloudFormation at all because of its limitations, or because they find other solutions preferable. Often there are other ways to accomplish the same goals, such as local scripts (Boto, Bash, Ansible, etc.) you manage yourself that build infrastructure, or Docker-based solutions (Convox, etc.). Deploying large stacks (i.e., many resources) can be problematic due to unintuitive API limits. For instance, API Gateway's CreateDeployment API has a default limit of 3 requests per minute as of 1/12/2018. This limit is readily exceeded even in moderately-sized CloudFormation stacks. Creating CW alarms is another commonly seen limit (PutMetricAlarm, 3 tps as of 1/12/2018) especially when creating many autoscaling policies for DynamoDB. One way to work around this limit is to include CloudFormation 'DependsOn' clauses to artificially chain resource creation. Creating/deleting stacks can be a little less clean than ideal. Some resources will leave behind traces in your AWS account even after deletion. E.g., Lambda will leave behind CloudWatch log groups that never expire. VPCs, Network Security, and Security Groups VPC Basics Homepage User guide FAQ Security groups Pricing VPC (Virtual Private Cloud) is the virtualized networking layer of your AWS systems. Most AWS users should have a basic understanding of VPC concepts, but few need to get into all the details. VPC configurations can be trivial or extremely complex, depending on the extent of your network and security needs. All modern AWS accounts (those created after 2013-12-04) are EC2-VPC accounts that support VPCs, and all instances will be in a default VPC. Older accounts may still be using EC2-Classic mode. Some features dont work without VPCs, so you probably will want to migrate. Back to top :arrow_up: VPC and Network Security Tips Security groups are your first line of defense for your servers. Be extremely restrictive of what ports are open to all incoming connections. In general, if you use CLBs, ALBs or other load balancing, the only ports that need to be open to incoming traffic would be port 22 and whatever port your application uses. Security groups access policy is 'deny by default'. Port hygiene: A good habit is to pick unique ports within an unusual range for each different kind of production service. For example, your web frontend might use 3010, your backend services 3020 and 3021, and your Postgres instances the usual 5432. Then make sure you have fine-grained security groups for each set of servers. This makes you disciplined about listing out your services, but also is more error-proof. For example, should you accidentally have an extra Apache server running on the default port 80 on a backend server, it will not be exposed. Migrating from Classic: For migrating from older EC2-Classic deployments to modern EC2-VPC setup, this article may be of help. You can migrate Elastic IPs between EC2-Classic and EC2-VPC. For basic AWS use, one default VPC may be sufficient. But as you scale up, you should consider mapping out network topology more thoroughly. A good overview of best practices is here. Consider controlling access to you private AWS resources through a VPN. You get better visibility into and control of connection and connection attempts. You expose a smaller surface area for attack compared to exposing separate (potentially authenticated) services over the public internet. e.g. A bug in the YAML parser used by the Ruby on Rails admin site is much less serious when the admin site is only visible to the private network and accessed through VPN. Another common pattern (especially as deployments get larger, security or regulatory requirements get more stringent, or team sizes increase) is to provide a bastion host behind a VPN through which all SSH connections need to transit. For a cheap VPN to access private AWS resources, consider using a point-to-site software VPN such as OpenVPN. It can either be installed using the official AMI, though you are limited to 2 concurrent users on the free license, or it can be installed using the openvpn package on linux. The linux package allows for unlimited concurrent users but the installation is less straightforward. This OpenVPN installer script can help you install it and add client keys easily. Consider using other security groups as sources for security group rules instead of using CIDRs that way, all hosts in the source security group and only hosts in that security group are allowed access. This is a much more dynamic and secure way of managing security group rules. VPC Flow Logs allow you to monitor the network traffic to, from, and within your VPC. Logs are stored in CloudWatch Logs groups, and can be used for security monitoring (with third party tools), performance evaluation, and forensic investigation. See the VPC Flow Logs User Guide for basic information. See the flowlogs-reader CLI tool and Python library to retrieve and work with VPC Flow Logs. IPv6 is available in VPC. Along with this announcement came the introduction of the Egress-Only Internet Gateway. In cases where one would use NAT Gateways to enable egress-only traffic for their VPC in IPv4, one can use an Egress-Only Internet Gateway for the same purpose in IPv6. Amazon provides an IPv6 CIDR block for your VPC at your request - at present you cannot implement your own IPv6 block if you happen to own one already. New and existing VPCs can both use IPv6. Existing VPCs will need to be configured to have an IPv6 CIDR block associated with them, just as new VPCs do. Back to top :arrow_up: PrivateLink Homepage User Guide Pricing One of the uses for Private link is Interface VPC Endpoints deploys an ENI into your VPC and subnets which allows you direct access to the AWS API's as if the were accessible locally in your VPC without having to go out to the internet. Another use case would be to expose a service of your own to other accounts in AWS through a VPC Endpoint Service Back to top :arrow_up: VPC and Network Security Gotchas and Limitations VPCs are tied to one Region in one Account. Subnets are tied to one VPC and limited to one Availability Zone. Security groups are tied to one VPC. If you are utilizing infrastructure in multiple VPCs you should make sure your configuration/deployment tools take that into account. VPC Endpoints are currently only available for S3 and DynamoDB. If you have a security requirement to lockdown outbound traffic from your VPC you may want to use DNS filtering to control outbound traffic to other services. Be careful when choosing your VPC IP CIDR block: If you are going to need to make use of ClassicLink, make sure that your private IP range doesnt overlap with that of EC2 Classic. If you are going to peer VPCs, carefully consider the cost of data transfer between VPCs, since for some workloads and integrations, this can be prohibitively expensive. New RDS instances require a subnet group within your VPC. If youre using the default VPC this isnt a concern, it will contain a subnet for each availability zone in your region. However, if youre creating your own VPC and plan on using RDS, make sure you have at least two subnets within the VPC to act as the subnet group. If you delete the default VPC, you can recreate it via the CLI or the console. Be careful with VPC VPN credentials! If lost or compromised, the VPN endpoint must be deleted and recreated. See the instructions for Replacing Compromised Credentials. Security Groups and Route Tables apply entries separately for IPv4 and IPv6, so one must ensure they add entries for both protocols accordingly. Managed NAT gateways are a convenient alternative to manually managing NAT instances, but they do come at a cost per gigabyte. Consider alternatives if you're transferring many terabytes from private subnets to the internet. If you transfer terabytes/petabytes of data from EC2 instances in private subnets to S3, avoid the NAT gateway data processing charge by setting up a Gateway Type VPC Endpoint and route the traffic to/from S3 through the VPC endpoints instead of going through the NAT gateways. KMS KMS Basics Homepage Developer guide FAQ Pricing KMS (Key Management Service) is a secure service for creating, storing and auditing usage of cryptographic keys. Service integration: KMS integrates with other AWS services: EBS, Elastic Transcoder, EMR, Redshift, RDS, SES, S3, WorkMail and Workspaces. Encryption APIs: The Encrypt and Decrypt API allow you to encrypt and decrypt data on the KMS service side, never exposing the master key contents. Data keys: The GenerateDataKey API generates a new key off of a master key. The data key contents are exposed to you so you can use it to encrypt and decrypt any size of data in your application layer. KMS does not store, manage or track data keys, you are responsible for this in your application. Auditing: Turn on CloudTrail to audit all KMS API events. Access: Use key policies and IAM policies to grant different levels of KMS access. For example, you create an IAM policy that only allows a user to encrypt and decrypt with a specific key. Back to top :arrow_up: KMS Tips Its very common for companies to manage keys completely via home-grown mechanisms, but its far preferable to use a service such as KMS from the beginning, as it encourages more secure design and improves policies and processes around managing keys. A good motivation and overview is in this AWS presentation. The cryptographic details are in this AWS whitepaper. This blog from Convox demonstrates why and how to use KMS for encryption at rest. Back to top :arrow_up: KMS Gotchas and Limitations The Encrypt API only works with < 4KB of data. Larger data requires generating and managing a data key in your application layer. KMS audit events are not available in the CloudTrail Lookup Events API. You need to look find them in the raw .json.gz files that CloudTrail saves in S3. In order to encrypt a multi-part upload to S3, the KMS Key Policy needs to allow kms:Decrypt and kms:GenerateDataKey* in addition to kms:Encrypt, otherwise the upload will fail with an AccessDenied error. KMS keys are region specific they are stored and can only be used in the region in which they are created. They can't be transferred to other regions. KMS keys have a key policy that must grant access to something to manage the key. If you don't grant anything access to the key on creation, then you have to reach out to support to have the key policy reset Reduce the Risk of the Key Becoming Unmanagable. If you use a key policy to grant access to IAM roles or users and then delete the user/role, recreating the user or role won't grant them permission to the key again. CloudFront CloudFront Basics Homepage Developer guide FAQ Pricing CloudFront is AWS content delivery network (CDN). Its primary use is improving latency for end users through accessing cacheable content by hosting it at over 60 global edge locations. Back to top :arrow_up: CloudFront Alternatives and Lock-in CDNs are a highly fragmented market. CloudFront has grown to be a leader, but there are many alternatives that might better suit specific needs. Back to top :arrow_up: CloudFront Tips IPv6 is supported. This is a configurable setting, and is enabled by default on new CloudFront distributions. IPv6 support extends to the use of WAF with CloudFront. HTTP/2 is now supported! Clients must support TLS 1.2 and SNI. While the most common use is for users to browse and download content (GET or HEAD methods) requests, CloudFront also supports (since 2013) uploaded data (POST, PUT, DELETE, OPTIONS, and PATCH). You must enable this by specifying the allowed HTTP methods when you create the distribution. Interestingly, the cost of accepting (uploaded) data is usually less than for sending (downloaded) data. In its basic version, CloudFront supports SSL via the SNI extension to TLS, which is supported by all modern web browsers. If you need to support older browsers, you need to pay a few hundred dollars a month for dedicated IPs. Consider invalidation needs carefully. CloudFront does support invalidation of objects from edge locations, but this typically takes many minutes to propagate to edge locations, and costs $0.005 per request after the first 1000 requests. (Some other CDNs support this better.) Everyone should use TLS nowadays if possible. Ilya Grigoriks table offers a good summary of features regarding TLS performance features of CloudFront. An alternative to invalidation that is often easier to manage, and instant, is to configure the distribution to cache with query strings and then append unique query strings with versions onto assets that are updated frequently. For good web performance, it is recommended to enable compression on CloudFront distributions if the origin is S3 or another source that does not already compress. Back to top :arrow_up: CloudFront Gotchas and Limitations If using S3 as a backing store, remember that the endpoints for website hosting and for general S3 are different. Example: bucketname.s3.amazonaws.com is a standard S3 serving endpoint, but to have redirect and error page support, you need to use the website hosting endpoint listed for that bucket, e.g. bucketname.s3-website-us-east-1.amazonaws.com (or the appropriate region). By default, CloudFront will not forward HTTP Host: headers through to your origin servers. This can be problematic for your origin if you run multiple sites switched with host headers. You can enable host header forwarding in the default cache behavior settings. 4096-bit SSL certificates: CloudFront do not support 4096-bit SSL certificates as of late 2016. If you are using an externally issued SSL certificate, youll need to make sure its 2048 bits. See ongoing discussion. Although connections from clients to CloudFront edge servers can make use of IPv6, connections to the origin server will continue to use IPv4. DirectConnect DirectConnect Basics Homepage User guide FAQ Pricing Direct Connect is a private, dedicated connection from your network(s) to AWS. Back to top :arrow_up: DirectConnect Tips If your data center has a partnering relationship with AWS, setup is streamlined. Use for more consistent predictable network performance guarantees (1 Gbps or 10 Gbps per link). Use to peer your colocation, corporate, or physical datacenter network with your VPC(s). Example: Extend corporate LDAP and/or Kerberos to EC2 instances running in a VPC. Example: Make services that are hosted outside of AWS for financial, regulatory, or legacy reasons callable from within a VPC. Redshift Redshift Basics Homepage Developer guide FAQ Pricing Redshift is AWS managed data warehouse solution, which is massively parallel, scalable, and columnar. It is very widely used. It was built using ParAccel technology and exposes Postgres-compatible interfaces. Back to top :arrow_up: Redshift Alternatives and Lock-in Whatever data warehouse you select, your business will likely be locked in for a long time. Also (and not coincidentally) the data warehouse market is highly fragmented. Selecting a data warehouse is a choice to be made carefully, with research and awareness of the market landscape and what business intelligence tools youll be using. Back to top :arrow_up: Redshift Tips Although Redshift is mostly Postgres-compatible, its SQL dialect and performance profile are different. Redshift supports only 12 primitive data types. (List of unsupported Postgres types) It has a leader node and computation nodes (the leader node distributes queries to the computation ones). Note that some functions can be executed only on the lead node. Make sure to create a new cluster parameter group and option group for your database since the default parameter group does not allow dynamic configuration changes. Major third-party BI tools support Redshift integration (see Quora). Top 10 Performance Tuning Techniques for Amazon Redshift provides an excellent list of performance tuning techniques. Amazon Redshift Utils contains useful utilities, scripts and views to simplify Redshift ops. VACUUM regularly following a significant number of deletes or updates to reclaim space and improve query performance. Avoid performing blanket VACUUM or ANALYZE operations at a cluster level. The checks on each table to determine whether VACUUM or ANALYZE action needs to be taken is wasteful. Only perform ANALYZE and VACUUM commands on the objects that require it. Utilize the Analyze & Vacuum Schema Utility to perform this work. The SQL to determine whether a table needs to be VACUUMed or ANALYZEd can be found in the Schema Utility README if you wish to create your own maintenance process. Redshift provides various column compression options to optimize the stored data size. AWS strongly encourages users to use automatic compression at the COPY stage, when Redshift uses a sample of the data being ingested to analyze the column compression options. However, automatic compression can only be applied to an empty table with no data. Therefore, make sure the initial load batch is big enough to provide Redshift with a representative sample of the data (the default sample size is 100,000 rows). Redshift uses columnar storage, hence it does not have indexing capabilities. You can, however, use distribution key and sortkey to improve performance. Redshift has two types of sort keys: compounding sort key and interleaved sort key. A compound sort key is made up of all columns listed in the sort key definition. It is most useful when you have queries with operations using the prefix of the sortkey. An interleaved sort key on the other hand gives equal weight to each column or a subset of columns in the sort key. So if you don't know ahead of time which column(s) you want to choose for sorting and filtering, this is a much better choice than the compound key. Here is an example using interleaved sort key. Distribution strategies: Since data in Redshift is physically distributed among nodes, choosing the right data distribution key and distribution style is crucial for adequate query performance. There are three possible distribution style settings EVEN (the default), KEY, or ALL. Use KEY to collocate join key columns for tables which are joined in queries. Use ALL to place the data in small-sized tables on all cluster nodes. Back to top :arrow_up: Redshift Gotchas and Limitations While Redshift can handle heavy queries well, it does not scale horizontally, i.e. does not handle multiple queries in parallel. Therefore, if you expect a high parallel load, consider replicating or (if possible) sharding your data across multiple clusters. The leader node, which manages communications with client programs and all communication with compute nodes, is the single point of failure. Although most Redshift queries parallelize well at the compute node level, certain stages are executed on the leader node, which can become the bottleneck. Redshift data commit transactions are very expensive and serialized at the cluster level. Therefore, consider grouping multiple mutation commands (COPY/INSERT/UPDATE) commands into a single transaction whenever possible. Redshift does not support multi-AZ deployments. Building multi-AZ clusters is not trivial. Here is an example using Kinesis. Beware of storing multiple small tables in Redshift. The way Redshift tables are laid out on disk makes it impractical. The minimum space required to store a table (in MB) is nodes * slices/node * columns. For example, on a 16 node cluster an empty table with 20 columns will occupy 640MB on disk. Query performance degrades significantly during data ingestion. WLM (Workload Management) tweaks help to some extent. However, if you need consistent read performance, consider having replica clusters (at the extra cost) and swap them during update. Never resize a live cluster. The resize operation can take hours depending on the dataset size. In rare cases, the operation may also get stuck and you'll end up having a non-functional cluster. The safer approach is to create a new cluster from a snapshot, resize the new cluster and shut down the old one. Redshift has reserved keywords that are not present in Postgres (see full list here). Watch out for DELTA (Delta Encodings). Redshift does not support many Postgres functions, most notably several date/time-related and aggregation functions. See the full list here. Uniqueness, primary key, and foreign key constraints on Redshift tables are informational only and are not enforced. They are, however, used by the query optimizer to generate query plans. NOT NULL column constraints are enforced. See here for more information on defining constraints. Compression on sort key can result in significant performance impact. So if your Redshift queries involving sort key(s) are slow, you might want to consider removing compression on a sort key. Choosing a sort key is very important since you can not change a tables sort key after it is created. If you need to change the sort or distribution key of a table, you need to create a new table with the new key and move your data into it with a query like insert into new_table select * from old_table. When moving data with a query that looks like insert into x select from y, you need to have twice as much disk space available as table y takes up on the clusters disks. Redshift first copies the data to disk and then to the new table. Here is a good article on how to this for big tables. EMR EMR Basics Homepage Release guide FAQ Pricing EMR (which used to stand for Elastic Map Reduce, but not anymore, since it now extends beyond map-reduce) is a service that offers managed deployment of Hadoop, HBase and Spark. It reduces the management burden of setting up and maintaining these services yourself. Back to top :arrow_up: EMR Alternatives and Lock-in Most of EMR is based on open source technology that you can in principle deploy yourself. However, the job workflows and much other tooling is AWS-specific. Migrating from EMR to your own clusters is possible but not always trivial. Back to top :arrow_up: EMR Tips EMR relies on many versions of Hadoop and other supporting software. Be sure to check which versions are in use. Off-the-shelf EMR and Hadoop can have significant overhead when compared with efficient processing on a single machine. If your data is small and performance matters, you may wish to consider alternatives, as this post illustrates. Python programmers may want to take a look at Yelps mrjob. It takes time to tune performance of EMR jobs, which is why third-party services such as Quboles data service are gaining popularity as ways to improve performance or reduce costs. Back to top :arrow_up: EMR Gotchas and Limitations EMR costs can pile up quickly since it involves lots of instances, efficiency can be poor depending on cluster configuration and choice of workload, and accidents like hung jobs are costly. See the section on EC2 cost management, especially the tips there about Spot instances. This blog post has additional tips, but was written prior to the shift to per-second billing. Beware of double-dipping. With EMR, you pay for the EC2 capacity and the service fees. In addition, EMR syncs task logs to S3, which means you pay for the storage and PUT requests at S3 standard rates. While the log files tend to be relatively small, every Hadoop job, depending on the size, generates thousands of log files that can quickly add up to thousands of dollars on the AWS bill. YARNs log aggregation is not available on EMR. Kinesis Streams Kinesis Streams Basics Homepage Developer guide FAQ Pricing Kinesis Streams (which used to be only called Kinesis, before Kinesis Firehose and Kinesis Analytics were launched) is a service that allows you to ingest high-throughput data streams for immediate or delayed processing by other AWS services. Kinesis Streams subcomponents are called shards. Each shard provides 1MB/s of write capacity and 2MB/s of read capacity at a maximum of 5 reads per second. A stream can have its shards programmatically increased or decreased based on a variety of metrics. All records entered into a Kinesis Stream are assigned a unique sequence number as they are captured. The records in a Stream are ordered by this number, so any time-ordering is preserved. This page summarizes key terms and concepts for Kinesis Streams. Back to top :arrow_up: Kinesis Streams Alternatives and Lock-in Kinesis is most closely compared to Apache Kafka, an open-source data ingestion solution. It is possible to set up a Kafka cluster hosted on EC2 instances (or any other VPS), however you are responsible for managing and maintaining both Zookeeper and the Kafka brokers in a highly available configuration. Confluent has a good blog post with their recommendations on how to do this here, which has links on the bottom to several other blogs they have written on the subject. Kinesis uses very AWS-specific APIs, so you should be aware of the potential future costs of migrating away from it, should you choose to use it. An application that efficiently uses Kinesis Streams will scale the number of shards up and down based on the required streaming capacity. (Note there is no direct equivalent to this with Apache Kafka.) Back to top :arrow_up: Kinesis Streams Tips The KCL (Kinesis Client Library) provides a skeleton interface for Java, Node, Python, Ruby and .NET programs to easily consume data from a Kinesis Stream. In order to start consuming data from a Stream, you only need to provide a config file to point at the correct Kinesis Stream, and functions for initialising the consumer, processing the records, and shutting down the consumer within the skeletons provided. The KCL uses a DynamoDB table to keep track of which records have been processed by the KCL. This ensures that all records are processed at least once. It is up to the developer to ensure that the program can handle doubly-processed records. The KCL also uses DynamoDB to keep track of other KCL workers. It automatically shares the available Kinesis Shards across all the workers as equally as possible. Back to top :arrow_up: Kinesis Streams Gotchas and Limitations Kinesis Streams shards each only permit 5 reads per second. If you are evenly distributing data across many shards, your read limit for the Stream will remain at 5 reads per second on aggregate, as each consuming application will need to check every single shard for new records. This puts a hard limit on the number of different consuming applications possible per Stream for a given maximum read latency. For example, if you have 5 consuming applications reading data from one Stream with any number of shards, they cannot read with a latency of less than one second, as each of the 5 consumers will need to poll each shard every second, reaching the cap of 5 reads per second per shard. This blog post further discusses the performance and limitations of Kinesis in production. Kinesis Streams are not included in the free tier. Make sure if you do any experimentation with it on a personal account, you shut down the stream or it may run up unexpected costs (~$11 per shard-month.) Kinesis Firehose Back to top :arrow_up: Kinesis Firehose Gotchas and Limitations When delivering from Firehose to Elasticsearch, the JSON document cannot contain an _id property. Firehose will not attempt to deliver those documents and won't log any error. Device Farm Device Farm Basics Homepage Developer guide FAQ Pricing Device Farm is an AWS service that enables mobile app testing on real devices. Supports iOS and Android (including Kindle Fire) devices, as well as the mobile web. Supports remote device access in order to allow for interactive testing/debugging. Back to top :arrow_up: Device Farm Tips AWS Mobile blog contains several examples of Device Farm usage for testing. Device Farm offers a free trial for users who want to evaluate their service. Device Farm offers two pricing models: Paying per device minute is useful for small usage levels or for situations where its hard to predict usage amount. Unmetered plans are useful in situations where active usage is expected from the beginning. To minimize waiting time for device availability, one approach is to create several device pools with different devices, then randomly choose one of the unused device pools on every run. Back to top :arrow_up: Device Farm Gotchas and Limitations Devices don't have a SIM card and therefore cant be used for testing SIM card-related features. Device Farm supports testing for most popular languages/frameworks, but not for all. An actual list of supported frameworks and languages is presented on this page. The API and CLI for Device Farm is quite a low level and may require developing additional tools or scripts on top of it. AWS provide several tools and plugins for Device Farm, however, it doesnt cover all cases or platforms. It may require developing specific tools or plugins to support specific requirements. In general, Device Farm doesnt have Android devices from Chinese companies like Huawei, Meizu, Lenovo, etc. An actual list of supported devices located here. Device availibility is uneven. It depends on several factors including device popularity. Usually, more modern devices see higher demand, thus the waiting time for them will be higher compared to relatively old devices. Mobile Hub Mobile Hub Basics Homepage User guide FAQ Pricing Mobile Hub orchestrates multiple services to create an AWS backend for mobile and web applications. Each project in Mobile Hub has one backend made up of configurable features, plus one or more applications. Features include Analytics, Cloud Logic, Conversational Bots, Hosting and Streaming, NoSQL Database, User Data Storage and User Sign-In. Each feature uses one or two services to deliver a chunk of functionality. Services used include API Gateway, CloudFront, Cognito, Device Farm, DynamoDB, Lambda, Lex, Pinpoint and S3. Application SDKs exist for Android (Java), iOS (Swift), Web (JS) and React Native (JS). There is also a CLI for JavaScript applications. Back to top :arrow_up: Mobile Hub Tips The Mobile Hub console has starter kits and tutorials for various app platforms. The CLI allows local development of Lambda code (JS by default) with awsmobile {pull|push} commands, to sync from cloud to folder, and back again. Mobile Hub itself is free, but each of the services has its own pricing model. Back to top :arrow_up: Mobile Hub Gotchas and Limitations The Cloud API feature allows importing an existing Lambda function instead of defining a new one, but there are some rough edges with the CLI. Check the GitHub issues. Mobile Hub uses CloudFormation under the covers, and gets confused when a service is changed outside of the Mobile Hub console. IoT IoT Basics Homepage User guide FAQ Pricing IoT is a platform for allowing clients such as IoT devices or software applications (examples) to communicate with the AWS cloud. Clients are also called devices (or things) and include a wide variety of device types. Roughly there are three categories of device types that interact with IoT services by sending message over an IoT protocol to the IoT Pub/Sub-style message broker, which is called the IoT Device Gateway: Send messages only: For example, the AWS IoT Button on an eddystone beacon. Send, receive, and process messages: For example, a simple processing board, such as a Raspberry Pi (quick start guide), or an Alexa device, such as the Echo or Echo Dot. These are designed to work with the Alexa skills kit, a programmable voice-enabled service. AWS has a useful quick-start (using the Console) and a slide presentation on core topics. IoT terms: AWS IoT Things (metadata for devices in a registry) and can store device state in a JSON document, which is called a device shadow. Device metadata can also be stored in IoT Thing Types. This aids in device metadata management by allowing for reuse of device description and configuration for more than one device. Note that IoT Thing Types can be deprecated, but not changed they are immutable. AWS IoT Certificates (device authentication) are the logical association of a unique certificate to the logical representation of a device. This association can be done in the Console. In addition, the public key of the certificate must be copied to the physical device. This covers the authentication of devices to a particular AWS Device Gateway (or message broker). You can associate an AWS IoT certificate with an IoT device or you can register your own CA (Certificate Authority) with AWS, generate your own certificate(s) and associate those certificates with your devices via the AWS Console or cli. AWS IoT Policies (device/topic authorization) are JSON files that are associated to one or more AWS IoT certificates. This authorizes associated devices to publish and/or subscribe to messages from one or more MQTT topics. AWS IoT Rules are SQL-like queries which allows for reuse of some or all device message data, as described in this presentation, which summarizes design patterns with for IoT Rules. Shown below is a diagram which summarizes the flow of messages between the AWS IoT services: Back to top :arrow_up: IoT Greengrass Homepage Greengrass is a software platform that extends AWS IoT capabilities allowing Lambda functions to be run directly on local devices. It also enables IoT devices to be able to securely communicate on a local network without having to connect to the cloud. Greengrass includes a local pub/sub message manager that can buffer messages if connectivity is lost so that inbound and outbound messages to the cloud are preserved. Locally deployed Lambda functions can be triggered by local events, messages from the cloud, or other sources. Greengrass includes secure authentication and authorization of devices within the local network and also between the local network and the AWS cloud. It also provides secure, over-the-air software updates of Lambda functions. Greengrass core software includes a message manager object, Lambda runtime, local copy service for IoT Thing (or device) shadows, and a deployment agent to manage Greengrass group configuration. Greengrass groups are containers for selected IoT devices settings, subscriptions and associated Lambda functions. In a Greengrass group a device is either a Greengrass core or an IoT device which will be connected that particular Greengrass core. The Greengrass core SDK enables Lambda functions to interact with the AWS Greengrass core on which they run in order to publish messages, interact with the local Thing Shadows service, or invoke other deployed Lambda functions. The AWS Greengrass Core SDK only supports sending MQTT messages with QoS = 0. Shown below is a diagram which shows the architecture of AWS IoT Greengrass services: Back to top :arrow_up: IoT Alternatives and Lock-in AWS, Microsoft and Google have all introduced IoT-specific sets of cloud services since late 2015. AWS was first, moving their IoT services to general availability in Dec 2015. Microsoft released their set of IoT services for Azure in Feb 2016. Google has only previewed, but not released their IoT services Android Things and Weave. Issues of lock-in center around your devices protocols (for example MQTT, AMQP), message formats (such as, JSON vs. Hex...) and security (certificates). Back to top :arrow_up: IoT Tips Getting started with Buttons: One way to start is to use an AWS IoT Button. AWS provides a number of code samples for use with their IoT Button, you can use the AWS IoT console, click the connect AWS IoT button link and you'll be taken to the AWS Lambda console. There you fill out your buttons serial number to associate it with a Lambda. (As of this writing, AWS IoT buttons are only available for sale in the US.) Connections and protocols: It is important to understand the details of about the devices you wish to connect to the AWS IoT service, including how you will secure the device connections, the device protocols, and more. Cloud vendors differ significantly in their support for common IoT protocols, such as MQTT, AMQP, XMPP. AWS IoT supports secure MQTT, WebSockets and HTTPS. Support for device security via certificate processing is a key differentiator in this space. In August 2016, AWS added just-in-time registrations for IoT devices to their services. Combining with other services: Its common to use other AWS services, such as AWS Lambda, Kinesis and DynamoDB, although this is by no means required. Sample IoT application reference architectures are in this screencast. Testing tools: To get started, AWS includes a lightweight MQTT client in the AWS IoT console. Here you can create and test sending and receiving messages to and from various MQTT topics. When testing locally, if using MQTT, it may be helpful to download and use the open source Mosquitto broker tool for local testing with devices and/or device simulators Use this MQTT load simulator to test device message load throughout your IoT solution. Back to top :arrow_up: IoT Gotchas and Limitations IoT protocols: It is important to verify the exact type of support for your particular IoT device message protocol. For example, one commonly used IoT protocol is MQTT. Within MQTT there are three possible levels of QoS in MQTT. AWS IoT supports MQTT QoS 0 (fire and forget, or at most once) and QoS 1(at least once, or includes confirmation), but not QoS 2 (exactly once, requires 4-step confirmation). This is important in understanding how much code youll need to write for your particular application message resolution needs. Here is a presentation about the nuances of connecting. The ecosystems to match IAM users or roles to IoT policies and their associated authorized AWS IoT devices are immature. Custom coding to enforce your security requirements is common. A common mistake is to misunderstand the importance of IoT device security. It is imperative to associate each device with a unique certificate (public key). You can generate your own certificates and upload them to AWS, or you can use AWS generated IoT device certificates. Its best to read and understand AWSs own guidance on this topic. There is only one AWS IoT Gateway (endpoint) per AWS account. For production scenarios, youll probably need to set up multiple AWS accounts in order to separate device traffic for development, test and production. Its interesting to note that the Azure IoT Gateway supports configuration of multiple endpoints, so that a single Azure account can be used with separate pub/sub endpoints for development, testing and production Limits: Be aware of limits, including device message size, type, frequency, and number of AWS IoT rules. Back to top :arrow_up: IoT Code Samples Simple Beer Service is a surprisingly useful code example using AWS IoT, Lambda, etc. IoT-elf offers clean Python sample using the AWS IoT SDK. IoT Button projects on Hackster include many different code samples for projects. 5 IoT code examples: a device simulator, MQTT sample, just in time registration, truck simulator, prediction data simulator. AWS Alexa trivia voice example is a quick-start using Alexa voice capability and Lambda. Some Raspberry Pi examples include the Beacon project, Danbo, and GoPiGo. SES SES Basics Homepage Documentation FAQ Pricing SES (or Simple Email Service) is a service that exposes SMTP endpoints for your application to directly integrate with. Back to top :arrow_up: SES Tips Bounce Handling: Make sure you handle this early enough. Your ability to send emails can be removed if SES sees too many bounces. Credentials: Many developers get confused between SES credentials and AWS API keys. Make sure to enter SMTP credentials while using the SMTP APIs. Back to top :arrow_up: SES Gotchas and Limitations Internet Access: SES SMTP endpoints are on the Internet and will not be accessible from a location without Internet access (e.g. a private subnet without NAT gateway route in the routing table). In such a case, set up an SMTP relay instance in a subnet with Internet access and configure your application to send emails to this SMTP relay instance rather than SES. The relay should have a forwarding rule to send all emails to SES). If you are using a proxy instead of a NAT, confirm that your proxy service supports SMTP. Certificate Manager Certificate Manager Basics Homepage User guide FAQ Pricing Use the Certificate Manager to manage SSL/TLS certificates in other AWS services. Supports importing existing certificates as well as issuing new ones. Provides Domain Validated (DV) certificates. Validation can be done in two ways. The first (and recommended) way is via DNS. If the zone lives within Route 53 and the user has access, the necessary record can be added in the console via a single click during the certificate request process. If the zone is not within Route 53 the user is required to update DNS manually. This is still preferred to the second way, which requires more user interaction, and is done by sending an email to 3 contact addresses in WHOIS and 5 common addresses for the domain, for each domain name present in the request. ACM will attempt to automatically renew a certificate issued by Amazon. It will first attempt to connect to the domain on HTTPS and check that the certificate used by the domain is the same with the certificate that it intends to renew. Failing that, it will check the DNS record used previously for validation. Failing that, ACM will attempt manual validation by sending emails to all domains in the certificate. Back to top :arrow_up: Certificate Manager Alternatives and Lock-in Certificates issued by the Certificate Manager cant be used outside of the services that support it. Imported certificates, however, can still be used elsewhere. Back to top :arrow_up: Certificate Manager Tips Supported services: Managed Load Balancers, CloudFront, API Gateway and Elastic Beanstalk. During the domain validation process, if DNS validation is unsuccessful Certificate Manager will send an email to every contact address specified in the domains WHOIS record and up to five common administrative addresses. Some anti-spam filters can mark emails as spam because of this. You should check the spam folder of your email if you dont receive a confirmation email. Setting up a certificate for a test domain you don't have email set up on? You can now use DNS validation instead. Remember when requesting a wildcard domain that the request will not be valid for the level just below the wildcard, or any subdomains preceding the wildcard. Take for example an approved, issued certificate for *.bar.example.com. This would be valid for foo.bar.example.com but not bar.example.com. Likewise it would also not be valid for www.bar.foo.example.com. You would need to add each of these domains to the certificate request. Back to top :arrow_up: Certificate Manager Gotchas and Limitations In order to use Certificate Manager for CloudFront distributions, the certificate must be issued or imported from us-east-1 (N. Virginia) region. Certificates used with Elastic Load Balancers must be issued in the same region as the load balancer. Certificates can not be moved or copied between regions, as of July 2017. If a domain uses load balancers present in multiple regions, a different certificate must be requested for each region. IoT has its own way of setting up certificates. By default the maximum number of domains per certificate is 10. You can get this limit increased to a maximum of 100 by contacting AWS support. Note for every different domain you have on the requested cert, you'll need to press accept on an email sent to that domain. For example if you request a cert with 42 different domains or sub domains, you'll need to press accept on 42 different links. If you request a limit increase to AWS support for this, they will respond to you asking to confirm this. Bypass this by saying in the body of your initial request: There is no way at the moment to add or remove a domain to/from an existing certificate. You must request a new certificate and re-approve it from each of the domains requested. WAF WAF Basics Homepage Documentation FAQ Pricing WAF (Web Application Firewall) is used in conjunction with the CloudFront and ALB services to inspect and block/allow web requests based on user-configurable conditions. HTTPS and HTTP requests are supported with this service. WAF's strength is in detecting malicious activity based on pattern-matching inputs for attacks such as SQL injections, XSS, etc. WAF supports inspection of requests received through both IPv6 and IPv4. Back to top :arrow_up: WAF Tips Getting a WAF API call history can be done through CloudTrail. This is enabled through the CloudTrail console. It's also possible to get full logs of all the web requests inspected Back to top :arrow_up: WAF Gotchas and Limitations As of May 2019, AWS WAF is available on Amazon CloudFront and in 12 commercial AWS regions: US East (N. Virginia), US East (Ohio), US West (Oregon), US West (N. California), EU (Ireland), EU (Frankfurt), EU (London), EU (Stockholm), Asia Pacific (Tokyo), Asia Pacific (Sydney), Asia Pacific (Singapore), and Asia Pacific (Seoul). OpsWorks OpsWorks Basics Homepage Documentation FAQ Pricing: Stacks, Chef Automate, Puppet Enterprise OpsWorks is a configuration management service that uses Chef or Puppet configuration management. It is broken out into three different services: OpsWorks Stacks: The service lets you configure and launch stacks specific to your application's needs, and allows you to automate application deployments. Chef runs can be performed manually via the Execute Cookbooks command, otherwise they are only run as part of lifecycle events. OpsWorks Stacks differs from standard configuration management services in that it also allows you to perform some infrastructure and application automation (such as creating Amazon EC2 instances and deploying applications via Chef cookbooks). OpsWorks for Chef Automate: This service launches a dedicated Chef Automate server in your account, which can be used to associate nodes, upload cookbook code, and configure systems. Automated patching, backups, OS updates, and minor Chef version upgrades are provided as part of the service. An AWS API is provided for associating/disassociating nodes. Chef runs can be scheduled on nodes using the chef-client cookbook. OpsWorks for Puppet Enterprise: This service launches a dedicated Puppet Master in your account, which can be used to associate nodes, upload modules, and configure systems. Automated patching, backups, OS updates, and minor Puppet version upgrades are provided as part of the service. An AWS API is provided for associating/disassociating nodes. By default, the Puppet agent will run automatically every 30 minutes on associated nodes. OpsWorks for Chef Automate and OpsWorks for Puppet Enterprise are strictly designed for configuration management, and do not provision infrastructure outside the Chef Server/Puppet Master that is created in our account. All three OpsWorks services support managing both Amazon EC2 and on-premises infrastructure, however the implementation details differ slightly. OpsWorks Stacks allows you to register instances and install the OpsWorks Agent to connect to your stack. OpsWorks for Chef Automate and OpsWorks for Puppet Enterprise allow you to associate new or existing infrastructure using either the opsworks-cm:AssociateNode API action or the vendor-supported method for associating nodes to Chef Server or Puppet Enterprise. Although OpsWorks will let you work with common Chef recipes or Puppet modules when creating your stacks, creating custom recipes will require familiarity with Chef or Puppet syntax. Chef/Puppet code is not supported as part of AWS Support. As of December 2016, OpsWorks Stacks supports Chef versions 12, 11.10.4, 11.4.4 and 0.9.15.5. As of December 2016, OpsWorks for Chef Automate uses Chef Server version 12.11.1 This is the current stable version of Chef. Berkshelfcan be used with Chef stacks of version 11.10 and later for managing cookbooks and their respective dependencies. However, on Chef 12.x stacks, Berkshelf must be installed by the stack administrator. Running your own Chef environment may be an alternative to consider - some considerations are listed in this Bitlancer article. Back to top :arrow_up: OpsWorks Alternatives and Lock-in Major competitors in Configuration Management include: Chef Puppet Ansible. Back to top :arrow_up: OpsWorks Tips OpsWorks Stacks and OpsWorks for Chef Automate use Chef cookbooks for configuration. Chef provides free training to learn syntax, best practices, etc. at https://learn.chef.io. OpsWorks for Puppet Enterprise uses Puppet manifests for configuration. Puppet provides a very useful learning VM for download at https://learn.puppet.com/. Back to top :arrow_up: OpsWorks Gotchas and Limitations OpsWorks Stacks is not available in the following regions: Montreal GovCloud Beijing OpsWorks for Chef Automate and OpsWorks for Puppet Enterprise are not available in the following regions: Montreal Sao Paulo GovCloud London Paris Seoul Mumbai Batch Batch Basics Homepage Documentation FAQ Pricing AWS Batch is a service that offers an environment to run batch computing jobs. The service dynamically provisions the optimal compute resources needed by the jobs based on their resource requirements, and can scale up to hundreds of thousands of jobs. These batch workloads have access to all other AWS services and features. AWS Batch, coupled with spot instances can help run the jobs when appropriate capacity is available, providing for optimal utilization of compute resources. The batch workloads are built as a Docker Image. These images can then pushed to the EC2 Container Registry (ECR), or any private repository that can be accessed from AWS. A Job Definition has the workload's Docker Image URI, and also lets the users specify the environment details like vCPUs, memory, volume mappings, environment variables, parameters, retry strategy, container properties, and the job's IAM role. The Compute Environments are EC2 clusters that provide the runtime for the batch workloads to execute in. AWS Batch provides managed, as well as unmanaged compute environments. The Managed Environments are provisioned and managed by AWS, while the Unmanaged Environments are managed by the customers. The Job Definitions are submitted to Job Queue(s) for execution. Each queue has a priority, and has at least one Compute Environment associated with it. AWS Batch uses ECS to execute the containerized jobs. Back to top :arrow_up: Batch Tips AWS Batch supports prioritization of jobs via the Job Queue Priority. Higher the number - higher the priority. AWS Batch supports launching the Compute Environment into specific VPC and subnets. A Compute Environment is same as an ECS Cluster. There is no additional cost for AWS Batch. You only pay the cost associated with the AWS Services being used - like EC2 Instances and any resources consumed by the batch jobs. Associate IAM Roles and policies with the Compute Environment to enable the containers access to other AWS resources. Use Unmanaged Compute Environments if you need specialized resources like Dedicated Hosts, or EFS. SQS SQS Basics Homepage Documentation FAQ Pricing SQS is a highly scalable, fully managed message queuing service from AWS. SQS supports the pull model, where the producers queue the messages, and the consumers pull messages off the queue. SQS provides a message visibility timeout, during which the message being processed will not be delivered to other consumers. If the consumer does not delete the message after processing, the message becomes available to other consumers upon reaching the message visibility timeout. This parameter is called VisibilityTimeout. Each message can have up to 10 custom fields, or attributes. SQS allows producers to set up to 15 minutes of delay before the messages are delivered to the consumers. This parameter is called DelaySeconds. There are two types of queues supported by SQS - Standard Queues Guarantee at least once delivery of the messages. Do not retain the order of delivery of the messages. FIFO Queues Guarantee only once delivery of the messages Guarantee the order of the delivery of the messages SQS supports fine grained access to various API calls and Queues via IAM policies. The messages that fail to process can be put in a dead letter queue. Back to top :arrow_up: SQS Alternatives and Lock-In Alternatives to SQS include Kafka, RabbitMQ, ActiveMQ and others. Google Cloud Platform has Pub/Sub, and Azure has Azure Queue Service. SQS vs SNS Back to top :arrow_up: SQS Tips SNS can be used in combination of SQS to build a fan out mechanism by having an SQS Queue subscribe to the SNS topic. SQS supports encryption using AWS KMS. Cloudwatch alarms can be creating using various SQS metrics to trigger autoscaling actions and/or notifications. Back to top :arrow_up: SQS Gotchas and Limitations SQS does not have a VPC endpoint (unlike S3 and DynamoDB), so SQS will need to be accessed using public SQS API endpoints. FIFO Queues are limited to 300 API calls per second. FIFO Queues cannot subscribe to an SNS topic. Standard Queues can deliver duplicate messages regardless of the visibility window. If only-once delivery is your only choice, then use FIFO queues, or build an additional layer to de-dupe the messages. You can send/receive messages in batch, however, there can only be maximum of 10 messages in a batch. SNS SNS Basics Homepage Documentation FAQ Pricing SNS (Simple Notification Service) is a pub/sub based, highly scalable, and fully managed messaging service that can also be used for mobile notifications. SNS can push the messages down to the subscribers via SMS, Email, SQS, and HTTP/S transport protocols. Producers publish messages to a SNS Topics, which can have many subscribers. Each subscription has an associated protocol, which is used to notify the subscriber. A copy of the message is sent to each subscriber using the associated protocol. SNS can also invoke lambda functions. Back to top :arrow_up: SNS Alternatives and Lock-In Popular alternatives to SNS are Kafka, Notification Hubs on Azure, and Pub/Sub on Google Cloud. SNS vs SQS: Both SNS and SQS are highly scalable, fully managed messaging services provided by AWS. SQS supports a pull model, while SNS supports a push model. Consumers have to pull messages from an SQS Queue, while they're pushed the message from an SNS Topic. An SQS message is intended to be processed by only one subscriber, while SNS topics can have many subscribers. After processing, the SQS message is deleted from the queue by the subscriber to avoid being re-processed. An SNS message is pushed to all subscribers of the topic at the same time, and is not available for deletion at the topic. SNS supports multiple transport protocols of delivery of the messages to the subscribers, while SQS subscribers have to pull the messages off the queue over HTTPS. Back to top :arrow_up: SNS Tips Fan-out architecture can be achieved by having multiple subscribers for a topic. This is particularly useful when events have to be fanned out to multiple, isolated systems. SNS topics can be used to power webhooks with backoff support to subscribers over HTTP/S. SQS queues can subscribe to SNS topics. SNS is used to manage notifications for other AWS services like Autoscaling Groups' notifications, CloudWatch Alarms, etc. SNS is frequently used as glue between disparate systems such as GitHub and AWS services. Back to top :arrow_up: SNS Gotchas and Limitations HTTP/S subscribers of SNS topics need to have public endpoints, as SNS does not support calling private endpoints (like those in a private subnet within a VPC). In a fan-out scenario, SSE-enabled SQS subscribers of an SNS topic will not receive the messages sent to the topic. High Availability This section covers tips and information on achieving high availability. High Availability Tips AWS offers two levels of redundancy, regions and availability zones (AZs). When used correctly, regions and zones do allow for high availability. You may want to use non-AWS providers for larger business risk mitigation (i.e. not tying your company to one vendor), but reliability of AWS across regions is very high. Multiple regions: Using multiple regions is complex, since its essentially like managing completely separate infrastructures. It is necessary for business-critical services with the highest levels of redundancy. However, for many applications (like your average consumer startup), deploying extensive redundancy across regions may be overkill. The High Scalability Blog has a good guide to help you understand when you need to scale an application to multiple regions. Multiple AZs: Using AZs wisely is the primary tool for high availability! A typical single-region high availability architecture would be to deploy in two or more availability zones, with load balancing in front, as in this AWS diagram. The bulk of outages in AWS services affect one zone only. There have been rare outages affecting multiple zones simultaneously (for example, the great EBS failure of 2011) but in general most customers outages are due to using only a single AZ for some infrastructure. Consequently, design your architecture to minimize the impact of AZ outages, especially single-zone outages. Deploy key infrastructure across at least two or three AZs. Replicating a single resource across more than three zones often wont make sense if you have other backup mechanisms in place, like S3 snapshots. A second or third AZ should significantly improve availability, but additional reliability of 4 or more AZs may not justify the costs or complexity (unless you have other reasons like capacity or Spot market prices). Watch out for cross-AZ traffic costs. This can be an unpleasant surprise in architectures with large volume of traffic crossing AZ boundaries. Deploy instances evenly across all available AZs, so that only a minimal fraction of your capacity is lost in case of an AZ outage. If your architecture has single points of failure, put all of them into a single AZ. This may seem counter-intuitive, but it minimizes the likelihood of any one SPOF to go down on an outage of a single AZ. EBS vs instance storage: For a number of years, EBSs had a poorer track record for availability than instance storage. For systems where individual instances can be killed and restarted easily, instance storage with sufficient redundancy could give higher availability overall. EBS has improved, and modern instance types (since 2015) are now EBS-only, so this approach, while helpful at one time, may be increasingly archaic. Be sure to use and understand CLBs/ALBs appropriately. Many outages are due to not using load balancers, or misunderstanding or misconfiguring them. Back to top :arrow_up: High Availability Gotchas and Limitations AZ naming differs from one customer account to the next. Your us-west-1a is not the same as another customers us-west-1a the letters are assigned to physical AZs randomly per account. This can also be a gotcha if you have multiple AWS accounts. Note that Zone IDs are consistent between accounts, and can be used to reliably align between AWS accounts. Cross-AZ traffic is not free. At large scale, the costs add up to a significant amount of money. If possible, optimize your traffic to stay within the same AZ as much as possible. Billing and Cost Management Billing and Cost Visibility AWS offers a free tier of service, that allows very limited usage of resources at no cost. For example, a micro instance and small amount of storage is available for no charge. Many services are only eligible for the free tier for the first twelve months that an account exists, but other services offer a free usage tier indefinitely. (If you have an old account but starting fresh, sign up for a new one to qualify for the free tier.) AWS Activate extends this to tens of thousands of dollars of free credits to startups in certain funds or accelerators. You can set billing alerts to be notified of unexpected costs, such as costs exceeding the free tier. You can set these in a granular way. AWS offers Cost Explorer, a tool to get better visibility into costs. Unfortunately, the AWS console and billing tools are rarely enough to give good visibility into costs. For large accounts, the AWS billing console can time out or be too slow to use. Tools: Enable billing reports and install an open source tool to help manage or monitor AWS resource utilization. Teevity Ice (originally written by Netflix) is probably the first one you should try. Check out docker-ice for a Dockerized version that eases installation. One challenge with Ice is that it doesnt cover amortized cost of reserved instances. Other tools include Security Monkey and Cloud Custodian. Use AWS Simple Monthly Calculator to get an estimate of usage charges for AWS services based on certain information you provide. Monthly charges will be based on your actual usage of AWS services, and may vary from the estimates the Calculator has provided. Third-party services: Several companies offer services designed to help you gain insights into expenses or lower your AWS bill, such as Cloudability, CloudHealth Technologies, and ParkMyCloud. Some of these charge a percentage of your bill, which may be expensive. See the market landscape. AWSs Trusted Advisor is another service that can help with cost concerns. Dont be shy about asking your account manager for guidance in reducing your bill. Its their job to keep you happily using AWS. Tagging for cost visibility: As the infrastructure grows, a key part of managing costs is understanding where they lie. Its strongly advisable to tag resources, and as complexity grows, group them effectively. If you set up billing allocation appropriately, you can then get visibility into expenses according to organization, product, individual engineer, or any other way that is helpful. If you need to do custom analysis of raw billing data or want to feed it to a third party cost analysis service, enable the detailed billing report feature. Multiple Amazon accounts can be linked for billing purposes using the Consolidated Billing feature. Large enterprises may need complex billing structures depending on ownership and approval processes. Multiple Amazon accounts can be managed centrally using AWS Organizations. Back to top :arrow_up: AWS Data Transfer Costs For deployments that involve significant network traffic, a large fraction of AWS expenses are around data transfer. Furthermore, costs of data transfer, within AZs, within regions, between regions, and into and out of AWS and the internet vary significantly depending on deployment choices. Some of the most common gotchas: AZ-to-AZ traffic: Note EC2 traffic between AZs is effectively the same as between regions. For example, deploying a Cassandra cluster across AZs is helpful for high availability, but can hurt on network costs. Using public IPs when not necessary: If you use an Elastic IP or public IP address of an EC2 instance, you will incur network costs, even if it is accessed locally within the AZ. Managed NAT Gateway data processing: Managed NAT Gateways are used to let traffic egress from private subnets--at a cost of 4.5 as a data processing fee layered on top of data transfer pricing. Past a certain point, running your own NAT instances becomes far more cost effective. Some services do cross-AZ traffic for free: Many AWS services you'd not consider on their own merits offer a hidden value of free cross-AZ data transfer. EFS, RDS, MSK, and others are examples of this. This figure gives an overview: Back to top :arrow_up: EC2 Cost Management With EC2, there is a trade-off between engineering effort (more analysis, more tools, more complex architectures) and spend rate on AWS. If your EC2 costs are small, many of the efforts here are not worth the engineering time required to make them work. But once you know your costs will be growing in excess of an engineers salary, serious investment is often worthwhile. Larger instances arent necessarily priced higher in the spot market therefore, you should look at the available options and determine which instances will be most cost effective for your jobs. See Bid Advisor. Spot instances: EC2 Spot instances are a way to get EC2 resources at significant discount often many times cheaper than standard on-demand prices if youre willing to accept the possibility that they be terminated with little to no warning. Use Spot instances for potentially very significant discounts whenever you can use resources that may be restarted and dont maintain long-term state. The huge savings that you can get with Spot come at the cost of a significant increase in complexity when provisioning and reasoning about the availability of compute capacity. Amazon maintains Spot prices at a market-driven fluctuating level, based on their inventory of unused capacity. Prices are typically low but can spike very high. See the price history to get a sense for this. You set a bid price high to indicate how high youre willing to pay, but you only pay the going rate, not the bid rate. If the market rate exceeds the bid, your instance may be terminated. Prices are per instance type and per availability zone. The same instance type may have wildly different price in different zones at the same time. Different instance types can have very different prices, even for similarly powered instance types in the same zone. Compare prices across instance types for better deals. Use Spot instances whenever possible. Setting a high bid price will assure your machines stay up the vast majority of the time, at a fraction of the price of normal instances. Get notified up to two minutes before price-triggered shutdown by polling your Spot instances metadata, or by watching for the termination CloudWatch event. Make sure your usage profile works well for Spot before investing heavily in tools to manage a particular configuration. Spot fleet: You can realize even bigger cost reductions at the same time as improvements to fleet stability relative to regular Spot usage by using Spot fleet to bid on instances across instance types, availability zones, and (through multiple Spot Fleet Requests) regions. Spot fleet targets maintaining a specified (and weighted-by-instance-type) total capacity across a cluster of servers. If the Spot price of one instance type and availability zone combination rises above the weighted bid, it will rotate running instances out and bring up new ones of another type and location up in order to maintain the target capacity without going over target cluster cost. Spot usage best practices: Application profiling: Profile your application to figure out its runtime characteristics. That would help give an understanding of the minimum cpu, memory, disk required. Having this information is critical before you try to optimize spot costs. Once you know the minimum application requirements, instead of resorting to fixed instance types, you can bid across a variety of instance types (that gives you higher chances of getting a spot instance to run your application).E.g., If you know that 4 cpu cores are enough for your job, you can choose any instance type that is equal or above 4 cores and that has the least Spot price based on history. This helps you bid for instances with greater discount (less demand at that point). Spot price monitoring and intelligence: Spot Instance prices fluctuate depending on instance types, time of day, region and availability zone. The AWS CLI tools and API allow you to describe Spot price metadata given time, instance type, and region/AZ. Based on history of Spot instance prices, you could potentially build a myriad of algorithms that would help you to pick an instance type in a way that optimizes cost, maximizes availability, or offers predictable performance. You can also track the number of times an instance of certain type got taken away (out bid) and plot that in graphite to improve your algorithm based on time of day. Spot machine resource utilization: For running spiky workloads (spark, map reduce jobs) that are schedule based and where failure is non critical, Spot instances become the perfect candidates. The time it takes to satisfy a Spot instance could vary between 2-10 mins depending on the type of instance and availability of machines in that AZ. If you are running an infrastructure with hundreds of jobs of spiky nature, it is advisable to start pooling instances to optimize for cost, performance and most importantly time to acquire an instance. Pooling implies creating and maintaining Spot instances so that they do not get terminated after use. This promotes re-use of Spot instances across jobs. This of course comes with the overhead of lifecycle management. Pooling has its own set of metrics that can be tracked to optimize resource utilization, efficiency and cost. Typical pooling implementations give anywhere between 45-60% cost optimizations and 40% reduction in spot instance creation time. An excellent example of Pooling implementation described by Netflix (part1, part2) Spot management gotchas Lifetime: There is no guarantee for the lifetime of a Spot instance. It is purely based on bidding. If anyone outbids your price, the instance is taken away. Spot is not suitable for time sensitive jobs that have strong SLA. Instances will fail based on demand for Spot at that time. AWS provides a two-minute warning before Amazon EC2 must terminate your Spot instance. API return data: - The Spot price API returns Spot prices of varying granularity depending on the time range specified in the api call.E.g If the last 10 min worth of history is requested, the data is more fine grained. If the last 2 day worth of history is requested, the data is more coarser. Do not assume you will get all the data points. There will be skipped intervals. Lifecycle management: Do not attempt any fancy Spot management unless absolutely necessary. If your entire usage is only a few machines and your cost is acceptable and your failure rate is lower, do not attempt to optimize. The pain for building/maintaining it is not worth just a few hundred dollar savings. Reserved Instances: allow you to get significant discounts on EC2 compute hours in return for a commitment to pay for instance hours of a specific instance type in a specific AWS region and availability zone for a pre-established time frame (1 or 3 years). Further discounts can be realized through partial or all upfront payment options. Consider using Reserved Instances when you can predict your longer-term compute needs and need a stronger guarantee of compute availability and continuity than the (typically cheaper) Spot market can provide. However be aware that if your architecture changes your computing needs may change as well so long term contracts can seem attractive but may turn out to be cumbersome. There are two types of Reserved Instances - Standard and Convertible. If you purchase excess Standard Reserved Instances, you may offer to sell back unused Reserved Instances via the Reserved Instance Marketplace, this allows you to potentially recoup the cost of unused EC2 compute instance hours by selling them to other AWS customers. Instance reservations are not tied to specific EC2 instances - they are applied at the billing level to eligible compute hours as they are consumed across all of the instances in an account. There have been scattered reports of Convertible RI purchases needing to be exercised in a block-- namely, if you buy five convertible RIs in one purchase, you can't convert just two of them. Reach out to your account manager for clarification if this may impact you. If you have multiple AWS accounts and have configured them to roll charges up to one account using the Consolidated Billing feature, you can expect unused Reserved Instance hours from one account to be applied to matching (region, availability zone, instance type) compute hours from another account. If you have multiple AWS accounts that are linked with Consolidated Billing, plan on using reservations, and want unused reservation capacity to be able to apply to compute hours from other accounts, youll need to create your instances in the availability zone with the same name across accounts. Keep in mind that when you have done this, your instances may not end up in the same physical data center across accounts - Amazon shuffles availability zones names across accounts in order to equalize resource utilization. Make use of dynamic Auto Scaling, where possible, in order to better match your cluster size (and cost) to the current resource requirements of your service. If you use RHEL instances and happen to have existing RHEL on-premise Red Hat subscriptions, then you can leverage Red Hat's Cloud Access program to migrate a portion of your on-premise subscriptions to AWS, and thereby saving on AWS charges for RHEL subscriptions. You can either use your own self-created RHEL AMI's or Red Hat provided Gold Images that will be added to your private AMI's once you sign up for Red Hat Cloud Access. Further Reading This section covers a few unusually useful or must know about resources or lists. AWS AWS In Plain English: A readable overview of all the AWS services. Awesome AWS: A curated list of AWS tools and software. AWS Tips I Wish I'd Known Before I Started: A list of tips from Rich Adams AWS Whitepapers: A list of technical AWS whitepapers, covering topics such as architecture, security and economics. Last Week in AWS: A weekly email newsletter covering the latest happenings in the AWS ecosystem. AWS Geek: A blog by AWS Community Hero Jerry Hargrove, with notes and hand-drawn diagrams about various AWS services. Books Amazon Web Services in Action AWS Lambda in Action Serverless Architectures on AWS Serverless Single Page Apps The Terraform Book AWS Scripted 2 book series Amazon Web Services For Dummies AWS System Administration Python and AWS Cookbook Resilience and Reliability on AWS AWS documentation as Kindle ebooks General references AWS Well Architected Framework Guide: Amazons own 56 page guide to operational excellence - guidelines and checklists to validate baseline security, reliability, performance (including high availability) and cost optimization practices. Awesome Microservices: A curated list of tools and technologies for microservice architectures. Worth browsing to learn about popular open source projects. Is it fast yet?: Ilya Grigoriks TLS performance overview High Performance Browser Networking: A full, modern book on web network performance; a presentation on the HTTP/2 portion is here. Disclaimer The authors and contributors to this content cannot guarantee the validity of the information found here. Please make sure that you understand that the information provided here is being provided freely, and that no kind of agreement or contract is created between you and any persons associated with this content or project. The authors and contributors do not assume and hereby disclaim any liability to any party for any loss, damage, or disruption caused by errors or omissions in the information contained in, associated with, or linked from this content, whether such errors or omissions result from negligence, accident, or any other cause. License This work is licensed under a Creative Commons Attribution-ShareAlike 4.0 International License.

 # # # # # # # # # # # # # # # # # # # #
 Repository: breach/breach_core, index: 897, word count: 14364 
 # # # # # # # # # # # # # # # # # # # #

:mortar_board: All things Vim! Chinese | Japanese | Portuguese | Russian | Vietnamese Licensed under CC BY-SA 4.0. Intro What is Vim? The Vim Philosophy First steps Minimal vimrc What kind of Vim am I running? Cheatsheets Basics Buffers, windows, tabs Active, loaded, listed, named buffers Argument list Mappings Mapleader Registers Ranges Marks Completion Motions, operators, text objects Autocmds Changelist, jumplist Undo tree Quickfix and location lists Macros Colorschemes Folding Sessions Locality Usage Getting help offline Getting help offline (alternative) Getting help online Autocmds in practice User events Nested autocmds Clipboard Clipboard usage (Windows, macOS) Clipboard usage (Linux, BSD, ...) Restore cursor position when opening file Temporary files Backup files Swap files Undo files Viminfo files Example configuration for temporary files Editing remote files Managing plugins Block insert Running external programs and using filters Cscope MatchIt True colors Tips Go to other end of selected text Saner behavior of n and N Saner command-line history Saner CTRL-L Disable audible and visual bells Quickly move current line Quickly add empty lines Quickly edit your macros Quickly jump to header or source file Quickly change font size in GUI Change cursor style dependent on mode Don't lose selection when shifting sidewards Reload a file on saving Smarter cursorline Faster keyword completion Cosmetic changes to colorschemes Commands :global and :vglobal - Execute a command on all matching lines. :normal and :execute - The scripting dream team. :redir and execute() - Capture command output. Debugging General tips Verbosity Profiling startup time Profiling at runtime Debugging Vim scripts Debugging syntax files Miscellaneous Additional resources Vim distributions Standard plugins Map CapsLock to Control Generating HTML from buffer Easter eggs Why hjkl for navigation? Common problems Editing small files is slow Editing huge files is slow Bracketed paste (or why do I have to set 'paste' all the time?) Delays when using escape key in terminal Function search undo Technical quirks Newline used for NUL Terminology Vim script? Vimscript? VimL? List of colorschemes List of plugins Intro What is Vim? Vim is a text editor with a long line of ancestors that goes back to qed. Bram Moolenaar released it in 1991. The project is hosted online at vim.org. Getting Vim: Use your favourite package manager or visit the download page from vim.org. Discussions and user questions are best done on the vim_use mailing list or using IRC (Freenode) in the #vim channel. Development happens on GitHub, discussions on the vim_dev mailing list. Read Why, oh WHY, do those #?@! nutheads use vi? to see common misconceptions about Vim explained. The Vim Philosophy Vim adheres to the modal editing philosophy. This means that it provides multiple modes and the meaning of keys changes according to the mode. You navigate files in normal mode, you insert text in insert mode, you select lines in visual mode, you access commands in command-line mode and so on. This might sound complicated at first, but has a huge advantage: you don't have to break your fingers by holding several keys at once, most of the time you simply press them one after the other. The more common the task, the fewer keys are needed. A related concept that works well with modal editing are operators and motions. Operators start a certain action, e.g. changing, removing, or selecting text. Afterwards you specify the region of text you want to act on using a motion. To change everything between parentheses, use ci( (read change inner parentheses). To remove an entire paragraph of text, use dap (read delete around paragraph). If you see advanced Vim users working, you'll notice that they speak the language of Vim as well as pianists handle their instruments. Complex operations are done using only a few key presses. They don't even think about it anymore as muscle memory took over already. This reduces cognitive load and helps to focus on the actual task. First steps Vim comes bundled with an interactive tutorial that teaches the most basic things you need to know about. You can start it from the shell: Don't be put off by how boring it looks like and work through the exercises. The editors or IDEs you used before were most probably all non-modal, so working by switching modes will seem awkward at first, but the more you use Vim, the more it becomes muscle memory. Vim was bolted on Stevie, a vi clone, and supports two operating modes: "compatible" and "nocompatible". Using Vim in compatible mode means using vi defaults for all options, opposed to Vim defaults. As long as you didn't create a user vimrc yet or started Vim with vim -N, compatible mode is assumed! Don't use Vim in compatible mode. Just don't. Next steps: Create your own vimrc. Have some cheatsheets ready for the first weeks. Read through the basics section to learn what is even possible. Learn on demand! You never finish learning Vim. If you encounter any problems, just look for it on the internet. Your problem was solved already. Vim comes with great documentation and knowing how to navigate it is a must: Getting help offline. Have a look at the additional resources. One last advice: Please learn how to use Vim properly before starting to add all kinds of hyped plugins that only implement features that Vim already supports natively. Minimal vimrc The user vimrc can be put into ~/.vimrc or for the sake of better separation into ~/.vim/vimrc. The latter makes it easy to put the entire configuration under version control and upload it to, let's say GitHub. You find many "minimal vimrcs" all over the net, and maybe my version isn't as minimal as it should be, but it provides a good set of sane settings that I deem to be useful for starting out. Eventually you have to read up on all the mentioned settings anyway and decide for yourself. :-) So here it is: minimal-vimrc In case you're interested, here's my vimrc. TIP: Most plugin authors maintain several plugins and also publish their vimrc on GitHub (often in a repository called "vim-config" or "dotfiles"), so whenever you find a plugin you like, look up its maintainer's GitHub page and look through the repositories. What kind of Vim am I running? Looking at :version will give you all the information you need to know about how the currently running Vim binary was compiled. The first line tells you when the binary was compiled and the version, e.g. 7.4. One of the next lines states Included patches: 1-1051, which is the patch level. Thus, your exact Vim version is 7.4.1051. Another line states something like Tiny version without GUI or Huge version with GUI. The obvious information from that is whether your Vim includes GUI support, e.g. for starting gvim from the shell or running :gui from Vim within a terminal emulator. The other important information is the Tiny and Huge. Vim distinguishes between feature sets called tiny, small, normal, big, and huge, all enabling different subsets of features. The majority of :version output is consumed by the feature list itself. +clipboard means the clipboard feature was compiled in, -clipboard means it wasn't compiled in. A few Vim features need to be compiled in for them to work. E.g. for :prof to work, you need a Vim with a huge feature set, because that set enables the +profile feature. If that's not the case and you installed Vim from a package manager, make sure to install a package called vim-x, vim-x11, vim-gtk, vim-gnome or similar, since these packages usually come with the huge feature set. You can also test for the version or features programmatically: Help: Cheatsheets http://people.csail.mit.edu/vgod/vim/vim-cheat-sheet-en.png https://cdn.shopify.com/s/files/1/0165/4168/files/preview.png http://michael.peopleofhonoronly.com/vim/vim_cheat_sheet_for_programmers_screen.png http://www.rosipov.com/images/posts/vim-movement-commands-cheatsheet.png Or quickly open a cheatsheet from within Vim: vim-cheat40. Basics Buffers, windows, tabs Vim is a text editor. Every time text is shown, the text is part of a buffer. Each file will be opened in its own buffer. Plugins show stuff in their own buffers etc. Buffers have many attributes, e.g. whether the text it contains is modifiable, or whether it is associated with a file and thus needs to be synchronized to disk on saving. Windows are viewports onto buffers. If you want to view several files at the same time or even different locations of the same file, you use windows. And please, please don't call them splits. You can split a window in two, but that doesn't make them splits. Windows can be split vertically or horizontally and the heights and widths of existing windows can be altered, too. Therefore, you can use whatever window layout you prefer. A tab page (or just tab) is a collection of windows. Thus, if you want to use multiple window layouts, use tabs. Putting it in a nutshell, if you start Vim without arguments, you'll have one tab page that holds one window that shows one buffer. By the way, the buffer list is global and you can access any buffer from any tab. Active, loaded, listed, named buffers Run Vim like this vim file1. The file's content will be loaded into a buffer. You have a loaded buffer now. The content of the buffer is only synchronized to disk (written back to the file) if you save it within Vim. Since the buffer is also shown in a window, it's also an active buffer. Now if you load another file via :e file2, file1 will become a hidden buffer and file2 the active one. Both buffers are also listed, thus they will get listed in the output of :ls. Plugin buffers or help buffers are often marked as unlisted, since they're not regular files you usually edit with a text editor. Listed and unlisted buffers can be shown via :ls!. Unnamed buffers, also often used by plugins, are buffers that don't have an associated filename. E.g. :enew will create an unnamed scratch buffer. Add some text and write it to disk via :w /tmp/foo, and it will become a named buffer. Argument list The global buffer list is a Vim thing. Before that, in vi, there only used to be the argument list, which is also available in Vim. Every filename given to Vim on the shell command-line, is remembered in the argument list. There can be multiple argument lists: by default all arguments are put into the global argument list, but you can use :arglocal to create a new argument list that is local to the window. List the current arguments with :args. Switch between files from the argument list with :next, :previous, :first, :last and friends. Alter it with :argadd, :argdelete or :args with a list of files. If you should prefer using the buffer or argument list for working with files is a matter of taste. My impression is that most people use the buffer list exclusively. Nevertheless, there is one huge use case for the argument list: batch processing via :argdo! A simple refactoring example: This replaces all occurrences of "foo" by "bar" in all C source and header files from the current directory and below. Help: :h argument-list Mappings You can define your own mappings with the :map family of commands. Each command of that family defines a mapping for a certain set of modes. Technically Vim comes with a whopping 12 modes, 6 of them can be mapped. Additionally, some commands act on multiple modes at once. | Recursive | Non-recursive | Unmap | Modes | |-----------|---------------|-----------|----------------------------------| | :map | :noremap | :unmap | normal, visual, operator-pending | | :nmap | :nnoremap | :nunmap | normal | | :xmap | :xnoremap | :xunmap | visual | | :cmap | :cnoremap | :cunmap | command-line | | :omap | :onoremap | :ounmap | operator-pending | | :imap | :inoremap | :iunmap | insert | E.g. this defines the mapping for normal mode only: Unmap it again by using :nunmap <space>. For a few more but rather uncommon modes (or combinations of them), see :h map-modes. So far, so good. There's only one problem that can be pretty confusing to beginners: :nmap is recursive! That is, the right-hand side takes other mappings into account. So you defined a mapping that simply echoes "Foo": But what if you want to map the default behavior of b (going one word back) to another key? If you hit a, we expect the cursor to go back a word, but instead "Foo" is printed in the command-line! Because the right-hand side, b, was mapped to another action already, namely :echo "Foo"<cr>. The proper way to resolve this problem is to use a non-recursive mapping instead: Rule of thumb: Always use non-recursive mappings unless recursing is actually desired. Look up your mappings by not giving a right-hand side. E.g. :nmap shows all normal mappings and :nmap <leader> shows all normal mappings that start with the mapleader. If you want to disable a standard mapping, map them to the special <nop> character, e.g. :noremap <left> <nop>. Help: :h key-notation :h mapping :h 05.3 Mapleader The mapleader is simply a placeholder than can be used with custom mappings and is set to \ by default. This mapping is triggered by \h. If you want to use <space>h instead: Moreover, there is <localleader> that is the local counterpart to <leader> and is supposed to be used for mappings that are local to the buffer, eg. filetype-specific plugins. It also defaults to \. Note: Set the mapleaders before mappings! All leader mappings that are in effect already, won't change just because the mapleader was changed. :nmap <leader> will show all normal mode leader mappings with the mapleader resolved already, so use it to double-check your mappings. See :h mapleader and :h maplocalleader for more. Registers Registers are slots that save text. Copying text into a register is called yanking and extracting text from a register is called pasting. Vim provides the following registers: | Type | Character | Filled by? | Readonly? | Contains text from? | |---------------------|------------------------|------------|-----------|---------------------| | Unnamed | " | vim | [ ] | Last yank or deletion. (d, c, s, x, y) | | Numbered | 0 to 9 | vim | [ ] | Register 0: Last yank. Register 1: Last deletion. Register 2: Second last deletion. And so on. Think of registers 1-9 as a read-only queue with 9 elements. | | Small delete | - | vim | [ ] | Last deletion that was less than one line. | | Named | a to z, A to Z | user | [ ] | If you yank to register a, you replace its text. If you yank to register A, you append to the text in register a. | | Read-only | :, ., % | vim | [x] | :: Last command, .: Last inserted text, %: Current filename. | | Alternate buffer | # | vim | [ ] | Most of the time the previously visited buffer of the current window. See :h alternate-file | | Expression | = | user | [ ] | Evaluation of the VimL expression that was yanked. E.g. do this in insert mode: <c-r>=5+5<cr> and "10" will be inserted in the buffer. | | Selection | +, * | vim | [ ] | * and + are the clipboard registers. | | Drop | ~ | vim | [x] | From last drag'n'drop. | | Black hole | _ | vim | [ ] | If you don't want any other registers implicitly affected. E.g. "_dd deletes the current line without affecting registers ", 1, +, *. | | Last search pattern | / | vim | [ ] | Last pattern used with /, ?, :global, etc. | Each register that is not readonly can be set by the user: Afterwards n would jump to the next occurrence of "register". There are numerous exceptions when registers get implicitly filled, so be sure to read :h registers. Yank with y and paste with p/P, but mind that Vim distinguishes between characterwise and linewise visual selections. See :h linewise. Example: linewise yy (or just Y) yanks the current line, move the cursor somewhere else, use p to paste below the current line P for pasting above it. Example: charwise Yank the first word with 0yw, move somewhere else, paste after the cursor on the current line with p and before the cursor with P. Example: explicit naming of register "aY yanks the current line into register a. Move to another line. "AY appends the current line to register a. I suggest playing around with all these registers a bit and constantly checking :reg, so you can see what's actually happening. Fun fact: In Emacs "yanking" stands for pasting (or reinserting previously killed text) not copying. Ranges Ranges are pretty easy to understand, but many Vimmers don't know about their full potential. Many commands take ranges. An address denotes a certain line. A range is either a single address or a pair of addresses separated by either , or ;. Ranges tell commands which lines to act on. Most commands act only on the current line by default. Notable exceptions are :write and :global which act on all lines. The usage of ranges is pretty intuitive, so here are some examples (using :d as short form of :delete): | Command | Lines acted on | |---------|----------------| | :d | Current line. | | :.d | Current line. | | :1d | First line. | | :$d | Last line. | | :1,$d | All lines. | | :%d | All lines (syntactic sugar for 1,$). | | :.,5d | Current line to line 5. | | :,5d | Also current line to line 5. | | :,+3d | Current line and the next 3 lines. | | :1,+3d | First line to current line + 3. | | :,-3d | Current line and the last 3 lines. (Vim will prompt you, since this is a reversed range.) | | :3,'xdelete | Lines 3 to the line marked by mark x. | | :/^foo/,$delete | From the next line that starts with "foo" to the end. | | :/^foo/+1,$delete | From the line after the line that starts with "foo" to the end. | Note that instead of ,, ; can be used as a separator. The difference is that in the case of from,to, the to is relative to the current line, but when using from;to, the to is relative to the address of from! Assuming you're on line 5, :1,+1d would delete lines 1 to 6, whereas :1;+1d would only delete lines 1 and 2. The / address can be preceded with another address. This allows you to stack patterns, e.g.: This would delete the first line containing "quux" after the first line containing "bar" after the first line containing "foo" after the current line. Sometimes Vim automatically prepends the command-line with a range. E.g. start a visual line selection with V, select some lines and type :. The command-line will be populated with the range '<,'>, which means the following command will use the previously selected lines as a range. (This is also why you sometimes see mappings like :vnoremap foo :<c-u>command. Here <c-u> is used to remove the range, because Vim will throw an error when giving a range to a command that doesn't support it.) Another example is using !! in normal mode. This will populate the command-line with :.!. If followed by an external program, that program's output would replace the current line. So you could replace the current paragraph with the output of ls by using :?^$?+1,/^$/-1!ls. Fancy! Help: Marks You use marks to remember a position, that is line number and column, in a file. | Marks | Set by.. | Usage | |-------|----------|-------| | a - z | User | Local to file, thus only valid within one file. Jumping to a lowercase mark, means jumping within the current file. | | A - Z | User | Global, thus valid between files. Also called file marks. Jumping to a file mark may switch to another buffer. | | 0 - 9 | viminfo | 0 is the position when the viminfo file was written last. In practice this means when the last Vim process ended. 1 is the position of when the second last Vim process ended and so on. | Put '/g' or `/g` in front of a mark to form a motion. Use mm to remember the current position with mark "m". Move around the file and then jump back via 'm (first non-blank) or `m (exact column). Lowercase marks will be remembered after exiting Vim, if you tell your viminfo file to do so, see :h viminfo-'. Use mM to remember the current position with file mark "M". Switch to another buffer and switch back via 'M or `M. Other motions include: | Motion | Jump to.. | |------------------|-----------| | '[, `[ | First line or character of previously changed or yanked text. | | '], `] | Last line or character of previously changed or yanked text. | | '<, `< | Beginning line or character of last visual selection. | | '>, `> | Ending line or character of last visual selection. | | '', | Position before the latest jump. | | '", `" | Position when last exiting the current buffer. | | '^, `^ | Position where last insertion stopped. | | '., `. | Position where last change was made. | | '(, `( | Start of current sentence. | | '), `) | End of current sentence. | | '{, `{ | Start of current paragraph. | | '}, `} | End of current paragraph. | Marks can also be used in a range. You probably saw this before and wondered what it means: Select some text in visual mode and do :, the command-line will be prepended with :'<,'>, which means the following command would get a range that denotes the visual selection. Use :marks to list all marks. Read everything in :h mark-motions. Completion Vim provides many kinds of insert mode completions. If there are multiple matches, a popup menu will let you navigate to the match of your choice. Typical kinds of completion are tags, functions from imported modules or libraries, file names, dictionary or simply words from the current buffer. Vim provides a mapping for each kind of completion and they all start with <c-x> (remember to use them in insert mode): | Mapping | Kind | Help | |---------|------|--------------| | <c-x><c-l> | whole lines | :h i^x^l | | <c-x><c-n> | keywords from current file | :h i^x^n | | <c-x><c-k> | keywords from 'dictionary' option | :h i^x^k | | <c-x><c-t> | keywords from 'thesaurus' option | :h i^x^t | | <c-x><c-i> | keywords from current and included files | :h i^x^i | | <c-x><c-]> | tags | :h i^x^] | | <c-x><c-f> | file names | :h i^x^f | | <c-x><c-d> | definitions or macros | :h i^x^d | | <c-x><c-v> | Vim commands | :h i^x^v | | <c-x><c-u> | user defined (as specified in 'completefunc') | :h i^x^u | | <c-x><c-o> | omni completion (as specified in 'omnifunc') | :h i^x^o | | <c-x>s | spelling suggestions | :h i^Xs | People might be confused about the difference between user defined completion and omni completion, but technically they do the same thing. They take a function that inspects the current position and return a list of suggestions. User defined completion is defined by the user for their own personal purposes. (Surprise!) It could be anything. Omni completion is meant for filetype-specific purposes, like completing struct members or class methods, and is often set by filetype plugins. Vim also allows for completing multiple kinds at once by setting the 'complete' option. By default that option includes quite a lot, so be sure to trim it to your taste. You can trigger this completion by using either <c-n> (next) and <c-p> (previous), which also happen to be the keys used for choosing entries in the popup menu. See :h i^n and :h 'complete' for more on this. Be sure to check out :h 'completeopt' for configuring the behaviour of the popup menu. The default is quite sane, but I prefer adding "noselect" as well. Help: Motions, operators, text objects Motions move the cursor. You all know h/j/k/l. Or w and b. Even / is a motion. They also take a count. 2?the<cr> jumps to the second last occurrence of "the". See :h navigation and everything below for all available motions. Operators act on a region of text, e.g. d, ~, gU, > to name just a few. They get used in two contexts, either in normal or visual mode. In normal mode, operators come first followed by a motion, e.g. >j. In visual mode, operators simply act on the selection, e.g. Vjd. Like motions, operators take a count, e.g. 2gUw makes the rest of the current word and the next one uppercase. Since motions and operators take counts, 2gU2w works just as well and executes gU2w twice. See :h operator for all available operators. Use :set tildeop to make ~ act as an operator. Text objects act on the surrounding area, opposed to motions that act into one direction. Actually they work on objects, e.g. a whole word, a whole sentence, everything between parentheses, and so on. Text objects can't be used to move the cursor in normal mode, because even the most-skilled cursors can't jump into two directions at the same time. It works in visual mode though, because then one side of the object is already selected and the cursor simply jumps to the other side. Text objects start with either i (think inner) or a (think around) followed by a character denoting the object. With i it only acts on the object itself, with a on the object plus trailing whitespace. E.g. diw deletes the current word and ci( changes everything between parentheses. Text objects take a count. Imagine ((( ))) and the cursor on or between the most inner parentheses, then d2a( will remove the 2 inner pairs of parentheses and everything in between. See :h text-objects for all available text objects. Autocmds You can trigger an action after many events in Vim, such as a buffer being saved or Vim having started up, by so-called autocmds. Vim relies extensively on autocmds. Don't believe me? Check :au, but don't let the output overwhelm you. These are all the autocmds that are in effect right now! See :h {event} for a quick overview of all available events and :h autocmd-events-abc for more details. A typical example would be filetype-specific settings: But how does a buffer even know that it contains Ruby code? Because another autocmd detected it as that and set the filetype accordingly which again triggered the FileType event. One of the first things everyone adds to their vimrc is filetype on. This simply means that filetype.vim is read at startup which sets autocmds for almost all filetypes under the sun. If you're brave enough, have a look at it: :e $VIMRUNTIME/filetype.vim. Search for "Ruby" and you'll find that Vim simply uses the file extension .rb to detect Ruby files: NOTE: Autocmds of the same event are executed in the order they were created. :au shows them in the correct order. The BufNewFile and BufRead events in this case are hardcoded in the C sources of Vim and get emitted every time you open a file via :e and similar commands. Afterwards all the hundreds of filetypes from filetype.vim are tested for. Putting it in a nutshell, Vim makes heavy use of events and autocmds but also exposes a clean interface to hook into that event-driven system for customization. Help: :h autocommand Changelist, jumplist The positions of the last 100 changes are kept in the changelist. Several small changes on the same line will be merged together, but the position will be that of the last change nevertheless (in case you added something in the middle of the line). Every time you jump, the position before the jump is remembered in the jumplist. A jumplist has up to 100 entries. Each window has its own jumplist. When you split a window, the jumplist is copied. A jump is one of the following commands: ', `, G, /, ?, n, N, %, (, ), [[, ]], {, }, :s, :tag, L, M, H and commands that start editing a new file. | List | List all entries | Go to older position | Go to newer position | |------------|------------------|----------------------|----------------------| | jumplist | :jumps | [count]<c-o> | [count]<c-i> | | changelist | :changes | [count]g; | [count]g, | When you list all entries, a marker > will be used to show the current position. Usually that will be below position 1, the latest position. If you want both lists to persist after restarting Vim, you need to use the viminfo file and :h viminfo-'. NOTE: The position before the latest jump is also kept as a mark and can be jumped to via or ''. Help: Undo tree The latest changes to the text state are remembered. You can use undo to revert changes and redo to reapply previously reverted changes. The important bit to understand it that the data structure holding recent changes is not a queue but a tree! Your changes are nodes in the tree and each (but the top node) has a parent node. Each node keeps information about the changed text and time. A branch is a series of nodes that starts from any node and goes up to the top node. New branches get created when you undo a change and then insert something else. Now you have 3 lines and the undo tree looks like this: The undo tree has 4 changes. The numbers represent the time the nodes were created. Now there are two ways to traverse this tree, let's call them branch-wise and time-wise. Undo (u) and redo (<c-r>) work branch-wise. They go up and down the current branch. u will revert the text state to the one of node "bar". Another u will revert the text state even further, to the one of node "foo". Now <c-r> goes back to the state of node "bar" and another <c-r> to the state of node "quux". (There's no way to reach node "baz" using branch-wise commands anymore.) Opposed to this, g- and g+ work time-wise. Thus, g- won't revert to the state of node "bar", like u does, but to the chronologically previous state, node "baz". Another g- would revert the state to the one of node "bar" and so on. Thus, g- and g+ simply go back and forth in time, respectively. | Command / Mapping | Action | |-------------------|--------| | [count]u, :undo [count] | Undo [count] changes. | | [count]<c-r>, :redo | Redo [count] changes. | | U | Undo all changes to the line of the latest change. | | [count]g-, :earlier [count]? | Go to older text state [count] times. The "?" can be either "s", "m", "h", "d", or "f". E.g. :earlier 2d goes to the text state from 2 days ago. :earlier 1f will go to the state of the latest file save. | | [count]g+, :later [count]? | Same as above, but other direction. | The undo tree is kept in memory and will be lost when Vim quits. See Undo files for how to enable persistent undo. If you're confused by the undo tree, undotree does a great job at visualizing it. Help: Quickfix and location lists The quickfix list is a data structure that holds file positions. Essentially, each entry in the quickfix list consists of a file path, a line number and optional column, and a description. Typical use cases are assembling compiler errors or results of a grep tool. Vim has a special type of buffer for showing the quickfix list: the quickfix buffer. Each line in the quickfix buffer shows one entry from the quickfix list. Usually you open a new window to display the quickfix list: the quickfix window. When that happens, the last window gets associated with the quickfix window. In the quickfix buffer <cr> opens the selected entry in the associated window and <c-w><cr> in a new window. The quickfix list was named after the "quick fix" feature from the Aztec C compiler. Actually there are two kinds of lists: quickfix and location lists. They behave almost the same, but have the follwing differences: There is only one quickfix list. There can be multiple location lists; one per window. They use slightly different commands for navigation. | Action | Quickfix | Location | |----------------|--------------|--------------| | open window | :copen | :lopen | | close window | :cclose | :lclose | | next entry | :cnext | :lnext | | previous entry | :cprevious | :lprevious | | first entry | :cfirst | :lfirst | | last entry | :clast | :llast | Mind that the quickfix and location windows don't need to be open for these commands to work. See :h quickfix for more information and a full list of commands. For conciseness, quickfix and location are often abbreviated as qf and loc respectively. Example: Let us use our good old friend grep for searching the files in the current directory recursively for a certain query and put the results in the quickfix list. Assuming any files contained the string "foo", it should be shown now in the quickfix window. Macros Vim allows recording typed characters into a register. It's a great way to automate certain tasks on the fly. (For more elaborate tasks, Vim scripting should be used instead.) Start recording by typing q followed by the register, e.g. q. (The command-line will signify this via "recording @q".) Stop recording by hitting q once again. Execute the macro via [count]@q. Repeat the last used macro via [count]@@. Example 1: Insert a line and repeat it 10 times: (The same could be done without macros: oabc<esc>10.) Example 2: For adding line numbers in front of all lines, start on the first line and add "1. " to it manually. Increment the number under the cursor by using <c-a>, displayed as ^A. Here we simply hope that the file doesn't contain more than 1000 lines when using 1000@q, but we can also use a recursive macro, which executes until the macro can't be applied to a line anymore: (The same could be done without macros: :%s/^/\=line('.') . '. ') Mind that I also show how to achieve the same without using macros, but this mostly works only for such simple examples. For more complex automation, macros are the bomb! Also see: Quickly edit your macros Help: Colorschemes Colorschemes are the way to style your Vim. Vim consists of many components and each of those can be customized with different colors for the foreground, background and a few other attributes like bold text etc. They can be set like this: This would paint the background of the editor red. See :h :highlight for more information. So, colorschemes are mostly collections of :highlight commands. Actually, most colorschemes are really 2 colorschemes! The example above sets colors via ctermbg and guibg. The former definition (cterm*) will only be used if Vim was started in a terminal emulator, e.g. xterm. The latter (gui*) will be used in graphical environments like gvim or MacVim. If you ever happen to use a colorscheme in terminal Vim and the colors don't look like the ones in the screenshot at all, chances are that the colorscheme only defines colors for the GUI. Conversely, if you use a graphical Vim (e.g. gvim or MacVim) and the colors look off, the colorscheme might only define colors for the terminal. The latter case can be "solved" by enabling true colors in Neovim or Vim 7.4.1830 and newer. This makes terminal Vim use the GUI definitions instead, but also requires the terminal emulator itself and all software in between (e.g. tmux) to be capable of handling true colors. (This gist gives a good overview about the topic.) Help: :h 'termguicolors' List of colorschemes Cosmetic changes to colorschemes Folding Every text (or source code) has a certain structure. If you have a structure, it means you have regions of logically separated text. Folding allows to "fold" such a region into a single line and displaying a short description. There are many commands that act on these regions called folds. Folds can be nested. Vim distinguishes between several types of fold methods: | 'foldmethod' | Usage | |--------------|-------| | diff | Used in diff windows to fold unchanged text. | | expr | Uses 'foldexpr' to basically create a new fold method. | | indent | Folds based on indentation. | | manual | Create folds yourself via zf, zF, and :fold. | | marker | Folds based on markers in the text (often in comments). | | syntax | Folds based on syntax, e.g. folding if blocks. | NOTE: Folding can be computationally intensive! If you experience any performance drawbacks (small delays when typing), have a look at FastFold, which prevents Vim from updating folds when it's not needed. Help: Sessions If you save a view (:h :mkview), the current state of the window (and options and mappings) gets saved for later use (:h :loadview). A session saves the views of all windows plus global settings. It basically makes a snapshot of your current Vim instance and saves it in a session file. Let me stress this: it saves the current state; everything done after saving a session won't be part of the session file. To "update" a session, simply write it out again. This makes it perfect for saving your projects and easy to switch between them. Try it right now! Open a few windows and tabs and do :mksession Foo.vim. If you omit the filename, Session.vim will be assumed. The file will be saved to the current working directory, check :pwd. Restart Vim and do :source Foo.vim and voil, the buffer list, window layout, mappings, working directory etc. should all be the same as before you saved the session. Do some more work and update the session by overwriting the already existing session file with :mksession! Foo.vim. Note that a session file is really just a collection of Vim commands that are supposed to restore a certain state of a Vim instance, so feel free to take a look at it: :vs Foo.vim. You can tell Vim what things to save in a session by setting 'sessionoptions'. For scripting purposes Vim keeps the name of the last sourced or written session in the internal variable v:this_session. Help: Locality Many of the concepts mentioned above also have local counterparts: | Global | Local | Scope | Help | |--------|-------|-------|------| | :set | :setlocal | buffer or window | :h local-options | | :map | :map <buffer> | buffer | :h :map-local | | :autocmd | :autocmd * <buffer> | buffer | :h autocmd-buflocal | | :cd | :lcd | window | :h :lcd | | <leader> | <localleader> | buffer | :h maplocalleader | Variables also have different scopes. Usage Getting help offline Vim comes with great documentation in the form of single text files with a special layout. Vim uses a system based on tags for accessing certain parts of those help files. First of all, read this: :help :help. This will open the file $VIMRUNTIME/doc/helphelp.txt in a new window and jump to the :help tag within that file. A few simple rules: options are enclosed in single quotes, e.g. :h 'textwidth' VimL functions end in (), e.g. :h reverse() commands start with :, e.g. :h :echo You can use <c-d> (this is ctrl+d) to list all tags that match the currently entered query. E.g. :h tab<c-d> will get you a list of all tags from tab over 'softtabstop' to setting-guitablabel. You want to list all VimL functions? Simple: :h ()<c-d>. You want to list all VimL functions that concern windows? :h win*()<c-d>. This quickly becomes second nature, but especially in the beginning, you sometimes don't know any part of the tag you are looking for. You can only imagine some keywords that could be involved. :helpgrep to the rescue! This will look for "backwards" in all documentation files and jump to the first match. The matches will be assembled in the quickfix list. Use :cn/:cp to jump to the next/previous match. Or use :copen to open the quickfix window, navigate to an entry and hit <cr> to jump to that match. See :h quickfix for the whole truth. Getting help offline (alternative) This list was compiled by @chrisbra, one of the most active Vim developers, and posted to vim_dev. It's reposted here with minor changes. If you know what you are looking for, it is usually easier to search for it using the help system, because the subjects follow a certain style guide. Also, the help has the advantage of belonging to your particular Vim version, so that obsolete topics or topics that have been added later won't turn up. Therefore, it is essential to learn the help system and the language it uses. Here are some examples (not necessarily complete and I might have forgotten something). Options are enclosed in single quotes. So you would use :h 'list' to go to the help topic for the list option. If you only know, you are looking for a certain option, you can also do :h options.txt to open the help page which describes all option handling and then you can search using regular expressions e.g. /width. Certain options have their own namespace, e.g. :h cpo-a, :h cpo-A, :h cpo-b, and so on. Normal mode commands are just that. Use :h gt to go to the help page for the "gt" command. Regexp items always start with "/", so :h /\+ takes you to the help item for the "+" quantifier in Vim regexes. If you need to know anything about regular expressions, start reading at :h pattern.txt. Key combinations. They usually start with a single letter indicating the mode for which they can be used. E.g. :h i_CTRL-X takes you to the family of CTRL-X commands for insert mode which can be used to auto complete different things. Note that certain keys will always be written the same, e.g. Control will always be CTRL. Note, for normal mode commands, the "n" is left away, e.g. :h CTRL-A. In contrast, :h c_CTRL-R will describe what CTRL-R does when entering commands in the command line and :h v_Ctrl-A talks about incrementing numbers in visual mode and :h g_CTRL-A talks about the g command (thus you have to press "g" then ). Here the "g" stand for the normal command "g" which always expect a second key before doing something similar to the commands starting with "z". Registers always start with "quote" so use :h quote to find out about the special ":" register. Vim script (VimL) is available at :h eval.txt. Certain aspects of the language are available at :h expr-X where 'X' is a single letter, e.g. :h expr-! will take you to the topic describing the '!' (Not) operator for VimL. Also important, see :h function-list to find a short description of all functions available. Mappings are talked about in the help page :h map.txt. Use :h mapmode-i to find out about the :imap command. Also use :map-topic to find out about certain subtopics particular for mappings (e.g. :h :map-local for buffer-local mappings or :h map_bar for how the '|' is handled in mappings. Command definitions are talked about at :h command-*, so use :h command-bar to find out about the '!' argument for custom commands. Window management commands always start with CTRL-W, so you find the corresponding help at :h CTRL-W_* (e.g. :h CTRL-W_p for switch to the previously accessed window). You can also access :h windows.txt and read your way through, if you are looking for window handling command. Ex commands always start with ":", so :h :s covers the ":s" command. Use CTRL-D after typing a topic and let Vim try to complete to all available topics. Use :helpgrep to search in all help pages (usually also includes help pages by installed plugins). See :h :helpgrep for how to use it. Once you have searched for a topic, all matches are available in the quickfix (or location) window which can be opened with :copen or :lopen. There you can also use / to further filter the matches. :h helphelp contains some information on how to use the help. The user manual. This describes help topics for beginners in a rather friendly way. Start at :h usr_toc.txt to find the table of content (as you might have guessed). Skimming over that help to find certain topics, .e.g you will find an entry "Digraphs" and "Entering special characters" in chapter 24 (so use :h usr_24.txt to go to that particular help page). Highlighting groups always start with hl-*. E.g. :h hl-WarningMsg talks about the "WarningMsg" highlighting group. Syntax highlighting is namespaced to ":syn-topic", e.g. :h :syn-conceal talks about the conceal argument for the :syn command. Quickfix commands usually start with ":c", while location list commands usually start with ":l". :h BufWinLeave talks about the BufWinLeave autocmd. Also, :h autocommands-events talks about all possible events. Startup arguments always start with "-", so :h -f takes you to the help of the "-f" command switch of Vim. Compiled extra features always start with "+", so :h +conceal talks about the conceal support. Error codes can be looked up directly in the help. :h E297 takes you exactly to the description of the error message. Sometimes however, those error codes are not described, but rather are listed at the Vim command that usually causes this. E.g. :h hE128 takes you directly to the :function command. Documentation for included syntax files is usually available at :h ft-*-syntax. E.g. :h ft-c-syntax talks about the C syntax file and the options it provides. Sometimes, additional sections for omni completion (:h ft-php-omni) or filetype plugins (:h ft-tex-plugin) are available. Also, a link to the user documentation (which describes certain commands more from a user perspective and less detailed) will be mentioned at the top of help pages if they are available. So :h pattern.txt mentions the user guide topics :h 03.9 and :h usr_27. Getting help online If you have an issue you can't resolve or are in need of general guidance, see the vim_use mailing list. Another great resource is using IRC. The channel #vim on Freenode is huge and usually full of helpful people. If you want to report a Vim bug, use the vim_dev mailing list. Autocmds in practice You can trigger any event right now: :doautocmd BufRead. User events Especially for plugins it's useful to create your own "User" events: Now users of your plugin can execute anything when Chibby finishes running: By the way, if there's no "catching" :autocmd, :doautocmd will output a pesky "No matching autocommands" message. That's why many plugins use silent doautocmd ... instead. But this has the disadvantage, that you can't simply use echo "foo" in the :autocmd, you have to use unsilent echo "foo" instead.. That's why it's better to check if there even is a receiving autocmd and not bothering emitting the event otherwise: Help: :h User Nested autocmds By default, autocmds do not nest! If an autocmd executes a command, which in turn would usually trigger another event, it won't happen. Let's say every time you start Vim, you want to automatically open your vimrc: When you now start Vim, it will open your vimrc, but the first thing you'll notice is that there won't be any highlighting although usually there would be. The problem is that :edit in your non-nested autocmd won't trigger the "BufRead" event, so the filetype never gets set to "vim" and $VIMRUNTIME/syntax/vim.vim never sourced. See :au BufRead *.vim. Use this instead: Help: :h autocmd-nested Clipboard Required features: +clipboard and optionally +xterm_clipboard if you want to use the 'clipboard' option on a Unix system with a Vim that doesn't have GUI support. Help: Also see: Bracketed paste (or why do I have to set 'paste' all the time?) Clipboard usage (Windows, macOS) Windows comes with a clipboard and macOS comes with a pasteboard. Both work like most users would expect them to work. You copy selected text with ctrl+c/cmd+c and paste them in another application with ctrl+v/cmd+v. Note that copied text is actually transferred to the clipboard, so you can close the application you copied from before pasting in another application without problems. Whenever this happens, the clipboard register * gets filled with the selection. From Vim use "*y and "*p to yank and paste from the clipboard respectively. If you don't even want to specify the * register all the time, put this in your vimrc: Usually all yank/delete/put operations fill the " register, now the * register is used for the same operations, therefore simply y and p will be enough. Let me repeat: Using the option above means that every yank/paste, even when only used in the same Vim window, will alter the clipboard. Decide for yourself if this is useful or not. If you're even too lazy to type y, you can send every visual selection to the clipboard by using these settings: Help: Clipboard usage (Linux, BSD, ...) If your OS uses X, things work a bit different. X implements the X Window System Protocol which happens to be at major version 11 since 1987, hence X is also often called X11. Prior, in X10, cut buffers were introduced that kind of worked like a clipboard as in copied text was actually held by X and it was accessible by all other applications. This mechanism still exists in X, but its use is deprecated now and most software doesn't use it anymore. Nowadays data is transferred between applications by the means of selections. From the 3 selection atoms defined, only 2 are used in practice: PRIMARY and CLIPBOARD. Selections work roughly like this: | Selection | When used? | How to paste? | How to access from Vim? | |-----------|------------|---------------|-------------------------| | PRIMARY | Selecting text | middle-click, shift+insert | * register | | CLIPBOARD | Selecting text and ctrl+c | ctrl+v | + register | NOTE: Selections (no, not even the CLIPBOARD selection) are never kept in the X server! Thus, you lose the data copied with ctrl+c when the application closes. Use "*p to paste the PRIMARY selection or "+y1G to yank the entire file to the CLIPBOARD selection. If you happen to access one of the two registers all the time, consider using: (The ^= is used to prepend to the default value, :h :set^=.) This will make all yank/delete/put operations use either * or + instead of the unnamed register ". Afterwards you can simply use y or p for accessing your chosen X selection. Help: Restore cursor position when opening file When you open a file, the cursor will be positioned at line 1, column 1. Fortunately the viminfo file remembers marks. The " mark contains the position in the buffer where you left off. Read: If the mark " contains a line number greater than line 1 but not greater than the last line in the file, jump to it. :h viminfo-' :h `quote :h g` Temporary files Backup files Before saving a file, Vim creates a backup file. If writing to disk was successful, the backup file will be deleted. With :set backup, the backup will persist. This means, the backup file will always have the same content as the original file before the most recent save. It's up to you to decide whether this is useful or not. You can disable backups entirely with :set nobackup nowritebackup, but you shouldn't need to nowadays. 'writebackup' is a security feature that makes sure that you don't lose the original file in case saving it should ever fail, no matter whether you keep the backup file afterwards or not. If you frequently use Vim to edit huge files, and you probably shouldn't, you can exclude those from backups with 'backupskip'. Vim knows different ways to create a backup: copying and renaming. Copying A full copy of the original file is created and used as backup. The original file gets emptied and then filled with the content of the Vim buffer. Renaming The original file is renamed to the backup file. The content of the Vim buffer gets written to a new file with the name of the original file. See :h 'backupcopy' for all the nitty-gritty details. Demo: :h backup :h write-fail Swap files When editing a file, unsaved changes get written to a swap file. Get the name of the current swap file with :swapname. Disable them with :set noswapfile. A swap file gets updated either all 200 characters or when nothing was typed for 4 seconds. They get deleted when you stop editing the file. You can change these numbers with :h 'updatecount' and :h 'updatetime'. If Vim gets killed (e.g. power outage), you lose all changes since the last time the file was written to disk, but the swap file won't be deleted. Now, if you edit the file again, Vim will offer the chance to recover the file from the swap file. When two people try to edit the same file, the second person will get a notice that the swap file already exists. It prevents people from trying to save different versions of a file. If you don't want that behaviour, see :h 'directory'. :h swap-file :h usr_11 Undo files The undo tree is kept in memory and will be lost when Vim quits. If you want it to persist, :set undofile. This will save the undo file for ~/foo.c in ~/foo.c.un~. :h 'undofile' :h undo-persistence Viminfo files When backup, swap, and undo files are all about text state, viminfo files are used for saving everything else that would otherwise be lost when quitting Vim. The viminfo file keeps histories (command line, search, input), registers, marks, buffer list, global variables etc. By default, the viminfo is written to ~/.viminfo. :h viminfo :h 'viminfo' Example configuration for temporary files Put all temporary files in their own directory under ~/.vim/files: Editing remote files Vim comes with the netrw plugin that enables editing remote files. Actually it transfers the remote file to a local temporary file via scp, opens a buffer using that file, and writes the changes back to the remote file on saving. This is extremely useful if you want to use your local configuration opposed to ssh'ing into a server and use whatever the admins want you to use. If you have a ~/.ssh/config set up already, this gets used automatically: Assuming the above content in ~/.ssh/config, this works just as well: Similar can be done with a ~/.netrc, see :h netrw-netrc. Make sure to read :h netrw-ssh-hack and :h g:netrw_ssh_cmd. Another possibility is using sshfs which uses FUSE to mount a remote filesystem into your local filesystem. Managing plugins Pathogen was the first popular tool for managing plugins. Actually it just adjusts the runtimepath (:h 'rtp') to include all the things put under a certain directory. You have to clone the repositories of the plugins there yourself. Real plugin managers expose commands that help you to install and update plugins from within Vim. List of plugin managers Block insert This is a technique to insert the same text on multiple consecutive lines at the same time. See this demo. Switch to visual block mode with <c-v>. Afterwards go down for a few lines. Hit I or A and start entering your text. It might be a bit confusing at first, but text is always entered for the current line and only after finishing the current insertion, the same text will be applied to all other lines of the prior visual selection. So a simple example is <c-v>3jItext<esc>. If you have lines of different length and want to append the same text right after the end of each line, do this: <c-v>3j$Atext<esc>. Sometime you need to place the cursor somewhere after the end of the current line. You can't do that by default, but you can set the virtualedit option: Afterwards $10l or 90| work even after the end of the line. See :h blockwise-examples for more info. It might seem complicated at first, but quickly becomes second nature. If you want to get real fancy, have a look at multiple-cursors. Running external programs and using filters Disclaimer: Vim is single-threaded, so running an external program in the foreground will block everything else. Sure, you can use one of Vim's programming interfaces, e.g. Lua, and use its thread support, but during that time the Vim process is blocked nevertheless. Neovim fixed that by adding a proper job API. (Apparently Bram is thinking about adding job control to Vim as well. If you have a very recent version, see :helpgrep startjob.) Use :! to start a job. If you want to list the files in the current working directory, use :!ls. Use | for piping in the shell as usual, e.g. :!ls -1 | sort | tail -n5. Without a range, the output of :! will be shown in a scrollable window. On the other hand, if a range is given, these lines will be filtered. This means they will be piped to the stdin of the filter program and after processing be replaced by the stdout of the filter. E.g. for prepending numbers to the next 5 lines, use this: :.,+4!nl -ba -w1 -s' ' Since manually adding the range is quite burdensome, Vim also provides some helpers for convenience. As always with ranges, you can also select lines in visual mode and then hit :. There's also an operator ! that takes a motion. E.g. !ip!sort will sort the lines of the current paragraph. A good use case for filtering is the Go programming language. The indentation is pretty opinionated, it even comes with a filter called gofmt for indenting Go source code properly. So plugins for Go often provide helper commands called :Fmt that basically do :%!gofmt, so they indent all lines in the file. People often use :r !prog to put the output of prog below the current line, which is fine for scripts, but when doing it on the fly, I find it easier to use !!ls instead, which replaces the current line. :h filter :h :read! Cscope Cscope does more things than ctags, but only supports C (and C++ and Java to some extent). Whereas a tags file only knows where a symbol was defined, a cscope database knows much more about your data: Where is this symbol defined? Where is this symbol used? What is this global symbol's definition? Where did this variable get its value? Where is this function in the source files? What functions call this function? What functions are called by this function? Where does the message "out of space" come from? Where is this source file in the directory structure? What files include this header file? 1. Build the database Do this in the root of your project: This will create 3 files: cscope{,.in,.po}.out in the current working directory. Think of them as your database. Unfortunately cscope only analyzes *.[c|h|y|l] files by default. If you want to use cscope for a Java project instead, do this: 2. Add the database Open a connection to your freshly built database: Verify that the connection was made: (Yes, you can add multiple connections.) 3. Query the database E.g. :cs find d foo will list all functions that are called by foo(...). | Kind | Explanation | |------|-------------| | s | symbol: find all references to the token | | g | global: find global definition(s) of the token | | c | calls: find all calls to the function | | t | text: find all instances of the text | | e | egrep: egrep search for the word | | f | file: open the filename | | i | includes: find files that include the filename | | d | depends: find functions called by this function | I suggest some convenience mappings e.g.: So, when :tag (or <c-]>) jumps to a definition from the tags file, :cstag does the same, but also takes connected cscope databases into account. The option 'cscopetag' makes :tag act like :cstag automatically. This is very convenient if you already have tag-related mappings. Help: :h cscope MatchIt Since Vim is written in C, a lot of features assume C-like syntax. By default, if your cursor is on { or #endif, you can use % to jump to the corresponding } or #ifdef respectively. Vim comes bundled with a plugin called matchit.vim which is not enabled by default. It makes % also cycle through HTML tags, if/else/endif constructs in VimL etc. and introduces a few new commands. Installation for Vim 8 Installation for Vim 7 and older Since the documentation of matchit is pretty extensive, I suggest also doing the following once: Small intro The plugin is ready to use now. See :h matchit-intro for the supported commands and :h matchit-languages for the supported languages. That said, it's easy to define your own matching pairs: Afterwards you can cycle through these 3 statements in any Python file by using % (forward) or g% (backward). Help: True colors Using true colors in a terminal emulator means being able to use 24 bits for RGB colors. That makes 16777216 (2^24) colors instead of the usual 256. As explained here, colorschemes can actually be two colorschemes by having definitions for terminals (xterm) and for GUIs (gvim). This made sense before terminal emulators learned about true colors. After :set termguicolors, Vim starts emitting escape sequences only understood by a terminal emulator that supports true colors. When your colors look weird, chances are your terminal emulator doesn't support true colors or your colorcheme has no GUI colors defined. Many people use the terminal multiplexer tmux which basically sits in between the terminal emulator and Vim. To make tmux forward the true color escape sequences emitted by Vim, you have to put the following in the user's .tmux.conf: The first line should be the same for most people and denotes the $TERM to be used within tmux. The second line adds the tmux-specific Tc (true color) capability to the other terminfo entries of xterm-256color. Obviously this assumes that the user is using TERM=xterm-256color outside of tmux. So, here is the checklist for enabling true colors: Read :h 'termguicolors'. Put set termguicolors in your vimrc. Make sure your colorscheme has color definitions for GUIs. (It should contain lines with guifg and guibg.) Make sure your terminal emulator of choice supports true colors. Using tmux? Configure it to add the Tc capability. A popular reference for colors in the terminal: https://gist.github.com/XVilka/8346728 Tips Go to other end of selected text o and O in a visual selection make the cursor go to the other end. Try with blockwise selection to see the difference. This is useful for quickly changing the size of the selected text. Saner behavior of n and N The direction of n and N depends on whether / or ? was used for searching forward or backward respectively. This is pretty confusing to me. If you want n to always search forward and N backward, use this: Saner command-line history If you're anything like me, you're used to going to next and previous items via <c-n> and <c-p> respectively. By default, this also works in the command-line and recalls older or more recent command-lines from history. So far, so good. But <up> and <down> are even smarter! They recall the command-line whose beginning matches the current command-line. E.g. :echo <up> may change to :echo "Vim rocks!". Of course, I don't want you to reach for the arrow keys: Here we also distinguish between command-line history and the wildmenu. See :h 'wildmenu'. I depend on this behaviour several times a day. Saner CTRL-L By default, <c-l> clears and redraws the screen (like :redraw!). The following mapping does the same, plus de-highlighting the matches found via /, ? etc., plus fixing syntax highlighting (sometimes Vim loses highlighting due to complex highlighting rules), plus force updating the syntax highlighting in diff mode: Disable audible and visual bells See Vim Wiki: Disable beeping. Quickly move current line Sometimes I need a quick way to move the current line above or below: These mappings also take a count, so 2]e moves the current line 2 lines below. Quickly add empty lines Now 5[<space> inserts 5 blank lines above the current line. Quickly edit your macros This is a real gem! The mapping takes a register (or * by default) and opens it in the cmdline-window. Hit <cr> when you're done editing for setting the register. I often use this to correct typos I did while recording a macro. Use it like this <leader>m or "q<leader>m. Notice the use of <c-r><c-r> to make sure that the <c-r> is inserted literally. See :h c_^R^R. Quickly jump to header or source file This technique can probably be applied to many filetypes. It sets file marks (see :h marks) when leaving a source or header file, so you can quickly jump back to the last accessed one by using 'C or 'H (see :h 'A). NOTE: The info is saved in the viminfo file, so make sure that :set viminfo? includes :h viminfo-'. Quickly change font size in GUI I think this was taken from tpope's config: Change cursor style dependent on mode I like to use a block cursor in normal mode, i-beam cursor in insert mode, and underline cursor in replace mode. This simply tells Vim to print a certain sequence of characters (escape sequence) when entering/leaving insert mode. The underlying terminal, or programs like tmux that sit between Vim and the terminal, will process and evaluate it. There's one drawback though: there are many terminal emulator implementations and not all use the same sequences for doing the same things. The sequences used above might not work with your implementation. Your implementation might not even support different cursor styles. Check the documentation. The example above works with iTerm2. Don't lose selection when shifting sidewards If you select one or more lines, you can use < and > for shifting them sidewards. Unfortunately you immediately lose the selection afterwards. You can use gv to reselect the last selection (see :h gv), thus you can work around it like this: Now you can use >>>>> on your visual selection without any problems. NOTE: The same can be achieved using ., which repeats the last change. Reload a file on saving Using autocmds you can do anything on saving a file, e.g. sourcing it in case of a dotfile or running a linter to check for syntactical errors in your source code. Smarter cursorline I love the cursorline, but I only want to use it in the current window and not when being in insert mode: Faster keyword completion The keyword completion (<c-n>/<c-p>) tries completing whatever is listed in the 'complete' option. By default, this also includes tags (which can be annoying) and scanning all included files (which can be very slow). If you can live without these things, disable them: Cosmetic changes to colorschemes Always use a dark gray statusline, no matter what colorscheme is chosen: This triggers every time you use :colorscheme .... If you want it to trigger only for a certain colorscheme: This triggers only for :colorscheme desert. Commands Useful commands that are good to know. Use :h :<command name> to learn more about them, e.g. :h :global. :global and :vglobal Execute a command on all matching lines. E.g. :global /regexp/ print will use :print on all lines that contain "regexp". Fun fact: You probably all know good old grep, the filter program written by Ken Thompson. What does it do? It prints all lines matching a certain regular expression! Now guess the short form of :global /regexp/ print? That's right! It's :g/re/p. Ken Thompson was inspired by vi's :global when he wrote grep. Despite its name, :global only acts on all lines by default, but it also takes a range. Assume you want use :delete on all lines from the current line to the next blank line (matched by the regular expression ^$) that contain "foo": For executing commands on all lines that do not match a given pattern, use :global! or its alias :vglobal (think inVerse) instead. :normal and :execute These commands are commonly used in Vim scripts. With :normal you can do normal mode mappings from the command-line. E.g. :normal! 4j will make the cursor go down 4 lines (without using any custom mapping for "j" due to the "!"). Mind that :normal also takes a range, so :%norm! Iabc would prepend "abc" to every line. With :execute you can mix commands with expressions. Assume you edit a C source file and want to switch to its header file: Both commands are often used together. Assume you want to make the cursor go down "n" lines: :redir and execute() Many commands print messages and :redir allows to redirect that output. You can redirect to files, registers or variables. In Vim 8 there is an even shorter way: Help: Debugging General tips If you encounter a strange behaviour, try reproducing it like this: This will start Vim without vimrc (thus default settings) and in nocompatible mode (which makes it use Vim defaults instead of vi defaults). (See :h --noplugin for other combinations of what to load at start.) If you can still reproduce it now, it's most likely a bug in Vim itself! Report it to the vim_dev mailing list. Most of the time the issue won't be resolved at this time and you'll have to further investigate. Plugins often introduce new/changed/faulty behaviour. E.g. if it happens on saving, check :verb au BufWritePost to get a list of potential culprits. If you're using a plugin manager, comment them out until you find the culprit. Issue is still not resolved? If it's not a plugin, it must be your other settings, so maybe your options or autocmds etc. Time to use binary search. Repeatedly split the search space in two until you find the culprit line. Due to the nature of binary division, it won't take many steps. In practice, it works like this: Put the :finish command in the middle of your vimrc. Vim will skip everything after it. If it still happens, the problem is in the active upper half. Move the :finish to the middle of that half. Otherwise, the issue is in the inactive lower half. Move the :finish to the middle of that half. And so on. Verbosity Another useful way for observing what Vim is currently doing is increasing the verbosity level. Currently Vim supports 9 different levels. See :h 'verbose' for the full list. This would show all the files that get sourced, e.g. the undo file or various plugins that act on saving. If you only want increase verbosity for a single command, there's also :verbose, which simply gets put in front of any other command. It takes the verbosity level as count and defaults to 1: It's very often used with its default verbosity level 1 to show where an option was set last: Naturally, the higher the verbosity level the more overwhelming the output. But fear no more, you can simply redirect the output to a file: You can also enable verbosity at starting time, with the -V option. It defaults to verbosity level 10. E.g. vim -V5. Profiling startup time Vim startup feels slow? Time to crunch some numbers: The first column is the most important as it shows the elapsed absolute time. If there is a big jump in time between two lines, the second line is either a very big file or a file with faulty VimL code that is worth investigating. Profiling at runtime Required feature: +profile Vim provides a built-in capability for profiling at runtime and is a great way to find slow code in your environment. The :profile command takes a bunch of sub-commands for specifying what to profile. If you want to profile everything, do this: :profile start /tmp/profile.log :profile file * :profile func * <do something in Vim> :qa Vim keeps the profiling information in memory and only writes it out to the logfile on exit. (Neovim has fixed this using :profile dump). Have a look at /tmp/profile.log. All code that was executed during profiling will be shown. Every line, how often it was executed and how much time it took. Jump to the bottom of the log. Here are two different sections FUNCTIONS SORTED ON TOTAL TIME and FUNCTIONS SORTED ON SELF TIME that are worth gold. At a quick glance you can see which functions are taking the longest. You can use :profile during startup as well: $ vim --cmd 'prof start prof.log | prof file * | prof func *' test.c :q $ tail -50 prof.log Debugging Vim scripts If you ever used a command-line debugger before, :debug will quickly feel familiar. Simply prepend :debug to any other command and you'll be put into debug mode. That is, the execution will stop at the first line about to be executed and that line will be displayed. See :h >cont and below for the 6 available debugger commands and note that, like in gdb and similar debuggers, you can also use their short forms: c, q, n, s, i, and f. Apart from that those, you're free to use any Vim command, e.g. :echo myvar, which gets executed in the context of the current position in the code. You basically get a REPL by simply using :debug 1. It would be a pain if you had to single-step through every single line, so of course we can define breakpoints, too. (Breakpoints are called breakpoints, because the execution stops when they're hit, thus you can simply skip code you're not interested in.) See :h :breakadd, :h :breakdel, and :h :breaklist for further details. Let's assume you want to know what code is run every time you save a file: As you can see, using <cr> will repeat the previous debugger command, s in this case. :debug can be used in combination with the verbose option. Debugging syntax files Syntax files are often the cause for slowdowns due to wrong and/or complex regular expressions. If the +profile feature is compiled in, Vim provides the super useful :syntime command. The output contains important metrics. E.g. you can see which regexp takes too long and should be optimized or which regexps are used all the time but never even match. See :h :syntime. Miscellaneous Additional resources | Resource | Description | |----------|-------------| | Seven habits of effective text editing | By Bram Moolenaar, the author of Vim. | | Seven habits of effective text editing 2.0 (PDF) | See above. | | IBM DeveloperWorks: Scripting the Vim editor | Five-part series on Vim scripting. | | Learn Vimscript the Hard Way | Develop a Vim plugin from scratch. | | Practical Vim (2nd Edition) | Hands down the best book about Vim. | | Why, oh WHY, do those #?@! nutheads use vi? | Common misconceptions explained. | | Your problem with Vim is that you don't grok vi | Concise, informative and correct. A real gem. | Screencasts vimcasts.org By wincent By Derek Wyatt Vim distributions Vim distributions are bundles of custom settings and plugins for Vim. More advanced users know how to configure their editor anyway, so distributions are mostly targeted at beginners. If you think about that, it's quite paradoxical though: Making it easier by adding even more things to learn about? I know that many people don't want to spend hours and hours on customizing an editor (and actually you never stop customizing your vimrc when you finally got hooked), but eventually you only get efficient in Vim when you take the time to learn it properly. Repeat after me: "A programmer should know their tools." Anyway, if you know what you're doing, you might draw some inspiration from looking at a few distributions: cream janus spacevim spf13 Standard plugins Many people are surprised by the fact that Vim comes with a handful of standard plugins. Some get loaded by default (:e $VIMRUNTIME/plugin) and some are not (:e $VIMRUNTIME/pack/dist/opt). Read :h pack-add on how to source the latter. Most of the plugins that get loaded by default will never get used, though. Disable them as you see fit. They will still be shown as sourced (:scriptnames), but only the first lines actually get read before Vim bails out. No further code (mappings, commands, logic) will be processed. | Plugin | Disable it using.. | Help | |------------|-------------------------------------|------| | 2html | let g:loaded_2html_plugin = 1 | :h 2html | | getscript | let g:loaded_getscriptPlugin = 1 | :h pi_getscript | | gzip | let g:loaded_gzip = 1 | :h pi_gzip | | logipat | let g:loaded_logipat = 1 | :h pi_logipat | | matchparen | let g:loaded_matchparen = 1 | :h pi_paren | | netrw | let g:loaded_netrwPlugin = 1 | :h pi_netrw | | rrhelper | let g:loaded_rrhelper = 1 | :e $VIMRUNTIME/plugin/rrhelper.vim | | spellfile | let g:loaded_spellfile_plugin = 1 | :h spellfile.vim | | tar | let g:loaded_tarPlugin = 1 | :h pi_tar | | vimball | let g:loaded_vimballPlugin = 1 | :h pi_vimball | | zip | let g:loaded_zipPlugin = 1 | :h pi_zip | Map CapsLock to Control CapsLock belongs to the most useless keys on your keyboard, but it's much easier to reach than the Control key, since it lies on your home row. Mapping CapsLock to Control is a great way to prevent or at least reduce RSI if you program a lot. Attention: When you get used to it, you can't live without it anymore. macOS: System Preferences -> Keyboard -> Keyboard Tab -> Modifier Keys. Change "CapsLock" to "Control". Linux: To change the keys in X, put this in your ~/.xmodmap: remove Lock = Caps_Lock keysym Caps_Lock = Control_L add Control = Control_L Afterwards source it via $ xmodmap ~/.xmodmap. An alternative would be using caps2esc or xcape. Windows: See superuser.com: Map Caps-Lock to Control in Windows 8.1. Generating HTML from buffer Generate HTML from any buffer using :TOhtml from the 2html standard plugin. The output can be used for printing or easy web publishing. The command creates a new buffer of the same name with .html appended. The colors are the same as seen in Vim. They depend on the colorscheme. The plugin knows several options to finetune the output, e.g. for setting the encoding and font. See :h :TOhtml. Easter eggs | Command | Message | |-----------|---------| | :Ni! | Do you demand a shrubbery? | | :h 'sm' | NOTE: Use of the short form is rated PG. | | :h 42 | What is the meaning of life, the universe and everything? Douglas Adams, the only person who knew what this question really was about is now dead, unfortunately. So now you might wonder what the meaning of death is... | | :h UserGettingBored | When the user presses the same key 42 times. Just kidding! :-) | | :h bar | Ceci n'est pas une pipe. | | :h holy-grail | You found it, Arthur! | | :h map-modes | :nunmap can also be used outside of a monastery. | | :help! | E478: Don't panic! (Glitch? When used in a help buffer (buftype=help) this works like :h help.txt instead.) | | :smile | Try it out yourself. ;-) Added in 7.4.1005. | | :hi! | Greetings, Vim user! | Why hjkl for navigation? When Bill Joy created vi, a predecessor of Vim, he did it on a ADM-3A which had no extra cursor buttons but used, you might already guessed it, hjkl instead. Keyboard layout: click This also shows why ~ is used to denote the home directory on Unix systems. Common problems Editing small files is slow There are two things which can have a huge impact on performance: Complex regular expressions. Particular the Ruby syntax file caused people to have slowdowns in the past. (Also see Debugging syntax files.) Screen redraws. Some features force all lines to redraw. | Typical culprit | Why? | Solution? | |-----------------|------|-----------| | :set cursorline | Causes all lines to redraw. | :set nocursorline | | :set cursorcolumn | Causes all lines to redraw. | :set nocursorcolumn | | :set relativenumber | Causes all lines to redraw. | :set norelativenumber | | :set foldmethod=syntax | If the syntax file is slow already, this makes it even worse. | :set foldmethod=manual, :set foldmethod=marker or FastFold | | :set synmaxcol=3000 | Due to internal representation, Vim has problems with long lines in general. Highlights columns till column 3000. | :set synmaxcol=200 | | matchparen.vim | Loaded by default. Uses regular expressions to find the accompanying parenthesis. | Disable plugin: :h matchparen | NOTE: You only need to do this if you experience actual performance drawbacks. In most cases using the things mentioned above is absolutely fine. Editing huge files is slow The biggest issue with big files is, that Vim reads the whole file at once. This is done due to how buffers are represented internally. (Discussion on vim_dev@) If you only want to read, tail hugefile | vim - is a good workaround. If you can live without syntax, settings and plugins for the moment: This should make navigation quite a lot faster, especially since no expensive regular expressions for syntax highlighting are used. You should also tell Vim not to use swapfiles and viminfo files to avoid long delays on writing: Putting it in a nutshell, try to avoid using Vim when intending to write really huge files. :\ Bracketed paste (or why do I have to set 'paste' all the time?) Bracketed paste mode allows terminal emulators to distinguish between typed text and pasted text. Did you ever tried pasting code into Vim and afterwards everything seemed messed up? This only happens if you paste via cmd+v, shift-insert, middle-click etc. because then you're just throwing text at the terminal emulator. Vim doesn't know that you just pasted the text, it thinks you're an extremely fast typist. Accordingly, it tries to indent the lines and fails. Obviously this is not an issue, if you paste using Vim's registers, e.g. "+p, because then Vim knows that you're actually pasting. To workaround this, you have to :set paste, so it gets pasted as-is. See :h 'paste' and :h 'pastetoggle'. If you're fed up with toggling 'paste' all the time, have a look at this fine plugin that does it for you: bracketed-paste. Additional read from the same author as the plugin: here. Neovim: Neovim tries to make all of this much more seamless and sets bracketed paste mode automatically if the terminal emulator supports it. Delays when using escape key in terminal If you live in the command-line, you probably use a so-called terminal emulator like xterm, gnome-terminal, iTerm2, etc. (opposed to a real terminal). Like their ancestors, terminal emulators use escape sequences (or control sequences) to control things like moving the cursor, changing text colors, etc. They're simply strings of ASCII characters starting with an escape character (displayed in caret notation as ^[). When such a string arrives, the terminal emulator looks up the accompanying action in the terminfo database. To make the problem clearer, I'll explain mapping timeouts first. They always happen when there's ambiguity between mappings: Both mappings work as expected, but when typing ,a, there will be a delay of 1 second, because Vim waits whether the user keys in another b or not. Escape sequences pose the same problem: <esc> is used a lot for returning to normal mode or quitting an action. Cursor keys are encoded using escape sequences. Vim expects Alt (also called Meta key) to send a proper 8-bit encoding with the high bit set, but many terminal emulators don't support it (or don't enable it by default) and send an escape sequence instead. You can test the above like this: vim -u NONE -N and type i<c-v><left> and you'll see a sequence inserted that starts with ^[ which denotes the escape character. Putting it in a nutshell, Vim has a hard time distinguishing between a typed <esc> character and a proper escape sequence. By default, Vim uses :set timeout timeoutlen=1000, so it delays on ambiguity of mappings and key codes by 1 second. This is a sane value for mappings, but you can define the key code timeout on its own which is the most common workaround for this entire issue: Under :h ttimeout you find a small table showing the relationship between these options. If you're using tmux between Vim and your terminal emulator, also put this in your ~/.tmux.conf: Function search undo A search pattern in a command (/, :substitute, ...) changes the "last used search pattern". (It's saved in the / register; print it with :echo @/). A simple text change can be redone with .. (It's saved in the . register; print it with :echo @.). Both things are not the case, if you do them from a function, though! Thus you can't easily highlight words from a function or redo the text changes made by it. Help: :h function-search-undo Technical quirks Newline used for NUL NUL characters (\0) in a file, are stored as newline (\n) in memory and displayed in a buffer as ^@. See man 7 ascii and :h NL-used-for-Nul for more information. Terminology Vim script? Vimscript? VimL? Vim script, Vimscript, and VimL all refer to the same thing: The programming language used for scripting Vim. Even though 8.0.360 changed all references from VimL to Vim script, which can now be considered the official term, VimL is still widespread all over the internet. No matter which term you use, everyone will understand it.

 # # # # # # # # # # # # # # # # # # # #
 Repository: evnaz/ENSwiftSideMenu, index: 4849, word count: 4128 
 # # # # # # # # # # # # # # # # # # # #

Infrared remote library for Arduino: send and receive infrared signals with multiple protocolsIRremote Arduino Library Available as Arduino library "IRremote" Version 3.3.1 - work in progress This library enables you to send and receive using infra-red signals on an Arduino. API A Doxygen documentation of the sources is available on the project homepage. Installation Click on the LibraryManager badge above to see the instructions. Supported IR Protocols Denon / Sharp, JVC, LG, NEC / Onkyo / Apple, Panasonic / Kaseikyo, RC5, RC6, Samsung, Sony, (Pronto), BoseWave, Lego, Whynter, MagiQuest. Protocols can be switched off and on by defining macros before the line #include <IRremote.h> like here: Wiki This is a quite old but maybe useful wiki for this library. Features of the 3.x version You can use any pin for sending now, like you are used with receiving. Simultaneous sending and receiving. See the UnitTest example. No more need to use 32 bit hex values in your code. Instead a (8 bit) command value is provided for decoding (as well as an 16 bit address and a protocol number). Protocol values comply to protocol standards, i.e. NEC, Panasonic, Sony, Samsung and JVC decode and send LSB first. Supports more protocols, since adding a protocol is quite easy now. Better documentation and more examples :-). Compatible with tone() library, see ReceiveDemo. Supports more platforms, since the new structure allows to easily add a new platform. Feedback LED also for sending. Ability to generate a non PWM signal to just simulate an active low receiver signal for direct connect to existent receiving devices without using IR. Easy configuration of protocols required, directly in your [source code[(https://github.com/Arduino-IRremote/Arduino-IRremote/blob/master/examples/SimpleReceiver/SimpleReceiver.ino#L18-L34). This reduces the memory footprint and increases decoding time. Converting your program to the 3.1 version This must be done also for all versions > 3.0.1 if USE_NO_SEND_PWM is defined. Starting with this version, the generation of PWM is done by software, thus saving the hardware timer and enabling arbitrary output pins. Therefore you must change all IrSender.begin(true); by IrSender.begin(IR_SEND_PIN, ENABLE_LED_FEEDBACK);. If you use a core that does not use the -flto flag for compile, you can activate the line #define SUPPRESS_ERROR_MESSAGE_FOR_BEGIN in IRRemote.h, if you get false error messages regarding begin() during compilation. Converting your 2.x program to the 3.x version Now there is an IRreceiver and IRsender object like the well known Arduino Serial object. Just remove the line IRrecv IrReceiver(IR_RECEIVE_PIN); and/or IRsend IrSender; in your program, and replace all occurrences of IRrecv. or irrecv. with IrReceiver. Since the decoded values are now in IrReceiver.decodedIRData and not in results any more, remove the line decode_results results or similar. Like for the Serial object, call IrReceiver.begin(IR_RECEIVE_PIN, ENABE_ED_FEEDBACK); or IrReceiver.begin(IR_RECEIVE_PIN, DISABLE_LED_FEEDBACK); instead of the IrReceiver.enableIRIn(); or irrecv.enableIRIn(); in setup(). Old decode(decode_results *aResults) function is replaced by simple decode(). So if you have a statement if(irrecv.decode(&results)) replace it with if (IrReceiver.decode()). The decoded result is now in in IrReceiver.decodedIRData and not in results any more, therefore replace any occurrences of results.value and results.decode_type (and similar) to IrReceiver.decodedIRData.decodedRawData and IrReceiver.decodedIRData.protocol. Overflow, Repeat and other flags are now in IrReceiver.receivedIRData.flags. Seldom used: results.rawbuf and results.rawlen must be replaced by IrReceiver.decodedIRData.rawDataPtr->rawbuf and IrReceiver.decodedIRData.rawDataPtr->rawlen. Running your 2.x program with the 3.x library version If you program is like: it should run on the 3.1.1 version as before. The following decoders are available: Denon, JVC, LG, NEC, Panasonic, RC5, RC6, Samsung, Sony. The results.value is set by the decoders for NEC, Panasonic, Sony, Samsung and JVC as MSB first like in 2.x. - The old functions sendNEC() and sendJVC() are deprecated and renamed to sendNECMSB() and sendJVCMSB() to make it clearer that they send data with MSB first, which is not the standard for NEC and JVC. Use them to send your old MSB-first 32 bit IR data codes. In the new version you will send NEC commands not by 32 bit codes but by a (constant) 8 bit address and an 8 bit command. Convert old MSB first 32 bit IR data codes to new LSB first 32 bit IR data codes The new decoders for NEC, Panasonic, Sony, Samsung and JVC IrReceiver.decodedIRData.decodedRawData is now LSB-first, as the definition of these protocols suggests! To convert one into the other, you must reverse the byte positions and then reverse all bit positions of each byte or write it as one binary string and reverse/mirror it. Example: 0xCB340102 byte reverse -> 02 01 34 CB bit reverse-> 40 80 2C D3. 0xCB340102 is binary 11001011001101000000000100000010. 0x40802CD3 is binary 01000000100000000010110011010011. If you read the first binary sequence backwards (right to left), you get the second sequence. FAQ IR does not work right when I use Neopixels (aka WS2811/WS2812/WS2812B) or other libraries blocking interrupts for a longer time (> 50 us). Whether you use the Adafruit Neopixel lib, or FastLED, interrupts get disabled on many lower end CPUs like the basic Arduinos for longer than 50 s. In turn, this stops the IR interrupt handler from running when it needs to. There are some solutions to this on some processors, see this page from Marc MERLIN The default IR timer on AVR's is timer 2. Since the Arduino Tone library as well as analogWrite() for pin 3 and pin 11 requires timer 2, this functionality cannot be used simultaneously. You can use tone() but after the tone has stopped, you must call IrReceiver.start() or better IrReceiver.start(<microsecondsOfToneDuration>) to restore the timer settings for receive. Or you change the timer to timer 1 in private/IRTimer.cpp.h. If you can live with the NEC protocol, you can try the MinimalReceiver example, it requires no timer. You can use multiple IR receiver by just connecting the output pins of several IR receivers together. The IR receivers use an NPN transistor as output device with just a 30k resistor to VCC. This is almost "open collector" and allows connecting of several output pins to one Arduino input pin. The minimal CPU frequency for receiving is 4 MHz, since the 50 us timer ISR takes around 12 us on a 16 MHz ATmega. Minimal version For applications only requiring NEC protocol, there is a receiver which has very small codesize of 500 bytes and does NOT require any timer. See the MinimalReceiver and IRDispatcherDemo example how to use it. Mapping of pins to interrupts can be found here. Handling unknown Protocols Disclaimer This library was never designed to handle long codes like the ones used by air conditioners. See Recording long Infrared Remote control signals with Arduino. The main reason is, that it was designed to fit inside MCUs with relatively low levels of resources and was intended to work as a library together with other applications which also require some resources of the MCU to operate. Protocol=UNKNOWN If you see something like Protocol=UNKNOWN Hash=0x13BD886C 35 bits received as output of e.g. the ReceiveDemo example, you either have a problem with decoding a protocol, or an unsupported protocol. If you have an odd number of bits received, it is likely, that your receiver circuit has problems. Maybe because the IR signal is too weak. If you see timings like + 600,- 600 + 550,- 150 + 200,- 100 + 750,- 550 then one 450 s space was split into two 150 and 100 s spaces with a spike / error signal of 200 s between. Maybe because of a defective receiver or a weak signal in conjunction with another light emitting source nearby. If you see timings like + 500,- 550 + 450,- 550 + 500,- 500 + 500,-1550, then marks are generally shorter than spaces and therefore MARK_EXCESS_MICROS (specified in your ino file) should be negative to compensate for this at decoding. If you see Protocol=UNKNOWN Hash=0x0 1 bits received it may be that the space after the initial mark is longer than RECORD_GAP_MICROS. This was observed for some LG air conditioner protocols. Try again with a line e.g. #define RECORD_GAP_MICROS 12000 before the line #include <IRremote.h> in your ino file. To see more info supporting you to find the reason for your UNKNOWN protocol, you must enable the line //#define DEBUG in IRremoteInt.h. How to deal with protocols not supported by IRremote If you do not know which protocol your IR transmitter uses, you have several choices. - Use the IRreceiveDump example to dump out the IR timing. You can then reproduce/send this timing with the SendRawDemo example. For long codes with more than 48 bits like from air conditioners, you can change the length of the input buffer in IRremote.h. - The IRMP AllProtocol example prints the protocol and data for one of the 40 supported protocols. The same library can be used to send this codes. - If you have a bigger Arduino board at hand (> 100 kByte program space) you can try the IRremoteDecode example of the Arduino library DecodeIR. - Use IrScrutinizer. It can automatically generate a send sketch for your protocol by exporting as "Arduino Raw". It supports IRremote, the old IRLib and Infrared4Arduino. Hints To increase strength of sent output signal you can increase the current through the send diode, and/or use 2 diodes in series, since one IR diode requires only 1.5 volt. The line #include "ATtinySerialOut.h" in PinDefinitionsAndMore.h (requires the library to be installed) saves 370 bytes program space and 38 bytes RAM for Digispark boards as well as enables serial output at 8MHz. The default software generated PWM has problems on AVR running with 8 MHz. The PWM frequency is around 30 instead of 38 kHz and RC6 is not reliable. You can switch to timer PWM generation by #define SEND_PWM_BY_TIMER. Examples In order to fit the examples to the 8K flash of ATtiny85 and ATtiny88, the Arduino library ATtinySerialOut is required for this CPU's. SimpleReceiver + SimpleSender This examples are a good starting point. ReceiveDemo + SendDemo More complete examples for the advanced user. ReceiveAndSend + UnitTest ReceiveDemo + SendDemo in one program. Receiving while sending. ReceiveAndSend Record and play back last received IR signal at button press. MinimalReceiver + SmallReceiver If code size matters, look at these examples. IRDispatcherDemo Framework for calling different functions for different IR codes. IRrelay Control a relay (connected to an output pin) with your remote. IRremoteExtensionTest Example for a user defined class, which itself uses the IRrecv class from IRremote. Compile options / macros for this library To customize the library to different requirements, there are some compile options / macros available. Modify it by commenting them out or in, or change the values if applicable. Or define the macro with the -D compiler option for global compile (the latter is not possible with the Arduino IDE, so consider using Sloeber. | Name | File | Default value | Description | |-|-|-|-| | SEND_PWM_BY_TIMER | Before #include <IRremote.h> | disabled | Disable carrier PWM generation in software and use (restricted) hardware PWM except for ESP32 where both modes are using the flexible hw_timer_t. | | USE_NO_SEND_PWM | Before #include <IRremote.h> | disabled | Use no carrier PWM, just simulate an active low receiver signal. Overrides SEND_PWM_BY_TIMER definition. | | NO_LEGACY_COMPATIBILITY | IRremoteInt.h | disabled | Disables the old decoder for version 2.x compatibility, where all protocols -especially NEC, Panasonic, Sony, Samsung and JVC- were MSB first. Saves around 60 bytes program space and 14 bytes RAM. | | EXCLUDE_EXOTIC_PROTOCOLS | Before #include <IRremote.h> | disabled | If activated, BOSEWAVE, MAGIQUEST,WHYNTER and LEGO_PF are excluded in decode() and in sending with IrSender.write(). Saves up to 650 bytes program space. | | EXCLUDE_UNIVERSAL_PROTOCOLS | Before #include <IRremote.h> | disabled | If activated, the universal decoder for pulse width or pulse distance protocols and decodeHash (special decoder for all protocols) are excluded in decode(). Saves up to 1000 bytes program space. | | MARK_EXCESS_MICROS | Before #include <IRremote.h> | 20 | MARK_EXCESS_MICROS is subtracted from all marks and added to all spaces before decoding, to compensate for the signal forming of different IR receiver modules. | | RECORD_GAP_MICROS | Before #include <IRremote.h> | 5000 | Minimum gap between IR transmissions, to detect the end of a protocol.Must be greater than any space of a protocol e.g. the NEC header space of 4500 us.Must be smaller than any gap between a command and a repeat; e.g. the retransmission gap for Sony is around 24 ms.Keep in mind, that this is the delay between the end of the received command and the start of decoding. | | FEEDBACK_LED_IS_ACTIVE_LOW | Before #include <IRremote.h> | disabled | Required on some boards (like my BluePill and my ESP8266 board), where the feedback LED is active low. | | DISABLE_LED_FEEDBACK_FOR_RECEIVE | Before #include <IRremote.h> | disabled | This completely disables the LED feedback code for receive, thus saving around 108 bytes program space and halving the receiver ISR processing time. | | IR_INPUT_IS_ACTIVE_HIGH | Before #include <IRremote.h> | disabled | Enable it if you use a RF receiver, which has an active HIGH output signal. | | RAW_BUFFER_LENGTH | IRremoteInt.h | 101 | Buffer size of raw input buffer. Must be odd! | | DEBUG | IRremoteInt.h | disabled | Enables lots of lovely debug output. | | IR_SEND_DUTY_CYCLE | IRremoteInt.h | 30 | Duty cycle of IR send signal. | | MICROS_PER_TICK | IRremoteInt.h | 50 | Resolution of the raw input buffer data. | |-|-|-|-| | IR_INPUT_PIN | TinyIRReceiver.h | 2 | The pin number for TinyIRReceiver IR input, which gets compiled in. | | IR_FEEDBACK_LED_PIN | TinyIRReceiver.h | LED_BUILTIN | The pin number for TinyIRReceiver feedback LED, which gets compiled in. | | DO_NOT_USE_FEEDBACK_LED | TinyIRReceiver.h | disabled | Enable it to disable the feedback LED function. | Modifying compile options with Arduino IDE First, use Sketch > Show Sketch Folder (Ctrl+K). If you did not yet stored the example as your own sketch, then you are instantly in the right library folder. Otherwise you have to navigate to the parallel libraries folder and select the library you want to access. In both cases the library files itself are located in the src directory. Modifying compile options with Sloeber IDE If you are using Sloeber as your IDE, you can easily define global symbols with Properties > Arduino > CompileOptions. Supported Boards Arduino Uno / Mega / Leonardo / Duemilanove / Diecimila / LilyPad / Mini / Fio / Nano etc. Teensy 1.0 / 1.0++ / 2.0 / 2++ / 3.0 / 3.1 / Teensy-LC; Credits: PaulStoffregen (Teensy Team) Sanguino ATmega8, 48, 88, 168, 328 ATmega8535, 16, 32, 164, 324, 644, 1284, ATmega64, 128 ATmega4809 (Nano every) ATtiny84, 85 SAMD21 (DUE, Zero) ESP32 ESP8266. This fork supports an impressive set of protocols. Sparkfun Pro Micro Nano Every, Uno WiFi Rev2, nRF5 BBC MicroBit, Nano33_BLE We are open to suggestions for adding support to new boards, however we highly recommend you contact your supplier first and ask them to provide support from their side. Timer and pin usage The receiver sample interval is generated by a timer. On many boards this must be a hardware timer, on some a software timer is available and used. The code for the timer and the timer selection is located in private/IRTimer.cpp.h. Every pin can be used for receiving. The send PWM signal is by default generated by software. Therefore every pin can be used for sending. The PWM pulse length is guaranteed to be constant by using delayMicroseconds(). Take care not to generate interrupts during sending with software generated PWM, otherwise you will get jitter in the generated PWM. E.g. wait for a former Serial.print() statement to be finished by Serial.flush(). Since the Arduino micros() function has a resolution of 4 us at 16 MHz, we always see a small jitter in the signal, which seems to be OK for the receivers. | Software generated PWM showing small jitter because of the limited resolution of 4 us of the Arduino core micros() function for an ATmega328 | Detail (ATmega328 generated) showing 33% Duty cycle | |-|-| | | | Hardware-PWM signal generation for sending If you define SEND_PWM_BY_TIMER, the send PWM signal is generated by a hardware timer. The same timer as for the receiver is used. Since each hardware timer has its dedicated output pins, you must change timer to change PWN output. The timer and the pin usage can be adjusted in private/IRTimer.cpp.h | Board/CPU | Hardware-PWM Pin | Timers | |--------------------------------------------------------------------------|---------------------|-------------------| | ATtiny84 | 6 | 1 | | ATtiny85 > 4 MHz | 1, 4 | 0, 1 | | ATtiny1604 | PA05 | TCB0 | | ATmega8 | 9 | 1 | | ATmega48, ATmega88, ATmega168, ATmega328 | 3, 9 | 1, 2 | | ATmega1284 | 13, 14, 6 | 1, 2, 3 | | ATmega164, ATmega324, ATmega644 | 13, 14 | 1, 2 | | ATmega8535 ATmega16, ATmega32 | 13 | 1 | | ATmega64, ATmega128, ATmega1281, ATmega2561 | 13 | 1 | | ATmega8515, ATmega162 | 13 | 1 | | ATmega1280, ATmega2560 | 5, 6, 9, 11, 46 | 1, 2, 3, 4, 5 | | ATmega4809 | A4 | TCB0 | | Leonardo (Atmega32u4) | 5, 9, 13 | 1, 3, 4_HS | | Zero (SAMD) | *, 9 | TC3 | | ESP32 | 4, all pins | 1 | | Sparkfun Pro Micro | 5, 9 | 1, 3 | | Teensy 1.0 | 17 | 1 | | Teensy 2.0 | 9, 10, 14 | 1, 3, 4_HS | | Teensy++ 1.0 / 2.0 | 1, 16, 25 | 1, 2, 3 | | Teensy 3.0 / 3.1 | 5 | CMT | | Teensy-LC | 16 | TPM1 | Adding new protocols To add a new protocol is quite straightforward. Best is too look at the existing protocols to find a similar one and modify it. As a rule of thumb, it is easier to work with a description of the protocol rather than trying to entirely reverse-engineer the protocol. Please include a link to the description in the header, if you found one. The durations you receive are likely to be longer for marks and shorter for spaces than the protocol suggests, but this depends on the receiver circuit in use. Most protocols use multiples of one time-unit for marks and spaces like e.g. NEC. It's easy to be off-by-one with the last bit, since the last space is not recorded by IRremote. Try to make use of the template functions decodePulseDistanceData() and sendPulseDistanceData(). If your protocol supports address and code fields, try to reflect this in your api like it is done in sendNEC(uint16_t aAddress, uint8_t aCommand, uint_fast8_t aNumberOfRepeats, bool aIsRepeat) and decodeNEC(). Integration To integrate your protocol, you need to extend the two functions decode() and getProtocolString() in IRreceice.cpp, add macros and function declarations for sending and receiving and extend the enum decode_type_t in IRremote.h. And at least it would be wonderful if you can provide an example how to use the new protocol. A detailed description can be found in the ir_Template.cpp file. NEC encoding 8 bit address NEC code 16 bit address NEC code Revision History Please see changelog.md. API documentation See API reference in wiki. To generate the API documentation, Doxygen, as well as Graphviz should be installed. (Note that on Windows, it is useful to specify the installer to add Graphviz to PATH or to do it manually. With Doxygen and Graphviz installed, issue the command doxygen from the command line in the main project directory, which will generate the API documentation in HTML format. The just generated docs/index.html can now be opened in a browser. Why do we use 33% duty cycle We do it according to the statement in the Vishay datasheet: - Carrier duty cycle 50 %, peak current of emitter IF = 200 mA, the resulting transmission distance is 25 m. - Carrier duty cycle 10 %, peak current of emitter IF = 800 mA, the resulting transmission distance is 29 m. - Factor 1.16 The reason is, that it is not the pure energy of the fundamental which is responsible for the receiver to detect a signal. Due to automatic gain control and other bias effects high intensity and lower energy (duty cycle) of the 38 kHz pulse counts more than high low intensity and higher energy. BTW, the best way to increase the IR power is to use 2 or 3 IR diodes in series. One diode requires 1.1 to 1.5 volt so you can supply 3 diodes with a 5 volt output. To keep the current, you must reduce the resistor by (5 - 1.3) / (5 - 2.6) = 1.5 e.g. from 150 ohm to 100 ohm for 25 mA and 2 diodes with 1.3 volt and a 5 volt supply. For 3 diodes it requires factor 2.5 e.g. from 150 ohm to 60 ohm. Quick comparison of 4 Arduino IR receiving libraries Here you find an ESP8266/ESP32 version of IRremote with an impressive list of supported protocols. This is a short comparison and may not be complete or correct I created this comparison matrix for myself in order to choose a small IR lib for my project and to have a quick overview, when to choose which library. It is dated from 03.02.2021. If you have complains about the data or request for extensions, please send a PM or open a discussion. | Subject | IRMP | IRLremote | IRLib2mostly unmaintained | IRremote | Minimal NEC | |---------|------|-----------|--------|----------|----------| | Number of protocols | 50 | Nec + Panasonic + Hash * | 12 + Hash * | 17 + Hash * | NEC | | 3.Party libs needed| % | PinChangeInterrupt if not pin 2 or 3 | % | % | % | | Timing method receive | Timer2 or interrupt for pin 2 or 3 | Interrupt | Timer2 or interrupt for pin 2 or 3 | Timer2 or interrupt for NEC | Interrupt | | Timing method send | PWM and timing with Timer2 interrupts | Timer2 interrupts | Timer2 and blocking wait | PWM with Timer2 and blocking wait with delayMicroseconds() | % | | Send pins| All | All | All ? | Timer dependent | % | | Decode method | OnTheFly | OnTheFly | RAM | RAM | OnTheFly | | Encode method | OnTheFly | OnTheFly | OnTheFly | OnTheFly or RAM | % | | Callback suppport | x | % | % | % | x | | Repeat handling | Receive + Send (partially) | % | ? | Receive + Send | x | | LED feedback | x | % | x | x | x | | FLASH usage (simple NEC example with 5 prints) | 1820(4300 for 15 main / 8000 for all 40 protocols)(+200 for callback)(+80 for interrupt at pin 2+3)| 1270(1400 for pin 2+3) | 4830 | 1770 | 900 | | RAM usage | 52(73 / 100 for 15 (main) / 40 protocols) | 62 | 334 | 227 | 19 | | Supported platforms | avr, megaAVR, attiny, Digispark (Pro), esp8266, ESP32, STM32, SAMD 21, Apollo3(plus arm and pic for non Arduino IDE) | avr, esp8266 | avr, SAMD 21, SAMD 51 | avr, attiny, esp8266, esp32, SAM, SAMD | All platforms with attachInterrupt() | | Last library update | 2/2021 | 4/2018 | 9/2019 | 2/2021 | 2/2021 | | Remarks | Decodes 40 protocols concurrently.39 Protocols to send.Work in progress. | Only one protocol at a time. | Consists of 5 libraries. Project containing bugs - 45 issues, no reaction for at least one year. | Decoding and sending are easy to extend.Supports Pronto codes. | Requires no timer. | * The Hash protocol gives you a hash as code, which may be sufficient to distinguish your keys on the remote, but may not work with some protocols like Mitsubishi Contributing If you want to contribute to this project: - Report bugs and errors - Ask for enhancements - Create issues and pull requests - Tell other people about this library - Contribute new protocols Check here for some guidelines. Contributors Check here Contact Email: zetoslab@gmail.com Please only email me if it is more appropriate than creating an Issue / PR. I will not respond to requests for adding support for particular boards, unless of course you are the creator of the board and would like to cooperate on the project. I will also ignore any emails asking me to tell you how to implement your ideas. However, if you have a private inquiry that you would only apply to you and you would prefer it to be via email, by all means. License Up to the version 2.7.0 the License is GPLv2. From the version 2.8.0 the license is the MIT license. Copyright Initially coded 2009 Ken Shirriff http://www.righto.com Copyright (c) 2016 Rafi Khan Copyright (c) 2020-2021 Armin Joachimsmeyer

 # # # # # # # # # # # # # # # # # # # #
 Repository: andreamazz/AMWaveTransition, index: 3407, word count: 7286 
 # # # # # # # # # # # # # # # # # # # #

Smart LESS CSS mixins library. lesshat Download latest | Get Started | Introduction | Contribute | Documentation | Current version: v4.1.0 (2016-07-19) Get started To use lesshat, you need node/npm installed then run npm install lesshat --save to install and save lesshat into your package.json. From here, you just need to reference the node_modules/lesshat/lesshat.less within your .less stylesheets. Bower Introduction Why lesshat? In August 2012, while we were developing and extending CSS Hat for LESS we needed universal mixins. Unfortunately, none of available were good enough that would satisfy our needs and thats why we created new custom ones on our own, which have become the most popular mixin library for the whole LESS CSS. Meet the best mixins library in the world. Features No restrictions If it's possible in CSS, it must be possible to be done with a mixin. Unlimited number of anything, shadows, gradients, gradient swatches. Standard naming convention In lesshat, mixins have names like all CSS3 properties. No .rounded or .shadow. It's stupid. Cross-browser lesshat takes care of exporting CSS for all available browsers. Bootstrap friendly You can now use prefixed lesshat version and gaily work with Bootstrap. Yeah it's that easy. Keyframes Although it's tricky as hell, but yeah lesshat has mixin for .keyframes Blank state ready If you call mixin without any arguments, lesshat does not pollute your CSS with empty properties. Instead lesshat generates nothing. Workflow No more one line editing! We created developer friendly worklow for editing and creating mixins. You can test mixins with Mocha, generate new mixin with Grunt. Find out more about the workflow in Contribute section. Structure of lesshat mixins Typical lesshat mixin: .supermixin(...) { @process: ~`(function(){})()`; -webkit-border-radius: @process; border-radius: @process; } In @process variable is all magic. Please don't edit javascript directly in .less file. Instead use lesshat-devstack. Use (almost) every property without interpolation! Correct mixin calling: .background-image(linear-gradient(to bottom, #fb83fa 0%,#e93cec 100%)) Incorrect calling: .background-image(~'linear-gradient(to bottom, #fb83fa 0%,#e93cec 100%)') Unfortunately, there are exceptions: .keyframes(~''); .calc(~''); .selection(~''); // in some cases you have to interpolate border-radius or LESS CSS begins to play on calculator .border-radius(~'20px / 40px'); Contribute: Download this repo. NPM install. Now you have lesshat devstack (see documentation.) If you create new mixin, use grunt generate command! If it's possible (almost always) test the coverage for new mixins, and never break existing tests. Commits should represent one logical change each. If a mixin goes through multiple iterations, squash your commits down to one. Finally, commit some code and open a pull request. Documentation: List of mixins: align-content flexbox align-items flexbox align-self flexbox animation animation-delay animation-direction animation-duration animation-fill-mode animation-iteration-count animation-name animation-play-state animation-timing-function appearance backface-visibility background-clip background-image background-origin background-size blur filter border-bottom-left-radius border-bottom-right-radius border-image border-radius border-top-left-radius border-top-right-radius box-shadow box-sizing brightness filter calc column-count column-gap column-rule column-width columns contrast filter display flexbox drop-shadow filter filter flex flexbox flex-basis flexbox flex-direction flexbox flex-grow flexbox flex-shrink flexbox flex-wrap flexbox font-face grayscale filter hue-rotate filter hyphens invert filter justify-content flexbox keyframes opacity order perspective perspective-origin placeholder rotate transform rotate3d transform rotateX transform rotateY transform rotateZ transform saturate filter scale transform scale3d transform scaleX transform scaleY transform scaleZ transform selection sepia filter size width, height skew transform skewX transform skewY transform transform transform-origin transform-style transition transition-delay transition-duration transition-property transition-timing-function translate transform translate3d transform translateX transform translateY transform translateZ transform user-select align-content Summary: The CSS align-content property aligns a flex container's lines within the flex container when there is an extra space on the cross-axis. This property has no effect on the single line flexible boxes. Resources: MDN, CSS-Tricks Syntax: Default value: stretch .align-content(flex-start | flex-end | center | space-between | space-around | stretch) Example: div { .align-content(flex-start); } // Result div { -webkit-align-content: flex-start; -ms-flex-line-pack: start; align-content: flex-start; } align-items Summary: The CSS align-items property aligns flex items of the current flex line the same way as justify-content but in the perpendicular direction. Resources: MDN, CSS-Tricks Syntax: Default value: stretch .align-items(flex-start | flex-end | center | baseline | stretch) Example: div { .align-items(flex-start); } // Result div { -webkit-box-align: flex-start; -moz-box-align: start; -webkit-align-items: start; -ms-flex-align: flex-start; align-items: flex-start; } align-self Summary: The align-self CSS property aligns flex items of the current flex line overriding the align-items value. If any of the flex item's cross-axis margin is set to auto, then align-self is ignored. Resources: MDN, CSS-Tricks Syntax: Default value: auto .align-self(auto | flex-start | flex-end | center | baseline | stretch) Example: div { .align-self(flex-start); } // Result div { -webkit-align-self: flex-start; -ms-flex-item-align: start; align-self: flex-start; } animation Summary: Shorthand to define a CSS animation, setting all parameters at once. Resources: WebPlatform, CSS3files Syntax: Default value: none .animation(animation-name | animation-duration | animation-timing-function | animation-delay | animation-iteration-count | animation-direction | animation-fill-mode , []*) Example: div { .animation(nameAnimation 2s linear alternate); } // Result div { -webkit-animation: nameAnimation 2s linear alternate; -moz-animation: nameAnimation 2s linear alternate; -o-animation: nameAnimation 2s linear alternate; animation: nameAnimation 2s linear alternate; } animation-delay Summary: Defines a length of time to elapse before an animation starts, allowing an animation to begin execution some time after it is applied. Resources: WebPlatform, MDN Syntax: Default value: 0 .animation-delay(<time>, ) Tips and tricks: If you omit units after time argument, animation-delay is trying to be smart and add properly value. if (time > 10) { time += 'ms'; } else { time += 's'; } Example: div { .animation-delay(2, 200); } // Result div { -webkit-animation-delay: 2s, 200ms; -moz-animation-delay: 2s, 200ms; -o-animation-delay: 2s, 200ms; animation-delay: 2s, 200ms; } animation-direction Summary: The animation-direction CSS property indicates whether the animation should play in reverse on alternate cycles. Resources: WebPlatform, MDN Syntax: Default value: normal .animation-direction(<single-animation-direction>, ) Example: div { .animation-direction(reverse, alternate); } // Result div { -webkit-animation-direction: reverse, alternate; -moz-animation-direction: reverse, alternate; -o-animation-direction: reverse, alternate; animation-direction: reverse, alternate; } animation-duration Summary: The animation-duration CSS property specifies the length of time that an animation should take to complete one cycle. Resources: WebPlatform, MDN Syntax: Default value: 0 .animation-duration(<time>, ) Tips and tricks: If you omit units after time argument, animation-duration is trying to be smart and add proper value. if (time > 10) { time += 'ms'; } else { time += 's'; } Example: div { .animation-duration(2000); } // Result div { -webkit-animation-duration: 2000ms; -moz-animation-duration: 2000ms; -o-animation-duration: 2000ms; animation-duration: 2000ms; } animation-fill-mode Summary: The animation-fill-mode CSS property specifies how a CSS animation should apply styles to its target before and after it is executing. Resources: WebPlatform, MDN Syntax: Default value: none .animation-fill-mode(<single-animation-fill-mode>, ) Example: div { .animation-fill-mode(forwards); } // Result div { -webkit-animation-fill-mode: forwards; -moz-animation-fill-mode: forwards; -o-animation-fill-mode: forwards; animation-fill-mode: forwards; } animation-iteration-count Summary: The animation-iteration-count CSS property specifies how a CSS animation should apply styles to its target before and after it is executing. Resources: WebPlatform, MDN Syntax: Default value: 1 .animation-iteration-count(<single-animation-iteration-count>, ) Example: div { .animation-iteration-count(3); } // Result div { -webkit-animation-iteration-count: 3; -moz-animation-iteration-count: 3; -o-animation-iteration-count: 3; animation-iteration-count: 3; } animation-name Summary: The animation-name CSS property specifies a list of animations that should be applied to the selected element. Each name indicates a @keyframes at-rule that defines the property values for the animation sequence. Resources: WebPlatform, MDN Syntax: Default value: none .animation-name(<single-animation-name>, ) Example: div { .animation-name(animation-1, animation-2); } // Result div { -webkit-animation-name: animation-1, animation-2; -moz-animation-name: animation-1, animation-2; -o-animation-name: animation-1, animation-2; animation-name: animation-1, animation-2; } animation-play-state Summary: The animation-play-state CSS property determines whether an animation is running or paused. You can query this property's value to determine whether or not the animation is currently running; in addition, you can set its value to pause and resume playback of an animation. Resources: WebPlatform, MDN Syntax: Default value: running .animation-play-state(<single-animation-play-state>, ) Example: div { .animation-play-state(paused); } // Result div { -webkit-animation-play-state: paused; -moz-animation-play-state: paused; -o-animation-play-state: paused; animation-play-state: paused; } animation-timing-function Summary: The animation-timing-function CSS property determines whether an animation is running or paused. You can query this property's value to determine whether or not the animation is currently running; in addition, you can set its value to pause and resume playback of an animation. Resources: WebPlatform, MDN Syntax: Default value: ease .animation-timing-function(<single-animation-timing-function>, ) Example: div { .animation-timing-function(cubic-bezier(0.1, 0.7, 1.0, 0.1)); } // Result div { -webkit-animation-timing-function: cubic-bezier(0.1, 0.7, 1.0, 0.1); -moz-animation-timing-function: cubic-bezier(0.1, 0.7, 1.0, 0.1); -o-animation-timing-function: cubic-bezier(0.1, 0.7, 1.0, 0.1); animation-timing-function: cubic-bezier(0.1, 0.7, 1.0, 0.1); } appearance Summary: Allows changing the style of any element to platform-based interface elements or vice versa. Resources: WebPlatform, CSS-Tricks Syntax: Default value: none .appearance(<appearance>) Example: div { .appearance(); } // Result div { -webkit-appearance: none; -moz-appearance: none; appearance: none; } backface-visibility Summary: The CSS backface-visibility property determines whether or not the back face of the element is visible when facing the user. The back face of an element always is a transparent background, letting, when visible, a mirror image of the front face be displayed. Resources: WebPlatform, MDN Syntax: Default value: none .backface-visibility(visible | hidden ) Example: div { .backface-visibility(hidden); } // Result div { -webkit-backface-visibility: none; -moz-backface-visibility: none; -ms-backface-visibility: none; -o-backface-visibility: none; backface-visibility: none; } background-clip Summary: The background-clip CSS property specifies whether an element's background, either the color or image, extends underneath its border. Resources: WebPlatform, MDN Syntax: Default value: border-box .background-clip(<box>) Example: div { .background-clip(padding-box); } // Result div { -webkit-background-clip: padding-box; -moz-background-clip: padding-box; background-clip: padding-box; } background-image Summary: With the background-image you can create prefixed linear or radial gradients. The CSS (linear|radial)-gradient() function creates an <image> which represents a linear|radial gradient of colors. The result of this function is an object of the CSS <gradient> data type. Like any other gradient, a CSS linear gradient is not a CSS <color> but an image with no intrinsic dimensions; that is, it has neither natural or preferred size, nor ratio. Its concrete size will match the one of the element it applies to. Resources: WebPlatform, MDN Syntax: Default value: none .background-image(<gradient>, ...) Tips and tricks: The background-image mixin is the most robust mixin of all. It generates SVG for Internet Explorer 9, old webkit, moz and opera syntax. Always use W3C syntax for the mixin. It can recalculate angle for older syntax, transform to top to bottom syntax and it can omit SVG syntax if it's impossible to express SVG e.g. when you call mixin with 55deg. If you call mixin without arguments, LESS Hat does not generate anything. Great online gradient generator. Example: div { .background-image(linear-gradient(to bottom, #fb83fa 0%,#e93cec 100%)); } // Result div { background-image: url(data:image/svg+xml;base64,PD94bWwgdmVyc2lvbj0iMS4wIiA/PjxzdmcgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIiB3aWR0aD0iMTAwJSIgaGVpZ2h0PSIxMDAlIiB2aWV3Qm94PSIwIDAgMSAxIiBwcmVzZXJ2ZUFzcGVjdFJhdGlvPSJub25lIj48bGluZWFyR3JhZGllbnQgaWQ9Imxlc3NoYXQtZ2VuZXJhdGVkIiBncmFkaWVudFVuaXRzPSJ1c2VyU3BhY2VPblVzZSIgeDE9IjAlIiB5MT0iMCUiIHgyPSIwJSIgeTI9IjEwMCUiPjxzdG9wIG9mZnNldD0iMCUiIHN0b3AtY29sb3I9IiNmYjgzZmEiIHN0b3Atb3BhY2l0eT0iMSIvPjxzdG9wIG9mZnNldD0iMTAwJSIgc3RvcC1jb2xvcj0iI2U5M2NlYyIgc3RvcC1vcGFjaXR5PSIxIi8+PC9saW5lYXJHcmFkaWVudD48cmVjdCB4PSIwIiB5PSIwIiB3aWR0aD0iMSIgaGVpZ2h0PSIxIiBmaWxsPSJ1cmwoI2xlc3NoYXQtZ2VuZXJhdGVkKSIgLz48L3N2Zz4=); background-image: -webkit-linear-gradient(top, #fb83fa 0%, #e93cec 100%); background-image: -moz-linear-gradient(top, #fb83fa 0%, #e93cec 100%); background-image: -o-linear-gradient(top, #fb83fa 0%, #e93cec 100%); background-image: linear-gradient(to bottom, #fb83fa 0%, #e93cec 100%); } background-origin Summary: The background-origin CSS property determines the background positioning area, that is the position of the origin of an image specified using the background-image CSS property. Resources: WebPlatform, MDN Syntax: Default value: padding-box .background-origin(<box>) Example: div { .background-origin(content-box); } // Result div { -webkit-background-origin: content-box; -moz-background-origin: content-box; background-origin: content-box; } background-size Summary: The background-size CSS property specifies the size of the background images. The size of the image can be fully constrained or only partially in order to preserve its intrinsic ratio. Resources: WebPlatform, MDN Syntax: Default value: auto auto .background-size(<bg-size>, ...) Tips and tricks: If you omit units, background-size adds px automatically. Example: div { .background-size(cover, 100%); } // Result div { -webkit-background-size: cover, 100%; -moz-background-size: cover, 100%; background-size: cover, 100%; } blur (shorthand for filter property) Summary: Applies a Gaussian blur to the input image. The value of radius defines the value of the standard deviation to the Gaussian function, or how many pixels on the screen blend into each other, so a larger value will create more blur. If no parameter is provided, then a value 0 is used. The parameter is specified as a CSS length, but does not accept percentage values. Resources: MDN Syntax: Default value: 0 .blur(length) Tips and tricks: If you omit units, blur adds px automatically. Example: div { .blur(5px); } // Result div { -webkit-filter: blur(5px); -moz-filter: blur(5px); -ms-filter: blur(5px); filter: blur(5px); } border-bottom-left-radius Summary: The border-bottom-left-radius CSS property sets the rounding of the bottom-left corner of the element. The rounding can be a circle or an ellipse, or if one of the value is 0 no rounding is done and the corner is square. Resources: WebPlatform, MDN Syntax: Default value: 0 .border-bottom-left-radius(length | percentage) Tips and tricks: If you omit units, border-bottom-left-radius adds px automatically. If you want to use syntax like 10px \ 5px, you have to interpolate argument ~'' or LESS CSS divides it (yeah awesome feature!). Also LESS Hat adds background-clip: padding-box, because it fixes problem with older Safari. Here is some resource. Example: div { .border-bottom-left-radius(10px); } // Result div { -webkit-border-bottom-left-radius: 10px; -moz-border-radius-bottomleft: 10px; border-bottom-left-radius: 10px; } border-bottom-right-radius Summary: The border-bottom-right-radius CSS property sets the rounding of the bottom-left corner of the element. The rounding can be a circle or an ellipse, or if one of the value is 0 no rounding is done and the corner is square. Resources: WebPlatform, MDN Syntax: Default value: 0 .border-bottom-right-radius(length | percentage) Tips and tricks: If you omit units, border-bottom-right-radius adds px automatically. If you want to use syntax like 10px \ 5px, you have to interpolate argument ~'' or LESS CSS divides it (yeah awesome feature!). Also LESS Hat adds background-clip: padding-box, because it fixes problem with older Safari. Here is some resource. Example: div { .border-bottom-right-radius(10px); } // Result div { -webkit-border-bottom-right-radius: 10px; -moz-border-radius-bottomright: 10px; border-bottom-right-radius: 10px; } border-image Summary: The border-image CSS property allows drawing an image on the borders of elements. This makes drawing complex looking widgets much simpler than it has been and removes the need for nine boxes in some cases. Resources: WebPlatform, MDN Syntax: Default value: based on individual properties .border-image(border-image-source border-image-slice border-image-width border-image-outset border-image-repeat) Tips and tricks: If you call mixin without arguments, LESS Hat does not generate anything. Good border-image online generator. Example: div { .border-image(url(border.png) 61 45 62 54 repeat); } // Result div { -webkit-border-image: url(border.png) 61 45 62 54 repeat; -moz-border-image: url(border.png) 61 45 62 54 repeat; -o-border-image: url(border.png) 61 45 62 54 repeat; border-image: url(border.png) 61 45 62 54 repeat; } border-radius Summary: The border-radius CSS property allows Web authors to define how rounded border corners are. The curve of each corner is defined using one or two radii, defining its shape: circle or ellipse. Resources: WebPlatform, MDN Syntax: Default value: 0 .border-radius(length | percentage | length / length | percentage / percentage) Tips and tricks: If you omit units, border-radius adds px automatically. If you want to use syntax like 10px \ 5px, you have to interpolate argument ~'' or LESS CSS divides it (yeah awesome feature!). Also LESS Hat adds background-clip: padding-box, because it fixes problem with older Safari. Here is some resource. Example: div { .border-radius(5px); } // Result div { -webkit-border-radius: 5px; -moz-border-radius: 5px; border-radius: 5px; } border-top-left-radius Summary: The border-top-left-radius CSS property sets the rounding of the top-left corner of the element. The rounding can be a circle or an ellipse, or if one of the value is 0 no rounding is done and the corner is square. Resources: WebPlatform, MDN Syntax: Default value: 0 .border-top-left-radius(length | percentage) Tips and tricks: If you omit units, border-top-left-radius adds px automatically. If you want to use syntax like 10px \ 5px, you have to interpolate argument ~'' or LESS CSS divides it (yeah awesome feature!). Also LESS Hat adds background-clip: padding-box, because it fixes problem with older Safari. Here is some resource. Example: div { .border-top-left-radius(5px); } // Result div { -webkit-border-top-left-radius: 5px; -moz-border-top-left-radius: 5px; border-top-left-radius: 5px; } border-top-right-radius Summary: The border-top-right-radius CSS property sets the rounding of the top-right corner of the element. The rounding can be a circle or an ellipse, or if one of the value is 0 no rounding is done and the corner is square. Resources: WebPlatform, MDN Syntax: Default value: 0 .border-top-right-radius(length | percentage) Tips and tricks: If you omit units, border-top-right-radius adds px automatically. If you want to use syntax like 10px \ 5px, you have to interpolate argument ~'' or LESS CSS divides it (yeah awesome feature!). Also LESS Hat adds background-clip: padding-box, because it fixes problem with older Safari. Here is some resource. Example: div { .border-top-right-radius(5px); } // Result div { -webkit-border-top-right-radius: 5px; -moz-border-top-right-radius: 5px; border-top-right-radius: 5px; } box-shadow Summary: The box-shadow CSS property describes one or more shadow effects as a comma-separated list. It allows casting a drop shadow from the frame of almost any element. If a border-radius is specified on the element with a box shadow, the box shadow takes on the same rounded corners. The z-ordering of multiple box shadows is the same as multiple text shadows (the first specified shadow is on top). Resources: WebPlatform, MDN Syntax: Default value: none .box-shadow(<offset-x> <offset-y> spread blur-radius color inset, ) Tips and tricks: If you omit units, box-shadow adds px automatically. Example: div { .box-shadow(0 1px 10px rgba(20,20,20,0.5)); } // Result div { -webkit-box-shadow: 0 1px 10px rgba(20,20,20,0.5); -moz-box-shadow: 0 1px 10px rgba(20,20,20,0.5); box-shadow: 0 1px 10px rgba(20,20,20,0.5); } box-sizing Summary: The box-sizing CSS property is used to alter the default CSS box model used to calculate widths and heights of elements. It is possible to use this property to emulate the behavior of browsers that do not correctly support the CSS box model specification. Resources: WebPlatform, MDN Syntax: Default value: content-box .box-sizing(content-box | padding-box | border-box) Example: div { .box-sizing(padding-box); } // Result div { -webkit-box-sizing: padding-box; -moz-box-sizing: padding-box; box-sizing: padding-box; } brightness (shorthand for filter property) Summary: Applies a linear multiplier to input image, making it appear more or less bright. A value of 0% will create an image that is completely black. A value of 100% leaves the input unchanged. Other values are linear multipliers on the effect. Values of an amount over 100% are allowed, providing brighter results. If the amount parameter is missing, a value of 100% is used. Resources: MDN Syntax: Default value: 0 .brightness(amount) Example: div { .brightness(0.5); } // Result div { -webkit-filter: brightness(0.5); -moz-filter: brightness(0.5); -ms-filter: brightness(0.5); filter: brightness(0.5); } calc Summary: The calc() CSS function can be used anywhere a <length>, <frequency>, <angle>, <time>, <number>, or <integer> is required.With calc(), you can perform calculations to determine CSS property values. THIS MIXIN MUST BE INTERPOLATED ~'' The -lh-property: 0 junk line of code is a neccesary sacrifice due to the hack nature of this set of mixins. (via less-properties) Resources: MDN Syntax: .calc(<element>, ~'<expression>') Example: div { .calc(width, ~'100% - 33px'); } // Result div { -lh-property: 0; width:-webkit-calc(100% - 33px); width:-moz-calc(100% - 33px); width:calc(100% - 33px); } column-count Summary: The column-count CSS property describes the number of columns of the element. Resources: WebPlatform, MDN Syntax: Default value: auto .column-count(<number> | auto) Example: div { .column-count(3); } // Result div { -webkit-column-count: 0.5; -moz-column-count: 0.5; column-count: 0.5; } column-gap Summary: The column-gap CSS property sets the size of the gap between columns for elements which are specified to display as a multi-column element. Resources: WebPlatform, MDN Syntax: Default value: normal .column-gap(<length> | normal) Tips and tricks: If you omit units, column-gap adds px automatically. Example: div { .column-gap(30); } // Result div { -webkit-column-gap: 30px; -moz-column-gap: 30px; column-gap: 30px; } column-rule Summary: In multi-column layouts, the column-rule CSS property specifies a straight line, or "rule", to be drawn between each column. Resources: WebPlatform, MDN Syntax: Default value: medium none black .column-rule(<column-rule-width> | <column-rule-style> | <column-rule-color>) Tips and tricks: If you omit units, column-rule adds px automatically. Example: div { .column-rule(5 outset #ff00ff); } // Result div { -webkit-column-rule: 5px outset #ff00ff; -moz-column-rule: 5px outset #ff00ff; column-rule: 5px outset #ff00ff; } column-width Summary: The column-width CSS property suggests an optimal column width. This is not a absolute value but a mere hint. Browser will adjust the width of the column around that suggested value, allowing to achieve scalable designs that fit different screen size. Resources: WebPlatform, MDN Syntax: Default value: auto .column-width(<length> | auto) Tips and tricks: If you omit units, column-width adds px automatically. Example: div { .column-width(100px); } // Result div { -webkit-column-width: 100px; -moz-column-width: 100px; column-width: 100px; } columns Summary: The columns CSS property is a shorthand property allowing to set both the column-width and the column-count properties at the same time. Resources: WebPlatform, MDN Syntax: Default value: auto .columns(<column-width> | <column-count>) Tips and tricks: If you omit units for column-width argument, columns adds px to it automatically. Example: div { .columns(100 3); } // Result div { -webkit-columns: 100px 3; -moz-columns: 100px 3; columns: 100px 3; } contrast Summary: Adjusts the contrast of the input. A value of 0% will create an image that is completely black. A value of 100% leaves the input unchanged. Values of amount over 100% are allowed, providing results with less contrast. If the amount parameter is missing, a value of 100% is used. Resources: MDN Syntax: Default value: 100% .contrast(<amount>) Tips and tricks: If you omit units, contrast adds % automatically. Example: div { .contrast(200); } // Result div { -webkit-filter: contrast(200%); -moz-filter: contrast(200%); -ms-filter: contrast(200%); filter: contrast(200%); } display Summary: The display CSS property specifies the type of rendering box used for an element. This mixin is specifically for flexbox purpose. Resources: CSS-Tricks Syntax: .display(<flex> | <inline-flex>) Example: div { .display(flex); } // Result div { display: -webkit-box; display: -ms-flexbox; display: -webkit-flex; display: -moz-box; } drop-shadow Summary: Applies a drop shadow effect to the input image. A drop shadow is effectively a blurred, offset version of the input image's alpha mask drawn in a particular color, composited below the image. Resources: MDN Syntax: .drop-shadow(<offset-x> <offset-y> [<blur-radius> | <spread-radius> | <color>]) Tips and tricks: If you omit units, drop-shadow adds px automatically. Example: div { .drop-shadow(16 16 10 black); } // Result div { -webkit-filter: drop-shadow(16px 16px 10px #000000); -moz-filter: drop-shadow(16px 16px 10px #000000); -ms-filter: drop-shadow(16px 16px 10px #000000); filter: drop-shadow(16px 16px 10px #000000); } filter Summary: The CSS filter property provides for effects like blurring or color shifting on an elements rendering before the element is displayed. Filters are commonly used to adjust the rendering of an image, a background, or a border. Resources: MDN Syntax: Default value: none .filter(<filter-function>*) Example: div { .filter(grayscale(0.5) blur(10px)); } // Result div { -webkit-filter: grayscale(0.5) blur(10px); -moz-filter: grayscale(0.5) blur(10px); -ms-filter: grayscale(0.5) blur(10px); filter: grayscale(0.5) blur(10px); } flex Summary: The flex CSS property specifies ability of a flex item to alter their dimensions to fill the available space. Flex items can be stretched to use available space proportional to their flex grow factor or their flex shrink factor to prevent overflow. Resources: MDN, CSS-Tricks Syntax: Default value: 0 1 auto .flex(none | [ <flex-grow> <flex-shrink> | <flex-basis> ]) Example: div { .flex(1 3 100px); } // Result div { -webkit-box-flex: 1; -moz-box-flex: 1; -webkit-flex: 1 3 100px; -ms-flex: 1 3 100px; flex: 1 3 100px; } flex-basis Summary: The CSS flex-basis property specifies the flex basis which is the initial main size of a flex item. Resources: MDN, CSS-Tricks Syntax: Default value: auto .flex-basis(<width>) Tips and tricks: If you omit units, flex-basis adds px automatically. Example: div { .flex-basis(100); } // Result div { -webkit-flex-basis: 100; flex-basis: 100px; } flex-direction Summary: The CSS flex-direction property specifies how flex items are placed in the flex container defining the main axis and the direction (normal or reversed). Resources: MDN, CSS-Tricks Syntax: Default value: row .flex-direction(row | row-reverse | column | column-reverse) Example: div { .flex-direction(row); } // Result div { -webkit-box-direction: normal; -moz-box-direction: normal; -webkit-box-orient: horizontal; -moz-box-orient: horizontal; -webkit-flex-direction: row; -ms-flex-direction: row; flex-direction: row; } flex-grow Summary: The CSS flex-grow property specifies the flex grow factor of a flex item. Resources: MDN, CSS-Tricks Syntax: Default value: 0 .flex-grow(<number>) Example: div { .flex-grow(2); } // Result div { -webkit-flex-grow: 2; flex-grow: 2; } flex-shrink Summary: The CSS flex-shrink property specifies the flex shrink factor of a flex item. Resources: MDN, CSS-Tricks Syntax: Default value: 1 .flex-shrink(<number>) Example: div { .flex-shrink(2); } // Result div { -webkit-flex-shrink: 2; flex-shrink: 2; } flex-wrap Summary: The CSS flex-wrap property specifies whether the children are forced into a single line or if the items can be flowed on multiple lines. Resources: MDN, CSS-Tricks Syntax: Default value: nowrap .flex-wrap(nowrap | wrap | wrap-reverse) Example: div { .flex-wrap(wrap-reverse); } // Result div { -webkit-flex-wrap: 2; -ms-flex-wrap: 2; flex-wrap: 2; } font-face Summary: The @font-face CSS at-rule allows authors to specify online fonts to display text on their web pages. Resources: MDN Syntax: .font-face(@fontname, @fontfile, @fontweight:normal, @fontstyle:normal) Example: div { .font-face(Hipster, ~'../fonts/hipster', bold, italic); } // Result div { font-family: "Hipster"; src: url("../fonts/hipster.eot"); src: url("../fonts/hipster.eot?#iefix") format("embedded-opentype"), url("../fonts/hipster.woff") format("woff"), url("../fonts/hipster.ttf") format("truetype"), url("../fonts/hipster.svg#Hipster") format("svg"); font-weight: bold; font-style: italic; } grayscale Summary: Converts the input image to grayscale. The value of amount defines the proportion of the conversion. A value of 100% is completely grayscale. A value of 0% leaves the input unchanged. Values between 0% and 100% are linear multipliers on the effect. If the amount parameter is missing, a value of 100% is used. Resources: MDN Syntax: Default value: 0 .grayscale(<percentage>) Tips and tricks: If you omit units, grayscale adds % automatically. Example: div { .grayscale(50); } // Result div { -webkit-filter: grayscale(50%); -moz-filter: grayscale(50%); -ms-filter: grayscale(50%); filter: grayscale(50%); } hue-rotate Summary: Applies a hue rotation on the input image. The value of angle defines the number of degrees around the color circle the input samples will be adjusted. A value of 0deg leaves the input unchanged. If the angle parameter is missing, a value of 0deg is used. Maximum value is 360deg. Resources: MDN Syntax: Default value: 0 .hue-rotate(<percentage>) Tips and tricks: If you omit units, hue-rotate adds deg automatically. Example: div { .hue-rotate(50); } // Result div { -webkit-filter: hue-rotate(50deg); -moz-filter: hue-rotate(50deg); -ms-filter: hue-rotate(50deg); filter: hue-rotate(50deg); } hyphens Summary: The hyphens CSS property tells the browser how to go about splitting words to improve the layout of text when line-wrapping. Resources: MDN Syntax: Default value: manual .hyphens(none | manual | auto) Example: div { .hyphens(none); } // Result div { -webkit-hyphens: none; -moz-hyphens: none; -ms-hyphens: none; } invert Summary: Inverts the samples in the input image. The value of amount defines the proportion of the conversion. A value of 100% is completely inverted. A value of 0% leaves the input unchanged. Values between 0% and 100% are linear multipliers on the effect. If the amount parameter is missing, a value of 100% is used. Resources: MDN Syntax: Default value: 0 .invert(<percentage>) Tips and tricks: If you omit units, invert adds % automatically. Example: div { .invert(100); } // Result div { -webkit-filter: invert(100%); -moz-filter: invert(100%); -ms-filter: invert(100%); filter: invert(100%); } justify-content Summary: The CSS justify-content property defines how a browser distributes available space between and around elements when aligning flex items in the main-axis of the current line. Resources: MDN, CSS-Tricks Syntax: Default value: flex-start .justify-content(flex-start | flex-end | center | space-between | space-around) Example: div { .justify-content(flex-start); } // Result div { -webkit-box-pack: flex-start; -moz-box-pack: start; -webkit-justify-content: start; -ms-flex-pack: flex-start; justify-content: flex-start; } keyframes Summary: The @keyframes CSS at-rule lets authors control the intermediate steps in a CSS animation sequence by establishing keyframes (or waypoints) along the animation sequence that must be reached by certain points during the animation. LESS CSS isn't great for complicated mixin like this one, so it's little bit tricky. LESS CSS compiler doesn't allow to have properties in the root. It's better to understand the problem on the example. // There is no selector color: red; SyntaxError: properties must be inside selector blocks, they cannot be in the root. div { color: red; } // This is correct Therefore LESS Hat generates placeholder selector lesshat-selector { -lh-property: 0; } with unknown property, which browsers ignore and after that, there is actually keyframes syntax. And also because of bad architecture of LESS CSS language, keyframes definition has to be on single line. THIS MIXIN MUST BE INTERPOLATED ~'' Resources: WebPlatform, MDN Syntax: .keyframes(~'<keyframes-name>, <keyframes-definition>') Tips and tricks: Properties inside <keyframes-definition> are automatically prefixed, if it's needed. Keyframes mixin supports prefix configuration but it's computationally demanding so it is commented out and all prefixes are rendered. Feel free to uncommented that if you need it. Example: .keyframes(~'animationName, 0%{ transform: scale(1.5); color: blue; } 100%{ transform: scale(2); color: red }'); // Result lesshat-selector {-lh-property: 0; } @-webkit-keyframes animationName{ 0%{ -webkit-transform: scale(1.5); color: blue; } 100%{ -webkit-transform: scale(2); color: red }} @-moz-keyframes animationName{ 0%{ -moz-transform: scale(1.5); color: blue; } 100%{ -moz-transform: scale(2); color: red }} @-o-keyframes animationName{ 0%{ -o-transform: scale(1.5); color: blue; } 100%{ -o-transform: scale(2); color: red }} @keyframes animationName{ 0%{ transform: scale(1.5); color: blue; } 100%{ transform: scale(2); color: red };} opacity Summary: The opacity CSS property specifies the transparency of an element, that is, the degree to which the background behind the element is overlaid. This is not shorthand method for filter opacity. Resources: MDN Syntax: Default value: 1 .opacity(<number>) Tips and tricks: You can enable old filter syntax for IE6, just set @ms_local: true. Example: div { .opacity(.5); } // Result div { -webkit-opacity: 0.5; -moz-opacity: 0.5; opacity: 0.5; } order Summary: The CSS order property specifies the order used to lay out flex items in their flex container. Resources: MDN, CSS-Tricks Syntax: Default value: 0 .order(<integer>) Example: div { .order(1); } // Result div { -webkit-box-ordinal-group: 1; -moz-box-ordinal-group: 1; -ms-flex-order: 1; -webkit-order: 1; order: 1; } perspective Summary: The perspective CSS property determines the distance between the z=0 plane and the user in order to give to the 3D-positioned element some perspective. Resources: MDN, CSS-Tricks Syntax: Default value: none .perspective(none | <length>) Tips and tricks: If you omit units, perspective adds px automatically. Example: div { .perspective(1000); } // Result div { -moz-perspective: 1000px; -webkit-perspective: 1000px; perspective: 1000px; } perspective-origin Summary: The perspective-origin CSS property determines the position the viewer is looking at. It is used as the vanishing point by the perspective property. Resources: MDN, CSS-Tricks Syntax: Default value: 50% 50% .perspective-origin(<percentage> | <length> | constants | inherit) Tips and tricks: If you omit units, perspective-origin adds % automatically. Example: div { .perspective-origin(top left); } // Result div { -moz-perspective-origin: top left; -webkit-perspective-origin: top left; perspective-origin: top left; } placeholder Summary: Placeholder is the short hint displayed in the input field before the user clicked to it. Default placeholder text in inputs has a light gray color (so far). Resources: CSS-Tricks Syntax: .placeholder(<color>, [<element>]) Example: div { .placeholder(#666666); } // Result div::-webkit-input-placeholder { color: #666666; } div:-moz-placeholder { color: #666666; } div::-moz-placeholder { color: #666666; } div:-ms-input-placeholder { color: #666666; } // In root (outside of selectors) .placeholder(#333333); // Result ::-webkit-input-placeholder { color: #666666; } :-moz-placeholder { color: #666666; } ::-moz-placeholder { color: #666666; } :-ms-input-placeholder { color: #666666; } // In root (outside of selectors) .placeholder(#333333, textarea); // Result textarea::-webkit-input-placeholder { color: #666666; } textarea:-moz-placeholder { color: #666666; } textarea::-moz-placeholder { color: #666666; } textarea:-ms-input-placeholder { color: #666666; } rotate Summary: Rotates the element clockwise around its origin by the specified angle. Resources: MDN Syntax: Default value: 0 .rotate(<angle>) Tips and tricks: If you omit units, rotate adds deg automatically. Example: div { .rotate(45); } // Result div { -webkit-transform: rotate(45deg); -moz-transform: rotate(45deg); -ms-transform: rotate(45deg); -o-transform: rotate(45deg); transform: rotate(45deg); } rotate3d Summary: The rotate3d()CSS function defines a transformation that moves the element around a fixed axe without deforming it. Resources: MDN Syntax: Default value: 0, 0, 0, 0 .rotate3d(<number>, <number>, <number>, <angle>) Tips and tricks: If you omit angle unit, rotate3d adds deg automatically. Example: div { .rotate3d(1, 0, 0, 50); } // Result div { -webkit-transform: rotate3d(1, 0, 0, 50deg); -moz-transform: rotate3d(1, 0, 0, 50deg); -ms-transform: rotate3d(1, 0, 0, 50deg); -o-transform: rotate3d(1, 0, 0, 50deg); transform: rotate3d(1, 0, 0, 50deg); } rotateX Summary: The rotateX() CSS function defines a transformation that moves the element around the abscissa without deforming it. Resources: MDN Syntax: Default value: 0 .rotateX(<angle>) Tips and tricks: If you omit units, rotateX adds deg automatically. Example: div { .rotateX(45); } // Result div { -webkit-transform: rotateX(45deg); -moz-transform: rotateX(45deg); -ms-transform: rotateX(45deg); -o-transform: rotateX(45deg); transform: rotateX(45deg); } rotateY Summary: The rotateY() CSS function defines a transformation that moves the element around the ordinate without deforming it. Resources: MDN Syntax: Default value: 0 .rotateY(<angle>) Tips and tricks: If you omit units, rotateY adds deg automatically. Example: div { .rotateY(45); } // Result div { -webkit-transform: rotateY(45deg); -moz-transform: rotateY(45deg); -ms-transform: rotateY(45deg); -o-transform: rotateY(45deg); transform: rotateY(45deg); } rotateZ Summary: The rotateZ() CSS function defines a transformation that moves the element around the z-axis without deforming it. Resources: MDN Syntax: Default value: 0 .rotateZ(<angle>) Tips and tricks: If you omit units, rotateZ adds deg automatically. Example: div { .rotateZ(45); } // Result div { -webkit-transform: rotateZ(45deg); -moz-transform: rotateZ(45deg); -ms-transform: rotateZ(45deg); -o-transform: rotateZ(45deg); transform: rotateZ(45deg); } saturate Summary: Saturates the input image. The value of amount defines the proportion of the conversion. Resources: MDN Syntax: Default value: 100% .saturate(<amount>) Tips and tricks: If you omit units, saturate adds % automatically. Example: div { .saturate(45); } // Result div { -webkit-filter: saturate(45deg); -moz-filter: saturate(45deg); -ms-filter: saturate(45deg); filter: saturate(45deg); } scale Summary: Specifies a 2D scaling operation described by [sx, sy]. If sy isn't specified, it is assumed to be equal to sx. Resources: MDN Syntax: Default value: 1 .scale(<sx>[, <sy>]) Example: div { .scale(2); } // Result div { -webkit-transform: scale(2); -moz-transform: scale(2); -ms-transform: scale(2); -o-transform: scale(2); transform: scale(2); } scale3d Summary: The scale3d() CSS function modifies the size of an element. Because the amount of scaling is defined by a vector, it can resize different dimensions at different scales. Resources: MDN Syntax: Default value: 1, 1, 1 .scale3d(<sx>, <sy>, <sz>) Example: div { .scale3d(1.5, .2, 3); } // Result div { -webkit-transform: scale3d(1.5, 0.2, 3); -moz-transform: scale3d(1.5, 0.2, 3); -ms-transform: scale3d(1.5, 0.2, 3); -o-transform: scale3d(1.5, 0.2, 3); transform: scale3d(1.5, 0.2, 3); } scaleX Summary: Specifies a scale operation using the vector [sx, 1]. Resources: MDN Syntax: Default value: 1 .scaleX(<sx>) Example: div { .scaleX(1.5); } // Result div { -webkit-transform: scaleX(1.5); -moz-transform: scaleX(1.5); -ms-transform: scaleX(1.5); -o-transform: scaleX(1.5); transform: scaleX(1.5); } scaleY Summary: Specifies a scale operation using the vector [1, sy]. Resources: MDN Syntax: Default value: 1 .scaleY(<sy>) Example: div { .scaleY(1.5); } // Result div { -webkit-transform: scaleY(1.5); -moz-transform: scaleY(1.5); -ms-transform: scaleY(1.5); -o-transform: scaleY(1.5); transform: scaleY(1.5); } scaleZ Summary: The scaleZ() CSS function modifies the z-coordinate of each element point by a constant facto, except if this scale factor is 1, in which case the function is the identity transform. Resources: MDN Syntax: Default value: 1 .scaleZ(<sz>) Example: div { .scaleZ(1.5); } // Result div { -webkit-transform: scaleZ(1.5); -moz-transform: scaleZ(1.5); -ms-transform: scaleZ(1.5); -o-transform: scaleZ(1.5); transform: scaleZ(1.5); } selection Summary: The ::selection CSS pseudo-element applies rules to the portion of a document that has been highlighted. LESS CSS compiler doesn't allow to have properties in the root. It's better to understand the problem on the example. // There is no selector color: red; SyntaxError: properties must be inside selector blocks, they cannot be in the root. div { color: red; } // This is correct Therefore LESS Hat generates placeholder selector lesshat-selector { -lh-property: 0; } with unknown property, which browsers ignore and after that, there is actually selection syntax. THIS MIXIN MUST BE INTERPOLATED ~'' Use this mixin outside of CSS selectors Resources: MDN Syntax: .selection(<CSS properties>[, <element>]) Example: .selection(~'color: blue; background: red'); // Result lesshat-selector {-lh-property: 0;} ::selection{color: blue; background: red} ::-moz-selection{color: blue; background: red;} sepia Summary: Converts the input image to Instagram like effect. Resources: MDN Syntax: .sepia(<percentage>) Tips and tricks: If you omit units, sepia adds % automatically. Example: div { .sepia(50); } // Result div { -webkit-filter: sepia(50%); -moz-filter: sepia(50%); filter: sepia(50%); } size Summary: This is helper mixin for fast dimensions setup. Syntax: .size(<width>, [<height>]) Tips and tricks: When you call mixin with only one argument, second will be the same. Also you can omit units and size adds it automatically. Example: div { .size(50); } // Result div { width: 50px; height: 50px; } skew Summary: Skews the element along the X and Y axes by the specified angles. If ay isn't provided, no skew is performed on the Y axis. Resources: MDN Syntax: Default value: 0 .skew(<ax>[, <ay>]) Tips and tricks: If you omit units, skew adds % automatically. Example: div { .skew(20, 30); } // Result div { -webkit-transform: skew(20deg, 30deg); -moz-transform: skew(20deg, 30deg); -ms-transform: skew(20deg, 30deg); -o-transform: skew(20deg, 30deg); transform: skew(20deg, 30deg); } skewX Summary: Skews the element along the X axis by the given angle. Resources: MDN Syntax: Default value: 0 .skewX(<angle>) Tips and tricks: If you omit units, skewX adds % automatically. Example: div { .skewX(20); } // Result div { -webkit-transform: skewX(20deg); -moz-transform: skewX(20deg); -ms-transform: skewX(20deg); -o-transform: skewX(20deg); transform: skewX(20deg); } skewY Summary: Skews the element along the Y axis by the given angle. Resources: MDN Syntax: Default value: 0 .skewY(<angle>) Tips and tricks: If you omit units, skewY adds % automatically. Example: div { .skewY(20); } // Result div { -webkit-transform: skewY(20deg); -moz-transform: skewY(20deg); -ms-transform: skewY(20deg); -o-transform: skewY(20deg); transform: skewY(20deg); } transform Summary: The CSS transform property lets you modify the coordinate space of the CSS visual formatting model. Resources: WebPlatform, MDN Syntax: Default value: none .transform(none | <transform-function>+) Tips and tricks: If you omit units, transform can adds correct unit automatically. translate: 'px', rotate: 'deg', rotate3d: 'deg', skew: 'deg' Example: div { .transform(scale(.5) translate(10, 20)); } // Result div { -webkit-transform: scale(.5) translate(10, 20); -moz-transform: scale(.5) translate(10, 20); -ms-transform: scale(.5) translate(10, 20); -o-transform: scale(.5) translate(10, 20); transform: scale(.5) translate(10, 20); } transform-origin Summary: The transform-origin CSS property lets you modify the origin for transformations of an element. Resources: WebPlatform, MDN Syntax: Default value: 50% 50% 0 .transform-origin(<percentage> | <length> | <named-position>) Tips and tricks: If you omit units, transform-origin adds % automatically. Example: div { .transform-origin(50 50); } // Result div { -webkit-transform-origin: 50% 50%; -moz-transform-origin: 50% 50%; -ms-transform-origin: 50% 50%; -o-transform-origin: 50% 50%; transform-origin: 50% 50%; } transform-style Summary: The transform-style CSS property determines if the children of the element are positioned in the 3D-space or are flattened in the plane of the element. Resources: WebPlatform, MDN Syntax: Default value: flat .transform-style(flat | preserve-3d) Example: div { .transform-style(preserve-3d); } // Result div { -webkit-transform-style: preserve-3d; -moz-transform-style: preserve-3d; -ms-transform-style: preserve-3d; -o-transform-style: preserve-3d; transform-style: preserve-3d; } transition Summary: The CSS transition property is a shorthand property for transition-property, transition-duration, transition-timing-function, and transition-delay. It allows to define the transition between two states of an element. Resources: WebPlatform, MDN Syntax: Default value: all 0 ease 0 .transition([ none | <single-transition-property> ] | <time> | <timing-function> | <time>) Tips and tricks: If you omit units after time argument, transition is trying to be smart and add properly value. if (time > 10) { time += 'ms'; } else { time += 's'; } And also properties inside transition definition are automatically prefixed, if it is needed. W3C property value is appending all prefixed values. Why? Some browsers support W3C unprefixed properties, but values must be sometimes prefixed. Let's consider this example: div { -webkit-transition: -webkit-filter .3s ease; -moz-transition: -moz-filter .3s ease; -o-transition: filter .3s ease; // There is a problem! Webkit needs -webkit-filter property transition: filter .3s ease; } Example: div { .transition(box-shadow 0.2s linear, color .4s .2s ease); } // Result div { -webkit-transition: -webkit-box-shadow 0.2s linear, color 0.4s 0.2s ease; -moz-transition: -moz-box-shadow 0.2s linear, color 0.4s 0.2s ease; -o-transition: box-shadow 0.2s linear, color 0.4s 0.2s ease; transition: box-shadow 0.2s linear, color 0.4s 0.2s ease; } transition-delay Summary: The transition-delay CSS property specifies the amount of time to wait between a change being requested to a property that is to be transitioned and the start of the transition effect. Resources: WebPlatform, MDN Syntax: Default value: 0 .transition-delay(<time>) Tips and tricks: If you omit units after time argument, transition-delay is trying to be smart and add properly value. if (time > 10) { time += 'ms'; } else { time += 's'; } Example: div { .transition-delay(200); } // Result div { -webkit-transition-delay: 200ms; -moz-transition-delay: 200ms; -o-transition-delay: 200ms; transition-delay: 200ms; } transition-duration Summary: The transition-duration CSS property specifies the number of seconds or milliseconds a transition animation should take to complete. By default, the value is 0s, meaning that no animation will occur. Resources: WebPlatform, MDN Syntax: Default value: 0 .transition-duration(<time>) Tips and tricks: If you omit units after time argument, transition-duration is trying to be smart and add properly value. if (time > 10) { time += 'ms'; } else { time += 's'; } Example: div { .transition-duration(6); } // Result div { -webkit-transition-duration: 6s; -moz-transition-duration: 6s; -o-transition-duration: 6s; transition-duration: 6s; } transition-property Summary: The transition-property CSS property is used to specify the names of CSS properties to which a transition effect should be applied. Resources: WebPlatform, MDN Syntax: Default value: all .transition-property(<propertyname> | all | none) Tips and tricks: And also properties inside transition-property definition are automatically prefixed, if it is needed. W3C property value is appending all prefixed values. Why? Some browsers support W3C unprefixed properties, but values must be sometimes prefixed. Let's consider this example: div { -webkit-transition: -webkit-filter .3s ease; -moz-transition: -moz-filter .3s ease; -o-transition: filter .3s ease; // There is a problem! Webkit needs -webkit-filter property transition: filter .3s ease; } Example: div { .transition-property(transform); } // Result div { -webkit-transition-property: -webkit-transform; -moz-transition-property: -moz-transform; -o-transition-property: -o-transform; transition-property: -webkit-transform,-moz-transform,-o-transform,transform; } transition-timing-function Summary: The CSS transition-timing-function property is used to describe how the intermediate values of the CSS properties being affected by a transition effect are calculated. This in essence lets you establish an acceleration curve, so that the speed of the transition can vary over its duration. Resources: WebPlatform, MDN Syntax: Default value: ease .transition-timing-function(<timing-function>, ...) Example: div { .transition-timing-function(cubic-bezier(0,0,1,1), ease); } // Result div { -webkit-transition-timing-function: cubic-bezier(0, 0, 1, 1), ease; -moz-transition-timing-function: cubic-bezier(0, 0, 1, 1), ease; -o-transition-timing-function: cubic-bezier(0, 0, 1, 1), ease; transition-timing-function: cubic-bezier(0, 0, 1, 1), ease; } translate Summary: Specifies a 2D translation by the vector [tx, ty]. If ty isn't specified, its value is assumed to be zero. Resources: MDN Syntax: Default value: 0 .translate(<tx>[, <ty>]) Tips and tricks: If you omit units, translate adds px automatically. Example: div { .translate(200); } // Result div { -webkit-transform: translate(200px); -moz-transform: translate(200px); -ms-transform: translate(200px); -o-transform: translate(200px); transform: translate(200px); } translate3d Summary: The translate3d() CSS function moves the position of the element in the 3D space. Resources: MDN Syntax: Default value: 0 .translate3d(<tx>, <ty>, <tz>) Tips and tricks: If you omit units, translate3d adds px automatically. Example: div { .translate3d(20, 30, 10); } // Result div { -webkit-transform: translate3d(20px, 30px, 10px); -moz-transform: translate3d(20px, 30px, 10px); -ms-transform: translate3d(20px, 30px, 10px); -o-transform: translate3d(20px, 30px, 10px); transform: translate3d(20px, 30px, 10px); } translateX Summary: Translates the element by the given amount along the X axis. Resources: MDN Syntax: Default value: 0 .translateX(<tx>) Tips and tricks: If you omit units, translateX adds px automatically. Example: div { .translateX(20); } // Result div { -webkit-transform: translateX(20px); -moz-transform: translateX(20px); -ms-transform: translateX(20px); -o-transform: translateX(20px); transform: translateX(20px); } translateY Summary: Translates the element by the given amount along the Y axis. Resources: MDN Syntax: Default value: 0 .translateY(<ty>) Tips and tricks: If you omit units, translateY adds px automatically. Example: div { .translateY(20); } // Result div { -webkit-transform: translateY(20px); -moz-transform: translateY(20px); -ms-transform: translateY(20px); -o-transform: translateY(20px); transform: translateY(20px); } translateZ Summary: Translates the element by the given amount along the Z axis. Resources: MDN Syntax: Default value: 0 .translateZ(<ty>) Tips and tricks: If you omit units, translateZ adds px automatically. Example: div { .translateZ(20); } // Result div { -webkit-transform: translateZ(20px); -moz-transform: translateZ(20px); -ms-transform: translateZ(20px); -o-transform: translateZ(20px); transform: translateZ(20px); } user-select Summary: Controls the appearance (only) of selection. Resources: MDN Syntax: Default value: auto .user-select(none | text | all | element) Example: div { .user-select(none); } // Result div { -webkit-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none; } Big Thanks to: Jan Kuca (help us with lesshat-devstack) MOZILLA DEVELOPER NETWORK (almost all summary are from MDN) CSS-Tricks (their CSS almanac is great resource) Angular UI router (example of good github profile) Marek Hrabe (for coding lesshat.com) Jan Vu Nam (for design lesshat.com and lesshat book icon)

 # # # # # # # # # # # # # # # # # # # #
 Repository: jedi4ever/veewee, index: 1503, word count: 5533 
 # # # # # # # # # # # # # # # # # # # #

[DEPRECATED]WARNING: THIS PROJECT IS DEPRECATED It will not receive any future updates or bug fixes. If you are using it, please migrate to another solution. Purpose iRate is a library to help you promote your iPhone and Mac App Store apps by prompting users to rate the app after using it for a few days. This approach is one of the best ways to get positive app reviews by targeting only regular users (who presumably like the app or they wouldn't keep using it!). Supported OS & SDK Versions Supported build target - iOS 10.3 / Mac OS 10.12 (Xcode 8.3) Earliest supported deployment target - iOS 8.0 / Mac OS 10.11 Earliest compatible deployment target - iOS 7.0 / Mac OS 10.9 NOTE: 'Supported' means that the library has been tested with this version. 'Compatible' means that the library should work on this OS version (i.e. it doesn't rely on any unavailable SDK features) but is no longer being tested for compatibility and may require tweaking or bug fixes to run correctly. ARC Compatibility As of version 1.7, iRate requires ARC. If you wish to use iRate in a non-ARC project, just add the -fobjc-arc compiler flag to the iRate.m class. To do this, go to the Build Phases tab in your target settings, open the Compile Sources group, double-click iRate.m in the list and type -fobjc-arc into the popover. If you wish to convert your whole project to ARC, comment out the #error line in iRate.m, then run the Edit > Refactor > Convert to Objective-C ARC... tool in Xcode and make sure all files that you wish to use ARC for (including iRate.m) are checked. Thread Safety iRate uses threading internally to avoid blocking the UI, but none of the iRate external interfaces are thread safe and you should not call any methods or set any properties on iRate except from the main thread. Installation To install iRate into your app, drag the iRate.h, .m and .bundle files into your project. You can omit the .bundle if you are not interested in localised text. iRate typically requires no configuration at all and will simply run automatically, using the application's bundle ID to look the app ID up on the App Store. Note: If you have apps with matching bundle IDs on both the Mac and iOS app stores (even if they use different capitalisation), the lookup mechanism won't work, so you'll need to manually set the appStoreID property, which is a numeric ID that can be found in iTunes Connect after you set up an app. Also, if you are creating a sandboxed Mac app and your app does not request the network access permission then you will need to set the appStoreID because it cannot be retrieved from the iTunes service. If you do wish to customise iRate, the best time to do this is in your AppDelegate's -[application:didFinishLaunchingWithOptions:] method. Applying the configuration any later may not work, as the prompt may already have been shown by that point: #import "iRate.h" - (BOOL)application:(UIApplication *)application didFinishLaunchingWithOptions:(NSDictionary *)launchOptions { //configure iRate [iRate sharedInstance].daysUntilPrompt = 5; [iRate sharedInstance].usesUntilPrompt = 15; return YES; } Configuration To configure iRate, there are a number of properties of the iRate class that can alter the behaviour and appearance of iRate. These should be mostly self- explanatory, but they are documented below: @property (nonatomic, assign) NSUInteger appStoreID; This should match the iTunes app ID of your application, which you can get from iTunes connect after setting up your app. This value is not normally necessary and is generally only required if you have the aforementioned conflict between bundle IDs for your Mac and iOS apps, or in the case of Sandboxed Mac apps, if your app does not have network permission because it won't be able to fetch the appStoreID automatically using iTunes services. @property (nonatomic, assign) NSUInteger appStoreGenreID; This is the type of app, used to determine the default text for the rating dialog. This is set automatically by calling an iTunes service, so you shouldn't need to set it manually for most purposes. If you do wish to override this value, setting it to the iRateAppStoreGameGenreID constant will cause iRate to use the "game" version of the rating dialog, and setting it to any other value will use the "app" version of the rating dialog. @property (nonatomic, copy) NSString *appStoreCountry; This is the two-letter country code used to specify which iTunes store to check. It is set automatically from the device locale preferences, so shouldn't need to be changed in most cases. You can override this to point to the US store, or another specific store if you prefer, which may be a good idea if your app is only available in certain countries. @property (nonatomic, copy) NSString *applicationName; This is the name of the app displayed in the iRate alert. It is set automatically from the application's info.plist, but you may wish to override it with a shorter or longer version. @property (nonatomic, copy) NSString *applicationBundleID; This is the application bundle ID, used to retrieve the appStoreID and appStoreGenreID from iTunes. This is set automatically from the app's info.plist, so you shouldn't need to change it except for testing purposes. @property (nonatomic, assign) float daysUntilPrompt; This is the number of days the user must have had the app installed before they are prompted to rate it. The time is measured from the first time the app is launched. This is a floating point value, so it can be used to specify a fractional number of days (e.g. 0.5). The default value is 10 days. @property (nonatomic, assign) NSUInteger usesUntilPrompt; This is the minimum number of times the user must launch the app before they are prompted to rate it. This avoids the scenario where a user runs the app once, doesn't look at it for weeks and then launches it again, only to be immediately prompted to rate it. The minimum use count ensures that only frequent users are prompted. The prompt will appear only after the specified number of days AND uses has been reached. This defaults to 10 uses. @property (nonatomic, assign) NSUInteger eventsUntilPrompt; For some apps, launches are not a good metric for usage. For example the app might be a daemon that runs constantly, or a game where the user can't write an informed review until they've reached a particular level. In this case you can manually log significant events and have the prompt appear after a predetermined number of these events. Like the usesUntilPrompt setting, the prompt will appear only after the specified number of days AND events, however once the day threshold is reached, the prompt will appear if EITHER the event threshold OR uses threshold is reached. This defaults to 10 events. @property (nonatomic, assign) float usesPerWeekForPrompt; If you are less concerned with the total number of times the app is used, but would prefer to use the frequency of times the app is used, you can use the usesPerWeekForPrompt property to set a minimum threshold for the number of times the user must launch the app per week (on average) for the prompt to be shown. Note that this is the average since the app was installed, so if the user goes for a long period without running the app, it may throw off the average. The default value is zero. @property (nonatomic, assign) float remindPeriod; How long the app should wait before reminding a user to rate after they select the "remind me later" option (measured in days). A value of zero means the app will remind the user next launch. Note that this value supersedes the other criteria, so the app won't prompt for a rating during the reminder period, even if a new version is released in the meantime. This defaults to 1 day. @property (nonatomic, copy) NSString *messageTitle; The title displayed for the rating prompt. If you don't want to display a title then set this to @""; @property (nonatomic, copy) NSString *message; The rating prompt message. This should be polite and courteous, but not too wordy. If you don't want to display a message then set this to @""; @property (nonatomic, copy) NSString *updateMessage; This is a message to be used for users who have previously rated the app, encouraging them to re-rate. This allows you to customise the message for these users. If you do not supply a custom message for this case, the standard message will be used. @property (nonatomic, copy) NSString *cancelButtonLabel; The button label for the button to dismiss the rating prompt without rating the app. @property (nonatomic, copy) NSString *rateButtonLabel; The button label for the button the user presses if they do want to rate the app. @property (nonatomic, copy) NSString *remindButtonLabel; The button label for the button the user presses if they don't want to rate the app immediately, but do want to be reminded about it in future. Set this to @"" if you don't want to display the remind me button - e.g. if you don't have space on screen. @property (nonatomic, assign) BOOL useAllAvailableLanguages; By default, iRate will use all available languages in the iRate.bundle, even if used in an app that does not support localisation. If you would prefer to restrict iRate to only use the same set of languages that your application already supports, set this property to NO. (Defaults to YES). @property (nonatomic, assign) BOOL promptForNewVersionIfUserRated; Because iTunes ratings are version-specific, you ideally want users to rate each new version of your app. Users who really love your app may be willing to update their review for new releases. Set promptForNewVersionIfUserRated to YES, and iRate will prompt the user again each time they install an update until they decline to rate the app. If they decline, they will not be asked again. @property (nonatomic, assign) BOOL onlyPromptIfLatestVersion; Set this to NO to enabled the rating prompt to be displayed even if the user is not running the latest version of the app. This defaults to YES because that way users won't leave bad reviews due to bugs that you've already fixed, etc. @property (nonatomic, assign) BOOL onlyPromptIfMainWindowIsAvailable; This setting is applicable to Mac OS only. By default, on Mac OS the iRate alert is displayed as sheet on the main window. Some applications do not have a main window, so this approach doesn't work. For such applications, set this property to NO to allow the iRate alert to be displayed as a regular modal window. @property (nonatomic, assign) BOOL promptAtLaunch; Set this to NO to disable the rating prompt appearing automatically when the application launches or returns from the background. The rating criteria will continue to be tracked, but the prompt will not be displayed automatically while this setting is in effect. You can use this option if you wish to manually control display of the rating prompt. @property (nonatomic, assign) BOOL verboseLogging; This option will cause iRate to send detailed logs to the console about the prompt decision process. If your app is not correctly prompting for a rating when you would expect it to, this will help you figure out why. Verbose logging is enabled by default on debug builds, and disabled on release and deployment builds. @property (nonatomic, assign) BOOL previewMode; If set to YES, iRate will always display the rating prompt on launch, regardless of how long the app has been in use or whether it's the latest version (unless you have explicitly disabled the promptAtLaunch option). Use this to proofread your message and check your configuration is correct during testing, but disable it for the final release (defaults to NO). @property (nonatomic, assign) BOOL useUIAlertControllerIfAvailable; By default, iRate will use UIAlertView on iOS to display the rating prompt. UIAlertView was deprecated in iOS8 and replaced by UIAlertController. Unfortunately, unlike UIAlertView, presenting an alert with UIAlertController interferes with the ability of the app to display other controllers, and since iRate could theoretically display an alert at any point during the app's lifetime, it might clash with the app attempting to present another view controller. For this reason, use of UIAlertController is disabled by default. You should only set this property to YES if you are certain that it won't clash with your app logic (e.g, if you have disabled automatic rating prompts, or if your app doesn't use any modal view controllers). @property (nonatomic, assign) BOOL useSKStoreReviewControllerIfAvailable; By default, iRate will use the SKStoreReviewController to request reviews on iOS 10.3 and above. To disable this, set useSKStoreReviewControllerIfAvailable to NO. Advanced properties If the default iRate behaviour doesn't meet your requirements, you can implement your own by using the advanced properties, methods and delegate. The properties below let you access internal state and override it: @property (nonatomic, strong) NSURL *ratingsURL; The URL that the app will direct the user to so they can write a rating for the app. This is set to the correct value for the given platform automatically. On iOS 6 and below this takes users directly to the ratings page, but on iOS 7 and Mac OS it takes users to the main app page (if there is a way to directly link to the ratings page on those platforms, I've yet to find it). If you are implementing your own rating prompt, you should probably use the openRatingsPageInAppStore method instead, especially on Mac OS, as the process for opening the Mac app store is more complex than merely opening the URL. @property (nonatomic, strong) NSDate *firstUsed; The first date on which the user launched the current version of the app. This is used to calculate whether the daysUntilPrompt criterion has been met. @property (nonatomic, strong) NSDate *lastReminded; The date on which the user last requested to be reminded to rate the app later. @property (nonatomic, assign) NSUInteger usesCount; The number of times the current version of the app has been used (launched). @property (nonatomic, assign) NSUInteger eventCount; The number of significant application events that have been recorded since the current version was installed. This is incremented by the logEvent method, but can also be manipulated directly. Check out the Events Demo to see how this os used. @property (nonatomic, readonly) float usesPerWeek; The average number of times per week that the current version of the app has been used (launched). @property (nonatomic, assign) BOOL declinedThisVersion; This flag indicates whether the user has declined to rate the current version (YES) or not (NO). This is not currently used by the iRate prompting logic, but may be useful for implementing your own logic. @property (nonatomic, assign) BOOL declinedAnyVersion; This flag indicates whether the user has declined to rate any previous version of the app (YES) or not (NO). iRate will not prompt the user automatically if this is set to YES. @property (nonatomic, assign) BOOL ratedThisVersion; This flag indicates whether the user has already rated the current version (YES) or not (NO). @property (nonatomic, readonly) BOOL ratedAnyVersion; This (readonly) flag indicates whether the user has previously rated any version of the app (YES) or not (NO). @property (nonatomic, assign) id<iRateDelegate> delegate; An object you have supplied that implements the iRateDelegate protocol, documented below. Use this to detect and/or override iRate's default behaviour. This defaults to the App Delegate, so if you are using your App Delegate as your iRate delegate, you don't need to set this property. Methods Besides configuration, iRate has the following methods: - (BOOL)shouldPromptForRating; Returns YES if the prompt criteria have been met, and NO if they have not. You can use this to decide when to display a rating prompt if you have disabled the automatic display at app launch. Calling this method will not call the iRateShouldPromptForRating delegate method. - (void)promptForRating; This method will immediately trigger the rating prompt without checking that the app store is available, and without calling the iRateShouldPromptForRating delegate method. Note that this method depends on the appStoreID and applicationGenre properties, which are only retrieved after polling the iTunes server, so if you intend to call this method directly, you will need to set these properties yourself beforehand, or use the promptIfNetworkAvailable method instead. - (void)promptIfNetworkAvailable; This method will check if the app store is available, and if it is, it will display the rating prompt to the user. The iRateShouldPromptForRating delegate method will be called before the alert is shown, so you can intercept it. Note that if your app is sandboxed and does not have the network access permission, this method will ignore the network availability status, however in this case you will need to manually set the appStoreID or iRate cannot function. - (void)promptIfAllCriteriaMet; This method will check if all prompting criteria have been met, and if the app store is available, and if it is, it will display the rating prompt to the user. The iRateShouldPromptForRating delegate method will be called before the alert is shown, so you can intercept it. - (void)openRatingsPageInAppStore; This method skips the user alert and opens the application ratings page in the Mac or iPhone app store, depending on which platform iRate is running on. This method does not perform any checks to verify that the machine has network access or that the app store is available. It also does not call the -iRateShouldOpenAppStore delegate method. You should use this method to open the ratings page instead of the ratingsURL property, as the process for launching the app store is more complex than merely opening the URL in many cases. Note that this method depends on the appStoreID which is only retrieved after polling the iTunes server. If you call this method without first doing an update check, you will either need to set the appStoreID property yourself beforehand, or risk that the method may take some time to make a network call, or fail entirely. On success, this method will call the -iRateDidOpenAppStore delegate method. On Failure it will call the -iRateCouldNotConnectToAppStore: delegate method. - (void)logEvent:(BOOL)deferPrompt; This method can be called from anywhere in your app (after iRate has been configured) and increments the iRate significant event count. When the predefined number of events is reached, the rating prompt will be shown. The optional deferPrompt parameter is used to determine if the prompt will be shown immediately (NO) or if the app will wait until the next launch (YES). - (void)remindLater; This method resets the reminder period. Delegate methods The iRateDelegate protocol provides the following methods that can be used intercept iRate events and override the default behaviour. All methods are optional. - (void)iRateCouldNotConnectToAppStore:(NSError *)error; This method is called if iRate cannot connect to the App Store, usually because the network connection is down. This may also fire if your app does not have access to the network due to Sandbox permissions, in which case you will need to manually set the appStoreID so that iRate can still function. - (void)iRateDidDetectAppUpdate; This method is called if iRate detects that the application has been updated since the last time it was launched. - (BOOL)iRateShouldPromptForRating; This method is called immediately before the rating prompt is displayed to the user. You can use this method to implement custom prompt logic in addition to the standard rules. You can also use this method to block the standard prompt alert and display the rating prompt in a different way, or bypass it altogether. - (void)iRateDidPromptForRating; This method is called immediately before the rating prompt is displayed. This is useful if you use analytics to track what percentage of users see the prompt and then go to the app store. This can help you fine tune the circumstances around when/how you show the prompt. - (void)iRateUserDidAttemptToRateApp; This is called when the user pressed the rate button in the rating prompt. This is useful if you want to log user interaction with iRate. This method is only called if you are using the standard iRate alert view prompt and will not be called automatically if you provide a custom rating implementation or call the openRatingsPageInAppStore method directly. - (void)iRateUserDidDeclineToRateApp; This is called when the user declines to rate the app. This is useful if you want to log user interaction with iRate. This method is only called if you are using the standard iRate alert view prompt and will not be called automatically if you provide a custom rating implementation. - (void)iRateUserDidRequestReminderToRateApp; This is called when the user asks to be reminded to rate the app. This is useful if you want to log user interaction with iRate. This method is only called if you are using the standard iRate alert view prompt and will not be called automatically if you provide a custom rating implementation. - (BOOL)iRateShouldOpenAppStore; This method is called immediately before iRate attempts to open the app store. Return NO if you wish to implement your own ratings page display logic. - (void)iRateDidOpenAppStore; This method is called immediately after iRate opens the app store. Localisation The default strings for iRate are already localised for many languages. By default, iRate will use all the localisations in the iRate.bundle even in an app that is not localised, or which is only localised to a subset of the languages that iRate supports. The iRate strings keys are: static NSString *const iRateMessageTitleKey = @"iRateMessageTitle"; static NSString *const iRateAppMessageKey = @"iRateAppMessage"; static NSString *const iRateGameMessageKey = @"iRateGameMessage"; static NSString *const iRateUpdateMessageKey = @"iRateUpdateMessage"; static NSString *const iRateCancelButtonKey = @"iRateCancelButton"; static NSString *const iRateRemindButtonKey = @"iRateRemindButton"; static NSString *const iRateRateButtonKey = @"iRateRateButton"; If you would prefer iRate to only use the localisations that are enabled in your application (so that if your app only supports English, French and Spanish, iRate will automatically be localised for those languages, but not for German, even though iRate includes a German language file), set the useAllAvailableLanguages option to NO. It is not recommended that you modify the strings files in the iRate.bundle, as it will complicate updating to newer versions of iRate. The exception to this is if you would like to submit additional languages or improvements or corrections to the localisations in the iRate project on github (which are greatly appreciated). If you want to add an additional language for iRate in your app without submitting them back to the github project, you can add these strings directly to the appropriate Localizable.strings file in your project folder. If you wish to replace some or all of the default iRate strings, the simplest option is to copy just those strings into your own Localizable.strings file and then modify them. iRate will automatically use strings in the main application bundle in preference to the ones in the iRate bundle so you can override any string in this way. If you do not want to use any of the default localisations, you can omit the iRate.bundle altogether. Note that if you only want to support a subset of languages that iRate supports, it is not necessary to delete the other strings files from iRate.bundle - just set useAllAvailableLanguages to NO, and iRate will only use the languages that your app already supports. The old method of overriding iRate's default strings by using individual setter methods (see below) is still supported, however the recommended approach is now to add those strings to your project's Localizable.strings file, which will be detected automatically by iRate. + (void)initialize { //overriding the default iRate strings [iRate sharedInstance].messageTitle = NSLocalizedString(@"Rate MyApp", @"iRate message title"); [iRate sharedInstance].message = NSLocalizedString(@"If you like MyApp, please take the time, etc", @"iRate message"); [iRate sharedInstance].cancelButtonLabel = NSLocalizedString(@"No, Thanks", @"iRate decline button"); [iRate sharedInstance].remindButtonLabel = NSLocalizedString(@"Remind Me Later", @"iRate remind button"); [iRate sharedInstance].rateButtonLabel = NSLocalizedString(@"Rate It Now", @"iRate accept button"); } Example Projects When you build and run the basic Mac or iPhone example project for the first time, it will show an alert asking you to rate the app. This is because the previewMode option is set. Disable the previewMode option and play with the other settings to see how the app behaves in practice. Advanced Example The advanced example demonstrates how you might implement a completely bespoke iRate interface using the iRateDelegate methods. Automatic prompting is disabled and instead the user can opt to rate the app by pressing the "Rate this app" button. When pressed, the app first checks that the app store is available (it may not be if the computer has no Internet connection or apple.com is down), and then launches the Mac App Store. The example is for Mac OS, but the same principle can be applied on iOS. Release Notes Version 1.12.2 Marked as deprecated Version 1.12.1 Fixed problems compiling on older Xcode versions due to SKStoreReviewController Version 1.12 Added support for SKStoreReviewController on iOS 10.3+ (thanks @EpicDraws!) Added Catalan, Hungarian, Croatian and Bosnian localizations Fixed random crash due to misconfigured NSURLRequest Version 1.11.7 Updated for iOS 10 and Xcode 8 Fixed checkForConnectivity crash Added Finnish language support Lowered Carthage deployment target to 8.0 Version 1.11.6 Fixed compatibility with iOS 7 Version 1.11.5 Now uses https URLs to avoid issues with App Transport Security Fixed Swift crashes due to nonstandard delegate implementation Added special case for Gibraltar Fixed warnings on latest Xcode Added Carthage support Added Taiwan Chinese (zh-TW) localization Better Italian localisation Exposed remindLater method Version 1.11.4 Added fix for possible Apple rejection issue to do with canOpenURL: Added fix for nil locale issue Added Macedonian translation Version 1.11.3 Added useUIAlertControllerIfAvailable option Disabled UIAlertController by default as it may interfere with in-app controller logic Version 1.11.2 Fixed critical bug in alert button handling on iOS 7 and earlier Version 1.11.1 Fixed deprecation warnings on Mac OS X 10.10 Yosemite Improved Urdu translation Version 1.11 Added promptIfCriteriaMet convenience method Added NSNotificationCenter notifications as alternative to delegate Now uses UIAlertController instead of UIAlertView if available Fixed compiler error when building with Xcode 6 Fixed error in Thai translation Fixed potential crash on iOS 6 Improved Farsi translation Now fully compatible with Swift Added Swift Demo example Version 1.10.3 Fixed another bug in the rating reset logic after upgrade Improved Turkish translation Version 1.10.2 Fixed bug where app would never prompt for rating after an upgrade if it had not already done so Improved italian localization Version 1.10.1 Fixed serious bug that prevents rating prompt appearing for any new apps Fixed issue where bad response from iTunes would be cached indefinitely Version 1.10 Now links directly to review page again on iOS 7.1 + (Apple has fixed support) No longer interrupts rating popups for the full daysUntilPrompt period after an app update Added promptForNewVersionIfUserRated option to re-prompt users who have previous rated (off by default) Added updateMessage property for use with promptForNewVersionIfUserRated option Fixed typo in French translation Version 1.9.3 No longer logs warning if app ID is not found, unless in verbose mode Minor translation fix for Vietnamese Version 1.9.2 Added Bengali, Farsi, Hindi, Punjabi, Thai and Vietnamese translations Version 1.9.1 Fixed problem with fetching app ID when device region is set to Europe Version 1.9 iRate will no longer ask users to rate the app again each version If the user selects "No, Thanks", they will now never be asked again Removed the promptAgainEachVersion option Version 1.8.3 Stricter warning compliance Now uses macros to avoid generating warnings when imported into apps with even stricter warning settings Version 1.8.2 Fixed issue where checkForConnectivityInBackground could be called on main thread, blocking user interaction Version 1.8.1 Added iRateDidOpenAppStore delegate method Language selection now works correctly if the user has an unsupported language Removed all support for StoreKit, as Apple have disabled the StoreKit rating panel Calling openRatingsPageInAppStore will now look up appStoreID automatically if not already known Improved error messaging when using iRate on the iOS Simulator Added Greek and Slovenian localizations Version 1.8 App store link works on iOS 7 (had to link to app home page instead of directly to reviews page for now - hopefully an alternative direct link can be found) Now uses NSJSONSerializer if available (iOS 4.x will still use the old parser) No longer requires StoreKit by default (see README for details) Fixed Czech and Austrian German locales for iOS 7 Removed disableAlertViewResizing property (no longer needed) Improved Czech translation Improved French translation Urdu support Fixed bug in alertview resizing for iOS 6 and below Now complies with the -Wextra warning level Version 1.7.5 Improved Arabic translation Improved podspec file Removed .DS_Store file Version 1.7.4 Added Arabic translation Improved French translation Added delegate method for tracking when prompt gets shown Version 1.7.3 Added Slovak, Czech and Austrian translations Fixed some bugs in Cancel/Remind button disabling logic Added podspec file Version 1.7.2 Added dutch translation iRate now displays the StoreKit product view controller correctly even if a modally presented view controller has been displayed Version 1.7.1 Fixed deprecation warning when targeting iOS6 as the base target Added iRateDidPresentStoreKitModal and iRateDidDismissStoreKitModal delegate methods Added additional error logging if StoreKit fails to load product info Added Ukrainian translation Version 1.7 On iOS 6, iRate can now use the StoreKit APIs to display the product page directly within the app. iRate now requires the StoreKit framework on iOS iRate now requires ARC. To use iRate in a non-ARC project, follow the instructions in the README file. Dropped support for 32-bit Macs running Snow Leopard Added Swedish translation Version 1.6.2 Fixed broken ratings URL (Apple changed it) Added Danish translation Version 1.6.1 Fixed typo in Italian strings file Version 1.6 Added new localisation system (see README for details) Added usesPerWeekForPrompt setting Fixed deprecation warning in iOS 6 Improved Spanish translation Improved German translation Version 1.5.3 Corrected minor spelling mistake in German translation Version 1.5.2 Restored App Store deep link on iOS6 (didn't work in beta, but now does) Added promptAgainForEachNewVersion option to enable/disable prompting each time the app is updated Added verboseLogging option to make it easier to diagnose why a new version isn't being correctly detected Renamed debug property to previewMode as this better describes its function Add Simplified Chinese localisation Version 1.5.1 Fixed crash on iOS 4.x and Mac OS 10.6.x when compiled using Xcode 4.4 Version 1.5 Added support for iOS6. Currently it does not appear to be possible to take users directly to the ratings page on iOS6, but iRate will now at least open the app store on the app page without an error. Fixed bug in the app store country selection logic Changed appStoreGenre to appStoreGenreID, as this is not locale-specific Version 1.4.9 Added support for sandboxed Mac App Store apps with no network access Updated ARC Helper library Version 1.4.8 Added explicit 60-second timeout for connectivity check iRate will now no longer spawn multiple download threads if closed and re-opened whilst performing a check Added Portuguese translation Version 1.4.7 Fixed a bug where advanced properties set in the delegate methods might be subsequently overridden by iRate Added Events Demo example Version 1.4.6 Fixed odd glitch where shaking device would cause UIAlertview to slowly shrink Added disableAlertViewResizing option (see README for details) Added Resizing Disabled example project Added Korean translation Version 1.4.5 Improved German, Spanish, Japanese, Russian and Polish translations Added onlyPromptIfMainWindowIsAvailable option Version 1.4.4 Added Turkish localisation Improved German translation Fixed alert layout for long app names Version 1.4.3 It is now possible again to use debug to test the iRate message for apps that are not yet on the App Store. Version 1.4.2 Added Hebrew localisation Fixed issue with UIAlertView label resizing Fixed some compiler warnings Version 1.4.1 Added logic to prevent UIAlertView collapsing in landscape mode Added Russian, Polish and Traditional Chinese localisations Improved Japanese localisation Now handles nil cancel button text correctly Version 1.4 Included localisation for French, German, Italian, Spanish and Japanese iRate is now completely zero-config in most cases! It is no longer necessary to set the app store ID in most cases iRate default text now uses "playing" instead of "using" for games iRate delegate now defaults to App Delegate unless otherwise specified By default, iRate no longer prompts the user to rate the app unless they are running the latest version Version 1.3.5 Fixed bug introduced in 1.3.4 where remind button would not appear on iOS Version 1.3.4 Fixed compiler warning Added iRateDidDetectAppUpdate delegate method Added ARC Test example Version 1.3.3 Added missing ivar required for 32-bit Mac OS builds. Version 1.3.2 Added logic to prevent multiple prompts from being displayed if user fails to close one prompt before the next is due to be opened. Added workaround for change in UIApplicationWillEnterForegroundNotification implementation in iOS5 Version 1.3.1 Added automatic support for ARC compile targets Now requires Apple LLVM 3.0 compiler target Version 1.3 Added additional delegate methods to facilitate logging Renamed disabled property to promptAtLaunch for clarity Version 1.2.3 iRate now uses CFBundleDisplayName for the application name (if available) Reorganised examples Version 1.2.2 Fixed misspelled delegate method Fixed bug in advanced Mac project where rating prompt was displayed automatically even if button was not pressed Removed unneeded project files Version 1.2.1 Exposed the shouldPromptForRating method to make it easier to control when rating prompt is displayed Increased MAC_APP_STORE_REFRESH_DELAY to 5 seconds to support older machines Version 1.2 Added delegate and additional accessor properties for custom behaviour Added advanced example project to demonstrate use of the delegate protocol Version 1.1 Now compatible with iOS 3.x Fixed incorrect iPhone review URL Version 1.0 Initial release.

 # # # # # # # # # # # # # # # # # # # #
 Repository: rvm/rvm, index: 1849, word count: 7344 
 # # # # # # # # # # # # # # # # # # # #

A utility for arming (creating) many bees (micro EC2 instances) to attack (load test) targets (web applications).h4. Bees with Machine Guns! A utility for arming (creating) many bees (micro EC2 instances) to attack (load test) targets (web applications). Also, retribution for "this shameful act":http://kottke.org/10/10/tiny-catapult-for-throwing-pies-at-bees against a proud hive. h2. Dependencies Python 2.6 - 3.6 boto paramiko h2. Installation for users pip install https://github.com/newsapps/beeswithmachineguns/archive/master.zip h2. Installation for developers (w/ virtualenv + virtualenvwrapper) git clone git://github.com/newsapps/beeswithmachineguns.git cd beeswithmachineguns mkvirtualenv --no-site-packages beesenv easy_install pip pip install -r requirements.txt h2. Configuring AWS credentials Bees uses boto to communicate with EC2 and thus supports all the same methods of storing credentials that it does. These include declaring environment variables, machine-global configuration files, and per-user configuration files. You can read more about these options on "boto's configuration page":http://code.google.com/p/boto/wiki/BotoConfig. At minimum, create a .boto file in your home directory with the following contents: [Credentials] aws_access_key_id = aws_secret_access_key = The credentials used must have sufficient access to EC2. Make sure the .boto file is only accessible by the current account: chmod 600 .boto h2. Usage A typical bees session looks something like this: bees up -s 4 -g public -k frakkingtoasters bees attack -n 10000 -c 250 -u http://www.ournewwebbyhotness.com/ bees down A bees session where this is being called from a python file, while specifying content type and a payload file. This is a working example, all of these objects exist in the us-east-1 region. import bees import json sOptions = '{"post_file":"data.json","contenttype":"application/json"}' options = json.loads(sOptions) bees.up(1,'bees-sg','us-east-1b','ami-5d155d37','m3.medium','ubuntu','commerce-bees','subnet-b12880e8') bees.attack('',2,2,**options) bees.down() In this case the data.json is a simple json file, mind the path. This spins up 4 servers in security group 'public' using the EC2 keypair 'frakkingtoasters', whose private key is expected to reside at ~/.ssh/frakkingtoasters.pem. Note: the default EC2 security group is called 'default' and by default it locks out SSH access. I recommend creating a 'public' security group for use with the bees and explicitly opening port 22 on that group. It then uses those 4 servers to send 10,000 requests, 250 at a time, to attack OurNewWebbyHotness.com. Lastly, it spins down the 4 servers. Please remember to do this--we aren't responsible for your EC2 bills. If you wanted 3 agents requesting url A and one requesting url B, your attack would look as follows (empty url -> use previous): bees attack -n 10000 -c 250 -u 'http://url.a,,,http://url.b' For complete options type: bees -h h2. Introduction to additions: h4. Additions contributed Hurl integration and multi regional testing. hurl is an http server load tester similar to ab/siege/weighttp/wrk with support for multithreading, parallelism, ssl, url ranges, and an api-server for querying the running performance statistics. hurl is primarily useful for benchmarking http server applications. For more information about hurl please visit https://github.com/VerizonDigital/hlx Multi regional testing was added so user can call up multiple bees from different regions simultaneously. Users have the ability to up, attack, and down instances from single command. regions.json file is supplied which contains public ami images with hurl pre installed for all regions. What kind of changes were made that's different from the old? Instead of writing bees information into a single ~/.bees file, each zone recognized in arguments creates a new unique bees file. Bees.py was modified to read these files. Up, attack, and down functions are run with threads. example .bees files in user home directory $ ls ~/.bees* | xargs -0 basename .bees.ap-southeast-1b .bees.eu-west-1b .bees.us-west-2b h4. Motivation Having the ability to generate a lot of HTTPS requests from many different regions around the world allows us to better test our platforms and services. This is also real helpful when there are tools that need to be tested for such things as location of requests. h4. Hurl Usage h4. bees up Command line arguments are still the same however to add multiple zones with multiple amis, the values must be comma delimited. The ami and zones must also be in same order for it to work. So for example -i ami-zone1,ami-zone2,ami-zone3 -z zone1,zone2,zone3. ./bees up -s 2 -k bees -g bees2 -l ubuntu -i ami-9342c0e0,ami-fd489d 9e,ami-e8c93e88 -z eu-west-1b,ap-southeast-1b,us-west-2b h4. bees attack In order to use the hurl platform, --hurl or -j must be supplied. Attacks will run concurrently and return a summarized output. The output is summarized per region. More information can be seen if user supplies the -o, --long_output options. ./bees attack --hurl -u $testurl -S20 -M1000 -H "Accept : text/html" h4. bees down Bringing down bees is the same and will bring down all bees for all regions ./bees down regions used: eu-west-1b,ap-southeast-1b,us-west-2b Some options were added to work with hurl h4. Examples $ ./bees --help Usage: bees COMMAND [options] Bees with Machine Guns A utility for arming (creating) many bees (small EC2 instances) to attack (load test) targets (web applications). commands: up Start a batch of load testing servers. attack Begin the attack on a specific url. down Shutdown and deactivate the load testing servers. report Report the status of the load testing servers. Options: -h, --help show this help message and exit up: In order to spin up new servers you will need to specify at least the -k command, which is the name of the EC2 keypair to use for creating and connecting to the new servers. The bees will expect to find a .pem file with this name in ~/.ssh/. Alternatively, bees can use SSH Agent for the key. -k KEY, --key=KEY The ssh key pair name to use to connect to the new servers. -s SERVERS, --servers=SERVERS The number of servers to start (default: 5). -g GROUP, --group=GROUP The security group(s) to run the instances under (default: default). -z ZONE, --zone=ZONE The availability zone to start the instances in (default: us-east-1d). -i INSTANCE, --instance=INSTANCE The instance-id to use for each server from (default: ami-ff17fb96). -t TYPE, --type=TYPE The instance-type to use for each server (default: t1.micro). -l LOGIN, --login=LOGIN The ssh username name to use to connect to the new servers (default: newsapps). -v SUBNET, --subnet=SUBNET The vpc subnet id in which the instances should be launched. (default: None). -b BID, --bid=BID The maximum bid price per spot instance (default: None). attack: Beginning an attack requires only that you specify the -u option with the URL you wish to target. -u URL, --url=URL URL of the target to attack. -K KEEP_ALIVE, --keepalive=KEEP_ALIVE Keep-Alive connection. -p POST_FILE, --post-file=POST_FILE The POST file to deliver with the bee's payload. -m MIME_TYPE, --mime-type=MIME_TYPE The MIME type to send with the request. -n NUMBER, --number=NUMBER The number of total connections to make to the target (default: 1000). -C COOKIES, --cookies=COOKIES Cookies to send during http requests. The cookies should be passed using standard cookie formatting, separated by semi-colons and assigned with equals signs. -Z CIPHERS, --ciphers=CIPHERS Openssl SSL/TLS cipher name(s) to use for negotiation. Passed directly to ab's -Z option. ab-only. -c CONCURRENT, --concurrent=CONCURRENT The number of concurrent connections to make to the target (default: 100). -H HEADERS, --headers=HEADERS HTTP headers to send to the target to attack. Multiple headers should be separated by semi-colons, e.g header1:value1;header2:value2 -e FILENAME, --csv=FILENAME Store the distribution of results in a csv file for all completed bees (default: ''). -P CONTENTTYPE, --contenttype=CONTENTTYPE ContentType header to send to the target of the attack. -S SECONDS, --seconds=SECONDS hurl only: The number of total seconds to attack the target (default: 60). -X VERB, --verb=VERB hurl only: Request command -HTTP verb to use -GET/PUT/etc. Default GET -M RATE, --rate=RATE hurl only: Max Request Rate. -a THREADS, --threads=THREADS hurl only: Number of parallel threads. Default: 1 -f FETCHES, --fetches=FETCHES hurl only: Num fetches per instance. -d TIMEOUT, --timeout=TIMEOUT hurl only: Timeout (seconds). -E SEND_BUFFER, --send_buffer=SEND_BUFFER hurl only: Socket send buffer size. -F RECV_BUFFER, --recv_buffer=RECV_BUFFER hurl only: Socket receive buffer size. -T TPR, --tpr=TPR The upper bounds for time per request. If this option is passed and the target is below the value a 1 will be returned with the report details (default: None). -R RPS, --rps=RPS The lower bounds for request per second. If this option is passed and the target is above the value a 1 will be returned with the report details (default: None). -A basic_auth, --basic_auth=basic_auth BASIC authentication credentials, format auth- username:password (default: None). -j, --hurl use hurl -o, --long_output display hurl output -L, --responses_per hurl only: Display http(s) response codes per interval instead of request statistics A bringing up bees example $ ./bees up -s 2 -k bees -g bees2 -l ubuntu -i ami-9342c0e0,ami-fd489d 9e,ami-e8c93e88 -z eu-west-1b,ap-southeast-1b,us-west-2b Connecting to the hive. GroupId found: bees2 Placement: eu-west-1b Attempting to call up 2 bees. Connecting to the hive. GroupId found: bees2 Placement: ap-southeast-1b Attempting to call up 2 bees. Connecting to the hive. GroupId found: bees2 Placement: us-west-2b Attempting to call up 2 bees. Waiting for bees to load their machine guns... Waiting for bees to load their machine guns... . Waiting for bees to load their machine guns... . . . . . . . . . . . . Bee i-5568c1d9 is ready for the attack. Bee i-5668c1da is ready for the attack. Bee i-2cf8aba2 is ready for the attack. The swarm has assembled 2 bees. Bee i-2bf8aba5 is ready for the attack. The swarm has assembled 2 bees. Bee i-d05a6c08 is ready for the attack. Bee i-d15a6c09 is ready for the attack. The swarm has assembled 2 bees. $ ./bees report Read 2 bees from the roster: eu-west-1b Bee i-5568c1d9: running @ 54.194.192.20 Bee i-5668c1da: running @ 54.194.197.233 Read 2 bees from the roster: ap-southeast-1b Bee i-2cf8aba2: running @ 52.77.228.132 Bee i-2bf8aba5: running @ 52.221.250.224 Read 2 bees from the roster: us-west-2b Bee i-d05a6c08: running @ 54.187.100.142 Bee i-d15a6c09: running @ 54.201.177.125 A bees attack example $ ./bees attack --hurl -u $testurl -S20 -M1000 -H "Accept : text/html" eu-west-1b Read 2 bees from the roster: eu-west-1b Connecting to the hive. Assembling bees. ap-southeast-1b Read 2 bees from the roster: ap-southeast-1b Connecting to the hive. Assembling bees. us-west-2b Read 2 bees from the roster: us-west-2b Connecting to the hive. Assembling bees. Each of 2 bees will fire 500 rounds, 50 at a time. Stinging URL so it will be cached for the attack. Organizing the swarm. Bee 0 is joining the swarm. Bee 1 is joining the swarm. Each of 2 bees will fire 500 rounds, 50 at a time. Stinging URL so it will be cached for the attack. Organizing the swarm. Bee 0 is joining the swarm. Bee 1 is joining the swarm. Bee 1 is firing her machine gun. Bang bang! Bee 0 is firing her machine gun. Bang bang! Each of 2 bees will fire 500 rounds, 50 at a time. Stinging URL so it will be cached for the attack. Organizing the swarm. Bee 0 is joining the swarm. Bee 1 is joining the swarm. Bee 1 is firing her machine gun. Bang bang! Bee 0 is firing her machine gun. Bang bang! Bee 0 is firing her machine gun. Bang bang! Bee 1 is firing her machine gun. Bang bang! Offensive complete. Summarized Results Total bytes: 32806393 Seconds: 20 Connect-ms-max: 8.751000 1st-resp-ms-max: 288.797000 1st-resp-ms-mean: 41.120797 Fetches/sec mean: 881.607553 connect-ms-min: 0.000000 Total fetches: 35274 bytes/sec mean: 819934.329261 end2end-ms-min mean: 7.538500 mean-bytes-per-conn: 930.044494 connect-ms-mean: 0.022659 Response Codes: 2xx: 372 3xx: 0 4xx: 34802 5xx: 0 Mission Assessment: Target crushed bee offensive. The swarm is awaiting new orders. Offensive complete. Summarized Results Total bytes: 7820249 Seconds: 20 Connect-ms-max: 198.442000 1st-resp-ms-max: 799.969000 1st-resp-ms-mean: 183.104679 Fetches/sec mean: 265.758560 connect-ms-min: 0.000000 Total fetches: 10633 bytes/sec mean: 195457.360660 end2end-ms-min mean: 167.372500 mean-bytes-per-conn: 735.470800 connect-ms-mean: 1.685486 Response Codes: 2xx: 423 3xx: 0 4xx: 10110 5xx: 0 Mission Assessment: Target crushed bee offensive. The swarm is awaiting new orders. Offensive complete. Summarized Results Total bytes: 26038521 Seconds: 20 Connect-ms-max: 15.233000 1st-resp-ms-max: 401.819000 1st-resp-ms-mean: 42.217669 Fetches/sec mean: 873.584785 connect-ms-min: 0.000000 Total fetches: 34953 bytes/sec mean: 650784.075365 end2end-ms-min mean: 11.345000 mean-bytes-per-conn: 744.958106 connect-ms-mean: 0.037327 Response Codes: 2xx: 411 3xx: 0 4xx: 34442 5xx: 0 Mission Assessment: Target crushed bee offensive. The swarm is awaiting new orders. A bees attack example with --long_output $ ./bees attack --hurl -u $testurl -S20 -M1000 -H "Accept : text/html" --long_output eu-west-1b Read 2 bees from the roster: eu-west-1b Connecting to the hive. Assembling bees. ap-southeast-1b Read 2 bees from the roster: ap-southeast-1b Connecting to the hive. Assembling bees. us-west-2b Read 2 bees from the roster: us-west-2b Connecting to the hive. Assembling bees. Each of 2 bees will fire 500 rounds, 50 at a time. Stinging URL so it will be cached for the attack. Organizing the swarm. Bee 0 is joining the swarm. Bee 1 is joining the swarm. Each of 2 bees will fire 500 rounds, 50 at a time. Stinging URL so it will be cached for the attack. Organizing the swarm. Bee 0 is joining the swarm. Bee 1 is joining the swarm. Each of 2 bees will fire 500 rounds, 50 at a time. Stinging URL so it will be cached for the attack. Organizing the swarm. Bee 0 is joining the swarm. Bee 1 is joining the swarm. Bee 0 is firing her machine gun. Bang bang! Bee 1 is firing her machine gun. Bang bang! Bee 1 is firing her machine gun. Bang bang! Bee 0 is firing her machine gun. Bang bang! Bee 0 is firing her machine gun. Bang bang! Bee 1 is firing her machine gun. Bang bang! hurl http://can.192bf.transactcdn.com/00192BF/test.html/config.workflow:ContinueWarranty -p 50 -H "Accept : text/html" -H "Content-Type : text/plain" -o /tmp/tmp.aAojMFs3ob -l 20 -A 1000 -j i-fb457323 ec2-54-186-204-52.us-west-2.compute.amazonaws.com Running 1 threads 50 parallel connections per thread with 1 reqests per connection +-----------/-----------+-----------+-----------+--------------+-----------+-------------+-----------+ | Cmpltd / Total | IdlKil | Errors | kBytes Recvd | Elapsed | Req/s | MB/s | +-----------/-----------+-----------+-----------+--------------+-----------+-------------+-----------+ | 0 / 0 | 0 | 0 | 0.00 | 0.50s | 0.00s | 0.00s | | 505 / 505 | 0 | 0 | 313.02 | 1.00s | 1007.98s | 0.61s | | 970 / 970 | 0 | 0 | 633.81 | 1.50s | 930.00s | 0.63s | | 1442 / 1442 | 0 | 0 | 961.08 | 2.00s | 944.00s | 0.64s | | 1900 / 1900 | 0 | 0 | 1276.81 | 2.50s | 916.00s | 0.62s | | 2376 / 2376 | 0 | 0 | 1606.85 | 3.00s | 952.00s | 0.64s | | 2835 / 2835 | 0 | 0 | 1922.85 | 3.50s | 918.00s | 0.62s | | 3310 / 3310 | 0 | 0 | 2252.20 | 4.00s | 950.00s | 0.64s | | 3769 / 3769 | 0 | 0 | 2568.62 | 4.50s | 918.00s | 0.62s | | 4243 / 4243 | 0 | 0 | 2897.27 | 5.00s | 946.11s | 0.64s | | 4706 / 4706 | 0 | 0 | 3215.84 | 5.50s | 926.00s | 0.62s | | 5178 / 5178 | 0 | 0 | 3543.10 | 6.00s | 944.00s | 0.64s | | 5641 / 5641 | 0 | 0 | 3862.09 | 6.50s | 926.00s | 0.62s | | 6114 / 6114 | 0 | 0 | 4190.05 | 7.00s | 946.00s | 0.64s | | 6581 / 6581 | 0 | 0 | 4511.81 | 7.50s | 934.00s | 0.63s | | 7053 / 7053 | 0 | 0 | 4839.07 | 8.00s | 944.00s | 0.64s | | 7514 / 7514 | 0 | 0 | 5156.25 | 8.50s | 922.00s | 0.62s | | 7975 / 7975 | 0 | 0 | 5475.88 | 9.00s | 920.16s | 0.62s | | 8450 / 8450 | 0 | 0 | 5803.62 | 9.50s | 950.00s | 0.64s | | 8910 / 8910 | 0 | 0 | 6122.53 | 10.00s | 920.00s | 0.62s | | 9382 / 9382 | 0 | 0 | 6447.58 | 10.50s | 944.00s | 0.63s | | 9844 / 9844 | 0 | 0 | 6766.37 | 11.00s | 924.00s | 0.62s | | 10316 / 10316 | 0 | 0 | 7093.14 | 11.50s | 944.00s | 0.64s | | 10778 / 10778 | 0 | 0 | 7411.51 | 12.00s | 924.00s | 0.62s | | 11250 / 11250 | 0 | 0 | 7738.70 | 12.50s | 944.00s | 0.64s | | 11710 / 11710 | 0 | 0 | 8056.08 | 13.00s | 920.00s | 0.62s | | 12184 / 12184 | 0 | 0 | 8384.46 | 13.50s | 946.11s | 0.64s | | 12644 / 12644 | 0 | 0 | 8701.20 | 14.00s | 920.00s | 0.62s | | 13119 / 13119 | 0 | 0 | 9030.51 | 14.50s | 950.00s | 0.64s | | 13582 / 13582 | 0 | 0 | 9349.72 | 15.00s | 926.00s | 0.62s | | 14053 / 14053 | 0 | 0 | 9676.28 | 15.50s | 942.00s | 0.64s | | 14516 / 14516 | 0 | 0 | 9994.85 | 16.00s | 926.00s | 0.62s | | 14987 / 14987 | 0 | 0 | 10321.41 | 16.50s | 942.00s | 0.64s | | 15450 / 15450 | 0 | 0 | 10640.41 | 17.00s | 926.00s | 0.62s | | 15922 / 15922 | 0 | 0 | 10967.66 | 17.50s | 944.00s | 0.64s | | 16386 / 16386 | 0 | 0 | 11287.13 | 18.00s | 926.15s | 0.62s | | 16386 / 16386 | 0 | 0 | 11287.13 | 18.50s | 0.00s | 0.00s | | 16855 / 16855 | 0 | 0 | 11612.32 | 19.00s | 938.00s | 0.64s | | 17320 / 17320 | 0 | 0 | 11932.69 | 19.50s | 930.00s | 0.63s | | 17794 / 17794 | 0 | 0 | 12261.34 | 20.00s | 948.00s | 0.64s | Bee: i-fb457323 max-parallel: 50 1st-resp-ms-min: 10.036 response-codes 200: 184 403: 17560 seconds: 20.006 connect-ms-max: 8.729 1st-resp-ms-max: 130.893 bytes: 16541472.0 1st-resp-ms-mean: 40.5336982642 end2end-ms-mean: 40.5487644838 fetches-per-sec: 889.433170049 connect-ms-min: 0.0 fetches: 17794 bytes-per-sec: 826825.552334 end2end-ms-min: 10.053 end2end-ms-max: 130.907 mean-bytes-per-conn: 929.609531303 connect-ms-mean: 0.0224927299369 hurl http://can.192bf.transactcdn.com/00192BF/test.html/config.workflow:ContinueWarranty -p 50 -H "Accept : text/html" -H "Content-Type : text/plain" -o /tmp/tmp.PkGEethemi -l 20 -A 1000 -j i-fa457322 ec2-54-186-127-166.us-west-2.compute.amazonaws.com Running 1 threads 50 parallel connections per thread with 1 reqests per connection +-----------/-----------+-----------+-----------+--------------+-----------+-------------+-----------+ | Cmpltd / Total | IdlKil | Errors | kBytes Recvd | Elapsed | Req/s | MB/s | +-----------/-----------+-----------+-----------+--------------+-----------+-------------+-----------+ | 0 / 0 | 0 | 0 | 0.00 | 0.50s | 0.00s | 0.00s | | 499 / 499 | 0 | 0 | 309.51 | 1.00s | 998.00s | 0.60s | | 965 / 965 | 0 | 0 | 631.24 | 1.50s | 930.14s | 0.63s | | 1435 / 1435 | 0 | 0 | 957.58 | 2.00s | 940.00s | 0.64s | | 1900 / 1900 | 0 | 0 | 1279.25 | 2.50s | 930.00s | 0.63s | | 2373 / 2373 | 0 | 0 | 1607.67 | 3.00s | 946.00s | 0.64s | | 2834 / 2834 | 0 | 0 | 1925.72 | 3.50s | 922.00s | 0.62s | | 3306 / 3306 | 0 | 0 | 2253.45 | 4.00s | 944.00s | 0.64s | | 3781 / 3781 | 0 | 0 | 2581.00 | 4.50s | 950.00s | 0.64s | | 4246 / 4246 | 0 | 0 | 2903.87 | 5.00s | 928.14s | 0.63s | | 4701 / 4701 | 0 | 0 | 3217.97 | 5.50s | 910.00s | 0.61s | | 5181 / 5181 | 0 | 0 | 3551.25 | 6.00s | 960.00s | 0.65s | | 5666 / 5666 | 0 | 0 | 3885.54 | 6.50s | 970.00s | 0.65s | | 6135 / 6135 | 0 | 0 | 4210.28 | 7.00s | 938.00s | 0.63s | | 6605 / 6605 | 0 | 0 | 4535.90 | 7.50s | 940.00s | 0.64s | | 7072 / 7072 | 0 | 0 | 4857.96 | 8.00s | 934.00s | 0.63s | | 7553 / 7553 | 0 | 0 | 5191.88 | 8.50s | 962.00s | 0.65s | | 8020 / 8020 | 0 | 0 | 5514.13 | 9.00s | 932.14s | 0.63s | | 8497 / 8497 | 0 | 0 | 5845.30 | 9.50s | 954.00s | 0.65s | | 8966 / 8966 | 0 | 0 | 6168.91 | 10.00s | 938.00s | 0.63s | | 9437 / 9437 | 0 | 0 | 6495.93 | 10.50s | 942.00s | 0.64s | | 9921 / 9921 | 0 | 0 | 6829.96 | 11.00s | 968.00s | 0.65s | | 10389 / 10389 | 0 | 0 | 7154.90 | 11.50s | 936.00s | 0.63s | | 10389 / 10389 | 0 | 0 | 7154.90 | 12.00s | 0.00s | 0.00s | | 10857 / 10857 | 0 | 0 | 7477.18 | 12.50s | 936.00s | 0.63s | | 11323 / 11323 | 0 | 0 | 7800.74 | 13.00s | 932.00s | 0.63s | | 11790 / 11790 | 0 | 0 | 8124.22 | 13.50s | 932.14s | 0.63s | | 12257 / 12257 | 0 | 0 | 8448.48 | 14.00s | 934.00s | 0.63s | | 12718 / 12718 | 0 | 0 | 8765.89 | 14.50s | 922.00s | 0.62s | | 13191 / 13191 | 0 | 0 | 9094.32 | 15.00s | 946.00s | 0.64s | | 13670 / 13670 | 0 | 0 | 9424.86 | 15.50s | 958.00s | 0.65s | | 14133 / 14133 | 0 | 0 | 9746.34 | 16.00s | 926.00s | 0.63s | | 14603 / 14603 | 0 | 0 | 10070.01 | 16.50s | 940.00s | 0.63s | | 15067 / 15067 | 0 | 0 | 10392.18 | 17.00s | 928.00s | 0.63s | | 15532 / 15532 | 0 | 0 | 10712.58 | 17.50s | 928.14s | 0.62s | | 16012 / 16012 | 0 | 0 | 11045.87 | 18.00s | 960.00s | 0.65s | | 16487 / 16487 | 0 | 0 | 11372.79 | 18.50s | 950.00s | 0.64s | | 16963 / 16963 | 0 | 0 | 11703.30 | 19.00s | 952.00s | 0.65s | | 17451 / 17451 | 0 | 0 | 12040.73 | 19.50s | 976.00s | 0.66s | | 17919 / 17919 | 0 | 0 | 12365.67 | 20.00s | 936.00s | 0.63s | Bee: i-fa457322 max-parallel: 50 1st-resp-ms-min: 7.623 response-codes 200: 183 403: 17686 seconds: 20.006 connect-ms-max: 8.547 1st-resp-ms-max: 140.328 bytes: 16676307.0 1st-resp-ms-mean: 39.7687282444 end2end-ms-mean: 39.7864872125 fetches-per-sec: 895.681295611 connect-ms-min: 0.0 fetches: 17919 bytes-per-sec: 833565.280416 end2end-ms-min: 7.636 end2end-ms-max: 140.342 mean-bytes-per-conn: 930.649422401 connect-ms-mean: 0.0225320387263 Offensive complete. Summarized Results Total bytes: 33217779 Seconds: 20 Connect-ms-max: 8.729000 1st-resp-ms-max: 140.328000 1st-resp-ms-mean: 40.151213 Fetches/sec mean: 892.557233 connect-ms-min: 0.000000 Total fetches: 35713 bytes/sec mean: 830195.416375 end2end-ms-min mean: 8.844500 mean-bytes-per-conn: 930.129477 connect-ms-mean: 0.022512 Response Codes: 2xx: 367 3xx: 0 4xx: 35246 5xx: 0 Mission Assessment: Target crushed bee offensive. The swarm is awaiting new orders. hurl http://can.192bf.transactcdn.com/00192BF/test.html/config.workflow:ContinueWarranty -p 50 -H "Accept : text/html" -H "Content-Type : text/plain" -o /tmp/tmp.L7eQsLiKs9 -l 20 -A 1000 -j i-9e6fc612 ec2-54-194-180-232.eu-west-1.compute.amazonaws.com Running 1 threads 50 parallel connections per thread with 1 reqests per connection +-----------/-----------+-----------+-----------+--------------+-----------+-------------+-----------+ | Cmpltd / Total | IdlKil | Errors | kBytes Recvd | Elapsed | Req/s | MB/s | +-----------/-----------+-----------+-----------+--------------+-----------+-------------+-----------+ | 0 / 0 | 0 | 0 | 0.00 | 0.50s | 0.00s | 0.00s | | 484 / 484 | 0 | 0 | 220.82 | 1.00s | 968.00s | 0.43s | | 957 / 957 | 0 | 0 | 463.33 | 1.50s | 944.11s | 0.47s | | 1409 / 1409 | 0 | 0 | 692.96 | 2.00s | 904.00s | 0.45s | | 1872 / 1872 | 0 | 0 | 930.33 | 2.50s | 926.00s | 0.46s | | 2345 / 2345 | 0 | 0 | 1170.94 | 3.00s | 946.00s | 0.47s | | 2803 / 2803 | 0 | 0 | 1405.75 | 3.50s | 916.00s | 0.46s | | 3259 / 3259 | 0 | 0 | 1637.65 | 4.00s | 912.00s | 0.45s | | 3729 / 3729 | 0 | 0 | 1878.61 | 4.50s | 940.00s | 0.47s | | 4190 / 4190 | 0 | 0 | 2112.86 | 5.00s | 922.00s | 0.46s | | 4645 / 4645 | 0 | 0 | 2346.13 | 5.50s | 908.18s | 0.45s | | 5108 / 5108 | 0 | 0 | 2581.82 | 6.00s | 926.00s | 0.46s | | 5566 / 5566 | 0 | 0 | 2816.64 | 6.50s | 916.00s | 0.46s | | 6035 / 6035 | 0 | 0 | 3055.19 | 7.00s | 938.00s | 0.47s | | 6501 / 6501 | 0 | 0 | 3294.11 | 7.50s | 932.00s | 0.47s | | 6928 / 6928 | 0 | 0 | 3510.92 | 8.00s | 854.00s | 0.42s | | 7381 / 7381 | 0 | 0 | 3743.17 | 8.50s | 906.00s | 0.45s | | 7851 / 7851 | 0 | 0 | 3981.82 | 9.00s | 940.00s | 0.47s | | 8308 / 8308 | 0 | 0 | 4216.12 | 9.50s | 912.18s | 0.46s | | 8757 / 8757 | 0 | 0 | 4444.00 | 10.00s | 898.00s | 0.45s | | 9218 / 9218 | 0 | 0 | 4680.35 | 10.50s | 922.00s | 0.46s | | 9690 / 9690 | 0 | 0 | 4920.66 | 11.00s | 944.00s | 0.47s | | 10158 / 10158 | 0 | 0 | 5159.12 | 11.50s | 936.00s | 0.47s | | 10627 / 10627 | 0 | 0 | 5398.73 | 12.00s | 938.00s | 0.47s | | 11104 / 11104 | 0 | 0 | 5641.39 | 12.50s | 954.00s | 0.47s | | 11576 / 11576 | 0 | 0 | 5883.38 | 13.00s | 944.00s | 0.47s | | 12056 / 12056 | 0 | 0 | 6126.94 | 13.50s | 960.00s | 0.48s | | 12528 / 12528 | 0 | 0 | 6368.94 | 14.00s | 942.12s | 0.47s | | 12997 / 12997 | 0 | 0 | 6606.86 | 14.50s | 938.00s | 0.46s | | 13447 / 13447 | 0 | 0 | 6837.57 | 15.00s | 900.00s | 0.45s | | 13899 / 13899 | 0 | 0 | 7067.20 | 15.50s | 904.00s | 0.45s | | 14378 / 14378 | 0 | 0 | 7312.78 | 16.00s | 958.00s | 0.48s | | 14815 / 14815 | 0 | 0 | 7534.72 | 16.50s | 874.00s | 0.43s | | 14815 / 14815 | 0 | 0 | 7534.72 | 17.00s | 0.00s | 0.00s | | 15290 / 15290 | 0 | 0 | 7778.25 | 17.50s | 950.00s | 0.48s | | 15743 / 15743 | 0 | 0 | 8008.39 | 18.00s | 904.19s | 0.45s | | 16218 / 16218 | 0 | 0 | 8251.92 | 18.50s | 950.00s | 0.48s | | 16676 / 16676 | 0 | 0 | 8484.63 | 19.00s | 916.00s | 0.45s | | 17138 / 17138 | 0 | 0 | 8721.49 | 19.50s | 924.00s | 0.46s | | 17597 / 17597 | 0 | 0 | 8954.50 | 20.00s | 918.00s | 0.46s | Bee: i-9e6fc612 max-parallel: 50 1st-resp-ms-min: 11.354 response-codes 200: 198 403: 17349 seconds: 20.006 connect-ms-max: 15.13 1st-resp-ms-max: 376.028 bytes: 13111135.0 1st-resp-ms-mean: 41.7301567789 end2end-ms-mean: 41.7460330541 fetches-per-sec: 879.586124163 connect-ms-min: 0.0 fetches: 17597 bytes-per-sec: 655360.141957 end2end-ms-min: 11.37 end2end-ms-max: 376.044 mean-bytes-per-conn: 745.07785418 connect-ms-mean: 0.0346185102867 hurl http://can.192bf.transactcdn.com/00192BF/test.html/config.workflow:ContinueWarranty -p 50 -H "Accept : text/html" -H "Content-Type : text/plain" -o /tmp/tmp.cDsfCaHBDo -l 20 -A 1000 -j i-9d6fc611 ec2-54-194-207-186.eu-west-1.compute.amazonaws.com Running 1 threads 50 parallel connections per thread with 1 reqests per connection +-----------/-----------+-----------+-----------+--------------+-----------+-------------+-----------+ | Cmpltd / Total | IdlKil | Errors | kBytes Recvd | Elapsed | Req/s | MB/s | +-----------/-----------+-----------+-----------+--------------+-----------+-------------+-----------+ | 0 / 0 | 0 | 0 | 0.00 | 0.50s | 0.00s | 0.00s | | 490 / 490 | 0 | 0 | 222.63 | 1.00s | 980.00s | 0.43s | | 958 / 958 | 0 | 0 | 461.10 | 1.50s | 936.00s | 0.47s | | 1437 / 1437 | 0 | 0 | 704.57 | 2.00s | 958.00s | 0.48s | | 1913 / 1913 | 0 | 0 | 948.61 | 2.50s | 952.00s | 0.48s | | 2394 / 2394 | 0 | 0 | 1192.90 | 3.00s | 962.00s | 0.48s | | 2868 / 2868 | 0 | 0 | 1435.92 | 3.50s | 948.00s | 0.47s | | 3327 / 3327 | 0 | 0 | 1669.34 | 4.00s | 918.00s | 0.46s | | 3802 / 3802 | 0 | 0 | 1912.88 | 4.50s | 948.10s | 0.47s | | 4265 / 4265 | 0 | 0 | 2147.93 | 5.00s | 926.00s | 0.46s | | 4737 / 4737 | 0 | 0 | 2389.92 | 5.50s | 944.00s | 0.47s | | 5192 / 5192 | 0 | 0 | 2620.67 | 6.00s | 910.00s | 0.45s | | 5663 / 5663 | 0 | 0 | 2862.15 | 6.50s | 942.00s | 0.47s | | 6100 / 6100 | 0 | 0 | 3084.09 | 7.00s | 874.00s | 0.43s | | 6568 / 6568 | 0 | 0 | 3324.03 | 7.50s | 936.00s | 0.47s | | 7030 / 7030 | 0 | 0 | 3558.57 | 8.00s | 924.00s | 0.46s | | 7502 / 7502 | 0 | 0 | 3800.57 | 8.50s | 942.12s | 0.47s | | 7960 / 7960 | 0 | 0 | 4033.27 | 9.00s | 916.00s | 0.45s | | 8410 / 8410 | 0 | 0 | 4263.98 | 9.50s | 900.00s | 0.45s | | 8886 / 8886 | 0 | 0 | 4505.92 | 10.00s | 952.00s | 0.47s | | 9359 / 9359 | 0 | 0 | 4748.42 | 10.50s | 946.00s | 0.47s | | 9809 / 9809 | 0 | 0 | 4977.03 | 11.00s | 900.00s | 0.45s | | 10269 / 10269 | 0 | 0 | 5212.87 | 11.50s | 920.00s | 0.46s | | 10737 / 10737 | 0 | 0 | 5450.49 | 12.03s | 894.84s | 0.44s | | 11184 / 11184 | 0 | 0 | 5679.66 | 12.53s | 894.00s | 0.45s | | 11643 / 11643 | 0 | 0 | 5913.09 | 13.03s | 918.00s | 0.46s | | 12109 / 12109 | 0 | 0 | 6152.01 | 13.53s | 932.00s | 0.47s | | 12575 / 12575 | 0 | 0 | 6388.81 | 14.03s | 932.00s | 0.46s | | 13041 / 13041 | 0 | 0 | 6627.73 | 14.53s | 932.00s | 0.47s | | 13497 / 13497 | 0 | 0 | 6859.83 | 15.03s | 912.00s | 0.45s | | 13946 / 13946 | 0 | 0 | 7090.03 | 15.53s | 898.00s | 0.45s | | 14412 / 14412 | 0 | 0 | 7326.42 | 16.03s | 930.14s | 0.46s | | 14861 / 14861 | 0 | 0 | 7556.62 | 16.53s | 898.00s | 0.45s | | 15319 / 15319 | 0 | 0 | 7789.74 | 17.03s | 916.00s | 0.46s | | 15779 / 15779 | 0 | 0 | 8025.58 | 17.53s | 920.00s | 0.46s | | 15779 / 15779 | 0 | 0 | 8025.58 | 18.03s | 0.00s | 0.00s | | 16239 / 16239 | 0 | 0 | 8259.31 | 18.53s | 920.00s | 0.46s | | 16704 / 16704 | 0 | 0 | 8497.29 | 19.03s | 928.14s | 0.46s | | 17175 / 17175 | 0 | 0 | 8737.09 | 19.53s | 942.00s | 0.47s | | 17628 / 17628 | 0 | 0 | 8968.28 | 20.03s | 906.00s | 0.45s | Bee: i-9d6fc611 max-parallel: 50 1st-resp-ms-min: 11.29 response-codes 200: 208 403: 17370 seconds: 20.027 connect-ms-max: 15.115 1st-resp-ms-max: 390.853 bytes: 13132194.0 1st-resp-ms-mean: 41.6057616907 end2end-ms-mean: 41.6218236432 fetches-per-sec: 880.211714186 connect-ms-min: 0.0 fetches: 17628 bytes-per-sec: 655724.471963 end2end-ms-min: 11.303 end2end-ms-max: 390.866 mean-bytes-per-conn: 744.962219197 connect-ms-mean: 0.0350904539766 Offensive complete. Summarized Results Total bytes: 26243329 Seconds: 20 Connect-ms-max: 15.130000 1st-resp-ms-max: 390.853000 1st-resp-ms-mean: 41.667959 Fetches/sec mean: 879.898919 connect-ms-min: 0.000000 Total fetches: 35225 bytes/sec mean: 655542.306960 end2end-ms-min mean: 11.336500 mean-bytes-per-conn: 745.020037 connect-ms-mean: 0.034854 Response Codes: 2xx: 406 3xx: 0 4xx: 34719 5xx: 0 Mission Assessment: Target crushed bee offensive. The swarm is awaiting new orders. hurl http://can.192bf.transactcdn.com/00192BF/test.html/config.workflow:ContinueWarranty -p 50 -H "Accept : text/html" -H "Content-Type : text/plain" -o /tmp/tmp.jfVcPxIqE5 -l 20 -A 1000 -j i-02fead8c ec2-52-77-216-107.ap-southeast-1.compute.amazonaws.com Running 1 threads 50 parallel connections per thread with 1 reqests per connection +-----------/-----------+-----------+-----------+--------------+-----------+-------------+-----------+ | Cmpltd / Total | IdlKil | Errors | kBytes Recvd | Elapsed | Req/s | MB/s | +-----------/-----------+-----------+-----------+--------------+-----------+-------------+-----------+ | 0 / 0 | 0 | 0 | 0.00 | 0.50s | 0.00s | 0.00s | | 100 / 100 | 0 | 0 | 23.95 | 1.00s | 200.00s | 0.05s | | 250 / 250 | 0 | 0 | 98.11 | 1.50s | 300.00s | 0.14s | | 388 / 388 | 0 | 0 | 167.60 | 2.00s | 276.00s | 0.14s | | 529 / 529 | 0 | 0 | 239.25 | 2.50s | 282.00s | 0.14s | | 673 / 673 | 0 | 0 | 311.39 | 3.00s | 287.43s | 0.14s | | 816 / 816 | 0 | 0 | 384.29 | 3.50s | 286.00s | 0.14s | | 953 / 953 | 0 | 0 | 452.42 | 4.00s | 274.00s | 0.13s | | 1091 / 1091 | 0 | 0 | 522.96 | 4.50s | 276.00s | 0.14s | | 1226 / 1226 | 0 | 0 | 591.12 | 5.00s | 270.00s | 0.13s | | 1372 / 1372 | 0 | 0 | 664.71 | 5.50s | 292.00s | 0.14s | | 1516 / 1516 | 0 | 0 | 736.85 | 6.00s | 288.00s | 0.14s | | 1656 / 1656 | 0 | 0 | 808.20 | 6.50s | 280.00s | 0.14s | | 1795 / 1795 | 0 | 0 | 877.78 | 7.00s | 278.00s | 0.14s | | 1937 / 1937 | 0 | 0 | 950.16 | 7.50s | 283.43s | 0.14s | | 2073 / 2073 | 0 | 0 | 1018.41 | 8.00s | 272.00s | 0.13s | | 2213 / 2213 | 0 | 0 | 1089.34 | 8.50s | 280.00s | 0.14s | | 2356 / 2356 | 0 | 0 | 1161.60 | 9.00s | 286.00s | 0.14s | | 2495 / 2495 | 0 | 0 | 1232.02 | 9.50s | 278.00s | 0.14s | | 2637 / 2637 | 0 | 0 | 1303.14 | 10.00s | 284.00s | 0.14s | | 2779 / 2779 | 0 | 0 | 1375.31 | 10.50s | 284.00s | 0.14s | | 2916 / 2916 | 0 | 0 | 1443.86 | 11.00s | 274.00s | 0.13s | | 3052 / 3052 | 0 | 0 | 1513.17 | 11.50s | 272.00s | 0.14s | | 3194 / 3194 | 0 | 0 | 1584.70 | 12.00s | 283.43s | 0.14s | | 3334 / 3334 | 0 | 0 | 1656.06 | 12.50s | 280.00s | 0.14s | | 3471 / 3471 | 0 | 0 | 1724.40 | 13.00s | 274.00s | 0.13s | | 3605 / 3605 | 0 | 0 | 1793.10 | 13.50s | 268.00s | 0.13s | | 3747 / 3747 | 0 | 0 | 1864.22 | 14.00s | 284.00s | 0.14s | | 3882 / 3882 | 0 | 0 | 1932.80 | 14.50s | 270.00s | 0.13s | | 4026 / 4026 | 0 | 0 | 2004.73 | 15.00s | 288.00s | 0.14s | | 4166 / 4166 | 0 | 0 | 2075.87 | 15.50s | 280.00s | 0.14s | | 4306 / 4306 | 0 | 0 | 2146.38 | 16.00s | 280.00s | 0.14s | | 4451 / 4451 | 0 | 0 | 2220.09 | 16.50s | 289.42s | 0.14s | | 4597 / 4597 | 0 | 0 | 2293.05 | 17.00s | 292.00s | 0.14s | | 4728 / 4728 | 0 | 0 | 2360.21 | 17.50s | 262.00s | 0.13s | | 4865 / 4865 | 0 | 0 | 2428.76 | 18.00s | 274.00s | 0.13s | | 5008 / 5008 | 0 | 0 | 2501.44 | 18.50s | 286.00s | 0.14s | | 5153 / 5153 | 0 | 0 | 2574.10 | 19.00s | 289.42s | 0.14s | | 5292 / 5292 | 0 | 0 | 2645.15 | 19.50s | 278.00s | 0.14s | | 5429 / 5429 | 0 | 0 | 2713.91 | 20.00s | 274.00s | 0.13s | Bee: i-02fead8c max-parallel: 50 1st-resp-ms-min: 167.119 response-codes 200: 208 403: 5171 seconds: 20.005 connect-ms-max: 194.213 1st-resp-ms-max: 402.352 bytes: 3995143.0 1st-resp-ms-mean: 179.083958914 end2end-ms-mean: 179.106678751 fetches-per-sec: 271.382154461 connect-ms-min: 0.0 fetches: 5429 bytes-per-sec: 199707.223194 end2end-ms-min: 167.165 end2end-ms-max: 402.373 mean-bytes-per-conn: 735.889298213 connect-ms-mean: 1.63028611266 hurl http://can.192bf.transactcdn.com/00192BF/test.html/config.workflow:ContinueWarranty -p 50 -H "Accept : text/html" -H "Content-Type : text/plain" -o /tmp/tmp.Ze2gnkVVd2 -l 20 -A 1000 -j i-03fead8d ec2-54-254-220-121.ap-southeast-1.compute.amazonaws.com Running 1 threads 50 parallel connections per thread with 1 reqests per connection +-----------/-----------+-----------+-----------+--------------+-----------+-------------+-----------+ | Cmpltd / Total | IdlKil | Errors | kBytes Recvd | Elapsed | Req/s | MB/s | +-----------/-----------+-----------+-----------+--------------+-----------+-------------+-----------+ | 0 / 0 | 0 | 0 | 0.00 | 0.50s | 0.00s | 0.00s | | 100 / 100 | 0 | 0 | 23.10 | 1.00s | 199.60s | 0.05s | | 250 / 250 | 0 | 0 | 98.11 | 1.50s | 300.00s | 0.15s | | 388 / 388 | 0 | 0 | 167.38 | 2.00s | 276.00s | 0.14s | | 526 / 526 | 0 | 0 | 237.71 | 2.50s | 276.00s | 0.14s | | 669 / 669 | 0 | 0 | 308.92 | 3.00s | 286.00s | 0.14s | | 810 / 810 | 0 | 0 | 380.79 | 3.50s | 282.00s | 0.14s | | 948 / 948 | 0 | 0 | 449.85 | 4.00s | 276.00s | 0.13s | | 1083 / 1083 | 0 | 0 | 518.65 | 4.50s | 270.00s | 0.13s | | 1224 / 1224 | 0 | 0 | 589.04 | 5.00s | 281.44s | 0.14s | | 1363 / 1363 | 0 | 0 | 659.88 | 5.50s | 278.00s | 0.14s | | 1503 / 1503 | 0 | 0 | 729.76 | 6.00s | 280.00s | 0.14s | | 1642 / 1642 | 0 | 0 | 800.81 | 6.50s | 278.00s | 0.14s | | 1775 / 1775 | 0 | 0 | 867.31 | 7.00s | 266.00s | 0.13s | | 1917 / 1917 | 0 | 0 | 939.69 | 7.50s | 284.00s | 0.14s | | 2060 / 2060 | 0 | 0 | 1011.53 | 8.00s | 286.00s | 0.14s | | 2197 / 2197 | 0 | 0 | 1081.14 | 8.50s | 274.00s | 0.14s | | 2331 / 2331 | 0 | 0 | 1147.94 | 9.00s | 268.00s | 0.13s | | 2474 / 2474 | 0 | 0 | 1221.26 | 9.50s | 285.43s | 0.14s | | 2618 / 2618 | 0 | 0 | 1292.98 | 10.00s | 288.00s | 0.14s | | 2756 / 2756 | 0 | 0 | 1363.52 | 10.50s | 276.00s | 0.14s | | 2893 / 2893 | 0 | 0 | 1432.07 | 11.00s | 274.00s | 0.13s | | 3035 / 3035 | 0 | 0 | 1504.45 | 11.50s | 284.00s | 0.14s | | 3170 / 3170 | 0 | 0 | 1572.19 | 12.00s | 270.00s | 0.13s | | 3301 / 3301 | 0 | 0 | 1639.35 | 12.50s | 262.00s | 0.13s | | 3439 / 3439 | 0 | 0 | 1707.99 | 13.00s | 276.00s | 0.13s | | 3574 / 3574 | 0 | 0 | 1777.21 | 13.50s | 269.46s | 0.13s | | 3712 / 3712 | 0 | 0 | 1845.64 | 14.00s | 276.00s | 0.13s | | 3851 / 3851 | 0 | 0 | 1916.90 | 14.50s | 278.00s | 0.14s | | 3987 / 3987 | 0 | 0 | 1984.94 | 15.00s | 272.00s | 0.13s | | 4124 / 4124 | 0 | 0 | 2054.97 | 15.50s | 274.00s | 0.14s | | 4266 / 4266 | 0 | 0 | 2125.88 | 16.00s | 284.00s | 0.14s | | 4408 / 4408 | 0 | 0 | 2198.26 | 16.50s | 284.00s | 0.14s | | 4539 / 4539 | 0 | 0 | 2263.73 | 17.00s | 262.00s | 0.13s | | 4679 / 4679 | 0 | 0 | 2334.88 | 17.50s | 280.00s | 0.14s | | 4822 / 4822 | 0 | 0 | 2406.50 | 18.00s | 285.43s | 0.14s | | 4962 / 4962 | 0 | 0 | 2478.07 | 18.50s | 280.00s | 0.14s | | 5101 / 5101 | 0 | 0 | 2548.07 | 19.00s | 278.00s | 0.14s | | 5240 / 5240 | 0 | 0 | 2618.91 | 19.50s | 278.00s | 0.14s | | 5382 / 5382 | 0 | 0 | 2689.82 | 20.00s | 284.00s | 0.14s | Bee: i-03fead8d max-parallel: 50 1st-resp-ms-min: 167.37 response-codes 200: 208 403: 5124 seconds: 20.005 connect-ms-max: 197.678 1st-resp-ms-max: 396.03 bytes: 3959940.0 1st-resp-ms-mean: 180.888643473 end2end-ms-mean: 180.91185859 fetches-per-sec: 269.032741815 connect-ms-min: 0.0 fetches: 5382 bytes-per-sec: 197947.513122 end2end-ms-min: 167.395 end2end-ms-max: 396.049 mean-bytes-per-conn: 735.774804905 connect-ms-mean: 1.66231845461 Offensive complete. Summarized Results Total bytes: 7955083 Seconds: 20 Connect-ms-max: 197.678000 1st-resp-ms-max: 402.352000 1st-resp-ms-mean: 179.986301 Fetches/sec mean: 270.207448 connect-ms-min: 0.000000 Total fetches: 10811 bytes/sec mean: 198827.368158 end2end-ms-min mean: 167.280000 mean-bytes-per-conn: 735.832052 connect-ms-mean: 1.646302 Response Codes: 2xx: 416 3xx: 0 4xx: 10295 5xx: 0 Mission Assessment: Target crushed bee offensive. The swarm is awaiting new orders. (trusty)rawm@localhost:~/beeswithmachineguns$ An example bees down $ ./bees down Read 2 bees from the roster: eu-west-1b Connecting to the hive. Calling off the swarm for eu-west-1b. Stood down 2 bees. Read 2 bees from the roster: ap-southeast-1b Connecting to the hive. Calling off the swarm for ap-southeast-1b. Stood down 2 bees. Read 2 bees from the roster: us-west-2b Connecting to the hive. Calling off the swarm for us-west-2b. Stood down 2 bees. h2. The caveat! (PLEASE READ) (The following was cribbed from our "original blog post about the bees":http://blog.apps.chicagotribune.com/2010/07/08/bees-with-machine-guns/.) If you decide to use the Bees, please keep in mind the following important caveat: they are, more-or-less a distributed denial-of-service attack in a fancy package and, therefore, if you point them at any server you dont own you will behaving unethically, have your Amazon Web Services account locked-out, and be liable in a court of law for any downtime you cause. You have been warned. h2. Troubleshooting h3. EC2 Instances Out Of Sync If you find yourself in a situation where 'bees report' seems to be out of sync with EC2 instances you know are (or are not) running: * You can reset the BWMG state by deleting ~/.bees.. Note that this will prevent BWMG from identifying EC2 instances that may now be orphaned by the tool * You can manually edit ~/.bees. to add or remove instance IDs and force synchronization with the reality from your EC2 dashboard This is helpful in cases where BWMG crashes, EC2 instances are terminated outside of the control of BWMG, or other situations where BWMG is out of sync with reality. h2. Bugs Please log your bugs on the "Github issues tracker":http://github.com/newsapps/beeswithmachineguns/issues. h2. Credits The bees are a creation of the News Applications team at the Chicago Tribune--visit "our blog":http://apps.chicagotribune.com/ and read "our original post about the project":http://blog.apps.chicagotribune.com/2010/07/%2008/bees-with-machine-guns/. Initial refactoring code and inspiration from "Jeff Larson":http://github.com/thejefflarson. Multiple url support from "timsu":https://github.com/timsu/beeswithmachineguns. Thanks to everyone who reported bugs against the alpha release. h2. License MIT.

 # # # # # # # # # # # # # # # # # # # #
 Repository: rollup/rollup, index: 476, word count: 6049 
 # # # # # # # # # # # # # # # # # # # #

AngularJS service to handle Rest API Restful Resources properly and easilyRestangular Restangular is an AngularJS service that simplifies common GET, POST, DELETE, and UPDATE requests with a minimum of client code. It's a perfect fit for any WebApp that consumes data from a RESTful API. Note This version of Restangular only supports Angular 1. For an Angular 2+ version of Restangular, check out ngx-restangular. It's a separate project with different maintainers, so issues regarding ngx-restangular should be reported over there :wink: Learn Restangular! Try the live demo on plunkr. It uses the same example as the official Angular Javascript Project, but with Restangular! Or watch a video introduction of a talk I gave at Devoxx France about Restangular. Table of contents Restangular Differences with $resource How do I add this to my project? Dependencies Production apps using Restangular Starter Guide Quick configuration for Lazy Readers Adding dependency to Restangular module in your app Using Restangular Creating Main Restangular object Let's code! Configuring Restangular Properties setBaseUrl setExtraFields setParentless setDefaultHttpFields addElementTransformer setOnElemRestangularized setResponseInterceptor setResponseExtractor (alias of setResponseInterceptor) addResponseInterceptor setRequestInterceptor addRequestInterceptor setFullRequestInterceptor addFullRequestInterceptor setErrorInterceptor setRestangularFields setMethodOverriders setDefaultRequestParams setFullResponse setDefaultHeaders setRequestSuffix setUseCannonicalId setPlainByDefault How to configure them globally Configuring in the config Configuring in the run How to create a Restangular service with a different configuration from the global one Decoupled Restangular Service Methods description Restangular methods Element methods Collection methods Custom methods Copying elements Enhanced promises - Using values directly in templates Using Self reference resources URL Building Creating new Restangular Methods Adding Custom Methods to Collections Example: Adding Custom Methods to Models Example: FAQ How can I handle errors? I need to send one header in EVERY Restangular request, how do I do this? Can I cache requests? Can it be used in $routeProvider.resolve? My response is actually wrapped with some metadata. How do I get the data in that case? I use Mongo and the ID of the elements is _id not id as the default. Therefore requests are sent to undefined routes What if each of my models has a different ID name like CustomerID for Customer How do I handle CRUD operations in a List returned by Restangular? When I set baseUrl with a port, it's stripped out. How can I access the unrestangularized element as well as the restangularized one? Restangular fails with status code 0 Why does this depend on Lodash / Underscore? How do I cancel a request? Supported Angular versions Server Frameworks Releases Notes License Back to top Differences with $resource Restangular has several features that distinguish it from $resource: It uses promises. Instead of doing the "magic" filling of objects like $resource, it uses promises. You can use this in $routeProvider.resolve. As Restangular returns promises, you can return any of the methods in the $routeProvider.resolve and you'll get the real object injected into your controller if you want. It doesn't have all those $resource bugs. Restangular doesn't have problem with trailing slashes, additional : in the URL, escaping information, expecting only arrays for getting lists, etc. It supports all HTTP methods. It supports ETag out of the box. You don't have to do anything. ETags and If-None-Match will be used in all of your requests It supports self linking elements. If you receive from the server some item that has a link to itself, you can use that to query the server instead of writing the URL manually. You don't have to create one $resource object per request. Each time you want to do a request, you can just do it using the object that was returned by Restangular. You don't need to create a new object for this. You don't have to write or remember ANY URL. With $resource, you need to write the URL Template. In here, you don't write any urls. You just write the name of the resource you want to fetch and that's it. It supports nested RESTful resources. If you have Nested RESTful resources, Restangular can handle them for you. You don't have to know the URL, the path, or anything to do all of the HTTP operations you want. Restangular lets you create your own methods. You can create your own methods to run the operation that you want. The sky is the limit. Support for wrapped responses. If your response for a list of element actually returns an object with some property inside which has the list, it's very hard to use $resource. Restangular knows that and it makes it easy on you. Check out https://github.com/mgonto/restangular#my-response-is-actually-wrapped-with-some-metadata-how-do-i-get-the-data-in-that-case You can build your own URLs with Restangular objects easily. Restangular lets you create a Restangular object for any url you want with a really nice builder. Let's see a quick and short example of these features ` Back to top How do I add this to my project? You can download this by: Using bower and running bower install restangular Using npm and running npm install restangular Downloading it manually by clicking here to download development unminified version or here to download minified production version Using CdnJS CDN files: ` Back to top Dependencies Restangular depends on Angular and Lodash (or Underscore). Back to top Production apps using Restangular Each time, there're more Production WebApps using Restangular. If your webapp uses it and it's not in the list, please create an issue or submit a PR: Life360 is using Restangular to build the WebApp version of their platform Thomson Reuters is using Restangular for the new Webapp they've built Quran.com is using Restangular for their alpha/beta app and soon to be main site Worldcampus.co is using Restangular for their beta international students social network. ENTSO-E Transparency Platform Back to top Starter Guide Quick Configuration (For Lazy Readers) This is all you need to start using all the basic Restangular features. ` The Restangular service may be injected into any Controller or Directive :) Note: When adding Restangular as a dependency it is not capitalized 'restangular' But when injected into your controller it is 'Restangular' Back to top Using Restangular Creating Main Restangular object There are 3 ways of creating a main Restangular object. The first one and most common one is by stating the main route of all requests. The second one is by stating the main route and object of all requests. ` Back to top Let's code! Now that we have our main Object let's start playing with it. ` Back to top Configuring Restangular Properties Restangular comes with defaults for all of its properties but you can configure them. So, if you don't need to configure something, there's no need to add the configuration. You can set all these configurations in RestangularProvider or Restangular service to change the global configuration or you can use the withConfig method in Restangular service to create a new Restangular service with some scoped configuration. Check the section on this later. setBaseUrl The base URL for all calls to your API. For example if your URL for fetching accounts is http://example.com/api/v1/accounts, then your baseUrl is /api/v1. The default baseUrl is an empty string which resolves to the same url that AngularJS is running, but you can also set an absolute url like http://api.example.com/api/v1 if you need to set another domain. setExtraFields These are the fields that you want to save from your parent resources if you need to display them. By default this is an Empty Array which will suit most cases setParentless Use this property to control whether Restangularized elements to have a parent or not. So, for example if you get an account and then get a nested list of buildings, you may want the buildings URL to be simple /buildings/123 instead of /accounts/123/buildings/123. This property lets you do that. This method accepts 1 parameter, it could be: Boolean: Specifies if all elements should be parentless or not Array: Specifies the routes (types) of all elements that should be parentless. For example ['buildings'] setDefaultHttpFields $http from AngularJS can receive a bunch of parameters like cache, transformRequest and so on. You can set all of those properties in the object sent on this setter so that they will be used in EVERY API call made by Restangular. This is very useful for caching for example. All properties that can be set can be checked here: http://docs.angularjs.org/api/ng.$http#parameters addElementTransformer This is a hook. After each element has been "restangularized" (Added the new methods from Restangular), the corresponding transformer will be called if it fits. This should be used to add your own methods / functions to entities of certain types. You can add as many element transformers as you want. The signature of this method can be one of the following: addElementTransformer(route, transformer): Transformer is called with all elements that have been restangularized, no matter if they're collections or not. addElementTransformer(route, isCollection, transformer): Transformer is called with all elements that have been restangularized and match the specification regarding if it's a collection or not (true | false) setTransformOnlyServerElements This sets whether transformers will be run for local objects and not by objects returned by the server. This is by default true but can be changed to false if needed (Most people won't need this). setOnElemRestangularized This is a hook. After each element has been "restangularized" (Added the new methods from Restangular), this will be called. It means that if you receive a list of objects in one call, this method will be called first for the collection and then for each element of the collection. I favor the usage of addElementTransformer instead of onElemRestangularized whenever possible as the implementation is much cleaner. This callback is a function that has 4 parameters: elem: The element that has just been restangularized. Can be a collection or a single element. isCollection: Boolean indicating if this is a collection or a single element. what: The model that is being modified. This is the "path" of this resource. For example buildings Restangular: The instanced service to use any of its methods This can be used together with addRestangularMethod (Explained later) to add custom methods to an element setResponseInterceptor This is deprecated. Use addResponseInterceptor since you can add more than one. addResponseInterceptor The responseInterceptor is called after we get each response from the server. It's a function that receives this arguments: data: The data received got from the server operation: The operation made. It'll be the HTTP method used except for a GET which returns a list of element which will return getList so that you can distinguish them. what: The model that's being requested. It can be for example: accounts, buildings, etc. url: The relative URL being requested. For example: /api/v1/accounts/123 response: Full server response including headers deferred: The deferred promise for the request. Some of the use cases of the responseInterceptor are handling wrapped responses and enhancing response elements with more methods among others. The responseInterceptor must return the restangularized data element. setRequestInterceptor This is deprecated. Use addRequestInterceptor since you can add more than one. addRequestInterceptor The requestInterceptor is called before sending any data to the server. It's a function that must return the element to be requested. This function receives the following arguments: element: The element to send to the server. operation: The operation made. It'll be the HTTP method used except for a GET which returns a list of element which will return getList so that you can distinguish them. what: The model that's being requested. It can be for example: accounts, buildings, etc. url: The relative URL being requested. For example: /api/v1/accounts/123 setFullRequestInterceptor This is deprecated. Use addFullRequestInterceptor since you can add more than one. addFullRequestInterceptor This adds a new fullRequestInterceptor. The fullRequestInterceptor is similar to the requestInterceptor but more powerful. It lets you change the element, the request parameters and the headers as well. It's a function that receives the same as the requestInterceptor plus the headers and the query parameters (in that order). It can return an object with any (or all) of following properties: * headers: The headers to send * params: The request parameters to send * element: The element to send * httpConfig: The httpConfig to call with If a property isn't returned, the one sent is used. setErrorInterceptor The errorInterceptor is called whenever there's an error. It's a function that receives the response, the deferred (for the promise) and the Restangular-response handler as parameters. The errorInterceptor function, whenever it returns false, prevents the promise linked to a Restangular request to be executed. All other return values (besides false) are ignored and the promise follows the usual path, eventually reaching the success or error hooks. The feature to prevent the promise to complete is useful whenever you need to intercept each Restangular error response for every request in your AngularJS application in a single place, increasing debugging capabilities and hooking security features in a single place. ` setRestangularFields Restangular requires 7 fields for every "Restangularized" element. These are: id: Id of the element. Default: id route: Name of the route of this element. Default: route parentResource: The reference to the parent resource. Default: parentResource restangularCollection: A boolean indicating if this is a collection or an element. Default: restangularCollection cannonicalId: If available, the path to the cannonical ID to use. Useful for PK changes etag: Where to save the ETag received from the server. Defaults to restangularEtag selfLink: The path to the property that has the URL to this item. If your REST API doesn't return a URL to an item, you can just leave it blank. Defaults to href Also all of Restangular methods and functions are configurable through restangularFields property. All of these fields except for id and selfLink are handled by Restangular, so most of the time you won't change them. You can configure the name of the property that will be binded to all of this fields by setting restangularFields property. setMethodOverriders You can now Override HTTP Methods. You can set here the array of methods to override. All those methods will be sent as POST and Restangular will add an X-HTTP-Method-Override header with the real HTTP method we wanted to do. setJsonp Typical web browsers prohibit requesting data from a server in a different domain (same-origin policy). JSONP or "JSON with padding" is a communication technique used in JavaScript programs running in web browsers to get around this. For JSONP to work, a server must know how to reply with JSONP-formatted results. JSONP does not work with JSON-formatted results. The JSONP parameters passed as arguments to a script are defined by the server. By setting the value of setJsonp to true, both get and getList will be performed using JSonp instead of the regular GET. You will need to add the 'JSON_CALLBACK' string to your URLs (see $http.jsonp). You can use setDefaultRequestParams to accomplish this: setDefaultRequestParams You can set default Query parameters to be sent with every request and every method. Additionally, if you want to configure request params per method, you can use requestParams configuration similar to $http. For example RestangularProvider.requestParams.get = {single: true}. Supported method to configure are: remove, get, post, put, common (all) ` setFullResponse You can set fullResponse to true to get the whole response every time you do any request. The full response has the restangularized data in the data field, and also has the headers and config sent. By default, it's set to false. Please note that in order for Restangular to access custom HTTP headers, your server must respond having the Access-Control-Expose-Headers: set. ` Or set it per service ` setDefaultHeaders You can set default Headers to be sent with every request. Send format: {header_name: header_value} ` setRequestSuffix If all of your requests require to send some suffix to work, you can set it here. For example, if you need to send the format like /users/123.json you can add that .json to the suffix using the setRequestSuffix method setUseCannonicalId You can set this to either true or false. By default it's false. If set to true, then the cannonical ID from the element will be used for URL creation (in DELETE, PUT, POST, etc.). What this means is that if you change the ID of the element and then you do a put, if you set this to true, it'll use the "old" ID which was received from the server. If set to false, it'll use the new ID assigned to the element. setPlainByDefault You can set this to true or false. By default it's false. If set to true, data retrieved will be returned with no embed methods from restangular. setEncodeIds You can set here if you want to URL Encode IDs or not. By default, it's true. Back to top Accessing configuration You can also access the configuration via RestangularProvider and Restangular via the configuration property if you don't want to use the setters. Check it out: ` Back to top How to configure them globally You can configure this in either the config or the run method. If your configurations don't need any other services, then I'd recommend you do them in the config. If your configurations depend on other services, you can configure them in the run using Restangular instead of RestangularProvider Configuring in the config ` Configuring in the run ` Back to top How to create a Restangular service with a different configuration from the global one Let's assume that for most requests you need some configuration (The global one), and for just a bunch of methods you need another configuration. In that case, you'll need to create another Restangular service with this particular configuration. This scoped configuration will inherit all defaults from the global one. Let's see how. ` Back to top Decoupled Restangular Service There're some times where you want to use Restangular but you don't want to expose Restangular object anywhere. For those cases, you can actually use the service feature of Restangular. Let's see how it works: ` You can also use on objects created by . We can also use Nested RESTful resources with this: ` Back to top Methods description There are 3 sets of methods. Collections have some methods and elements have others. There are are also some common methods for all of them Restangular methods These are the methods that can be called on the Restangular object. * one(route, id): This will create a new Restangular object that is just a pointer to one element with the route route and the specified id. * all(route): This will create a new Restangular object that is just a pointer to a list of elements for the specified path. * oneUrl(route, url): This will create a new Restangular object that is just a pointer to one element with the specified URL. * allUrl(route, url): This creates a Restangular object that is just a pointer to a list at the specified URL. * copy(fromElement): This will create a copy of the from element so that we can modify the copied one. * restangularizeElement(parent, element, route, fromServer, collection, reqParams): Restangularizes a new element * restangularizeCollection(parent, element, route, fromServer, reqParams): Restangularizes a new collection Back to top Element methods get([queryParams, headers]): Gets the element. Query params and headers are optionals getList(subElement, [queryParams, headers]): Gets a nested resource. subElement is mandatory. It's a string with the name of the nested resource (and URL). For example buildings put([queryParams, headers]): Does a put to the current element post(subElement, elementToPost, [queryParams, headers]): Does a POST and creates a subElement. Subelement is mandatory and is the nested resource. Element to post is the object to post to the server remove([queryParams, headers]): Does a DELETE. By default, remove sends a request with an empty object, which may cause problems with some servers or browsers. This shows how to configure RESTangular to have no payload. head([queryParams, headers]): Does a HEAD trace([queryParams, headers]): Does a TRACE options([queryParams, headers]): Does a OPTIONS patch(object, [queryParams, headers]): Does a PATCH one(route, id): Used for RequestLess connections and URL Building. See section below. all(route): Used for RequestLess connections and URL Building. See section below. several(route, ids*): Used for RequestLess connections and URL Building. See section below. oneUrl(route, url): This will create a new Restangular object that is just a pointer to one element with the specified URL. allUrl(route, url): This creates a Restangular object that is just a pointer to a list at the specified URL. getRestangularUrl(): Gets the URL of the current object. getRequestedUrl(): Gets the real URL the current object was requested with (incl. GET parameters). Will equal getRestangularUrl() when no parameters were used, before calling get(), or when using on a nested child. getParentList(): Gets the parent list to which it belongs (if any) clone(): Copies the element. It's an alias to calling Restangular.copy(elem). plain(): Returns the plain element received from the server without any of the enhanced methods from Restangular. It's an alias to calling Restangular.stripRestangular(elem) withHttpConfig(httpConfig): It lets you set a configuration for $http only for the next call. Check the Local Config HTTP section for an example. save: Calling save will determine whether to do PUT or POST accordingly Back to top Collection methods getList([queryParams, headers]): Gets itself again (Remember this is a collection). get(id): Gets one item from the collection by id. post(elementToPost, [queryParams, headers]): Creates a new element of this collection. head([queryParams, headers]): Does a HEAD trace: ([queryParams, headers]): Does a TRACE options: ([queryParams, headers]): Does a OPTIONS patch(object, [queryParams, headers]): Does a PATCH remove([queryParams, headers]): Does a DELETE. By default, remove sends a request with an empty object, which may cause problems with some servers or browsers. This shows how to configure RESTangular to have no payload. putElement(idx, params, headers): Puts the element on the required index and returns a promise of the updated new array getRestangularUrl(): Gets the URL of the current object. getRequestedUrl(): Gets the real URL the current object was requested with (incl. GET parameters). Will equal getRestangularUrl() when no parameters were used, before calling getList(), or when using on a nested child. one(route, id): Used for RequestLess connections and URL Building. See section below. all(route): Used for RequestLess connections and URL Building. See section below. several(route, ids*): Used for RequestLess connections and URL Building. See section below. oneUrl(route, url): This will create a new Restangular object that is just a pointer to one element with the specified URL. allUrl(route, url): This creates a Restangular object that is just a pointer to a list at the specified URL. clone(): Copies the collection. It's an alias to calling Restangular.copy(collection). withHttpConfig(httpConfig): It lets you set a configuration for $http only for the next call. Check the Local Config HTTP section for an example. Back to top Custom methods customGET(path, [params, headers]): Does a GET to the specific path. Optionally you can set params and headers. customGETLIST(path, [params, headers]): Does a GET to the specific path. In this case, you expect to get an array, not a single element. Optionally you can set params and headers. customDELETE(path, [params, headers]): Does a DELETE to the specific path. Optionally you can set params and headers. customPOST([elem, path, params, headers]): Does a POST to the specific path. Optionally you can set params and headers and elem. Elem is the element to post. If it's not set, it's assumed that it's the element itself from which you're calling this function. customPUT([elem, path, params, headers]): Does a PUT to the specific path. Optionally you can set params and headers and elem. Elem is the element to post. If it's not set, it's assumed that it's the element itself from which you're calling this function. customPATCH([elem, path, params, headers]): Does a PATCH to the specific path. Accepts the same arguments as customPUT. customOperation(operation, path, [params, headers, elem]): This does a custom operation to the path that we specify. This method is actually used from all the others in this subsection. Operation can be one of: get, post, put, remove, head, options, patch, trace addRestangularMethod(name, operation, [path, params, headers, elem]): This will add a new restangular method to this object with the name name to the operation and path specified (or current path otherwise). There's a section on how to do this later. Let's see an example of this: ` All custom methods have an alias where you replace custom by do. For example, customGET is equal to doGET. Just pick whatever syntax you prefer. Back to top Copying elements Before modifying an object, we sometimes want to copy it and then modify the copied object. We can't use angular.copy for this because it'll not change the this bound in the functions we add to the object. In this cases, you must use Restangular.copy(fromElement). Back to top Enhanced promises Restangular uses enhanced promises when returning. What does this mean? All promises returned now have 2 additional methods and collection promises have 3. These are the methods: call(methodName, params*): This will return a new promise of the previous value, after calling the method called methodName with the parameters params. get(fieldName): This will return a new promise for the type of the field. The param of this new promise is the property fieldName from the original promise result. push(object): This method will only be in the promises of arrays. It's a subset of the call method that does a push. $object: This returns the reference to the object that will be filled once the server responds a value. This means that if you call getList this will be an empty array by default. Once the array is returned from the server, this same $object property will get filled with results from the server. I know these explanations are quite complicated, so let's see an example :D. ` Back to top Using values directly in templates Since Angular 1.2, Promise unwrapping in templates has been disabled by default and will be deprecated soon. This means that the following will cease to work: ` ` As this was a really handy way of working with Restangular, I've made a feature similar to $resource that will enable this behavior again: ` ` The $object property is a new property I've added to promises. By default, it'll be an empty array or object. Once the sever has responded with the real value, that object or array is filled with the correct response, therefore making the ng-repeat work :). Pretty neat :D Back to top Using Self reference resources A lot of REST APIs return the URL to self of the element that you're querying. You can use that with Restangular so that you don't have to create the URLs yourself, but use the ones provided by the server. Let's say that when doing a GET to /people you get the following ` In this case, as you can see, the URL to each element can't be guessed so we need to use that to reference the element. Restangular supports both relative and absolute URLs :). How do we do this with Restangular? First, we need to configure the path for the link to self. For that, in the config we do: ` Then, we can just use this :) ` Back to top URL Building Sometimes, we have a lot of nested entities (and their IDs), but we just want the last child. In those cases, doing a request for everything to get the last child is overkill. For those cases, I've added the possibility to create URLs using the same API as creating a new Restangular object. This connections are created without making any requests. Let's see how to do this: ` Back to top Using local $http configuration There're sometimes when you want to set a specific configuration $http configuration just for one Restangular's call. For that, you can use withHttpConfig. You must call that method just before doing the HTTP request. Let's learn how to use it with the following example: ` Back to top Creating new Restangular Methods Let's assume that your API needs some custom methods to work. If that's the case, always calling customGET or customPOST for that method with all parameters is a pain in the ass. That's why every element has a addRestangularMethod method. This can be used together with the hook addElementTransformer to do some neat stuff. Let's see an example to learn this: ` Back to top Adding Custom Methods to Collections Create custom methods for your collection using Restangular.extendCollection(). This is an alias for: Example: Back to top Adding Custom Methods to Models Create custom methods for your models using Restangular.extendModel(). This is an alias for: Back to top Example: Back to top FAQ How can I handle errors? Errors can be checked on the second argument of the then. ` I need to send one header in EVERY Restangular request, how do I do this? You can use defaultHeaders property for this or $httpProvider.defaults.headers, whichever suits you better. defaultsHeaders can be scoped with withConfig so it's really cool. Can I cache requests? $http can cache requests if you send the property cache to true. You can do that for every Restangular request by using defaultHttpFields property. This is the way: ` Can it be used in $routeProvider.resolve? Yes, of course. Every method in Restangular returns a promise so this can be used without any problem. How can I send a delete WITHOUT a body? You must add a requestInterceptor for this. ` My response is actually wrapped with some metadata. How do I get the data in that case? So, let's assume that your data is the following: ` In this case, you'd need to use RestangularProvider's addResponseInterceptor. See the following: ` I use Mongo and the ID of the elements is _id not id as the default. Therefore requests are sent to undefined routes What you need to do is to configure the RestangularFields and set the id field to _id. Let's see how: ` What if each of my models has a different ID name like CustomerID for Customer In some cases, people have different ID name for each entity. For example, they have CustomerID for customer and EquipmentID for Equipment. If that's the case, you can override Restangular's getIdFromElem. For that, you need to do: ` With that, you'd get what you need :) How can I send files in my request using Restangular? This can be done using the customPOST / customPUT method. Look at the following example: ` This basically tells the request to use the Content-Type: multipart/form-data as the header. Also formData is the body of the request, be sure to add all the params here, including the File you want to send of course. There is an issue already closed but with a lot of information from other users and @mgonto as well: GitHub - Restangular How do I handle CRUD operations in a List returned by Restangular? The best option for doing CRUD operations with a list, is to actually use the "real" list, and not the promise. It makes it easy to interact with it. Let's see an example :). ` When you actually get a list by doing ` You're actually assigning a Promise to the owners value of the $scope. As Angular knows how to process promises, if in your view you do an ng-repeat of this $scope variable, results will be shown once the promise is resolved (Response arrived). However, changes to that promise that you do from your HTML won't be seen in the scope, as it's not a real array. It's just a promise of an array. Removing an element from a collection, keeping the collection restangularized While the example above removes the deleted user from the collection, it also overwrites the collection object with a plain array (because of _.without) which no longer knows about its Restangular attributes. If want to keep the restangularized collection, remove the element by modifying the collection in place: When I set baseUrl with a port, it's stripped out. It won't be stripped out anymore as I've ditched $resource :). Now you can happily put the port :). How can I access the unrestangularized element as well as the restangularized one? In order to get this done, you need to use the responseExtractor. You need to set a property there that will point to the original response received. Also, you need to actually copy this response as that response is the one that's going to be restangularized later ` Alternatively, if you just want the stripped out response on any given call, you can use the .plain() method, doing something like this: ` Addendum : If you want originalElement to be the original response object instead of having an original value for each key in your newResponse array, replace ` By ` Restangular fails with status code 0 This is typically caused by Cross Origin Request policy. In order to enable cross domain communication and get correct response with appropriate status codes, you must have the CORS headers attached, even in error responses. If the server does not attach the CORS headers to the response then the XHR object won't parse it, thus the XHR object won't have any response body, status or any other response data inside which typically will cause your request to fail with status code 0. Why does this depend on Lodash / Underscore? This is a very good question. I could've done the code so that I don't depend on Underscore nor Lodash, but I think both libraries make your life SO much easier. They have all of the "functional" stuff like map, reduce, filter, find, etc. With these libraries, you always work with immutable stuff, you get compatibility for browsers which don't implement ECMA5 nor some of these cool methods, and they're actually quicker. So, why not use it? If you've never heard of them, by using Restangular, you could start using them. Trust me, you're never going to give them up after this! Back to top How do I cancel a request? Sometimes you may wish to cancel a request, this is how you would do it: This is a little counterintuitive, so let me explain. Restangular is built on top of $http, which takes a timeout parameter. As per the $http docs: timeout in milliseconds, or promise that should abort the request when resolved. Resolving the promise (canceler in this case), will cancel the request. Back to top Supported Angular versions Restangular supports all Angular versions from 1.0.X - 1.5.X Also, when using Restangular with version >= 1.1.4, in case you're using Restangular inside a callback not handled by Angular, you have to wrap the whole request with $scope.apply to make it work or you need to run one extra $digest manually. Check out https://github.com/mgonto/restangular/issues/71 Back to top Server Frameworks Users reported that this server frameworks play real nice with Restangular, as they let you create a Nested RESTful Resources API easily: Ruby on Rails CakePHP, Laravel and FatFREE, Symfony2 with RestBundle, Silex for PHP Play1 & 2 for Java & scala Dropwizard for Java Restify and Express for NodeJS Tastypie and Django Rest Framework for Django Slim Framework Symfony2 with FOSRestBundle (PHP) Microsoft ASP.NET Web API 2 Grails Framework (example) Back to top Releases Notes New releases notes are together with releases in GitHub at: https://github.com/mgonto/restangular/releases To see old releases notes, you can click here Back to top Contributors Martin Gontovnikas (@mgonto) Paul Dijou (@paul_dijou) Back to top License The MIT License Copyright (c) 2014 Martin Gontovnikas http://www.gon.to/ Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the "Software"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. Back to top

 # # # # # # # # # # # # # # # # # # # #
 Repository: aasm/aasm, index: 2739, word count: 4932 
 # # # # # # # # # # # # # # # # # # # #

The SDK for Jetpac's iOS Deep Belief image recognition frameworkDeepBeliefSDK The SDK for Jetpac's iOS, Android, Linux, and OS X Deep Belief image recognition framework. This is a framework implementing the convolutional neural network architecture described by Alex Krizhevsky, Ilya Sutskever, and Geoffrey Hinton. The processing code has been highly optimized to run within the memory and processing constraints of modern mobile devices, and can analyze an image in under 300ms on an iPhone 5S. It's also easy to use together with OpenCV. We're releasing this framework because we're excited by the power of this approach for general image recognition, especially when it can run locally on low-power devices. It gives your phone the ability to see, and I can't wait to see what applications that helps you build. Getting started iOS Android Linux OS X Raspberry Pi 1 Raspberry Pi 2 Beaglebone Black Javascript Building from Source Adding to an existing application iOS Android Linux OS X Using with OpenCV Documentation Examples Networks API Reference FAQ More Information License Credits Getting Started on iOS You'll need the usual tools required for developing iOS applications - XCode 5, an OS X machine and a modern iOS device (it's been tested as far back as the original iPhone 4). Open up the SimpleExample/SimpleExample.xcodeproj, build and run. You should see some warnings (the example is based on Apple sample code which has some anachronisms in it unfortunately), then once it's running a live camera stream should be visible on your phone. Move it to look closely at your keyboard, and some tags should start appearing in the top left of the screen. These should include things that look like keyboards, including calculators, remote controls, and even typewriters! You should experiment with other objects like coffee cups, doors, televisions, and even dogs if you have any handy! The results will not be human quality, but the important part is that they're capturing meaningful attributes of the images. Understanding images with no context is extremely hard, and while this approach is a massive step forward compared to the previous state of the art, you'll still need to adapt it to the domain you're working in to get the best results in a real application. Happily the framework includes the ability to retrain the network for custom objects that you care about. If you have logos you need to pick out, machine parts you need to spot, or just want to be able to distinguish between different kinds of scenes like offices, beaches, mountains or forests, you should look at the LearningExample sample code. It builds a custom layer on top of the basic neural network that responds to images you've trained it on, and allows you to embed the functionality in your own application easily. There's also this full how-to guide on training and embedding your own custom object recognition code. Adding to an existing iOS application To use the library in your own application: Add the following frameworks to the Link Binary with Libraries in your XCode project's Build Phases: DeepBelief.framework Accelerate.framework libc++.dylib Add #import <DeepBelief/DeepBelief.h> to the top of the file you want to use the code in. You should then be able to use code like this to classify a single image that you've included as a resource in your bundle. The code assumes it's called 'dog.jpg', but you should change it to match the name of your file. Getting Started on Android I've been using Google's ADT toolchain. To get started import the AndroidExample into their custom version of Eclipse, build and run it. Hopefully you should see a similar result to the iPhone app, with live video and tags displayed. You'll need to hold the phone in landscape orientation, look for the tag text and use that as your guide. The Android implementation uses NEON SIMD instructions, so it may not work on older phones, and will definitely not work on non-ARM devices. As a benchmark for expected performance, classification takes around 650ms on a Samsung Galaxy S5. Adding to an existing Android application Under the hood the Android implementation uses a native C++ library that's linked to Java applications using JNA. That means the process of including the code is a bit more complex than on iOS. If you look at the AndroidExample sample code, you'll see a 'libs' folder. This contains a deepbelief.jar file that has the Java interface to the underlying native code, and then inside the armeabi there's jnidispatch.so which is part of JNA and handles the mechanics of calling native functions, and libjpcnn.so which implements the actual object recognition algorithm. You'll need to replicate this folder structure and copy the files to your own application's source tree. Once you've done that, you should be able to import the Java interface to the library: import com.jetpac.deepbelief.DeepBelief.JPCNNLibrary; This class contains a list of Java functions that correspond to exactly to the C interface functions. The class code is available in the AndroidLibrary folder, and you should be able to rebuild it yourself by running ant, but here are the definitions using JNA types: There are a few quirks to using the interface that the example code demonstrates how to work around. jpcnn_create_network() requires a standard filename path, but to distribute the network with an application it needs to be an asset, and because that may be compressed and part of an archive, there's no way to get a path to it. To fix that, initDeepBelief() copys the file to the application's data directory: This has some overhead obviously, so one optimization might be to check for the existence of the file and only copy it over if it doesn't already exist. jpcnn_create_image_buffer_from_uint8_data() needs a plain byte array, and the classifyBitmap() function shows how you can extract what you need from a normal Bitmap object: Native objects are not garbage-collected, so you'll have to remember to explicitly call jpcnn_destroy_image_buffer() and other calls on objects you've created through the library if you want to avoid memory leaks. The rest of classifyBitmap() also demonstrates how to pull out the results as Java-accessible arrays from the JNA types. Getting Started on Linux I've been using Ubuntu 12.04 and 14.04 on x86-64 platforms, but the library ships as a simple .so with minimal dependencies, so hopefully it should work on most distros. As long as you have git and the build-essentials packages installed, you should be able to build an example by running the following commands in a terminal: If the example program ran successfully, the output should look like this: It's analyzing the default Lena image, and giving low probabilities of a wig and a bonnet, which isn't too crazy. You can pass in a command-line argument to analyze your own images, and the results are tab separated text, so you can pipe the results into other programs for further processing. Adding to an existing Linux application To use the library in your own application, first make sure you've run the install.sh script in AndroidLibrary/ to install the libjpcnn.so in /usr/lib, and libjpcnn.h in /usr/include, as described in Getting Started on Linux. Then you should be able to access all the API functions by including the libjpcnn.h header, eg: Here's how you would run a basic classification of a single image, from the SimpleLinux example: Getting Started on OS X Load the examples/OSXExample/MyRecorder.xcodeproj XCode project, build, and run. On any machine with a webcam, you should see a window appear showing live video. Move the webcam until it has a clear view of an object like a wine bottle, glass, mug, or a computer keyboard, and you should start to see overlaid labels and percentages. Adding to an existing OS X application The DeepBelief.framework you'll need is in the OSXLibrary folder. Since installing frameworks in a shared location can be a pain, and Apple recommends keeping applications as self-contained as possible, it's designed to be bundled inside your app folder. The OS X Example sample code uses this approach, and is a good starting point for understanding the process. It has a symbolic link back to the framework, but you'll probably want to copy the library into your own source tree. Apple's documentation on bundling private frameworks is the best documentation for the whole process, but here's the summary of what you'll need to do: Copy DeepBelief.framework into your source tree Drag it into the Frameworks folder of your project in the XCode navigator. Add it to the "Link Binary with Libraries" build phase in the project settings. Add a new "Copy Files Build Phase" to the project build phases. Add the framework as a new file in that build phase, with the destination as "Frameworks". Once you've done that, you should be able to build your app, and then "Show package contents" on the built product should show DeepBelief.framework inside the Contents/Frameworks folder. At that point, just add #import <DeepBelief/DeepBelief.h> and all of the code you need should be identical to the snippets shown in the iOS guide. Using with OpenCV It's pretty straightforward to use DeepBelief together with OpenCV, you just need to convert the images over. There's sample code showing the whole process, but the heart of it is this image format conversion: Once you've done that, you can run the image classification and prediction as normal on the image handle. The sample code has some other convenience classes too, to help make using the library in C++ a bit easier. If you're using the Java interface, the same sort of call sequence works to handle the conversion, though you'll need byte[] arrays and you'll have to call image.get(0, 0, pixels) to actually get the raw image data you need. Getting Started on a Raspberry Pi 1 The library is available as a Raspbian .so library in the RaspberryPiLibrary folder. Using it is very similar to ordinary Linux, and you can follow most of the same instructions, substituting the install.sh in the Pi folder. The biggest difference is that the Pi library uses the GPU to handle a lot of the calculations, so you need to run the example program as a super user, e.g. sudo ./deepbelief. This optimization allows an image to be recognized on a stock Pi in around five seconds, and in three seconds with a boosted GPU clock rate. Getting Started on a Raspberry Pi 2 There's no pre-built library for the Pi 2, and the GPU version that's fastest on the Pi 1 doesn't work, so you can't just re-use the older library. The good news is that the CPU has improved so much, you can get better performance using the optimized Eigen open-source library, and compiling it from source. Here are the instructions: mkdir ~/projects cd ~/projects Clone this repository into ~/projects/DeepBeliefSDK sudo apt-get install -y mercurial hg clone https://bitbucket.org/eigen/eigen ln -s ~/projects/eigen ~/projects/DeepBeliefSDK/eigen cd ~/projects/DeepBeliefSDK/source make clean sudo apt-get install gcc-4.8 g++-4.8 sudo rm -rf /usr/bin/gcc sudo rm -rf /usr/bin/g++ sudo ln -s /usr/bin/gcc-4.8 /usr/bin/gcc sudo ln -s /usr/bin/g++-4.8 /usr/bin/g++ make GEMM=eigen TARGET=pi2 ./jpcnn -i data/dog.jpg -n ../networks/jetpac.ntwk -t -m s -d You should see the classification results, with a time of around 3.8 seconds on a stock Pi 2. If you then overclock it with raspi-config, you can increase that to 3.2s. Getting Started on a Beaglebone Black Like the Pi 2, theres no pre-built library for the Beaglebone Black, but you can build it yourself using the ARM-optimized Eigen open-source library. You will need to use the latest development version of Eigen to make sure NEON is enabled on the default gcc v4.6 compiler though, see this patch. Here are the instructions: mkdir ~/projects cd ~/projects Clone this repository into ~/projects/DeepBeliefSDK sudo apt-get install -y mercurial hg clone https://bitbucket.org/eigen/eigen ln -s ~/projects/eigen ~/projects/DeepBeliefSDK/eigen cd ~/projects/DeepBeliefSDK/source make clean make GEMM=eigen TARGET=beagle ./jpcnn -i data/dog.jpg -n ../networks/jetpac.ntwk -t -m s -d Getting Started with Javascript The Javascript version of the library includes complete source, and a browser demo page. The interface is similar to the C version, but uses native Javascript image objects, camelCase function names, and classes. You'll need to include the jpcnn.js file, and then load the networks/jetpac_untransposed.ntwk file (which is a slightly-modified version of the standard Jetpac network). Then you should be able to call Network.classifyImage(), with an option to accelerate the calculations using WebGL if you're in a browser that supports it. On my 2012 MacBook Pro in Chrome, the WebGL version takes around 600ms, whereas the naive CPU path takes 5 seconds. Building from Source If youre on a platform that isnt covered here, you can compile your own version of the library from the code and Makefile inside the source directory. Its designed to have no dependencies by default, using plain, portable C++, and its possible to get it running on almost any device that has a compiler and the standard C libraries. Here are the minimal instructions: mkdir ~/projects cd ~/projects git clone https://github.com/jetpacapp/DeepBeliefSDK.git cd ~/projects/DeepBeliefSDK/source make clean make ./jpcnn -i data/dog.jpg -n ../networks/jetpac.ntwk -t -m s -d There are two arguments you can pass into the make file to control compilation. PLATFORM (used as make PLATFORM=foo) controls settings for specific devices, for example enabling particular cpus in gcc. The GEMM argument decides which implementation of the matrix multiplication that takes the bulk of the execution time to use, so you can swap in something like Eigen or Intels MKL on supported platforms. Examples All of the sample code projects are included in the 'examples' folder in this git repository. SimpleiOS LearningExample SavedModelExample AndroidExample SimpleLinux OSXExample SimpleOpenCV SimpleiOS This is a self-contained iOS application that shows you how to load the neural network parameters, and process live video to estimate the probability that one of the 1,000 pre-defined Imagenet objects are present. The code is largely based on the SquareCam Apple sample application, which is fairly old and contains some ugly code. If you look for jpcnn_* calls in SquareCamViewController.m you should be able to follow the sequence of first loading the network, applying it to video frames as they arrive, and destroying the objects once you're all done. LearningExample This application allows you to apply the image recognition code to custom objects you care about. It demonstrates how to capture positive and negative examples, feed them into a trainer to create a prediction model, and then apply that prediction model to the live camera feed. It can be a bit messy thanks to all the live video feed code, but if you look for jpcnn_* you'll be able to spot the main flow. Once a prediction model has been fully trained, the parameters are written to the XCode console so they can be used as pre-trained predictors. SavedModelExample This shows how you can use a custom prediction model that you've built using the LearningExample sample code. I've included the simple 'wine_bottle_predictor.txt' that I quickly trained on a bottle of wine, you should be able to run it yourself and see the results of that model's prediction on your own images. AndroidExample A basic Android application that applies the classification algorithm to live video from the phone's camera. The first thing it does after initialization is analyze the standard image-processing image of Lena, you should see log output from that first. After that it continuously analyzes incoming camera frames, both displaying the found labels on screen and printing them to the console. SimpleLinux This is a small command line tool that shows how you can load a network file and classify an image using the default Imagenet categories. If you run it with no arguments, it looks for lena.png and analyzes that, otherwise it tries to load the file name in the first argument as its input image. The network file name is hardcoded to "jetpac.ntwk" in the current folder. In a real application you'll want to set that yourself, either hard-coding it to a known absolute location for the file, or passing it in dynamically as an argument or environment variable. The output of the tool is tab-separated lines, with the probability first followed by the imagenet label, so you can sort and process it easily through pipes on the command line. OSXExample This project is based on Apple's MyRecorder sample code, which is both quite old and fairly gnarly thanks to its use of QTKit! The complexity is mostly in the way it accesses the webcam, and converts the supplied image down to a simple array of RGB bytes to feed into the neural network code. If you search for 'jpcnn' in the code, you'll see the calls to the library nestled amongst all the plumbing for the interface and the video, they should be fairly straightforward. The main steps are loading the 'jetpac.ntwk' neural network, that's included as a resource in the app, then extracting an image from the video, classifying it, and displaying the found labels in the UI. When you build and run the project, you should see a window appear with the webcam view in it, and any found labels overlaid on top. You'll also see some performance stats being output to the console - on my mid-2012 Macbook Pro it takes around 60ms to do the calculations. SimpleOpenCV This is a basic Linux command-line tool that shows how OpenCV and the DeepBelief framework can work together. The main() function uses C++ classes defined in deepbeliefopencv.h to load a network, then it creates an OpenCV image from either lena.png or another file supplied on the command line. A wrapper class for the library's image handle object is then used to convert the OpenCV image into one the DeepBelief framework can analyze. The classification is run on that image, and the found labels are printed out. If you're doing a lot of work with OpenCV, the most crucial part for you is probably the conversion of the image objects between the two systems. That's defined in deepbeliefopencv.cpp in the Image::Image(const cv::Mat& image) constructor, and the section on using OpenCV covers what's going on in the actual code. Networks There are currently three pre-built models available in the networks folder. jetpac.ntwk is the in-house model used here at Jetpac, and it's licensed under the same BSD conditions as the rest of the project. It has a few oddities, like only 999 labels (a file truncation problem I discovered too late during training) but has served us well and is a good place to start. The excellent libccv project also made a couple of networks available under a Creative Commons Attribution 4.0 International License. I've converted them over into a binary format, and they're in the networks folder as ccv2010.ntwk and ccv2012.ntwk. You should be able to substitute these in anywhere you'd use jetpac.ntwk. The 2012 file has very similar labels to our original, and the 2010 is an older architecture. You may notice slightly slower performance, the arrangement of the layers is a bit different (in technical terms the local-response normalization happens before the max-pooling in these models, which is more expensive since there's more data to normalize), but the accuracy of the 2012 model especially is good. One common technique in the academic world is to take multiple models and merge their votes for higher accuracy, so one application of the multiple models might be improved accuracy. API Reference Because we reuse the same code across a lot of different platforms, we use a plain-old C interface to our library. All of the handles to different objects are opaque pointers, and you have to explictly call the *_destroy_* function on any handles that have been returned from *_create_* calls if you want to avoid memory leaks. Input images are created from raw arrays of 8-bit RGB data, you can see how to build those from iOS types by searching for jpcnn_create_image_buffer() in the sample code. The API is broken up into two sections. The first gives you access to one of the pre-trained neural networks you'll find in the networks folder. These have been trained on 1,000 Imagenet categories, and the output will give you a decent general idea of what's in an image. The second section lets you replace the highest layer of the neural network with your own classification step. This means you can use it to recognize the objects you care about more accurately. Pre-trained calls jpcnn_create_network jpcnn_destroy_network jpcnn_create_image_buffer_from_file jpcnn_create_image_buffer_from_uint8_data jpcnn_destroy_image_buffer jpcnn_classify_image jpcnn_print_network Custom training calls jpcnn_create_trainer jpcnn_destroy_trainer jpcnn_train jpcnn_create_predictor_from_trainer jpcnn_destroy_predictor jpcnn_load_predictor jpcnn_print_predictor jpcnn_predict jpcnn_create_network void* jpcnn_create_network(const char* filename) This takes the filename of the network parameter file as an input, and builds a neural network stack based on that definition. Right now the only available file is the 1,000 category jetpac.ntwk, built here at Jetpac based on the approach used by Krizhevsky to win the Imagenet 2012 competition. You'll need to make sure you include this 60MB file in the 'Copy Files' build phase of your application, and then call something like this to get the actual path: jpcnn_destroy_network void jpcnn_destroy_network(void* networkHandle) Once you're finished with the neural network, call this to destroy it and free up the memory it used. jpcnn_create_image_buffer_from_file void* jpcnn_create_image_buffer_from_file(const char* filename) Takes a filename (see above for how to get one from your bundle) and creates an image object that you can run the classification process on. It can load PNGS and JPEGS. jpcnn_create_image_buffer_from_uint8_data void* jpcnn_create_image_buffer_from_uint8_data(unsigned char* pixelData, int width, int height, int channels, int rowBytes, int reverseOrder, int doRotate) If you already have data in memory, you can use this function to copy it into an image object that you can then classify. It's useful if you're doing video capture, as the sample code does. jpcnn_destroy_image_buffer void jpcnn_destroy_image_buffer(void* imageHandle) Once you're done classifying an image, call this to free up the memory it used. jpcnn_classify_image void jpcnn_classify_image(void* networkHandle, void* inputHandle, unsigned int flags, int layerOffset, float** outPredictionsValues, int* outPredictionsLength, char*** outPredictionsNames, int* outPredictionsNamesLength) This is how you actually get tags for an image. It takes in a neural network and an image, and returns an array of floats. Each float is a predicted value for an imagenet label, between 0 and 1, where higher numbers are more confident predictions. The three outputs are: outPredictionsValues is a pointer to the array of predictions. outPredictionsLength holds the length of the predictions array. outPredictionsNames is an array of C strings representing imagenet labels, each corresponding to the prediction value at the same index in outPredictionsValues. outPredictionsNamesLength is the number of name strings in the label array. In the simple case this is the same as the number of predictions, but in different modes this can get more complicated! See below for details. In the simple case you can leave the flags and layerOffset arguments as zero, and you'll get an array of prediction values out. Pick the highest (possibly with a threshold like 0.1 to avoid shaky ones), and you can use that as a simple tag for the image. There are several optional arguments you can use to improve your results though. layerOffset The final output of the neural network represents the high-level categories that it's been trained on, but often you'll want to work with other types of objects. The good news is that it's possible to take the results from layers that are just before the final one, and use those as inputs to simple statistical algorithms to recognize entirely new kinds of things. This paper on Decaf does a good job of describing the approach, but the short version is that those high-level layers can be seen as adjectives that help the output layer make its final choice between categories, and those same adjectives turn out to be useful for choosing between a lot of other categories it hasn't been trained on too. For example, there might be some signals that correlate with 'spottiness' and 'furriness', which would be useful for picking out leopards, even if they were originally learned from pictures of dalmatians. The layerOffset argument lets you control which layer you're sampling, as a negative offset from the start of the network. Try setting it to -2, and you should get an array of 4096 floats in outPredictionsValues, though since these are no longer representing Imagenet labels the names array will no longer be valid. You can then feed those values into a training system like libSVM to help you distinguish between the kinds of objects you care about. flags The image recognition algorithm always crops the input image to the biggest square that fits within its bounds, resamples that area to 256x256 pixels and then takes a slightly smaller 224x224 sample square from somewhere within that main square. The flags argument controls how that 224-pixel sample square is positioned within the larger one. If it's left as zero, then it's centered with a 16 pixel margin at all edges. The sample code uses JPCNN_RANDOM_SAMPLE to jitter the origin of the 224 square randomly within the bounds each call, since this, combined with smoothing of the results over time, helps ensure that the identification of tags is robust to slight position changes. The JPCNN_MULTISAMPLE flag takes ten different sample positions within the image and runs them all through the classification pipeline simultaneously. This is a costly operation, so it doesn't tend to be practical on low-processing-power platforms like the iPhone. jpcnn_print_network void jpcnn_print_network(void* networkHandle) This is a debug logging call that prints information about a loaded neural network. jpcnn_create_trainer void* jpcnn_create_trainer() Returns a handle to a trainer object that you can feed training examples into to build your own custom prediction model. jpcnn_destroy_trainer void jpcnn_destroy_trainer(void* trainerHandle) Disposes of the memory used by the trainer object and destroys it. jpcnn_train void jpcnn_train(void* trainerHandle, float expectedLabel, float* predictions, int predictionsLength) To create your own custom prediction model, you need to train it using 'positive' examples of images containing the object you care about, and 'negative' examples of images that don't. Once you've created a trainer object, you can call this with the neural network results for each positive or negative image, and with an expectedLabel of '0.0' for negatives and '1.0' for positives. Picking the exact number of each you'll need is more of an art than a science, since it depends on how easy your object is to recognize and how cluttered your environment is, but I've had decent results with as few as a hundred of each. You can use the output of any layer of the neural network, but I've found using the penultimate one works well. I discuss how to do this above in the layerOffset section. To see how this works in practice, try out the LearningExample sample code for yourself. jpcnn_create_predictor_from_trainer void* jpcnn_create_predictor_from_trainer(void* trainerHandle) Once you've passed in all your positive and negative examples to jpcnn_train, you can call this to build a predictor model from them all. Under the hood, it's using libSVM to create a support vector machine model based on the examples. jpcnn_destroy_predictor void jpcnn_destroy_predictor(void* predictorHandle) Deallocates any memory used by the predictor model, call this once you're finished with it. jpcnn_load_predictor void* jpcnn_load_predictor(const char* filename) Loads a predictor you've already created from a libSVM-format text file. Since you can't save files on iOS devices, the only way to create this file in the first place is to call jpcnn_print_predictor once you've created a predictor, and then copy and paste the results from the developer console into a file, and then add it to your app's resources. The SavedModelExample sample code shows how to use this call. jpcnn_print_predictor void jpcnn_print_predictor(void* predictorHandle) Outputs the parameters that define a custom predictor to stderr (and hence the developer console in XCode). You'll need to copy and paste this into your own text file to subsequently reload the predictor. jpcnn_predict float jpcnn_predict(void* predictorHandle, float* predictions, int predictionsLength) Given the output from a pre-trained neural network, and a custom prediction model, returns a value estimating the probability that the image contains the object it has been trained against. FAQ Is this available for platforms other than iOS, Android, OS X, and Linux x86-64? Not right now. I hope to make it available on other devices like the Raspberry Pi in the future. I recommend checking out Caffe, OverFeat and libCCV if you're on the desktop too, they're great packages. Is the source available? Not at the moment. The compiled library and the neural network parameter set are freely reusable in your own apps under the BSD license though. Can I train my own networks? There aren't any standard formats for sharing large neural networks unfortunately, so there's no easy way to import other CNNs into the app. The custom training should help you apply the included pre-trained network to your own problems to a large extent though. More Information Join the Deep Belief Developers email list to find out more about the practical details of implementing deep learning. License The binary framework and jetpac.ntwk network parameter file are under the BSD three-clause license, included in this folder as LICENSE. All source code is under that BSD license unless otherwise noted. The ccv2010.ntwk and ccv2012.ntwk network models were converted from files created as part of the LibCCV project and are licensed under the Creative Commons Attribution 4.0 International License. To view a copy of this license, visit http://creativecommons.org/licenses/by/4.0/. Credits Big thanks go to: Daniel Nouri for his invaluable help on CNNs. Alex Krizhevsky, Ilya Sutskever, and Geoffrey Hinton for their ground-breaking work on ConvNet. Yann LeCun for his pioneering research and continuing support of the field. The Berkeley Vision and Learning Center for their work on lightweight custom training of CNNs. My colleagues Cathrine, Dave, Julian, and Sophia at Jetpac for all their help. Pete Warden

 # # # # # # # # # # # # # # # # # # # #
 Repository: avelino/awesome-go, index: 96, word count: 26024 
 # # # # # # # # # # # # # # # # # # # #

A curated list of awesome Go frameworks, libraries and software Awesome Go Sponsorships We have no monthly cost, but we have employees working hard to maintain the Awesome Go, with money raised we can repay the effort of each person involved! All billing and distribution will be open to the entire community. A curated list of awesome Go frameworks, libraries and software. Inspired by awesome-python. Contributing Please take a quick gander at the contribution guidelines first. Thanks to all contributors; you rock! If you see a package or project here that is no longer maintained or is not a good fit, please submit a pull request to improve this file. Thank you! Contents Awesome Go Audio and Music Authentication and OAuth Bot Building Build Automation Command Line Configuration Continuous Integration CSS Preprocessors Data Structures Database Database Drivers Date and Time Distributed Systems Dynamic DNS Email Embeddable Scripting Languages Error Handling File Handling Financial Forms Functional Game Development Generation and Generics Geographic Go Compilers Goroutines GUI Hardware Images IoT Job Scheduler JSON Logging Machine Learning Messaging Microsoft Office Microsoft Excel Miscellaneous Dependency Injection Project Layout Strings Uncategorized Natural Language Processing Networking HTTP Clients OpenGL ORM Package Management Performance Query Language Resource Embedding Science and Data Analysis Security Serialization Server Applications Stream Processing Template Engines Testing Text Processing Third-party APIs Utilities UUID Validation Version Control Video Web Frameworks Middlewares Actual middlewares Libraries for creating HTTP middlewares Routers WebAssembly Windows XML Tools Code Analysis Editor Plugins Go Generate Tools Go Tools Software Packages DevOps Tools Other Software Resources Benchmarks Conferences E-Books Gophers Meetups Style Guides Twitter Websites Tutorials Audio and Music Libraries for manipulating audio. flac - Native Go FLAC encoder/decoder with support for FLAC streams. gaad - Native Go AAC bitstream parser. GoAudio - Native Go Audio Processing Library. gosamplerate - libsamplerate bindings for go. id3v2 - ID3 decoding and encoding library for Go. malgo - Mini audio library. minimp3 - Lightweight MP3 decoder library. mix - Sequence-based Go-native audio mixer for music apps. music-theory - Music theory models in Go. Oto - A low-level library to play sound on multiple platforms. PortAudio - Go bindings for the PortAudio audio I/O library. portmidi - Go bindings for PortMidi. vorbis - "Native" Go Vorbis decoder (uses CGO, but has no dependencies). waveform - Go package capable of generating waveform images from audio streams. Authentication and OAuth Libraries for implementing authentications schemes. authboss - Modular authentication system for the web. It tries to remove as much boilerplate and "hard things" as possible so that each time you start a new web project in Go, you can plug it in, configure, and start building your app without having to build an authentication system each time. branca - Golang implementation of Branca Tokens. casbin - Authorization library that supports access control models like ACL, RBAC, ABAC. cookiestxt - provides parser of cookies.txt file format. go-email-normalizer - Golang library for providing a canonical representation of email address. go-guardian - Go-Guardian is a golang library that provides a simple, clean, and idiomatic way to create powerful modern API and web authentication that supports LDAP, Basic, Bearer token and Certificate based authentication. go-jose - Fairly complete implementation of the JOSE working group's JSON Web Token, JSON Web Signatures, and JSON Web Encryption specs. go-oauth2-server - Standalone, specification-compliant, OAuth2 server written in Golang. gologin - chainable handlers for login with OAuth1 and OAuth2 authentication providers. gorbac - provides a lightweight role-based access control (RBAC) implementation in Golang. goth - provides a simple, clean, and idiomatic way to use OAuth and OAuth2. Handles multiple providers out of the box. httpauth - HTTP Authentication middleware. jeff - Simple, flexible, secure and idiomatic web session management with pluggable backends. jwt - Clean and easy to use implementation of JSON Web Tokens (JWT). jwt - Lightweight JSON Web Token (JWT) library. jwt - Safe, simple and fast JSON Web Tokens for Go. jwt-auth - JWT middleware for Golang http servers with many configuration options. loginsrv - JWT login microservice with plugable backends such as OAuth2 (Github), htpasswd, osiam. oauth2 - Successor of goauth2. Generic OAuth 2.0 package that comes with JWT, Google APIs, Compute Engine and App Engine support. osin - Golang OAuth2 server library. otpgo - Time-Based One-Time Password (TOTP) and HMAC-Based One-Time Password (HOTP) library for Go. paseto - Golang implementation of Platform-Agnostic Security Tokens (PASETO). permissions2 - Library for keeping track of users, login states and permissions. Uses secure cookies and bcrypt. rbac - Minimalistic RBAC package for Go applications. scope - Easily Manage OAuth2 Scopes In Go. scs - Session Manager for HTTP servers. securecookie - Efficient secure cookie encoding/decoding. session - Go session management for web servers (including support for Google App Engine - GAE). sessiongate-go - Go session management using the SessionGate Redis module. sessions - Dead simple, highly performant, highly customizable sessions service for go http servers. sessionup - Simple, yet effective HTTP session management and identification package. sjwt - Simple jwt generator and parser. Bot Building Libraries for building and working with bots. echotron - Library for Telegram Bots written in pure Go. ephemeral-roles - A Discord bot for managing ephemeral roles based upon voice channel member presence. go-chat-bot - IRC, Slack & Telegram bot written in Go. go-joe - A general-purpose bot library inspired by Hubot but written in Go. go-sarah - Framework to build bot for desired chat services including LINE, Slack, Gitter and more. go-tgbot - Pure Golang Telegram Bot API wrapper, generated from swagger file, session-based router and middleware. go-twitch-irc - Libary to write bots for twitch.tv chat Golang CryptoTrading Bot - A golang implementation of a console-based trading bot for cryptocurrency exchanges. govkbot - Simple Go VK bot library. hanu - Framework for writing Slack bots. Kelp - official trading and market-making bot for the Stellar DEX. Works out-of-the-box, written in Golang, compatible with centralized exchanges and custom trading strategies. margelet - Framework for building Telegram bots. micha - Go Library for Telegram bot api. olivia - A chatbot built with an artificial neural network. slack-bot - Ready to use Slack Bot for lazy developers: Custom commands, Jenkins, Jira, Bitbucket, Github... slacker - Easy to use framework to create Slack bots. slackscot - Another framework for building Slack bots. tbot - Telegram bot server with API similar to net/http. telebot - Telegram bot framework written in Go. telegram-bot-api - Simple and clean Telegram bot client. Tenyks - Service oriented IRC bot using Redis and JSON for messaging. Build Automation Libraries and tools helping with build automation. 1build - Command line tool to frictionlessly manage project-specific commands. anko - Simple application watcher for multiple programming languages. gaper - Builds and restarts a Go project when it crashes or some watched file changes. gilbert - Build system and task runner for Go projects. goyek - Create build pipelines in Go. mmake - Modern Make. realize - Go build system with file watchers and live reload. Run, build and watch file changes with custom paths. Task - simple "Make" alternative. taskctl - Concurrent task runner. Command Line Standard CLI Libraries for building standard or basic Command Line applications. argparse - Command line argument parser inspired by Python's argparse module. argv - Go library to split command line string as arguments array using the bash syntax. cli - Feature-rich and easy to use command-line package based on golang struct tags. cli - Simple and complete API for building command line interfaces in Go. climax - Alternative CLI with "human face", in spirit of Go command. clr - A Simple and Clear CLI library. Dependency free. cmd - Extends the standard flag package to support sub commands and more in idomatic way. cmdr - A POSIX/GNU style, getopt-like command-line UI Go library. cobra - Commander for modern Go CLI interactions. commandeer - Dev-friendly CLI apps: sets up flags, defaults, and usage based on struct fields and tags. complete - Write bash completions in Go + Go command bash completion. Dnote - A simple command line notebook with multi-device sync. env - Tag-based environment configuration for structs. flag - Simple but powerful command line option parsing library for Go supporting subcommand. flaggy - A robust and idiomatic flags package with excellent subcommand support. flagvar - A collection of flag argument types for Go's standard flag package. go-arg - Struct-based argument parsing in Go. go-commander - Go library to simplify CLI workflow. go-flags - go command line option parser. go-getoptions - Go option parser inspired on the flexibility of Perls GetOpt::Long. gocmd - Go library for building command line applications. hiboot cli - cli application framework with auto configuration and dependency injection. job - JOB, make your short-term command as a long-term job. kingpin - Command line and flag parser supporting sub commands. liner - Go readline-like library for command-line interfaces. mitchellh/cli - Go library for implementing command-line interfaces. mow.cli - Go library for building CLI applications with sophisticated flag and argument parsing and validation. ops - Unikernel Builder/Orchestrator. pflag - Drop-in replacement for Go's flag package, implementing POSIX/GNU-style --flags. sand - Simple API for creating interpreters and so much more. sflags - Struct based flags generator for flag, urfave/cli, pflag, cobra, kingpin and other libraries. strumt - Library to create prompt chain. ts - Timestamp convert & compare tool. ukautz/clif - Small command line interface framework. urfave/cli - Simple, fast, and fun package for building command line apps in Go (formerly codegangsta/cli). wlog - Simple logging interface that supports cross-platform color and concurrency. wmenu - Easy to use menu structure for cli applications that prompts users to make choices. Advanced Console UIs Libraries for building Console Applications and Console User Interfaces. asciigraph - Go package to make lightweight ASCII line graph in command line apps with no other dependencies. aurora - ANSI terminal colors that supports fmt.Printf/Sprintf. box-cli-maker - Make Highly Customized Boxes for your CLI. cfmt - Contextual fmt inspired by bootstrap color classes. cfmt - Simple and convenient formatted stylized output fully compatible with fmt library. chalk - Intuitive package for prettifying terminal/console output. colourize - Go library for ANSI colour text in terminals. ctc - The non-invasive cross-platform terminal color library does not need to modify the Print method. go-ataman - Go library for rendering ANSI colored text templates in terminals. go-colorable - Colorable writer for windows. go-colortext - Go library for color output in terminals. go-isatty - isatty for golang. go-prompt - Library for building a powerful interactive prompt, inspired by python-prompt-toolkit. gocui - Minimalist Go library aimed at creating Console User Interfaces. gommon/color - Style terminal text. gookit/color - Terminal color rendering tool library, support 16 colors, 256 colors, RGB color rendering output, compatible with Windows. marker - Easiest way to match and mark strings for colorful terminal outputs. mpb - Multi progress bar for terminal applications. progressbar - Basic thread-safe progress bar that works in every OS. pterm - A library to beautify console output on every platform with many combinable components. simpletable - Simple tables in terminal with Go. tabby - A tiny library for super simple Golang tables. table - Small library for terminal color based tables . tabular - Print ASCII tables from command line utilities without the need to pass large sets of data to the API. termbox-go - Termbox is a library for creating cross-platform text-based interfaces. termdash - Go terminal dashboard based on termbox-go and inspired by termui. termui - Go terminal dashboard based on termbox-go and inspired by blessed-contrib. uilive - Library for updating terminal output in realtime. uiprogress - Flexible library to render progress bars in terminal applications. uitable - Library to improve readability in terminal apps using tabular data. yacspin - Yet Another CLi Spinner package, for working with terminal spinners. Configuration Libraries for configuration parsing. aconfig - Simple, useful and opinionated config loader. cleanenv - Minimalistic configuration reader (from files, ENV, and wherever you want). config - A lightweight yet powerful config package for Go projects. config - Cloud native application configuration. Bind ENV to structs in only two lines. config - JSON or YAML configuration wrapper with environment variables and flags parsing. configuration - Library for initializing configuration structs from env variables, files, flags and 'default' tag. configure - Provides configuration through multiple sources, including JSON, flags and environment variables. configuro - opinionated configuration loading & validation framework from ENV and Files focused towards 12-Factor compliant applications. confita - Load configuration in cascade from multiple backends into a struct. conflate - Library/tool to merge multiple JSON/YAML/TOML files from arbitrary URLs, validation against a JSON schema, and application of default values defined in the schema. env - Parse environment variables to Go structs (with defaults). envcfg - Un-marshaling environment variables to Go structs. envconf - Configuration from environment. envconfig - Read your configuration from environment variables. envh - Helpers to manage environment variables. fig - Tiny library for reading configuration from a file and from environment variables (with validation & defaults). gcfg - read INI-style configuration files into Go structs; supports user-defined types and subsections. genv - Read environment variables easily with dotenv support. go-aws-ssm - Go package that fetches parameters from AWS System Manager - Parameter Store. go-ini - A Go package that marshals and unmarshals INI-files. go-ssm-config - Go utility for loading configuration parameters from AWS SSM (Parameter Store). go-up - A simple configuration library with recursive placeholders resolution and no magic. goConfig - Parses a struct as input and populates the fields of this struct with parameters from command line, environment variables and configuration file. godotenv - Go port of Ruby's dotenv library (Loads environment variables from .env). gofigure - Go application configuration made easy. gone/jconf - Modular JSON configuration. Keep you config structs along with the code they configure and delegate parsing to submodules without sacrificing full config serialization. gonfig - Tag-based configuration parser which loads values from different providers into typesafe struct. gookit/config - application config manage(load,get,set). support JSON, YAML, TOML, INI, HCL. multi file load, data override merge. harvester - Harvester, a easy to use static and dynamic configuration package supportig seeding, env vars and Consul integration. hjson - Human JSON, a configuration file format for humans. Relaxed syntax, fewer mistakes, more comments. hocon - Configuration library for working with the HOCON(a human-friendly JSON superset) format, supports features like environment variables, referencing other values, comments and multiple files. ingo - Flags persisted in an ini-like config file. ini - Go package to read and write INI files. joshbetz/config - Small configuration library for Go that parses environment variables, JSON files, and reloads automatically on SIGHUP. kelseyhightower/envconfig - Go library for managing configuration data from environment variables. koanf - Light weight, extensible library for reading config in Go applications. Built in support for JSON, TOML, YAML, env, command line. konfig - Composable, observable and performant config handling for Go for the distributed processing era. mini - Golang package for parsing ini-style configuration files. nasermirzaei89/env - Simple useful package for read environment variables. onion - Layer based configuration for Go, Supports JSON, TOML, YAML, properties, etcd, env, and encryption using PGP. store - Lightweight configuration manager for Go. swap - Instantiate/configure structs recursively, based on build environment. (YAML, TOML, JSON and env). typenv - Minimalistic, zero dependency, typed environment variables library. viper - Go configuration with fangs. xdg - Go implementation of the XDG Base Directory Specification and XDG user directories. xdg - Cross platform package that follows the XDG Standard. Continuous Integration Tools for help with continuous integration. CDS - Enterprise-Grade CI/CD and DevOps Automation Open Source Platform. drone - Drone is a Continuous Integration platform built on Docker, written in Go. duci - A simple ci server no needs domain specific languages. gomason - Test, Build, Sign, and Publish your go binaries from a clean workspace. goveralls - Go integration for Coveralls.io continuous code coverage tracking system. overalls - Multi-Package go project coverprofile for tools like goveralls. roveralls - Recursive coverage testing tool. CSS Preprocessors Libraries for preprocessing CSS files. gcss - Pure Go CSS Preprocessor. go-libsass - Go wrapper to the 100% Sass compatible libsass project. Data Structures Generic datastructures and algorithms in Go. algorithms - Algorithms and data structures.CLRS study. binpacker - Binary packer and unpacker helps user build custom binary stream. bit - Golang set data structure with bonus bit-twiddling functions. bitset - Go package implementing bitsets. bloom - Bloom filters implemented in Go. bloom - Golang Bloom filter implementation. bloomfilter - Yet another Bloomfilter implementation in Go, compatible with Java's Guava library. boomfilters - Probabilistic data structures for processing continuous, unbounded streams. cmap - a thread-safe concurrent map for go, support using interface{} as key and auto scale up shards. concurrent-writer - Highly concurrent drop-in replacement for bufio.Writer. conjungo - A small, powerful and flexible merge library. count-min-log - Go implementation Count-Min-Log sketch: Approximately counting with approximate counters (Like Count-Min sketch but using less memory). crunch - Go package implementing buffers for handling various datatypes easily. cuckoo-filter - Cuckoo filter: a comprehensive cuckoo filter, which is configurable and space optimized compared with other implements, and all features mentioned in original paper is available. cuckoofilter - Cuckoo filter: a good alternative to a counting bloom filter implemented in Go. deque - A highly optimized double-ended queue. deque - Fast ring-buffer deque (double-ended queue). dict - Python-like dictionaries (dict) for Go. dsu - Disjoint Set data structure implementation in Go. encoding - Integer Compression Libraries for Go. go-adaptive-radix-tree - Go implementation of Adaptive Radix Tree. go-datastructures - Collection of useful, performant, and thread-safe data structures. go-edlib - Go string comparison and edit distance algorithms library (Levenshtein, LCS, Hamming, Damerau levenshtein, Jaro-Winkler, etc.) compatible with Unicode. go-ef - A Go implementation of the Elias-Fano encoding. go-geoindex - In-memory geo index. go-mcache - Fast in-memory key:value store/cache library. Pointer caches. go-rquad - Region quadtrees with efficient point location and neighbour finding. gocache - A complete Go cache library with mutiple stores (memory, memcache, redis, ...), chainable, loadable, metrics cache and more. goconcurrentqueue - Concurrent FIFO queue. gods - Go Data Structures. Containers, Sets, Lists, Stacks, Maps, BidiMaps, Trees, HashSet etc. gofal - fractional api for Go. golang-set - Thread-Safe and Non-Thread-Safe high-performance sets for Go. goset - A useful Set collection implementation for Go. goskiplist - Skip list implementation in Go. gostl - Data structure and algorithm library for go, designed to provide functions similar to C++ STL. gota - Implementation of dataframes, series, and data wrangling methods for Go. goterator - Iterator implementation to provide map and reduce functionalities. hide - ID type with marshalling to/from hash to prevent sending IDs to clients. hilbert - Go package for mapping values to and from space-filling curves, such as Hilbert and Peano curves. hyperloglog - HyperLogLog implementation with Sparse, LogLog-Beta bias correction and TailCut space reduction. iter - Go implementation of C++ STL iterators and algorithms. levenshtein - Levenshtein distance and similarity metrics with customizable edit costs and Winkler-like bonus for common prefix. levenshtein - Implementation to calculate levenshtein distance in Go. merkletree - Implementation of a merkle tree providing an efficient and secure verification of the contents of data structures. mspm - Multi-String Pattern Matching Algorithm for information retrieval. nan - Zero allocation Nullable structures in one library with handy conversion functions, marshallers and unmarshallers. null - Nullable Go types that can be marshalled/unmarshalled to/from JSON. ordered-concurrently - Go module that processes work concurrently and returns output in a channel in the order of input. parapipe - FIFO Pipeline which parallels execution on each stage while maintaining the order of messages and results. parsefields - Tools for parse JSON-like logs for collecting unique fields and events. pipeline - An implementation of pipelines with fan-in and fan-out. ptrie - An implementation of prefix tree. remember-go - A universal interface for caching slow database queries (backed by redis, memcached, ristretto, or in-memory). ring - Go implementation of a high performance, thread safe bloom filter. roaring - Go package implementing compressed bitsets. set - Simple set data structure implementation in Go using LinkedHashMap. skiplist - Very fast Go Skiplist implementation. skiplist - Skiplist implementation in Go. slices - Functions that operate on slices; like package strings but adapted to work with slices. timedmap - Map with expiring key-value pairs. treap - Persistent, fast ordered map using tree heaps. trie - Trie implementation in Go. ttlcache - In-memory string-interface{} cache with various time-based expiration options and callbacks. typ - Null Types, Safe primitive type conversion and fetching value from complex structures. willf/bloom - Go package implementing Bloom filters. Database Databases implemented in Go. badger - Fast key-value store in Go. bbolt - An embedded key/value database for Go. bcache - Eventually consistent distributed in-memory cache Go library. BigCache - Efficient key/value cache for gigabytes of data. Bitcask - Bitcask is an embeddable, persistent and fast key-value (KV) database written in pure Go with predictable read/write performance, low latency and high throughput thanks to the bitcask on-disk layout (LSM+WAL). buntdb - Fast, embeddable, in-memory key/value database for Go with custom indexing and spatial support. cache - In-memory key:value store with expiration time, 0 dependencies, <100 LoC, 100% coverage. cache2go - In-memory key:value cache which supports automatic invalidation based on timeouts. clusteredBigCache - BigCache with clustering support and individual item expiration. cockroach - Scalable, Geo-Replicated, Transactional Datastore. Coffer - Simple ACID key-value database that supports transactions. couchcache - RESTful caching micro-service backed by Couchbase server. CovenantSQL - CovenantSQL is a SQL database on blockchain. Databunker - Personally identifiable information (PII) storage service built to comply with GDPR and CCPA. dgraph - Scalable, Distributed, Low Latency, High Throughput Graph Database. diskv - Home-grown disk-backed key-value store. eliasdb - Dependency-free, transactional graph database with REST API, phrase search and SQL-like query language. fastcache - fast thread-safe inmemory cache for big number of entries. Minimizes GC overhead. GCache - Cache library with support for expirable Cache, LFU, LRU and ARC. go-cache - In-memory key:value store/cache (similar to Memcached) library for Go, suitable for single-machine applications. goleveldb - Implementation of the LevelDB key/value database in Go. groupcache - Groupcache is a caching and cache-filling library, intended as a replacement for memcached in many cases. hare - A simple database management system that stores each table as a text file of line-delimited JSON. immudb - immudb is a lightweight, high-speed immutable database for systems and applications written in Go. influxdb - Scalable datastore for metrics, events, and real-time analytics. Kivik - Kivik provides a common Go and GopherJS client library for CouchDB, PouchDB, and similar databases. ledisdb - Ledisdb is a high performance NoSQL like Redis based on LevelDB. levigo - Levigo is a Go wrapper for LevelDB. moss - Moss is a simple LSM key-value storage engine written in 100% Go. nutsdb - Nutsdb is a simple, fast, embeddable, persistent key/value store written in pure Go. It supports fully serializable transactions and many data structures such as list, set, sorted set. piladb - Lightweight RESTful database engine based on stack data structures. pogreb - Embedded key-value store for read-heavy workloads. prometheus - Monitoring system and time series database. pudge - Fast and simple key/value store written using Go's standard library. rosedb - An embedded k-v database based on LSM+WAL, supports string, list, hash, set, zset. rqlite - The lightweight, distributed, relational database built on SQLite. Scribble - Tiny flat file JSON store. slowpoke - Key-value store with persistence. tempdb - Key-value store for temporary items. tidb - TiDB is a distributed SQL database. Inspired by the design of Google F1. tiedot - Your NoSQL database powered by Golang. ttlcache - In-memory key value storage with TTL for each record. unitdb - Fast timeseries database for IoT, realtime messaging applications. Access unitdb with pubsub over tcp or websocket using github.com/unit-io/unitd application. Vasto - A distributed high-performance key-value store. On Disk. Eventual consistent. HA. Able to grow or shrink without service interruption. VictoriaMetrics - fast, resource-effective and scalable open source time series database. May be used as long-term remote storage for Prometheus. Supports PromQL. Database schema migration. avro - Discover SQL schemas and convert them to AVRO schemas. Query SQL records into AVRO bytes. darwin - Database schema evolution library for Go. go-fixtures - Django style fixtures for Golang's excellent built-in database/sql library. go-pg-migrate - CLI-friendly package for go-pg migrations management. go-pg-migrations - A Go package to help write migrations with go-pg/pg. goose - Database migration tool. You can manage your database's evolution by creating incremental SQL or Go scripts. gormigrate - Database schema migration helper for Gorm ORM. migrate - Database migrations. CLI and Golang library. migrator - Dead simple Go database migration library. migrator - MySQL database migrator designed to run migrations to your features and manage database schema update with intuitive go code. pravasan - Simple Migration tool - currently for MySQL but planning to soon support Postgres, SQLite, MongoDB, etc. schema - Library to embed schema migrations for database/sql-compatible databases inside your Go binaries. skeema - Pure-SQL schema management system for MySQL, with support for sharding and external online schema change tools. soda - Database migration, creation, ORM, etc... for MySQL, PostgreSQL, and SQLite. sql-migrate - Database migration tool. Allows embedding migrations into the application using go-bindata. Database tools. chproxy - HTTP proxy for ClickHouse database. clickhouse-bulk - Collects small insterts and sends big requests to ClickHouse servers. datagen - A fast data generator that's multi-table aware and supports multi-row DML. dbbench - Database benchmarking tool with support for several databases and scripts. go-mysql - Go toolset to handle MySQL protocol and replication. go-mysql-elasticsearch - Sync your MySQL data into Elasticsearch automatically. kingshard - kingshard is a high performance proxy for MySQL powered by Golang. myreplication - MySql binary log replication listener. Supports statement and row based replication. octillery - Go package for sharding databases ( Supports every ORM or raw SQL ). orchestrator - MySQL replication topology manager & visualizer. pg_timetable - Advanced scheduling for PostgreSQL. pgweb - Web-based PostgreSQL database browser. prep - Use prepared SQL statements without changing your code. pREST - Simplify and accelerate development, instant, realtime, high-performance on any Postgres application, existing or new. rwdb - rwdb provides read replica capability for multiple database servers setup. vitess - vitess provides servers and tools which facilitate scaling of MySQL databases for large scale web services. SQL query builder, libraries for building and using SQL. buildsqlx - Go database query builder library for PostgreSQL. dbq - Zero boilerplate database operations for Go. Dotsql - Go library that helps you keep sql files in one place and use them with ease. gendry - Non-invasive SQL builder and powerful data binder. godbal - Database Abstraction Layer (dbal) for go. Support SQL builder and get result easily. goqu - Idiomatic SQL builder and query library. gosql - SQL Query builder with better null values support. hasql - Library for accessing multi-host SQL database installations. igor - Abstraction layer for PostgreSQL that supports advanced functionality and uses gorm-like syntax. jet - Framework for writing type-safe SQL queries in Go, with ability to easily convert database query result into desired arbitrary object structure. mpath - MPTT (Modified Preorder Tree Traversal) package for SQL records - materialized path realisation. ormlite - Lightweight package containing some ORM-like features and helpers for sqlite databases. ozzo-dbx - Powerful data retrieval methods as well as DB-agnostic query building capabilities. qry - Tool that generates constants from files with raw SQL queries. sq - Type-safe SQL builder and struct mapper for Go. sqlf - Fast SQL query builder. sqlingo - A lightweight DSL to build SQL in Go. sqrl - SQL query builder, fork of Squirrel with improved performance. Squalus - Thin layer over the Go SQL package that makes it easier to perform queries. Squirrel - Go library that helps you build SQL queries. xo - Generate idiomatic Go code for databases based on existing schema definitions or custom queries supporting PostgreSQL, MySQL, SQLite, Oracle, and Microsoft SQL Server. Database Drivers Libraries for connecting and operating databases. Relational Databases avatica - Apache Avatica/Phoenix SQL driver for database/sql. bgc - Datastore Connectivity for BigQuery for go. firebirdsql - Firebird RDBMS SQL driver for Go. go-adodb - Microsoft ActiveX Object DataBase driver for go that uses database/sql. go-mssqldb - Microsoft MSSQL driver for Go. go-oci8 - Oracle driver for go that uses database/sql. go-sql-driver/mysql - MySQL driver for Go. go-sqlite3 - SQLite3 driver for go that uses database/sql. godror - Oracle driver for Go, using the ODPI-C driver. gofreetds - Microsoft MSSQL driver. Go wrapper over FreeTDS. pgx - PostgreSQL driver supporting features beyond those exposed by database/sql. pig - Simple pgx wrapper to execute and scan query results easily. pq - Pure Go Postgres driver for database/sql. Sqinn-Go - SQLite with pure Go. NoSQL Databases aerospike-client-go - Aerospike client in Go language. arangolite - Lightweight golang driver for ArangoDB. asc - Datastore Connectivity for Aerospike for go. forestdb - Go bindings for ForestDB. go-couchbase - Couchbase client in Go. go-pilosa - Go client library for Pilosa. go-rejson - Golang client for redislabs' ReJSON module using Redigo golang client. Store and manipulate structs as JSON objects in redis with ease. gocb - Official Couchbase Go SDK. gocosmos - REST client and standard database/sql driver for Azure Cosmos DB. gocql - Go language driver for Apache Cassandra. godis - redis client implement by golang, inspired by jedis. godscache - A wrapper for the Google Cloud Platform Go Datastore package that adds caching using memcached. gomemcache - memcache client library for the Go programming language. gorethink - Go language driver for RethinkDB. goriak - Go language driver for Riak KV. mgm - MongoDB model-based ODM for Go (based on official MongoDB driver). mgo - (unmaintained) MongoDB driver for the Go language that implements a rich and well tested selection of features under a very simple API following standard Go idioms. mongo-go-driver - Official MongoDB driver for the Go language. neo4j - Neo4j Rest API Bindings for Golang. Neo4j-GO - Neo4j REST Client in golang. neoism - Neo4j client for Golang. qmgo - The MongoDB driver for Go. Its based on official MongoDB driver but easier to use like Mgo. redeo - Redis-protocol compatible TCP servers/services. redigo - Redigo is a Go client for the Redis database. redis - Redis client for Golang. xredis - Typesafe, customizable, clean & easy to use Redis client. Search and Analytic Databases. bleve - Modern text indexing library for go. elastic - Elasticsearch client for Go. elasticsql - Convert sql to elasticsearch dsl in Go. elastigo - Elasticsearch client library. go-elasticsearch - Official Elasticsearch client for Go. goes - Library to interact with Elasticsearch. riot - Go Open Source, Distributed, Simple and efficient Search Engine. skizze - probabilistic data-structures service and storage. Multiple Backends. cachego - Golang Cache component for multiple drivers. cayley - Graph database with support for multiple backends. dsc - Datastore connectivity for SQL, NoSQL, structured files. gokv - Simple key-value store abstraction and implementations for Go (Redis, Consul, etcd, bbolt, BadgerDB, LevelDB, Memcached, DynamoDB, S3, PostgreSQL, MongoDB, CockroachDB and many more). Date and Time Libraries for working with dates and times. carbon - Simple Time extension with a lot of util methods, ported from PHP Carbon library. cronrange - Parses Cron-style time range expressions, checks if the given time is within any ranges. date - Augments Time for working with dates, date ranges, time spans, periods, and time-of-day. dateparse - Parse date's without knowing format in advance. durafmt - Time duration formatting library for Go. feiertage - Set of functions to calculate public holidays in Germany, incl. specialization on the states of Germany (Bundeslnder). Things like Easter, Pentecost, Thanksgiving... go-persian-calendar - The implementation of the Persian (Solar Hijri) Calendar in Go (golang). go-str2duration - Convert string to duration. Support time.Duration returned string and more. go-sunrise - Calculate the sunrise and sunset times for a given location. go-week - An efficient package to work with ISO8601 week dates. gostradamus - A Go package for working with dates. iso8601 - Efficiently parse ISO8601 date-times without regex. kair - Date and Time - Golang Formatting Library. now - Now is a time toolkit for golang. NullTime - Nullable time.Time. strftime - C99-compatible strftime formatter. timespan - For interacting with intervals of time, defined as a start time and a duration. timeutil - Useful extensions (Timedelta, Strftime, ...) to the golang's time package. tuesday - Ruby-compatible Strftime function. Distributed Systems Packages that help with building Distributed Systems. arpc - More effective network communication, support two-way-calling, notify, broadcast. celeriac - Library for adding support for interacting and monitoring Celery workers, tasks and events in Go. consistent - Consistent hashing with bounded loads. consistenthash - Consistent hashing with configurable replicas. dht - BitTorrent Kademlia DHT implementation. digota - grpc ecommerce microservice. dot - distributed sync using operational transformation/OT. doublejump - A revamped Google's jump consistent hash. dragonboat - A feature complete and high performance multi-group Raft library in Go. drmaa - Job submission library for cluster schedulers based on the DRMAA standard. dynamolock - DynamoDB-backed distributed locking implementation. dynatomic - A library for using DynamoDB as an atomic counter. emitter-io - High performance, distributed, secure and low latency publish-subscribe platform built with MQTT, Websockets and love. flowgraph - flow-based programming package. gleam - Fast and scalable distributed map/reduce system written in pure Go and Luajit, combining Go's high concurrency with Luajit's high performance, runs standalone or distributed. glow - Easy-to-Use scalable distributed big data processing, Map-Reduce, DAG execution, all in pure Go. gmsec - A Go distributed systems development framework. go-health - Library for enabling asynchronous dependency health checks in your service. go-jump - Port of Google's "Jump" Consistent Hash function. go-kit - Microservice toolkit with support for service discovery, load balancing, pluggable transports, request tracking, etc. go-micro - A distributed systems development framework. go-mysql-lock - MySQL based distributed lock. go-pdu - A decentralized identity-based social network. go-sundheit - A library built to provide support for defining async service health checks for golang services. go-zero - A web and rpc framework. It's born to ensure the stability of the busy sites with resilient design. Builtin goctl greatly improves the development productivity. gorpc - Simple, fast and scalable RPC library for high load. grpc-go - The Go language implementation of gRPC. HTTP/2 based RPC. hprose - Very newbility RPC Library, support 25+ languages now. jsonrpc - The jsonrpc package helps implement of JSON-RPC 2.0. jsonrpc - JSON-RPC 2.0 HTTP client implementation. KrakenD - Ultra performant API Gateway framework with middlewares. liftbridge - Lightweight, fault-tolerant message streams for NATS. micro - A distributed systems runtime for the cloud and beyond. NATS - Lightweight, high performance messaging system for microservices, IoT, and cloud native systems. outboxer - Outboxer is a go library that implements the outbox pattern. pglock - PostgreSQL-backed distributed locking implementation. pjrpc - Golang JSON-RPC Server-Client with Protobuf spec. raft - Golang implementation of the Raft consensus protocol, by HashiCorp. raft - Go implementation of the Raft consensus protocol, by CoreOS. rain - BitTorrent client and library. redis-lock - Simplified distributed locking implementation using Redis. resgate - Realtime API Gateway for building REST, real time, and RPC APIs, where all clients are synchronized seamlessly. ringpop-go - Scalable, fault-tolerant application-layer sharding for Go applications. rpcx - Distributed pluggable RPC service framework like alibaba Dubbo. Semaphore - A straightforward (micro) service orchestrator. sleuth - Library for master-less p2p auto-discovery and RPC between HTTP services (using ZeroMQ). tendermint - High-performance middleware for transforming a state machine written in any programming language into a Byzantine Fault Tolerant replicated state machine using the Tendermint consensus and blockchain protocols. torrent - BitTorrent client package. Dynamic DNS Tools for updating dynamic DNS records. DDNS - Personal DDNS client with Digital Ocean Networking DNS as backend. dyndns - Background Go process to regularly and automatically check your IP Address and make updates to (one or many) Dynamic DNS records for Google domains whenever your address changes. GoDNS - A dynamic DNS client tool, supports DNSPod & HE.net, written in Go. Email Libraries and tools that implement email creation and sending. chasquid - SMTP server written in Go. douceur - CSS inliner for your HTML emails. email - A robust and flexible email library for Go. email-verifier - A Go library for email verification without sending any emails. go-dkim - DKIM library, to sign & verify email. go-email-validator - Modular email validator for syntax, disposable, smtp, etc... checking. go-imap - IMAP library for clients and servers. go-message - Streaming library for the Internet Message Format and mail messages. go-premailer - Inline styling for HTML mail in Go. go-simple-mail - Very simple package to send emails with SMTP Keep Alive and two timeouts: Connect and Send. Hectane - Lightweight SMTP client providing an HTTP API. hermes - Golang package that generates clean, responsive HTML e-mails. mailchain - Send encrypted emails to blockchain addresses written in Go. mailgun-go - Go library for sending mail with the Mailgun API. MailHog - Email and SMTP testing with web and API interface. SendGrid - SendGrid's Go library for sending email. smtp - SMTP server protocol state machine. Embeddable Scripting Languages Embedding other languages inside your go code. anko - Scriptable interpreter written in Go. binder - Go to Lua binding library, based on gopher-lua. cel-go - Fast, portable, non-Turing complete expression evaluation with gradual typing. ecal - A simple embeddable scripting language which supports concurrent event processing. expr - Expression evaluation engine for Go: fast, non-Turing complete, dynamic typing, static typing. gentee - Embeddable scripting programming language. gisp - Simple LISP in Go. go-duktape - Duktape JavaScript engine bindings for Go. go-lua - Port of the Lua 5.2 VM to pure Go. go-php - PHP bindings for Go. go-python - naive go bindings to the CPython C-API. goja - ECMAScript 5.1(+) implementation in Go. golua - Go bindings for Lua C API. gopher-lua - Lua 5.1 VM and compiler written in Go. gval - A highly customizable expression language written in Go. ngaro - Embeddable Ngaro VM implementation enabling scripting in Retro. purl - Perl 5.18.2 embedded in Go. tengo - Bytecode compiled script language for Go. Error Handling Libraries for handling errors. emperror - Error handling tools and best practices for Go libraries and applications. eris - A better way to handle, trace, and log errors in Go. Compatible with the standard error library and github.com/pkg/errors. errlog - Hackable package that determines responsible source code for an error (and some other fast-debugging features). Pluggable to any logger in-place. errors - Drop-in replacement for the standard library errors package and github.com/pkg/errors. Provides various error handling primitives. errors - Package that provides simple error handling primitives. errors - Simple golang error handling with classification primitives. errors - The most simple error wrapper with awesome performance and minimal memory overhead. errors - Drop-in replacement for builting Go errors. This is a minimal error handling package with custom error types, user friendly messages, Unwrap & Is. With very easy to use and straightforward helper functions. errorx - A feature rich error package with stack traces, composition of errors and more. Falcon - A Simple Yet Highly Powerful Package For Error Handling. go-multierror - Go (golang) package for representing a list of errors as a single error. tracerr - Golang errors with stack trace and source fragments. File Handling Libraries for handling files and file systems. afero - FileSystem Abstraction System for Go. afs - Abstract File Storage (mem, scp, zip, tar, cloud: s3, gs) for Go. baraka - A library to process http file uploads easily. bigfile - A file transfer system, support to manage files with http api, rpc call and ftp client. checksum - Compute message digest, like MD5 and SHA256, for large files. copy - Copy directory recursively. flop - File operations library which aims to mirror feature parity with GNU cp. go-csv-tag - Load csv file using tag. go-decent-copy - Copy files for humans. go-exiftool - Go bindings for ExifTool, the well-known library used to extract as much metadata as possible (EXIF, IPTC, ...) from files (pictures, PDF, office, ...). go-gtfs - Load gtfs files in go. gut/yos - Simple and reliable package for file operations like copy/move/diff/list on files, directories and symbolic links. higgs - A tiny cross-platform Go library to hide/unhide files and directories. notify - File system event notification library with simple API, similar to os/signal. opc - Load Open Packaging Conventions (OPC) files for Go. parquet - Read and write parquet files. pdfcpu - PDF processor. skywalker - Package to allow one to concurrently go through a filesystem with ease. stl - Modules to read and write STL (stereolithography) files. Concurrent algorithm for reading. tarfs - Implementation of the FileSystem interface for tar files. todotxt - Go library for Gina Trapani's todo.txt files, supports parsing and manipulating of task lists in the todo.txt format. vfs - A pluggable, extensible, and opinionated set of filesystem functionality for Go across a number of filesystem types such as os, S3, and GCS. Financial Packages for accounting and finance. accounting - money and currency formatting for golang. currency - Handles currency amounts, provides currency information and formatting. currency - High performant & accurate currency computation package. decimal - Arbitrary-precision fixed-point decimal numbers. fastme - Fast extensible matching engine Go implementation. go-finance - Comprehensive financial markets data in Go. go-finance - Library of financial functions for time value of money (annuities), cash flow, interest rate conversions, bonds and depreciation calculations. go-finance - Module to fetch exchange rates, check VAT numbers via VIES and check IBAN bank account numbers. go-finnhub - Client for stock market, forex and crypto data from finnhub.io. Access real-time financial market data from 60+ stock exchanges, 10 forex brokers, and 15+ crypto exchanges. go-money - Implementation of Fowler's Money pattern. ofxgo - Query OFX servers and/or parse the responses (with example command-line client). orderbook - Matching Engine for Limit Order Book in Golang. sleet - One unified interface for multiple Payment Service Providers (PsP) to process online payment. techan - Technical analysis library with advanced market analysis and trading strategies. transaction - Embedded transactional database of accounts, running in multithreaded mode. vat - VAT number validation & EU VAT rates. Forms Libraries for working with forms. bind - Bind form data to any Go values. binding - Binds form and JSON data from net/http Request to struct. conform - Keeps user input in check. Trims, sanitizes & scrubs data based on struct tags. form - Decodes url.Values into Go value(s) and Encodes Go value(s) into url.Values. Dual Array and Full map support. formam - decode form's values into a struct. forms - Framework-agnostic library for parsing and validating form/JSON data which supports multipart forms and files. gorilla/csrf - CSRF protection for Go web applications & services. nosurf - CSRF protection middleware for Go. qs - Go module for encoding structs into URL query parameters. queryparam - Decode url.Values into usable struct values of standard or custom types. Functional Packages to support functional programming in Go. fpGo - Monad, Functional Programming features for Golang. fuego - Functional Experiment in Go. go-underscore - Useful collection of helpfully functional Go collection utilities. gofp - A lodash like powerful utility library for Golang. Game Development Awesome game development libraries. Azul3D - 3D game engine written in Go. Ebiten - dead simple 2D game library in Go. engo - Engo is an open-source 2D game engine written in Go. It follows the Entity-Component-System paradigm. g3n - Go 3D Game Engine. go-astar - Go implementation of the A* path finding algorithm. go-sdl2 - Go bindings for the Simple DirectMedia Layer. go3d - Performance oriented 2D/3D math package for Go. gonet - Game server skeleton implemented with golang. goworld - Scalable game server engine, featuring space-entity framework and hot-swapping. Leaf - Lightweight game server framework. nano - Lightweight, facility, high performance golang based game server framework. Oak - Pure Go game engine. Pitaya - Scalable game server framework with clustering support and client libraries for iOS, Android, Unity and others through the C SDK. Pixel - Hand-crafted 2D game library in Go. prototype - Cross-platform (Windows/Linux/Mac) library for creating desktop games using a minimal API. raylib-go - Go bindings for raylib, a simple and easy-to-use library to learn videogames programming. termloop - Terminal-based game engine for Go, built on top of Termbox. tile - Data-oriented and cache-friendly 2D Grid library (TileMap), includes pathfinding, observers and import/export. Generation and Generics Tools to enhance the language with features like generics via code generation. efaceconv - Code generation tool for high performance conversion from interface{} to immutable type without allocations. gen - Code generation tool for generics-like functionality. generis - Code generation tool providing generics, free-form macros, conditional compilation and HTML templating. go-enum - Code generation for enums from code comments. go-linq - .NET LINQ-like query methods for Go. go-xray - Helpers for making the use of reflection easier. goderive - Derives functions from input types. gotype - Golang source code parsing, usage like reflect package. GoWrap - Generate decorators for Go interfaces using simple templates. interfaces - Command line tool for generating interface definitions. jennifer - Generate arbitrary Go code without templates. pkgreflect - Go preprocessor for package scoped reflection. typeregistry - A library to create type dynamically. Geographic Geographic tools and servers geoserver - geoserver Is a Go Package For Manipulating a GeoServer Instance via the GeoServer REST API. gismanager - Publish Your GIS Data(Vector Data) to PostGIS and Geoserver. mbtileserver - A simple Go-based server for map tiles stored in mbtiles format. osm - Library for reading, writing and working with OpenStreetMap data and APIs. pbf - OpenStreetMap PBF golang encoder/decoder. S2 geojson - Convert geojson to s2 cells & demonstrating some S2 geometry features on map. S2 geometry - S2 geometry library in Go. Tile38 - Geolocation DB with spatial index and realtime geofencing. WGS84 - Library for Coordinate Conversion and Transformation (ETRS89, OSGB36, NAD83, RGF93, Web Mercator, UTM). Go Compilers Tools for compiling Go to other languages. c4go - Transpile C code to Go code. f4go - Transpile FORTRAN 77 code to Go code. gopherjs - Compiler from Go to JavaScript. tardisgo - Golang to Haxe to CPP/CSharp/Java/JavaScript transpiler. Goroutines Tools for managing and working with Goroutines. ants - A high-performance and low-cost goroutine pool in Go. artifex - Simple in-memory job queue for Golang using worker-based dispatching. async - An alternative sync library for Go (Future, Promise, Locks). async - A safe way to execute functions asynchronously, recovering them in case of panic. breaker - Flexible mechanism to make execution flow interruptible. channelify - Transform your function to return channels for easy and powerful parallel processing. concurrency-limiter - Concurrency limiter with support for timeouts , dynamic priority and context cancellation of goroutines. conexec - A concurrent toolkit to help execute funcs concurrently in an efficient and safe way. It supports specifying the overall timeout to avoid blocking and uses goroutine pool to improve efficiency. cyclicbarrier - CyclicBarrier for golang. go-floc - Orchestrate goroutines with ease. go-flow - Control goroutines execution order. go-tools/multithreading - Manage a pool of goroutines using this lightweight library with a simple API. go-trylock - TryLock support on read-write lock for Golang. go-waitgroup - Like sync.WaitGroup with error handling and concurrency control. go-workers - Easily and safely run workers for large data processing pipelines. goccm - Go Concurrency Manager package limits the number of goroutines that allowed to run concurrently. gohive - A highly performant and easy to use Goroutine pool for Go. gollback - asynchronous simple function utilities, for managing execution of closures and callbacks. gowl - Gowl is a process management and process monitoring tool at once. An infinite worker pool gives you the ability to control the pool and processes and monitor their status. goworker - goworker is a Go-based background worker. gowp - gowp is concurrency limiting goroutine pool. gpool - manages a resizeable pool of context-aware goroutines to bound concurrency. grpool - Lightweight Goroutine pool. hands - A process controller used to control the execution and return strategies of multiple goroutines. Hunch - Hunch provides functions like: All, First, Retry, Waterfall etc., that makes asynchronous flow control more intuitive. kyoo - Provides an unlimited job queue and concurrent worker pools. neilotoole/errgroup - Drop-in alternative to sync/errgroup, limited to a pool of N worker goroutines. nursery - Structured concurrency in Go. oversight - Oversight is a complete implementation of the Erlang supervision trees. parallel-fn - Run functions in parallel. pond - Minimalistic and High-performance goroutine worker pool written in Go. pool - Limited consumer goroutine or unlimited goroutine pool for easier goroutine handling and cancellation. queue - Gives you a sync.WaitGroup like queue group accessibility. Helps you to throttle and limit goroutines, wait for the end of the all goroutines and much more. routine - go routine control with context, support: Main, Go, Pool and some useful Executors. semaphore - Semaphore pattern implementation with timeout of lock/unlock operations based on channel and context. semaphore - Fast resizable semaphore implementation based on CAS (faster than channel-based semaphore implementations). stl - Software transactional locks based on Software Transactional Memory (STM) concurrency control mechanism. threadpool - Golang threadpool implementation. tunny - Goroutine pool for golang. worker-pool - goworker is a Go simple async worker pool. workerpool - Goroutine pool that limits the concurrency of task execution, not the number of tasks queued. GUI Libraries for building GUI Applications. Toolkits app - Package to create apps with GO, HTML and CSS. Supports: MacOS, Windows in progress. fyne - Cross platform native GUIs designed for Go based on Material Design. Supports: Linux, macOS, Windows, BSD, iOS and Android. go-astilectron - Build cross platform GUI apps with GO and HTML/JS/CSS (powered by Electron). go-gtk - Go bindings for GTK. go-sciter - Go bindings for Sciter: the Embeddable HTML/CSS/script engine for modern desktop UI development. Cross platform. gotk3 - Go bindings for GTK3. gowd - Rapid and simple desktop UI development with GO, HTML, CSS and NW.js. Cross platform. qt - Qt binding for Go (support for Windows / macOS / Linux / Android / iOS / Sailfish OS / Raspberry Pi). ui - Platform-native GUI library for Go. Cross platform. Wails - Mac, Windows, Linux desktop apps with HTML UI using built-in OS HTML renderer. walk - Windows application library kit for Go. webview - Cross-platform webview window with simple two-way JavaScript bindings (Windows / macOS / Linux). Interaction go-appindicator - Go bindings for libappindicator3 C library. gosx-notifier - OSX Desktop Notifications library for Go. mac-activity-tracker - OSX library to notify about any (pluggable) activity on your machine. mac-sleep-notifier - OSX Sleep/Wake notifications in golang. robotgo - Go Native cross-platform GUI system automation. Control the mouse, keyboard and other. systray - Cross platform Go library to place an icon and menu in the notification area. trayhost - Cross-platform Go library to place an icon in the host operating system's taskbar. Hardware Libraries, tools, and tutorials for interacting with hardware. See go-hardware for a comprehensive list. Images Libraries for manipulating images. bild - Collection of image processing algorithms in pure Go. bimg - Small package for fast and efficient image processing using libvips. cameron - An avatar generator for Go. canvas - Vector graphics to PDF, SVG or rasterized image. darkroom - An image proxy with changeable storage backends and image processing engines with focus on speed and resiliency. draft - Generate High Level Microservice Architecture diagrams for GraphViz using simple YAML syntax. geopattern - Create beautiful generative image patterns from a string. gg - 2D rendering in pure Go. gift - Package of image processing filters. gltf - Efficient and robust glTF 2.0 reader, writer and validator. go-cairo - Go binding for the cairo graphics library. go-gd - Go binding for GD library. go-nude - Nudity detection with Go. go-opencv - Go bindings for OpenCV. go-webcolors - Port of webcolors library from Python to Go. gocv - Go package for computer vision using OpenCV 3.3+. goimagehash - Go Perceptual image hashing package. goimghdr - The imghdr module determines the type of image contained in a file for Go. govatar - Library and CMD tool for generating funny avatars. govips - A lightning fast image processing and resizing library for Go. gridder - A Grid based 2D Graphics library. image2ascii - Convert image to ASCII. imagick - Go binding to ImageMagick's MagickWand C API. imaginary - Fast and simple HTTP microservice for image resizing. imaging - Simple Go image processing package. img - Selection of image manipulation tools. ln - 3D line art rendering in Go. mergi - Tool & Go library for image manipulation (Merge, Crop, Resize, Watermark, Animate). mort - Storage and image processing server written in Go. mpo - Decoder and conversion tool for MPO 3D Photos. picfit - An image resizing server written in Go. pt - Path tracing engine written in Go. resize - Image resizing for Go with common interpolation methods. rez - Image resizing in pure Go and SIMD. smartcrop - Finds good crops for arbitrary images and crop sizes. steganography - Pure Go Library for LSB steganography. stegify - Go tool for LSB steganography, capable of hiding any file within an image. svgo - Go Language Library for SVG generation. tga - Package tga is a TARGA image format decoder/encoder. webp-server - Simple and minimal image server capable of storing, resizing, converting and caching images. IoT (Internet of Things) Libraries for programming devices of the IoT. connectordb - Open-Source Platform for Quantified Self & IoT. devices - Suite of libraries for IoT devices, experimental for x/exp/io. eywa - Project Eywa is essentially a connection manager that keeps track of connected devices. flogo - Project Flogo is an Open Source Framework for IoT Edge Apps & Integration. gatt - Gatt is a Go package for building Bluetooth Low Energy peripherals. gobot - Gobot is a framework for robotics, physical computing, and the Internet of Things. huego - An extensive Philips Hue client library for Go. iot - IoT is a simple framework for implementing a Google IoT Core device. mainflux - Industrial IoT Messaging and Device Management Server. periph - Peripherals I/O to interface with low-level board facilities. sensorbee - Lightweight stream processing engine for IoT. Job Scheduler Libraries for scheduling jobs. clockwerk - Go package to schedule periodic jobs using a simple, fluent syntax. clockwork - Simple and intuitive job scheduling library in Go. cronticker - A ticker implementation to support cron schedules. go-cron - Simple Cron library for go that can execute closures or functions at varying intervals, from once a second to once a year on a specific date and time. Primarily for web applications and long running daemons. go-quartz - Simple, zero-dependency scheduling library for Go. gocron - Easy and fluent Go job scheduling. This is an actively maintained fork of jasonlvhit/gocron. gron - Define time-based tasks using a simple Go API and Grons scheduler will run them accordingly. JobRunner - Smart and featureful cron job scheduler with job queuing and live monitoring built in. jobs - Persistent and flexible background jobs library. leprechaun - Job scheduler that supports webhooks, crons and classic scheduling. scheduler - Cronjobs scheduling made easy. tasks - An easy to use in-process scheduler for recurring tasks in Go. JSON Libraries for working with JSON. ajson - Abstract JSON for golang with JSONPath support. ask - Easy access to nested values in maps and slices. Works in combination with encoding/json and other packages that "Unmarshal" arbitrary data into Go data-types. dynjson - Client-customizable JSON formats for dynamic APIs. ej - Write and read JSON from different sources succinctly. epoch - Contains primitives for marshaling/unmarshaling Unix timestamp/epoch to/from build-in time.Time type in JSON. fastjson - Fast JSON parser and validator for Go. No custom structs, no code generation, no reflection. gjo - Small utility to create JSON objects. GJSON - Get a JSON value with one line of code. go-jsonerror - Go-JsonError is ment to allow us to easily create json response errors that follow the JsonApi spec. go-respond - Go package for handling common HTTP JSON responses. gojq - JSON query in Golang. gojson - Automatically generate Go (golang) struct definitions from example JSON. JayDiff - JSON diff utility written in Go. jettison - Fast and flexible JSON encoder for Go. JSON-to-Go - Convert JSON to Go struct. JSON-to-Proto - Convert JSON to Protobuf online. json2go - Advanced JSON to Go struct conversion. Provides package that can parse multiple JSON documents and create struct to fit them all. jsonapi-errors - Go bindings based on the JSON API errors reference. jsondiff - JSON diff library for Go based on RFC6902 (JSON Patch). jsonf - Console tool for highlighted formatting and struct query fetching JSON. jsongo - Fluent API to make it easier to create Json objects. jsonhal - Simple Go package to make custom structs marshal into HAL compatible JSON responses. jsonic - Utilities to handle and query JSON without defining structs in a type safe manner. jzon - JSON library with standard compatible API/behavior. kazaam - API for arbitrary transformation of JSON documents. mapslice-json - Go MapSlice for ordered marshal/ unmarshal of maps in JSON. mp - Simple cli email parser. It currently takes stdin and outputs JSON. Logging Libraries for generating and working with log files. distillog - distilled levelled logging (think of it as stdlib + log levels). glg - glg is simple and fast leveled logging library for Go. glo - PHP Monolog inspired logging facility with identical severity levels. glog - Leveled execution logs for Go. go-cronowriter - Simple writer that rotate log files automatically based on current date and time, like cronolog. go-log - A logging library with strack traces, object dumping and optional timestamps. go-log - Simple and configurable Logging in Go, with level, formatters and writers. go-log - Log lib supports level and multi handlers. go-log - Log4j implementation in Go. go-logger - Simple logger of Go Programs, with level handlers. gologger - Simple easy to use log lib for go, logs in Colored Console, Simple Console, File or Elasticsearch. gomol - Multiple-output, structured logging for Go with extensible logging outputs. gone/log - Fast, extendable, full-featured, std-lib source compatible log library. httpretty - Pretty-prints your regular HTTP requests on your terminal for debugging (similar to http.DumpRequest). journald - Go implementation of systemd Journal's native API for logging. kemba - A tiny debug logging tool inspired by debug, great for CLI tools and applications. log - An O(1) logging system that allows you to connect one log to multiple writers (e.g. stdout, a file and a TCP connection). log - Structured logging package for Go. log - Simple, configurable and scalable Structured Logging for Go. log - Structured log interface for Go cleanly separates logging facade from its implementation. log-voyage - Full-featured logging saas written in golang. log15 - Simple, powerful logging for Go. logdump - Package for multi-level logging. logex - Golang log lib, supports tracking and level, wrap by standard log lib. logger - Minimalistic logging library for Go. logmatic - Colorized logger for Golang with dynamic log level configuration. logo - Golang logger to different configurable writers. logrus - Structured logger for Go. logrusiowriter - io.Writer implementation using logrus logger. logrusly - logrus plug-in to send errors to a Loggly. logur - An opinionated logger interface and collection of logging best practices with adapters and integrations for well-known libraries (logrus, go-kit log, zap, zerolog, etc). logutils - Utilities for slightly better logging in Go (Golang) extending the standard logger. logxi - 12-factor app logger that is fast and makes you happy. lumberjack - Simple rolling logger, implements io.WriteCloser. mlog - Simple logging module for go, with 5 levels, an optional rotating logfile feature and stdout/stderr output. onelog - Onelog is a dead simple but very efficient JSON logger. It is the fastest JSON logger out there in all scenarios. Also, it is one of the logger with the lowest allocation. ozzo-log - High performance logging supporting log severity, categorization, and filtering. Can send filtered log messages to various targets (e.g. console, network, mail). phuslu/log - Structured Logging Made Easy. rollingwriter - RollingWriter is an auto-rotate io.Writer implementation with multi policies to provide log file rotation. seelog - Logging functionality with flexible dispatching, filtering, and formatting. spew - Implements a deep pretty printer for Go data structures to aid in debugging. sqldb-logger - A logger for Go SQL database driver without modify existing *sql.DB stdlib usage. stdlog - Stdlog is an object-oriented library providing leveled logging. It is very useful for cron jobs. tail - Go package striving to emulate the features of the BSD tail program. xlog - Plugin architecture and flexible log system for Go, with level ctrl, multiple log target and custom log format. xlog - Structured logger for net/context aware HTTP handlers with flexible dispatching. yell - Yet another minimalistic logging library. zap - Fast, structured, leveled logging in Go. zerolog - Zero-allocation JSON logger. zkits-logger - A powerful zero-dependency JSON logger. Machine Learning Libraries for Machine Learning. bayesian - Naive Bayesian Classification for Golang. CloudForest - Fast, flexible, multi-threaded ensembles of decision trees for machine learning in pure Go. ddt - Dynamic decision tree, create trees defining customizable rules. eaopt - An evolutionary optimization library. evoli - Genetic Algorithm and Particle Swarm Optimization library. fonet - A Deep Neural Network library written in Go. go-cluster - Go implementation of the k-modes and k-prototypes clustering algorithms. go-deep - A feature-rich neural network library in Go. go-fann - Go bindings for Fast Artificial Neural Networks(FANN) library. go-featureprocessing - Fast and convenient feature processing for low latency machine leraning in Go. go-galib - Genetic Algorithms library written in Go / golang. go-pr - Pattern recognition package in Go lang. gobrain - Neural Networks written in go. godist - Various probability distributions, and associated methods. goga - Genetic algorithm library for Go. GoLearn - General Machine Learning library for Go. golinear - liblinear bindings for Go. GoMind - A simplistic Neural Network Library in Go. goml - On-line Machine Learning in Go. gonet - Neural Network for Go. Goptuna - Bayesian optimization framework for black-box functions written in Go. Everything will be optimized. goRecommend - Recommendation Algorithms library written in Go. gorgonia - graph-based computational library like Theano for Go that provides primitives for building various machine learning and neural network algorithms. gorse - An offline recommender system backend based on collaborative filtering written in Go. goscore - Go Scoring API for PMML. gosseract - Go package for OCR (Optical Character Recognition), by using Tesseract C++ library. libsvm - libsvm golang version derived work based on LIBSVM 3.14. neat - Plug-and-play, parallel Go framework for NeuroEvolution of Augmenting Topologies (NEAT). neural-go - Multilayer perceptron network implemented in Go, with training via backpropagation. ocrserver - A simple OCR API server, seriously easy to be deployed by Docker and Heroku. onnx-go - Go Interface to Open Neural Network Exchange (ONNX). probab - Probability distribution functions. Bayesian inference. Written in pure Go. randomforest - Easy to use Random Forest library for Go. regommend - Recommendation & collaborative filtering engine. shield - Bayesian text classifier with flexible tokenizers and storage backends for Go. tfgo - Easy to use Tensorflow bindings: simplifies the usage of the official Tensorflow Go bindings. Define computational graphs in Go, load and execute models trained in Python. Varis - Golang Neural Network. Messaging Libraries that implement messaging systems. ami - Go client to reliable queues based on Redis Cluster Streams. APNs2 - HTTP/2 Apple Push Notification provider for Go Send push notifications to iOS, tvOS, Safari and OSX apps. Asynq - A simple, reliable, and efficient distributed task queue for Go built on top of Redis. Beaver - A real time messaging server to build a scalable in-app notifications, multiplayer games, chat apps in web and mobile apps. Benthos - A message streaming bridge between a range of protocols. Bus - Minimalist message bus implementation for internal communication. Centrifugo - Real-time messaging (Websockets or SockJS) server in Go. Commander - A high-level event driven consumer/producer supporting various "dialects" such as Apache Kafka. Confluent Kafka Golang Client - confluent-kafka-go is Confluent's Golang client for Apache Kafka and the Confluent Platform. dbus - Native Go bindings for D-Bus. drone-line - Sending Line notifications using a binary, docker or Drone CI. emitter - Emits events using Go way, with wildcard, predicates, cancellation possibilities and many other good wins. event - Implementation of the pattern observer. EventBus - The lightweight event bus with async compatibility. gaurun-client - Gaurun Client written in Go. Glue - Robust Go and Javascript Socket Library (Alternative to Socket.io). go-mq - RabbitMQ client with declarative configuration. go-notify - Native implementation of the freedesktop notification spec. go-nsq - the official Go package for NSQ. go-res - Package for building REST/real-time services where clients are synchronized seamlessly, using NATS and Resgate. go-socket.io - socket.io library for golang, a realtime application framework. go-vitotrol - Client library to Viessmann Vitotrol web service. Gollum - A n:m multiplexer that gathers messages from different sources and broadcasts them to a set of destinations. golongpoll - HTTP longpoll server library that makes web pub-sub simple. gopush-cluster - gopush-cluster is a go push server cluster. gorush - Push notification server using APNs2 and google GCM. gosd - A library for scheduling when to dispatch a message to a channel. guble - Messaging server using push notifications (Google Firebase Cloud Messaging, Apple Push Notification services, SMS) as well as websockets, a REST API, featuring distributed operation and message-persistence. hare - A user friendly library for sending messages and listening to TCP sockets. hub - A Message/Event Hub for Go applications, using publish/subscribe pattern with support for alias like rabbitMQ exchanges. jazz - A simple RabbitMQ abstraction layer for queue administration and publishing and consuming of messages. machinery - Asynchronous task queue/job queue based on distributed message passing. mangos - Pure go implementation of the Nanomsg ("Scalability Protocols") with transport interoperability. melody - Minimalist framework for dealing with websocket sessions, includes broadcasting and automatic ping/pong handling. Mercure - Server and library to dispatch server-sent updates using the Mercure protocol (built on top of Server-Sent Events). messagebus - messagebus is a Go simple async message bus, perfect for using as event bus when doing event sourcing, CQRS, DDD. NATS Go Client - Lightweight and high performance publish-subscribe and distributed queueing messaging system - this is the Go library. nsq-event-bus - A tiny wrapper around NSQ topic and channel. oplog - Generic oplog/replication system for REST APIs. pubsub - Simple pubsub package for go. rabbus - A tiny wrapper over amqp exchanges and queues. rabtap - RabbitMQ swiss army knife cli app. RapidMQ - RapidMQ is a lightweight and reliable library for managing of the local messages queue. redisqueue - redisqueue provides a producer and consumer of a queue that uses Redis streams. rmqconn - RabbitMQ Reconnection. Wrapper over amqp.Connection and amqp.Dial. Allowing to do a reconnection when the connection is broken before forcing the call to the Close () method to be closed. sarama - Go library for Apache Kafka. Uniqush-Push - Redis backed unified push service for server-side notifications to mobile devices. zmq4 - Go interface to ZeroMQ version 4. Also available for version 3 and version 2. Microsoft Office unioffice - Pure go library for creating and processing Office Word (.docx), Excel (.xlsx) and Powerpoint (.pptx) documents. Microsoft Excel Libraries for working with Microsoft Excel. excelize - Golang library for reading and writing Microsoft Excel (XLSX) files. go-excel - A simple and light reader to read a relate-db-like excel as a table. goxlsxwriter - Golang bindings for libxlsxwriter for writing XLSX (Microsoft Excel) files. xlsx - Library to simplify reading the XML format used by recent version of Microsoft Excel in Go programs. xlsx - Fast and safe way to read/update your existing Microsoft Excel files in Go programs. Miscellaneous Dependency Injection Libraries for working with dependency injection. alice - Additive dependency injection container for Golang. container - A powerful IoC Container with fluent and easy-to-use interface. di - A dependency injection container for go programming language. dig - A reflection based dependency injection toolkit for Go. dingo - A dependency injection toolkit for Go, based on Guice. fx - A dependency injection based application framework for Go (built on top of dig). gocontainer - Simple Dependency Injection Container. goioc/di - Spring-inspired Dependency Injection Container. kinit - Customizable dependency injection container with the global mode, cascade initialization and panic-safe finalization. linker - A reflection based dependency injection and inversion of control library with components lifecycle support. nject/npoint - A type safe, reflective framework based on types for libraries, tests, and endpoints. wire - Strict Runtime Dependency Injection for Golang. Project Layout Unofficial set of patterns for structuring projects. cookiecutter-golang - A Go application boilerplate template for quick starting projects following production best practices. go-sample - A sample layout for Go application projects with the real code. go-todo-backend - Go Todo Backend example using modular project layout for product microservice. gobase - A simple skeleton for golang application with basic setup for real golang application. golang-standards/project-layout - Set of common historical and emerging project layout patterns in the Go ecosystem. golang-templates/seed - Go application GitHub repository template. insidieux/inizio - Golang project layout generator with plugins. modern-go-application - Go application boilerplate and example applying modern practices. scaffold - Scaffold generates a starter Go project layout. Lets you focus on business logic implemented. Strings Libraries for working with strings. go-formatter - Implements replacement fields surrounded by curly braces {} format strings. gobeam/Stringy - String manipulation library to convert string to camel case, snake case, kebab case / slugify etc. strutil - String utilities. xstrings - Collection of useful string functions ported from other languages. Uncategorized These libraries were placed here because none of the other categories seemed to fit. anagent - Minimalistic, pluggable Golang evloop/timer handler with dependency-injection. antch - A fast, powerful and extensible web crawling & scraping framework. archiver - Library and command for making and extracting .zip and .tar.gz archives. autoflags - Go package to automatically define command line flags from struct fields. avgRating - Calculate average score and rating based on Wilson Score Equation. banner - Add beautiful banners into your Go applications. base64Captcha - Base64captch supports digit, number, alphabet, arithmetic, audio and digit-alphabet captcha. battery - Cross-platform, normalized battery information library. bitio - Highly optimized bit-level Reader and Writer for Go. browscap_go - GoLang Library for Browser Capabilities Project. captcha - Package captcha provides an easy to use, unopinionated API for captcha generation. conv - Package conv provides fast and intuitive conversions across Go types. datacounter - Go counters for readers/writer/http.ResponseWriter. faker - Random fake data and struct generator for Go. ffmt - Beautify data display for Humans. gatus - Automated service health dashboard. ghorg - Quickly clone an entire org/users repositories into one directory - Supports GitHub, GitLab, and Bitbucket. go-commons-pool - Generic object pool for Golang. go-openapi - Collection of packages to parse and utilize open-api schemas. go-resiliency - Resiliency patterns for golang. go-unarr - Decompression library for RAR, TAR, ZIP and 7z archives. gofakeit - Random data generator written in go. gommit - Analyze git commit messages to ensure they follow defined patterns. gopsutil - Cross-platform library for retrieving process and system utilization(CPU, Memory, Disks, etc). gosh - Provide Go Statistics Handler, Struct, Measure Method. gosms - Your own local SMS gateway in Go that can be used to send SMS. gotoprom - Type-safe metrics builder wrapper library for the official Prometheus client. gountries - Package that exposes country and subdivision data. health - Easy to use, extensible health check library. healthcheck - An opinionated and concurrent health-check HTTP handler for RESTful services. hostutils - A golang library for packing and unpacking FQDNs list. indigo - Distributed unique ID generator of using Sonyflake and encoded by Base58. lk - A simple licensing library for golang. llvm - Library for interacting with LLVM IR in pure Go. metrics - Library for metrics instrumentation and Prometheus exposition. morse - Library to convert to and from morse code. numa - NUMA is a utility library, which is written in go. It help us to write some NUMA-AWARED code. pdfgen - HTTP service to generate PDF from Json requests. persian - Some utilities for Persian language in go. sandid - Every grain of sand on earth has its own ID. shellwords - A Golang library to manipulate strings according to the word parsing rules of the UNIX Bourne shell. shortid - Distributed generation of super short, unique, non-sequential, URL friendly IDs. shoutrrr - Notification library providing easy access to various messaging services like slack, mattermost, gotify and smtp among others. stateless - A fluent library for creating state machines. stats - Monitors Go MemStats + System stats such as Memory, Swap and CPU and sends via UDP anywhere you want for logging etc... turtle - Emojis for Go. url-shortener - A modern, powerful, and robust URL shortener microservice with mysql support. VarHandler - Generate boilerplate http input and output handling. xdg - FreeDesktop.org (xdg) Specs implemented in Go. xkg - X Keyboard Grabber. Natural Language Processing Libraries for working with human languages. address - Handles address representation, validation and formatting. detectlanguage - Language Detection API Go Client. Supports batch requests, short phrase or single word language detection. getlang - Fast natural language detection package. go-i18n - Package and an accompanying tool to work with localized text. go-localize - Simple and easy to use i18n (Internationalization and localization) engine - used for translating locale strings. go-mystem - CGo bindings to Yandex.Mystem - russian morphology analyzer. go-nlp - Utilities for working with discrete probability distributions and other tools useful for doing NLP work. go-pinyin - CN Hanzi to Hanyu Pinyin converter. go-stem - Implementation of the porter stemming algorithm. go-unidecode - ASCII transliterations of Unicode text. go2vec - Reader and utility functions for word2vec embeddings. gojieba - This is a Go implementation of jieba which a Chinese word splitting algorithm. golibstemmer - Go bindings for the snowball libstemmer library including porter 2. gosentiwordnet - Sentiment analyzer using sentiwordnet lexicon in Go. gotokenizer - A tokenizer based on the dictionary and Bigram language models for Golang. (Now only support chinese segmentation) gounidecode - Unicode transliterator (also known as unidecode) for Go. govader - Go implementation of VADER Sentiment Analysis. gse - Go efficient text segmentation; support english, chinese, japanese and other. icu - Cgo binding for icu4c C library detection and conversion functions. Guaranteed compatibility with version 50.1. iuliia-go - Transliterate Cyrillic Latin in every possible way. kagome - JP morphological analyzer written in pure Go. libtextcat - Cgo binding for libtextcat C library. Guaranteed compatibility with version 2.2. MMSEGO - This is a GO implementation of MMSEG which a Chinese word splitting algorithm. nlp - Extract values from strings and fill your structs with nlp. nlp - Go Natural Language Processing library supporting LSA (Latent Semantic Analysis). paicehusk - Golang implementation of the Paice/Husk Stemming Algorithm. petrovich - Petrovich is the library which inflects Russian names to given grammatical case. porter - This is a fairly straightforward port of Martin Porter's C implementation of the Porter stemming algorithm. porter2 - Really fast Porter 2 stemmer. prose - Library for text processing that supports tokenization, part-of-speech tagging, named-entity extraction, and more. English only. RAKE.go - Go port of the Rapid Automatic Keyword Extraction Algorithm (RAKE). segment - Go library for performing Unicode Text Segmentation as described in Unicode Standard Annex #29 sentences - Sentence tokenizer: converts text into a list of sentences. shamoji - The shamoji is word filtering package written in Go. snowball - Snowball stemmer port (cgo wrapper) for Go. Provides word stem extraction functionality Snowball native. spaGO - Self-contained Machine Learning and Natural Language Processing library in Go. stemmer - Stemmer packages for Go programming language. Includes English and German stemmers. textcat - Go package for n-gram based text categorization, with support for utf-8 and raw text. transliterator - Provides one-way string transliteration with supporting of language-specific transliteration rules. whatlanggo - Natural language detection package for Go. Supports 84 languages and 24 scripts (writing systems e.g. Latin, Cyrillic, etc). when - Natural EN and RU language date/time parser with pluggable rules. Networking Libraries for working with various layers of the network. arp - Package arp implements the ARP protocol, as described in RFC 826. buffstreams - Streaming protocolbuffer data over TCP made easy. canopus - CoAP Client/Server implementation (RFC 7252). cidranger - Fast IP to CIDR lookup for Go. dhcp6 - Package dhcp6 implements a DHCPv6 server, as described in RFC 3315. dns - Go library for working with DNS. ether - Cross-platform Go package for sending and receiving ethernet frames. ethernet - Package ethernet implements marshaling and unmarshaling of IEEE 802.3 Ethernet II frames and IEEE 802.1Q VLAN tags. fasthttp - Package fasthttp is a fast HTTP implementation for Go, up to 10 times faster than net/http. fortio - Load testing library and command line tool, advanced echo server and web UI. Allows to specify a set query-per-second load and record latency histograms and other useful stats and graph them. Tcp, Http, gRPC. ftp - Package ftp implements a FTP client as described in RFC 959. ftpserverlib - Fully featured FTP server library. gaio - High performance async-io networking for Golang in proactor mode. gev - gev is a lightweight, fast non-blocking TCP network library based on Reactor mode. gmqtt - Gmqtt is a flexible, high-performance MQTT broker library that fully implements the MQTT protocol V3.1.1. gnet - gnet is a high-performance, lightweight, non-blocking, event-driven networking framework written in pure Go. gNxI - A collection of tools for Network Management that use the gNMI and gNOI protocols. go-getter - Go library for downloading files or directories from various sources using a URL. go-powerdns - PowerDNS API bindings for Golang. go-stun - Go implementation of the STUN client (RFC 3489 and RFC 5389). gobgp - BGP implemented in the Go Programming Language. gohooks - GoHooks make it easy to send and consume secured web-hooks from a Go application. Inspired by Spatie's Laravel Webhook Client and Server. golibwireshark - Package golibwireshark use libwireshark library to decode pcap file and analyse dissection data. gopacket - Go library for packet processing with libpcap bindings. gopcap - Go wrapper for libpcap. goshark - Package goshark use tshark to decode IP packet and create data struct to analyse packet. gosnmp - Native Go library for performing SNMP actions. gotcp - Go package for quickly writing tcp applications. grab - Go package for managing file downloads. graval - Experimental FTP server framework. HTTPLab - HTTPLabs let you inspect HTTP requests and forge responses. httpproxy - HTTP proxy handler and dialer. iplib - Library for working with IP addresses (net.IP, net.IPNet), inspired by python ipaddress and ruby ipaddr jazigo - Jazigo is a tool written in Go for retrieving configuration for multiple network devices. kcp-go - KCP - Fast and Reliable ARQ Protocol. kcptun - Extremely simple & fast udp tunnel based on KCP protocol. lhttp - Powerful websocket framework, build your IM server more easily. linkio - Network link speed simulation for Reader/Writer interfaces. llb - It's a very simple but quick backend for proxy servers. Can be useful for fast redirection to predefined domain with zero memory allocation and fast response. mdns - Simple mDNS (Multicast DNS) client/server library in Golang. mqttPaho - The Paho Go Client provides an MQTT client library for connection to MQTT brokers via TCP, TLS or WebSockets. nbio - High-performance, non-blocking, event-driven, easy-to-use, least-dependency networking framework written in Go. NFF-Go - Framework for rapid development of performant network functions for cloud and bare-metal (former YANFF). packet - Send packets over TCP and UDP. It can buffer messages and hot-swap connections if needed. panoptes-stream - A cloud native distributed streaming network telemetry (gNMI, Juniper JTI and Cisco MDT). peerdiscovery - Pure Go library for cross-platform local peer discovery using UDP multicast. portproxy - Simple TCP proxy which adds CORS support to API's which don't support it. publicip - Package publicip returns your public facing IPv4 address (internet egress). quic-go - An implementation of the QUIC protocol in pure Go. raw - Package raw enables reading and writing data at the device driver level for a network interface. sftp - Package sftp implements the SSH File Transfer Protocol as described in https://filezilla-project.org/specs/draft-ietf-secsh-filexfer-02.txt. ssh - Higher-level API for building SSH servers (wraps crypto/ssh). sslb - It's a Super Simples Load Balancer, just a little project to achieve some kind of performance. stun - Go implementation of RFC 5389 STUN protocol. tcp_server - Go library for building tcp servers faster. tspool - A TCP Library use worker pool to improve performance and protect your server. utp - Go uTP micro transport protocol implementation. vssh - Go library for building network and server automation over SSH protocol. water - Simple TUN/TAP library. webrtc - A pure Go implementation of the WebRTC API. winrm - Go WinRM client to remotely execute commands on Windows machines. xtcp - TCP Server Framework with simultaneous full duplex communication, graceful shutdown, and custom protocol. HTTP Clients Libraries for making HTTP requests. gentleman - Full-featured plugin-driven HTTP client library. go-http-client - Make http calls simply and easily. grequests - A Go "clone" of the great and famous Requests library. heimdall - An enchanced http client with retry and hystrix capabilities. httpretry - Enriches the default go HTTP client with retry functionality. pester - Go HTTP client calls with retries, backoff, and concurrency. request - HTTP client for golang. If you have experience about axios or requests, you will love it. No 3rd dependency. resty - Simple HTTP and REST client for Go inspired by Ruby rest-client. rq - A nicer interface for golang stdlib HTTP client. sling - Sling is a Go HTTP client library for creating and sending API requests. OpenGL Libraries for using OpenGL in Go. gl - Go bindings for OpenGL (generated via glow). glfw - Go bindings for GLFW 3. go-glmatrix - Go port of glMatrix library. goxjs/gl - Go cross-platform OpenGL bindings (OS X, Linux, Windows, browsers, iOS, Android). goxjs/glfw - Go cross-platform glfw library for creating an OpenGL context and receiving events. mathgl - Pure Go math package specialized for 3D math, with inspiration from GLM. ORM Libraries that implement Object-Relational Mapping or datamapping techniques. beego orm - Powerful orm framework for go. Support: pq/mysql/sqlite3. ent - An entity framework for Go. Simple, yet powerful ORM for modeling and querying data. go-firestorm - A simple ORM for Google/Firebase Cloud Firestore. go-pg - PostgreSQL ORM with focus on PostgreSQL specific features and performance. go-queryset - 100% type-safe ORM with code generation and MySQL, PostgreSQL, Sqlite3, SQL Server support based on GORM. go-sql - A easy ORM for mysql. go-sqlbuilder - A flexible and powerful SQL string builder library plus a zero-config ORM. go-store - Simple and fast Redis backed key-value store library for Go. GORM - The fantastic ORM library for Golang, aims to be developer friendly. gormt - Mysql database to golang gorm struct. gorp - Go Relational Persistence, ORM-ish library for Go. grimoire - Grimoire is a database access layer and validation for golang. (Support: MySQL, PostgreSQL and SQLite3). lore - Simple and lightweight pseudo-ORM/pseudo-struct-mapping environment for Go. marlow - Generated ORM from project structs for compile time safety assurances. pop/soda - Database migration, creation, ORM, etc... for MySQL, PostgreSQL, and SQLite. QBS - Stands for Query By Struct. A Go ORM. reform - Better ORM for Go, based on non-empty interfaces and code generation. rel - Modern Database Access Layer for Golang - Testable, Extendable and Crafted Into a Clean and Elegant API. SQLBoiler - ORM generator. Generate a featureful and blazing-fast ORM tailored to your database schema. upper.io/db - Single interface for interacting with different data sources through the use of adapters that wrap mature database drivers. XORM - Simple and powerful ORM for Go. (Support: MySQL, MyMysql, PostgreSQL, Tidb, SQLite3, MsSql and Oracle). Zoom - Blazing-fast datastore and querying engine built on Redis. Package Management Official tooling for dependency and package management go modules - Modules are the unit of source code interchange and versioning. The go command has direct support for working with modules, including recording and resolving dependencies on other modules. Official experimental tooling for package management dep - Go dependency tool. vgo - Versioned Go. Unofficial libraries for package and dependency management. glide - Manage your golang vendor and vendored packages with ease. Inspired by tools like Maven, Bundler, and Pip. godep - dependency tool for go, godep helps build packages reproducibly by fixing their dependencies. gom - Go Manager - bundle for go. goop - Simple dependency manager for Go (golang), inspired by Bundler. gop - Build and manage your Go applications out of GOPATH. gopm - Go Package Manager. govendor - Go Package Manager. Go vendor tool that works with the standard vendor file. gpm - Barebones dependency manager for Go. johnny-deps - Minimal dependency version using Git. modgv - Converts 'go mod graph' output into Graphviz's DOT language. mvn-golang - plugin that provides way for auto-loading of Golang SDK, dependency management and start build environment in Maven project infrastructure. nut - Vendor Go dependencies. VenGO - create and manage exportable isolated go virtual environments. Performance jaeger - A distributed tracing system. pixie - No instrumentation tracing for Golang applications via eBPF. profile - Simple profiling support package for Go. statsviz - Live visualization of your Go application runtime statistics. tracer - Simple, lightweight tracing. Query Language api-fu - Comprehensive GraphQL implementation. dasel - Query and update data structures using selectors from the command line. Comparable to jq/yq but supports JSON, YAML, TOML and XML with zero runtime dependencies. gojsonq - A simple Go package to Query over JSON Data. gqlgen - go generate based graphql server library. graphql - graphql parser + utilities. graphql - GraphQL server with a focus on ease of use. graphql-go - Implementation of GraphQL for Go. gws - Apollos' "GraphQL over Websocket" client and server implementation. jsonpath - A query library for retrieving part of JSON based on JSONPath syntax. jsonql - JSON query expression library in Golang. jsonslice - Jsonpath queries with advanced filters. rql - Resource Query Language for REST API. rqp - Query Parser for REST API. Filtering, validations, both AND, OR operations are supported directly in the query. straf - Easily Convert Golang structs to GraphQL objects. Resource Embedding debme - Create an embed.FS from an existing embed.FS subdirectory. esc - Embeds files into Go programs and provides http.FileSystem interfaces to them. fileb0x - Simple tool to embed files in go with focus on "customization" and ease to use. go-embed - Generates go code to embed resource files into your library or executable. go-resources - Unfancy resources embedding with Go. go.rice - go.rice is a Go package that makes working with resources such as HTML, JS, CSS, images, and templates very easy. mule - Embed external resources like images, movies ... into Go source code to create single file binaries using go generate. Focussed on simplicity. packr - The simple and easy way to embed static files into Go binaries. rebed - Recreate folder structures and files from Go 1.16's embed.FS type statics - Embeds static resources into go files for single binary compilation + works with http.FileSystem + symlinks. statik - Embeds static files into a Go executable. templify - Embed external template files into Go code to create single file binaries. vfsgen - Generates a vfsdata.go file that statically implements the given virtual filesystem. Science and Data Analysis Libraries for scientific computing and data analyzing. assocentity - Package assocentity returns the average distance from words to a given entity. bradleyterry - Provides a Bradley-Terry Model for pairwise comparisons. calendarheatmap - Calendar heatmap in plain Go inspired by Github contribution activity. chart - Simple Chart Plotting library for Go. Supports many graphs types. dataframe-go - Dataframes for machine-learning and statistics (similar to pandas). decimal - Package decimal implements arbitrary-precision decimal floating-point arithmetic. evaler - Simple floating point arithmetic expression evaluator. ewma - Exponentially-weighted moving averages. geom - 2D geometry for golang. go-dsp - Digital Signal Processing for Go. go-estimate - State estimation and filtering algorithms in Go. go-gt - Graph theory algorithms written in "Go" language. godesim - Extended/multivariable ODE solver framework for event-based simulations with simple API. goent - GO Implementation of Entropy Measures. gohistogram - Approximate histograms for data streams. gonum - Gonum is a set of numeric libraries for the Go programming language. It contains libraries for matrices, statistics, optimization, and more. gonum/plot - gonum/plot provides an API for building and drawing plots in Go. goraph - Pure Go graph theory library(data structure, algorith visualization). gosl - Go scientific library for linear algebra, FFT, geometry, NURBS, numerical methods, probabilities, optimisation, differential equations, and more. GoStats - GoStats is an Open Source GoLang library for math statistics mostly used in Machine Learning domains, it covers most of the Statistical measures functions. graph - Library of basic graph algorithms. ode - Ordinary differential equation (ODE) solver which supports extended states and channel-based iteration stop conditions. orb - 2D geometry types with clipping, GeoJSON and Mapbox Vector Tile support. pagerank - Weighted PageRank algorithm implemented in Go. piecewiselinear - Tiny linear interpolation library. PiHex - Implementation of the "Bailey-Borwein-Plouffe" algorithm for the hexadecimal number Pi. rootfinding - root-finding algorithms library for finding roots of quadratic functions. sparse - Go Sparse matrix formats for linear algebra supporting scientific and machine learning applications, compatible with gonum matrix libraries. stats - Statistics package with common functions missing from the Golang standard library. streamtools - general purpose, graphical tool for dealing with streams of data. TextRank - TextRank implementation in Golang with extendable features (summarization, weighting, phrase extraction) and multithreading (goroutine) support. triangolatte - 2D triangulation library. Allows translating lines and polygons (both based on points) to the language of GPUs. Security Libraries that are used to help make your application more secure. acmetool - ACME (Let's Encrypt) client tool with automatic renewal. acra - Network encryption proxy to protect database-based applications from data leaks: strong selective encryption, SQL injections prevention, intrusion detection system. argon2-hashing - light wrapper around Go's argon2 package that closely mirrors with Go's standard library Bcrypt and simple-scrypt package. argon2pw - Argon2 password hash generation with constant-time password comparison. autocert - Auto provision Let's Encrypt certificates and start a TLS server. BadActor - In-memory, application-driven jailer built in the spirit of fail2ban. Cameradar - Tool and library to remotely hack RTSP streams from surveillance cameras. certificates - An opinionated tool for generating tls certificates. firewalld-rest - A rest application to dynamically update firewalld rules on a linux server. go-generate-password - Password generator that can be used on the cli or as a library. go-password-validator - Password validator based on raw cryptographic entropy values. go-yara - Go Bindings for YARA, the "pattern matching swiss knife for malware researchers (and everyone else)". goArgonPass - Argon2 password hash and verification designed to be compatible with existing Python and PHP implementations. goSecretBoxPassword - A probably paranoid package for securely hashing and encrypting passwords. Interpol - Rule-based data generator for fuzzing and penetration testing. lego - Pure Go ACME client library and CLI tool (for use with Let's Encrypt). memguard - A pure Go library for handling sensitive values in memory. nacl - Go implementation of the NaCL set of API's. optimus-go - ID hashing and Obfuscation using Knuth's Algorithm. passlib - Futureproof password hashing library. secure - HTTP middleware for Go that facilitates some quick security wins. secureio - An keyexchanging+authenticating+encrypting wrapper and multiplexer for io.ReadWriteCloser based on XChaCha20-poly1305, ECDH and ED25519. simple-scrypt - Scrypt package with a simple, obvious API and automatic cost calibration built-in. ssh-vault - encrypt/decrypt using ssh keys. sslmgr - SSL certificates made easy with a high level wrapper around acme/autocert. themis - high-level cryptographic library for solving typical data security tasks (secure data storage, secure messaging, zero-knowledge proof authentication), available for 14 languages, best fit for multi-platform apps. Serialization Libraries and tools for binary serialization. asn1 - Asn.1 BER and DER encoding library for golang. bambam - generator for Cap'n Proto schemas from go. bel - Generate TypeScript interfaces from Go structs/interfaces. Useful for JSON RPC. binstruct - Golang binary decoder for mapping data into the structure. cbor - Small, safe, and easy CBOR encoding and decoding library. colfer - Code generation for the Colfer binary format. csvutil - High Performance, idiomatic CSV record encoding and decoding to native Go structures. elastic - Convert slices, maps or any other unknown value across different types at run-time, no matter what. fixedwidth - Fixed-width text formatting (UTF-8 supported). fwencoder - Fixed width file parser (encoding and decoding library) for Go. go-capnproto - Cap'n Proto library and parser for go. go-codec - High Performance, feature-Rich, idiomatic encode, decode and rpc library for msgpack, cbor and json, with runtime-based OR code-generation support. go-lctree - Provides a CLI and primitives to serialize and deserialize LeetCode binary trees. gogoprotobuf - Protocol Buffers for Go with Gadgets. goprotobuf - Go support, in the form of a library and protocol compiler plugin, for Google's protocol buffers. jsoniter - High-performance 100% compatible drop-in replacement of "encoding/json". mapstructure - Go library for decoding generic map values into native Go structures. php_session_decoder - GoLang library for working with PHP session format and PHP Serialize/Unserialize functions. pletter - A standard way to wrap a proto message for message brokers. structomap - Library to easily and dynamically generate maps from static structures. unitpacking - Library to pack unit vectors into as fewest bytes as possible. Server Applications algernon - HTTP/2 web server with built-in support for Lua, Markdown, GCSS and Amber. Caddy - Caddy is an alternative, HTTP/2 web server that's easy to configure and use. consul - Consul is a tool for service discovery, monitoring and configuration. cortex-tenant - Prometheus remote write proxy that adds add Cortex tenant ID header based on metric labels. devd - Local webserver for developers. discovery - A registry for resilient mid-tier load balancing and failover. dudeldu - A simple SHOUTcast server. etcd - Highly-available key value store for shared configuration and service discovery. Fider - Fider is an open platform to collect and organize customer feedback. Flagr - Flagr is an open-source feature flagging and A/B testing service. flipt - A self contained feature flag solution written in Go and Vue.js go-feature-flag - A feature flag solution, with only a YAML file in the backend (S3, GitHub, HTTP, local file ...), no server to install, just add a file in a central system and refer to it. go-proxy-cache - Simple Reverse Proxy with Caching, written in Go, using Redis. jackal - An XMPP server written in Go. lets-proxy2 - Reverse proxy for handle https with issue certificates in fly from lets-encrypt. minio - Minio is a distributed object storage server. nginx-prometheus - Nginx log parser and exporter to Prometheus. nsq - A realtime distributed messaging platform. protoxy - A proxy server that converts JSON request bodies to Protocol Buffers. psql-streamer - Stream database events from PostgreSQL to Kafka. riemann-relay - Relay to load-balance Riemann events and/or convert them to Carbon. RoadRunner - High-performance PHP application server, load-balancer and process manager. SFTPGo - Fully featured and highly configurable SFTP server with optional FTP/S and WebDAV support. It can serve local filesystem and Cloud Storage backends such as S3 and Google Cloud Storage. simple-jwt-provider - Simple and lightweight provider which exhibits JWTs, supports login, password-reset (via mail) and user management. Trickster - HTTP reverse proxy cache and time series accelerator. Stream Processing Libraries and tools for stream processing and reactive programming. go-streams - Go stream processing library. machine - Go library for writing and generating stream workers with built in metrics and traceability. stream - Go Stream, like Java 8 Stream: Filter/Map/FlatMap/Peek/Sorted/ForEach/Reduce... Template Engines Libraries and tools for templating and lexing. ace - Ace is an HTML template engine for Go, inspired by Slim and Jade. Ace is a refinement of Gold. amber - Amber is an elegant templating engine for Go Programming Language It is inspired from HAML and Jade. damsel - Markup language featuring html outlining via css-selectors, extensible via pkg html/template and others. ego - Lightweight templating language that lets you write templates in Go. Templates are translated into Go and compiled. extemplate - Tiny wrapper around html/template to allow for easy file-based template inheritance. fasttemplate - Simple and fast template engine. Substitutes template placeholders up to 10x faster than text/template. gofpdf - PDF document generator with high level support for text, drawing and images. gospin - Article spinning and spintax/spinning syntax engine, useful for A/B, testing pieces of text/articles and creating more natural conversations. goview - Goview is a lightweight, minimalist and idiomatic template library based on golang html/template for building Go web application. hero - Hero is a handy, fast and powerful go template engine. jet - Jet template engine. kasia.go - Templating system for HTML and other text documents - go implementation. liquid - Go implementation of Shopify Liquid templates. maroto - A maroto way to create PDFs. Maroto is inspired in Bootstrap and uses gofpdf. Fast and simple. mustache - Go implementation of the Mustache template language. pongo2 - Django-like template-engine for Go. quicktemplate - Fast, powerful, yet easy to use template engine. Converts templates into Go code and then compiles it. raymond - Complete handlebars implementation in Go. Razor - Razor view engine for Golang. Soy - Closure templates (aka Soy templates) for Go, following the official spec. sprig - Useful template functions for Go templates. velvet - Complete handlebars implementation in Go. Testing Libraries for testing codebases and generating test data. Testing Frameworks apitest - Simple and extensible behavioural testing library for REST based services or HTTP handlers that supports mocking external http calls and rendering of sequence diagrams. assert - Basic Assertion Library used along side native go testing, with building blocks for custom assertions. badio - Extensions to Go's testing/iotest package. baloo - Expressive and versatile end-to-end HTTP API testing made easy. biff - Bifurcation testing framework, BDD compatible. charlatan - Tool to generate fake interface implementations for tests. commander - Tool for testing cli applications on windows, linux and osx. covergates - Self-hosted code coverage report review and management service. cupaloy - Simple snapshot testing addon for your test framework. dbcleaner - Clean database for testing purpose, inspired by database_cleaner in Ruby. dsunit - Datastore testing for SQL, NoSQL, structured files. embedded-postgres - Run a real Postgres database locally on Linux, OSX or Windows as part of another Go application or test. endly - Declarative end to end functional testing. flute - HTTP client testing framework. frisby - REST API testing framework. ginkgo - BDD Testing Framework for Go. gnomock - integration testing with real dependencies (database, cache, even Kubernetes or AWS) running in Docker, without mocks. go-carpet - Tool for viewing test coverage in terminal. go-cmp - Package for comparing Go values in tests. go-hit - Hit is an http integration test framework written in golang. go-mutesting - Mutation testing for Go source code. go-testdeep - Extremely flexible golang deep comparison, extends the go testing package. go-vcr - Record and replay your HTTP interactions for fast, deterministic and accurate tests. goblin - Mocha like testing framework fo Go. goc - Goc is a comprehensive coverage testing system for The Go Programming Language. gocheck - More advanced testing framework alternative to gotest. GoConvey - BDD-style framework with web UI and live reload. gocrest - Composable hamcrest-like matchers for Go assertions. godog - Cucumber or Behat like BDD framework for Go. gofight - API Handler Testing for Golang Router framework. gogiven - YATSPEC-like BDD testing framework for Go. gomatch - library created for testing JSON against patterns. gomega - Rspec like matcher/assertion library. GoSpec - BDD-style testing framework for the Go programming language. gospecify - This provides a BDD syntax for testing your Go code. It should be familiar to anybody who has used libraries such as rspec. gosuite - Brings lightweight test suites with setup/teardown facilities to testing by leveraging Go1.7's Subtests. gotest.tools - A collection of packages to augment the go testing package and support common patterns. Hamcrest - fluent framework for declarative Matcher objects that, when applied to input values, produce self-describing results. httpexpect - Concise, declarative, and easy to use end-to-end HTTP and REST API testing. jsonassert - Package for verifying that your JSON payloads are serialized correctly. restit - Go micro framework to help writing RESTful API integration test. schema - Quick and easy expression matching for JSON schemas used in requests and responses. stop-and-go - Testing helper for concurrency. testcase - Idiomatic testing framework for Behavior Driven Development. testfixtures - A helper for Rails' like test fixtures to test database applications. Testify - Sacred extension to the standard go testing package. testmd - Convert markdown snippets into testable go code. testsql - Generate test data from SQL files before testing and clear it after finished. trial - Quick and easy extendable assertions without introducing much boilerplate. Tt - Simple and colorful test tools. wstest - Websocket client for unit-testing a websocket http.Handler. Mock counterfeiter - Tool for generating self-contained mock objects. go-localstack - Tool for using localstack in AWS testing. go-sqlmock - Mock SQL driver for testing database interactions. go-txdb - Single transaction based database driver mainly for testing purposes. gock - Versatile HTTP mocking made easy. gomock - Mocking framework for the Go programming language. govcr - HTTP mock for Golang: record and replay HTTP interactions for offline testing. hoverfly - HTTP(S) proxy for recording and simulating REST/SOAP APIs with extensible middleware and easy-to-use CLI. httpmock - Easy mocking of HTTP responses from external resources. minimock - Mock generator for Go interfaces. mockhttp - Mock object for Go http.ResponseWriter. mockit - Allows functions and method easy mocking, without defining new types; it's similar to Mockito for Java. timex - A test-friendly replacement for the native time package. Fuzzing and delta-debugging/reducing/shrinking. go-fuzz - Randomized testing system. gofuzz - Library for populating go objects with random values. Tavor - Generic fuzzing and delta-debugging framework. Selenium and browser control tools. cdp - Type-safe bindings for the Chrome Debugging Protocol that can be used with browsers or other debug targets that implement it. chromedp - a way to drive/test Chrome, Safari, Edge, Android Webviews, and other browsers supporting the Chrome Debugging Protocol. ggr - a lightweight server that routes and proxies Selenium WebDriver requests to multiple Selenium hubs. playwright-go - browser automation library to control Chromium, Firefox and WebKit with a single API. rod - A Devtools driver to make web automation and scraping easy. selenoid - alternative Selenium hub server that launches browsers within containers. Fail injection failpoint - An implementation of failpoints for Golang. Text Processing Libraries for parsing and manipulating texts. Specific Formats align - A general purpose application that aligns text. allot - Placeholder and wildcard text parsing for CLI tools and bots. bbConvert - Converts bbCode to HTML that allows you to add support for custom bbCode tags. blackfriday - Markdown processor in Go. bluemonday - HTML Sanitizer. codetree - Parses indented code (python, pixy, scarlet, etc.) and returns a tree structure. colly - Fast and Elegant Scraping Framework for Gophers. commonregex - A collection of common regular expressions for Go. dataflowkit - Web scraping Framework to turn websites into structured data. did - DID (Decentralized Identifiers) Parser and Stringer in Go. doi - Document object identifier (doi) parser in Go. editorconfig-core-go - Editorconfig file parser and manipulator for Go. enca - Minimal cgo bindings for libenca. encdec - Package provides a generic interface to encoders and decodersa. genex - Count and expand Regular Expressions into all matching Strings. github_flavored_markdown - GitHub Flavored Markdown renderer (using blackfriday) with fenced code block highlighting, clickable header anchor links. go-fixedwidth - Fixed-width text formatting (encoder/decoder with reflection). go-humanize - Formatters for time, numbers, and memory size to human readable format. go-nmea - NMEA parser library for the Go language. go-output-format - Output go structures into multiple formats (YAML/JSON/etc) in your command line app. go-runewidth - Functions to get fixed width of the character or string. go-slugify - Make pretty slug with multiple languages support. go-toml - Go library for the TOML format with query support and handy cli tools. go-vcard - Parse and format vCard. go-wildcard - Simple and lightweight wildcard pattern matching. go-zero-width - Zero-width character detection and removal for Go. gofeed - Parse RSS and Atom feeds in Go. gographviz - Parses the Graphviz DOT language. gommon/bytes - Format bytes to string. gonameparts - Parses human names into individual name parts. goq - Declarative unmarshaling of HTML using struct tags with jQuery syntax (uses GoQuery). GoQuery - GoQuery brings a syntax and a set of features similar to jQuery to the Go language. goregen - Library for generating random strings from regular expressions. goribot - A simple golang spider/scraping framework,build a spider in 3 lines. gotext - GNU gettext utilities for Go. guesslanguage - Functions to determine the natural language of a unicode text. html-to-markdown - Convert HTML to Markdown. Even works with entire websites and can be extended through rules. htmlquery - An XPath query package for HTML, lets you extract data or evaluate from HTML documents by an XPath expression. inject - Package inject provides a reflect based injector. ltsv - High performance LTSV (Labeled Tab Separated Value) reader for Go. mxj - Encode / decode XML as JSON or map[string]interface{}; extract values with dot-notation paths and wildcards. Replaces x2j and j2x packages. normalize - Sanitize, normalize and compare fuzzy text. omniparser - A versatile ETL library that parses text input (CSV/txt/JSON/XML/EDI/X12/EDIFACT/etc) in streaming fashion and transforms data into JSON output using data-driven schema. pagser - Pagser is a simple, extensible, configurable parse and deserialize html page to struct based on goquery and struct tags for golang crawler. podcast - iTunes Compliant and RSS 2.0 Podcast Generator in Golang sdp - SDP: Session Description Protocol [RFC 4566]. sh - Shell parser and formatter. slug - URL-friendly slugify with multiple languages support. Slugify - Go slugify application that handles string. syndfeed - A syndication feed for Atom 1.0 and RSS 2.0. toml - TOML configuration format (encoder/decoder with reflection). Utility gofuckyourself - A sanitization-based swear filter for Go. gotabulate - Easily pretty-print your tabular data with Go. kace - Common case conversions covering common initialisms. parseargs-go - string argument parser that understands quotes and backslashes. parth - URL path segmentation parsing. radix - fast string sorting algorithm. regroup - Match regex expression named groups into go struct using struct tags and automatic parsing. Tagify - Produces a set of tags from given source. textwrap - Implementation of textwrap module from Python. TySug - Alternative suggestions with respect to keyboard layouts. xj2go - Convert xml or json to go struct. xurls - Extract urls from text. Third-party APIs Libraries for accessing third party APIs. airtable - Go client library for the Airtable API. amazon-product-advertising-api - Go Client Library for Amazon Product Advertising API. anaconda - Go client library for the Twitter 1.1 API. appstore-sdk-go - Unofficial Golang SDK for AppStore Connect API. aws-sdk-go - The official AWS SDK for the Go programming language. brewerydb - Go library for accessing the BreweryDB API. cachet - Go client library for Cachet (open source status page system). circleci - Go client library for interacting with CircleCI's API. clarifai - Go client library for interfacing with the Clarifai API. codeship-go - Go client library for interacting with Codeship's API v2. coinpaprika-go - Go client library for interacting with Coinpaprika's API. device-check-go - Go client library for interacting with iOS DeviceCheck API v1. discordgo - Go bindings for the Discord Chat API. ethrpc - Go bindings for Ethereum JSON RPC API. facebook - Go Library that supports the Facebook Graph API. fcm - Go library for Firebase Cloud Messaging. gads - Google Adwords Unofficial API. gami - Go library for Asterisk Manager Interface. gcm - Go library for Google Cloud Messaging. geo-golang - Go Library to access Google Maps, MapQuest, Nominatim, OpenCage, Bing, Mapbox, and OpenStreetMap geocoding / reverse geocoding APIs. github - Go library for accessing the GitHub REST API v3. githubql - Go library for accessing the GitHub GraphQL API v4. go-aws-news - Go application and library to fetch what's new from AWS. go-chronos - Go library for interacting with the Chronos Job Scheduler go-hacknews - Tiny Go client for HackerNews API. go-here - Go client library around the HERE location based APIs. go-imgur - Go client library for imgur go-jira - Go client library for Atlassian JIRA go-marathon - Go library for interacting with Mesosphere's Marathon PAAS. go-myanimelist - Go client library for accessing the MyAnimeList API. go-openproject - Go client library for interacting with OpenProject API. go-postman-collection - Go module to work with Postman Collections (compatible with Insomnia). go-sophos - Go client library for the Sophos UTM REST API with zero dependencies. go-sptrans - Go client library for the SPTrans Olho Vivo API. go-telegraph - Telegraph publishing platform API client. go-trending - Go library for accessing trending repositories and developers at Github. go-twitch - Go client for interacting with the Twitch v3 API. go-twitter - Go client library for the Twitter v1.1 APIs. go-unsplash - Go client library for the Unsplash.com API. go-xkcd - Go client for the xkcd API. go-yapla - Go client library for the Yapla v2.0 API. gogtrends - Google Trends Unofficial API. golang-tmdb - Golang wrapper for The Movie Database API v3. golyrics - Golyrics is a Go library to fetch music lyrics data from the Wikia website. gomalshare - Go library MalShare API malshare.com GoMusicBrainz - Go MusicBrainz WS2 client library. google - Auto-generated Google APIs for Go. google-analytics - Simple wrapper for easy google analytics reporting. google-cloud - Google Cloud APIs Go Client Library. google-email-audit-api - Go client library for Google G Suite Email Audit API. google-play-scraper - Get data from Google Play Store. gopaapi5 - Go Client Library for Amazon Product Advertising API 5.0. gosip - Go client library SharePoint API. gostorm - GoStorm is a Go library that implements the communications protocol required to write Storm spouts and Bolts in Go that communicate with the Storm shells. hipchat - This project implements a golang client library for the Hipchat API. hipchat (xmpp) - A golang package to communicate with HipChat over XMPP. igdb - Go client for the Internet Game Database API. kanka - Go client for the Kanka API. lastpass-go - Go client library for the LastPass API. libgoffi - Library adapter toolbox for native libffi integration Medium - Golang SDK for Medium's OAuth2 API. megos - Client library for accessing an Apache Mesos cluster. minio-go - Minio Go Library for Amazon S3 compatible cloud storage. mixpanel - Mixpanel is a library for tracking events and sending Mixpanel profile updates to Mixpanel from your go applications. patreon-go - Go library for Patreon API. paypal - Wrapper for PayPal payment API. playlyfe - The Playlyfe Rest API Go SDK. pushover - Go wrapper for the Pushover API. rawg-sdk-go - Go library for the RAWG Video Games Database API rrdaclient - Go Library to access statdns.com API, which is in turn RRDA API. DNS Queries over HTTP. shopify - Go Library to make CRUD request to the Shopify API. simples3 - Simple no frills AWS S3 Library using REST with V4 Signing written in Go. slack - Slack API in Go. smite - Go package to wraps access to the Smite game API. spotify - Go Library to access Spotify WEB API. steam - Go Library to interact with Steam game servers. stripe - Go client for the Stripe API. textbelt - Go client for the textbelt.com txt messaging API. translate - Go online translation package. Trello - Go wrapper for the Trello API. TripAdvisor - Go wrapper for the TripAdvisor API. tumblr - Go wrapper for the Tumblr v2 API. twitter-scraper - Scrape the Twitter Frontend API without authentication and limits. uptimerobot - Go wrapper and command-line client for the Uptime Robot v2 API. vl-go - Go client library around the VerifID identity verification layer API. webhooks - Webhook receiver for GitHub and Bitbucket. wit-go - Go client for wit.ai HTTP API. ynab - Go wrapper for the YNAB API. zooz - Go client for the Zooz API. Utilities General utilities and tools to make your life easier. apm - Process manager for Golang applications with an HTTP API. backscanner - A scanner similar to bufio.Scanner, but it reads and returns lines in reverse order, starting at a given position and going backward. beyond - The Go tool that will drive you to the AOP world! blank - Verify or remove blanks and whitespace from strings. bleep - Perform any number of actions on any set of OS signals in Go. boilr - Blazingly fast CLI tool for creating projects from boilerplate templates. changie - Automated changelog tool for preparing releases with lots of customization options. chyle - Changelog generator using a git repository with multiple configuration possibilities. circuit - An efficient and feature complete Hystrix like Go implementation of the circuit breaker pattern. circuitbreaker - Circuit Breakers in Go. clockwork - A simple fake clock for golang. cmd - Library for executing shell commands on osx, windows and linux. command - Command pattern for Go with thread safe serial and parallel dispatcher. copy - Package for fast copying structs of different types. copy-pasta - Universal multi-workstation clipboard that uses S3 like backend for the storage. countries - Full implementation of ISO-3166-1, ISO-4217, ITU-T E.164, Unicode CLDR and IANA ccTLD standarts. create-go-app - A powerful CLI for create a new production-ready project with backend (Golang), frontend (JavaScript, TypeScript) & deploy automation (Ansible, Docker) by running one command. ctop - Top-like interface (e.g. htop) for container metrics. ctxutil - A collection of utility functions for contexts. dbt - A framework for running self-updating signed binaries from a central, trusted repository. Death - Managing go application shutdown with signals. Deepcopier - Simple struct copying for Go. delve - Go debugger. dlog - Compile-time controlled logger to make your release smaller without removing debug calls. equalizer - Quota manager and rate limiter collection for Go. ergo - The management of multiple local services running over different ports made easy. evaluator - Evaluate an expression dynamicly based on s-expression. It's simple and easy to extend. filetype - Small package to infer the file type checking the magic numbers signature. filler - small utility to fill structs using "fill" tag. filter - provide filtering, sanitizing, and conversion of Go data. fzf - Command-line fuzzy finder written in Go. generate - runs go generate recursively on a specified path or environment variable and can filter by regex. ghokin - Parallelized formatter with no external dependencies for gherkin (cucumber, behat...). git-time-metric - Simple, seamless, lightweight time tracking for Git. go-astitodo - Parse TODOs in your GO code. go-bind-plugin - go:generate tool for wrapping symbols exported by golang plugins (1.8 only). go-bsdiff - Pure Go bsdiff and bspatch libraries and CLI tools. go-clip - A minimalistic clipboard manager for Mac. go-convert - Package go-convert enbles you to convert a value into another type. go-countries - Lightweight lookup over ISO-3166 codes. go-dry - DRY (don't repeat yourself) package for Go. go-funk - Modern Go utility library which provides helpers (map, find, contains, filter, chunk, reverse, ...). go-health - Health package simplifies the way you add health check to your services. go-httpheader - Go library for encoding structs into Header fields. go-lock - go-lock is a lock library implementing read-write mutex and read-write trylock without starvation. go-problemdetails - Go package for working with Problem Details. go-rate - Timed rate limiter for Go. go-safe - Panic-safe sandbox. go-sitemap-generator - XML Sitemap generator written in Go. go-trigger - Go-lang global event triggerer, Register Events with an id and trigger the event from anywhere from your project. go-type - Library providing Go types for store/validation and transfer of ISO-4217, ISO-3166, and other types. goback - Go simple exponential backoff package. goctx - Get your context value with high performance. godaemon - Utility to write daemons. godropbox - Common libraries for writing Go services/applications from Dropbox. gohper - Various tools/modules help for development. golarm - Fire alarms with system events. golog - Easy and lightweight CLI tool to time track your tasks. gopencils - Small and simple package to easily consume REST APIs. goplaceholder - a small golang lib to generate placeholder images. goreadability - Webpage summary extractor using Facebook Open Graph and arc90's readability. goreleaser - Deliver Go binaries as fast and easily as possible. goreporter - Golang tool that does static analysis, unit testing, code review and generate code quality report. goseaweedfs - SeaweedFS client library with almost full features. gostrutils - Collections of string manipulation and conversion functions. gotenv - Load environment variables from .env or any io.Reader in Go. goval - Evaluate arbitrary expressions in Go. gpath - Library to simplify access struct fields with Go's expression in reflection. gubrak - Golang utility library with syntactic sugar. It's like lodash, but for golang. handy - Many utilities and helpers like string handlers/formatters and validators. hostctl - A CLI tool to manage /etc/hosts with easy commands. htcat - Parallel and Pipelined HTTP GET Utility. hub - wrap git commands with additional functionality to interact with github from the terminal. hystrix-go - Implements Hystrix patterns of programmer-defined fallbacks aka circuit breaker. immortal - *nix cross-platform (OS agnostic) supervisor. intrinsic - Use x86 SIMD without writing any assembly code. jsend - JSend's implementation writen in Go. jump - Jump helps you navigate faster by learning your habits. koazee - Library inspired in Lazy evaluation and functional programming that takes the hassle out of working with arrays. lets-go - Go module that provides common utilities for Cloud Native REST API development. Also contains AWS Specific utilities. limiters - Rate limiters for distributed applications in Golang with configurable back-ends and distributed locks. lrserver - LiveReload server for Go. mc - Minio Client provides minimal tools to work with Amazon S3 compatible cloud storage and filesystems. mergo - Helper to merge structs and maps in Golang. Useful for configuration default values, avoiding messy if-statements. mimemagic - Pure Go ultra performant MIME sniffing library/utility. mimesniffer - A MIME type sniffer for Go. mimetype - Package for MIME type detection based on magic numbers. minify - Fast minifiers for HTML, CSS, JS, XML, JSON and SVG file formats. minquery - MongoDB / mgo.v2 query that supports efficient pagination (cursors to continue listing documents where we left off). moldova - Utility for generating random data based on an input template. mole - cli app to easily create ssh tunnels. mongo-go-pagination - Mongodb Pagination for official mongodb/mongo-go-driver package which supports both normal queries and Aggregation pipelines. mssqlx - Database client library, proxy for any master slave, master master structures. Lightweight and auto balancing in mind. multitick - Multiplexor for aligned tickers. myhttp - Simple API to make HTTP GET requests with timeout support. netbug - Easy remote profiling of your services. nfdump - Read nfdump netflow files. nostromo - CLI for building powerful aliases. okrun - go run error steamroller. olaf - Twitter Snowflake implemented in Go. onecache - Caching library with support for multiple backend stores (Redis, Memcached, filesystem etc). panicparse - Groups similar goroutines and colorizes stack dump. pattern-match - Pattern matching libray. peco - Simplistic interactive filtering tool. pgo - Convenient functions for PHP community. pm - Process (i.e. goroutine) manager with an HTTP API. ptr - Package that provide functions for simplified creation of pointers from constants of basic types. rclient - Readable, flexible, simple-to-use client for REST APIs. repeat - Go implementation of different backoff strategies useful for retrying operations and heartbeating. request - Go HTTP Requests for Humans. rerate - Redis-based rate counter and rate limiter for Go. rerun - Recompiling and rerunning go apps when source changes. rest-go - A package that provide many helpful methods for working with rest api. retry - The most advanced functional mechanism to perform actions repetitively until successful. retry - A simple but highly configurable retry package for Go. retry - Simple and easy retry mechanism package for Go. retry - A pretty simple library to ensure your work to be done. retry-go - Retrying made simple and easy for golang. robustly - Runs functions resiliently, catching and restarting panics. scan - Scan golang sql.Rows directly to structs, slices, or primitive types. scany - Library for scanning data from a database into Go structs and more. serve - A static http server anywhere you need. shutdown - App shutdown hooks for os.Signal handling. silk - Read silk netflow files. slice - Type-safe functions for common Go slice operations. sliceconv - Slice conversion between primitive types. slicer - Makes working with slices easier. sorty - Fast Concurrent / Parallel Sorting. spinner - Go package to easily provide a terminal spinner with options. sqlx - provides a set of extensions on top of the excellent built-in database/sql package. statiks - Fast, zero-configuration, static HTTP filer server. Storm - Simple and powerful toolkit for BoltDB. structs - Implement simple functions to manipulate structs. tik - Simple and easy timing wheel package for Go. tome - Tome was designed to paginate simple RESTful APIs. toolbox - Slice, map, multimap, struct, function, data conversion utilities. Service router, macro evaluator, tokenizer. ugo - ugo is slice toolbox with concise syntax for Go. UNIS - Common Architecture for String Utilities in Go. usql - usql is a universal command-line interface for SQL databases. util - Collection of useful utility functions. (strings, concurrency, manipulations, ...). wuzz - Interactive cli tool for HTTP inspection. xferspdy - Xferspdy provides binary diff and patch library in golang. UUID Libraries for working with UUIDs. goid - Generate and Parse RFC4122 compliant V4 UUIDs. gouid - Generate cryptographically secure random string IDs with just one allocation. nanoid - A tiny and efficient Go unique string ID generator. sno - Compact, sortable and fast unique IDs with embedded metadata. ulid - Go implementation of ULID (Universally Unique Lexicographically Sortable Identifier). uniq - No hassle safe, fast unique identifiers with commands. uuid - Generate, encode, and decode UUIDs v1 with fast or cryptographic-quality random node identifier. uuid - Implementation of Universally Unique Identifier (UUID). Supports both creation and parsing of UUIDs. Actively maintained fork of satori uuid. uuid - Go package for UUIDs based on RFC 4122 and DCE 1.1: Authentication and Security Services. wuid - An extremely fast unique number generator, 10-135 times faster than UUID. Validation Libraries for validation. checkdigit - Provide check digit algorithms (Luhn, Verhoeff, Damm) and calculators (ISBN, EAN, JAN, UPC, etc.). gody - :balloon: A lightweight struct validator for Go. govalid - Fast, tag-based validation for structs. govalidator - Validators and sanitizers for strings, numerics, slices and structs. govalidator - Validate Golang request data with simple rules. Highly inspired by Laravel's request validation. jio - jio is a json schema validator similar to joi. ozzo-validation - Supports validation of various data types (structs, strings, maps, slices, etc.) with configurable and extensible validation rules specified in usual code constructs instead of struct tags. terraform-validator - A norms and conventions validator for Terraform. validate - Go package for data validation and filtering. support validate Map, Struct, Request(Form, JSON, url.Values, Uploaded Files) data and more features. validate - This package provides a framework for writing validations for Go applications. validator - Go Struct and Field validation, including Cross Field, Cross Struct, Map, Slice and Array diving. Version Control Libraries for version control. gh - Scriptable server and net/http middleware for GitHub Webhooks. git2go - Go bindings for libgit2. go-git - highly extensible Git implementation in pure Go. go-vcs - manipulate and inspect VCS repositories in Go. hercules - gaining advanced insights from Git repository history. hgo - Hgo is a collection of Go packages providing read-access to local Mercurial repositories. Video Libraries for manipulating video. gmf - Go bindings for FFmpeg av* libraries. go-astisub - Manipulate subtitles in GO (.srt, .stl, .ttml, .webvtt, .ssa/.ass, teletext, .smi, etc.). go-astits - Parse and demux MPEG Transport Streams (.ts) natively in GO. go-m3u8 - Parser and generator library for Apple m3u8 playlists. go-mpd - Parser and generator library for MPEG-DASH manifest files. goav - Comprehensive Go bindings for FFmpeg. gst - Go bindings for GStreamer. libgosubs - Subtitle format support for go. Supports .srt, .ttml, and .ass. libvlc-go - Go bindings for libvlc 2.X/3.X/4.X (used by the VLC media player). m3u8 - Parser and generator library of M3U8 playlists for Apple HLS. v4l - Video capture library for Linux, written in Go. Web Frameworks Full stack web frameworks. aah - Scalable, performant, rapid development Web framework for Go. Aero - High-performance web framework for Go, reaches top scores in Lighthouse. Air - An ideally refined web framework for Go. appy - An opinionated productive web framework that helps scaling business easier. Banjo - Very simple and fast web framework for Go. Beego - beego is an open-source, high-performance web framework for the Go programming language. Buffalo - Bringing the productivity of Rails to Go! Confetti Framework - Confetti is a Go web application framework with an expressive, elegant syntax. Confetti combines the elegance of Laravel and the simplicity of Go. Echo - High performance, minimalist Go web framework. Fiber - An Express.js inspired web framework build on Fasthttp. Fireball - More "natural" feeling web framework. Flamingo - Framework for pluggable web projects. Including a concept for modules and offering features for DI, Configareas, i18n, template engines, graphql, observability, security, events, routing & reverse routing etc. Flamingo Commerce - Providing e-commerce features using clean architecture like DDD and ports and adapters, that you can use to build flexible e-commerce applications. Gearbox - A web framework written in Go with a focus on high performance and memory optimization. Gin - Gin is a web framework written in Go! It features a martini-like API with much better performance, up to 40 times faster. If you need performance and good productivity. Ginrpc - Gin parameter automatic binding tool,gin rpc tools. Gizmo - Microservice toolkit used by the New York Times. go-json-rest - Quick and easy way to setup a RESTful JSON API. go-rest - Small and evil REST framework for Go. Goa - Goa provides a holistic approach for developing remote APIs and microservices in Go. goa - goa is just like koajs for golang, it is a flexible, light, high-performance and extensible web framework based on middleware. Golax - A non Sinatra fast HTTP framework with support for Google custom methods, deep interceptors, recursion and more. Golf - Golf is a fast, simple and lightweight micro-web framework for Go. It comes with powerful features and has no dependencies other than the Go Standard Library. Gondola - The web framework for writing faster sites, faster. gongular - Fast Go web framework with input mapping/validation and (DI) Dependency Injection. GoTuna - Minimalistic web framework for Go with mux router, middlewares, sessions, templates, embeded views and static files. goweb - Web framework with routing, websockets, logging, middleware, static file server (optional gzip), and automatic TLS. Goyave - Feature-complete REST API framework aimed at clean code and fast development, with powerful built-in functionalities. hiboot - hiboot is a high performance web application framework with auto configuration and dependency injection support. Macaron - Macaron is a high productive and modular design web framework in Go. mango - Mango is a modular web-application framework for Go, inspired by Rack, and PEP333. Microservice - The framework for the creation of microservices, written in Golang. neo - Neo is minimal and fast Go Web Framework with extremely simple API. patron - Patron is a microservice framework following best cloud practices with a focus on productivity. Resoursea - REST framework for quickly writing resource based services. REST Layer - Framework to build REST/GraphQL API on top of databases with mostly configuration over code. Revel - High-productivity web framework for the Go language. rex - Rex is a library for modular development built upon gorilla/mux, fully compatible with net/http. rux - Simple and fast web framework for build golang HTTP applications. tango - Micro & pluggable web framework for Go. tigertonic - Go framework for building JSON web services inspired by Dropwizard. uAdmin - Fully featured web framework for Golang, inspired by Django. utron - Lightweight MVC framework for Go(Golang). vox - A golang web framework for humans, inspired by Koa heavily. WebGo - A micro-framework to build web apps; with handler chaining, middleware and context injection. With standard library compliant HTTP handlers(i.e. http.HandlerFunc). YARF - Fast micro-framework designed to build REST APIs and web services in a fast and simple way. Middlewares Actual middlewares client-timing - An HTTP client for Server-Timing header. CORS - Easily add CORS capabilities to your API. formjson - Transparently handle JSON input as a standard form POST. go-fault - Fault injection middleware for Go. go-server-timing - Add/parse Server-Timing header. Limiter - Dead simple rate limit middleware for Go. ln-paywall - Go middleware for monetizing APIs on a per-request basis with the Lightning Network (Bitcoin). Tollbooth - Rate limit HTTP request handler. XFF - Handle X-Forwarded-For header and friends. Libraries for creating HTTP middlewares alice - Painless middleware chaining for Go. catena - http.Handler wrapper catenation (same API as "chain"). chain - Handler wrapper chaining with scoped data (net/context-based "middleware"). go-wrap - Small middlewares package for net/http. gores - Go package that handles HTML, JSON, XML and etc. responses. Useful for RESTful APIs. interpose - Minimalist net/http middleware for golang. mediary - add interceptors to http.Client to allow dumping/shaping/tracing/... of requests/responses. muxchain - Lightweight middleware for net/http. negroni - Idiomatic HTTP middleware for Golang. render - Go package for easily rendering JSON, XML, and HTML template responses. renderer - Simple, lightweight and faster response (JSON, JSONP, XML, YAML, HTML, File) rendering package for Go. rye - Tiny Go middleware library (with canned Middlewares) that supports JWT, CORS, Statsd, and Go 1.7 context. stats - Go middleware that stores various information about your web application. Routers alien - Lightweight and fast http router from outer space. bellt - A simple Go HTTP router. Bone - Lightning Fast HTTP Multiplexer. Bxog - Simple and fast HTTP router for Go. It works with routes of varying difficulty, length and nesting. And he knows how to create a URL from the received parameters. chi - Small, fast and expressive HTTP router built on net/context. fasthttprouter - High performance router forked from httprouter. The first router fit for fasthttp. FastRouter - a fast, flexible HTTP router written in Go. gocraft/web - Mux and middleware package in Go. Goji - Goji is a minimalistic and flexible HTTP request multiplexer with support for net/context. goroute - Simple yet powerful HTTP request multiplexer. GoRouter - GoRouter is a Server/API micro framwework, HTTP request router, multiplexer, mux that provides request router with middleware supporting net/context. gowww/router - Lightning fast HTTP router fully compatible with the net/http.Handler interface. httprouter - High performance router. Use this and the standard http handlers to form a very high performance web framework. httptreemux - High-speed, flexible tree-based HTTP router for Go. Inspiration from httprouter. lars - Is a lightweight, fast and extensible zero allocation HTTP router for Go used to create customizable frameworks. mux - Powerful URL router and dispatcher for golang. ozzo-routing - An extremely fast Go (golang) HTTP router that supports regular expression route matching. Comes with full support for building RESTful APIs. pure - Is a lightweight HTTP router that sticks to the std "net/http" implementation. Siesta - Composable framework to write middleware and handlers. vestigo - Performant, stand-alone, HTTP compliant URL Router for go web applications. violetear - Go HTTP router. xmux - High performance muxer based on httprouter with net/context support. xujiajun/gorouter - A simple and fast HTTP router for Go. WebAssembly dom - DOM library. go-canvas - Library to use HTML5 Canvas, with all drawing within go code. tinygo - Go compiler for small places. Microcontrollers, WebAssembly, and command-line tools. Based on LLVM. vert - Interop between Go and JS values. wasmbrowsertest - Run Go WASM tests in your browser. webapi - Bindings for DOM and HTML generated from WebIDL. Windows d3d9 - Go bindings for Direct3D9. go-ole - Win32 OLE implementation for golang. gosddl - Converter from SDDL-string to user-friendly JSON. SDDL consist of four part: Owner, Primary Group, DACL, SACL. XML Libraries and tools for manipulating XML. XML-Comp - Simple command line XML comparer that generates diffs of folders, files and tags. xml2map - XML to MAP converter written Golang. xmlwriter - Procedural XML generation API based on libxml2's xmlwriter module. xpath - XPath package for Go. xquery - XQuery lets you extract data from HTML/XML documents using XPath expression. zek - Generate a Go struct from XML. Tools Go software and plugins. Code Analysis apicompat - Checks recent changes to a Go project for backwards incompatible changes. dupl - Tool for code clone detection. errcheck - Errcheck is a program for checking for unchecked errors in Go programs. gcvis - Visualise Go program GC trace data in real time. go-checkstyle - checkstyle is a style check tool like java checkstyle. This tool inspired by java checkstyle, golint. The style referred to some points in Go Code Review Comments. go-cleanarch - go-cleanarch was created to validate Clean Architecture rules, like a The Dependency Rule and interaction between packages in your Go projects. go-critic - source code linter that brings checks that are currently not implemented in other linters. go-mod-outdated - An easy way to find outdated dependencies of your Go projects. go-outdated - Console application that displays outdated packages. goast-viewer - Web based Golang AST visualizer. GoCover.io - GoCover.io offers the code coverage of any golang package as a service. goimports - Tool to fix (add, remove) your Go imports automatically. golang-ifood-sdk - iFood API SDK. golines - Formatter that automatically shortens long lines in Go code. GoLint - Golint is a linter for Go source code. Golint online - Lints online Go source files on GitHub, Bitbucket and Google Project Hosting using the golint package. GoPlantUML - Library and CLI that generates text plantump class diagram containing information about structures and interfaces with the relationship among them. goreturns - Adds zero-value return statements to match the func return types. gosimple - gosimple is a linter for Go source code that specialises on simplifying code. gostatus - Command line tool, shows the status of repositories that contain Go packages. lint - Run linters as part of go test. php-parser - A Parser for PHP written in Go. staticcheck - staticcheck is go vet on steroids, applying a ton of static analysis checks you might be used to from tools like ReSharper for C#. tarp - tarp finds functions and methods without direct unit tests in Go source code. tickgit - CLI and go package for surfacing code comment TODOs (in any language) and applying a git blameto identify the author. unconvert - Remove unnecessary type conversions from Go source. unused - unused checks Go code for unused constants, variables, functions and types. validate - Automatically validates struct fields with tags. Editor Plugins Go plugin for JetBrains IDEs - Go plugin for JetBrains IDEs. go-language-server - A wrapper to turn the VSCode go extension into a language server supporting the language-server-protocol. go-mode - Go mode for GNU/Emacs. go-plus - Go (Golang) Package For Atom That Adds Autocomplete, Formatting, Syntax Checking, Linting and Vetting. gocode - Autocompletion daemon for the Go programming language. goimports-reviser - Formatting tool for imports. goprofiling - This extension adds benchmark profiling support for the Go language to VS Code. GoSublime - Golang plugin collection for the text editor SublimeText 3 providing code completion and other IDE-like features. gounit-vim - Vim plugin for generating Go tests based on the function's or method's signature. theia-go-extension - Go language support for the Theia IDE. vim-compiler-go - Vim plugin to highlight syntax errors on save. vim-go - Go development plugin for Vim. vscode-go - Extension for Visual Studio Code (VS Code) which provides support for the Go language. Watch - Runs a command in an acme win on file changes. Go Generate Tools generic - flexible data type for Go. genny - Elegant generics for Go. gocontracts - brings design-by-contract to Go by synchronizing the code with the documentation. gonerics - Idiomatic Generics in Go. gotests - Generate Go tests from your source code. gounit - Generate Go tests using your own templates. hasgo - Generate Haskell inspired functions for your slices. re2dfa - Transform regular expressions into finite state machines and output Go source code. TOML-to-Go - Translates TOML into a Go type in the browser instantly. xgen - XSD (XML Schema Definition) parser and Go/C/Java/Rust/TypeScript code generator. Go Tools colorgo - Wrapper around go command for colorized go build output. depth - Visualize dependency trees of any package by analyzing imports. docs - Automatically generate RESTful API documentation for GO projects - aligned with Open API Specification standard. generator-go-lang - A Yeoman generator to get new Go projects started. go-callvis - Visualize call graph of your Go program using dot format. go-james - Go project skeleton creator, builds and tests your projects without the manual setup. go-pkg-complete - Bash completion for go and wgo. go-swagger - Swagger 2.0 implementation for go. Swagger is a simple yet powerful representation of your RESTful API. godbg - Implementation of Rusts dbg! macro for quick and easy debugging during development. gomodrun - Go tool that executes and caches binaries included in go.mod files. gothanks - GoThanks automatically stars your go.mod github dependencies, sending this way some love to their maintainers. igo - An igo to go transpiler (new language features for Go language!) OctoLinker - Navigate through go files efficiently with the OctoLinker browser extension for GitHub. richgo - Enrich go test outputs with text decorations. roumon - Monitor current state of all active goroutines via a command line interface. rts - RTS: response to struct. Generates Go structs from server responses. typex - Examine Go types and their transitive dependencies, alternatively export results as TypeScript value objects (or types) declaration. Software Packages Software written in Go. DevOps Tools abbreviate - abbreviate is a tool turning long strings in to shorter ones with configurable seperaters, for example to embed branch names in to deployment stack IDs. aptly - aptly is a Debian repository management tool. aurora - Cross-platform web-based Beanstalkd queue server console. awsenv - Small binary that loads Amazon (AWS) environment variables for a profile. Blast - A simple tool for API load testing and batch jobs. bombardier - Fast cross-platform HTTP benchmarking tool. bosun - Time Series Alerting Framework. cassowary - Modern cross-platform HTTP load-testing tool written in Go. DepCharge - Helps orchestrating the execution of commands across the many dependencies in larger projects. docker-go-mingw - Docker image for building Go binaries for Windows with MinGW toolchain. Dockerfile-Generator - A go library and an executable that produces valid Dockerfiles using various input channels. dogo - Monitoring changes in the source file and automatically compile and run (restart). drone-jenkins - Trigger downstream Jenkins jobs using a binary, docker or Drone CI. drone-scp - Copy files and artifacts via SSH using a binary, docker or Drone CI. Dropship - Tool for deploying code via cdn. easyssh-proxy - Golang package for easy remote execution through SSH and SCP downloading via ProxyCommand. fac - Command-line user interface to fix git merge conflicts. gaia - Build powerful pipelines in any programming language. Gitea - Fork of Gogs, entirely community driven. gitea-github-migrator - Migrate all your GitHub repositories, issues, milestones and labels to your Gitea instance. go-furnace - Hosting solution written in Go. Deploy your Application with ease on AWS, GCP or DigitalOcean. go-selfupdate - Enable your Go applications to self update. gobrew - gobrew lets you easily switch between multiple versions of go. godbg - Web-based gdb front-end application. Gogs - A Self Hosted Git Service in the Go Programming Language. gonative - Tool which creates a build of Go that can cross compile to all platforms while still using the Cgo-enabled versions of the stdlib packages. govvv - go build wrapper to easily add version information into Go binaries. gox - Dead simple, no frills Go cross compile tool. goxc - build tool for Go, with a focus on cross-compiling and packaging. grapes - Lightweight tool designed to distribute commands over ssh with ease. GVM - GVM provides an interface to manage Go versions. Hey - Hey is a tiny program that sends some load to a web application. httpref - httpref is a handy CLI reference for HTTP methods, status codes, headers, and TCP and UDP ports. jcli - Jenkins CLI allows you manage your Jenkins as an easy way. kala - Simplistic, modern, and performant job scheduler. kcli - Command line tool for inspecting kafka topics/partitions/messages. kubernetes - Container Cluster Manager from Google. lstags - Tool and API to sync Docker images across different registries. lwc - A live-updating version of the UNIX wc command. manssh - manssh is a command line tool for managing your ssh alias config easily. Moby - Collaborative project for the container ecosystem to assemble container-based systems. Mora - REST server for accessing MongoDB documents and meta data. ostent - collects and displays system metrics and optionally relays to Graphite and/or InfluxDB. Packer - Packer is a tool for creating identical machine images for multiple platforms from a single source configuration. Pewpew - Flexible HTTP command line stress tester. Pomerium - Pomerium is an identity-aware access proxy. Rodent - Rodent helps you manage Go versions, projects and track dependencies. s3-proxy - S3 Proxy with GET, PUT and DELETE methods and authentication (OpenID Connect and Basic Auth). s3gof3r - Small utility/library optimized for high speed transfer of large objects into and out of Amazon S3. s5cmd - Blazing fast S3 and local filesystem execution tool. Scaleway-cli - Manage BareMetal Servers from Command Line (as easily as with Docker). script - Making it easy to write shell-like scripts in Go for DevOps and system administration tasks. sg - Benchmarks a set of HTTP endpoints (like ab), with possibility to use the response code and data between each call for specific server stress based on its previous response. skm - SKM is a simple and powerful SSH Keys Manager, it helps you to manage your multiple SSH keys easily! StatusOK - Monitor your Website and REST APIs.Get Notified through Slack, E-mail when your server is down or response time is more than expected. terraform-provider-openapi - Terraform provider plugin that dynamically configures itself at runtime based on an OpenAPI document (formerly known as swagger file) containing the definitions of the APIs exposed. traefik - Reverse proxy and load balancer with support for multiple backends. trubka - A CLI tool to manage and troubleshoot Apache Kafka clusters with the ability of generically publishing/consuming protocol buffer and plain text events to/from Kafka. uTask - Automation engine that models and executes business processes declared in yaml. Vegeta - HTTP load testing tool and library. It's over 9000! webhook - Tool which allows user to create HTTP endpoints (hooks) that execute commands on the server. Wide - Web-based IDE for Teams using Golang. winrm-cli - Cli tool to remotely execute commands on Windows machines. Other Software Better Go Playground - Go playground with syntax highlight, code completion and other features. blocky - Fast and lightweight DNS proxy as ad-blocker for local network with many features. borg - Terminal based search engine for bash snippets. boxed - Dropbox based blog engine. Cherry - Tiny webchat server in Go. Circuit - Circuit is a programmable platform-as-a-service (PaaS) and/or Infrastructure-as-a-Service (IaaS), for management, discovery, synchronization and orchestration of services and hosts comprising cloud applications. Comcast - Simulate bad network connections. confd - Manage local application configuration files using templates and data from etcd or consul. croc - Easily and securely send files or folders from one computer to another. Docker - Open platform for distributed applications for developers and sysadmins. Documize - Modern wiki software that integrates data from SaaS tools. dp - Through SDK for data exchange with blockchain, developers can get easy access to DAPP development. drive - Google Drive client for the commandline. Duplicacy - A cross-platform network and cloud backup tool based on the idea of lock-free deduplication. Gebug - A tool that makes debugging of Dockerized Go applications super easy by enabling Debugger and Hot-Reload features, seamlessly. gfile - Securely transfer files between two computers, without any third party, over WebRTC. Go Package Store - App that displays updates for the Go packages in your GOPATH. go-peerflix - Video streaming torrent client. GoBoy - Nintendo Game Boy Color emulator written in Go. gocc - Gocc is a compiler kit for Go written in Go. GoDocTooltip - Chrome extension for Go Doc sites, which shows function description as tooltip at function list. GoLand - Full featured cross-platform Go IDE. Gor - Http traffic replication tool, for replaying traffic from production to stage/dev environments in real-time. Guora - A self-hosted Quora like web application written in Go. hugo - Fast and Modern Static Website Engine. ide - Browser accessible IDE. Designed for Go with Go. ipe - Open source Pusher server implementation compatible with Pusher client libraries written in GO. joincap - Command-line utility for merging multiple pcap files together. Juju - Cloud-agnostic service deployment and orchestration - supports EC2, Azure, Openstack, MAAS and more. Leaps - Pair programming service using Operational Transforms. lgo - Interactive Go programming with Jupyter. It supports code completion, code inspection and 100% Go compatibility. limetext - Lime Text is a powerful and elegant text editor primarily developed in Go that aims to be a Free and open-source software successor to Sublime Text. LiteIDE - LiteIDE is a simple, open source, cross-platform Go IDE. mockingjay - Fake HTTP servers and consumer driven contracts from one configuration file. You can also make the server randomly misbehave to help do more realistic performance tests. myLG - Command Line Network Diagnostic tool written in Go. naclpipe - Simple NaCL EC25519 based crypto pipe tool written in Go. nes - Nintendo Entertainment System (NES) emulator written in Go. Orbit - A simple tool for running commands and generating files from templates. peg - Peg, Parsing Expression Grammar, is an implementation of a Packrat parser generator. restic - De-duplicating backup program. scc - Sloc Cloc and Code, a very fast accurate code counter with complexity calculations and COCOMO estimates. Seaweed File System - Fast, Simple and Scalable Distributed File System with O(1) disk seek. shell2http - Executing shell commands via http server (for prototyping or remote control). snap - Powerful telemetry framework. Snitch - Simple way to notify your team and many tools when someone has deployed any application via Tsuru. Stack Up - Stack Up, a super simple deployment tool - just Unix - think of it like 'make' for a network of servers. syncthing - Open, decentralized file synchronization tool and protocol. tcpdog - eBPF based TCP observability. tcpprobe - TCP tool for network performance and path monitoring, including socket statistics. term-quiz - Quizzes for your terminal. toxiproxy - Proxy to simulate network and system conditions for automated tests. tsuru - Extensible and open source Platform as a Service software. vaku - CLI & API for folder-based functions in Vault like copy, move, and search. vFlow - High-performance, scalable and reliable IPFIX, sFlow and Netflow collector. wellington - Sass project management tool, extends the language with sprite functions (like Compass). woke - Detect non-inclusive language in your source code. Resources Where to discover new Go libraries. Benchmarks autobench - Framework to compare the performance between different Go versions. go-benchmark-app - Powerful HTTP-benchmark tool mixed with b, Wrk, Siege tools. Gathering statistics and various parameters for benchmarks and comparison results. go-benchmarks - Few miscellaneous Go microbenchmarks. Compare some language features to alternative approaches. go-http-routing-benchmark - Go HTTP request router benchmark and comparison. go-json-benchmark - Go JSON benchmark. go-ml-benchmarks - benchmarks for machine learning inference in Go. go-web-framework-benchmark - Go web framework benchmark. go_serialization_benchmarks - Benchmarks of Go serialization methods. gocostmodel - Benchmarks of common basic operations for the Go language. golang-sql-benchmark - Collection of benchmarks for popular Go database/SQL utilities. gospeed - Go micro-benchmarks for calculating the speed of language constructs. kvbench - Key/Value database benchmark. skynet - Skynet 1M threads microbenchmark. speedtest-resize - Compare various Image resize algorithms for the Go language. Conferences Capital Go - Washington, D.C., USA. dotGo - Paris, France. GoCon - Tokyo, Japan. GoDays - Berlin, Germany. GoLab - Florence, Italy. GolangUK - London, UK. GopherChina - Shanghai, China. GopherCon - Denver, USA. GopherCon Australia - Sydney, Australia. GopherCon Brazil - Florianpolis, BR. GopherCon Europe - Berlin, Germany. GopherCon India - Pune, India. GopherCon Israel - Tel Aviv, Israel. GopherCon Russia - Moscow, Russia. GopherCon Singapore - Mapletree Business City, Singapore. GopherCon Vietnam - Ho Chi Minh City, Vietnam. GothamGo - New York City, USA. GoWayFest - Minsk, Belarus. E-Books A Go Developer's Notebook An Introduction to Programming in Go Build Web Application with Golang Building Web Apps With Go For the Love of Go - A series of introductory books for Go beginners. Go 101 - A book focusing on Go syntax/semantics and all kinds of details. Go Bootcamp Go Succinctly - in Persian. GoBooks - A curated list of Go books. How To Code in Go eBook - A 600 page introduction to Go aimed at first time developers. Learning Go Network Programming With Go Practical Go Lessons Spaceship Go A Journey to the Standard Library The Go Programming Language The Golang Standard Library by Example (Chinese) Web Application with Go the Anti-Textbook Writing A Compiler In Go Writing An Interpreter In Go Gophers Free Gophers Pack - Gopher graphics pack by Maria Letta with illustrations and emotional characters in vector and raster. Go-gopher-Vector - Go gopher Vector Data [.ai, .svg]. gopher-logos - adorable gopher logos. gopher-stickers gopher-vector gophericons gopherize.me - Gopherize yourself. gophers - Gopher artworks by Ashley McNamara. gophers - Free gophers. gophers - random gopher graphics. gophers - Gopher amigurumi toy pattern. Meetups Basel Go Meetup Belfast Gophers Berlin Golang Brisbane Gophers Canberra Gophers Go Language NYC Go London User Group Go Remote Meetup Go Toronto Go User Group Atlanta GoBandung GoBridge, San Francisco, CA GoCracow - Krakow, Poland GoJakarta Golang Amsterdam Golang Argentina Golang Baltimore, MD Golang Bangalore Golang Belo Horizonte - Brazil Golang Boston Golang Bulgaria Golang Cardiff, UK Golang Copenhagen Golang Curitiba - Brazil Golang DC, Arlington, VA Golang Dorset, UK Golang Estonia Golang Gurgaon, India Golang Hamburg - Germany Golang Israel Golang Joinville - Brazil Golang Kathmandu Golang Korea Golang Lima - Peru Golang Lyon Golang Marseille Golang Melbourne Golang Mountain View Golang New York Golang North East Golang Paris Golang Poland Golang Pune Golang Singapore Golang Stockholm Golang Sydney, AU Golang So Paulo - Brazil Golang Taipei Golang Turkey Golang Vancouver, BC Golang Vienna, Austria Golang Golang Golang GoSF - San Francisco, CA Istanbul Golang Seattle Go Programmers Ukrainian Golang User Groups Utah Go User Group Women Who Go - San Francisco, CA Add the group of your city/country here (send PR) Style Guides bahlo/go-styleguide CockroachDB GitLab Hyperledger Magnetico Sourcegraph Thanos Uber Social Media Twitter @golang @golang_news @golangch @golangflow @golangweekly Reddit r/golang Websites Awesome Go @LibHunt - Your go-to Go Toolbox. Awesome Remote Job - Curated list of awesome remote jobs. A lot of them are looking for Go hackers. awesome-awesomeness - List of other amazingly awesome lists. CodinGame - Learn Go by solving interactive tasks using small games as practical examples. Go Blog - The official Go blog. Go Challenge - Learn Go by solving problems and getting feedback from Go experts. Go Code Club - A group of Gophers read and discuss a different Go project every week. Go Community on Hashnode - Community of Gophers on Hashnode. Go Forum - Forum to discuss Go. Go In 5 Minutes - 5 minute screencasts focused on getting one thing done. Go Projects - List of projects on the Go community wiki. Go Report Card - A report card for your Go package. go.dev - A hub for Go developers. gocryforhelp - Collection of Go projects that needs help. Good place to start your open-source way in Go. godoc.org - Documentation for open source Go packages. Golang Developer Jobs - Developer Jobs exclusivly for Golang related Roles. Golang Flow - Post Updates, News, Packages and more. Golang News - Links and news about Go programming. Golang Resources - A curation of the best articles, exercises, talks and videos to learn Go. golang-graphics - Collection of Go images, graphics, and art. golang-nuts - Go mailing list. Google Plus Community - The Google+ community for #golang enthusiasts. Gopher Community Chat - Join Our New Slack Community For Gophers (Understand how it came). Gophercises - Free coding exercises for budding gophers. gowalker.org - Go Project API documentation. json2go - Advanced JSON to Go struct conversion - online tool. justforfunc - Youtube channel dedicated to Go programming language tips and tricks, hosted by Francesc Campoy @francesc. Learn Go Programming - Learn Go concepts with illustrations. Lille Gophers - Golang talks community in Lille, France (@LilleGophers). Made with Golang r/Golang - News about Go. studygolang - The community of studygolang in China. Trending Go repositories on GitHub today - Good place to find new Go libraries. TutorialEdge - Golang Tutorials 50 Shades of Go - Traps, Gotchas, and Common Mistakes for New Golang Devs. A Guide to Golang E-Commerce - Building a Golang site for e-commerce (demo included). A Tour of Go - Interactive tour of Go. Build web application with Golang - Golang ebook intro how to build a web app with golang. Building and Testing a REST API in Go with Gorilla Mux and PostgreSQL - Well write an API with the help of the powerful Gorilla Mux. Building Go Web Applications and Microservices Using Gin - Get familiar with Gin and find out how it can help you reduce boilerplate code and build a request handling pipeline. Caching Slow Database Queries - How to cache slow database queries. Canceling MySQL - How to cancel MySQL queries. Debugged.it Go patterns - Advanced Go patterns with ready-to-run examples. Design Patterns in Go - Collection of programming design patterns implemented in Go. Ethereum Development with Go - A little e-book on Ethereum Development with Go. Games With Go - A video series teaching programming and game development. Go By Example - Hands-on introduction to Go using annotated example programs. Go Cheat Sheet - Go's reference card. Go database/sql tutorial - Introduction to database/sql. Go Playground for iOS - Interactively edit & play Go snippets on your mobile device. Go WebAssembly Tutorial - Building a Simple Calculator go-patterns - Curated list of Go design patterns, recipes and idioms. goapp - An opinionated guideline to structure & develop a Go web application/service. Golang for Node.js Developers - Examples of Golang compared to Node.js for learning. Golangbot - Tutorials to get started with programming in Go. GolangCode - Collection of code snippets and tutorials to help tackle every day issues. GopherSnippets - Code snippets with tests and testable examples for the Go programming language. Hackr.io - Learn Go from the best online golang tutorials submitted & voted by the golang programming community. How to Benchmark: dbq vs sqlx vs GORM - Learn how to benchmark in Go. As a case-study, we will benchmark dbq, sqlx and GORM. How To Deploy a Go Web Application with Docker - Learn how to use Docker for Go development and how to build production Docker images. How to Use Godog for Behavior-driven Development in Go - Get started with Godog a Behavior-driven development framework for building and testing Go applications. Learn Go with 1000+ Exercises - Learn Go with thousands of examples, exercises, and quizzes. Learn Go with TDD - Learn Go with test-driven development. Learning Golang - From zero to hero - Getting started with golang for beginner. package main - YouTube channel about Programming in Go. Programming with Google Go - Coursera Specialization to learn about Go from scratch. The worlds easiest introduction to WebAssembly with Golang Working with Go - Intro to go for experienced programmers. Your basic Go - Huge collection of tutorials and how to's.

 # # # # # # # # # # # # # # # # # # # #
 Repository: jmechner/Prince-of-Persia-Apple-II, index: 1446, word count: 4283 
 # # # # # # # # # # # # # # # # # # # #

A formatter for Python files==== YAPF ==== .. image:: https://badge.fury.io/py/yapf.svg :target: https://badge.fury.io/py/yapf :alt: PyPI version .. image:: https://travis-ci.org/google/yapf.svg?branch=main :target: https://travis-ci.org/google/yapf :alt: Build status .. image:: https://coveralls.io/repos/google/yapf/badge.svg?branch=main :target: https://coveralls.io/r/google/yapf?branch=main :alt: Coverage status Introduction Most of the current formatters for Python --- e.g., autopep8, and pep8ify --- are made to remove lint errors from code. This has some obvious limitations. For instance, code that conforms to the PEP 8 guidelines may not be reformatted. But it doesn't mean that the code looks good. YAPF takes a different approach. It's based off of 'clang-format' <https://cl ang.llvm.org/docs/ClangFormat.html>, developed by Daniel Jasper. In essence, the algorithm takes the code and reformats it to the best formatting that conforms to the style guide, even if the original code didn't violate the style guide. The idea is also similar to the 'gofmt' <https://golang.org/cmd/ gofmt/> tool for the Go programming language: end all holy wars about formatting - if the whole codebase of a project is simply piped through YAPF whenever modifications are made, the style remains consistent throughout the project and there's no point arguing about style in every code review. The ultimate goal is that the code YAPF produces is as good as the code that a programmer would write if they were following the style guide. It takes away some of the drudgery of maintaining your code. .. footer:: YAPF is not an official Google product (experimental or otherwise), it is just code that happens to be owned by Google. .. contents:: Installation To install YAPF from PyPI: .. code-block:: shell $ pip install yapf (optional) If you are using Python 2.7 and want to enable multiprocessing: .. code-block:: shell $ pip install futures YAPF is still considered in "alpha" stage, and the released version may change often; therefore, the best way to keep up-to-date with the latest development is to clone this repository. Note that if you intend to use YAPF as a command-line tool rather than as a library, installation is not necessary. YAPF supports being run as a directory by the Python interpreter. If you cloned/unzipped YAPF into DIR, it's possible to run: .. code-block:: shell $ PYTHONPATH=DIR python DIR/yapf [options] ... Python versions YAPF supports Python 2.7 and 3.6.4+. (Note that some Python 3 features may fail to parse with Python versions before 3.6.4.) YAPF requires the code it formats to be valid Python for the version YAPF itself runs under. Therefore, if you format Python 3 code with YAPF, run YAPF itself under Python 3 (and similarly for Python 2). Usage Options:: usage: yapf [-h] [-v] [-d | -i] [-r | -l START-END] [-e PATTERN] [--style STYLE] [--style-help] [--no-local-style] [-p] [-vv] [files [files ...]] Formatter for Python code. positional arguments: files optional arguments: -h, --help show this help message and exit -v, --version show version number and exit -d, --diff print the diff for the fixed source -i, --in-place make changes to files in place -r, --recursive run recursively over directories -l START-END, --lines START-END range of lines to reformat, one-based -e PATTERN, --exclude PATTERN patterns for files to exclude from formatting --style STYLE specify formatting style: either a style name (for example "pep8" or "google"), or the name of a file with style settings. The default is pep8 unless a .style.yapf or setup.cfg or pyproject.toml file located in the same directory as the source or one of its parent directories (for stdin, the current directory is used). --style-help show style settings and exit; this output can be saved to .style.yapf to make your settings permanent --no-local-style don't search for local style definition -p, --parallel Run yapf in parallel when formatting multiple files. Requires concurrent.futures in Python 2.X -vv, --verbose Print out file names while processing Return Codes Normally YAPF returns zero on successful program termination and non-zero otherwise. If --diff is supplied, YAPF returns zero when no changes were necessary, non-zero otherwise (including program error). You can use this in a CI workflow to test that code has been YAPF-formatted. Excluding files from formatting (.yapfignore) In addition to exclude patterns provided on commandline, YAPF looks for additional patterns specified in a file named .yapfignore located in the working directory from which YAPF is invoked. .yapfignore's syntax is similar to UNIX's filename pattern matching:: * matches everything ? matches any single character [seq] matches any character in seq [!seq] matches any character not in seq Note that no entry should begin with ./. Formatting style The formatting style used by YAPF is configurable and there are many "knobs" that can be used to tune how YAPF does formatting. See the style.py module for the full list. To control the style, run YAPF with the --style argument. It accepts one of the predefined styles (e.g., pep8 or google), a path to a configuration file that specifies the desired style, or a dictionary of key/value pairs. The config file is a simple listing of (case-insensitive) key = value pairs with a [yapf] heading. For example: .. code-block:: ini [yapf] based_on_style = pep8 spaces_before_comment = 4 split_before_logical_operator = true The based_on_style setting determines which of the predefined styles this custom style is based on (think of it like subclassing). Four styles are predefined: pep8 (default) google (based off of the Google Python Style Guide_) yapf (for use with Google open source projects) facebook .. _Google Python Style Guide: https://github.com/google/styleguide/blob/gh-pages/pyguide.md See _STYLE_NAME_TO_FACTORY in style.py_ for details. .. _style.py: https://github.com/google/yapf/blob/main/yapf/yapflib/style.py It's also possible to do the same on the command line with a dictionary. For example: .. code-block:: shell --style='{based_on_style: pep8, indent_width: 2}' This will take the pep8 base style and modify it to have two space indentations. YAPF will search for the formatting style in the following manner: Specified on the command line In the [style] section of a .style.yapf file in either the current directory or one of its parent directories. In the [yapf] section of a setup.cfg file in either the current directory or one of its parent directories. In the [tool.yapf] section of a pyproject.toml file in either the current directory or one of its parent directories. In the [style] section of a ~/.config/yapf/style file in your home directory. If none of those files are found, the default style is used (PEP8). Example An example of the type of formatting that YAPF can do, it will take this ugly code: .. code-block:: python x = { 'a':37,'b':42, 'c':927} y = 'hello ''world' z = 'hello '+'world' a = 'hello {}'.format('world') class foo ( object ): def f (self ): return 37*-+2 def g(self, x,y=42): return y def f ( a ) : return 37+-+a[42-x : y**3] and reformat it into: .. code-block:: python x = {'a': 37, 'b': 42, 'c': 927} y = 'hello ' 'world' z = 'hello ' + 'world' a = 'hello {}'.format('world') class foo(object): def f(self): return 37 * -+2 def g(self, x, y=42): return y def f(a): return 37 + -+a[42 - x:y**3] Example as a module The two main APIs for calling yapf are FormatCode and FormatFile, these share several arguments which are described below: .. code-block:: python >>> from yapf.yapflib.yapf_api import FormatCode # reformat a string of code >>> FormatCode("f ( a = 1, b = 2 )") 'f(a=1, b=2)\n' A style_config argument: Either a style name or a path to a file that contains formatting style settings. If None is specified, use the default style as set in style.DEFAULT_STYLE_FACTORY. .. code-block:: python >>> FormatCode("def g():\n return True", style_config='pep8') 'def g():\n return True\n' A lines argument: A list of tuples of lines (ints), [start, end], that we want to format. The lines are 1-based indexed. It can be used by third-party code (e.g., IDEs) when reformatting a snippet of code rather than a whole file. .. code-block:: python >>> FormatCode("def g( ):\n a=1\n b = 2\n return a==b", lines=[(1, 1), (2, 3)]) 'def g():\n a = 1\n b = 2\n return a==b\n' A print_diff (bool): Instead of returning the reformatted source, return a diff that turns the formatted source into reformatter source. .. code-block:: python >>> print(FormatCode("a==b", filename="foo.py", print_diff=True)) --- foo.py (original) +++ foo.py (reformatted) @@ -1 +1 @@ -a==b +a == b Note: the filename argument for FormatCode is what is inserted into the diff, the default is <unknown>. FormatFile returns reformatted code from the passed file along with its encoding: .. code-block:: python >>> from yapf.yapflib.yapf_api import FormatFile # reformat a file >>> print(open("foo.py").read()) # contents of file a==b >>> FormatFile("foo.py") ('a == b\n', 'utf-8') The in_place argument saves the reformatted code back to the file: .. code-block:: python >>> FormatFile("foo.py", in_place=True) (None, 'utf-8') >>> print(open("foo.py").read()) # contents of file (now fixed) a == b Formatting diffs Options:: usage: yapf-diff [-h] [-i] [-p NUM] [--regex PATTERN] [--iregex PATTERN][-v] [--style STYLE] [--binary BINARY] This script reads input from a unified diff and reformats all the changed lines. This is useful to reformat all the lines touched by a specific patch. Example usage for git/svn users: git diff -U0 --no-color --relative HEAD^ | yapf-diff -i svn diff --diff-cmd=diff -x-U0 | yapf-diff -p0 -i It should be noted that the filename contained in the diff is used unmodified to determine the source file to update. Users calling this script directly should be careful to ensure that the path in the diff is correct relative to the current working directory. optional arguments: -h, --help show this help message and exit -i, --in-place apply edits to files instead of displaying a diff -p NUM, --prefix NUM strip the smallest prefix containing P slashes --regex PATTERN custom pattern selecting file paths to reformat (case sensitive, overrides -iregex) --iregex PATTERN custom pattern selecting file paths to reformat (case insensitive, overridden by -regex) -v, --verbose be more verbose, ineffective without -i --style STYLE specify formatting style: either a style name (for example "pep8" or "google"), or the name of a file with style settings. The default is pep8 unless a .style.yapf or setup.cfg or pyproject.toml file located in the same directory as the source or one of its parent directories (for stdin, the current directory is used). --binary BINARY location of binary to use for yapf Knobs ALIGN_CLOSING_BRACKET_WITH_VISUAL_INDENT Align closing bracket with visual indentation. ALLOW_MULTILINE_LAMBDAS Allow lambdas to be formatted on more than one line. ALLOW_MULTILINE_DICTIONARY_KEYS Allow dictionary keys to exist on multiple lines. For example: .. code-block:: python x = { ('this is the first element of a tuple', 'this is the second element of a tuple'): value, } ALLOW_SPLIT_BEFORE_DEFAULT_OR_NAMED_ASSIGNS Allow splitting before a default / named assignment in an argument list. ALLOW_SPLIT_BEFORE_DICT_VALUE Allow splits before the dictionary value. ARITHMETIC_PRECEDENCE_INDICATION Let spacing indicate operator precedence. For example: .. code-block:: python a = 1 * 2 + 3 / 4 b = 1 / 2 - 3 * 4 c = (1 + 2) * (3 - 4) d = (1 - 2) / (3 + 4) e = 1 * 2 - 3 f = 1 + 2 + 3 + 4 will be formatted as follows to indicate precedence: .. code-block:: python a = 1*2 + 3/4 b = 1/2 - 3*4 c = (1+2) * (3-4) d = (1-2) / (3+4) e = 1*2 - 3 f = 1 + 2 + 3 + 4 BLANK_LINE_BEFORE_NESTED_CLASS_OR_DEF Insert a blank line before a def or class immediately nested within another def or class. For example: .. code-block:: python class Foo: # <------ this blank line def method(): pass BLANK_LINE_BEFORE_MODULE_DOCSTRING Insert a blank line before a module docstring. BLANK_LINE_BEFORE_CLASS_DOCSTRING Insert a blank line before a class-level docstring. BLANK_LINES_AROUND_TOP_LEVEL_DEFINITION Sets the number of desired blank lines surrounding top-level function and class definitions. For example: .. code-block:: python class Foo: pass # <------ having two blank lines here # <------ is the default setting class Bar: pass BLANK_LINES_BETWEEN_TOP_LEVEL_IMPORTS_AND_VARIABLES Sets the number of desired blank lines between top-level imports and variable definitions. Useful for compatibility with tools like isort. COALESCE_BRACKETS Do not split consecutive brackets. Only relevant when DEDENT_CLOSING_BRACKETS or INDENT_CLOSING_BRACKETS is set. For example: .. code-block:: python call_func_that_takes_a_dict( { 'key1': 'value1', 'key2': 'value2', } ) would reformat to: .. code-block:: python call_func_that_takes_a_dict({ 'key1': 'value1', 'key2': 'value2', }) COLUMN_LIMIT The column limit (or max line-length) CONTINUATION_ALIGN_STYLE The style for continuation alignment. Possible values are: - ``SPACE``: Use spaces for continuation alignment. This is default behavior. - ``FIXED``: Use fixed number (CONTINUATION_INDENT_WIDTH) of columns (ie: CONTINUATION_INDENT_WIDTH/INDENT_WIDTH tabs or CONTINUATION_INDENT_WIDTH spaces) for continuation alignment. - ``VALIGN-RIGHT``: Vertically align continuation lines to multiple of INDENT_WIDTH columns. Slightly right (one tab or a few spaces) if cannot vertically align continuation lines with indent characters. CONTINUATION_INDENT_WIDTH Indent width used for line continuations. DEDENT_CLOSING_BRACKETS Put closing brackets on a separate line, dedented, if the bracketed expression can't fit in a single line. Applies to all kinds of brackets, including function definitions and calls. For example: .. code-block:: python config = { 'key1': 'value1', 'key2': 'value2', } # <--- this bracket is dedented and on a separate line time_series = self.remote_client.query_entity_counters( entity='dev3246.region1', key='dns.query_latency_tcp', transform=Transformation.AVERAGE(window=timedelta(seconds=60)), start_ts=now()-timedelta(days=3), end_ts=now(), ) # <--- this bracket is dedented and on a separate line DISABLE_ENDING_COMMA_HEURISTIC Disable the heuristic which places each list element on a separate line if the list is comma-terminated. EACH_DICT_ENTRY_ON_SEPARATE_LINE Place each dictionary entry onto its own line. FORCE_MULTILINE_DICT Respect EACH_DICT_ENTRY_ON_SEPARATE_LINE even if the line is shorter than COLUMN_LIMIT. I18N_COMMENT The regex for an internationalization comment. The presence of this comment stops reformatting of that line, because the comments are required to be next to the string they translate. I18N_FUNCTION_CALL The internationalization function call names. The presence of this function stops reformatting on that line, because the string it has cannot be moved away from the i18n comment. INDENT_DICTIONARY_VALUE Indent the dictionary value if it cannot fit on the same line as the dictionary key. For example: .. code-block:: python config = { 'key1': 'value1', 'key2': value1 + value2, } INDENT_WIDTH The number of columns to use for indentation. INDENT_BLANK_LINES Set to True to prefer indented blank lines rather than empty INDENT_CLOSING_BRACKETS Put closing brackets on a separate line, indented, if the bracketed expression can't fit in a single line. Applies to all kinds of brackets, including function definitions and calls. For example: .. code-block:: python config = { 'key1': 'value1', 'key2': 'value2', } # <--- this bracket is indented and on a separate line time_series = self.remote_client.query_entity_counters( entity='dev3246.region1', key='dns.query_latency_tcp', transform=Transformation.AVERAGE(window=timedelta(seconds=60)), start_ts=now()-timedelta(days=3), end_ts=now(), ) # <--- this bracket is indented and on a separate line JOIN_MULTIPLE_LINES Join short lines into one line. E.g., single line if statements. NO_SPACES_AROUND_SELECTED_BINARY_OPERATORS Do not include spaces around selected binary operators. For example: .. code-block:: python 1 + 2 * 3 - 4 / 5 will be formatted as follows when configured with ``*``, ``/``: .. code-block:: python 1 + 2*3 - 4/5 SPACES_AROUND_POWER_OPERATOR Set to True to prefer using spaces around **. SPACES_AROUND_DEFAULT_OR_NAMED_ASSIGN Set to True to prefer spaces around the assignment operator for default or keyword arguments. SPACES_AROUND_DICT_DELIMITERS Adds a space after the opening '{' and before the ending '}' dict delimiters. .. code-block:: python {1: 2} will be formatted as: .. code-block:: python { 1: 2 } SPACES_AROUND_LIST_DELIMITERS Adds a space after the opening '[' and before the ending ']' list delimiters. .. code-block:: python [1, 2] will be formatted as: .. code-block:: python [ 1, 2 ] SPACES_AROUND_SUBSCRIPT_COLON Use spaces around the subscript / slice operator. For example: .. code-block:: python my_list[1 : 10 : 2] SPACES_AROUND_TUPLE_DELIMITERS Adds a space after the opening '(' and before the ending ')' tuple delimiters. .. code-block:: python (1, 2, 3) will be formatted as: .. code-block:: python ( 1, 2, 3 ) SPACES_BEFORE_COMMENT The number of spaces required before a trailing comment. This can be a single value (representing the number of spaces before each trailing comment) or list of of values (representing alignment column values; trailing comments within a block will be aligned to the first column value that is greater than the maximum line length within the block). For example: With ``spaces_before_comment=5``: .. code-block:: python 1 + 1 # Adding values will be formatted as: .. code-block:: python 1 + 1 # Adding values <-- 5 spaces between the end of the statement and comment With ``spaces_before_comment=15, 20``: .. code-block:: python 1 + 1 # Adding values two + two # More adding longer_statement # This is a longer statement short # This is a shorter statement a_very_long_statement_that_extends_beyond_the_final_column # Comment short # This is a shorter statement will be formatted as: .. code-block:: python 1 + 1 # Adding values <-- end of line comments in block aligned to col 15 two + two # More adding longer_statement # This is a longer statement <-- end of line comments in block aligned to col 20 short # This is a shorter statement a_very_long_statement_that_extends_beyond_the_final_column # Comment <-- the end of line comments are aligned based on the line length short # This is a shorter statement SPACE_BETWEEN_ENDING_COMMA_AND_CLOSING_BRACKET Insert a space between the ending comma and closing bracket of a list, etc. SPACE_INSIDE_BRACKETS Use spaces inside brackets, braces, and parentheses. For example: .. code-block:: python method_call( 1 ) my_dict[ 3 ][ 1 ][ get_index( *args, **kwargs ) ] my_set = { 1, 2, 3 } SPLIT_ARGUMENTS_WHEN_COMMA_TERMINATED Split before arguments if the argument list is terminated by a comma. SPLIT_ALL_COMMA_SEPARATED_VALUES If a comma separated list (dict, list, tuple, or function def) is on a line that is too long, split such that all elements are on a single line. SPLIT_ALL_TOP_LEVEL_COMMA_SEPARATED_VALUES Variation on SPLIT_ALL_COMMA_SEPARATED_VALUES in which, if a subexpression with a comma fits in its starting line, then the subexpression is not split. This avoids splits like the one for b in this code: .. code-block:: python abcdef( aReallyLongThing: int, b: [Int, Int]) With the new knob this is split as: .. code-block:: python abcdef( aReallyLongThing: int, b: [Int, Int]) SPLIT_BEFORE_BITWISE_OPERATOR Set to True to prefer splitting before &, | or ^ rather than after. SPLIT_BEFORE_ARITHMETIC_OPERATOR Set to True to prefer splitting before +, -, *, /, //, or @ rather than after. SPLIT_BEFORE_CLOSING_BRACKET Split before the closing bracket if a list or dict literal doesn't fit on a single line. SPLIT_BEFORE_DICT_SET_GENERATOR Split before a dictionary or set generator (comp_for). For example, note the split before the for: .. code-block:: python foo = { variable: 'Hello world, have a nice day!' for variable in bar if variable != 42 } SPLIT_BEFORE_DOT Split before the . if we need to split a longer expression: .. code-block:: python foo = ('This is a really long string: {}, {}, {}, {}'.format(a, b, c, d)) would reformat to something like: .. code-block:: python foo = ('This is a really long string: {}, {}, {}, {}' .format(a, b, c, d)) SPLIT_BEFORE_EXPRESSION_AFTER_OPENING_PAREN Split after the opening paren which surrounds an expression if it doesn't fit on a single line. SPLIT_BEFORE_FIRST_ARGUMENT If an argument / parameter list is going to be split, then split before the first argument. SPLIT_BEFORE_LOGICAL_OPERATOR Set to True to prefer splitting before and or or rather than after. SPLIT_BEFORE_NAMED_ASSIGNS Split named assignments onto individual lines. SPLIT_COMPLEX_COMPREHENSION For list comprehensions and generator expressions with multiple clauses (e.g multiple for calls, if filter expressions) and which need to be reflowed, split each clause onto its own line. For example: .. code-block:: python result = [ a_var + b_var for a_var in xrange(1000) for b_var in xrange(1000) if a_var % b_var] would reformat to something like: .. code-block:: python result = [ a_var + b_var for a_var in xrange(1000) for b_var in xrange(1000) if a_var % b_var] SPLIT_PENALTY_AFTER_OPENING_BRACKET The penalty for splitting right after the opening bracket. SPLIT_PENALTY_AFTER_UNARY_OPERATOR The penalty for splitting the line after a unary operator. SPLIT_PENALTY_ARITHMETIC_OPERATOR The penalty of splitting the line around the +, -, *, /, //, %, and @ operators. SPLIT_PENALTY_BEFORE_IF_EXPR The penalty for splitting right before an if expression. SPLIT_PENALTY_BITWISE_OPERATOR The penalty of splitting the line around the &, |, and ^ operators. SPLIT_PENALTY_COMPREHENSION The penalty for splitting a list comprehension or generator expression. SPLIT_PENALTY_EXCESS_CHARACTER The penalty for characters over the column limit. SPLIT_PENALTY_FOR_ADDED_LINE_SPLIT The penalty incurred by adding a line split to the unwrapped line. The more line splits added the higher the penalty. SPLIT_PENALTY_IMPORT_NAMES The penalty of splitting a list of import as names. For example: .. code-block:: python from a_very_long_or_indented_module_name_yada_yad import (long_argument_1, long_argument_2, long_argument_3) would reformat to something like: .. code-block:: python from a_very_long_or_indented_module_name_yada_yad import ( long_argument_1, long_argument_2, long_argument_3) SPLIT_PENALTY_LOGICAL_OPERATOR The penalty of splitting the line around the and and or operators. USE_TABS Use the Tab character for indentation. (Potentially) Frequently Asked Questions Why does YAPF destroy my awesome formatting? YAPF tries very hard to get the formatting correct. But for some code, it won't be as good as hand-formatting. In particular, large data literals may become horribly disfigured under YAPF. The reasons for this are manyfold. In short, YAPF is simply a tool to help with development. It will format things to coincide with the style guide, but that may not equate with readability. What can be done to alleviate this situation is to indicate regions YAPF should ignore when reformatting something: .. code-block:: python # yapf: disable FOO = { # ... some very large, complex data literal. } BAR = [ # ... another large data literal. ] # yapf: enable You can also disable formatting for a single literal like this: .. code-block:: python BAZ = { (1, 2, 3, 4), (5, 6, 7, 8), (9, 10, 11, 12), } # yapf: disable To preserve the nice dedented closing brackets, use the dedent_closing_brackets in your style. Note that in this case all brackets, including function definitions and calls, are going to use that style. This provides consistency across the formatted codebase. Why Not Improve Existing Tools? We wanted to use clang-format's reformatting algorithm. It's very powerful and designed to come up with the best formatting possible. Existing tools were created with different goals in mind, and would require extensive modifications to convert to using clang-format's algorithm. Can I Use YAPF In My Program? Please do! YAPF was designed to be used as a library as well as a command line tool. This means that a tool or IDE plugin is free to use YAPF. I still get non Pep8 compliant code! Why? YAPF tries very hard to be fully PEP 8 compliant. However, it is paramount to not risk altering the semantics of your code. Thus, YAPF tries to be as safe as possible and does not change the token stream (e.g., by adding parentheses). All these cases however, can be easily fixed manually. For instance, .. code-block:: python from my_package import my_function_1, my_function_2, my_function_3, my_function_4, my_function_5 FOO = my_variable_1 + my_variable_2 + my_variable_3 + my_variable_4 + my_variable_5 + my_variable_6 + my_variable_7 + my_variable_8 won't be split, but you can easily get it right by just adding parentheses: .. code-block:: python from my_package import (my_function_1, my_function_2, my_function_3, my_function_4, my_function_5) FOO = (my_variable_1 + my_variable_2 + my_variable_3 + my_variable_4 + my_variable_5 + my_variable_6 + my_variable_7 + my_variable_8) Gory Details Algorithm Design The main data structure in YAPF is the UnwrappedLine object. It holds a list of FormatToken\s, that we would want to place on a single line if there were no column limit. An exception being a comment in the middle of an expression statement will force the line to be formatted on more than one line. The formatter works on one UnwrappedLine object at a time. An UnwrappedLine typically won't affect the formatting of lines before or after it. There is a part of the algorithm that may join two or more UnwrappedLine\s into one line. For instance, an if-then statement with a short body can be placed on a single line: .. code-block:: python if a == 42: continue YAPF's formatting algorithm creates a weighted tree that acts as the solution space for the algorithm. Each node in the tree represents the result of a formatting decision --- i.e., whether to split or not to split before a token. Each formatting decision has a cost associated with it. Therefore, the cost is realized on the edge between two nodes. (In reality, the weighted tree doesn't have separate edge objects, so the cost resides on the nodes themselves.) For example, take the following Python code snippet. For the sake of this example, assume that line (1) violates the column limit restriction and needs to be reformatted. .. code-block:: python def xxxxxxxxxxx(aaaaaaaaaaaa, bbbbbbbbb, cccccccc, dddddddd, eeeeee): # 1 pass # 2 For line (1), the algorithm will build a tree where each node (a FormattingDecisionState object) is the state of the line at that token given the decision to split before the token or not. Note: the FormatDecisionState objects are copied by value so each node in the graph is unique and a change in one doesn't affect other nodes. Heuristics are used to determine the costs of splitting or not splitting. Because a node holds the state of the tree up to a token's insertion, it can easily determine if a splitting decision will violate one of the style requirements. For instance, the heuristic is able to apply an extra penalty to the edge when not splitting between the previous token and the one being added. There are some instances where we will never want to split the line, because doing so will always be detrimental (i.e., it will require a backslash-newline, which is very rarely desirable). For line (1), we will never want to split the first three tokens: def, xxxxxxxxxxx, and (. Nor will we want to split between the ) and the : at the end. These regions are said to be "unbreakable." This is reflected in the tree by there not being a "split" decision (left hand branch) within the unbreakable region. Now that we have the tree, we determine what the "best" formatting is by finding the path through the tree with the lowest cost. And that's it!

 # # # # # # # # # # # # # # # # # # # #
 Repository: vsouza/awesome-ios, index: 98, word count: 34879 
 # # # # # # # # # # # # # # # # # # # #

A curated list of awesome iOS ecosystem, including Objective-C and Swift Projects Content Courses Accessibility Alexa Analytics App Routing Apple TV Architecture Patterns ARKit Authentication Blockchain Bridging Cache Charts Code Quality Linter Color Command Line Concurrency Core Data Database Data Structures / Algorithms Date & Time Debugging EventBus Files Functional Programming Games GCD Gesture Graphics Hardware Bluetooth Camera Force Touch iBeacon Location Other Hardware Layout Logging Localization Machine Learning Maps Math Media Audio GIF Image Media Processing PDF Streaming Video Messaging Networking Notifications Push Notifications Push Notification Providers Local Notifications Objective-C Runtime Optimization Parsing CSV JSON XML & HTML Other Parsing Passbook Payments Permissions Products Reactive Programming React-Like Reflection Regex SDK Official Unofficial Security Encryption Keychain Server Testing TDD / BDD A/B Testing UI Testing Other Testing Text Font UI Activity Indicator Alert & Action Sheet Animation Transition Badge Button Calendar Cards Form & Settings Keyboard Label Login Menu Navigation Bar PickerView Popup Pull to Refresh Rating Stars ScrollView Segmented Control Slider Splash View Status Bar Stepper Switch Tab Bar Table View / Collection View Table View Collection View Expandable Cell Header Placeholder Collection View Layout Tag TextField & TextView UIPageControl Web View Utility User Consent VR Walkthrough / Intro / Tutorial Websocket Project setup Dependency / Package Manager Tools Rapid Development Injection Deployment / Distribution App Store Xcode Extensions (Xcode 8+) Themes Other Xcode Reference Style Guides Good Websites News, Blogs and more UIKit references Forums and discuss lists Tutorials and Keynotes Prototyping Newsletters Medium Social Media Twitter Facebook Groups Podcasts Books Other Awesome Lists Contributing Courses Getting Started Courses, tutorials and guides Apple- Start Developing with iOS - Apple Guide. Apple - Object-Oriented Programming with Objective-C Apple - Programming with Objective-C CodeProject - Getting Started with iPhone and iOS Development. Lifehacker - I Want to Write iOS Apps. Where Do I Start? Ray Wenderlich - Learn to code iOS Apps. Stanford - Developing iOS 7 Apps for iPhone and iPad Stanford - Developing iOS 10 Apps with Swift - Stanford's 2017 iTunes U course. Stanford - Developing iOS 11 Apps with Swift - Stanford's 2017 iTunes U course updated for iOS 11 and Swift. Swifteducation - Teaching App Development with Swift Udacity - Intro to iOS App Development with Swift Udemy - ARKit - Beginner to Professional in Swift 4 and iOS 11 ARStarter - Get started with ARKit - A little exercise for beginners. iOS 13 & Swift 5 - The Complete iOS App Development Bootcamp Classpert - A list of 500 iOS Development courses (free and paid), from top e-learning platforms - Complete catalog of courses from Udacity, Pluralsight, Coursera, Edx, Treehouse and Skillshare. Accessibility Frameworks that help to support accessibility features and enable people with disabilities to use your app Capable - Track accessibility features to improve your app for people with certain disabilities. Alexa Frameworks that help to support writing custom alexa skills in swift AlexaSkillsKit - Swift library to develop custom Alexa Skills. Analytics Analytics platforms, SDK's, error tracking and real-time answers about your app Instabug - In-app feedback, Bug and Crash reporting, Fix Bugs Faster through user-steps, video recordings, screen annotation, network requests logging. Mixpanel - Advanced analytics platform. Localytics - Brings app marketing and analytics together. Answers by Fabric - Answers gives you real-time insight into peoples experience in your app. ARAnalytics - Analytics abstraction library offering a sane API for tracking events and user data. Segment - The hassle-free way to integrate analytics into any iOS application. MOCA Analytics - Paid cross-platform analytics backend. Countly - Open source, mobile & web analytics, crash reports and push notifications platform for iOS & Android. Abbi - A Simple SDK for developers to manage and maximise conversions of all in-app promotions. devtodev - Comprehensive analytics service that improves your project and saves time for product development. Bugsnag - Error tracking with a free tier. Error reports include data on device, release, user, and allows arbitrary data. Inapptics - Helps analyze and visualize user behavior in mobile apps. Provides visual user journeys, heatmaps and crash replays. Matomo - The MatomoTracker is an iOS, tvOS and macOS SDK for sending app analytics to a Matomo server. Sentry - Sentry provides self-hosted and cloud-based error monitoring that helps all software teams discover, triage, and prioritize errors in real-time. App Routing Elegant URL routing, navigation frameworks, deep links and more WAAppRouting - iOS routing done right. Handles both URL recognition and controller displaying with parsed parameters. All in one line, controller stack preserved automatically! DeepLinkKit - A splendid route-matching, block-based way to handle your deep links. IntentKit - An easier way to handle third-party URL schemes in iOS apps. JLRoutes - URL routing library for iOS with a simple block-based API. IKRouter - URLScheme router than supports auto creation of UIViewControllers for associated url parameters to allow creation of navigation stacks Appz - Easily launch and deeplink into external applications, falling back to web if not installed. URLNavigator - Elegant URL Routing for Swift Marshroute - Marshroute is an iOS Library for making your Routers simple but extremely powerful. SwiftRouter - A URL Router for iOS. Router - Simple Navigation for iOS. ApplicationCoordinator - Coordinator is an object that handles navigation flow and shares flows handling for the next coordinator after switching on the next chain. RxFlow - Navigation framework for iOS applications based on a Reactive Flow Coordinator pattern. Linker - Lightweight way to handle internal and external deeplinks for iOS. CoreNavigation - Navigate between view controllers with ease. DZURLRoute - Universal route engine for iOS app, it can handle URLScheme between applications and page route between UIViewController. Crossroad - Crossroad is an URL router focused on handling Custom URL Schemes. Using this, you can route multiple URL schemes and fetch arguments and parameters easily. ZIKRouter - An interface-oriented router for discovering modules and injecting dependencies with protocol in OC & Swift, iOS & macOS. Handles route in a type safe way. RouteComposer - Library that helps to handle view controllers composition, routing and deeplinking tasks. LiteRoute - Easy transition between VIPER modules, implemented on pure Swift. Composable Navigator - An open source library for building deep-linkable SwiftUI applications with composition, testing and ergonomics in mind Apple TV tvOS view controllers, wrappers, template managers and video players. Voucher - A simple library to make authenticating tvOS apps easy via their iOS counterparts. XCDYouTubeKit - YouTube video player for iOS, tvOS and macOS. TVMLKitchen - Swifty TVML template manager with or without client-server. BrowserTV - Turn your Apple TV into a dashboard displaying any webpage! Swift-GA-Tracker-for-Apple-tvOS - Google Analytics tracker for Apple tvOS provides an easy integration of Google Analytics measurement protocol for Apple TV. ParallaxView - iOS controls and extensions that add parallax effect to your application. TvOSTextViewer - Light and scrollable view controller for tvOS to present blocks of text FocusTvButton - Light wrapper of UIButton that allows extra customization for tvOS TvOSMoreButton - A basic tvOS button which truncates long text with '... More'. TvOSPinKeyboard - PIN keyboard for tvOS. TvOSScribble - Handwriting numbers recognizer for Siri Remote. TvOSCustomizableTableViewCell - Light wrapper of UITableViewCell that allows extra customization for tvOS. TvOSSlider - TvOSSlider is an implementation of UISlider for tvOS. Architecture Patterns Clean architecture, Viper, MVVM, Reactive... choose your weapon. SwiftyVIPER - Makes implementing VIPER architecture much easier and cleaner. CleanArchitectureRxSwift - Example of Clean Architecture of iOS app using RxSwift. Viperit - Viper Framework for iOS. Develop an app following VIPER architecture in an easy way. Written and tested in Swift. Reactant - Reactant is a reactive architecture for iOS. YARCH - More clean alternative to VIPER with unidirectional data flow (flux-like). iOS-Viper-Architecture - This repository contains a detailed sample app that implements VIPER architecture in iOS using libraries and frameworks like Alamofire, AlamofireImage, PKHUD, CoreData etc. Tempura - A holistic approach to iOS development, inspired by Redux and MVVM. VIPER Module Generator - A Clean VIPER Modules Generator with comments and predfined functions. MMVMi - A Validation Model for MVC and MVVM Design Patterns in iOS Applications. ios-architecture - A collection of iOS architectures - MVC, MVVM, MVVM+RxSwift, VIPER, RIBs and many others. Clean Architecture for SwiftUI + Combine - A demo project showcasing the production setup of the SwiftUI app with Clean Architecture. Spin - A universal implementation of a Feedback Loop system for RxSwift, ReactiveSwift and Combine ARKit Library and tools to help you build unparalleled augmented reality experiences ARKit-CoreLocation - Combines the high accuracy of AR with the scale of GPS data. Virtual Objects - Placing Virtual Objects in Augmented Reality. ARVideoKit - Record and capture ARKit videos, photos, Live Photos, and GIFs. ARKitEnvironmentMapper - A library that allows you to generate and update environment maps in real-time using the camera feed and ARKit's tracking capabilities. SmileToUnlock - This library uses ARKit Face Tracking in order to catch a user's smile. Placenote - A library that makes ARKit sessions persistent to a location using advanced computer vision. Poly - Unofficial Google Poly SDK search and display 3D models. ARKit Emperor - The Emperor give you the most practical ARKit samples ever. Authentication Oauth and Oauth2 libraries, social logins and captcha tools. Heimdallr.swift - Easy to use OAuth 2 library for iOS, written in Swift. OhMyAuth - Simple OAuth2 library with a support of multiple services. AuthenticationViewController - A simple to use, standard interface for authenticating to oauth 2.0 protected endpoints via SFSafariViewController. OAuth2 - OAuth2 framework for macOS and iOS, written in Swift. OAuthSwift - Swift based OAuth library for iOS SimpleAuth - Simple social authentication for iOS. AlamofireOauth2 - A swift implementation of OAuth2. SwiftyOAuth - A simple OAuth library for iOS with a built-in set of providers. Simplicity - A simple way to implement Facebook and Google login in your iOS and macOS apps. InstagramAuthViewController - A ViewController for Instagram authentication. InstagramSimpleOAuth - A quick and simple way to authenticate an Instagram user in your iPhone or iPad app. DropboxSimpleOAuth - A quick and simple way to authenticate a Dropbox user in your iPhone or iPad app. BoxSimpleOAuth - A quick and simple way to authenticate a Box user in your iPhone or iPad app. InstagramLogin - A simple way to authenticate Instagram accounts on iOS. ReCaptcha - (In)visible ReCaptcha for iOS. LinkedInSignIn - Simple view controller to login and retrieve access token from LinkedIn. Blockchain Tool for smart contract interactions. Bitcoin protocol implementations and Frameworks for interacting with cryptocurrencies. Web3.swift - Web3 library for interacting with the Ethereum blockchain. web3swift - Elegant Web3js functionality in Swift. Native ABI parsing and smart contract interactions. EthereumKit - EthereumKit is a free, open-source Swift framework for easily interacting with the Ethereum. BitcoinKit - Bitcoin protocol toolkit for Swift, BitcoinKit implements Bitcoin protocol in Swift. It is an implementation of the Bitcoin SPV protocol written (almost) entirely in swift. EtherWalletKit - Ethereum Wallet Toolkit for iOS - You can implement Ethereum wallet without a server and blockchain knowledge. CoinpaprikaAPI - Coinpaprika API client with free & frequently updated market data from the world of crypto: coin prices, volumes, market caps, ATHs, return rates and more. Bitcoin-Swift-Kit - Full Bitcoin library written on Swift. Complete SPV wallet implementation for Bitcoin, Bitcoin Cash and Dash blockchains. Bridging Sharing code between Objective-C and Swift, iOS and macOS, Javascript and Objective-C. RubyMotion - RubyMotion is a revolutionary toolchain that lets you quickly develop and test native iOS and macOS applications for iPhone, iPad and Mac, all using the Ruby language. JSPatch - JSPatch bridge Objective-C and Javascript using the Objective-C runtime. You can call any Objective-C class and method in JavaScript by just including a small engine. JSPatch is generally use for hotfix iOS App. WebViewJavascriptBridge - An iOS/macOS bridge for sending messages between Obj-C and JavaScript in UIWebViews/WebViews. MAIKit - A framework for sharing code between iOS and macOS. Xamarin - Xamarin is a free, cross-platform, open-source platform that lets you quickly develop and test native iOS, watchOS and macOS applications for iPhone, iPad, Watch and Mac, all using the C# language. Cache Thread safe, offline and high performance cache libs and frameworks. Awesome Cache - Delightful on-disk cache (written in Swift). mattress - iOS Offline Caching for Web Content. Carlos - A simple but flexible cache. HanekeSwift - A lightweight generic cache for iOS written in Swift with extra love for images. YYCache - High performance cache framework for iOS. Cache - Nothing but Cache. MGCacheManager - A delightful iOS Networking Cache Managing Class. SPTPersistentCache - Everyone tries to implement a cache at some point in their iOS apps lifecycle, and this is ours. By Spotify. Track - Track is a thread safe cache write by Swift. Composed of DiskCache and MemoryCache which support LRU. UITableView Cache - UITableView cell cache that cures scroll-lags on a cell instantiating. RocketData - A caching and consistency solution for immutable models. PINCache - Fast, non-deadlocking parallel object cache for iOS and macOS. Johnny - Melodic Caching for Swift. Disk - Delightful framework for iOS to easily persist structs, images, and data. Cachyr - A small key-value data cache for iOS, macOS and tvOS, written in Swift. Cache - Swift caching library. MemoryCache - MemoryCache is type-safe memory cache. Charts Beautiful, Easy and Fully customized charts Charts - A powerful chart / graph framework, the iOS equivalent to MPAndroidChart. PNChart - A simple and beautiful chart lib used in Piner and CoinsMan for iOS. XJYChart - A Beautiful chart for iOS. Support animation, click, slide, area highlight. BEMSimpleLineGraph - Elegant Line Graphs for iOS (charting library). JBChartView - iOS-based charting library for both line and bar graphs. XYPieChart - A simple and animated Pie Chart for your iOS app. TEAChart - Simple and intuitive iOS chart library. Contribution graph, clock chart, and bar chart. EChart - iOS/iPhone/iPad Chart, Graph. Event handling and animation supported. FSLineChart - A line chart library for iOS. chartee - A charting library for mobile platforms. ANDLineChartView - ANDLineChartView is easy to use view-based class for displaying animated line chart. TWRCharts - An iOS wrapper for ChartJS. Easily build animated charts by leveraging the power of native Obj-C code. SwiftCharts - Easy to use and highly customizable charts library for iOS. FlowerChart - Flower-shaped chart with custom appearance animation, fully vector. Scrollable-GraphView - An adaptive scrollable graph view for iOS to visualise simple discrete datasets. Written in Swift. Dr-Charts - Dr-Charts is a highly customisable, easy to use and interactive chart / graph framework in Objective-C. Graphs - Light weight charts view generator for iOS. FSInteractiveMap - A charting library to visualize and interact with a vector map on iOS. It's like Geochart but for iOS. JYRadarChart - An iOS open source Radar Chart implementation. TKRadarChart - A customizable radar chart in Swift. MagicPie - Awesome layer based pie chart. Fantastically fast and fully customizable. Amazing animations available with MagicPie. PieCharts - Easy to use and highly customizable pie charts library for iOS. CSPieChart - iOS PieChart Opensource. This is very easy to use and customizable. DDSpiderChart - Easy to use and customizable Spider (Radar) Chart library for iOS written in Swift. core-plot - a 2D plotting lib which is highly customizable and capable of drawing many types of plots. ChartProgressBar - Draw a chart with progress bar style. SMDiagramViewSwift - Meet cute and very flexibility library for iOS application for different data view in one circle diagram. Swift LineChart - Line Chart library for iOS written in Swift. SwiftChart - Line and area chart library for iOS. EatFit - Eat fit is a component for attractive data representation inspired by Google Fit. CoreCharts - CoreCharts is a simple powerful yet Charts library for apple products. Code Quality Quality always matters. Code checkers, memory vigilants, syntastic sugars and more. Bootstrap - iOS project bootstrap aimed at high quality coding. KZAsserts - Set of custom assertions that automatically generate NSError's, allow for both Assertions in Debug and Error handling in Release builds, with beautiful DSL. PSPDFUIKitMainThreadGuard - Simple snippet generating assertions when UIKit is used on background threads. ocstyle - Objective-C style checker. spacecommander - Commit fully-formatted Objective-C code as a team without even trying. DWURecyclingAlert - Optimizing UITableViewCell For Fast Scrolling. Tailor - Cross-platform static analyzer for Swift that helps you to write cleaner code and avoid bugs. SwiftCop - SwiftCop is a validation library fully written in Swift and inspired by the clarity of Ruby On Rails Active Record validations. Trackable - Trackable is a simple analytics integration helper library. Its especially designed for easy and comfortable integration with existing projects. MLeaksFinder - Find memory leaks in your iOS app at develop time. HeapInspector-for-iOS - Find memory issues & leaks in your iOS app without instruments. FBMemoryProfiler - iOS tool that helps with profiling iOS Memory usage. FBRetainCycleDetector - iOS library to help detecting retain cycles in runtime. Buglife - Awesome bug reporting for iOS apps. Warnings-xcconfig - An xcconfig (Xcode configuration) file for easily turning on a boatload of warnings in your project or its targets. Aardvark - Aardvark is a library that makes it dead simple to create actionable bug reports. Stats - In-app memory usage monitoring. GlueKit - A type-safe observer framework for Swift. SwiftFormat - A code library and command-line formatting tool for reformatting Swift code. PSTModernizer - Makes it easier to support older versions of iOS by fixing things and adding missing methods. Bugsee - In-app bug and crash reporting with video, logs, network traffic and traces. Fallback - Syntactic sugar for nested do-try-catch. ODUIThreadGuard - A guard to help you check if you make UI changes not in main thread. IBAnalyzer - Find common xib and storyboard-related problems without running your app or writing unit tests. DecouplingKit - decoupling between modules in your iOS Project. Clue - Flexible bug report framework for iOS with screencast, networking, interactions and view structure. WeakableSelf - A Swift micro-framework to encapsulate [weak self] and guard statements within closures. Linter Static code analyzers to enforce style and conventions. OCLint - Static code analysis tool for improving quality and reducing defects. Taylor - Measure Swift code metrics and get reports in Xcode, Jenkins and other CI platforms. Swiftlint - A tool to enforce Swift style and conventions. IBLinter - A linter tool for Interface Builder. SwiftLinter - Share lint rules between projects and lint changed files with SwiftLint. AnyLint - Lint anything by combining the power of Swift & regular expressions. Color Hex color extensions, theming, color pickers and other awesome color tools. DynamicColor - Yet another extension to manipulate colors easily in Swift. SwiftHEXColors - HEX color handling as an extension for UIColor. Colours - A beautiful set of predefined colors and a set of color methods to make your iOS/macOS development life easier. UIColor-Hex-Swift - Convenience method for creating autoreleased color using RGBA hex string. Hue - Hue is the all-in-one coloring utility that you'll ever need. FlatUIColors - Flat UI color palette helpers written in Swift. RandomColorSwift - An attractive color generator for Swift. Ported from randomColor.js. PFColorHash - Generate color based on the given string. BCColor - A lightweight but powerful color kit (Swift). DKNightVersion - Manage Colors, Integrate Night/Multiple Themes. PrettyColors - PrettyColors is a Swift library for styling and coloring text in the Terminal. The library outputs ANSI escape codes and conforms to ECMA Standard 48. TFTColor - Simple Extension for RGB and CMKY Hex Strings and Hex Values (ObjC & Swift). CostumeKit - Base types for theming an app. CSS3ColorsSwift - A UIColor extension with CSS3 Colors name. ChromaColorPicker - An intuitive iOS color picker built in Swift. Lorikeet - A lightweight Swift framework for aesthetically pleasing color-scheme generation and CIE color-difference calculation. Gestalt - An unintrusive & light-weight iOS app-theming library with support for animated theme switching. SheetyColors - An action sheet styled color picker for iOS. Command Line Smart, beautiful and elegant tools to help you create command line applications. Swiftline - Swiftline is a set of tools to help you create command line applications. Commander - Compose beautiful command line interfaces in Swift. ColorizeSwift - Terminal string styling for Swift. Guaka - The smartest and most beautiful (POSIX compliant) Command line framework for Swift. Marathon - Marathon makes it easy to write, run and manage your Swift scripts. CommandCougar - An elegant pure Swift library for building command line applications. Crayon - Terminal string styling with expressive api and 256/TrueColor support. SwiftShell - A Swift framework for shell scripting and running shell commands. SourceDocs - Command Line Tool that generates Markdown documentation from inline source code comments. ModuleInterface - Command Line Tool that generates the Module's Interface from a Swift project. Concurrency Job schedulers, Coroutines, Asynchronous and Type safe threads libs and frameworks written in Swift Venice - CSP (Coroutines, Channels, Select) for Swift. Concurrent - Functional Concurrency Primitives. Flow - Operation Oriented Programming in Swift. Brisk - A Swift DSL that allows concise and effective concurrency manipulation. Aojet - An actor model library for swift. Overdrive - Fast async task based Swift framework with focus on type safety, concurrency and multi threading. AsyncNinja - A complete set of concurrency and reactive programming primitives. Kommander - Kommander is a Swift library to manage the task execution in different threads. Through the definition a simple but powerful concept, Kommand. Threadly - Type-safe thread-local storage in Swift. Flow-iOS - Make your logic flow and data flow clean and human readable. Queuer - A queue manager, built on top of OperationQueue and Dispatch (aka GCD). SwiftQueue - Job Scheduler with Concurrent run, failure/retry, persistence, repeat, delay and more. GroupWork - Easy concurrent, asynchronous tasks in Swift. StickyLocking - A general purpose embedded hierarchical lock manager used to build highly concurrent applications of all types. SwiftCoroutine - Swift coroutines library for iOS and macOS. Core Data Core data Frameworks, wrappers, generators and boilerplates. Ensembles - A synchronization framework for Core Data. Mogenerator - Automatic Core Data code generation. MagicalRecord - Super Awesome Easy Fetching for Core Data. CoreStore - Powerful Core Data framework for Incremental Migrations, Fetching, Observering, etc. Core Data Query Interface A type-safe, fluent query framework for Core Data. Graph - An elegant data-driven framework for CoreData in Swift. CoreDataDandy - A feature-light wrapper around Core Data that simplifies common database operations. Sync - Modern Swift JSON synchronization to Core Data. AlecrimCoreData - A powerful and simple Core Data wrapper framework written in Swift. AERecord - Super awesome Core Data wrapper in Swift. CoreDataStack - The Big Nerd Ranch Core Data Stack. JSQCoreDataKit - A swifter Core Data stack. Skopelos - A minimalistic, thread safe, non-boilerplate and super easy to use version of Active Record on Core Data. Simply all you need for doing Core Data. Cadmium - A complete swift framework that wraps CoreData and helps facilitate best practices. DataKernel - Simple CoreData wrapper to ease operations. DATAStack - 100% Swift Simple Boilerplate Free Core Data Stack. NSPersistentContainer. JustPersist - JustPersist is the easiest and safest way to do persistence on iOS with Core Data support out of the box. PrediKit - An NSPredicate DSL for iOS, macOS, tvOS, & watchOS. Inspired by SnapKit and lovingly written in Swift. PredicateFlow - Write amazing, strong-typed and easy-to-read NSPredicate, allowing you to write flowable NSPredicate, without guessing attribution names, predicate operation or writing wrong arguments type. CloudCore - Robust CloudKit synchronization: offline editing, relationships, shared and public databases, field-level deltas, and more. Database Wrappers, clients, Parse alternatives and safe tools to deal with ephemeral and persistent data. Realm - The alternative to CoreData and SQLite: Simple, modern and fast. YapDatabase - YapDatabase is an extensible database for iOS & Mac. Couchbase Mobile - Couchbase document store for mobile with cloud sync. FMDB - A Cocoa / Objective-C wrapper around SQLite. FCModel - An alternative to Core Data for people who like having direct SQL access. Zephyr - Effortlessly synchronize NSUserDefaults over iCloud. Prephirences - Prephirences is a Swift library that provides useful protocols and convenience methods to manage application preferences, configurations and app-state. Storez - Safe, statically-typed, store-agnostic key-value storage (with namespace support). SwiftyUserDefaults - Statically-typed NSUserDefaults. SugarRecord - Data persistence management library. SQLite.swift - A type-safe, Swift-language layer over SQLite3. GRDB.swift - A versatile SQLite toolkit for Swift, with WAL mode support. Fluent - Simple ActiveRecord implementation for working with your database in Swift. ParseAlternatives - A collaborative list of Parse alternative backend service providers. TypedDefaults - TypedDefaults is a utility library to type-safely use NSUserDefaults. realm-cocoa-converter - A library that provides the ability to import/export Realm files from a variety of data container formats. YapDatabaseExtensions - YapDatabase extensions for use with Swift. RealmGeoQueries - RealmGeoQueries simplifies spatial queries with Realm Cocoa. In the absence of and official functions, this library provide the possibility to do proximity search. SwiftMongoDB - A MongoDB interface for Swift. ObjectiveRocks - An Objective-C wrapper of Facebook's RocksDB - A Persistent Key-Value Store for Flash and RAM Storage. OHMySQL - An Objective-C wrapper of MySQL C API. SwiftStore - Key-Value store for Swift backed by LevelDB. OneStore - A single value proxy for NSUserDefaults, with clean API. MongoDB - A Swift wrapper around the mongo-c client library, enabling access to MongoDB servers. MySQL - A Swift wrapper around the MySQL client library, enabling access to MySQL servers. Redis - A Swift wrapper around the Redis client library, enabling access to Redis. PostgreSQL - A Swift wrapper around the libpq client library, enabling access to PostgreSQL servers. FileMaker - A Swift wrapper around the FileMaker XML Web publishing interface, enabling access to FileMaker servers. Nora - Nora is a Firebase abstraction layer for working with FirebaseDatabase and FirebaseStorage. PersistentStorageSerializable - Swift library that makes easier to serialize the user's preferences (app's settings) with system User Defaults or Property List file on disk. WCDB - WCDB is an efficient, complete, easy-to-use mobile database framework for iOS, macOS. StorageKit - Your Data Storage Troubleshooter. UserDefaults - Simple, Strongly Typed UserDefaults for iOS, macOS and tvOS. Default - Modern interface to UserDefaults + Codable support. IceCream - Sync Realm Database with CloudKit. FirebaseHelper - Safe and easy wrappers for common Firebase Realtime Database functions. Shallows - Your lightweight persistence toolbox. StorageManager - Safe and easy way to use FileManager as Database. RealmWrapper - Safe and easy wrappers for RealmSwift. UserDefaultsStore - An easy and very light way to store and retrieve -reasonable amount- of Codable objects, in a couple lines of code. PropertyKit - Protocol-First, Type and Key-Safe Swift Property for iOS, macOS and tvOS. PersistenceKit - Store and retrieve Codable objects to various persistence layers, in a couple lines of code. ModelAssistant - Elegant library to manage the interactions between view and model in Swift. MMKV - An efficient, small mobile key-value storage framework developed by WeChat. Works on iOS, Android, macOS and Windows. Defaults - Swifty and modern UserDefaults. MongoKitten - A pure Swift MongoDB client implementation with support for embedded databases. SecureDefaults - A lightweight wrapper over UserDefaults/NSUserDefaults with an extra AES-256 encryption layer. Unrealm - Unrealm enables you to easily store Swift native Classes, Structs and Enums into Realm. QuickDB - Save and Retrieve any Codable in JUST ONE line of code + more easy usecases. ObjectBox - ObjectBox is a superfast, light-weight object persistence framework. Data Structures / Algorithms Diffs, keypaths, sorted lists and other amazing data structures wrappers and libraries. Changeset - Minimal edits from one collection to another. BTree - Fast ordered collections for Swift using in-memory B-trees. SwiftStructures - Examples of commonly used data structures and algorithms in Swift. diff - Simple diff library in pure Swift. Brick - A generic view model for both basic and complex scenarios. Algorithm - Algorithm is a collection of data structures that are empowered by a probability toolset. AnyObjectConvertible - Convert your own struct/enum to AnyObject easily. Dollar - A functional tool-belt for Swift Language similar to Lo-Dash or Underscore.js in Javascript https://www.dollarswift.org/. Result - Swift type modeling the success/failure of arbitrary operations. EKAlgorithms - Some well known CS algorithms & data structures in Objective-C. Monaka - Convert custom struct and fundamental values to NSData. Buffer - Swift -framework for efficient array diffs, collection observation and cell configuration. SwiftGraph - Graph data structure and utility functions in pure Swift. SwiftPriorityQueue - A priority queue with a classic binary heap implementation in pure Swift. Pencil - Write values to file and read it more easily. HeckelDiff - A fast Swift diffing library. Dekoter - NSCoding's counterpart for Swift structs. swift-algorithm-club - Algorithms and data structures in Swift, with explanations! Impeller - A Distributed Value Store in Swift. Dispatch - Multi-store Flux implementation in Swift. DeepDiff - Diff in Swift. Differ - Swift library to generate differences and patches between collections. Probably - A Swift probability and statistics library. RandMyMod - RandMyMod base on your own struct or class create one or a set of randomized instance. KeyPathKit - KeyPathKit provides a seamless syntax to manipulate data using typed keypaths. Differific - A fast and convenient diffing framework. OneWaySynchronizer - The simplest abstraction to synchronize local data with remote source. DifferenceKit - A fast and flexible O(n) difference algorithm framework for Swift collection. Date & Time Time and NSCalendar libraries. Also contains Sunrise and Sunset time generators, time pickers and NSTimer interfaces. Timepiece - Intuitive NSDate extensions in Swift. SwiftDate - The best way to manage Dates and Timezones in Swift. SwiftMoment - A time and calendar manipulation library. DateTools - Dates and times made easy in Objective-C. SwiftyTimer - Swifty API for NSTimer. DateHelper - Convenience extension for NSDate in Swift. iso-8601-date-formatter - A Cocoa NSFormatter subclass to convert dates to and from ISO-8601-formatted strings. Supports calendar, week, and ordinal formats. EmojiTimeFormatter - Format your dates/times as emojis. Kronos - Elegant NTP date library in Swift. TrueTime - Get the true current time impervious to device clock time changes. 10Clock - This Control is a beautiful time-of-day picker heavily inspired by the iOS 10 "Bedtime" timer. NSDate-TimeAgo - A "time ago", "time since", "relative date", or "fuzzy date" category for NSDate and iOS, Objective-C, Cocoa Touch, iPhone, iPad. AnyDate - Swifty Date & Time API inspired from Java 8 DateTime API. TimeZonePicker - A TimeZonePicker UIViewController similar to the iOS Settings app. Time - Type-safe time calculations in Swift, powered by generics. Chronology - Building a better date/time library. Solar - A Swift micro library for generating Sunrise and Sunset times. TimePicker - Configurable time picker component based on a pan gesture and its velocity. LFTimePicker - Custom Time Picker ViewController with Selection of start and end times in Swift. NVDate - Swift4 Date extension library. Schedule - A missing lightweight task scheduler for Swift with an incredibly human-friendly syntax. Debugging Debugging tools, crash reports, logs and console UI's. Xniffer - A swift network profiler built on top of URLSession. Netfox - A lightweight, one line setup, iOS / macOS network debugging library! PonyDebugger - Remote network and data debugging for your native iOS app using Chrome Developer Tools. DBDebugToolkit - Set of easy to use debugging tools for iOS developers & QA engineers. Flex - An in-app debugging and exploration tool for iOS. chisel - Collection of LLDB commands to assist debugging iOS apps. Alpha - Next generation debugging framework for iOS. AEConsole - Customizable Console UI overlay with debug log on top of your iOS App. GodEye - Automatically display Log,Crash,Network,ANR,Leak,CPU,RAM,FPS,NetFlow,Folder and etc with one line of code based on Swift. NetworkEye - a iOS network debug library, It can monitor HTTP requests within the App and displays information related to the request. Dotzu - iOS app debugger while using the app. Crash report, logs, network. Hyperion - In-app design review tool to inspect measurements, attributes, and animations. Httper-iOS - App for developers to test REST API. Droar - Droar is a modular, single-line installation debugging window. Wormholy - iOS network debugging, like a wizard. AppSpector - Remote iOS and Android debugging and data collection service. You can debug networking, logs, CoreData, SQLite, NSNotificationCenter and mock device's geo location. Woodpecker - View sandbox files, UserDefaults, network request from Mac. LayoutInspector - Debug app layouts directly on iOS device: inspect layers in 3D and debug each visible view attributes. MTHawkeye - Profiling / Debugging assist tools for iOS, include tools: UITimeProfiler, Memory Allocations, Living ObjC Objects Sniffer, Network Transaction Waterfall, etc. Playbook - A library for isolated developing UI components and automatically snapshots of them. DoraemonKit - A full-featured iOS App development assistant30+ tools included. You deserve it. Atlantis - A little and powerful iOS framework for intercepting HTTP/HTTPS Traffic from your iOS app. No more messing around with proxy and certificate config. Inspect Traffic Log with Proxyman app. EventBus Promises and Futures libraries to help you write better async code in Swift. SwiftEventBus - A publish/subscribe event bus optimized for iOS. PromiseKit - Promises for iOS and macOS. Bolts - Bolts is a collection of low-level libraries designed to make developing mobile apps easier, including tasks (promises) and app links (deep links). SwiftTask - Promise + progress + pause + cancel + retry for Swift. When - A lightweight implementation of Promises in Swift. then - Elegant Async code in Swift. Bolts-Swift - Bolts is a collection of low-level libraries designed to make developing mobile apps easier. RWPromiseKit - A light-weighted Promise library for Objective-C. FutureLib - FutureLib is a pure Swift 2 library implementing Futures & Promises inspired by Scala. SwiftNotificationCenter - A Protocol-Oriented NotificationCenter which is type safe, thread safe and with memory safety. FutureKit - A Swift based Future/Promises Library for iOS and macOS. signals-ios - Typeful eventing. BrightFutures - Write great asynchronous code in Swift using futures and promises. NoticeObserveKit - NoticeObserveKit is type-safe NotificationCenter wrapper that associates notice type with info type. Hydra - Promises & Await - Write better async code in Swift. Promis - The easiest Future and Promises framework in Swift. No magic. No boilerplate. Bluebird.swift - Promise/A+, Bluebird inspired, implementation in Swift 4. Promise - A Promise library for Swift, based partially on Javascript's A+ spec. promises - Google provides a synchronization construct for Objective-C and Swift to facilitate writing asynchronous code. Continuum - NotificationCenter based Lightweight UI / AnyObject binder. Futures - Lightweight promises for iOS, macOS, tvOS, watchOS, and server-side Swift. EasyFutures - Swift Futures & Promises. Easy to use. Highly combinable. TopicEventBus - Publishsubscribe design pattern implementation framework, with ability to publish events by topic. (NotificationCenter extended alternative). Files File management, file browser, zip handling and file observers. FileKit - Simple and expressive file management in Swift. Zip - Swift framework for zipping and unzipping files. FileBrowser - Powerful Swift file browser for iOS. Ares - Zero-setup P2P file transfer between Macs and iOS devices. FileProvider - FileManager replacement for Local, iCloud and Remote (WebDAV/FTP/Dropbox/OneDrive/SMB2) files on iOS/tvOS and macOS. KZFileWatchers - A micro-framework for observing file changes, both local and remote. Helpful in building developer tools. ZipArchive - ZipArchive is a simple utility class for zipping and unzipping files on iOS and Mac. FileExplorer - Powerful file browser for iOS that allows its users to choose and remove files and/or directories. ZIPFoundation - Effortless ZIP Handling in Swift. AppFolder - AppFolder is a lightweight framework that lets you design a friendly, strongly-typed representation of a directories inside your app's container. ZipZap - zip file I/O library for iOS, macOS and tvOS. AMSMB2 - Swift framework to connect SMB 2/3 shares for iOS. Functional Programming Collection of Swift functional programming tools. Forbind - Functional chaining and promises in Swift. Funky - Functional programming tools and experiments in Swift. LlamaKit - Collection of must-have functional Swift tools. Oriole - A functional utility belt implemented as Swift protocol extensions. Prelude - Swift framework of simple functional programming tools. Swiftx - Functional data types and functions for any project. Swiftz - Functional programming in Swift. OptionalExtensions - Swift framework with extensions for the Optional Type. Argo - Functional JSON parsing library for Swift. Runes - Infix operators for monadic functions in Swift. Bow - Typed Functional Programming companion library for Swift. Games Sage - A cross-platform chess library for Swift. ShogibanKit - ShogibanKit is a framework for implementing complex Japanese Chess (Shogii) in Swift. No UI, nor AI. SKTiled - Swift framework for working with Tiled assets in SpriteKit. CollectionNode - A swift framework for a collectionView in SpriteKit. AssetImportKit - Swifty cross platform library (macOS, iOS) that converts Assimp supported models to SceneKit scenes. glide engine - SpriteKit and GameplayKit based engine for making 2d games, with practical examples and tutorials. SwiftFortuneWheel - A cross-platform framework for games like a Wheel of Fortune. GCD Grand Central Dispatch syntax sugars, tools and timers. GCDKit - Grand Central Dispatch simplified with Swift. Async - Syntactic sugar in Swift for asynchronous dispatches in Grand Central Dispatch. SwiftSafe - Thread synchronization made easy. YYDispatchQueuePool - iOS utility class to manage global dispatch queue. AlecrimAsyncKit - Bringing async and await to Swift world with some flavouring. GrandSugarDispatch - Syntactic sugar for Grand Central Dispatch (GCD). Threader - Pretty GCD calls and easier code execution. Dispatch - Just a tiny library to make using GCD easier and intuitive. GCDTimer - Well tested Grand Central Dispatch (GCD) Timer in Swift. Chronos-Swift - Grand Central Dispatch Utilities. Me - A super slim solution to the nested asynchronous computations. SwiftyTask - An extreme queuing system with high performance for managing all task in app with closure. Gesture Libraries and tools to handle gestures. Tactile - A better way to handle gestures on iOS. SwiftyGestureRecognition - Aids with prototyping UIGestureRecognizers in Xcode Playgrounds. DBPathRecognizer - Gesture recognizer tool. Sensitive - Special way to work with gestures in iOS. SplitViewDragAndDrop - Easily add drag and drop to pass data between your apps in split view mode. FDFullscreenPopGesture - An UINavigationController's category to enable fullscreen pop gesture in an iOS7+ system style with AOP. Graphics CoreGraphics, CoreAnimation, SVG, CGContext libraries, helpers and tools. Graphicz - Light-weight, operator-overloading-free complements to CoreGraphics! PKCoreTechniques - The code for my CoreGraphics+CoreAnimation talk, held during the 2012 iOS Game Design Seminar at the Technical University Munich. MPWDrawingContext - An Objective-C wrapper for CoreGraphics CGContext. DePict - A simple, declarative, functional drawing framework, in Swift! SwiftSVG - A single pass SVG parser with multiple interface options (String, NS/UIBezierPath, CAShapeLayer, and NS/UIView). InkKit - Write-Once, Draw-Everywhere for iOS and macOS. YYAsyncLayer - iOS utility classes for asynchronous rendering and display. NXDrawKit - NXDrawKit is a simple and easy but useful drawing kit for iPhone. jot - An iOS framework for easily adding drawings and text to images. SVGKit - Display and interact with SVG Images on iOS / macOS, using native rendering (CoreAnimation) (currently only supported for iOS - macOS code needs updating). Snowflake - SVG in Swift. HxSTLParser - Basic STL loader for SceneKit. ProcessingKit - Visual designing library for iOS & OSX. EZYGradientView - Create gradients and blur gradients without a single line of code. AEConicalGradient - Conical (angular) gradient layer written in Swift. MKGradientView - Core Graphics based gradient view capable of producing Linear (Axial), Radial (Circular), Conical (Angular), Bilinear (Four Point) gradients, written in Swift. EPShapes - Design shapes in Interface Builder. Macaw - Powerful and easy-to-use vector graphics library with SVG support written in Swift. BlockiesSwift - Unique blocky identicons/profile picture generator. Rough - lets you draw in a sketchy, hand-drawn-like, style. GraphLayout - UI controls for graph visualization. It is powered by Graphviz. Drawsana - iOS framework for building raster drawing and image markup views. AnimatedGradientView - A simple framework to add animated gradients to your iOS app. Hardware Bluetooth Libraries to deal with nearby devices, BLE tools and MultipeerConnectivity wrappers. Discovery - A very simple library to discover and retrieve data from nearby devices (even if the peer app works at background). LGBluetooth - Simple, block-based, lightweight library over CoreBluetooth. Will clean up your Core Bluetooth related code. PeerKit An open-source Swift framework for building event-driven, zero-config Multipeer Connectivity apps. BluetoothKit - Easily communicate between iOS/macOS devices using BLE. Bluetonium - Bluetooth mapping in Swift. BlueCap - iOS Bluetooth LE framework. Apple Family - Quickly connect Apple devices together with Bluetooth, wifi, and USB. Bleu - BLE (Bluetooth LE) for U. Bluejay - A simple Swift framework for building reliable Bluetooth LE apps. BabyBluetooth - The easiest way to use Bluetooth (BLE) in iOS/MacOS. ExtendaBLE - Simple Blocks-Based BLE Client for iOS/tvOS/watchOS/OSX/Android. Quickly configuration for centrals/peripherals, perform packet based read/write operations, and callbacks for characteristic updates. PeerConnectivity - Functional wrapper for Apple's MultipeerConnectivity framework. AZPeerToPeerConnection - AZPeerToPeerConnectivity is a wrapper on top of Apple iOS Multipeer Connectivity framework. It provides an easier way to create and manage sessions. Easy to integrate. MultiPeer - Multipeer is a wrapper for Apple's MultipeerConnectivity framework for offline data transmission between Apple devices. It makes easy to automatically connect to multiple nearby devices and share information using either bluetooth or wifi. BerkananSDK - Mesh messaging SDK with the goal to create a decentralized mesh network for the people, powered by their device's Bluetooth antenna. Camera Mocks, ImagePickers, and multiple options of customizable camera implementation TGCameraViewController - Custom camera with AVFoundation. Beautiful, light and easy to integrate with iOS projects. PBJVision - iOS camera engine, features touch-to-record video, slow motion video, and photo capture. Cool-iOS-Camera - A fully customisable and modern camera implementation for iOS made with AVFoundation. SCRecorder - Camera engine with Vine-like tap to record, animatable filters, slow motion, segments editing. ALCameraViewController - A camera view controller with custom image picker and image cropping. Written in Swift. CameraManager - Simple Swift class to provide all the configurations you need to create custom camera view in your app. RSBarcodes_Swift - 1D and 2D barcodes reader and generators for iOS 8 with delightful controls. Now Swift. LLSimpleCamera - A simple, customizable camera control - video recorder for iOS. Fusuma - Instagram-like photo browser and a camera feature with a few line of code in Swift. BarcodeScanner - Simple and beautiful barcode scanner. HorizonSDK-iOS - State of the art real-time video recording / photo shooting iOS library. FastttCamera - Fasttt and easy camera framework for iOS with customizable filters. DKCamera - A lightweight & simple camera framework for iOS. Written in Swift. NextLevel - Next Level is a media capture camera library for iOS. CameraEngine - Camera engine for iOS, written in Swift, above AVFoundation. SwiftyCam - A Snapchat Inspired iOS Camera Framework written in Swift. CameraBackground - Show camera layer as a background to any UIView. Lumina - Full service camera that takes photos, videos, streams frames, detects metadata, and streams CoreML predictions. RAImagePicker - RAImagePicker is a protocol-oriented framework that provides custom features from the built-in Image Picker Edit. FDTake - Easily take a photo or video or choose from library. YPImagePicker - Instagram-like image picker & filters for iOS. MockImagePicker - Mock UIImagePickerController for testing camera based UI in simulator. iOS-Depth-Sampler - A collection of code examples for Depth APIs. TakeASelfie - An iOS framework that uses the front camera, detects your face and takes a selfie. HybridCamera - Video and photo camera for iOS, similar to the SnapChat camera. CameraKit-iOS - Massively increase camera performance and ease of use in your next iOS project. Force Touch Quick actions and peek and pop interactions QuickActions - Swift wrapper for iOS Home Screen Quick Actions (App Icon Shortcuts). JustPeek - JustPeek is an iOS Library that adds support for Force Touch-like Peek and Pop interactions on devices that do not natively support this kind of interaction. PeekView - PeekView supports peek, pop and preview actions for iOS devices without 3D Touch capibility. iBeacon Device detect libraries and iBeacon helpers Proxitee - Allows developers to create proximity aware applications utilizing iBeacons & geo fences. OWUProximityManager - iBeacons + CoreBluetooth. Vicinity - Vicinity replicates iBeacons (by analyzing RSSI) and supports broadcasting and detecting low-energy Bluetooth devices in the background. BeaconEmitter - Turn your Mac as an iBeacon. MOCA Proximity - Paid proximity marketing platform that lets you add amazing proximity experiences to your app. JMCBeaconManager - An iBeacon Manager class that is responsible for detecting beacons nearby. Location Location monitoring, detect motion and geofencing libraries IngeoSDK - Always-On Location monitoring framework for iOS. LocationManager - Provides a block-based asynchronous API to request the current location, either once or continuously. SwiftLocation - Location & Beacon Monitoring in Swift. SOMotionDetector - Simple library to detect motion. Based on location updates and acceleration. LocationPicker - A ready for use and fully customizable location picker for your app. BBLocationManager - A Location Manager for easily implementing location services & geofencing in iOS. set-simulator-location - CLI for setting location in the iOS simulator. NominatimKit - A Swift wrapper for (reverse) geocoding of OpenStreetMap data. Other Hardware MotionKit - Get the data from Accelerometer, Gyroscope and Magnetometer in only Two or a few lines of code. CoreMotion now made insanely simple. DarkLightning - Simply the fastest way to transmit data between iOS/tvOS and macOS. Deviice - Simply library to detect the device on which the app is running (and some properties). DeviceKit - DeviceKit is a value-type replacement of UIDevice. Luminous - Luminous is a big framework which can give you a lot of information (more than 50) about the current system. Device - Light weight tool for detecting the current device and screen size written in swift. WatchShaker - WatchShaker is a watchOS helper to get your shake movement written in swift. WatchCon - WatchCon is a tool which enables creating easy connectivity between iOS and WatchOS. TapticEngine - TapticEngine generates iOS Device vibrations. UIDeviceComplete - UIDevice extensions that fill in the missing pieces. NFCNDEFParse - NFC Forum Well Known Type Data Parser for iOS11 and Core NFC. Device.swift - Super-lightweight library to detect used device. SDVersion - Lightweight Cocoa library for detecting the running device's model and screen size. Haptico - Easy to use haptic feedback generator with pattern-play support. NFCPassportReader - Swift library to read an NFC enabled passport. Supports BAC, Secure Messaging, and both active and passive authentication. Requires iOS 13 or above. Layout Auto Layout, UI frameworks and a gorgeous list of tools to simplify layout constructions Masonry - Harness the power of AutoLayout NSLayoutConstraints with a simplified, chainable and expressive syntax. FLKAutoLayout - UIView category which makes it easy to create layout constraints in code. Faade - Programmatic view layout for the rest of us - an autolayout alternative. PureLayout - The ultimate API for iOS & macOS Auto Layout impressively simple, immensely powerful. Objective-C and Swift compatible. SnapKit - A Swift Autolayout DSL for iOS & macOS. Cartography - A declarative Auto Layout DSL for Swift. AutoLayoutPlus - A bit of steroids for AutoLayout. Neon - A powerful Swift programmatic UI layout framework. MisterFusion - A Swift DSL for AutoLayout. It is the extremely clear, but concise syntax, in addition, can be used in both Swift and Objective-C. SwiftBox - Flexbox in Swift, using Facebook's css-layout. ManualLayout - Easy to use and flexible library for manually laying out views and layers for iOS and tvOS. Supports AsyncDisplayKit. Stevia - Elegant view layout for iOS. Manuscript - AutoLayoutKit in pure Swift. FDTemplateLayoutCell - Template auto layout cell for automatically UITableViewCell height calculating. SwiftAutoLayout - Tiny Swift DSL for Autolayout. FormationLayout - Work with auto layout and size classes easily. SwiftyLayout - Lightweight declarative auto-layout framework for Swift. Swiftstraints - Auto Layout In Swift Made Easy. SwiftBond - Bond is a Swift binding framework that takes binding concepts to a whole new level. It's simple, powerful, type-safe and multi-paradigm. Restraint - Minimal Auto Layout in Swift. EasyPeasy - Auto Layout made easy. Auto Layout Magic - Build 1 scene, let Auto Layout Magic generate the constraints for you! Scenes look great across all devices! Anchorman - An autolayout library for the damn fine citizens of San Diego. LayoutKit - LayoutKit is a fast view layout library for iOS. Relayout - Swift microframework for declaring Auto Layout constraints functionally. Anchorage - A collection of operators and utilities that simplify iOS layout code. Compose - Compose is a library that helps you compose complex and dynamic views. BrickKit - With BrickKit, you can create complex and responsive layouts in a simple way. It's easy to use and easy to extend. Create your own reusable bricks and behaviors. Framezilla - Elegant library which wraps working with frames with a nice chaining syntax. TinyConstraints - The syntactic sugar that makes Auto Layout sweeter for human use. MyLinearLayout - MyLayout is a powerful iOS UI framework implemented by Objective-C. It integrates the functions with Android Layout,iOS AutoLayout,SizeClass, HTML CSS float and flexbox and bootstrap. SugarAnchor - Same native NSLayoutAnchor & NSLayoutConstraints; but with more natural and easy to read syntactic sugar. Typesafe, concise & readable. EasyAnchor - Declarative, extensible, powerful Auto Layout. PinLayout - Fast Swift Views layouting without auto layout. No magic, pure code, full control and blazing fast. Concise syntax, intuitive, readable & chainable. SnapLayout - Concise Auto Layout API to chain programmatic constraints while easily updating existing constraints. Cupcake - An easy way to create and layout UI components for iOS. MiniLayout - Minimal AutoLayout convenience layer. Program constraints succinctly. Bamboo - Bamboo makes Auto Layout (and manual layout) elegant and concise. FlexLayout - FlexLayout gently wraps the highly optimized facebook/yoga flexbox implementation in a concise, intuitive & chainable syntax. Layout - A declarative UI framework for iOS. CGLayout - Powerful autolayout framework based on constraints, that can manage UIView(NSView), CALayer and not rendered views. Not Apple Autolayout wrapper. YogaKit - Powerful layout engine which implements Flexbox. FlightLayout - Balanced medium between manual layout and auto-layout. Great for calculating frames for complex animations. QLayout - AutoLayout Utility for iOS. Layoutless - Minimalistic declarative layout and styling framework built on top of Auto Layout. Yalta - An intuitive and powerful Auto Layout library. SuperLayout - Simplify Auto Layout with super syntactic sugar. QuickLayout - QuickLayout offers a simple way, to easily manage Auto Layout in code. EEStackLayout - A structured vertical stack layout. RKAutoLayout - Simple wrapper over AutoLayout. Grid - The most powerful Grid container missed in SwiftUI. Localization Tools to manage strings files, translate and enable localization in your apps. Hodor - Simple solution to localize your iOS App. Swifternalization - Localize iOS apps in a smarter way using JSON files. Swift framework. Rubustrings - Check the format and consistency of Localizable.strings files. BartyCrouch - Incrementally update/translate your Strings files from Code and Storyboards/XIBs. LocalizationKit - Localization management in realtime from a web portal. Easily manage your texts and translations without redeploy and resubmission. Localize-Swift - Swift 2.0 friendly localization and i18n with in-app language switching. LocalizedView - Setting up application specific localized string within Xib file. transai - command line tool help you manage localization string files. Strsync - Automatically translate and synchronize .strings files from base language. IBLocalizable - Localize your views directly in Interface Builder with IBLocalizable. nslocalizer - A tool for finding missing and unused NSLocalizedStrings. L10n-swift - Localization of an application with ability to change language "on the fly" and support for plural forms in any language. Localize - Easy tool to localize apps using JSON or Strings and of course IBDesignables with extensions for UI components. CrowdinSDK - Crowdin iOS SDK delivers all new translations from Crowdin project to the application immediately. attranslate - Semi-automatically translate or synchronize .strings files or crossplatform-files from different languages. Logging Debugging lives here. Logging tools, frameworks, integrations and more. CleanroomLogger - A configurable and extensible Swift-based logging API that is simple, lightweight and performant. CocoaLumberjack - A fast & simple, yet powerful & flexible logging framework for Mac and iOS. NSLogger - a high performance logging utility which displays traces emitted by client applications running on macOS, iOS and Android. QorumLogs Swift Logging Utility for Xcode & Google Docs. Log - A logging tool with built-in themes, formatters, and a nice API to define your owns. Rainbow - Delightful console output for Swift developers. SwiftyBeaver - Convenient logging during development and release. SwiftyTextTable - A lightweight tool for generating text tables. Watchdog - Class for logging excessive blocking on the main thread. XCGLogger - A debug log framework for use in Swift projects. Allows you to log details to the console (and optionally a file), just like you would have with NSLog or println, but with additional information, such as the date, function name, filename and line number. puree - A log collector for iOS. Colors - A pure Swift library for using ANSI codes. Basically makes command-line coloring and styling very easy! Loggerithm - A lightweight Swift logger, uses print in development and NSLog in production. Support colourful and formatted output. AELog - Simple, lightweight and flexible debug logging framework written in Swift. ReflectedStringConvertible - A protocol that allows any class to be printed as if it were a struct. Evergreen - Most natural Swift logging. SwiftTrace - Trace Swift and Objective-C method invocations. Willow - Willow is a powerful, yet lightweight logging library written in Swift. Bugfender - Cloud storage for your app logs. Track user behaviour to find problems in your mobile apps. LxDBAnything - Automate box any value! Print log without any format control symbol! Change debug habit thoroughly! XLTestLog - Styling and coloring your XCTest logs on Xcode Console. XLFacility - Elegant and extensive logging facility for macOS & iOS (includes database, Telnet and HTTP servers). Atlantis - A powerful input-agnostic swift logging framework made to speed up development with maximum readability. StoryTeller - Taking a completely different approach to logging, Story Teller replacing fixed logging levels in It then uses dynamic expressions to control the logging so you only see what is important. LumberMill - Stupidly simple logging. TinyConsole - A tiny log console to display information while using your iOS app. Lighty - Easy to use and lightweight logger for iOS, macOS, tvOS, watchOS and Linux. JustLog - Console, file and remote Logstash logging via TCP socket. Twitter Logging Service - Twitter Logging Service is a robust and performant logging framework for iOS clients. Reqres - Network request and response body logger with Alamofire support. TraceLog - Dead Simple: logging the way it's meant to be! Runs on ios, osx, and Linux. OkLog - A network logger for iOS and macOS projects. Spy - Lightweight, flexible, multiplatform (iOS, macOS, tvOS, watchOS, Linux) logging utility written in pure Swift that allows you to log on different levels and channels which you can define on your own depending on your needs. Diagnostics - Allow users to easily share Diagnostics with your support team to improve the flow of fixing bugs. Gedatsu - Provide readable format about AutoLayout error console log. Machine Learning A collection of ML Models, deep learning and neural networking libraries Swift-Brain - Artificial Intelligence/Machine Learning data structures and Swift algorithms for future iOS development. Bayes theorem, Neural Networks, and more AI. AIToolbox - A toolbox of AI modules written in Swift: Graphs/Trees, Linear Regression, Support Vector Machines, Neural Networks, PCA, KMeans, Genetic Algorithms, MDP, Mixture of Gaussians. Tensorflow-iOS - The official Google-built powerful neural network library port for iOS. Bender - Easily craft fast Neural Networks. Use TensorFlow models. Metal under the hood. CoreML-samples - Sample code for Core ML using ResNet50 provided by Apple and a custom model generated by coremltools. Revolver - A framework for building fast genetic algorithms in Swift. Comes with modular architecture, pre-implemented operators and loads of examples. CoreML-Models - A collection of unique Core ML Models. Serrano - A deep learning library for iOS and macOS. Swift-AI - The Swift machine learning library. TensorSwift - A lightweight library to calculate tensors in Swift, which has similar APIs to TensorFlow's. DL4S - Deep Learning for Swift: Accelerated tensor operations and dynamic neural networks based on reverse mode automatic differentiation for every device that can run Swift. SwiftCoreMLTools - A Swift library for creating and exporting CoreML Models in Swift. Maps Mapbox GL - An OpenGL renderer for Mapbox Vector Tiles with SDK bindings for iOS. GEOSwift - The Swift Geographic Engine. PXGoogleDirections - Google Directions API helper for iOS, written in Swift. Cluster - Easy Map Annotation Clustering. JDSwiftHeatMap - JDSwiftMap is an IOS Native MapKit Library. You can easily make a highly customized HeatMap. ClusterKit - An iOS map clustering framework targeting MapKit, Google Maps and Mapbox. FlyoverKit - FlyoverKit enables you to present stunning 360 flyover views on your MKMapView with zero effort while maintaining full configuration possibilities. MapViewPlus - Use any custom view as custom callout view of your MKMapView with cool animations. Also, easily use any image as annotation view. MSFlightMapView - Add and animate geodesic flights on Google map. WhirlyGlobe-Maply - 3D globe and flat-map SDK for iOS. This toolkit has a large API for fine-grained control over the map or globe. It reads a wide variety of GIS data formats. Math Math frameworks, functions and libraries to custom operations, statistical calculations and more. Euler - Swift Custom Operators for Mathematical Notation. SwiftMath - A math framework for Swift. Includes: vectors, matrices, complex numbers, quaternions and polynomials. Arithmosophi - A set of protocols for Arithmetic and Logical operations. Surge - A Swift library that uses the Accelerate framework to provide high-performance functions for matrix math, digital signal processing, and image manipulation. Upsurge - Swift math. Swift-MathEagle - A general math framework to make using math easy. Currently supports function solving and optimisation, matrix and vector algebra, complex numbers, big int and big frac and general handy extensions and functions. iosMath - A library for displaying beautifully rendered math equations. Enables typesetting LaTeX math formulae in iOS. BigInt - Arbitrary-precision arithmetic in pure Swift. SigmaSwiftStatistics - A collection of functions for statistical calculation. VectorMath - A Swift library for Mac and iOS that implements common 2D and 3D vector and matrix functions, useful for games or vector-based graphics. Expression - A Mac and iOS library for evaluating numeric expressions at runtime. Metron - Metron is a comprehensive collection of geometric functions and types that extend the 2D geometric primitives provided by CoreGraphics. NumericAnnex - NumericAnnex supplements the numeric facilities provided in the Swift standard library. Media Audio AudioBus - Add Next Generation Live App-to-App Audio Routing. AudioKit - A powerful toolkit for synthesizing, processing, and analyzing sounds. EZAudio - An iOS/macOS audio visualization framework built upon Core Audio useful for anyone doing real-time, low-latency audio processing and visualizations. novocaine - Painless high-performance audio on iOS and macOS. QHSpeechSynthesizerQueue - Queue management system for AVSpeechSynthesizer (iOS Text to Speech). Cephalopod - A sound fader for AVAudioPlayer written in Swift. Chirp - The easiest way to prepare, play, and remove sounds in your Swift app! Beethoven - An audio processing Swift library for pitch detection of musical signals. AudioPlayerSwift - AudioPlayer is a simple class for playing audio in iOS, macOS and tvOS apps. AudioPlayer - AudioPlayer is syntax and feature sugar over AVPlayer. It plays your audio files (local & remote). TuningFork - Simple Tuner for iOS. MusicKit - A framework for composing and transforming music in Swift. SubtleVolume - Replace the system volume popup with a more subtle indicator. NVDSP - iOS/macOS DSP for audio (with Novocaine). SRGMediaPlayer-iOS - The SRG Media Player library for iOS provides a simple way to add a universal audio / video player to any iOS application. IQAudioRecorderController - A drop-in universal library allows to record audio within the app with a nice User Interface. TheAmazingAudioEngine2 - The Amazing Audio Engine is a sophisticated framework for iOS audio applications, built so you don't have to. InteractivePlayerView - Custom iOS music player view. ESTMusicIndicator - Cool Animated music indicator view written in Swift. QuietModemKit - iOS framework for the Quiet Modem (data over sound). SwiftySound - Super simple library that lets you play sounds with a single line of code (and much more). Written in Swift 3, supports iOS, macOS and tvOS. CocoaPods and Carthage compatible. BPMAnalyser - Fast and simple instrument to get the BPM rate from your audio-files. PandoraPlayer - A lightweight music player for iOS, based on AudioKit. SonogramView - Audio visualisation of song. AudioIndicatorBars - AIB indicates for your app users which audio is playing. Just like the Podcasts app. Porcupine - On-device wake word detection engine for macOS, iOS, and watchOS, powered by deep learning. Voice Overlay - An overlay that gets your users voice permission and input as text in a customizable UI. ModernAVPlayer - Persistence player to resume playback after bad network connection even in background mode, manage headphone interactions, system interruptions, now playing informations and remote commands. FDWaveformView - An easy way to display an audio waveform in your app, including animation. FDSoundActivatedRecorder - Start recording when the user speaks. GIF YLGIFImage - Async GIF image decoder and Image viewer supporting play GIF images. It just use very less memory. FLAnimatedImage - Performant animated GIF engine for iOS. gifu - Highly performant animated GIF support for iOS in Swift. AnimatedGIFImageSerialization - Complete Animated GIF Support for iOS, with Functions, NSJSONSerialization-style Class, and (Optional) UIImage Swizzling XAnimatedImage - XAnimatedImage is a performant animated GIF engine for iOS written in Swift based on FLAnimatedImage SwiftGif - A small UIImage extension with gif support. APNGKit - High performance and delightful way to play with APNG format in iOS. YYImage - Image framework for iOS to display/encode/decode animated WebP, APNG, GIF, and more. AImage - A animated GIF&APNG engine for iOS in Swift with low memory & cpu usage.Optimized for Multi-Image case. NSGIF2 - Simplify creation of a GIF from the provided video file url. SwiftyGif - High performance GIF engine. Image GPU Image - An open source iOS framework for GPU-based image and video processing. UIImage DSP - iOS UIImage processing functions using the vDSP/Accelerate framework for speed. AsyncImageView - Simple extension of UIImageView for loading and displaying images asynchronously without lock up the UI. SDWebImage - Asynchronous image downloader with cache support with an UIImageView category. DFImageManager - Modern framework for fetching images from various sources. Zero config yet immense customization and extensibility. Uses NSURLSession. MapleBacon - An image download and caching library for iOS written in Swift. NYTPhotoViewer - Slideshow and image viewer. IDMPhotoBrowser - Photo Browser / Viewer. Concorde - Download and decode progressive JPEGs. TOCropViewController - A view controller that allows users to crop UIImage objects. YXTMotionView - A custom image view that implements device motion scrolling. PINRemoteImage - A thread safe, performant, feature rich image fetcher. SABlurImageView - Easily Adding Animated Blur/Unblur Effects To An Image. FastImageCache - iOS library for quickly displaying images while scrolling. BKAsciiImage - Convert UIImage to ASCII art. AlamofireImage - An image component library for Alamofire. Nuke - Image loading, processing, caching and preheating. FlagKit - Beautiful flag icons for usage in apps and on the web. YYWebImage - Asynchronous image loading framework (supports WebP, APNG, GIF). RSKImageCropper - An image cropper for iOS like in the Contacts app with support for landscape orientation. Silo - Image loading framework with loaders. Ody - Ody is an easy to use random image generator built with Swift, Perfect for placeholders. Banana - Image slider with very simple interface. JDSwiftAvatarProgress - Easy customizable avatar image asynchronously with progress bar animated. Kingfisher - A lightweight and pure Swift implemented library for downloading and caching image from the web. EBPhotoPages - A photo gallery for iOS with a modern feature set. Similar features as the Facebook photo browser. UIImageView-BetterFace-Swift - The Swift version of https://github.com/croath/UIImageView-BetterFace KFSwiftImageLoader - An extremely high-performance, lightweight, and energy-efficient pure Swift async web image loader with memory and disk caching for iOS and Apple Watch. Toucan - Fabulous Image Processing in Swift. ImageLoaderSwift - A lightweight and fast image loader for iOS written in Swift. ImageScout - A Swift implementation of fastimage. Supports PNG, GIF, and JPEG. JLStickerTextView - A UIImageView allow you to add multiple Label (multiple line text support) on it, you can edit, rotate, resize the Label as you want with one finger ,then render the text on Image. Agrume - A lemony fresh iOS image viewer written in Swift. PASImageView - Rounded async imageview downloader lightly cached and written in Swift. Navi - Focus on avatar caching. SwiftPhotoGallery - Simple, fullscreen image gallery with tap, swipe, and pinch gestures. MetalAcc - GPU-based Media processing library using Metal written in Swift. MWPhotoBrowser - A simple iOS photo and video browser with grid view, captions and selections. UIImageColors - iTunes style color fetcher for UIImage. CDFlipView - A view that takes a set of images, make transition from one to another by using flipping effects. GPUImage2 - GPUImage 2 is a BSD-licensed Swift framework for GPU-accelerated video and image processing. TGLParallaxCarousel - A lightweight 3D Linear Carousel with parallax effect. ImageButter - Makes dealing with images buttery smooth. SKPhotoBrowser - Simple PhotoBrowser/Viewer inspired by Facebook, Twitter photo browsers written by swift. YUCIHighPassSkinSmoothing - An implementation of High Pass Skin Smoothing using Apple's Core Image Framework. CLImageViewPopup - A simple Image full screen pop up. APKenBurnsView - Ken Burns effect with face recognition! Moa - An image download extension of the image view for iOS, tvOS and macOS. JMCMarchingAnts - Library that lets you add marching ants (animated) selection to the edges of the images. ImageViewer - An image viewer la Twitter. FaceAware - An extension that gives UIImageView the ability to focus on faces within an image when using AspectFill. SwiftyAvatar - A UiimageView class for creating circular avatar images, IBDesignable to make all changes via storyboard. ShinpuruImage - Syntactic Sugar for Accelerate/vImage and Core Image Filters. ImagePickerSheetController - ImagePickerSheetController is like the custom photo action sheet in iMessage just without the glitches. ComplimentaryGradientView - Create complementary gradients generated from dominant and prominent colors in supplied image. Inspired by Grade.js. ImageSlideshow - Swift image slideshow with circular scrolling, timer and full screen viewer. Imaginary - Remote images, as easy as one, two, three. PPAssetsActionController - Highly customizable Action Sheet Controller with Assets Preview. Vulcan - Multi image downloader with priority in Swift. FacebookImagePicker - Facebook album photo picker written in Swift. Lightbox - A convenient and easy to use image viewer for your iOS app. Ebblink - An iOS SDK for sharing photos that automatically expire and can be deleted at any time. Sharaku - Instagram-like image filter ViewController. CTPanoramaView - Displays spherical or cylindrical panoramas or 360-photos with touch or motion based control options. Twitter Image Pipline - streamlined framework for fetching and storing images in an application. TinyCrayon - A smart and easy-to-use image masking and cutout SDK for mobile apps. FlexibleImage - A simple way to play with image! TLPhotoPicker - Multiple phassets picker for iOS lib. like a facebook. YapImageManager - A high-performance image downloader written in Swift, powered by YapDatabase. PhotoEditorSDK - A fully customizable photo editor for your app. SimpleImageViewer - A snappy image viewer with zoom and interactive dismissal transition. AZImagePreview - A framework that makes image viewing easy. FaceCropper - Crop faces, inside of your image, with iOS 11 Vision api. Paparazzo - Custom iOS camera and photo picker with editing capabilities. ZImageCropper - A Swift project to crop image in any shape. InitialsImageView - An UIImageView extension that generates letter initials as a placeholder for user profile images, with a randomized background color. DTPhotoViewerController - A fully customizable photo viewer ViewController, inspired by Facebook photo viewer. LetterAvatarKit - A UIImage extension that generates letter-based avatars written in Swift. AXPhotoViewer - An iPhone/iPad photo gallery viewer, useful for viewing a large (or small!) number of photos TJProfileImage - Live rendering of componets properties in Interface Builder. Viewer - Image viewer (or Lightbox) with support for local and remote videos and images. OverlayComposite - An asynchronous, multithreaded, image compositing framework written in Swift. MCScratchImageView - A custom ImageView that is used to cover the surface of other view like a scratch card, user can swipe the mulch to see the view below. MetalPetal - A GPU-accelerated image/video processing framework based on Metal. ShadowImageView - ShadowImageView is a iOS 10 Apple Music style image view, help you create elegent image with shadow. Avatar - Generate random user Avatar images using CoreGraphics and QuartzCore. Serrata - Slide image viewer library similar to Twitter and LINE. StyleArt - Style Art library process images using COREML with a set of pre trained machine learning models and convert them to Art style. greedo-layout-for-ios - Full aspect ratio grid layout for iOS. ImageDetect - Detect and crop faces, barcodes and texts inside of your image, with iOS 11 Vision api. THTiledImageView - Provide ultra-high-quality images through tiling techniques. GPUImage3 - GPUImage 3 is a BSD-licensed Swift framework for GPU-accelerated video and image processing using Metal. Gallery - Your next favorite image and video picker. ATGMediaBrowser - Image slide-show viewer with multiple predefined transition styles, and ability to create new transitions with ease. Pixel - An image editor and engine using CoreImage. OnlyPictures - A simple and flexible way to add source of overlapping circular pictures. SFSafeSymbols - Safely access Apple's SF Symbols using static typing. BSZoomGridScrollView - iOS customizable grid style scrollView UI library to display your UIImage array input, designed primarily for SwiftUI as well as to interoperate with UIKit. Media Processing SwiftOCR - Fast and simple OCR library written in Swift. QR Code Scanner - QR Code implementation. QRCode - A QRCode generator written in Swift. EFQRCode - A better way to operate two-dimensional code in Swift. NSFWDetector - A NSFW (aka porn) detector with CoreML. PDF Reader - PDF Reader Core for iOS. UIView 2 PDF - PDF generator using UIViews or UIViews with an associated XIB. FolioReaderKit - A Swift ePub reader and parser framework for iOS. PDFGenerator - A simple Generator of PDF in Swift. Generate PDF from view(s) or image(s). SimplePDF - Create a simple PDF effortlessly. SwiftPDFGenerator - PDF generator using UIViews; Swift Version of 'UIView 2 PDF'. PSPDFKit - Render PDF, add/edit annotations, fill forms, add/edit pages, view/create digital signatures. TPPDF - Generate PDF using commands and automatic layout. FastPdfKit - A Static Library to be embedded on iOS applications to display pdf documents derived from Fast PDF. UIImagePlusPDF - UIImage extensions to simply use PDF files. Streaming HaishinKit.swift - Camera and Microphone streaming library via RTMP, HLS for iOS, macOS. StreamingKit - A fast and extensible gapless AudioPlayer/AudioStreamer for macOS and iOS. Jukebox - Player for streaming local and remote audio files. Written in Swift. LFLiveKit - H264 and AAC Hard codingsupport GPUImage Beauty rtmp transmissionweak network lost frameDynamic switching rate. Airstream - A framework for streaming audio between Apple devices using AirPlay. OTAcceleratorCore - A painless way to integrate audio/video(screen sharing) to any iOS applications via Tokbox. Video VIMVideoPlayer - A simple wrapper around the AVPlayer and AVPlayerLayer classes. MobilePlayer - A powerful and completely customizable media player for iOS. XCDYouTubeKit - YouTube video player for iOS, tvOS and macOS. AVAnimator - An open source iOS native library that makes it easy to implement non-trivial video/audio enabled apps. Periscope VideoViewController - Video view controller with Periscope fast rewind control. MHVideoPhotoGallery - A Photo and Video Gallery. PlayerView - Player View is a delegated view using AVPlayer of Swift. SRGMediaPlayer-iOS - The SRG Media Player library for iOS provides a simple way to add a universal audio / video player to any iOS application. AVPlayerViewController-Subtitles - AVPlayerViewController-Subtitles is a library to display subtitles on iOS. It's built as a Swift extension and it's very easy to integrate. MPMoviePlayerController-Subtitles - MPMoviePlayerController-Subtitles is a library to display subtitles on iOS. It's built as a Swift extension and it's very easy to integrate. ZFPlayer - Based on AVPlayer, support for the horizontal screen, vertical screen (full screen playback can also lock the screen direction), the upper and lower slide to adjust the volume, the screen brightness, or so slide to adjust the playback progress. Player - video player in Swift, simple way to play and stream media in your iOS or tvOS app. BMPlayer - Video player in swift3 and swift2 for iOS, based on AVPlayer, support the horizontal, vertical screen. support adjust volume, brigtness and seek by slide. VideoPager - Paging Video UI, and some control components is available. ios-360-videos - NYT360Video plays 360-degree video streamed from an AVPlayer. swift-360-videos - Pure swift (no SceneKit) 3D library with focus on video and 360. ABMediaView - UIImageView subclass for drop-in image, video, GIF, and audio display, with functionality for fullscreen and minimization to the bottom-right corner. PryntTrimmerView - A set of UI elements to trim, crop and select frames inside a video. VGPlayer - A simple iOS video player in Swift,Support play local and network,Background playback mode. YoutubeKit - A video player that fully supports Youtube IFrame API and YoutubeDataAPI for easily create a Youtube app. Swift-YouTube-Player - Swift library for embedding and controlling YouTube videos in your iOS applications! JDVideoKit - You can easily transfer your video into Three common video type via this framework. VersaPlayer - Versatile AVPlayer implementation for iOS, macOS, and tvOS. Messaging Also see push notifications XMPPFramework - An XMPP Framework in Objective-C for Mac and iOS. Chatto - A lightweight framework to build chat applications, made in Swift. MessageKit - Eventually, a Swift re-write of JSQMessagesViewController. Messenger - This is a native iOS Messenger app, making realtime chat conversations and audio calls with full offline support. OTTextChatAccelerator - OpenTok Text Chat Accelerator Pack enables text messages between mobile or browser-based devices. chat-sdk-ios - Chat SDK iOS - Open Source Mobile Messenger. AsyncMessagesViewController - A smooth, responsive and flexible messages UI library for iOS. MessageViewController - A SlackTextViewController replacement written in Swift for the iPhone X. SwiftyMessenger - Swift toolkit for passing messages between iOS apps and extensions. Messenger Chat with Firebase - Swift messaging chat app with Firebase Firestore integration. SwiftKafka - Swift SDK for Apache Kafka by IBM. ChatLayout - A lightweight framework to build chat UI that uses custom UICollectionViewLayout to provide full control over the presentation as well as all the tools available in UICollectionView. Networking AFNetworking - A delightful iOS and macOS networking framework. RestKit - RestKit is an Objective-C framework for iOS that aims to make interacting with RESTful web services simple, fast and fun. FSNetworking - Foursquare iOS networking library. ASIHTTPRequest - Easy to use CFNetwork wrapper for HTTP requests, Objective-C, macOS and iPhone. Overcoat - Small but powerful library that makes creating REST clients simple and fun. ROADFramework - Attributed-oriented approach for interacting with web services. The framework has built-in json and xml serialization for requests and responses and can be easily extensible. Alamofire - Alamofire is an HTTP networking library written in Swift, from the creator of AFNetworking. Transporter - A tiny library makes uploading and downloading easier. CDZPinger - Easy-to-use ICMP Ping. NSRails - iOS/Mac OS framework for Rails. NKMultipeer - A testable abstraction over multipeer connectivity. CocoaAsyncSocket - Asynchronous socket networking library for Mac and iOS. Siesta - Elegant abstraction for RESTful resources that untangles stateful messes. An alternative to callback- and delegate-based networking. Reachability.swift - Replacement for Apple's Reachability re-written in Swift with closures. OctopusKit - A simplicity but graceful solution for invoke RESTful web service APIs. Moya - Network abstraction layer written in Swift. TWRDownloadManager - A modern download manager based on NSURLSession to deal with asynchronous downloading, management and persistence of multiple files. HappyDns - A Dns library, support custom dns server, dnspod httpdns. Only support A record. Bridge - A simple extensible typed networking library. Intercept and process/alter requests and responses easily. TRON - Lightweight network abstraction layer, written on top of Alamofire. EVCloudKitDao - Simplified access to Apple's CloudKit. EVURLCache - a NSURLCache subclass for handling all web requests that use NSURLRequest. ResponseDetective - Sherlock Holmes of the networking layer. Pitaya - A Swift HTTP / HTTPS networking library just incidentally execute on machines. Just - Swift HTTP for Humans. agent - Minimalistic Swift HTTP request agent for iOS and macOS. Reach - A simple class to check for internet connection availability in Swift. SwiftHTTP - Thin wrapper around NSURLSession in swift. Simplifies HTTP requests. Netdiag - A network diagnosis library. Support Ping/TcpPing/Rtmp/TraceRoute/DNS/external IP/external DNS. AFNetworkingHelper - A custom wrapper over AFNetworking library that we use inside RC extensively. NetKit - A Concise HTTP Framework in Swift. RealReachability - We need to observe the REAL reachability of network. That's what RealReachability do. MonkeyKing - MonkeyKing helps you post messages to Chinese Social Networks. NetworkKit - Lightweight Networking and Parsing framework made for iOS, Mac, WatchOS and tvOS. APIKit - A networking library for building type safe web API client in Swift. ws - Elegant JSON WebService in Swift. SPTDataLoader - The HTTP library used by the Spotify iOS client. SWNetworking - Powerful high-level iOS, macOS and tvOS networking library. Networking - Simple HTTP Networking in Swift a NSURLSession wrapper with image caching support. SOAPEngine - This generic SOAP client allows you to access web services using a your iOS app, macOS app and AppleTV app. Swish - Nothing but Net(working). Malibu - Malibu is a networking library built on promises. YTKNetwork - YTKNetwork is a high level request util based on AFNetworking. UnboxedAlamofire - Alamofire + Unbox: the easiest way to download and decode JSON into swift objects. MMLanScan - An iOS LAN Network Scanner library. Domainer - Manage multi-domain url auto mapping ip address table. Restofire - Restofire is a protocol oriented network abstraction layer in swift that is built on top of Alamofire to use services in a declartive way. AFNetworking+RetryPolicy - An objective-c category that adds the ability to set the retry logic for requests made with AFNetworking. SwiftyZeroMQ - ZeroMQ Swift Bindings for iOS, macOS, tvOS and watchOS. Nikka - A super simple Networking wrapper that supports many JSON libraries, Futures and Rx. XMNetworking - A lightweight but powerful network library with simplified and expressive syntax based on AFNetworking. Merhaba - Bonjour networking for discovery and connection between iOS, macOS and tvOS devices. DBNetworkStack - Resource-oritented networking which is typesafe, extendable, composeable and makes testing a lot easier. EFInternetIndicator - A little swift Internet error status indicator using ReachabilitySwift. AFNetworking-Synchronous - Synchronous requests for AFNetworking 1.x, 2.x, and 3.x. QwikHttp - a robust, yet lightweight and simple to use HTTP networking library designed for RESTful APIs. NetClient - Versatile HTTP networking library written in Swift 3. WANetworkRouting - An iOS library to route API paths to objects on client side with request, mapping, routing and auth layers. Reactor - Powering your RAC architecture. SWNetworking - Powerful high-level iOS, macOS and tvOS networking library. from the creator of SWNetworking. Digger - Digger is a lightweight download framework that requires only one line of code to complete the file download task. Ciao - Publish and discover services using mDNS(Bonjour, Zeroconf). Bamboots - Bamboots is a network request framework based on Alamofire, aiming at making network request easier for business development. SolarNetwork - Elegant network abstraction layer in Swift. FGRoute - An easy-to-use library that helps developers to get wifi ssid, router and device ip addresses. RxRestClient - Simple REST Client based on RxSwift and Alamofire. TermiNetwork - A networking library written with Swift 4.0 that supports multi-environment configuration, routing and automatic deserialization. Dots - Lightweight Concurrent Networking Framework. Gem - An extreme light weight system with high performance for managing all http request with automated parser with modal. RMHttp - Lightweight REST library for iOS and watchOS. AlamoRecord - An elegant yet powerful iOS networking layer inspired by ActiveRecord. MHNetwork - Protocol Oriented Network Layer Aim to avoid having bloated singleton NetworkManager. ThunderRequest - A simple URLSession wrapper with a generic protocol based request body approach and easy deserialisation of responses. ReactiveAPI - Write clean, concise and declarative network code relying on URLSession, with the power of RxSwift. Inspired by Retrofit. Squid - Declarative and reactive networking framework based on Combine and providing means for HTTP requests, transparent pagination, and WebSocket communication. Email Mail Core 2 - MailCore 2 provide a simple and asynchronous API to work with e-mail protocols IMAP, POP and SMTP. Postal - A swift framework providing simple access to common email providers. Representations apollo-ios - A GraphQL client for iOS. JSONRPCKit - A JSON-RPC 2.0 library. protobuf-swift - Google ProtocolBuffers for Apple Swift swift-protobuf - Plugin and runtime library for using protobuf with Swift. Notifications Push Notifications Orbiter - Push Notification Registration for iOS. PEM - Automatically generate and renew your push notification profiles. Knuff - The debug application for Apple Push Notification Service (APNS). FBNotifications - Facebook Analytics In-App Notifications Framework. NWPusher - macOS and iOS application and framework to play with the Apple Push Notification service (APNs). SimulatorRemoteNotifications - Library to send mock remote notifications to the iOS simulator. APNSUtil - Library makes code simple settings and landing for apple push notification service. Push Notification Providers Most of these are paid services, some have free tiers. Urban Airship Growth Push - Popular in Japan. Braze Batch Boxcar Carnival Catapush Netmera OneSignal - Free. PushBots Pushwoosh Pushkin - Free and open-source. Pusher - Free and unlimited. Swrve Local Notifications DLLocalNotifications - Easily create Local Notifications in swift - Wrapper of UserNotifications Framework. Objective-C Runtime Objective-C Runtime wrappers, libraries and tools. Lumos - A light Swift wrapper around Objective-C Runtime. Swizzlean - An Objective-C Swizzle Helper Class. Optimization Unreachable - Unreachable code path optimization hint for Swift. Parsing CSV CSwiftV - A csv parser written in swift conforming to rfc4180. CSV.swift - CSV reading and writing library written in Swift. CodableCSV - Read and write CSV files row-by-row & field-by-field or through Swift's Codable interface. JSON SBJson - This framework implements a strict JSON parser and generator in Objective-C. Mantle - Model framework for Cocoa and Cocoa Touch. Groot - Convert JSON dictionaries and arrays to and from Core Data managed objects. PropertyMapper - Data mapping and validation with minimal amount of code. JSONModel - Magical Data Modeling Framework for JSON. Create rapidly powerful, atomic and smart data model classes. SwiftyJSON - The better way to deal with JSON data in Swift. FastEasyMapping - Serialize & deserialize JSON fast. ObjectMapper - A framework written in Swift that makes it easy for you to convert your Model objects (Classes and Structs) to and from JSON. JASON - JSON parsing with outstanding performances and convenient operators. Gloss - A shiny JSON parsing library in Swift. SwiftyJSONAccelerator - Generate Swift 5 model files from JSON with Codeable support. alexander - An extremely simple JSON helper written in Swift. Freddy - A reusable framework for parsing JSON in Swift. mapper - A JSON deserialization library for Swift. Alembic - Functional JSON parsing, mapping to objects, and serialize to JSON. Arrow - Elegant JSON Parsing in Swift. JSONExport - JSONExport is a desktop application for macOS which enables you to export JSON objects as model classes with their associated constructors, utility methods, setters and getters in your favorite language. Elevate - Elevate is a JSON parsing framework that leverages Swift to make parsing simple, reliable and composable. MJExtension - A fast, convenient and nonintrusive conversion between JSON and model. Your model class don't need to extend another base class. You don't need to modify any model file. AlamofireObjectMapper - An Alamofire extension which converts JSON response data into swift objects using ObjectMapper. JAYSON - Strict and Scalable JSON library. HandyJSON - A handy swift JSON-object serialization/deserialization library for Swift. Marshal - Marshaling the typeless wild west of [String: Any] (Protocol based). Motis - Easy JSON to NSObject mapping using Cocoa's key value coding (KVC). NSTEasyJSON - The easiest way to deal with JSON data in Objective-C (similar to SwiftyJSON). Serpent - A protocol to serialize Swift structs and classes for encoding and decoding. FlatBuffersSwift - This project brings FlatBuffers (an efficient cross platform serialization library) to Swift. CodableAlamofire - An extension for Alamofire that converts JSON data into Decodable objects (Swift 4). WAMapping - A library to turn dictionary into object and vice versa for iOS. Designed for speed! Himotoki - A type-safe JSON decoding library purely written in Swift. PMHTTP - Swift/Obj-C HTTP framework with a focus on REST and JSON. NativeJSONMapper - Simple Swift 4 encoding & decoding. PMJSON - Pure Swift JSON encoding/decoding library. jsoncafe.com - Online Template driven Model Class Generator from JSON. Mappable - lightweight and powerful JSON object mapping library, specially optimized for immutable properties. XML & HTML AEXML - Simple and lightweight XML parser written in Swift. Ji - XML/HTML parser for Swift. Ono - A sensible way to deal with XML & HTML for iOS & macOS. Fuzi - A fast & lightweight XML & HTML parser in Swift with XPath & CSS support. Kanna - Kanna() is an XML/HTML parser for macOS/iOS. SwiftyXMLParser - Simple XML Parser implemented in Swift. HTMLKit - An Objective-C framework for your everyday HTML needs. SWXMLHash - Simple XML parsing in Swift. SwiftyXML - The most swifty way to deal with XML data in swift 4. XMLCoder - Encoder & Decoder for XML using Swift's Codable protocols. Other Parsing WKZombie - WKZombie is a Swift framework for iOS/macOS to navigate within websites and collect data without the need of User Interface or API, also known as Headless browser. It can be used to run automated tests or manipulate websites using Javascript. URLPreview - An NSURL extension for showing preview info of webpages. FeedKit - An RSS and Atom feed parser written in Swift. Erik - Erik is an headless browser based on WebKit. An headless browser allow to run functional tests, to access and manipulate webpages using javascript. URLEmbeddedView - Automatically caches the object that is confirmed the Open Graph Protocol, and displays it as URL embedded card. SwiftCssParser - A Powerful , Extensible CSS Parser written in pure Swift. RLPSwift - Recursive Length Prefix encoding written in Swift. AcknowledgementsPlist - AcknowledgementsPlist manages the licenses of libraries that depend on your iOS app. CoreXLSX - Excel spreadsheet (XLSX) format support in pure Swift. Passbook passbook - Passbook gem let's you create pkpass for passbook iOS 6+. Dubai - Generate and Preview Passbook Passes. Passkit - Design, Create and validate Passbook Passes. Payments Caishen - A Payment Card UI & Validator for iOS. Stripe - Payment integration on your app with PAY. Suitable for people with low knowledge on Backend. Braintree - Free payment processing on your first $50k. Requires Backend. Venmo Make and accept payments in your iOS app via Venmo. Moltin - Add eCommerce to your app with a simple SDK, so you can create a store and sell physical products, no backend required. PatronKit - A framework to add patronage to your apps. SwiftyStoreKit - Lightweight In App Purchases Swift framework for iOS 8.0+ and macOS 9.0+ InAppFramework - In App Purchase Manager framework for iOS. SwiftInAppPurchase - Simply code In App Purchases with this Swift Framework. monza - Ruby Gem for Rails - Easy iTunes In-App Purchase Receipt validation, including auto-renewable subscriptions. PayPal - Accept payments in your iOS app via PayPal. card.io-iOS-SDK - card.io provides fast, easy credit card scanning in mobile apps. SwiftLuhn - Debit/Credit card validation port of the Luhn Algorithm in Swift. ObjectiveLuhn - Luhn Credit Card Validation Algorithm. RMStore - A lightweight iOS library for In-App Purchases. MFCard - Easily integrate Credit Card payments in iOS App / Customisable Card UI. TPInAppReceipt - Reading and Validating In App Store Receipt. iCard - Bank Card Generator with Swift using SnapKit DSL. CreditCardForm-iOS - CreditCardForm is iOS framework that allows developers to create the UI which replicates an actual Credit Card. merchantkit - A modern In-App Purchases management framework for iOS. TipJarViewController - Easy, drop-in tip jar for iOS apps. FramesIos - Payment Form UI and Utilities in Swift. YRPayment - Better payment user experience library with cool animation in Swift. AnimatedCardInput Easy to use library with customisable components for input of Credit Card data. Permissions Proposer - Make permission request easier (Supports Camera, Photos, Microphone, Contacts, Location). ISHPermissionKit - A unified way for iOS apps to request user permissions. ClusterPrePermissions - Reusable pre-permissions utility that lets developers ask users for access in their own dialog, before making the system-based request. Permission - A unified API to ask for permissions on iOS. STLocationRequest - A simple and elegant 3D-Flyover location request screen written Swift. PAPermissions - A unified API to ask for permissions on iOS. AREK - AREK is a clean and easy to use wrapper over any kind of iOS permission. SPPermissions - Ask permissions on Swift. Available List, Dialog & Native interface. Can check state permission. Reactive Programming RxSwift - Reactive Programming in Swift. RxOptional - RxSwift extensions for Swift optionals and "Occupiable" types. ReactiveTask - Flexible, stream-based abstraction for launching processes. ReactiveCocoa - Streams of values over time. RxMediaPicker - A reactive wrapper built around UIImagePickerController. ReactiveCoreData - ReactiveCoreData (RCD) is an attempt to bring Core Data into the ReactiveCocoa (RAC) world. ReSwift - Unidirectional Data Flow in Swift - Inspired by Redux. ReactiveKit - ReactiveKit is a collection of Swift frameworks for reactive and functional reactive programming. RxPermission - RxSwift bindings for Permissions API in iOS. RxAlamofire - RxSwift wrapper around the elegant HTTP networking in Swift Alamofire. RxRealm - Rx wrapper for Realm's collection types. RxMultipeer - A testable RxSwift wrapper around MultipeerConnectivity. RxBluetoothKit - iOS & macOS Bluetooth library for RxSwift. RxGesture - RxSwift reactive wrapper for view gestures. NSObject-Rx - Handy RxSwift extensions on NSObject, including rx_disposeBag. RxCoreData - RxSwift extensions for Core Data. RxAutomaton - RxSwift + State Machine, inspired by Redux and Elm. ReactiveArray - An array class implemented in Swift that can be observed using ReactiveCocoa's Signals. Interstellar - Simple and lightweight Functional Reactive Coding in Swift for the rest of us. ReduxSwift - Predictable state container for Swift apps too. Aftermath - Stateless message-driven micro-framework in Swift. RxKeyboard - Reactive Keyboard in iOS. JASONETTE-iOS - Native App over HTTP. Create your own native iOS app with nothing but JSON. ReactiveSwift - Streams of values over time by ReactiveCocoa group. Listenable - Swift object that provides an observable platform. Reactor - Unidirectional Data Flow using idiomatic Swiftinspired by Elm and Redux. Snail - An observables framework for Swift. RxWebSocket - Reactive extension over Starscream for websockets. ACKReactiveExtensions - Useful extensions for ReactiveCocoa ReactiveLocation - CoreLocation made reactive Hanson - Lightweight observations and bindings in Swift, with support for KVO and NotificationCenter. Observable - The easiest way to observe values in Swift. SimpleApiClient - A configurable api client based on Alamofire4 and RxSwift4 for iOS. VueFlux - Unidirectional Data Flow State Management Architecture for Swift - Inspired by Vuex and Flux. RxAnimated - Animated RxCocoa bindings. BindKit - Two-way data binding framework for iOS. Only one API to learn. STDevRxExt - STDevRxExt contains some extension functions for RxSwift and RxCocoa which makes our live easy. RxReduce - Lightweight framework that ease the implementation of a state container pattern in a Reactive Programming compliant way. RxCoordinator - Powerful navigation library for iOS based on the coordinator pattern. RxAlamoRecord Combines the power of the AlamoRecord and RxSwift libraries to create a networking layer that makes interacting with API's easier than ever reactively. CwlSignal A Swift framework for reactive programming. LightweightObservable - A lightweight implementation of an observable sequence that you can subscribe to. Bindy - Simple, lightweight swift bindings with KVO support and easy to read syntax. OpenCombine Open source implementation of Apple's Combine framework for processing values over time. Verge - Verge is a faster and scalable state management library for UIKit and SwiftUI React-Like Render - Swift and UIKit a la React. Katana - Swift apps a la React and Redux. TemplateKit - React-inspired framework for building component-based user interfaces in Swift. CoreEvents - Simple library with C#-like events. Tokamak - React-like framework providing a declarative API for building native UI components with easy to use one-way data binding. Reflection Reflection - Reflection provides an API for advanced reflection at runtime including dynamic construction of types. Reflect - Reflection, Dict2Model, Model2Dict, Archive. EVReflection - Reflection based JSON encoding and decoding. Including support for NSDictionary, NSCoding, Printable, Hashable and Equatable. JSONNeverDie - Auto reflection tool from JSON to Model, user friendly JSON encoder / decoder, aims to never die. SwiftKVC - Key-Value Coding (KVC) for native Swift classes and structs. Runtime - A Swift Runtime library for viewing type info, and the dynamic getting and setting of properties. Regex Regex - A Swift framework providing an NSRegularExpression-backed Regex type. SwiftRegex - Perl-like Regex =~ operator for Swift. PySwiftyRegex - Easily deal with Regex in Swift in a Pythonic way. Regex - Regular expressions for swift. Regex - Regex class for Swift. Wraps NSRegularExpression. SDK Official Spotify Spotify iOS SDK. SpotifyLogin Spotify SDK Login in Swift. Facebook Facebook iOS SDK. Google Analytics Google Analytics SDK for iOS. Paypal iOS SDK The PayPal Mobile SDKs enable native apps to easily accept PayPal and credit card payments. Pocket SDK for saving stuff to Pocket. Tumblr Library for easily integrating Tumblr data into your iOS or macOS application. Evernote Evernote SDK for iOS. Box iOS + macOS SDK for the Box API. OneDrive Live SDK for iOS. Stripe Stripe bindings for iOS and macOS. Venmo AWS Amazon Web Services Mobile SDK for iOS. Zendesk Zendesk Mobile SDK for iOS. Dropbox SDKs for Drop-ins and Dropbox Core API. Firebase Mobile (and web) application development platform. ResearchKit ResearchKit is an open source software framework that makes it easy to create apps for medical research or for other research projects. Primer - Easy SDK for creating personalized landing screens, signup, and login flows on a visual editor with built in a/b/n testing and analytics. Azure - Client library for accessing Azure Storage on an iOS device. 1Password - 1Password Extension for iOS Apps. CareKit - CareKit is an open source software framework for creating apps that help people better understand and manage their health. By Apple. Shopify - Shopifys Mobile Buy SDK makes it simple to sell physical products inside your mobile app. Pinterest - Pinterest iOS SDK. playkit-ios - PlayKit: Kaltura Player SDK for iOS. algoliasearch-client-swift - Algolia Search API Client for Swift. twitter-kit-ios - Twitter Kit is a native SDK to include Twitter content inside mobile apps. rides-ios-sdk - Uber Rides iOS SDK (beta). Apphud - A complete solution to integrate auto-renewable subscriptions and regular in-app purchases in 30 minutes with no server code required. Adapty - Integrate in-app subscriptions and a/b testing for them with 3 lines of code. Unofficial STTwitter A stable, mature and comprehensive Objective-C library for Twitter REST API 1.1. FHSTwitterEngine Twitter API for Cocoa developers. Giphy Giphy API client for iOS in Objective-C. UberKit - A simple, easy-to-use Objective-C wrapper for the Uber API. InstagramKit - Instagram iOS SDK. DribbbleSDK - Dribbble iOS SDK. objectiveflickr - ObjectiveFlickr, a Flickr API framework for Objective-C. Easy Social - Twitter & Facebook Integration. das-quadrat - A Swift wrapper for Foursquare API. iOS and macOS. SocialLib - SocialLib handles sharing message to multiple social media. PokemonKit - Pokeapi wrapper, written in Swift. TJDropbox - A Dropbox v2 client library written in Objective-C GitHub.swift - :octocat: Unofficial GitHub API client in Swift CloudRail SI - Abstraction layer / unified API for multiple API providers. Interfaces eg for Cloud Storage (Dropbox, Google, ...), Social Networks (Facebook, Twitter, ...) and more. Medium SDK - Swift - Unofficial Medium API SDK in Swift with sample project. Swifter - :bird: A Twitter framework for iOS & macOS written in Swift. SlackKit - a Slack client library for iOS and macOS written in Swift. RandomUserSwift - Swift Framework to Generate Random Users - An Unofficial SDK for randomuser.me. PPEventRegistryAPI - Swift 3 Framework for Event Registry API (eventregistry.org). UnsplashKit - Swift client for Unsplash. Swiftly Salesforce - An easy-to-use framework for building iOS apps that integrate with Salesforce, using Swift and promises. Spartan - An Elegant Spotify Web API Library Written in Swift for iOS and macOS. BigBoard - An Elegant Financial Markets Library Written in Swift that makes requests to Yahoo Finance API's under the hood. BittrexApiKit - Simple and complete Swift wrapper for Bittrex Exchange API. SwiftyVK Library for easy interact with VK social network API written in Swift. ARKKit - ARK Ecosystem Cryptocurrency API Framework for iOS & macOS, written purely in Swift 4.0. SwiftInstagram - Swift Client for Instagram API. SwiftyArk - A simple, lightweight, fully-asynchronous cryptocurrency framework for the ARK Ecosystem. PerfectSlackAPIClient - A Slack API Client for the Perfect Server-Side Swift Framework. Mothership - Tunes Connect Library inspired by FastLane. SwiftFlyer - An API wrapper for bitFlyer that supports all providing API. waterwheel.swift - The Waterwheel Swift SDK provides classes to natively connect iOS, macOS, tvOS, and watchOS applications to Drupal 7 and 8. ForecastIO - A Swift library for the Forecast.io Dark Sky API. JamfKit - A JSS communication framework written in Swift. Security cocoapods-keys - A key value store for storing environment and application keys. simple-touch - Very simple swift wrapper for Biometric Authentication Services (Touch ID) on iOS. SwiftPasscodeLock - An iOS passcode lock with TouchID authentication written in Swift. Smile-Lock - A library for make a beautiful Passcode Lock View. zxcvbn-ios - A realistic password strength estimator. TPObfuscatedString - Simple String obfuscation using core Swift. LTHPasscodeViewController - An iOS passcode lockscreen replica (from Settings), with TouchID and simple (variable length) / complex support. iOS-App-Security-Class - Simple class to check if iOS app has been cracked, being debugged or enriched with custom dylib and as well detect jailbroken environment. BiometricAuth - Simple framework for biometric authentication (via TouchID) in your application. SAPinViewController - Simple and easy to use default iOS PIN screen. This simple library allows you to draw a fully customisable PIN screen same as the iOS default PIN view. My inspiration to create this library was form THPinViewController, however SAPinViewController is completely implemented in Swift. Also the main purpose of creating this library was to have simple, easy to use and fully customisable PIN screen. TOPasscodeViewController - A modal passcode input and validation view controller for iOS. BiometricAuthentication - Use Apple FaceID or TouchID authentication in your app using BiometricAuthentication. KKPinCodeTextField - A customizable verification code textField for phone verification codes, passwords etc. Virgil SWIFT PFS SDK - An SDK that allows developers to add the Perfect Forward Secrecy (PFS) technologies to their digital solutions to protect previously intercepted traffic from being decrypted even if the main Private Key is compromised. Virgil Security Objective-C/Swift SDK - An SDK which allows developers to add full end-to-end security to their existing digital solutions to become HIPAA and GDPR compliant and more using Virgil API. Vault - Safe place for your encryption keys. SecurePropertyStorage - Helps you define secure storages for your properties using Swift property wrappers. Encryption AESCrypt-ObjC - A simple and opinionated AES encrypt / decrypt Objective-C class that just works. IDZSwiftCommonCrypto - A wrapper for Apple's Common Crypto library written in Swift. Arcane - Lightweight wrapper around CommonCrypto in Swift. SwiftMD5 - A pure Swift implementation of MD5. SwiftHash - Hash in Swift. SweetHMAC - A tiny and easy to use Swift class to encrypt strings using HMAC algorithms. SwCrypt - RSA public/private key generation, RSA, AES encryption/decryption, RSA sign/verify in Swift with CommonCrypto in iOS and macOS. SwiftSSL - An Elegant crypto toolkit in Swift. SwiftyRSA - RSA public/private key encryption in Swift. EnigmaKit - Enigma encryption in Swift. Themis - High-level crypto library, providing basic asymmetric encryption, secure messaging with forward secrecy and secure data storage, supports iOS/macOS, Android and different server side platforms. Obfuscator-iOS - Secure your app by obfuscating all the hard-coded security-sensitive strings. swift-sodium - Safe and easy to use crypto for iOS. CryptoSwift - Crypto related functions and helpers for Swift implemented in Swift programming language. SCrypto - Elegant Swift interface to access the CommonCrypto routines. SipHash - Simple and secure hashing in Swift with the SipHash algorithm. RNCryptor - CCCryptor (AES encryption) wrappers for iOS and Mac in Swift. -- For ObjC, see RNCryptor/RNCryptor-objc. CatCrypto - An easy way for hashing and encryption. SecureEnclaveCrypto - Demonstration library for using the Secure Enclave on iOS. RSASwiftGenerator - Util for generation RSA keys on your client and save to keychain or cover into Data. Virgil Security Objective-C/Swift Crypto Library - A high-level cryptographic library that allows to perform all necessary operations for securely storing and transferring data. JOSESwift - A framework for the JOSE standards JWS, JWE, and JWK written in Swift. Keychain UICKeyChainStore - UICKeyChainStore is a simple wrapper for Keychain on iOS. Valet - Securely store data in the iOS or macOS Keychain without knowing a thing about how the Keychain works. Locksmith - A powerful, protocol-oriented library for working with the keychain in Swift. KeychainAccess - Simple Swift wrapper for Keychain that works on iOS and macOS. Keychains - Because you should care... about the security... of your shit. Lockbox - Objective-C utility class for storing data securely in the key chain. SAMKeychain - Simple Objective-C wrapper for the keychain that works on Mac and iOS. SwiftKeychainWrapper - A simple wrapper for the iOS Keychain to allow you to use it in a similar fashion to User Defaults. SwiftyKeychainKit - Keychain wrapper with the benefits of static typing and convenient syntax, support for primitive types, Codable, NSCoding. Server Server side projects supporting coroutines, Linux, MacOS, iOS, Apache Modules, Async calls, libuv and more. Perfect - Server-side Swift. The Perfect library, application server, connectors and example apps. Swifter - Tiny http server engine written in Swift programming language. CocoaHTTPServer - A small, lightweight, embeddable HTTP server for macOS or iOS applications. Curassow - Swift HTTP server using the pre-fork worker model. Zewo - Lightweight library for web server applications in Swift on macOS and Linux powered by coroutines. Vapor - Elegant web framework for Swift that works on iOS, macOS, and Ubuntu. swiftra - Sinatra-like DSL for developing web apps in Swift. blackfire - A fast HTTP web server based on Node.js and Express written in Swift. swift-http - HTTP Implementation for Swift on Linux and macOS. Trevi - libuv base Swift web HTTP server framework. Express - Swift Express is a simple, yet unopinionated web application server written in Swift. Taylor - A lightweight library for writing HTTP web servers with Swift. Frank - Frank is a DSL for quickly writing web applications in Swift. Kitura - A Swift Web Framework and HTTP Server. Swifton - A Ruby on Rails inspired Web Framework for Swift that runs on Linux and macOS. Dynamo - High Performance (nearly)100% Swift Web server supporting dynamic content. Redis - Pure-Swift Redis client implemented from the original protocol spec. macOS + Linux compatible. NetworkObjects - Swift backend / server framework (Pure Swift, Supports Linux). Noze.io - Evented I/O streams a.k.a. Node.js for Swift. Lightning - A Swift Multiplatform Web and Networking Framework. SwiftGD - A simple Swift wrapper for libgd. Jobs - A job system for Swift backends. ApacheExpress - Write Apache Modules in Swift! GCDWebServer - Lightweight GCD based HTTP server for macOS & iOS (includes web based uploader & WebDAV server). Embassy - Super lightweight async HTTP server library in pure Swift runs in iOS / MacOS / Linux. smoke-framework - A light-weight server-side service framework written in the Swift programming language. Text Twitter Text Obj - An Objective-C implementation of Twitter's text processing library. Nimbus - Nimbus is a toolkit for experienced iOS software designers. NSStringEmojize - A category on NSString to convert Emoji Cheat Sheet codes to their equivalent Unicode characters. MMMarkdown - An Objective-C static library for converting Markdown to HTML. DTCoreText - Methods to allow using HTML code with CoreText. DTRichTextEditor - A rich-text editor for iOS. NBEmojiSearchView - A searchable emoji dropdown view. Pluralize.swift - Great Swift String Pluralize Extension. RichEditorView - RichEditorView is a simple, modular, drop-in UIView subclass for Rich Text Editing. Money - Swift value types for working with money & currency. PhoneNumberKit - A Swift framework for parsing, formatting and validating international phone numbers. Inspired by Google's libphonenumber. YYText - Powerful text framework for iOS to display and edit rich text. Format - A Swift Formatter Kit. Tribute - Programmatic creation of NSAttributedString doesn't have to be a pain. EmojiKit - Effortless emoji-querying in Swift. Roman - Seamless Roman numeral conversion in Swift. ZSSRichTextEditor - A beautiful rich text WYSIWYG editor for iOS with a syntax highlighted source view. pangu.Objective-C - Paranoid text spacing in Objective-C. SwiftString - A comprehensive, lightweight string extension for Swift. Marklight - Markdown syntax highlighter for iOS. MarkdownTextView - Rich Markdown editing control for iOS. TextAttributes - An easier way to compose attributed strings. Reductio - Automatic summarizer text in Swift. SmarkDown - A Pure Swift implementation of the markdown mark-up language. SwiftyMarkdown - Converts Markdown files and strings into NSAttributedString. SZMentions - Library to help handle mentions. SZMentionsSwift - Library to help handle mentions. Heimdall - Heimdall is a wrapper around the Security framework for simple encryption/decryption operations. NoOptionalInterpolation - Get rid of "Optional(...)" and "nil" in string interpolation. Easy pluralization. Smile Emoji in Swift. ISO8601 Super lightweight ISO8601 Date Formatter in Swift. Translucid - Lightweight library to set an Image as text background. FormatterKit - stringWithFormat: for the sophisticated hacker set. BonMot - Beautiful, easy attributed strings in Swift. SwiftValidators - String validation for iOS developed in Swift. Inspired by validator.js. StringStylizer - Type strict builder class for NSAttributedString. SwiftyAttributes - Swift extensions that make it a breeze to work with attributed strings. MarkdownKit - A simple and customizable Markdown Parser for Swift. CocoaMarkdown - Markdown parsing and rendering for iOS and macOS. Notepad - A fully themeable markdown editor with live syntax highlighting. KKStringValidator - Fast and simple string validation for iOS. With UITextField extension. ISO8859 - Convert ISO8859 1-16 Encoded Text to String in Swift. Supports iOS, tvOS, watchOS and macOS. Emojica - Replace standard emoji in strings with a custom emoji set, such as Twemoji or EmojiOne. SwiftRichString - Elegant & Painless Attributed Strings Management Library in Swift. libPhoneNumber-iOS - iOS port from libphonenumber (Google's phone number handling library). AttributedTextView - Easiest way to create an attributed UITextView with support for multiple links (including hashtags and mentions). StyleDecorator - Design string simply by linking attributes to needed parts. Mustard - Mustard is a Swift library for tokenizing strings when splitting by whitespace doesn't cut it. Input Mask - Pattern-based user input formatter, parser and validator for iOS. Attributed - Modern Swift framework for attributed strings. Atributika - Easily build NSAttributedString by detecting and styling HTML-like tags, hashtags, mentions, RegExp or NSDataDetector patterns. Guitar - A Cross-Platform String Library Written in Swift. RealTimeCurrencyFormatter - An ObjC international currency formatting utility. Down - Blazing fast Markdown rendering in Swift, built upon cmark. Marky Mark - Highly customizable Markdown parsing and native rendering in Swift. MarkdownView - Markdown View for iOS. Highlighter - Highlight whatever you want! Highlighter will magically find UI objects such as UILabel, UITextView, UITexTfield, UIButton in your UITableViewCell or other Class. Sprinter - A library for formatting strings on iOS and macOS. Highlightr - An iOS & macOS syntax highlighter, supports 176 languages and comes with 79 styles. fuse-swift - A lightweight fuzzy-search library, with zero dependencies. EFMarkdown - A lightweight Markdown library for iOS. Croc - A lightweight Swift library for Emoji parsing and querying. PostalCodeValidator - A validator for postal codes with support for 200+ regions. CodeMirror Swift - A lightweight wrapper of CodeMirror for macOS and iOS. Support Syntax Highlighting & Themes. TwitterTextEditor - A standalone, flexible API that provides a full featured rich text editor for iOS applications. Font FontBlaster - Programmatically load custom fonts into your iOS app. GoogleMaterialIconFont - Google Material Design Icons for Swift and ObjC project. ios-fontawesome - NSString+FontAwesome. FontAwesome.swift - Use FontAwesome in your Swift projects. SwiftFontName - OS font complements library. Localized font supported. SwiftIconFont - Icons fonts for iOS (FontAwesome, Iconic, Ionicon, Octicon, Themify, MapIcon, MaterialIcon). FontAwesomeKit - Icon font library for iOS. Currently supports Font-Awesome, Foundation icons, Zocial, and ionicons. Iconic - Auto-generated icon font library for iOS, watchOS and tvOS. GoogleMaterialDesignIcons - Google Material Design Icons Font for iOS. OcticonsKit - Use Octicons as UIImage / UIFont in your projects with Swifty manners. IoniconsKit - Use Ionicons as UIImage / UIFont in your projects with Swifty manners. FontAwesomeKit.Swift - A better choice for iOS Developer to use FontAwesome Icon. UIFontComplete - Font management (System & Custom) for iOS and tvOS. Swicon - Use 1600+ icons (and more!) from FontAwesome and Google Material Icons in your swift/iOS project in an easy and space-efficient way! SwiftIcons - A library for using different font icons: dripicons, emoji, font awesome, icofont, ionicons, linear icons, map icons, material icons, open iconic, state, weather. It supports UIImage, UIImageView, UILabel, UIButton, UISegmentedControl, UITabBarItem, UISlider, UIBarButtonItem, UIViewController, UITextfield, UIStepper. Font-Awesome-Swift - Font Awesome swift library for iOS. JQSwiftIcon - Icon Fonts on iOS using string interpolation written in Swift. Money - A precise, type-safe representation of a monetary amount in a given currency. Testing TDD / BDD Kiwi - A behavior-driven development library for iOS development. Specta - A light-weight TDD / BDD framework for Objective-C & Cocoa. Quick - A behavior-driven development framework for Swift and Objective-C. XcodeCoverage - Code coverage for Xcode projects. OHHTTPStubs - Stub your network requests easily! Test your apps with fake network data and custom response time, response code and headers! Dixie - Dixie is an open source Objective-C testing framework for altering object behaviours. gh-unit - Test Framework for Objective-C. Nimble - A Matcher Framework for Swift and Objective-C Sleipnir - BDD-style framework for Swift. SwiftCheck - QuickCheck for Swift. Spry - A Mac and iOS Playgrounds Unit Testing library based on Nimble. swift-corelibs-xctest - The XCTest Project, A Swift core library for providing unit test support. PlaygroundTDD - Small library to easily run your tests directly within a Playground. A/B Testing Switchboard - Switchboard - easy and super light weight A/B testing for your mobile iPhone or android app. This mobile A/B testing framework allows you with minimal servers to run large amounts of mobile users. SkyLab - Multivariate & A/B Testing for iOS and Mac. MSActiveConfig - Remote configuration and A/B Testing framework for iOS. ABKit - AB testing framework for iOS. UI Testing appium - Appium is an open source test automation framework for use with native and hybrid mobile apps. robotframework-appiumlibrary - AppiumLibrary is an appium testing library for RobotFramework. Cucumber - Behavior driver development for iOS. Kif - An iOS Functional Testing Framework. Subliminal - An understated approach to iOS integration testing. ios-driver - Test any iOS native, hybrid, or mobile web application using Selenium / WebDriver. Remote - Control your iPhone from inside Xcode for end-to-end testing. LayoutTest-iOS - Write unit tests which test the layout of a view in multiple configurations. EarlGrey - :tea: iOS UI Automation Test Framework. UI Testing Cheat Sheet - How do I test this with UI Testing? Bluepill - Bluepill is a reliable iOS testing tool that runs UI tests using multiple simulators on a single machine. Flawless App - tool for visual quality check of mobile app in a real-time. It compares initial design with the actual implementation right inside iOS simulator. TouchVisualizer - Lightweight touch visualization library in Swift. A single line of code and visualize your touches! UITestHelper - UITest helper library for creating readable and maintainable tests. ViewInspector - Runtime inspection and unit testing of SwiftUI views AutoMate - XCTest extensions for writing UI automation tests. Other Testing NaughtyKeyboard - The Big List of Naughty Strings is a list of strings which have a high probability of causing issues when used as user-input data. This is a keyboard to help you test your app from your iOS device. Fakery - Swift fake data generator. DVR - Network testing for Swift. Cuckoo - First boilerplate-free mocking framework for Swift. Vinyl - Network testing la VCR in Swift. Mockit - A simple mocking framework for Swift, inspired by the famous Mockito for Java. Cribble - Swifty tool for visual testing iPhone and iPad apps. second_curtain - Upload failing iOS snapshot tests cases to S3. trainer - Convert xcodebuild plist files to JUnit reports. Buildasaur - Automatic testing of your Pull Requests on GitHub and BitBucket using Xcode Server. Keep your team productive and safe. Get up and running in minutes. Kakapo - Dynamically Mock server behaviors and responses in Swift. AcceptanceMark Tool to auto-generate Xcode tests classes from Markdown tables. MetovaTestKit - A collection of testing utilities to turn crashing test suites into failing test suites. MirrorDiffKit - Pretty diff between any structs or classes. SnappyTestCase - iOS Simulator type agnostic snapshot testing, built on top of the FBSnapshotTestCase. XCTestExtensions - XCTestExtensions is a Swift extension that provides convenient assertions for writing Unit Test. OCMock - Mock objects for Objective-C. Mockingjay - An elegant library for stubbing HTTP requests with ease in Swift. PinpointKit - Let your testers and users send feedback with annotated screenshots and logs using a simple gesture. iOS Snapshot Test Case Snapshot test your UIViews and CALayers on iOS and tvOS. DataFixture - Creation of data model easily, with no headache. SnapshotTesting - Delightful Swift snapshot testing. Mockingbird - Simplify software testing, by easily mocking any system using HTTP/HTTPS, allowing a team to test and develop against a service that is not complete, unstable or just to reproduce planned cases. UI Motif - A lightweight and customizable JSON stylesheet framework for iOS. Texture - Smooth asynchronous user interfaces for iOS apps. GaugeKit - Customizable gauges. Easy reproduce Apple's style gauges. iCarousel - A simple, highly customisable, data-driven 3D carousel for iOS and Mac OS. HorizontalDial - A horizontal scroll dial like Instagram. ComponentKit - A React-Inspired View Framework for iOS, by Facebook. RKNotificationHub - Make any UIView a full fledged notification center. phone-number-picker - A simple and easy to use view controller enabling you to enter a phone number with a country code similar to WhatsApp written in Swift. BEMCheckBox - Tasteful Checkbox for iOS. MPParallaxView - Apple TV Parallax effect in Swift. Splitflap - A simple split-flap display for your Swift applications. EZSwipeController - UIPageViewController like Snapchat/Tinder/iOS Main Pages. Curry - Curry is a framework built to enhance and compliment Foundation and UIKit. Pages - UIPageViewController made simple. BAFluidView - UIView that simulates a 2D view of a fluid in motion. WZDraggableSwitchHeaderView - Showing status for switching between viewControllers. SCTrelloNavigation - An iOS native implementation of a Trello Animated Navagation. Spots - Spots is a view controller framework that makes your setup and future development blazingly fast. AZExpandableIconListView - An expandable/collapsible view component written in Swift. FlourishUI - A highly configurable and out-of-the-box-pretty UI library. Navigation Stack - Navigation Stack is a stack-modeled navigation controller. UIView-draggable - UIView category that adds dragging capabilities. EPSignature - Signature component for iOS in Swift. EVFaceTracker - Calculate the distance and angle of your device with regards to your face. LeeGo - Declarative, configurable & highly reusable UI development as making Lego bricks. MEVHorizontalContacts - An iOS UICollectionViewLayout subclass to show a list of contacts with configurable expandable menu items. VisualEffectView - UIVisualEffectView subclass with tint color. Cacao - Pure Swift Cross-platform UIKit (Cocoa Touch) implementation (Supports Linux). JDFlipNumberView - Representing analog flip numbers like airport/trainstation displays. DCKit - Set of iOS controls, which have useful IBInspectable properties. Written on Swift. BackgroundVideoiOS - A swift and objective-C object that lets you add a background video to iOS views. NightNight - Elegant way to integrate night mode to swift projects. SwiftTheme - Powerful theme/skin manager for iOS. FDStackView - Use UIStackView directly in iOS. RedBeard - It's a complete framework that takes away much of the pain of getting a beautiful, powerful iOS App crafted. Material - Material is an animation and graphics framework that allows developers to easily create beautiful applications. DistancePicker - Custom control to select a distance with a pan gesture, written in Swift. OAStackView - OAStackView tries to port back the stackview to iOS 7+. OAStackView aims at replicating all the features in UIStackView. PageController - Infinite paging controller, scrolling through contents and title bar scrolls with a delay. StatusProvider - Protocol to handle initial Loadings, Empty Views and Error Handling in a ViewController & views. StackLayout - An alternative to UIStackView for common Auto Layout patterns. NightView - Dazzling Nights on iOS. SwiftVideoBackground - Easy to Use UIView subclass for implementing a video background. ConfettiView - Confetti View lets you create a magnificent confetti view in your app. BouncyPageViewController - Page view controller with bounce effect. LTHRadioButton - A radio button with a pretty fill animation. Macaw-Examples - Various usages of the Macaw library. Reactions - Fully customizable Facebook reactions control. Newly - Newly is a drop in solution to add Twitter/Facebook/Linkedin-style new updates/tweets/posts available button. CardStackController - iOS custom controller used in Jobandtalent app to present new view controllers as cards. Material Components - Google developed UI components that help developers execute Material Design. FAQView - An easy to use FAQ view for iOS written in Swift. LMArticleViewController - UIViewController subclass to beautifully present news articles and blog posts. FSPagerView - FSPagerView is an elegant Screen Slide Library. It is extremely helpful for making BannerProduct ShowWelcome/Guide PagesScreen/ViewController Sliders. ElongationPreview - ElongationPreview is an elegant push-pop style view controller with 3D-Touch support and gestures. Pageboy - A simple, highly informative page view controller. IGColorPicker - A customizable color picker for iOS in Swift. KPActionSheet - A replacement of default action sheet, but has very simple usage. SegmentedProgressBar - Snapchat / Instagram Stories style animated indicator. Magnetic - SpriteKit Floating Bubble Picker (inspired by Apple Music). AmazingBubbles - Apple Music like Bubble Picker using Dynamic Animation. Haptica - Easy Haptic Feedback Generator. GDCheckbox - An easy to use custom checkbox/radio button component for iOS, with support of IBDesign Inspector. HamsterUIKit - A simple and elegant UIKit(Chart) for iOS. AZEmptyState - A UIControl subclass that makes it easy to create empty states. URWeatherView - Show the weather effects onto view. LCUIComponents - A framework supports creating transient views on top of other content onscreen such as popover with a data list. ViewComposer - let lbl: UILabel = [.text("Hello"), .textColor(.red)] - Create views using array literal of enum expressing view attributes. BatteryView - Simple battery shaped UIView. ShadowView - Make shadows management easy on UIView. Pulley - A library to imitate the iOS 10 Maps UI. N8iveKit - A set of frameworks making iOS development more fun. Panda - Create view hierarchies declaratively. NotchKit - A simple way to hide the notch on the iPhone X Overlay - Overlay is a flexible UI framework designed for Swift. It allows you to write CSS like Swift code. SwiftyUI - High performance and lightweight(one class each UI) UIView, UIImage, UIImageView, UIlabel, UIButton, Promise and more. NotchToolkit - A framework for iOS that allow developers use the iPhone X notch in creative ways. PullUpController - Pull up controller with multiple sticky points like in iOS Maps. DrawerKit - DrawerKit lets an UIViewController modally present another UIViewController in a manner similar to the way Apple's Maps app works. Shades - Easily add drop shadows, borders, and round corners to a UIView. ISPageControl - A page control similar to that used in Instagram. Mixin - React.js like Mixin. More powerful Protocol-Oriented Programming. Shiny - Iridescent Effect View (inspired by Apple Pay Cash). StackViewController - A controller that uses a UIStackView and view controller composition to display content in a list. UberSignature - Provides an iOS view controller allowing a user to draw their signature with their finger in a realistic style. SwViewCapture - A nice iOS View Capture Swift Library which can capture all content. HGRippleRadarView - A beautiful radar view to show nearby items (users, restaurants, ...) with ripple animation, fully customizable. GDGauge - Full Customizable, Beautiful, Easy to use gauge view Edit. STAControls - Handy UIControl subclasses. (Think Three20/NimbusKit of UIControls.) Written in Objective-C. ApplyStyleKit - Elegant apply style, using Swift Method Chain. OverlayContainer - A library to develop overlay based interfaces, such as the one presented in the iOS 12 Apple Maps or Stocks apps. ClassicKit - A collection of classic-style UI components for iOS. Sejima - A collection of User Interface components for iOS. UI Fabric by Microsoft - UI framework based on Fluent Design System by Microsoft. Activity Indicator NVActivityIndicatorView - Collection of nice loading animations. RPLoadingAnimation - Loading animations by using Swift CALayer. LiquidLoader - Spinner loader components with liquid animation. iOS-CircleProgressView - This control will allow a user to use code instantiated or interface builder to create and render a circle progress view. iOS Circle Progress Bar - iOS Circle Progress Bar. LinearProgressBar - Linear Progress Bar (inspired by Google Material Design) for iOS. STLoadingGroup - loading views. ALThreeCircleSpinner - A pulsing spinner view written in swift. MHRadialProgressView - iOS radial animated progress view. Loader - Amazing animated switch activity indicator written in swift. MBProgressHUD - Drop-in class for displays a translucent HUD with an indicator and/or labels while work is being done in a background thread. SVProgressHUD - A clean and lightweight progress HUD for your iOS app. ProgressHUD - ProgressHUD is a lightweight and easy-to-use HUD. M13ProgressSuite - A suite containing many tools to display progress information on iOS. PKHUD - A Swift based reimplementation of the Apple HUD (Volume, Ringer, Rotation,) for iOS 8 and above. EZLoadingActivity - Lightweight loading activity HUD. FFCircularProgressView - FFCircularProgressView - An iOS 7-inspired blue circular progress view. MRProgress - Collection of iOS drop-in components to visualize progress. BigBrother - Automatically sets the network activity indicator for any performed request. AlamofireNetworkActivityIndicator - Controls the visibility of the network activity indicator on iOS using Alamofire. KDCircularProgress - A circular progress view with gradients written in Swift. DACircularProgress - DACircularProgress is a UIView subclass with circular UIProgressView properties. KYNavigationProgress - Simple extension of UINavigationController to display progress on the UINavigationBar. GearRefreshControl - A custom animation for the UIRefreshControl. NJKWebViewProgress - A progress interface library for UIWebView. You can implement progress bar for your in-app browser using this module. MKRingProgressView - A beautiful ring/circular progress view similar to Activity app on Apple Watch, written in Swift. Hexacon - A new way to display content in your app like the Apple Watch SpringBoard, written in Swift. ParticlesLoadingView - A customizable SpriteKit particles animation on the border of a view. RPCircularProgress - (Swift) Circular progress UIView subclass with UIProgressView properties. MBCircularProgressBar - A circular, animatable & highly customizable progress bar, editable from the Interface Builder using IBDesignable. WSProgressHUD - This is a beautiful hud view for iPhone & iPad. DBMetaballLoading - A metaball loading written in Swift. FillableLoaders - Completely customizable progress based loaders drawn using custom CGPaths written in Swift. VHUD Simple HUD. SwiftSpinner - A beautiful activity indicator and modal alert written in Swift using blur effects, translucency, flat and bold design. SnapTimer - Implementation of Snapchat's stories timer. LLSpinner - An easy way to create a full screen activity indicator. SVUploader - A beautiful uploader progress view that makes things simple and easy. YLProgressBar - UIProgressView replacement with an highly and fully customizable animated progress bar in pure Core Graphics. FlexibleSteppedProgressBar - A beautiful easily customisable stepped progress bar. GradientLoadingBar - An animated gradient loading bar. DSGradientProgressView - A simple and customizable animated progress bar written in Swift. GradientProgressBar - A gradient progress bar (UIProgressView). BPCircleActivityIndicator - A lightweight and awesome Loading Activity Indicator for your iOS app. DottedProgressBar - Simple and customizable animated progress bar with dots for iOS. RSLoadingView - Awesome loading animations using 3D engine written with Swift. SendIndicator - Yet another task indicator. StepProgressView - Step-by-step progress view with labels and shapes. A good replacement for UIActivityIndicatorView and UIProgressView. BPBlockActivityIndicator - A simple and awesome Loading Activity Indicator(with funny block animation) for your iOS app. JDBreaksLoading - You can easily start up a little breaking game indicator by one line. SkeletonView - An elegant way to show users that something is happening and also prepare them to which contents he is waiting. Windless - Windless makes it easy to implement invisible layout loading view. Skeleton - An easy way to create sliding CAGradientLayer animations! Works great for creating skeleton screens for loading content. StatusBarOverlay - Automatically show/hide a "No Internet Connection" bar when your app loses/gains connection. It supports apps which hide the status bar and "The Notch". RetroProgress - Retro looking progress bar straight from the 90s. LinearProgressBar - Material Linear Progress Bar for your iOS apps. MKProgress - A lightweight ProgressHUD written in Swift. Looks similar to /MBProgressHUD/SVProgressHUD/KVNProgressHUD. RHPlaceholder - Simple library which give you possibility to add Facebook like loading state for your views. IHProgressHUD - Simple HUD, thread safe, supports iOS, tvOS and App Extensions. ActivityIndicatorView - A number of preset loading indicators created with SwiftUI. Animation Pop - An extensible iOS and macOS animation library, useful for physics-based interactions. AnimationEngine - Easily build advanced custom animations on iOS. RZTransitions - A library of custom iOS View Controller Animations and Interactions. DCAnimationKit - A collection of animations for iOS. Simple, just add water animations. Spring - A library to simplify iOS animations in Swift. Fluent - Swift animation made easy. Cheetah - Easy animation library on iOS. Pop By Example - A project tutorial in how to use Pop animation framework by example. AppAnimations - Collection of iOS animations to inspire your next project. EasyAnimation - A Swift library to take the power of UIView.animateWithDuration() to a whole new level - layers, springs, chain-able animations, and mixing view/layer animations together. Animo - SpriteKit-like animation builders for CALayers. CurryFire - A framework for creating unique animations. IBAnimatable - Design and prototype UI, interaction, navigation, transition and animation for App Store ready Apps in Interface Builder with IBAnimatable. CKWaveCollectionViewTransition - Cool wave like transition between two or more UICollectionView. DaisyChain - Easy animation chaining. PulsingHalo - iOS Component for creating a pulsing animation. DKChainableAnimationKit - Chainable animations in Swift. JDAnimationKit - Animate easy and with less code with Swift. Advance - A powerful animation framework for iOS. UIView-Shake - UIView category that adds shake animation. Walker - A new animation engine for your app. Morgan - An animation set for your app. MagicMove - Keynote-style Magic Move transition animations. Shimmer - An easy way to add a simple, shimmering effect to any view in an iOS app. SAConfettiView - Confetti! Who doesn't like confetti? CCMRadarView - CCMRadarView uses the IBDesignable tools to make an easy customizable radar view with animation. Pulsator - Pulse animation for iOS. Interpolate - Swift interpolation for gesture-driven animations. ADPuzzleAnimation - Custom animation for UIView inspired by Fabric - Answers animation. Wave - :ocean: Declarative chainable animations in Swift. Stellar - A fantastic Physical animation library for swift. MotionMachine - A powerful, elegant, and modular animation library for Swift. JRMFloatingAnimation - An Objective-C animation library used to create floating image views. AHKBendableView - UIView subclass that bends its edges when its position changes. FlightAnimator - Advanced Natural Motion Animations, Simple Blocks Based Syntax. ZoomTransitioning - A custom transition with image zooming animation. Ubergang - A tweening engine for iOS written in Swift. JHChainableAnimations - Easy to read and write chainable animations in Objective-C. Popsicle - Delightful, extensible Swift value interpolation framework. WXWaveView - Add a pretty water wave to your view. Twinkle - Swift and easy way to make elements in your iOS and tvOS app twinkle. MotionBlur - MotionBlur allows you to add motion blur effect to iOS animations. RippleEffectView - RippleEffectView - A Neat Rippling View Effect. SwiftyAnimate - Composable animations in Swift. SamuraiTransition - Swift based library providing a collection of ViewController transitions featuring a number of neat cutting animations. Lottie - An iOS library for a real time rendering of native vector animations from Adobe After Effects. anim - An animation library for iOS with custom easings and easy to follow API. AnimatedCollectionViewLayout - A UICollectionViewLayout subclass that adds custom transitions/animations to the UICollectionView. Dance - A radical & elegant animation library built for iOS. AKVideoImageView - UIImageView subclass which allows you to display a looped video as a background. Spruce iOS Animation Library - Swift library for choreographing animations on the screen. CircularRevealKit - UI framework that implements the material design's reveal effect. TweenKit - Animation library for iOS in Swift. Water - Simple calculation to render cheap water effects. Pastel - Gradient animation effect like Instagram. YapAnimator - Your fast and friendly physics-based animation system. Bubble - Fruit Animation. Gemini - Gemini is rich scroll based animation framework for iOS, written in Swift. WaterDrops - Simple water drops animation for iOS in Swift. ViewAnimator - ViewAnimator brings your UI to life with just one line. Ease - Animate everything with Ease. Kinieta - An Animation Engine with Custom Bezier Easing, an Intuitive API and perfect Color Intepolation. LSAnimator - Easy to Read and Write Multi-chain Animations Kit in Objective-C and Swift. YetAnotherAnimationLibrary - Designed for gesture-driven animations. Fast, simple, & extensible! Anima - Anima is chainable Layer-Based Animation library for Swift4. MotionAnimation - Lightweight animation library for UIKit. AGInterfaceInteraction - library performs interaction with UI interface. PMTween - An elegant and flexible tweening library for iOS. VariousViewsEffects - Animates views nicely with easy to use extensions. TheAnimation - Type-safe CAAnimation wrapper. It makes preventing to set wrong type values. Poi - Poi makes you use card UI like tinder UI .You can use it like tableview method. Sica - Simple Interface Core Animation. Run type-safe animation sequencially or parallelly. fireworks - Fireworks effect for UIView Disintegrate - Disintegration animation inspired by THAT thing Thanos did at the end of Avengers: Infinity War. Wobbly - Wobbly is a Library of predefined, easy to use iOS animations. LoadingShimmer - An easy way to add a shimmering effect to any view with just one line of code. It is useful as an unobtrusive loading indicator. Transition BlurryModalSegue - A custom modal segue for providing a blurred overlay effect. DAExpandAnimation - A custom modal transition that presents a controller with an expanding effect while sliding out the presenter remnants. BubbleTransition - A custom modal transition that presents and dismiss a controller with an expanding bubble effect. RPModalGestureTransition - You can dismiss modal by using gesture. RMPZoomTransitionAnimator - A custom zooming transition animation for UIViewController. ElasticTransition - A UIKit custom transition that simulates an elastic drag. Written in Swift. ElasticTransition-ObjC - A UIKit custom transition that simulates an elastic drag.This is the Objective-C Version of Elastic Transition written in Swift by lkzhao. ZFDragableModalTransition - Custom animation transition for present modal view controller. ZOZolaZoomTransition - Zoom transition that animates the entire view hierarchy. Used extensively in the Zola iOS application. JTMaterialTransition - An iOS transition for controllers based on material design. AnimatedTransitionGallery - Collection of iOS 7 custom animated transitions using UIViewControllerAnimatedTransitioning protocol. TransitionTreasury - Easier way to push your viewController. Presenter - Screen transition with safe and clean code. Kaeru - Switch viewcontroller like iOS task manager. View2ViewTransition - Custom interactive view controller transition from one view to another view. AZTransitions - API to make great custom transitions in one method. Hero - Elegant transition library for iOS & tvOS. Motion - Seamless animations and transitions in Swift. PresenterKit - Swifty view controller presentation for iOS. Transition - Easy interactive interruptible custom ViewController transitions. Gagat - A delightful way to transition between visual styles in your iOS applications. DeckTransition - A library to recreate the iOS Apple Music now playing transition. TransitionableTab - TransitionableTab makes it easy to animate when switching between tab. AlertTransition - AlertTransition is a extensible library for making view controller transitions, especially for alert transitions. SemiModalViewController - Present view / view controller as bottom-half modal. ImageTransition - ImageTransition is a library for smooth animation of images during transitions. LiquidTransition - removes boilerplate code to perform transition, allows backward animations, custom properties animation and much more! SPStorkController - Very similar to the controllers displayed in Apple Music, Podcasts and Mail Apple's applications. AppstoreTransition - Simulates the appstore card animation transition. DropdownTransition - Simple and elegant Dropdown Transition for presenting controllers from top to bottom. Alert & Action Sheet SweetAlert - Live animated Alert View for iOS written in Swift. NYAlertViewController - Highly configurable iOS Alert Views with custom content views. SCLAlertView-Swift - Beautiful animated Alert View, written in Swift. TTGSnackbar - Show simple message and action button on the bottom of the screen with multi kinds of animation. Swift-Prompts - A Swift library to design custom prompts with a great scope of options to choose from. BRYXBanner - A lightweight dropdown notification for iOS 7+, in Swift. LNRSimpleNotifications - Simple Swift in-app notifications. LNRSimpleNotifications is a simplified Swift port of TSMessages. HDNotificationView - Emulates the native Notification Banner UI for any alert. JDStatusBarNotification - Easy, customizable notifications displayed on top of the statusbar. Notie - In-app notification in Swift, with customizable buttons and input text field. EZAlertController - Easy Swift UIAlertController. GSMessages - A simple style messages/notifications for iOS 7+. OEANotification - In-app customizable notification views on top of screen for iOS which is written in Swift 2.1. RKDropdownAlert - Extremely simple UIAlertView alternative. TKSwarmAlert - Animated alert library like Swarm app. SimpleAlert - Customizable simple Alert and simple ActionSheet for Swift. Hokusai - A Swift library to provide a bouncy action sheet. SwiftNotice - SwiftNotice is a GUI library for displaying various popups (HUD) written in pure Swift, fits any scrollview. SwiftOverlays - SwiftOverlays is a Swift GUI library for displaying various popups and notifications. SwiftyDrop - SwiftyDrop is a lightweight pure Swift simple and beautiful dropdown message. LKAlertController - An easy to use UIAlertController builder for swift. DOAlertController - Simple Alert View written in Swift, which can be used as a UIAlertController. (AlertController/AlertView/ActionSheet). CustomizableActionSheet - Action sheet allows including your custom views and buttons. Toast-Swift - A Swift extension that adds toast notifications to the UIView object class. PMAlertController - PMAlertController is a great and customizable substitute to UIAlertController. PopupViewController - UIAlertController drop in replacement with much more customization. AlertViewLoveNotification - A simple and attractive AlertView to ask permission to your users for Push Notification. CRToast - A modern iOS toast view that can fit your notification needs. JLToast - Toast for iOS with very simple interface. CuckooAlert - Multiple use of presentViewController for UIAlertController. KRAlertController - A colored alert view for your iOS. Dodo - A message bar for iOS written in Swift. MaterialActionSheetController - A Google like action sheet for iOS written in Swift. SwiftMessages - A very flexible message bar for iOS written in Swift. FCAlertView - A Flat Customizable AlertView for iOS. (Swift). FCAlertView - A Flat Customizable AlertView for iOS. (Objective-C). CDAlertView - Highly customizable alert/notification/success/error/alarm popup. RMActionController - Present any UIView in an UIAlertController like manner. RMDateSelectionViewController - Select a date using UIDatePicker in a UIAlertController like fashion. RMPickerViewController - Select something using UIPickerView in a UIAlertController like fashion. Jelly - Jelly provides custom view controller transitions with just a few lines of code. Malert - Malert is a simple, easy and custom iOS UIAlertView written in Swift. RAlertView - AlertView, iOS popup window, A pop-up framework, Can be simple and convenient to join your project. NoticeBar - A simple NoticeBar written by Swift 3, similar with QQ notice view. LIHAlert - Advance animated banner alerts for iOS. BPStatusBarAlert - A simple alerts that appear on the status bar and below navigation bar(like Facebook). CFAlertViewController - A library that helps you display and customise alerts and action sheets on iPad and iPhone. NotificationBanner - The easiest way to display highly customizable in app notification banners in iOS. Alertift - Swifty, modern UIAlertController wrapper. PCLBlurEffectAlert - Swift AlertController with UIVisualEffectView. JDropDownAlert - Multi dirction dropdown alert view. BulletinBoard - Generate and Display Bottom Card Interfaces on iOS CFNotify - A customizable framework to create draggable views. StatusAlert - Display Apple system-like self-hiding status alerts without interrupting user flow. Alerts & Pickers - Advanced usage of native UIAlertController with TextField, DatePicker, PickerView, TableView and CollectionView. RMessage - A crisp in-app notification/message banner built in ObjC. InAppNotify - Swift library to manage in-app notification in swift language, like WhatsApp, Telegram, Frind, etc. FloatingActionSheetController - FloatingActionSheetController is a cool design ActionSheetController library written in Swift. TOActionSheet - A custom-designed reimplementation of the UIActionSheet control for iOS XLActionController - Fully customizable and extensible action sheet controller written in Swift. PopMenu - A cool and customizable popup style action sheet NotchyAlert - Use the iPhone X notch space to display creative alerts. Sheet - SHEET helps you easily create a wide variety of action sheets with navigation features used in the Flipboard App ALRT - An easier constructor for UIAlertController. Present an alert from anywhere. CatAlertController - Use UIAlertController like a boss. Loaf - A simple framework for easy iOS Toasts. SPAlert - Native popup from Apple Music & Feedback in AppStore. Contains Done & Heart presets. CleanyModal - Use nice customized alerts and action sheets with ease, API is similar to native UIAlertController. Badge MIBadgeButton - Notification badge for UIButtons. EasyNotificationBadge - UIView extension that adds a notification badge. e swift-badge - Badge view for iOS written in swift BadgeHub - Make any UIView a full fledged animated notification center. It is a way to quickly add a notification badge icon to a UIView. Button SSBouncyButton - iOS7-style bouncy button UI component. DOFavoriteButton - Cute Animated Button written in Swift. VBFPopFlatButton - Flat button with 9 different states animated using Facebook POP. HTPressableButton - Flat design pressable button. LiquidFloatingActionButton - Material Design Floating Action Button in liquid state JTFadingInfoView - An UIButton-based view with fade in/out animation features. Floaty - :heart: Floating Action Button for iOS TVButton - Recreating the cool parallax icons from Apple TV as iOS UIButtons (in Swift). SwiftyButton - Simple and customizable button in Swift AnimatablePlayButton - Animated Play and Pause Button using CALayer, CAKeyframeAnimation. gbkui-button-progress-view - Inspired by Apples download progress buttons in the App Store. ZFRippleButton - Custom UIButton effect inspired by Google Material Design JOEmojiableBtn - Emoji selector like Facebook Reactions. EMEmojiableBtn - Option selector that works similar to Reactions by fb. Objective-c version. WYMaterialButton - Interactive and fully animated Material Design button for iOS developers. DynamicButton - Yet another animated flat buttons in Swift OnOffButton - Custom On/Off Animated UIButton, written in Swift. By Creativedash WCLShineButton - This is a UI lib for iOS. Effects like shining. EasySocialButton - An easy way to create beautiful social authentication buttons. NFDownloadButton - Revamped Download Button. LGButton - A fully customisable subclass of the native UIControl which allows you to create beautiful buttons without writing any line of code. MultiToggleButton - A UIButton subclass that implements tap-to-toggle button text (Like the camera flash and timer buttons). PMSuperButton - A powerful UIButton with super powers, customizable from Storyboard! JSButton - A fully customisable swift subclass on UIButton which allows you to create beautiful buttons without writing any line of code. TransitionButton - UIButton sublass for loading and transition animation ButtonProgressBar-iOS - A small and flexible UIButton subclass with animated loading progress, and completion animation. SpicyButton - Full-featured IBDesignable UIButton class DesignableButton - UIButton subclass with centralised and reusable styles. View styles and customise in InterfaceBuilder in real time! BEMCheckBox - Tasteful Checkbox for iOS. (Check box) ExpandableButton - Customizable and easy to use expandable button in Swift. TORoundedButton - A high-performance button control with rounded corners. FloatingButton - Easily customizable floating button menu created with SwiftUI. Calendar CVCalendar - A custom visual calendar for iOS 8+ written in Swift (2.0). RSDayFlow - iOS 7+ Calendar with Infinite Scrolling. NWCalendarView - An availability calendar implementation for iOS GLCalendarView - A fully customizable calendar view acting as a date range picker JTCalendar - A customizable calendar view for iOS. JTAppleCalendar - The Unofficial Swift Apple Calendar Library. View. Control. for iOS & tvOS Daysquare - An elegant calendar control for iOS. ASCalendar - A calendar control for iOS written in swift with mvvm pattern Calendar - A set of views and controllers for displaying and scheduling events on iOS Koyomi - Simple customizable calendar component in Swift DateTimePicker - A nicer iOS UI component for picking date and time RCalendarPicker - RCalendarPicker A date picker control. CalendarKit - Fully customizable calendar day view. GDPersianCalendar - Customizable and easy to use Persian Calendar component. MBCalendarKit - A calendar framework for iOS built with customization, and localization in mind. PTEventView - An Event View based on Apple's Event Detail View within Calender.Supports ARC, Autolayout and editing via StoryBoard. KDCalendarView - A calendar component for iOS written in Swift 4.0. It features both vertical and horizontal layout (and scrolling) and the display of native calendar events. CalendarPopUp - CalendarPopUp - JTAppleCalendar library. ios_calendar - It's lightweight and simple control with supporting Locale and CalendarIdentifier. There're samples for iPhone and iPad, and also with using a popover. With supporting Persian calendar FSCalendar - A fully customizable iOS calendar library, compatible with Objective-C and Swift. ElegantCalendar - The elegant full-screen calendar missed in SwiftUI. Cards Card based UI's, pan gestures, flip and swipe animations MDCSwipeToChoose - Swipe to "like" or "dislike" any view, just like Tinder.app. Build a flashcard app, a photo viewer, and more, in minutes, not hours! TisprCardStack - Library that allows to have cards UI. CardAnimation - Card flip animation by pan gesture. Koloda - KolodaView is a class designed to simplify the implementation of Tinder like cards on iOS. KVCardSelectionVC - Awesome looking Dial like card selection ViewController. DMSwipeCards - Tinder like card stack that supports lazy loading and generics TimelineCards - Presenting timelines as cards, single or bundled in scrollable feed!. Cards - Awesome iOS 11 AppStore's Card Views. MMCardView - Custom CollectionView like Wallet App CardsLayout - Nice card-designed custom collection view layout. CardParts - A reactive, card-based UI framework built on UIKit. VerticalCardSwiper - A marriage between the Shazam Discover UI and Tinder, built with UICollectionView in Swift. Shuffle - A multi-directional card swiping library inspired by Tinder Form & Settings Input validators, form helpers and form builders. Form - The most flexible and powerful way to build a form on iOS XLForm - XLForm is the most flexible and powerful iOS library to create dynamic table-view forms. Fully compatible with Swift & Obj-C. Eureka - Elegant iOS form builder in Swift. YALField - Custom Field component with validation for creating easier form-like UI from interface builder. Former - Former is a fully customizable Swift2 library for easy creating UITableView based form. SwiftForms - A small and lightweight library written in Swift that allows you to easily create forms. Formalist - Declarative form building framework for iOS SwiftyFORM - SwiftyFORM is a form framework for iOS written in Swift SwiftValidator - A rule-based validation library for Swift GenericPasswordRow - A row for Eureka to implement password validations. formvalidator-swift - A framework to validate inputs of text fields and text views in a convenient way. ValidationToolkit - Lightweight framework for input validation written in Swift. ATGValidator - Rule based validation framework with form and card validation support for iOS. ValidatedPropertyKit - Easily validate your Properties with Property Wrappers. FDTextFieldTableViewCell - Adds a UITextField to the cell and places it correctly. Keyboard RSKKeyboardAnimationObserver - Showing / dismissing keyboard animation in simple UIViewController category. RFKeyboardToolbar - This is a flexible UIView and UIButton subclass to add customized buttons and toolbars to your UITextFields/UITextViews. IQKeyboardManager - Codeless drop-in universal library allows to prevent issues of keyboard sliding up and cover UITextField/UITextView. NgKeyboardTracker - Objective-C library for tracking keyboard in iOS apps. MMNumberKeyboard - A simple keyboard to use with numbers and, optionally, a decimal point. KeyboardObserver - For less complicated keyboard event handling. TPKeyboardAvoiding - A drop-in universal solution for moving text fields out of the way of the keyboard in iOS YYKeyboardManager - iOS utility class allows you to access keyboard view and track keyboard animation. KeyboardMan - KeyboardMan helps you make keyboard animation. MakemojiSDK - Emoji Keyboard SDK (iOS) Typist - Small, drop-in Swift UIKit keyboard manager for iOS apps-helps manage keyboard's screen presence and behavior without notification center. KeyboardHideManager - Codeless manager to hide keyboard by tapping on views for iOS written in Swift Toolbar - Awesome autolayout Toolbar. IHKeyboardAvoiding - A drop-in universal solution for keeping any UIView visible when the keyboard is being shown - no more UIScrollViews! NumPad - Number Pad (inspired by Square's design). Ribbon - A simple cross-platform toolbar/custom input accessory view library for iOS & macOS. Label LTMorphingLabel - Graceful morphing effects for UILabel written in Swift. ActiveLabel.swift - UILabel drop-in replacement supporting Hashtags (#), Mentions (@) and URLs (http://) written in Swift MZTimerLabel - A handy class for iOS to use UILabel as a countdown timer or stopwatch just like in Apple Clock App. CountdownLabel - Simple countdown UILabel with morphing animation, and some useful function. IncrementableLabel - Incrementable label for iOS, macOS, and tvOS. TTTAttributedLabel - A drop-in replacement for UILabel that supports attributes, data detectors, links, and more NumberMorphView - A label view for displaying numbers which can transition or animate using a technique called number tweening or number morphing. GlitchLabel - Glitching UILabel for iOS. TOMSMorphingLabel - Configurable morphing transitions between text values of a label. THLabel - UILabel subclass, which additionally allows shadow blur, inner shadow, stroke text and fill gradient. RQShineLabel - Secret app like text animation ZCAnimatedLabel - UILabel replacement with fine-grain appear/disappear animation TriLabelView - A triangle shaped corner label view for iOS written in Swift. Preloader.Ophiuchus - Custom Label to apply animations on whole text or letters. MTLLinkLabel - MTLLinkLabel is linkable UILabel. Written in Swift. UICountingLabel - Adds animated counting support to UILabel. SlidingText - Swift UIView for sliding text with page indicator. NumericAnimatedLabel - Swift UIView for showing numeric label with incremental and decremental step animation while changing value. Useful for scenarios like displaying currency. JSLabel - A simple designable subclass on UILabel with extra IBDesignable and Blinking features. AnimatedMaskLabel - Animated Mask Label is a nice gradient animated label. This is an easy way to add a shimmering effect to any view in your app. STULabel - A label view that's faster than UILabel and supports asynchronous rendering, links with UIDragInteraction, very flexible text truncation, Auto Layout, UIAccessibility and more. Login LFLoginController - Customizable login screen, written in Swift. LoginKit - LoginKit is a quick and easy way to add a Login/Signup UX to your iOS app. Cely - Plug-n-Play login framework written in Swift. Menu ENSwiftSideMenu - A simple side menu for iOS 7/8 written in Swift. RESideMenu - iOS 7/8 style side menu with parallax effect inspired by Dribbble shots. SSASideMenu - A Swift implementation of RESideMenu. A iOS 7/8 style side menu with parallax effect. RadialMenu - RadialMenu is a custom control for providing a touch context menu (like iMessage recording in iOS 8) built with Swift & POP cariocamenu - The fastest zero-tap iOS menu. VLDContextSheet - Context menu similar to the one in the Pinterest iOS app GuillotineMenu - Our Guillotine Menu Transitioning Animation implemented in Swift reminds a bit of a notorious killing machine. MediumMenu - A menu based on Medium iOS app. SwiftySideMenu - SwiftySideMenu is a lightweight and easy to use side menu controller to add left menu and center view controllers with scale animation based on Pop framework. LLSlideMenu - This is a spring slide menu for iOS apps Swift-Slide-Menu - A Slide Menu, written in Swift, inspired by Slide Menu Material Design. MenuItemKit - UIMenuItem with image and block(closure) BTNavigationDropdownMenu - The elegant dropdown menu, written in Swift, appears underneath navigation bar to display a list of related items when a user click on the navigation title. ALRadialMenu - A radial/circular menu featuring spring animations. Written in swift AZDropdownMenu - An easy to use dropdown menu that supports images. CircleMenu - An animated, multi-option menu button. SlideMenuControllerSwift - iOS Slide Menu View based on Google+, iQON, Feedly, Ameba iOS app. It is written in pure Swift. SideMenu - Simple side menu control in Swift inspired by Facebook. Right and Left sides. Lots of customization and animation options. Can be implemented in Storyboard with no code. CategorySliderView - slider view for choosing categories. add any UIView type as category item view. Fully customisable MKDropdownMenu - A Dropdown Menu for iOS with many customizable parameters to suit any needs. ExpandingMenu - ExpandingMenu is menu button for iOS written in Swift. PageMenu - A paging menu controller built from other view controllers placed inside a scroll view (like Spotify, Windows Phone, Instagram) XXXRoundMenuButton - A simple circle style menu. IGCMenu - Grid and Circular menu with animation.Easy to customise. EEJSelectMenu - Single selection menu with cool animations, responsive with all screen sizes. IGLDropDownMenu - An iOS drop down menu with pretty animation and easy to customize. Side-Menu.iOS - Animated side menu with customizable UI PopMenu - PopMenu is pop animation menu inspired by Sina weibo / NetEase app. FlowingMenu - Interactive view transition to display menus with flowing and bouncing effects in Swift Persei - Animated top menu for UITableView / UICollectionView / UIScrollView written in Swift DropDown - A Material Design drop down for iOS KYGooeyMenu - A not bad gooey effects menu. SideMenuController - A side menu controller written in Swift Context-Menu.iOS - You can easily add awesome animated context menu to your app. ViewDeck - An implementation of the sliding functionality found in the Path 2.0 or Facebook iOS apps. FrostedSidebar - Hamburger Menu using Swift and iOS 8 API's VHBoomMenuButton - A menu which can ... BOOM! DropDownMenuKit - A simple, modular and highly customizable UIKit menu, that can be attached to the navigation bar or toolbar, written in Swift. RevealMenuController - Expandable item groups, custom position and appearance animation. Similar to ActionSheet style. RHSideButtons - Library provides easy to implement variation of Android (Material Design) Floating Action Button for iOS. You can use it as your app small side menu. Swift-CircleMenu - Rotating circle menu written in Swift 3. AKSideMenu - Beautiful iOS side menu library with parallax effect. InteractiveSideMenu - Customizable iOS Interactive Side Menu written in Swift 3. YNDropDownMenu - Adorable iOS drop down menu with Swift3. KWDrawerController - Drawer view controller that easy to use! JNDropDownMenu - Easy to use tableview style drop down menu with multi-column support written in Swift3. FanMenu - Menu with a circular layout based on Macaw. AirBar - UIScrollView driven expandable menu written in Swift 3. FAPanels - FAPanels for transition SwipeMenuViewController - Swipable tab and menu View and ViewController. DTPagerController - A fully customizable container view controller to display set of ViewControllers in horizontal scroller PagingKit - PagingKit provides customizable menu UI It has more flexible layout and design than the other libraries. Dropdowns - Dropdown in Swift Parchment - A paging view controller with a highly customizable menu. Built on UICollectionView, with support for custom layouts and infinite data sources. ContextMenu - An iOS context menu UI inspired by Things 3. Panels - Panels is a framework to easily add sliding panels to your application. UIMenuScroll - Creating the horizontal swiping navigation how on Facebook Messenger. CircleBar - A fun, easy-to-use tab bar navigation controller for iOS. SPLarkController - Settings screen with buttons and switches. SwiftyMenu - A Simple and Elegant DropDown menu for iOS Navigation Bar HidingNavigationBar - Easily hide and show a view controller's navigation bar (and tab bar) as a user scrolls KMNavigationBarTransition - A drop-in universal library helps you to manage the navigation bar styles and makes transition animations smooth between different navigation bar styles while pushing or popping a view controller for all orientations. LTNavigationBar - UINavigationBar Category which allows you to change its appearance dynamically BusyNavigationBar - A UINavigationBar extension to show loading effects KDInteractiveNavigationController - A UINavigationController subclass that support pop interactive UINavigationbar with hidden or show. AMScrollingNavbar - Scrollable UINavigationBar that follows the scrolling of a UIScrollView NavKit - Simple and integrated way to customize navigation bar experience on iOS app. RainbowNavigation - An easy way to change backgroundColor of UINavigationBar when Push & Pop TONavigationBar - A simple subclass that adds the ability to set the navigation bar background to 'clear' and gradually transition it visibly back in, similar to the effect in the iOS Music app. PickerView ActionSheetPicker-3.0 - Quickly reproduce the dropdown UIPickerView / ActionSheet functionality on iOS. PickerView - A customizable alternative to UIPickerView in Swift. DatePickerDialog - Date picker dialog for iOS CZPicker - A picker view shown as a popup for iOS. AIDatePickerController - :date: UIDatePicker modally presented with iOS 7 custom transitions. CountryPicker - :date: UIPickerView with Country names flags and phoneCodes McPicker - A customizable, closure driven UIPickerView drop-in solution with animations that is rotation ready. Mandoline - An iOS picker view to serve all your "picking" needs D2PDatePicker - Elegant and Easy-to-Use iOS Swift Date Picker CountryPickerView- A simple, customizable view for efficiently collecting country information in iOS apps planet - A country picker MICountryPicker - Swift country picker with search option. ADDatePicker - A fully customizable iOS Horizontal PickerView library, written in pure swift. SKCountryPicker - A simple, customizable Country picker for picking country or dialing code. Popup MMPopupView - Pop-up based view(e.g. alert sheet), can easily customize. STPopup - STPopup provides a UINavigationController in popup style, for both iPhone and iPad. NMPopUpView - Simple iOS class for showing nice popup windows. Swift and Objective-C versions available. PopupController - A customizable controller for showing temporary popup view. SubscriptionPrompt - Subscription View Controller like the Tinder uses Presentr - Wrapper for custom ViewController presentations in iOS 8+ PopupDialog - A simple, customizable popup dialog for iOS written in Swift. Replaces UIAlertControllers alert style. SelectionDialog - Simple selection dialog. AZDialogViewController - A highly customizable alert dialog controller that mimics Snapchat's alert dialog. MIBlurPopup - MIBlurPopup let you create amazing popups with a blurred background. LNPopupController - a framework for presenting view controllers as popups of other view controllers, much like the Apple Music and Podcasts apps. PopupWindow - PopupWindow is a simple Popup using another UIWindow in Swift. SHPopup - SHPopup is a simple lightweight library for popup view. Popover - Popover is a balloon library like Facebook app. It is written in pure swift. SwiftEntryKit - A highly customizable popups, alerts and banners presenter for iOS. It offers various presets and is written in pure Swift. FFPopup - FFPopup is a lightweight library for presenting custom views as a popup. PopupView - Toasts and popups library written with SwiftUI. ProgressView ProgressMeter - Display the progress on a meter with customized annotations for iOS developed in Swift GradientCircularProgress - Customizable progress indicator library in Swift. Pull to Refresh DGElasticPullToRefresh - Elastic pull to refresh for iOS developed in Swift PullToBounce - Animated "Pull To Refresh" Library for UIScrollView. SVPullToRefresh - Give pull-to-refresh & infinite scrolling to any UIScrollView with 1 line of code. http://samvermette.com/314 UzysAnimatedGifPullToRefresh - Add PullToRefresh using animated GIF to any scrollView with just simple code PullToRefreshCoreText - PullToRefresh extension for all UIScrollView type classes with animated text drawing style BOZPongRefreshControl - A pull-down-to-refresh control for iOS that plays pong, originally created for the MHacks III iOS app CBStoreHouseRefreshControl - Fully customizable pull-to-refresh control inspired by Storehouse iOS app SurfingRefreshControl - Inspired by CBStoreHouseRefreshControl.Customizable pull-to-refresh control,written in pure Swift mntpulltoreact - One gesture, many actions. An evolution of Pull to Refresh. ADChromePullToRefresh - Chrome iOS app style pull to refresh with multiple actions. BreakOutToRefresh - A playable pull to refresh view using SpriteKit. MJRefresh An easy way to use pull-to-refresh. HTPullToRefresh - Easily add vertical and horizontal pull to refresh to any UIScrollView. Can also add multiple pull-to-refesh views at once. PullToRefreshSwift - iOS Simple Cool PullToRefresh Library. It is written in pure swift. GIFRefreshControl - GIFRefreshControl is a pull to refresh that supports GIF images as track animations. ReplaceAnimation - Pull-to-refresh animation in UICollectionView with a sticky header flow layout, written in Swift PullToMakeSoup - Custom animated pull-to-refresh that can be easily added to UIScrollView RainyRefreshControl - Simple refresh control for iOS inspired by concept. ESPullToRefresh - Customisable pull-to-refresh, including nice animation on the top CRRefresh - An easy way to use pull-to-refresh. KafkaRefresh - Animated, customizable, and flexible pull-to-refresh framework for faster and easier iOS development. Rating Stars FloatRatingView - Whole, half or floating point ratings control written in Swift TTGEmojiRate - An emoji-liked rating view for iOS, implemented in Swift. StarryStars - StarryStars is iOS GUI library for displaying and editing ratings Cosmos - A star rating control for iOS / Swift HCSStarRatingView - Simple star rating view for iOS written in Objective-C MBRateApp - A groovy app rate stars screen for iOS written in Swift RPInteraction - Review page interaction - handy and pretty way to ask for review. ScrollView ScrollingFollowView - ScrollingFollowView is a simple view which follows UIScrollView scrolling. UIScrollView-InfiniteScroll - UIScrollView infinite scroll category. GoAutoSlideView - GoAutoSlideView extends UIScrollView by featuring infinitely and automatically slide. AppStoreStyleHorizontalScrollView - App store style horizontal scroll view. PullToDismiss - You can dismiss modal viewcontroller by pulling scrollview or navigationbar in Swift. SpreadsheetView - Full configurable spreadsheet view user interfaces for iOS applications. With this framework, you can easily create complex layouts like schedule, gantt chart or timetable as if you are using Excel. VegaScroll - VegaScroll is a lightweight animation flowlayout for UICollectionView completely written in Swift 4, compatible with iOS 11 and Xcode 9 ShelfView-iOS - iOS custom view to display books on shelf SlideController - SlideController is simple and flexible UI component completely written in Swift. It is a nice alternative for UIPageViewController built using power of generic types. CrownControl - Inspired by the Apple Watch Digital Crown, CrownControl is a tiny accessory view that enables scrolling through scrollable content without lifting your thumb. SegementSlide - Multi-tier UIScrollView nested scrolling solution. Segmented Control BetterSegmentedControl - An easy to use, customizable replacement for UISegmentedControl & UISwitch. LUNSegmentedControl - Customizable segmented control with interactive animation. AKASegmentedControl - :chocolate_bar: Fully customizable Segmented Control for iOS. TwicketSegmentedControl - Custom UISegmentedControl replacement for iOS, written in Swift. SJFluidSegmentedControl - A segmented control with custom appearance and interactive animations. Written in Swift 3.0. HMSegmentedControl - A drop-in replacement for UISegmentedControl mimicking the style of the segmented control used in Google Currents and various other Google products. YUSegment - A customizable segmented control for iOS. Supports both text and image. MultiSelectSegmentedControl - adds Multiple-Selection to the standard UISegmentedControl. DynamicMaskSegmentSwitch - A segment switcher with dynamic text mask effect PinterestSegment - A Pinterest-like segment control with masking animation. DGRunkeeperSwitch - Runkeeper design switch control (two part segment control) Slider VolumeControl - Custom volume control for iPhone featuring a well-designed round slider. WESlider - Simple and light weight slider with chapter management IntervalSlider - IntervalSlider is a slider library like ReutersTV app. written in pure swift. RangeSlider - A simple range slider made in Swift CircleSlider - CircleSlider is a Circular slider library. written in pure Swift. MARKRangeSlider - A custom reusable slider control with 2 thumbs (range slider). ASValueTrackingSlider - A UISlider subclass that displays the slider value in a popup view TTRangeSlider - A slider, similar in style to UISlider, but which allows you to pick a minimum and maximum range. MMSegmentSlider - Customizable animated slider for iOS. StepSlider - StepSlider its custom implementation of slider such as UISlider for preset integer values. JDSlider - An iOS Slider written in Swift. SnappingSlider - A beautiful slider control for iOS built purely upon Swift MTCircularSlider - A feature-rich circular slider control. VerticalSlider - VerticalSlider is a vertical implementation of the UISlider slider control. CircularSlider - A powerful Circular Slider. It's written in Swift, it's 100% IBDesignable and all parameters are IBInspectable. HGCircularSlider - A custom reusable circular slider control for iOS application. RangeSeekSlider - A customizable range slider for iOS. SectionedSlider - Control Center Slider. MultiSlider - UISlider clone with multiple thumbs and values, optional snap intervals, optional value labels. AGCircularPicker - AGCircularPicker is helpful component for creating a controller aimed to manage any calculated parameter. Fluid Slider - A slider widget with a popup bubble displaying the precise value selected. Splash View CBZSplashView - Twitter style Splash Screen View. Grows to reveal the Initial view behind. SKSplashView - Create custom animated splash views similar to the ones in the Twitter, Uber and Ping iOS app. RevealingSplashView - A Splash view that animates and reveals its content, inspired by Twitter splash Status Bar Bartinter - Status bar tint depending on content behind, updates dynamically. Stepper PFStepper - May be the most elegant stepper you have ever had! ValueStepper - A Stepper object that displays its value. GMStepper - A stepper with a sliding label in the middle. barceloneta - The right way to increment/decrement values with a simple gesture on iOS. SnappingStepper - An elegant alternative to the UIStepper written in Swift SMNumberWheel - A custom control written in Swift, which is ideal for picking numbers very fast but yet very accurate using a rotating wheel Switch AnimatedSwitch - UISwitch which paints over the parent view with the color in Swift. ViralSwitch - A UISwitch that infects its superview with its tint color. JTMaterialSwitch - A customizable switch UI with ripple effect and bounce animations, inspired from Google's Material Design. TKSwitcherCollection - An animate switch collection SevenSwitch - iOS7 style drop in replacement for UISwitch. PMZSwitch - Yet another animated toggle Switcher - Swift - Custom UISwitcher with animation when change status RAMPaperSwitch - RAMPaperSwitch is a Swift module which paints over the parent view when the switch is turned on. AIFlatSwitch - A flat component alternative to UISwitch on iOS Switch - An iOS switch control implemented in Swift with full Interface Builder support. Tab Bar ESTabBarController - A tab bar controller for iOS that allows highlighting buttons and setting custom actions to them. GooeyTabbar - A gooey effect tabbar animated-tab-bar - RAMAnimatedTabBarController is a Swift module for adding animation to tabbar items. FoldingTabBar.iOS - Folding Tab Bar and Tab Bar Controller GGTabBar - Another UITabBar & UITabBarController (iOS Tab Bar) replacement, but uses Auto Layout for arranging it's views hierarchy. adaptive-tab-bar - AdaptiveController is a 'Progressive Reduction' Swift module for adding custom states to Native or Custom iOS UI elements Pager - Easily create sliding tabs with Pager XLPagerTabStrip - Android PagerTabStrip for iOS. TabPageViewController - Paging view controller and scroll tab view. TabDrawer - Customizable TabBar UI element that allows you to run a block of code upon TabBarItem selection, written in Swift SwipeViewController - SwipeViewController is a Swift modification of RKSwipeBetweenViewControllers - navigate between pages / ViewControllers ColorMatchTabs - Interesting way to display tabs BATabBarController - A TabBarController with a unique animation for selection ScrollPager - A scroll pager that displays a list of tabs (segments) and manages paging between given views Segmentio - Animated top/bottom segmented control written in Swift. KYWheelTabController - KYWheelTabController is a subclass of UITabBarController.It displays the circular menu instead of UITabBar. SuperBadges - Add emojis and colored dots as badges for your Tab Bar buttons AZTabBarController - A custom tab bar controller for iOS written in Swift 3.0 MiniTabBar - A clean simple alternative to the UITabBar SwipeableTabBarController - UITabBarController with swipe interaction between its tabs. SMSwipeableTabView - Swipeable Views with Tabs (Like Android SwipeView With Tabs Layout) Tabman - A powerful paging view controller with indicator bar for iOS. WormTabStrip Beatiful ViewPager For iOS written in Swift (inspired by Android SmartTabLayout) SSCustomTabMenu Simple customizable iOS bottom menu with Tabbar. SmoothTab - Smooth customizable tabs for iOS apps. ExpandedTabBar - Very creative designed solution for "more" items in UITabBarController BEKCurveTabbar - compatible with XCode +10 and fully customizable via Interface_Builder panel. BEKCurveTabBar derived UITabBar class and compatible with every iOS devices. Table View / Collection View Table View MGSwipeTableCell - UITableViewCell subclass that allows to display swippable buttons with a variety of transitions. YXTPageView - A PageView, which supporting scrolling to transition between a UIView and a UITableView. ConfigurableTableViewController - Typed, yet Flexible Table View Controller https://holko.pl/2016/01/05/typed-table-view-controller/ Lightning-Table - A declarative api for working with UITableView. Static - Simple static table views for iOS in Swift. AMWaveTransition - Custom transition between viewcontrollers holding tableviews. SWTableViewCell - An easy-to-use UITableViewCell subclass that implements a swippable content view which exposes utility buttons (similar to iOS 7 Mail Application) ZYThumbnailTableView - a TableView have thumbnail cell only, and you can use gesture let it expands other expansionView, all diy BWSwipeRevealCell - A Swift library for swipeable table cells preview-transition - PreviewTransition is a simple preview gallery controller QuickTableViewController - A simple way to create a UITableView for settings in Swift. TableKit - Type-safe declarative table views with Swift VBPiledView - Simple and beautiful stacked UIView to use as a replacement for an UITableView, UIImageView or as a menu VTMagic - VTMagic is a page container library for iOS. MCSwipeTableViewCell - :point_up_2: Convenient UITableViewCell subclass that implements a swippable content to trigger actions (similar to the Mailbox app). MYTableViewIndex - A pixel perfect replacement for UITableView section index, written in Swift ios-dragable-table-cells - Support for drag-n-drop of UITableViewCells in a navigation hierarchy of view controllers. You drag cells by tapping and holding them. Bohr - Bohr allows you to set up a settings screen for your app with three principles in mind: ease, customization and extensibility. SwiftReorder - Add drag-and-drop reordering to any table view with just a few lines of code. Robust, lightweight, and completely customizable. e HoverConversion - HoverConversion realized vertical paging with UITableView. UIViewController will be paging when reaching top or bottom of UITableView contentOffset. TableViewDragger - A cells of UITableView can be rearranged by drag and drop. FlexibleTableViewController - Swift library of generic table view controller with external data processing of functionality, like determine cell's reuseIdentifier related to indexPath, configuration of requested cell for display and cell selection handler CascadingTableDelegate - A no-nonsense way to write cleaner UITableViewDelegate and UITableViewDataSource in Swift. TimelineTableViewCell - Simple timeline view implemented by UITableViewCell written in Swift 3.0. RHPreviewCell - I envied so much Spotify iOS app this great playlist preview cell. Now you can give your users ability to quick check "what content is hidden under your UITableViewCell". TORoundedTableView - A subclass of UITableView that styles it like Settings.app on iPad TableFlip - A simpler way to do cool UITableView animations! ( DTTableViewManager - Protocol-oriented UITableView management, powered by generics and associated types. SwipeCellKit - Swipeable UITableViewCell based on the stock Mail.app, implemented in Swift. ReverseExtension - A UITableView extension that enables cell insertion from the bottom of a table view. SelectionList - Simple single-selection or multiple-selection checklist, based on UITableView. AZTableViewController - Elegant and easy way to integrate pagination with dummy views. SAInboxViewController - UIViewController subclass inspired by "Inbox by google" animated transitioning. StaticTableViewController - Dynamically hide / show cells of static UITableViewController. OKTableViewLiaison - Framework to help you better manage UITableView configuration. ThunderTable - A simple declarative approach to UITableViewController management using a protocol-based approach. Collection View Dwifft - Swift Diff MEVFloatingButton - An iOS drop-in UITableView, UICollectionView and UIScrollView superclass category for showing a customizable floating button on top of it. Preheat - Automates prefetching of content in UITableView and UICollectionView DisplaySwitcher - Custom transition between two collection view layouts Reusable - A Swift mixin for UITableViewCells and UICollectionViewCells Sapporo - Cellmodel-driven collectionview manager StickyCollectionView-Swift - UICollectionView layout for presenting of the overlapping cells. TLIndexPathTools - TLIndexPathTools is a small set of classes that can greatly simplify your table and collection views. IGListKit - A data-driven UICollectionView framework for building fast and flexible lists. FlexibleCollectionViewController - Swift library of generic collection view controller with external data processing of functionality, like determine cell's reuseIdentifier related to indexPath, configuration of requested cell for display and cell selection handler etc ASCollectionView - A Swift collection view inspired by Airbnb. GLTableCollectionView - Netflix and App Store like UITableView with UICollectionView EditDistance - Incremental update tool for UITableView and UICollectionView SwiftSpreadSheet - Spreadsheet CollectionViewLayout in Swift. Fully customizable. GenericDataSource - A generic small reusable components for data source implementation for UITableView/UICollectionView in Swift. PagingView - Infinite paging, Smart auto layout, Interface of similar to UIKit. PJFDataSource - PJFDataSource is a small library that provides a simple, clean architecture for your app to manage its data sources while providing a consistent user interface for common content states (i.e. loading, loaded, empty, and error). DataSources - Type-safe data-driven List-UI Framework. (We can also use ASCollectionNode) KDDragAndDropCollectionView - Dragging & Dropping data across multiple UICollectionViews. SectionScrubber - A component to quickly scroll between collection view sections CollectionKit - A modern Swift framework for building reusable data-driven collection components. AZCollectionViewController - Easy way to integrate pagination with dummy views in CollectionView, make Instagram Discover within minutes. CampcotCollectionView - CampcotCollectionView is a custom UICollectionView written in Swift that allows to expand and collapse sections. It provides a simple API to manage collection view appearance. Stefan - A guy that helps you manage collections and placeholders in easy way. Parade - Parallax Scroll-Jacking Effects Engine for iOS / tvOS. MSPeekCollectionViewDelegateImplementation - A custom paging behavior that peeks the previous and next items in a collection view. SimpleSource - Easy and type-safe iOS table and collection views in Swift. Conv - Conv smart represent UICollectionView data structure more than UIKit. Carbon - A declarative library for building component-based user interfaces in UITableView and UICollectionView. ThunderCollection - A simple declarative approach to UICollectionViewController management using a protocol-based approach. DiffableDataSources - A library for backporting UITableView/UICollectionViewDiffableDataSource. Expandable Cell folding-cell - FoldingCell is an expanding content cell inspired by folding paper material AEAccordion - UITableViewController with accordion effect (expand / collapse cells). ThreeLevelAccordian - This is a customisable three level accordian with options for adding images and accessories images. YNExpandableCell - Awesome expandable, collapsible tableview cell for iOS. Savory - A swift accordion view implementation. ExpyTableView - Make your table view expandable just by implementing one method. FTFoldingPaper - Emulates paper folding effect. Can be integrated with UITableView or used with other UI components. CollapsibleTableSectionViewController - A swift library to support collapsible sections in a table view. ExpandableCell - Fully refactored YNExapnadableCell with more concise, bug free. Awesome expandable, collapsible tableview cell for iOS. expanding-collection - ExpandingCollection is a card peek/pop controller Header ParallaxTableViewHeader - Parallax scrolling effect on UITableView header view when a tableView is scrolled. CSStickyHeaderFlowLayout - UICollectionView replacement of UITableView. Do even more like Parallax Header, Sticky Section Header. GSKStretchyHeaderView - Configurable yet easy to use stretchy header view for UITableView and UICollectionView. Placeholder DZNEmptyDataSet - A drop-in UITableView/UICollectionView superclass category for showing empty datasets whenever the view has no content to display. HGPlaceholders - Nice library to show and create placeholders and Empty States for any UITableView/UICollectionView in your project ListPlaceholder - ListPlaceholder is a swift library allows you to easily add facebook style animated loading placeholder to your tableviews or collection views WLEmptyState - A component that lets you customize the view when the dataset of UITableView is empty. Collection View Layout CHTCollectionViewWaterfallLayout - The waterfall (i.e., Pinterest-like) layout for UICollectionView. FMMosaicLayout - A drop-in mosaic collection view layout with a focus on simple customizations. mosaic-layout - A mosaic collection view layout inspired by Lightbox's Algorithm, written in Swift TLLayoutTransitioning - Enhanced transitioning between UICollectionView layouts in iOS. CenteredCollectionView - A lightweight UICollectionViewLayout that 'pages' and centers it's cells written in Swift. CollectionViewSlantedLayout - UICollectionViewLayout with slanted content SquareMosaicLayout - An extandable mosaic UICollectionViewLayout with a focus on extremely flexible customizations BouncyLayout - BouncyLayout is a collection view layout that makes your cells bounce. AZSafariCollectionViewLayout - AZSafariCollectionViewLayout is replica of safari browser history page layout. very easy to use, IBInspectable are given for easy integration. -ollectionView, make Instagram Discover within minutes. Blueprints - A framework that is meant to make your life easier when working with collection view flow layouts. UICollectionViewSplitLayout - UICollectionViewSplitLayout makes collection view more responsive. Swinflate - A bunch of layouts providing light and seamless experiences in your CollectionView. Tag PARTagPicker - This pod provides a view controller for choosing and creating tags in the style of wordpress or tumblr. AMTagListView - UIScrollView subclass that allows to add a list of highly customizable tags. TagCellLayout - UICollectionView layout for Tags with Left, Center & Right alignments. TTGTagCollectionView - Show simple text tags or custom tag views in a vertical scrollable view. TagListView - Simple and highly customizable iOS tag list view, in Swift. RKTagsView - Highly customizable iOS tags view (like NSTokenField). Supports editing, multiple selection, Auto Layout and much more. WSTagsField - An iOS text field that represents different Tags. AKMaskField - AKMaskField is UITextField subclass which allows enter data in the fixed quantity and in the certain format. YNSearch - Awesome fully customizable search view like Pinterest written in Swift 3. SFFocusViewLayout - UICollectionViewLayout with focused content. TextField & TextView JVFloatLabeledTextField - UITextField subclass with floating labels. ARAutocompleteTextView - subclass of UITextView that automatically displays text suggestions in real-time. Perfect for email Textviews. IQDropDownTextField - TextField with DropDown support using UIPickerView. UITextField-Shake - UITextField category that adds shake animation. Also with Swift version HTYTextField - A UITextField with bouncy placeholder. MVAutocompletePlaceSearchTextField - A drop-in Autocompletion control for Place Search like Google Places, Uber, etc. AutocompleteField - Add word completion to your UITextFields. RSKGrowingTextView - A light-weight UITextView subclass that automatically grows and shrinks. RSKPlaceholderTextView - A light-weight UITextView subclass that adds support for placeholder. StatefulViewController - Placeholder views based on content, loading, error or empty states. MBAutoGrowingTextView - An auto-layout base UITextView subclass which automatically grows with user input and can be constrained by maximal and minimal height - all without a single line of code. TextFieldEffects - Custom UITextFields effects inspired by Codrops, built using Swift. Reel Search - RAMReel is a controller that allows you to choose options from a list. MLPAutoCompleteTextField - a subclass of UITextField that behaves like a typical UITextField with one notable exception: it manages a drop down table of autocomplete suggestions that update as the user types. SkyFloatingLabelTextField - A beautiful and flexible text field control implementation of "Float Label Pattern". Written in Swift. VMaskTextField - VMaskTextField is a library which create an input mask for iOS. TJTextField - UITextField with underline and left image. NextGrowingTextView - The next in the generations of 'growing textviews' optimized for iOS 7 and above. RPFloatingPlaceholders - UITextField and UITextView subclasses with placeholders that change into floating labels when the fields are populated with text. CurrencyTextField - UITextField that automatically formats text to display in the currency format. UITextField-Navigation - UITextField-Navigation adds next, previous and done buttons to the keyboard for your UITextFields. AutoCompleteTextField - Auto complete with suggestion textfield. PLCurrencyTextField - UITextField that support currency in the right way. PasswordTextField - A custom TextField with a switchable icon which shows or hides the password and enforce good password policies. AnimatedTextInput - Animated UITextField and UITextView replacement for iOS. KMPlaceholderTextView - A UITextView subclass that adds support for multiline placeholder written in Swift. NxEnabled - Library which allows you binding enabled property of button with textable elements (TextView, TextField). AwesomeTextField - Awesome TextField is a nice and simple library for iOS. It's highly customisable and easy-to-use tool. Works perfectly for any registration or login forms in your app. ModernSearchBar - The famous iOS search bar with auto completion feature implemented. SelectableTextView - A text view that supports selection and expansion. CBPinEntryView - A customisable view written in Swift 4.2 for any pin, code or password entry. Supports one time codes in iOS 12. GrowingTextView - An UITextView in Swift3 and Swift2.3. Support auto growing, placeholder and length limit. DTTextField - DTTextField is a custom textfield with floating placeholder and error label in Swift3.0. TextFieldCounter - UITextField character counter with lovable UX. RSFloatInputView - A Float Input View with smooth animation and supporting icon and seperator written with Swift. TaniwhaTextField - TaniwhaTextField is a lightweight and beautiful swift textfield framework. It has float label pattern, and also you can highly customise it. InstantSearch iOS - A library of widgets and helpers to build instant-search applications on iOS. SearchTextField - UITextField subclass with autocompletion suggestions list. PYSearch - An elegant search controller which replaces the UISearchController for iOS (iPhone & iPad). styled-text - Declarative text styles and streamlined Dynamic Type support for iOS. TweeTextField - Lightweight set of text fields with nice animation and functionality. MeasurementTextField - UITextField-based control for (NS)Measurement values input. VENTokenField - Easy-to-use token field that is used in the Venmo app. ALTextInputBar - An auto growing text input bar for messaging apps. Tagging - TextView that provides easy to use tagging feature for Mention or Hashtag. InputBarAccessoryView - A simple and easily customizable InputAccessoryView for making powerful input bars with autocomplete and attachments. CocoaTextField - UITextField created according to the Material.IO guidelines of 2019. CHIOTPField - A set of textfields that can be used for One-time passwords, SMS codes, PIN codes, etc. Streamoji - Custom emoji rendering library with support for GIFs and images, UITextView extension. UIPageControl PageControl - A nice, animated UIPageControl alternative. PageControls - This is a selection of custom page controls to replace UIPageControl, inspired by a dribbble found here. CHIPageControl - A set of cool animated page controls to replace boring UIPageControl. Page-Control - Beautiful, animated and highly customizable UIPageControl alternative. TKRubberIndicator - Rubber Indicator in Swift. Web View Otafuku - Otafuku provides utility classes to use WKWebView in Swift. SwiftWebVC - A drop-in inline browser for your Swift iOS app. SVWebViewController - A drop-in inline browser for your iOS app. PTPopupWebView - PTPopupWebView is a simple and useful WebView for iOS, which can be popup and has many of the customized item. Utility Underscore.m - A DSL for Data Manipulation. XExtensionItem - Easier sharing of structured data between iOS applications and share extensions. ReflectableEnum - Reflection for enumerations in Objective-C. ObjectiveSugar - ObjectiveC additions for humans. Ruby style. OpinionatedC - Because Objective-C should have inherited more from Smalltalk. SwiftRandom - Generator for random data. RandomKit - Random data generation in Swift. YOLOKit - Getting square objects down round holes. EZSwiftExtensions - :smirk: How Swift standard types and classes were supposed to work. Pantry - The missing light persistence layer for Swift. SwiftParsec - A parser combinator library written in the Swift programming language. OrderedSet - A Swift collection of unique, ordered objects. Datez - Swift library for dealing with NSDate, NSCalendar, and NSDateComponents. BFKit - An Objective-C collection of useful classes to develop Apps faster. BFKit-Swift - A Swift collection of useful classes to develop Apps faster. Scale - Unit converter in Swift (available via CocoaPods). Standard Template Protocols - Protocols for your every day iOS needs. TimeLord - Easy DateTime (NSDate) management in Swift. AppVersionMonitor - Monitor iOS app version easily. Sugar - Something sweet that goes great with your Cocoa. Then - Super sweet syntactic sugar for Swift initializers. Kvitto - App Store Receipt Validation. Notificationz - Helping you own NSNotificationCenter in Swift. SwiftFoundation - Cross-Platform, Protocol-Oriented Programming base library to complement the Swift Standard Library. (Pure Swift, Supports Linux). libextobjc - A Cocoa library to extend the Objective-C programming language. VersionTrackerSwift - Track which versions of your app a user has previously installed.. DeviceGuru - DeviceGuru is a simple lib (Swift) to know the exact type of the device, e.g. iPhone 6 or iPhone 6s. AEAppVersion - Simple and Lightweight App Version Tracking for iOS written in Swift. BlocksKit - The Objective-C block utilities you always wish you had. SwiftyUtils - All the reusable code that we need in each project. RateLimit - Simple utility for only executing code every so often. Outlets - Utility functions for validating IBOutlet and IBAction connections. EasyAbout - A way to easily add CocoaPods licenses and App Version to your iOS App using the Settings Bundle. Validated - A Swift -Library for Somewhat Dependent Types. Cent - Extensions for Swift Standard Types and Classes. AssistantKit - Easy way to detect iOS device properties, OS versions and work with screen sizes. Powered by Swift. SwiftLinkPreview - It makes a preview from an url, grabbing all the information such as title, relevant texts and images. BundleInfos - Simple getter for Bundle informations. like short version from bundle. YAML.framework - Proper YAML support for Objective-C based on LibYAML. ReadabilityKit - Metadata extractor for news, articles and full-texts in Swift. MissionControl-iOS - Super powerful remote config utility written in Swift (iOS, watchOS, tvOS, macOS). SwiftTweaks - Tweak your iOS app without recompiling! UnsupportedOSVersionAlert - Alerts users with a popup if they use an app with an unsupported version of iOS (e.g. iOS betas). SwiftSortUtils - This library takes a shot at making sorting in Swift more pleasant. It also allows you to reuse your old NSSortDescriptor instances in Swift. Retry - Haven't you wished for try to sometimes try a little harder? Meet retry . ObjectiveKit - Swift-friendly API for Objective C runtime functions. MoyaSugar - Syntactic sugar for Moya. SwifterSwift - A handy collection of more than 400 native Swift 4 extensions to boost your productivity. Eject - An eject button for Interface Builder to generate swift code. ContactsWrapper - Easy to use wrapper for both contacts and contacts group with Objective-C. XestiMonitors - An extensible monitoring framework written in Swift. OpenSourceController - The simplest way to display the libraries licences used in your application. App-Update-Tracker - Easily detect and run code upon app installation or update. ExtensionalSwift - Useful swift extensions in one place. InAppSettingsKit - This iOS framework allows settings to be in-app in addition to or instead of being in the Settings app. MMWormhole - Message passing between iOS apps and extensions. DefaultStringConvertible - A default CustomStringConvertible implementation for Swift types. FluxCapacitor - FluxCapacitor makes implementing Flux design pattern easily with protocols and typealias. VTAcknowledgementsViewController - Ready to use Acknowledgements/Licenses/Credits view controller for CocoaPods. Closures - Swifty closures for UIKit and Foundation. WhatsNew - Showcase new features after an app update similar to Pages, Numbers and Keynote. MKUnits - Unit conversion library for Swift. ActionClosurable - Extensions which helps to convert objc-style target/action to swifty closures. ios_system - Drop-in replacement for system() in iOS programs. SwiftProvisioningProfile - Parse provisioning profiles into Swift models. Once - Minimalist library to manage one-off operations. ZamzamKit - A collection of micro utilities and extensions for Standard Library, Foundation and UIKit. DuctTape - KeyPath dynamicMemberLookup based syntax sugar for swift. ReviewKit - A framework which helps gatekeep review prompt requests using SKStoreReviewController to users who have had a good time using your app by logging positive and negative actions. User Consent SmartlookConsentSDK - Open source SDK which provides a configurable control panel where user can select their privacy options and store the user preferences for the app. PrivacyFlash Pro - Generate a privacy policy for your iOS app from its code VR VR Toolkit iOS - A sample project that provides the basics to create an interactive VR experience on iOS. 360 VR Player - A open source, ad-free, native and universal 360 degree panorama video player for iOS. simple360player - Free & ad-free 360 VR Video Player. Flat or Stereoscopic. In Swift 2. Swifty360Player - iOS 360-degree video player streaming from an AVPlayer with Swift. Walkthrough / Intro / Tutorial Onboard - Easily create a beautiful and engaging onboarding experience with only a few lines of code. EAIntroView - Highly customizable drop-in solution for introduction views. MYBlurIntroductionView - A super-charged version of MYIntroductionView for building custom app introductions and tutorials. BWWalkthrough - A class to build custom walkthroughs for your iOS App. GHWalkThrough - A UICollectionView backed drop-in component for introduction views. ICETutorial - A nice tutorial like the one introduced in the Path 3.X App. JazzHands - Jazz Hands is a simple keyframe-based animation framework for UIKit. Animations can be controlled via gestures, scroll views, KVO, or ReactiveCocoa. RazzleDazzle - A simple keyframe-based animation framework for iOS, written in Swift. Perfect for scrolling app intros. Instructions - Easily add customizable coach marks into you iOS project. SwiftyWalkthrough - The easiest way to create a great walkthrough experience in your apps, powered by Swift. Gecco - Spotlight view for iOS. VideoSplashKit - VideoSplashKit - UIViewController library for creating easy intro pages with background videos. Presentation - Presentation helps you to make tutorials, release notes and animated pages. AMPopTip - An animated popover that pops out a given frame, great for subtle UI tips and onboarding. AlertOnboarding - A simple and handsome AlertView for onboard your users in your amazing world. EasyTipView - Fully customisable tooltip view in Swift. paper-onboarding - PaperOnboarding is a material design slider. InfoView - Swift based simple information view with pointed arrow. Intro - An iOS framework to easily create simple animated walkthrough, written in Swift. AwesomeSpotlightView - Tool to create awesome tutorials or educate user to use application. Or just highlight something on screen. Written in Swift. SwiftyOnboard - A simple way to add onboarding to your project. WVWalkthroughView - Utility to easily create walkthroughs to help with user onboarding. SwiftyOverlay - Easy and quick way to show intro / instructions over app UI without any additional images in real-time! SwiftyOnboardVC - Lightweight walkthrough controller thats uses view controllers as its subviews making the customization endless. Minamo - Simple coach mark library written in Swift. Material Showcase iOS - An elegant and beautiful showcase for iOS apps. WhatsNewKit - Showcase your awesome new app features. OnboardKit - Customisable user onboarding for your iOS app. ConcentricOnboarding - SwiftUI library for a walkthrough or onboarding flow with tap actions. WebSocket SocketRocket - A conforming Objective-C WebSocket client library. socket.io-client-swift - Socket.IO-client for iOS/macOS. SwiftWebSocket - High performance WebSocket client library for Swift, iOS and macOS. Starscream - Websockets in swift for iOS and macOS. SwiftSocket - simple socket library for apple swift lang. Socks - Pure-Swift Sockets: TCP, UDP; Client, Server; Linux, macOS. SwifterSockets - A collection of socket utilities in Swift for OS-X and iOS. Swift-ActionCableClient - ActionCable is a new WebSocket server being released with Rails 5 which makes it easy to add real-time features to your app. DNWebSocket - Object-Oriented, Swift-style WebSocket Library (RFC 6455) for Swift-compatible Platforms. Project setup crafter - CLI that allows you to configure iOS project's template using custom DSL syntax, simple to use and quite powerful. liftoff - Another CLI for creating iOS projects. amaro - iOS Boilerplate full of delights. chairs - Swap around your iOS Simulator Documents. SwiftPlate - Easily generate cross platform Swift framework projects from the command line. xcproj - Read and update Xcode projects. Tuist - A tool to create, maintain and interact with Xcode projects at scale. SwiftKit - Start your next Open-Source Swift Framework. swift5-module-template - A starting point for any Swift 5 module that you want other people to include in their projects. Dependency / Package Manager CocoaPods - CocoaPods is the dependency manager for Objective-C projects. It has thousands of libraries and can help you scale your projects elegantly. Xcode Maven - The Xcode Maven Plugin can be used in order to run Xcode builds embedded in a Maven lifecycle. Carthage - A simple, decentralized dependency manager for Cocoa. SWM (Swift Modules) - A package/dependency manager for Swift projects similar to npm (node.js package manager) or bower (browser package manager from Twitter). Does not require the use of Xcode. CocoaSeeds - Git Submodule Alternative for Cocoa. swift-package-manager - The Package Manager for the Swift Programming Language. punic - Clean room reimplementation of Carthage tool. Rome - A cache tool for Carthage built frameworks. Athena - Gradle Plugin to enhance Carthage by uploading the archived frameworks into Maven repository, currently support only Bintray, Artifactory and Mavel local. Accio - A SwiftPM based dependency manager for iOS & Co. with improvements over Carthage. Tools Shark - Swift Script that transforms the .xcassets folder into a type safe enum. SBConstants - Generate a constants file by grabbing identifiers from storyboards in a project. R.swift - Tool to get strong typed, autocompleted resources like images, cells and segues in your Swift project. SwiftGen - A collection of Swift tools to generate Swift code (enums for your assets, storyboards, Localizable.strings and UIColors). Blade - Generate Xcode image catalogs for iOS / macOS app icons, universal images, and more. Retini - A super simple retina (2x, 3x) image converter. Jazzy - Soulful docs for Swift & Objective-C. appledoc - ObjectiveC code Apple style documentation set generator. Laurine - Laurine - Localization code generator written in Swift. Sweet! StoryboardMerge - Xcode storyboards diff and merge tool. ai2app - Creating AppIcon sets from Adobe Illustrator (all supported formats). ViewMonitor - ViewMonitor can measure view positions with accuracy. abandoned-strings - Command line program that detects unused resource strings in an iOS or macOS application. swiftenv - swiftenv allows you to easily install, and switch between multiple versions of Swift. Misen - Script to support easily using Xcode Asset Catalog in Swift. git-xcp - A Git plugin for versioning workflow of real-world Xcode project. fastlane's best friend. WatchdogInspector - Shows your current framerate (fps) in the status bar of your iOS app. Cichlid - automatically delete the current project's DerivedData directories. Delta - Managing state is hard. Delta aims to make it simple. SwiftLintXcode - An Xcode plug-in to format your code using SwiftLint. XCSwiftr - An Xcode Plugin to convert Objective-C to Swift. SwiftKitten - Swift autocompleter for Sublime Text, via the adorable SourceKitten framework. Kin - Have you ever found yourself undoing a merge due to a broken Xcode build? Then Kin is your tool. It will parse your project configuration file and detect errors. AVXCAssets-Generator - AVXCAssets Generator takes path for your assets images and creates appiconset and imageset for you in just one click. Peek - Take a Peek at your application. SourceKitten - An adorable little framework and command line tool for interacting with SourceKit. xcbuild - Xcode-compatible build tool. XcodeIssueGenerator - An executable that can be placed in a Run Script Build Phase that marks comments like // TODO: or // SERIOUS: as warnings or errors so they display in the Xcode Issue Navigator. SwiftCompilationPerformanceReporter - Generate automated reports for slow Swift compilation paths in specific targets. BuildTimeAnalyzer - Build Time Analyzer for Swift. Duration - A simple Swift package for measuring and reporting the time taken for operations. Benchmark - The Benchmark module provides methods to measure and report the time used to execute Swift code. MBAssetsImporter - Import assets from Panoramio or from your macOS file system with their metadata to your iOS simulator (Swift 2.0). Realm Browser - Realm Browser is a macOS utility to open and modify realm database files. SuperDelegate SuperDelegate provides a clean application delegate interface and protects you from bugs in the application lifecycle. fastlane-plugin-appicon - Generate required icon sizes and iconset from a master application icon. infer - A static analyzer for Java, C and Objective-C. PlayNow - Small app that creates empty Swift playground files and opens them with Xcode. Xtrace - Trace Objective-C method calls by class or instance. xcenv - Groom your Xcode environment. playgroundbook - Tool for Swift Playground books. Ecno - Ecno is a task state manager built on top of UserDefaults in pure Swift 3. ipanema - ipanema analyzes and prints useful information from .ipa file. pxctest - Parallel XCTest - Execute XCTest suites in parallel on multiple iOS Simulators. IBM Swift Sandbox - The IBM Swift Sandbox is an interactive website that lets you write Swift code and execute it in a server environment on top of Linux! FBSimulatorControl - A macOS library for managing and manipulating iOS Simulators Nomad - Suite of command line utilities & libraries for sending APNs, create & distribute .ipa, verify In-App-Purchase receipt and more. Cookiecutter - A template for new Swift iOS / tvOS / watchOS / macOS Framework project ready with travis-ci, cocoapods, Carthage, SwiftPM and a Readme file. Sourcery - A tool that brings meta-programming to Swift, allowing you to code generate Swift code. AssetChecker - Keeps your Assets.xcassets files clean and emits warnings when something is suspicious. PlayAlways - Create Xcode playgrounds from your menu bar GDPerformanceView-Swift - Shows FPS, CPU usage, app and iOS versions above the status bar and report FPS and CPU usage via delegate. Traits - Library for a real-time design and behavior modification of native iOS apps without recompiling (code and interface builder changes are supported). Struct - A tool for iOS and Mac developers to automate the creation and management of Xcode projects. Nori - Easier to apply code based style guide to storyboard. Attabench - Microbenchmarking app for Swift with nice log-log plots. Gluten - Nano library to unify XIB and it's code. LicensePlist - A license list generator of all your dependencies for iOS applications. AppDevKit - AppDevKit is an iOS development library that provides developers with useful features to fulfill their everyday iOS app development needs. Tweaks - An easy way to fine-tune, and adjust parameters for iOS apps in development. FengNiao - A command line tool for cleaning unused resources in Xcode. LifetimeTracker - Find retain cycles / memory leaks sooner. Plank - A tool for generating immutable model objects. Lona - A tool for defining design systems and using them to generate cross-platform UI code, Sketch files, images, and other artifacts. XcodeGen - Command line tool that generates your Xcode project from a spec file and your folder structure. iSimulator - iSimulator is a GUI utility to control the Simulator, and manage the app installed on the simulator. Natalie - Storyboard Code Generator. Transformer - Easy Online Attributed String Creator. This tool lets you format a string directly in the browser and then copy/paste the attributed string code into your app. ProvisionQL - Quick Look plugin for apps and provisioning profile files. xib2Storyboard - A tool to convert Xcode .xib to .storyboard files. Zolang - A programming language for sharing logic between iOS, Android and Tools. xavtool - Command-line utility to automatically increase iOS / Android applications version. Cutter - A tool to generate iOS Launch Images (Splash Screens) for all screen sizes starting from a single template. nef - A set of command line tools for Xcode Playground: lets you have compile-time verification of your documentation written as Xcode Playgrounds, generates markdown files, integration with Jekyll for building microsites and Carbon to export code snippets. Pecker - CodePecker is a tool to detect unused code. Speculid - generate Image Sets and App Icons from SVG, PNG, and JPEG files SkrybaMD - Markdown Documentation generator. If your team needs an easy way to maintain and create documentation, this generator is for you. Storyboard -> SwiftUI Converter - Storyboard -> SwiftUI Converter is a converter to convert .storyboard and .xib to SwiftUI. Swift Package Index - Swift packages list with many information about quality and compatiblity of package. Xcodes.app - The easiest way to install and switch between multiple versions of Xcode. Rapid Development Playgrounds - Playgrounds for Objective-C for extremely fast prototyping / learning. MMBarricade - Runtime configurable local server for iOS apps. STV Framework - Native visual iOS development. swiftmon - swiftmon restarts your swift application in case of any file change. Model2App - Turn your Swift data model into a working CRUD app. Code Injection dyci - Code injection tool. injectionforxcode - Code injection including Swift. Vaccine - Vaccine is a framework that aims to make your apps immune to recompile-decease. Dependency Injection Swinject - Dependency injection framework for Swift. Reliant - Nonintrusive Objective-C dependency injection. Kraken - A Dependency Injection Container for Swift with easy-to-use syntax. Cleanse - Lightweight Swift Dependency Injection Framework by Square. Typhoon - Powerful dependency injection for Objective-C. Pilgrim - Powerful dependency injection Swift (successor to Typhoon). Perform - Easy dependency injection for storyboard segues. Alchemic - Advanced, yet simple to use DI framework for Objective-C. Guise - An elegant, flexible, type-safe dependency resolution framework for Swift. Weaver - A declarative, easy-to-use and safe Dependency Injection framework for Swift. StoryboardBuilder - Simple dependency injection for generating views from storyboard. ViperServices - Dependency injection container for iOS applications written in Swift. Each service can have boot and shutdown code. DITranquillity - Dependency injection framework for iOS applications written in clean Swift. Needle Compile-time safe Swift dependency injection framework with real code. Locatable - A micro-framework that leverages Property Wrappers to implement the Service Locator pattern. Deployment / Distribution fastlane - Connect all iOS deployment tools into one streamlined workflow. deliver - Upload screenshots, metadata and your app to the App Store using a single command. snapshot - Automate taking localized screenshots of your iOS app on every device. buddybuild - A mobile iteration platform - build, deploy, and collaborate. Bitrise - Mobile Continuous Integration & Delivery with dozens of integrations to build, test, deploy and collaborate. watchbuild - Get a notification once your iTunes Connect build is finished processing. Crashlytics - A crash reporting and beta testing service. TestFlight Beta Testing - The beta testing service hosted on iTunes Connect (requires iOS 8 or later). AppCenter - Continuously build, test, release, and monitor apps for every platform. boarding - Instantly create a simple signup page for TestFlight beta testers. HockeyKit - A software update kit. Rollout.io - SDK to patch, fix bugs, modify and manipulate native apps (Obj-c & Swift) in real-time. AppLaunchpad - Free App Store screenshot builder. LaunchKit - A set of web-based tools for mobile app developers, now open source! Instabug - In-app feedback, Bug and Crash reporting, Fix Bugs Faster through user-steps, video recordings, screen annotation, network requests logging. Appfigurate - Secure runtime configuration for iOS and watchOS, apps and app extensions. ScreenshotFramer - With Screenshot Framer you can easily create nice-looking and localized App Store Images. Semaphore - CI/CD service which makes it easy to build, test and deploy applications for any Apple device. iOS support is fully integrated in Semaphore 2.0, so you can use the same powerful CI/CD pipeline features for iOS as you do for Linux-based development. Appcircle.io Automated mobile CI/CD/CT for iOS with online device simulators Screenplay - Instant rollbacks and canary deployments for iOS. App Store Apple's Common App Rejections Styleguide - Highlighted some of the most common issues that cause apps to get rejected. Free App Store Optimization Tool - Lets you track your App Store visibility in terms of keywords and competitors. App Release Checklist - A checklist to pore over before you ship that amazing app that has taken ages to complete, but you don't want to rush out in case you commit a schoolboy error that will end up making you look dumber than you are. Harpy - Notify users when a new version of your iOS app is available, and prompt them with the App Store link. appirater - A utility that reminds your iPhone app's users to review the app. Siren - Notify users when a new version of your app is available and prompt them to upgrade. Appstore Review Guidelines - A curated list of points which a developer has to keep in mind before submitting his/her application on appstore for review. AppVersion - Keep users on the up-to date version of your App. Xcode Extensions (Xcode 8+) CleanClosureXcode - An Xcode Source Editor extension to clean the closure syntax. xTextHandler - Xcode Source Editor Extension Toolset (Plugins for Xcode 8). SwiftInitializerGenerator - Xcode 8 Source Code Extension to Generate Swift Initializers. XcodeEquatableGenerator - Xcode 8 Source Code Extension will generate conformance to Swift Equatable protocol based on type and fields selection. Import - Xcode extension for adding imports from anywhere in the code. Mark - Xcode extension for generating MARK comments. XShared - Xcode extension which allows you copying the code with special formatting quotes for social (Slack, Telegram). XGist - Xcode extension which allows you to send your text selection or entire file to GitHub's Gist and automatically copy the Gist URL into your Clipboard. Swiftify - Objective-C to Swift online code converter and Xcode extension. DocumenterXcode - Attempt to give a new life for VVDocumenter-Xcode as source editor extension. Snowonder - Magical import declarations formatter for Xcode. XVim2 - Vim key-bindings for Xcode 9. Comment Spell Checker - Xcode extension for spell checking and auto correcting code comments. nef - This Xcode extension enables you to make a code selection and export it to a snippets. Available on Mac AppStore. Themes Dracula Theme - A dark theme for Xcode. Xcode themes list - Color themes for Xcode. Solarized-Dark-for-Xcode - Solarized Dark Theme for Xcode 5. WWDC2016 Xcode Color Scheme - A color scheme for Xcode based on the WWDC 2016 invitation. DRL Theme - A soft darkness theme for Xcode. Other Xcode awesome-xcode-scripts - A curated list of useful xcode scripts. Synx - A command-line tool that reorganizes your Xcode project folder to match your Xcode groups. dsnip - Tool to generate (native) Xcode code snippets from all protocols/delegate methods of UIKit (UITableView, ...) SBShortcutMenuSimulator - 3D Touch shortcuts in the Simulator. awesome-gitignore-templates - A collection of swift, objective-c, android and many more langugages .gitignore templates. swift-project-template - Template for iOS Swift project generation. Swift-VIPER-Module - Xcode template for create modules with VIPER Architecture written in Swift 3. ViperC - Xcode template for VIPER Architecture for both Objective-C and Swift. XcodeCodeSnippets - A set of code snippets for iOS development, includes code and comments snippets. Xcode Keymap for Visual Studio Code - This extension ports popular Xcode keyboard shortcuts to Visual Studio Code. Xcode Template Manager - Xcode Template Manager is a Swift command line tool that helps you manage your Xcode project templates. VIPER Module Template - Xcode Template of VIPER Module which generates all layers of VIPER. Xcode Developer Disk Images - Xcode Developer Disk Images is needed when you want to put your build to the device, however sometimes your Xcode is not updated with the latest Disk Images, you could find them here for convenience. Reference Swift Cheat Sheet - A quick reference cheat sheet for common, high level topics in Swift. Objective-C Cheat Sheet - A quick reference cheat sheet for common, high level topics in Objective-C. SwiftSnippets - A collection of Swift snippets to be used in Xcode. App Store Checklist - A checklist of what to look for before submitting your app to the App Store. whats-new-in-swift-4 - An Xcode playground showcasing the new features in Swift 4.0. WWDC-Recap - A collection of session summaries in markdown format, from WWDC 19 & 17. Style Guides NY Times - Objective C Style Guide - The Objective-C Style Guide used by The New York Times. raywenderlich Style Guide - A style guide that outlines the coding conventions for raywenderlich.com. GitHub Objective-C Style Guide - Style guide & coding conventions for Objective-C projects. Objective-C Coding Convention and Best Practices - Gist with coding conventions. Swift Style Guide by @raywenderlich - The official Swift style guide for raywenderlich.com. Spotify Objective-C Coding Style - Guidelines for iOS development in use at Spotify. GitHub - Style guide & coding conventions for Swift projects - A guide to our Swift style and conventions by @github. Futurice iOS Good Practices - iOS starting guide and good practices suggestions by @futurice. SlideShare Swift Style Guide - SlideShare Swift Style Guide we are using for our upcoming iOS 8 only app written in Swift. Prolific Interactive Style Guide - A style guide for Swift. Swift Style Guide by LinkedIn - LinkedIn's Official Swift Style Guide. Good Websites News, Blogs and more BGR iMore Lifehacker NSHipster Objc.io ASCIIwwdc Natasha The Robot Apple's Swift Blog iOS Programming Subreddit iOS8-day-by-day iOScreator Mathew Sanders iOS Dev Nuggets iOS Developer and Designer interview - A small guide to help those looking to hire a developer or designer for iOS work. iOS9-day-by-day Code Facebook Feeds for iOS Developer - The list of RSS feeds for iOS developers. Cocoa Controls - Open source UI components for iOS and macOS. Ohmyswift UIKit references iOS Fonts UIAppearance list Forums and discuss lists "iOS" on Stackoverflow Tutorials and Keynotes AppCoda Tutorials Point Code with Chris Cocoa with Love Brian Advent youtube channel - Swift tutorials Youtube Channel. raywenderlich.com - Tutorials for developers and gamers. Mike Ash Big Nerd Ranch Tuts+ Thinkster Swift Education - A community of educators sharing materials for teaching Swift and app development. Cocoa Dev Central Use Your Loaf Swift Tutorials by Jameson Quave Awesome-Swift-Education - All of the resources for Learning About Swift. Awesome-Swift-Playgrounds - A List of Awesome Swift Playgrounds! learn-swift - Learn Apple's Swift programming language interactively through these playgrounds. Treehouse's iOS Courses and Workshops - Topics for beginner and advanced developers in both Objective-C and Swift. The Swift Summary Book - A summary of Apple's Swift language written on Playgrounds. Hacking With Swift - Learn to code iPhone and iPad apps with 3 Swift tutorials. Realm Academy LearnAppMaking - LearnAppMaking helps app developers to build, launch and market iOS apps. iOS Development with Swift in Motion - This live video course locks in the language fundamentals and then offers interesting examples and exercises to build and practice your knowledge and skills. Conferences.digital - Watch conference videos in a native macOS app. DaddyCoding - iOS Tutorials ranging from beginners to advance. Learn Swift - Learn Swift - curated list of the top online Swift tutorials and courses. iOS UI Template iOS UI Design Kit iOS Design Guidelines iOS GUI by Facebook Design Resources Prototyping FluidUI Proto.io Framer Principle Newsletters AwesomeiOS Weekly - AwesomeiOS Weekly. iOS Goodies - Weekly iOS newsletter. raywenderlich.com Weekly - sign up to receive the latest tutorials from raywenderlich.com each week. iOS Dev Tools Weekly - The greatest iOS development tools, including websites, desktop and mobile apps, and back-end services. iOS Trivia Weekly - Three challenging questions about iOS development every Wednesday. Indie iOS Focus Weekly - Looking for the best iOS dev links, tutorials, & tips beyond the usual news? Curated by Chris Beshore. Published every Thursday. iOS Dev Weekly - Subscribe to a hand-picked round up of the best iOS development links every week. Free. Swift Weekly Brief - A community-driven weekly newsletter about Swift.org. Curated by Jesse Squires and published for free every Thursday. Server-Side Swift Weekly - A weekly newsletter with the best links related to server-side Swift and cross-platform developer tools. Curated by @maxdesiatov iOS Cookies Newsletter - A weekly digest of new iOS libraries written in Swift. Swift Developments - A weekly curated newsletter containing a hand picked selection of the latest links, videos, tools and tutorials for people interested in designing and developing their own iOS, WatchOS and AppleTV apps using Swift. Mobile Developers Cafe - A weekly newsletter for Mobile developers with loads of iOS content. Medium iOS App Development - Stories and technical tips about building apps for iOS, Apple Watch, and iPad/iPhone. Swift Programming - The Swift Programming Language. Flawless App - Development & design & marketing tips for iOS developers. Social Media Twitter @objcio @CocoaPods @CocoaPodsFeed @RubyMotion Podcasts The Ray Wenderlich Podcast Debug App Story iPhreaks Under the Radar Core Intuition Swift Playhouse Release Notes More Than Just Code Runtime Consult Swift Unwrapped Fireside Swift Swift by Sundell Books The Swift Programming Language by Apple iOS Programming: The Big Nerd Ranch Guide by Christian Keur, Aaron Hillegass Programming in Objective-C by Stephen G. Kochan The Complete Friday Q & A: Volume 1 Core Data for iOS: Developing Data-Driven Applications for the iPad, iPhone, and iPod touch Cocoa Design Patterns Hello Swift! by Tanmay Bakshi with Lynn Beighley iOS Development with Swift by Craig Grummitt Anyone Can Create an App by Wendy L. Wise Advanced Swift by Chris Eidhof, Ole Begemann, and Airspeed Velocity Functional Swift by Chris Eidhof, Florian Kugler, and Wouter Swierstra Core Data by Florian Kugler and Daniel Eggert Classic Computer Science Problems in Swift Swift in Depth Other Awesome Lists Other amazingly awesome lists can be found in the awesome-awesomeness list. Open Source apps list of open source iOS apps. Awesome-swift @matteocrippa - A collaborative list of awesome swift resources. @Wolg - A curated list of awesome Swift frameworks, libraries and software. Awesome-Swift-Education - All of the resources for Learning About Swift. awesome watchkit apps curated list of sample watchkit apps and tutorials. iOS Learning Resources Comprehensive collection of high quality, frequently updated and well maintained iOS tutorial sites. Awesome iOS Animation @ameizi - A curated list of awesome iOS animation, including Objective-C and Swift libraries. @jzau - Collection of Animation projects. awesome-ios-chart - A curated list of awesome iOS chart libraries, including Objective-C and Swift. awesome-gists - A list of amazing gists (iOS section). awesome-ios-ui - A curated list of awesome iOS UI/UX libraries. Awesome-Server-Side-Swift/TheList - A list of Awesome Server Side Swift 3 projects. awesome-interview-questions - A curated awesome list of lists of interview questions including iOS. iOS-Playbook - Guidelines and best practices for excellent iOS apps. iOS-Learning-Materials - Curated list of articles, web-resources, tutorials and code repositories that may help you dig a little bit deeper into iOS. Awesome-iOS-Twitter - A curated list of awesome iOS Twitter accounts. Marketing for Engineers - A curated collection of marketing articles & tools to grow your product. Awesome ARKit - A curated list of awesome ARKit projects and resources. CocoaConferences - List of cocoa conferences for iOS & macOS developers. example-ios-apps - A curated list of Open Source example iOS apps developed in Swift. Curated-Resources-for-Learning-Swift - A curated list of resources recommended by the developers. ClassicProblemSolvingAndDataStructuresInSwift - Collection of popular algorithms, data structure and problem solving in Swift 4. Awesome list of open source applications for macOS - List of awesome open source applications for macOS. Awesome iOS Interview question list - Guide for interviewers and interviewees. Review these iOS interview questions - and get some practical tips along the way. Top App Developers - A list of top iOS app developers. Contributing and License See the guide Distributed under the MIT license. See LICENSE for more information.

 # # # # # # # # # # # # # # # # # # # #
 Repository: redox-os/redox, index: 868, word count: 16951 
 # # # # # # # # # # # # # # # # # # # #

A curated list of amazingly awesome Elixir and Erlang libraries, resources and shiny things. Updates:Awesome Elixir A curated list of amazingly awesome Elixir libraries, resources, and shiny things inspired by awesome-php. If you think a package should be added, please add a :+1: (:+1:) at the according issue or create a new one. There are other sites with curated lists of elixir packages which you can have a look at. Awesome Elixir Actors Algorithms and Data structures Applications Artificial Intelligence Audio and Sounds Authentication Authorization Behaviours and Interfaces Benchmarking Bittorrent BSON Build Tools Caching Chatting Cloud Infrastructure and Management Code Analysis Command Line Applications Configuration Cryptography CSV Date and Time Debugging Deployment Documentation Domain-specific language ECMAScript Email Embedded Systems Encoding and Compression Errors and Exception Handling Eventhandling Examples and funny stuff Feature Flags and Toggles Feeds Files and Directories Formulars Framework Components Frameworks Games Geolocation GUI Hardware HTML HTTP Images Instrumenting / Monitoring JSON Languages Lexical analysis Logging Macros Markdown Miscellaneous Native Implemented Functions Natural Language Processing (NLP) Networking Office ORM and Datamapping OTP Package Management PDF Protocols Queue Release Management REST and API Search Security SMS Static Page Generation Statistics Templating Testing Text and Numbers Third Party APIs Translations and Internationalizations Utilities Validations Version Control Video WebAssembly XML YAML Resources Books Cheat Sheets Community Editors Newsletters Other Awesome Lists Reading Screencasts Styleguides Websites Contributing Actors Libraries and tools for working with actors and such. bpe - Business Process Engine in Erlang. (Doc). dflow - Pipelined flow processing engine. exactor - Helpers for easier implementation of actors in Elixir. exos - A Port Wrapper which forwards cast and call to a linked Port. flowex - Railway Flow-Based Programming with Elixir GenStage. mon_handler - A minimal GenServer that monitors a given GenEvent handler. pool_ring - Create a pool based on a hash ring. poolboy - A hunky Erlang worker pool factory. pooler - An OTP Process Pool Application. sbroker - Sojourn-time based active queue management library. workex - Backpressure and flow control in EVM processes. Algorithms and Data structures Libraries and implementations of algorithms and data structures. array - An Elixir wrapper library for Erlang's array. aruspex - Aruspex is a configurable constraint solver, written purely in Elixir. bimap - Pure Elixir implementation of bidirectional maps and multimaps. bitmap - Pure Elixir implementation of bitmaps. blocking_queue - BlockingQueue is a simple queue implemented as a GenServer. It has a fixed maximum length established when it is created. bloomex - A pure Elixir implementation of Scalable Bloom Filters. clope - Elixir implementation of CLOPE: A Fast and Effective Clustering Algorithm for Transactional Data. combination - Elixir library to generate combinations and permutations from Enumerable collection. count_buffer - Buffer a large set of counters and flush periodically. cuckoo - A pure Elixir implementation of Cuckoo Filters. cuid - Collision-resistant ids optimized for horizontal scaling and sequential lookup performance, written in Elixir. data_morph - Create Elixir structs from data. dataframe - Package providing functionality similar to Python's Pandas or R's data.frame(). datastructures - A collection of protocols, implementations and wrappers to work with data structures. def_memo - A memoization macro (defmemo) for elixir using a genserver backing store. dlist - Deque implementations in Elixir. eastar - A* graph pathfinding in pure Elixir. ecto_materialized_path - Tree structure, hierarchy and ancestry for the ecto models. ecto_state_machine - Finite state machine pattern implemented on Elixir and adopted for Ecto. elistrix - A latency / fault tolerance library to help isolate your applications from an uncertain world of slow or failed services. emel - A simple and functional machine learning library written in elixir. erlang-algorithms - Implementations of popular data structures and algorithms. exconstructor - An Elixir library for generating struct constructors that handle external data with ease. exfsm - Simple elixir library to define a static FSM. exkad - A kademlia implementation in Elixir. exmatrix - ExMatrix is a small library for working with matrices, originally developed for testing matrix multiplication in parallel. exor_filter - Nif for xor_filters. 'Faster and Smaller Than Bloom and Cuckoo Filters'. ezcryptex - Thin layer on top of Cryptex. flow - Computational parallel flows on top of GenStage. fnv - Pure Elixir implementation of FowlerNollVo hash functions. fsm - Finite state machine as a functional data structure. fuse - This application implements a so-called circuit-breaker for Erlang. gen_fsm - A generic finite state-machine - Elixir wrapper around OTP's gen_fsm. graphmath - An Elixir library for performing 2D and 3D mathematics. hash_ring_ex - A consistent hash-ring implementation for Elixir. hypex - Fast Elixir implementation of HyperLogLog. indifferent - Indifferent access for Elixir maps/list/tuples with custom key conversion. isaac - Isaac is an elixir module for ISAAC: a fast cryptographic random number generator. jumper - Jump consistent hash implementation in Elixir (without NIFs). key2value - Erlang 2-way Set Associative Map. lfsr - Elixir implementation of a binary Galois Linear Feedback Shift Register. loom - A CRDT library with -CRDT support. luhn - Luhn algorithm in Elixir. lz4 - LZ4 bindings for Erlang for fast data compressing. machinery - A state machine library for structs in general, it integrates with Phoenix out of the box. mason - Coerce maps into structs. This is helpful e.g. when you interface a REST API and want to create a struct from the response. matrex - A blazing fast matrix library for Elixir/Erlang with C implementation using CBLAS. merkle_tree - A Merkle hash tree implementation in Elixir. minmaxlist - Elixir library extending Enum.min_by/2, Enum.max_by/2 and Enum.min_max_by/2 to return a list of results instead of just one. mmath - A library for performing math on number 'arrays' in binaries. monad - Haskell inspired monads in Elixir stylish syntax. monadex - Upgrade your Elixir pipelines with monads. murmur - A pure Elixir implementation of the non-cryptographic hash Murmur3. nary_tree - An Elixir implementation of generic n-ary tree data structure. natural_sort - Elixir natural sort implementation for lists of strings. navigation_tree - A navigation tree representation with helpers to generate HTML out of it. parallel_stream - A parallel stream implementation for Elixir. paratize - Elixir library providing some handy parallel processing (execution) facilities that support configuring number of workers and timeout. parex - Parallel Execute (Parex) is an Elixir module for executing multiple (slow) processes in parallel. qex - Wraps :queue, with improved API and Inspect, Collectable and Enumerable protocol implementations. ratio - Adds Rational Numbers and allows them to be used in common arithmatic operations. Also supports conversion between Floats and Rational Numbers. red_black_tree - Red-Black tree implementation in Elixir. remodel - An Elixir presenter package used to transform map structures. rendezvous - Implementation of the Rendezvous or Highest Random Weight (HRW) hashing algorithm in Elixir. rock - Elixir implementation of ROCK: A Robust Clustering Algorithm for Categorical Attributes. sfmt - SIMD-oriented Fast Mersenne Twister (SFMT) for Erlang. simhash - Simhash implementation using Siphash and N-grams. sleeplocks - BEAM friendly spinlocks for Elixir/Erlang. sorted_set - Sorted Sets for Elixir. spacesaving - stream count distinct element estimation using the "space saving" algorithm. structurez - A playground for data structures in Elixir. supermemo - An Elixir implementation of the Supermemo 2 algorithm. tfidf - An Elixir implementation of term frequencyinverse document frequency. the_fuzz - Fuzzy string-matching algorithm implementations. tinymt - Tiny Mersenne Twister (TinyMT) for Erlang. trie - Erlang Trie Implementation. witchcraft - Common algebraic structures and functions for Elixir. zipper_tree - Variadic arity tree with a zipper for Elixir. Applications Standalone applications. * CaptainFact - A collaborative, real-time video fact-checking platform. (Docs). * chat - A tiny text chat sample based on N2O. * Consolex - Consolex is a tool that allows you to attach a web based console to any mix project. * dragonfly_server - Elixir app to serve Dragonfly images. * exchat - A Slack-like app by Elixir, Phoenix & React (redux). * Exon - A mess manager developed in Elixir and provides a simple API to manage & document your stuff. (Docs). * ExShop - Digital goods shop & blog created using Phoenix framework. * Hydra - A multi-headed beast: API gateway, request cache, and data transformations. * Igthorn - Cryptocurrecy trading platform / trading bot with admin panel. * majremind - A self-maintained database of your updated server which tells you which one needs to be updated. * medex - Medical Examination - application for register health check callbacks and represent their state via HTTP. * medusa_server - A simple cowboy web server written in Elixir to stack images. (Docs). * Nvjorn - A multi-protocol network services monitor written in Elixir using Poolboy. * Phoenix Battleship - The Good Old game built with Elixir, Phoenix Framework, React and Redux. * Phoenix Toggl - Toggl tribute done in Elixir, Phoenix Framework, React and Redux. * Phoenix Trello - Trello tribute done in Elixir, Phoenix Framework, React and Redux. * poxa - Open Pusher implementation, compatible with Pusher libraries. * Queerlink - A simple yet efficient URL shortening service written in Elixir. * RemoteRetro - A real-time application for conducting Agile retrospectives at remoteretro.org written in Elixir/Phoenix/React. * Sprint Poker - Online estimation tool for Agile teams, written using Elixir Lang, Phoenix Framework and React. * Startup Job - An umbrella project to search startup jobs scraped from websites written in Elixir/Phoenix and React/Redux. * Tai - A composable, real time, cryptocurrency market data and trade execution toolkit. * tty2048 - Terminal-based 2048 game written in Elixir. * uai_shot - A multiplayer ship game built with Elixir, Phoenix Framework and Phaser. * workbench - From Idea to Execution - Manage your trading operation across a globally distributed cluster. Artificial Intelligence When your code becomes smarter than you. Exnn - Evolutive Neural Networks framework la G.Sher written in Elixir. (Docs). Neat-Ex - An Elixir implementation of the NEAT algorithm. (Docs). Runhyve - Runhyve is complete virtual machines manager for bhyve on FreeBSD. It's written in Elixir and uses Phoenix framework. simple_bayes - A Simple Bayes / Naive Bayes implementation in Elixir. Synapses - A lightweight library for neural networks. Audio and Sounds Libraries working with sounds and tones. erlaudio - Erlang PortAudio bindings. firmata - This package implements the Firmata protocol. synthex - A signal synthesis library. Authentication Libraries for implementing authentication schemes. aeacus - A simple configurable identity/password authentication module (Compatible with Ecto/Phoenix). apache_passwd_md5 - Apache/APR Style Password Hashing. aws_auth - AWS Signature Version 4 Signing Library for Elixir. basic_auth - Elixir Plug to easily add HTTP basic authentication to an app. coherence - Coherence is a full featured, configurable authentication system for Phoenix. (Docs). doorman - Tools to make Elixir authentication simple and flexible. elixir_auth_google - The simplest way to add Google OAuth authentication ("Sign in with Google") to your Elixir/Phoenix app. github_oauth - A simple github oauth library. goth - OAuth 2.0 library for server to server applications via Google Cloud APIs. guardian - An authentication framework for use with Elixir applications. (Docs). htpasswd - Apache htpasswd file reader/writer in Elixir. mojoauth - MojoAuth implementation in Elixir. oauth2 - An OAuth 2.0 client library for Elixir. oauth2_facebook - A Facebook OAuth2 Provider for Elixir. oauth2_github - A GitHub OAuth2 Provider for Elixir. oauth2cli - Simple OAuth2 client written for Elixir. oauth2ex - Another OAuth 2.0 client library for Elixir. oauther - An OAuth 1.0 implementation for Elixir. passwordless_auth - Simple passwordless login or 2-factor / multi-factor authentication for Elixir. phauxth - Authentication library for Phoenix 1.3 and other Plug-based apps. phoenix_client_ssl - Client SSL Authentication Plugs for Phoenix and other Plug-based apps. phx_gen_auth - An authentication system generator for Phoenix 1.5 applications. pow - Robust, modular, and extendable user authentication system (Website - Doc). samly - SAML SP SSO made easy (Doc). sesamex - Another simple and flexible authentication solution in 5 minutes!. sigaws - AWS Signature V4 signing and verification library (Doc). ueberauth - An Elixir Authentication System for Plug-based Web Applications. ueberauth_auth0 - An Ueberauth strategy for using Auth0 to authenticate your users. ueberauth_cas - Central Authentication Service strategy for berauth. ueberauth_facebook - Facebook OAuth2 Strategy for berauth. ueberauth_foursquare - Foursquare OAuth2 Strategy for berauth. ueberauth_github - A GitHub strategy for berauth. ueberauth_google - A Google strategy for berauth. ueberauth_identity - A simple username/password strategy for berauth. ueberauth_line - LINE Strategy for berauth. ueberauth_microsoft - A Microsoft strategy for berauth. ueberauth_slack - A Slack strategy for berauth. ueberauth_twitter - Twitter Strategy for berauth. ueberauth_vk - vk.com Strategy for berauth. ueberauth_weibo - Weibo OAuth2 Strategy for berauth. zachaeus - An easy to use licensing system, based on asymmetric cryptography. Authorization Libraries for implementing Authorization handling. authorize - Rule based authorization, for advanced authorization rules. bodyguard - A flexible authorization library for Phoenix applications. canada - A simple authorization library that provides a friendly interface using declarative permission rules. canary - An authorization library for Elixir applications that restricts what resources the current user is allowed to access. (Docs). speakeasy - Middleware based authentication and authorization for Absinthe GraphQL powered by Bodyguard. terminator - Database based authorization (ACL), with custom DSL rules for requiring needed permissions. (Docs). Behaviours and Interfaces Definitions how something should behave, like Interfaces from OOP-World connection - Connection behaviour for connection processes. The API is superset of the GenServer API. gen_state_machine - Elixir wrapper for gen_statem. stockastic - Simple Elixir wrapper for the Stockfighter API. Benchmarking Running code to see how long it takes, which is faster and/or if improvements have been made. benchee - Easy and extensible benchmarking in Elixir! benchfella - Benchmarking tool for Elixir. bmark - A benchmarking tool for Elixir. Bittorrent Sharing is caring with Elixir bento - An incredibly fast, correct, pure-Elixir Bencoding library. tracker_request - Dealing with bittorrent tracker requests and responses. wire - Encode and decode bittorrent peer wire protocol messages with Elixir. BSON Libraries and implementations working with BSON. BSONMap - Elixir package that applies a function to each document in a BSON file and has a low memory consumption. cyanide - An Elixir BSON encoding/decoding library. Build Tools Project build and automation tools. active - Recompilation and Reloading on FileSystem changes. coffee_rotor - Rotor plugin to compile CoffeeScript files. dismake - Mix compiler running make. etude - Parallel computation coordination compiler for Erlang/Elixir. ExMake - A modern, scriptable, dependency-based build tool loosely based on Make principles. Exscript - Elixir escript library. mad - Small and Fast Rebar Replacement. pc - A rebar3 port compiler. reaxt - React template into your Elixir application for server rendering. rebar3_abnfc_plugin - Rebar3 abnfc compiler. rebar3_asn1_compiler - Plugin for compiling ASN.1 modules with Rebar3. rebar3_auto - Rebar3 plugin to auto compile and reload on file change. rebar3_diameter_compiler - Compile diameter .dia files in rebar3 projects. rebar3_eqc - A rebar3 plugin to enable the execution of Erlang QuickCheck properties. rebar3_exunit - A plugin to run Elixir ExUnit tests from rebar3 build tool. rebar3_idl_compiler - This is a plugin for compiling Erlang IDL files using Rebar3. rebar3_live - Rebar3 live plugin. rebar3_neotoma_plugin - Rebar3 neotoma (Parser Expression Grammar) compiler. rebar3_protobuffs - rebar3 protobuffs provider using protobuffs from Basho. rebar3_run - Run a release with one simple command. rebar3_yang_plugin - Rebar3 yang compiler. reltool_util - Erlang reltool utility functionality application. relx - A release assembler for Erlang. remix - Automatic recompilation of Mix code on file change. rotor - Super-simple build system for Elixir. sass_elixir - A sass plugin for Elixir projects. Caching Libraries for caching data. cachex - A powerful caching library for Elixir with a wide featureset. con_cache - ConCache is an ETS based key/value storage. elixir_locker - Locker is an Elixir wrapper for the locker Erlang library that provides some useful libraries that should make using locker a bit easier. gen_spoxy - Caching made fun. jc - In-memory, distributable cache with pub/sub, JSON-query and consistency support. locker - Atomic distributed "check and set" for short-lived keys. lru_cache - Simple LRU Cache, implemented with ets. memoize - A memoization macro that easily cache function. nebulex - A fast, flexible and extensible distributed and local caching library for Elixir. stash - A straightforward, fast, and user-friendly key/value store. Chatting Chatting via IRC, Slack, HipChat and other systems using Elixir. alice - A Slack bot framework for Elixir. chatty - A basic IRC client that is most useful for writing a bot. cog - Cog is an open chatops platform that gives you a secure, collaborative command line right in your chat window. ExGram - a library to build Telegram Bots, you can use the low-level methods and models or use the really opinionated framework included. (Docs). ExIrc - IRC client adapter for Elixir projects. ExMustang - A simple, clueless slackbot and collection of responders. Guri - Automate tasks using chat messages. hedwig - XMPP Client/Bot Framework for Elixir.(Docs). hipchat_elixir - HipChat client library for Elixir, based on httpc. kaguya - A small, powerful, and modular IRC bot. slacker - A bot library for the Slack chat service. yocingo - Create your own Telegram Bot. Cloud Infrastructure and Management Applications, tools and libraries for your own cloud service. aws - AWS clients for Elixir. Bonny - Kubernetes Operator Development Framework. Cloudi - CloudI is for back-end server processing tasks that require soft-realtime transaction. discovery - An OTP application for auto-discovering services with Consul. erlcloud - Cloud Computing library for Erlang (Amazon EC2, S3, SQS, SimpleDB, Mechanical Turk, ELB). (Docs). ex_aws - AWS client, supporting Dynamo, Kinesis, Lambda, SQS, and S3. ex_riak_cs - Riak CS API client. fleet_api - A simple wrapper for the Fleet (CoreOS) API. Can be used with etcd tokens or via direct node URLs. Gandi - Gandi Wrapper for Leaseweb infrastructure. IElixir - Jupyter's kernel for Elixir programming language. k8s - Kubernetes Elixir client with CRD support, multi-cluster support, pluggable auth, and configurable middleware. Kazan - Kubernetes client for Elixir, generated from the k8s open API specifications. Kubex - Kubernetes client and integration for Elixir, written in pure Elixir. Leaseweb - Elixir Wrapper for Leaseweb infrastructure. libcluster - Automatic cluster formation/healing for Elixir applications.(Docs). nodefinder - Strategies for automatic node discovery in Erlang. nomad - Create cloud portable Elixir and Phoenix apps. Write once, use everywhere! sidejob - Parallel worker and capacity limiting library for Erlang. sidetask - SideTask is an alternative to Task.Supervisor using Basho's sidejob library with parallelism and capacity limiting. skycluster - Automatic Erlang cluster formation, messaging and management for Elixir/Erlang applications. Integrated with Kubernetes. Code Analysis Libraries and tools for code base analysis, parsing, and manipulation. belvedere - An example of CircleCI integration with Elixir. coverex - Coverage Reports for Elixir. credo - A static code analysis tool with a focus on code consistency and teaching Elixir. (Docs). DepViz - A visual tool to help developers understand Elixir recompilation in their projects. (Code). dialyxir - Mix tasks to simplify use of Dialyzer in Elixir projects.(Docs). dogma - A code style linter for Elixir, powered by shame.(Docs). excoveralls - Coverage report tool for Elixir with coveralls.io integration. exprof - A simple code profiler for Elixir, using eprof. Command Line Applications Anything helpful for building CLI applications. anubis - Command-Line application framework for Elixir. ex_cli - User friendly CLI apps for Elixir. ex_prompt - Helper package to add interactivity to your command line applications as easy as possible. firex - Firex is a library for automatically generating command line interfaces (CLIs) from an elixir module. getopt - Command-line options parser for Erlang. loki - Library for creating interactive command-line application. optimus - Command-line option parser for Elixir inspired by clap.rs. phoenix-cli - Command-line interface for Phoenix Framework like Rails commands. progress_bar - Command-line progress bars and spinners. ratatouille - A TUI (terminal UI) kit for Elixir. scribe - Pretty-print tables of Elixir structs and maps. Inspired by hirb. table_rex - Generate configurable ASCII style tables for display. tabula - Pretty print list of Ecto query results / maps in ascii tables (GitHub Markdown/OrgMode). Configuration Libraries and tools working with configurations confex - Helper module that provides a nice way to read environment configuration at runtime. configparser_ex - A simple Elixir parser for the same kind of files that Python's configparser library handles. conform - Easy release configuration for Elixir apps. dotenv - A port of dotenv to Elixir. ex_conf - Simple Elixir Configuration Management. figaro - Simple Elixir project configuration. figaro_elixir - Environmental variables manager for Elixir. hush - Read and inject configuration at runtime, and in release mode with support for multiple providers. hush_aws_secrets_manager - AWS Secrets Manager provider for hush. hush_gcp_secret_manager - Google Secret Manager provider for hush. sweetconfig - Read YAML configuration files from any point at your app. Cryptography Encrypting and decrypting data aescmac - AES CMAC (RFC 4493) in Elixir. cipher - Elixir crypto library to encrypt/decrypt arbitrary binaries. cloak - Cloak makes it easy to use encryption with Ecto.(Docs). comeonin - Password hashing (argon2, bcrypt, pbkdf2_sha512) library for Elixir.(https://hexdocs.pm/comeonin/api-reference.html). crypto_rsassa_pss - RSASSA-PSS Public Key Cryptographic Signature Algorithm for Erlang. elixir_tea - TEA implementation in Elixir. ex_bcrypt - Elixir wrapper for the OpenBSD bcrypt password hashing algorithm. ex_crypto - Elixir wrapper for Erlang crypto and public_key modules. Provides sensible defaults for many crypto functions to make them easier to use.(Docs). exgpg - Use gpg from Elixir. ntru_elixir - Elixir wrapper for libntru. A post quantum cryptography system. one_time_pass_ecto - One-time password library for Elixir. pot - Erlang library for generating one time passwords compatible with Google Authenticator. rsa - public_key cryptography wrapper for Elixir. rsa_ex - Library for working with RSA keys. siphash-elixir - Elixir implementation of the SipHash hash family. tea_crypto - Tiny Encryption Algorithm implementation. CSV Libraries and implementations working with CSV. cesso - CSV handling library for Elixir. csv - CSV Decoding and Encoding for Elixir. csv2sql - A fast and fully automated CSV to database importer. csvlixir - A CSV reading/writing application for Elixir. ecsv - Fast libcsv-based stream parser for Elixir. ex_csv - CSV for Elixir. nimble_csv - A simple and fast CSV parsing and dumping library for Elixir. Date and Time Libraries for working with dates and times. block_timer - Macros to use :timer.apply_after and :timer.apply_interval with a block. calendar - Calendar is a date and time library for Elixir. calendarific - Calendarific is a wrapper for the holiday API Calendarific. calixir - Calixir is a port of the Lisp calendar software calendrica-4.0 to Elixir. chronos - An Elixir date/time library. cocktail - Elixir date recurrence library based on iCalendar events. cronex - Cron like system you can mount in your supervision tree. crontab - A Cron Expressions Parser, Composer & Date Candidate Finder. emojiclock - An Elixir module for giving you an emoji clock for a given hour. ex_ical - ICalendar parser. filtrex - A library for performing and validating complex SQL-like filters from a client (e.g. smart filters). good_times - Expressive and easy to use datetime functions. jalaali - Jalaali calendar implementation for Elixir. milliseconds - Simple library to work with milliseconds in Elixir. moment - Parse, validate, manipulate, and display dates in Elixir. open_hours - Time calculations using business hours. quantum - Cron-like job scheduler for Elixir applications. repeatex - Natural language parsing for repeating dates. tiktak - Fast and lightweight web scheduler written in Elixir. timelier - A cron-style scheduler for Elixir. timex - Easy to use Date and Time modules for Elixir. timex_interval - A date/time interval library for Elixir projects, based on Timex. tzdata - The timezone database in Elixir. Debugging Libraries and tools for debugging code and applications. beaker - Statistics and Metrics library for Elixir. booter - Boot an Elixir application, step by step. dbg - Distributed tracing for Elixir. eflame - Flame Graph profiler for Erlang. eh - A tool to look up Elixir documentation from the command line. eper - Erlang performance and debugging tools. ether - Ether provides functionality to hook Elixir into the Erlang debugger. ex_debug_toolbar - A toolbar for Phoenix projects to interactively debug code and display useful information about requests: logs, timelines, database queries etc. exrun - Distributed tracing for Elixir with rate limiting and simple macro-based interface. extrace - Elixir wrapper for Recon Trace. git_hooks - Add git hooks to Elixir projects. observer_cli - Visualize Elixir & Erlang nodes on the command line, it aims to helpe developers debug production systems. quaff - The Debug module provides a simple helper interface for running Elixir code in the erlang graphical debugger. rexbug - An Elixir wrapper for the redbug production-friendly Erlang tracing debugger. visualixir - A process visualizer for remote BEAM nodes. Deployment Installing and running your code automatically on other machines. akd - Capistrano like, Configurable, and easy to set up Elixir Deployment Automation Framework. ansible-elixir-stack - 1-command setup & deploys to servers, with first-class support for Phoenix apps. bootleg - Simple deployment and server automation for Elixir. bottler - Bottler is a collection of tools that aims to help you generate releases, ship them to your servers, install them there, and get them live on production. edeliver - Deployment for Elixir and Erlang. elixir-on-docker - A project template to get started developing clustered Elixir applications for cloud environments. exdm - Deploy Elixir applications via mix tasks. exreleasy - Dead simple and Mix friendly tool for releasing Elixir applications. gatling - Collection of mix tasks to automatically create a exrm release from git and launch/upgrade it on your server. Gigalixir - A fully-featured PaaS designed for Elixir. Supports clustering, hot upgrades, and remote console/observer. Free to try without a credit card. heroku-buildpack-elixir - Heroku buildpack to deploy Elixir apps to Heroku. Documentation Libraries and tools for creating documentation. blue_bird - BlueBird is a library written in the Elixir programming language for the Phoenix framework. It lets you generate API documentation in the API Blueprint format from annotations in controllers and automated tests. bureaucrat - Generate Phoenix API documentation from tests. ex_doc - ExDoc is a tool to generate documentation for your Elixir projects. ex_doc_dash - Formatter for ExDoc to generate docset documentation for use in Dash.app. hexdocset - Convert hex doc to Dash.app's docset format. inch-ci - Documentation badges for Ruby & Elixir. maru_swagger - Add swagger compliant documentation to your maru API. phoenix_api_docs - Generate API Blueprint documentation from controllers and tests in the Phoenix framework. phoenix_swagger - Provides swagger integration to the Phoenix framework. xcribe - Generate API documentation from tests using Swagger (OpenAPI) or API Blueprint specification. Domain-specific language Specialized computer languages for a particular application domain. Absinthe Graphql - Fully featured GraphQL library. absinthe_gen - Scaffold generator for Absithne. JSON-LD.ex - An implementation of the JSON-LD standard for RDF.ex. RDF.ex - An implementation of the RDF data model in Elixir. SPARQL.ex - An implementation of the SPARQL standards in Elixir. ECMAScript Implementations working with JavaScript, JScript or ActionScript. elixirscript - A transcompiler from Elixir to Javascript. estree - A implementation of the SpiderMonkey Parser API in Elixir. phoenix_gon - Allow you to pass Phoenix environment or controller variables to JavaScript without problems. phoenix_routes_js - Phoenix routes helpers in JavaScript code and browser console. Email Working with Email and stuff. bamboo - Composable, testable and adapter based email library. Out of the box support for rendering with Phoenix and a plug for previewing sent emails in dev. burnex - Burner email (temporary address) detector. echo - A meta-notification system; Echo checks notification preferences & dispatches notifications. ex_postmark - Postmark adapter for sending template emails in Elixir. gen_smtp - A generic Erlang SMTP server and client that can be extended via callback modules. gmail - A simple Gmail REST API client for Elixir. mail - An RFC2822 implementation in Elixir, built for composability. mailer - A simple SMTP mailer. mailibex - Library containing Email-related implementations in Elixir: dkim, spf, dmark, mimemail, smtp. mailman - Mailman provides a clean way of defining mailers in your Elixir applications. pop3mail - Pop3 client to download email (including attachments) from the inbox via the commandline or Elixir API. ravenx - Notification dispatch library for Elixir applications. smoothie - Smoothie inline styles of your email templates, and generates a plain text version from the HTML. swoosh - Compose, deliver and test your Emails (with attachments!) easily in Elixir with adapters for SMTP, Sendgrid, Mandrill, Mailgun, Postmark and lots others, plus Phoenix integration with mailbox preview. Embedded Systems Embedded systems development. nerves - A framework for writing embedded software in Elixir. Encoding and Compression Transforming data in different formats or compressing it. ex_rlp - Elixir implementation of Ethereum's RLP (Recursive Length Prefix) encoding. huffman - Huffman encoding and decoding in Elixir. Errors and Exception Handling Working with errors and exceptions. exceptional - Helpers for happy-path programming & exception handling. happy - Happy path programming, alternative to elixir with form. OK - Elegant error handling with result monads, featuring a simple & powerful with construct and a happy path pipe operator. sentry-elixir - The Official Elixir client for Sentry. Eventhandling Sending/Emitting and receiving/handling Events in Elixir. cizen - Build highly concurrent, monitorable, and extensible applications with a collection of sagas. event_bus - Simple event bus implementation with topic filtering and built-in event store and event watcher. goldrush - Small, Fast event processing and monitoring for Erlang/OTP applications. reaxive - Reaxive is a reactive event handling library, inspired by Elm and Reactive Extensions. wait_for_it - Provides convenient and easy-to-use facilities for synchronizing concurrent activities. Examples and funny stuff Example code and stuff too funny or curious not to mention. butler_cage - A Butler plugin for showing silly photos of Nick Cage. butler_tableflip - Flipping tables with butler. changelog.com - CMS that runs changelog.com built with Phoenix 1.4. coderplanets.com - GraphQL api for coderplanets.com built with Phoenix 1.4 and Absinthe. dice - Roll the dice, in Elixir. elixir_koans - Elixir koans is a fun, easy way to get started with the elixir programming language. ex_chain - Simple Markov Chain that generates funny tweets, built using Elixir. ex_iss - This package is for interfacing with the Open Notify API to information such as the ISS's current location, crew, and when it will pass over a location. feedx - Add social feed functionality to current applications. Exemplify OTP umbrella app, with 3 apps. Thin phoenix controllers. harakiri - Help applications kill themselves. hello_phoenix - Application template for SPAs with Phoenix, React and Redux. hexpm - Source code for the hex package manager site built with Phoenix 1.3. kaisuu - Watch Japan's Kanji Usage on Twitter in Realtime. koans - Learn Elixir by using elixir-koans. lolcat - This is the clone of busyloop/lolcat. But it does not support animation and some features of the original. magnetissimo - Web application that indexes all popular torrent sites, and saves it to the local database. oop - OOP in Elixir! phoenix-chat-example - A step-by-step example/tutorial for building a Chat app in Phoenix for complete beginners. Covers testing, docs and deployement. Phoenix 1.5.3. phoenix-ecto-encryption-example - A comprehensive example/tutorial showing people how to use Ecto Types to transparently encrypt/decrypt data in a Phoenix 1.4 app. phoenix-flux-react - An experiment with Phoenix Channels, GenEvents, React and Flux. phoenix-liveview-counter-tutorial - complete beginners step-by-step tutorial building a real time counter in Phoenix 1.5.3 and LiveView 0.14.1. phoenix-todo-list-tutorial - A complete beginners step-by-step tutorial for building a Todo List from scratch in Phoenix 1.5.3. portal - A shooting fault-tolerant doors for distributed portal data-transfer application in Elixir. real world example app - Elixir / Phoenix implementation of RealWorld.io backend specs - a Medium clone. rollex - Elixir library using a Pratt Parser algorithm to calculate dice rolls. rubix - A very simple (and barely-functioning) Ruby runner for Elixir. stranger - Elixir Phoenix app to chat anonymously with a randomly chosen stranger. tilex - Source code for Hashrocket's TIL website built with Phoenix 1.3. weather - A command line weather app built using Elixir. Feature Flags and Toggles Libraries to manage feature toggles (AKA feature flags): ON/OFF values that can be toggled at runtime through some interface ConfigCat - Elixir SDK for ConfigCat hosted feature flag service. flippant - Feature flipping for the Elixir world. fun_with_flags - A feature toggle library using Redis or Ecto for persistence, an ETS cache for speed and PubSub for distributed cache busting. Comes with a management web UI for Phoenix and Plug. molasses - A feature toggle library using redis or SQL (using Ecto) as a backing service. Feeds Libraries working with feeds like RSS or ATOM. atomex - ATOM feed builder with a focus on standards compliance, security and extensibility. feeder - Parse RSS and Atom feeds. feeder_ex - RSS feed parser. Simple wrapper for feeder. feedme - RSS/Atom parser built on erlang's xmerl xml parser. Files and Directories Libraries and implementations for working with files and directories. Belt - Extensible file upload library with support for SFTP, S3 and Filesystem storage. cassius - Monitor Linux file system events. dir_walker - DirWalker lazily traverses one or more directory trees, depth first, returning successive file names. elixgrep - A framework for doing Hadoop style Map/Reduce operations on collections of files. ex_guard - ExGuard is a mix command to handle events on file system modifications. ex_minimatch - Globbing paths without walking the tree!. exfile - File upload handling, persistence, and processing in Elixir and Plug. exfswatch - A file change watcher wrapper based on fs. eye_drops - Configurable mix task to watch file changes and run the corresponding command. format_parser.ex - Elixir library to figure out the type and the format of a file. fs - Erlang FileSystem Listener. fwatch - A callback-based file watcher based on fs. librex - Elixir library to convert office documents to other formats using LibreOffice. Radpath - Path library for Elixir, inspired by Python's Enhpath. sentix - A cross-platform file watcher for Elixir based on fswatch. sizeable - An Elixir library to make file sizes human-readable. waffle - Flexible file upload and attachment library for Elixir. zarex - Filename sanitization for Elixir. Formulars Handling web formulars and similar stuff. forms - Erlang Business Documents Generator. Framework Components Standalone component from web development frameworks. absinthe_plug - Plug support for Absinthe. access pass - Authentication framework that can be used with or outside of phoenix. Similar to Addict but geared towards API usage.(Docs). addict - User authentication for Phoenix Framework. airbrake_plug - Report errors in your Plug stack or whatever to Airbrake. ashes - A code generation tool for the Phoenix web framework. better_params - Elixir Plug for cleaner request params in web apps. blaguth - Basic Access Authentication in Plug applications. commanded - Command handling middleware for Command Query Responsibility Segregation (CQRS) applications. cors_plug - An Elixir plug that adds CORS headers to requests and responds to preflight requests (OPTIONS). corsica - Elixir library for dealing with CORS requests. crudex - CRUD utilities for Phoenix and Ecto. dayron - A repository similar to Ecto.Repo that works with REST API requests instead of a database. ex_admin - ExAdmin is an auto administration package for Elixir and the Phoenix Framework. exdjango - A few elixir libraries for working with django. exrecaptcha - Simple reCaptcha display/verify code for Elixir applications. filterable - Simple query params filtering for Phoenix framework inspired by Rails has_scope. graphql_parser - An Elixir binding for libgraphqlparser. http_router - HTTP Router with various macros to assist in developing your application and organizing your code. kerosene - Pagination for Ecto and Phoenix. mellon - An authentication module for Plug applications. multiverse - Plug that allows to add version compatibility layers via API Request/Response Gateways. params - Use Ecto to enforce/validate parameters structure, akin to Rails' strong parameters. passport - Passport provides authentication for Phoenix applications. phoenix_ecto - Phoenix and Ecto integration. phoenix_haml - Phoenix Template Engine for Haml. phoenix_html - Phoenix.HTML functions for working with HTML strings and templates. phoenix_html_sanitizer - HTML Sanitizer integration for Phoenix. phoenix_html_simplified_helpers - Some helpers for phoenix html (truncate, time_ago_in_words, number_with_delimiter). phoenix_linguist - A project that integrates Phoenix with Linguist, providing a plug and view helpers. It looks abandoned: its last commit was on 2015 and its CI runs Elixir 1.0.3. phoenix_live_reload - Provides live-reload functionality for Phoenix. phoenix_meta_tags - Generate meta tags for a website. phoenix_pubsub_postgres - Postgresql PubSub adapter for Phoenix apps. phoenix_pubsub_rabbitmq - RabbitMQ adapter for Phoenix's PubSub layer. phoenix_pubsub_redis - The Redis PubSub adapter for the Phoenix framework. phoenix_pubsub_vernemq - The VerneMQ MQTT pubsub adapter for the Phoenix framework. phoenix_slime - Slim template support for Phoenix. phoenix_token_auth - Token authentication solution for Phoenix. Useful for APIs or single page apps. phx_component_helpers - Extensible live_components, without boilerplate. plug - A specification and conveniences for composable modules in between web applications. plug_accesslog - Plug for writing access logs. plug_and_play - Set up a Plug application with less boilerplate. plug_auth - Collection of authentication-related plugs. plug_canonical_host - Plug to ensure all requests are served from a single canonical host. plug_checkup - Plug for adding simple health checks to your app. plug_cloudflare - Inspired by mod_cloudflare, this Elixir plug parses Cloudflares CF-Connecting-IP HTTP request header into Plug.Conn's remote_ip field. plug_forward_peer - Very simple plug which reads X-Forwarded-For or Forwarded header according to RFC7239 and fill conn.remote_ip with the root client ip. plug_fprof - A Plug that adds fprof tracing to requests, to allow for easy profiling. plug_graphql - Phoenix Plug integration for GraphQL Elixir. plug_heartbeat - A plug for responding to heartbeat requests. plug_jwt - Plug for JWT authentication. plug_password - Plug for adding simple cookie-based authentication. plug_rails_cookie_session_store - Rails compatible Plug session store. plug_redirect_https - Plug to redirect http requests to https requests behind a reverse proxy. plug_require_header - Require and extract HTTP headers and handle missing ones. plug_response_header - easy manipulation of HTTP response headers. plug_ribbon - Injects a ribbon to your web application in the development environment. plug_secex - Plug that adds various HTTP Headers to make Phoenix/Elixir app more secure. plug_session_memcached - A very simple memcached session store for Elixir's plug. plug_sigaws - AWS Signature V4 authentication protection for Phoenix/Plug Routes (Docs). plug_statsd - A plug for automatically sending timing and count metrics to statsd. plugs - Collection of Plug middleware for web applications. plugsnag - Bugsnag notifier for Elixir's plug. raygun - Capture bugs and send them to Raygun. react_phoenix - Render React.js components in Phoenix views focusing on easy installation and Brunch compatibility. recaptcha - A simple reCaptcha 2 library for Elixir applications. resin - Resin is a plug that will add a configurable delay to every request that's passing through it, unless run in production. revision_plate_ex - Plug application and middleware that serves endpoint returns application's REVISION. rummage_ecto - A configurable framework to search, sort and paginate Ecto Queries. rummage_phoenix - A support framework for searching, sorting and paginating models in Phoenix, with HTML support. scaffold - A mix task for creating new projects based on templates fetched from a Git-repo. scrivener - Paginate your Ecto queries. scrivener_headers - Helpers for paginating API responses with Scrivener and HTTP headers. scrivener_html - Helpers built to work with Scrivener's page struct to easily build HTML output for various CSS frameworks. sentinel - An authentication framework for Phoenix extending guardian with routing and other basic functionality. surface - A server-side rendering component library for Phoenix. torch - Torch is a rapid admin generator for Phoenix apps. It uses generators rather than DSLs to ensure that the code remains maintainable. trailing_format_plug - An Elixir plug to support legacy APIs that use a rails-like trailing format. turn_the_page - Fast, simple and lightweight pagination system for your Elixir application. webassembly - Web DSL for Elixir. weebo - An XML-RPC parser/formatter for Elixir, with full support for datatype mapping. Frameworks Web development frameworks. exelli - An Elli Elixir wrapper with some sugar syntax goodies. kitto - A framework for interactive dashboards. n2o - Distributed Application Server. nitro - Nitrogen-compatible Web Framework. phoenix - Elixir Web Framework targeting full-featured, fault tolerant applications with realtime functionality. placid - A REST toolkit for building highly-scalable and fault-tolerant HTTP APIs with Elixir. rackla - API Gateways in Elixir. relax - Simple Elixir implementation of a jsonapi.org server. rest - Micro-REST framework with typed JSON. RIG - Create low-latency, interactive user experiences for stateless microservices. sugar - Modular web framework for Elixir. trot - An Elixir web micro-framework. Games Libraries for and implementations of games. Binbo - A chess representation written in Erlang using Bitboards, ready for use on game servers. entice - A distributed Entity-Component-System framework, providing its own example MMORPG server. mines - A minesweeper clone in the terminal. vim_snake - A classical multiplayer snake game with Vim-style keybinding built with Phoenix framework. Geolocation Libraries for geocoding addresses and working with latitudes and longitudes. distance_api_matrix - Provide distance and heading calculations via Google distance matrix api. geo - A collection of GIS functions for Elixir. geocalc - Calculate distance, bearing and more between latitude/longitude points. geocoder - A simple, efficient geocoder/reverse geocoder with a built-in cache. geohash - Geohash encode/decode library. geohash_nif - Drop in replacement for Geohash encode/decode library implemented as a NIF. geohax - Geohash encoding and decoding with neighbors finder. geoip - Find geolocation for a given IP, hostname or Plug.Conn. geolix - MaxMind GeoIP2 database reader/decoder. geonames - A simple Elixir wrapper around the GeoNames API. ip2location - An Elixir library for IP2Location database. ipgeobase - Find Russian and Ukraine city by IP address and find country for other country. proj - Elixir coordinate conversion library using OSGeo's PROJ.4. segseg - Segment-segment intersection classifier and calculator. topo - A Geometry library for Elixir that calculates spatial relationships between two geometries. wheretz - Elixir version of Ruby gem for lookup of timezone by georgraphic coordinates. GUI Libraries for writing Graphical User Interfaces. scenic - Portable 2D UI framework. Hardware Hardware related things like I/O interfaces and such. elixir_ale - Elixir access to hardware I/O interfaces such as GPIO, I2C, and SPI. nerves - Framework for building firmware for platforms like Raspberry Pi and BeagleBone Black. HTML Libraries and implementations working with HTML (for xml tools please go to the XML section). exquery - A library for parsing HTML and querying elements within. floki - A simple HTML parser that enables searching using CSS like selectors. html_sanitize_ex - HTML sanitizer for Elixir. modest_ex - A library to do pipeable transformations on html strings with CSS selectors, e.g. find(), prepend(), append(), replace() etc. myhtmlex - Elixir/Erlang bindings for lexborisov's myhtml. readability - Readability is for extracting and curating articles. texas - Texas is a powerful abstraction over updating your clients using server-side rendering and server-side Virtual DOM diff/patching. tidy_ex - Elixir binding to the granddaddy of HTML tools http://www.html-tidy.org. HTTP Libraries for working with HTTP and scraping websites. Ace - HTTP web server and client, supports http1 and http2. bolt - Simple and fast http proxy. cauldron - An HTTP/SPDY server as a library. Crawler - A high performance web crawler in Elixir. Crawly - high-level web crawling & scraping framework for Elixir. elli - Elli is a webserver you can run inside your Erlang application to expose an HTTP API. etag_plug - A simple to use shallow ETag plug. explode - An easy utility for responding with standard HTTP/JSON error payloads in Plug- and Phoenix-based applications. exvcr - HTTP request/response recording library for Elixir, inspired by VCR. finch - An HTTP client with a focus on performance, built on top of Mint and NimblePool. fuzzyurl - An Elixir library for parsing, constructing, and wildcard-matching URLs. Also available for Ruby and JavaScript. gun - HTTP/1.1, HTTP/2 and Websocket client for Erlang/OTP. hackney - Simple HTTP client written in Erlang. http - HTTP server for Elixir. http_digex - A module to create basic digest HTTP auth header. http_proxy - Multi port HTTP Proxy. httpoison - Yet Another HTTP client for Elixir powered by hackney. httpotion - Fancy HTTP client for Elixir, based on ibrowse. ivar - A lightweight wrapper around HTTPoison that provides a fluent and composable way to build http requests. lhttpc - A lightweight HTTP/1.1 client implemented in Erlang. mint - Functional HTTP client for Elixir with support for HTTP/1 and HTTP/2. mnemonic_slugs - A memorable, mnemonic slug generator in Elixir. mochiweb - MochiWeb is an Erlang library for building lightweight HTTP servers. neuron - A GraphQL client for Elixir. plug_wait1 - Plug adapter for the wait1 protocol. raxx - Interface for HTTP webservers, frameworks and clients. river - An HTTP/2 client that is lightweight and lightning fast. scrape - Scrape any website, article or RSS/Atom Feed with ease. sparql_client - A SPARQL protocol client for Elixir. spell - Spell is a Web Application Messaging Protocol (WAMP) client implementation in Elixir. tesla - HTTP client library, with support for middleware and multiple adapters. Tube - Pure Elixir WebSocket client library. uri_query - URI encode nested GET parameters and array values in Elixir. uri_template - RFC6570 compliant URI template processor for Elixir. web_socket - An exploration into a stand-alone library for Plug applications to easily adopt WebSockets. webdriver - This is an implementation of the WebDriver protocol client. It currently supports PhantomJS, FireFox, ChromeDriver and remote webdriver servers (e.g. Selenium). yuri - Simple struct for representing URIs. Images Libraries for working with and manipulating images. alchemic_avatar - Elixir library for generating letter avatar from string. artifact - File upload and on-the-fly processing for Elixir. bump - A BMP file writer in pure Elixir. chunky_svg - A library for drawing things with SVG. cloudex - Cloudex is an Elixir library that can upload image files or urls to Cloudinary. eikon - An Elixir library providing a read-only interface for image files. elixir_exif - Parse exif tags and thumbnail data from jpeg files. ex_image_info - An Elixir library to parse images (binaries) and get the dimensions, detected mime-type and overall validity for a set of image formats. exexif - Pure Elixir library to extract TIFF and EFIX metadata from jpeg files. exfavicon - An Elixir library for discovering favicons. identicon - An Elixir library for generating 5x5 identicons. image64 - A tool for working with base64 encoded images. imagineer - Image parsing in Elixir. imgex - Unofficial client library for generating imgix URLs in Elixir. mogrify - An Elixir wrapper for ImageMagick command line. png - A pure Erlang library for creating PNG images. It can currently create 8 and 16 bit RGB, RGB with alpha, indexed, grayscale and grayscale with alpha images. thumbnex - Create thumbnails from images and video screenshots. Instrumenting / Monitoring Libraries for collecting and exporting metrics. appsignal-elixir - Collects error and performance data from your Elixir applications and sends it to AppSignal. elixometer - A light Elixir wrapper around exometer. erlang-metrics - A generic interface to different metrics systems in Erlang. exometer - Basic measurement objects and probe behavior in Erlang. folsom_ddb - DalmatinerDB backend to store folsom metrics. graphitex - Graphite/Carbon client for Elixir. instream - InfluxDB driver for Elixir. instrumental - An Elixir client for Instrumental. newrelic.ex - Collects metrics from your Elixir/Phoenix application and sends them to NewRelic. prometheus - Prometheus.io monitoring system and time series database client in Erlang. prometheus-ecto - Ecto instrumenter for prometheus.ex. prometheus-phoenix - Phoenix instrumenter for prometheus.ex. prometheus-plugs - Plugs instrumenters/exporter for prometheus.ex. prometheus.ex - Elixir-friendly Prometheus.io monitoring system and time series database client. prometheus_process_collector - Prometheus collector which exports the current state of process metrics including cpu, memory, file descriptor usage and native threads count as well as the process start and up times. spandex - Platform agnostic tracing library originally developed for Datadog APM. telemetry - Dynamic dispatching library for metrics and instrumentations. wobserver - Web based metrics, monitoring, and observer. JSON Libraries and implementations working with JSON. exjson - JSON parser and generator in Elixir. ja_serializer - JSONAPI.org Serialization in Elixir. jason - A blazing fast JSON parser and generator in pure Elixir. jazz - Yet another library to handle JSON in Elixir. joken - Encodes and decodes JSON Web Tokens. jose - JSON Object Signing and Encryption (JOSE) for Erlang and Elixir. json - Native JSON library for Elixir. json_pointer - Implementation of RFC 6901 which defines a string syntax for identifying a specific value within a JSON document. json_stream_encoder - JsonStreamEncoder is a streaming encoder for streaming JSON to an IOish thing in Elixir. json_web_token_ex - An Elixir implementation of the JSON Web Token (JWT) Standards Track (RFC 7519). jsonapi - A project that will render your data models into JSONAPI Documents. jsx - An Erlang application for consuming, producing, and manipulating json. jsxn - jsx but with maps. jwalk - Helper module for working with Erlang representations of JSON. jwtex - A library to encode and decode JWT tokens. poison - Poison is a new JSON library for Elixir focusing on wicked-fast speed without sacrificing simplicity, completeness, or correctness. tiny - Tiny, fast and fully compliant JSON parser for Elixir. world_json - topojson country and state/province collections for elixir/erlang. Languages Languages built on top of Elixir. Elchemy - Compiler allowing to translate Elm programming language code to Elixir. lighthouse_scheme - A small Lisp-like language and interactive REPL, built in Elixir. Monkey - Elixir implementation of an interpreter and REPL for the js-like Monkey programming language. Lexical analysis All about lexical analyser, lexer, scanner, tokenizer or compiler. abnf_parsec - ABNF in and parser out. ex_abnf - Parser for ABNF Grammars in Elixir. lex_luthor - LexLuthor is a Lexer in Elixir which uses macros to generate a reusable lexers. Logging Logging infos and messages. bunyan - Bunyan: An Elixir Logger. exlager - Elixir binding for lager. exsentry - Error logging to Sentry. gelf_logger - A Logger backend that will generate Graylog Extended Log Format (GELF) messages. honeybadger - Error logging to Honeybadger. json_logger - JSON Logger is a logger backend that outputs elixir logs in JSON format. lager - A logging framework for Erlang/OTP by basho.com. lager_logger - A lager backend that forwards all log messages to Elixir's Logger. logfmt - Logfmt is a module for encoding and decoding logfmt-style log lines. logger_logstash_backend - A backend for the Elixir Logger that will send logs to the Logstash UDP input. logglix - A logger backend for posting errors to Loggly. logster - Easily parsable, one-line logging for Phoenix and Plug applications, inspired by Lograge. metrix - Log custom app metrics to stdout for use by Librato and other downstream processors. mstore - MStore is a experimental metric store build in erlang, the primary functions are open, new, get and put. quiet_logger - A simple plug to suppress health check logging (e.g.: when using Kubernetes). rogger - Elixir logger to publish log messages in RabbitMQ. rollbax - Exception tracking and logging to Rollbar. slack_logger_backend - A logger backend for posting errors to Slack. syslog - Erlang port driver for interacting with syslog via syslog(3). timber - Structured logging platform; turns raw text logs into rich structured events. youtrack_logger_backend - A logger backend that will post messages to YouTrack (an issue tracker made by JetBrains). Macros Macros for faster and easier development. Sugar for your code. anaphora - Anaphora is the anaphoric macro collection for Elixir. An anaphoric macro is one that deliberately captures a variable (typically it) from forms supplied to the macro. apix - Simple convention and DSL for transformation of elixir functions to an API for later documentation and or validation. backports - Use new functions in Elixir 1.1 and 1.2. crudry - Crudry is an elixir library for DRYing CRUD of Phoenix Contexts and Absinthe Resolvers. eventsourced - Build functional, event-sourced domain models. expat - Reusable, composable patterns across Elixir libraries. guardsafe - Macros expanding into code that can be safely used in guard clauses. kwfuns - Macros to create functions with syntax based keyword parameters with default values. lineo - parse transform for accurate line numbers. mdef - Easily define multiple function heads in Elixir. named_args - Allows named arg style arguments in Elixir. ok_jose - Pipe elixir functions that match {:ok,_}, {:error,_} tuples or custom patterns. opus - A framework for pluggable business logic components. pathex - Zero-dependency, blazing fast functional lenses. pattern_tap - Macro for tapping into a pattern match while using the pipe operator. pipe_here - Easily pipe values into any argument position. pipe_to - The enhanced pipe operator which can specify the target position. pipes - Macros for more flexible composition with the Elixir Pipe operator. pit - Transform values as they flow inside a pipe. rebind - rebind parse transform for Erlang. rulex - Simple rule handler using Elixir pattern matching. shorter_maps - ~M sigil for map shorthand. ~M{id name} ~> %{id: id, name: name}. unsafe - Generate easy unsafe (!) bindings for Elixir functions. Markdown Libraries and tools working with Markdown and such. cmark - Elixir NIF for CommonMark (in C), a parser following the CommonMark spec. discount - Elixir NIF for discount, a Markdown parser. earmark - Markdown parser for Elixir. Markdown - Implemented entirely as a NIF binding to the Hoedown library. Pandex - Lightweight Elixir wrapper for Pandoc. Converts Markdown, CommonMark, HTML, Latex, HTML, HTML5, opendocument, rtf, texttile, asciidoc to each other. Miscellaneous Useful libraries or tools that don't fit in the categories above. address_us - Library for parsing US Addresses into their individual parts. AlloyCI - AlloyCI is a Continuous Integration, Deployment, and Delivery coordinator, written in Elixir, that takes advantage of the GitLab CI Runner, and its capabilities as executor, to prepare and run your pipelines. Apex - Awesome Print for Elixir. AtomVM - AtomVM allows to run Elixir/Erlang code on embedded devices such as ESP32 and STM32 microcontrollers. bupe - EPUB Generator and Parser. charm - Use ANSI terminal characters to write colors and cursor positions. codec-beam - Generate Erlang VM byte code from Haskell. Countries - Countries is a collection of all sorts of useful information for every country in the ISO 3166 standard. countriex - A pure elixir country data provider containing various information for every country in ISO 3166. dye - A library for dyeing your terminal output. dynamic_compile - Compile and load Erlang modules from string input. ecto_autoslug_field - Automatically creates slugs for your Ecto models. egaugex - Client to fetch and parse realtime data from egauge devices. elixir-browser - Browser detection for Elixir. epub_cover_extractor - Extract cover from EPUB files. erlang_term - Provide the in-memory size of Erlang terms, ignoring where these are stored. ex2ms - Translates Elixir functions to match specifications for use with ets. ex_phone_number - Format, normalize, and validate phone numbers. ex_rated - Simple and flexible rate-limiting for API's or anything. exfcm - Simple wrapper for posting Firebase Cloud Messages. exldap - A module for working with LDAP from Elixir. exlibris - A collection of random library functions. expool - A small process pooling library for parallel tasks in Elixir. exprint - A printf / sprintf library for Elixir, works as a wrapper for :io.format. expyplot - Elixir interface for Plotting/Graphing library using matplotlib.pyplot. exquisite - LINQ-like match_spec generation for Elixir. exsync - Yet another Elixir reloader. funnel - Streaming Elixir API built upon ElasticSearch's percolation. gen_task - Generic Task behavior that helps to encapsulate worker errors and recover from them in classic GenStage's. gimei_ex - Elixir port of gimei library. growl - Simple wrapper for growl, the notification system for OSX. hammer - A rate-limiter with pluggable storage backends, including Redis. html_entities - Elixir module for decoding HTML entities in a string. huex - Elixir client for Philips Hue connected light bulbs. japan_municipality_key - Elixir Library for Japan municipality key converting. Jisho-Elixir - An API wrapper for Jisho.org, an online Japanese dictionary. Allows users to search by word, symbol, and or tags (refer to docs). keys1value - Erlang set associative map for key lists. licensir - A mix task that lists the license(s) of all installed packages in your project. mixgraph - An interactive dependency plotter for your Hex Package. mixstar - MixStar starred GitHub repository that depends on your project. netrc - Reads netrc files implemented in Elixir. notifier - A pluggable architecture for desktop notifications. onetime - An onetime key-value store for Elixir. pact - Better dependency injection in Elixir for cleaner code and testing. phone - A parser to get useful info from telephone numbers. porcelain - Porcelain implements a saner approach to launching and communicating with external OS processes from Elixir. presentex - Elixir to HTML/JavaScript based presentation framework. ratekeeper - Rate limiter and rate-limited actions scheduler. ratx - Rate limiter and overload protection for erlang application. reprise - Simplified module reloader for Elixir. spawndir - Spawns processes from the file system. spotify_ex - An Elixir wrapper for the Spotify Web API. std_json_io - Application for managing and communicating with IO servers via JSON. url_unroller - Simple URL unroller (un-shortener) in Elixir. vessel - Elixir MapReduce interfaces with Hadoop Streaming integration. Native Implemented Functions Tools and libraries working with Erlang NIF. hsnif - Tool that allows to write Erlang NIF libraries in Haskell. nifty - Helper script for setting up the boilerplate required when writing a NIF. Rustler - Library for writing NIFs for Erlang or Elixir safely in Rust. No segfaults. Natural Language Processing (NLP) Tools and libraries that work with human (natural) languages. gibran - Gibran is an Elixir port of WordsCounted, a natural language processor that extracts useful statistics from text. Paasaa - Natural language detection for Elixir. Petrovich - Elixir library to inflect Russian first, last, and middle names. Tongue - Elixir port of Nakatani Shuyo's natural language detector. Woolly - Woolly is an ambitious Text Mining and Natural Language Processing API for Elixir. Networking Libraries and tools for using network related stuff. asn - Can be used to map from IP to AS to ASN. chatter - Secure message broadcasting based on a mixture of UDP multicast and TCP. download - Download files from the internet easily. eio - Elixir server of engine.io. ExPcap - PCAP parser written in Elixir. FlyingDdns - A dyndns server written in elixir. hades - A wrapper for NMAP written in Elixir. mac - Can be used to find a vendor of a MAC given in hexadecimal string (according to IEEE). pool - Socket acceptor pool for Elixir. reagent - reagent is a socket acceptor pool for Elixir. sockerl - Sockerl is an advanced Erlang/Elixir socket library for TCP protocols and provides fast, useful and easy-to-use API for implementing servers, clients and client connection pools. socket - Socket wrapping for Elixir. sshex - Simple SSH helpers for Elixir. sshkit - An Elixir toolkit for performing tasks on one or more servers, built on top of Erlangs SSH application. torex - Simple Tor connection library. tunnerl - SOCKS4 and SOCKS5 proxy server. wifi - Various utility functions for working with the local Wifi network in Elixir. wpa_supplicant - Elixir interface to the wpa_supplicant. Office Libraries for working with office suite documents. elixlsx - A writer for XLSX files. excellent - An OpenXL (Excel 2000) Parser for Elixir. xlsxir - Xlsx file parser with support for ISO 8601 date formats. Data is extracted to an Erlang Term Storage (ETS) table and is accessed through various functions. ORM and Datamapping Libraries that implement object-relational mapping or datamapping techniques. amnesia - Mnesia wrapper for Elixir. arbor - Ecto adjacency list and tree traversal. arc_ecto - Arc.Ecto provides an integration with Arc and Ecto. atlas - Object Relational Mapper for Elixir. barrel_ex - Barrel-db distributed document-oriented database REST client in Elixir. Bolt.Sips - Neo4j driver for Elixir using the Bolt protocol. boltun - Transforms notifications from the Postgres LISTEN/NOTIFY mechanism into callback execution. caylir - Cayley driver for Elixir. comeonin_ecto_password - Ecto custom type for storing encrypted password using Comeonin. couchdb_connector - A connector for CouchDB, the Erlang-based, JSON document database. craterl - Erlang client for crate. database_url - Parse database URL and return keyword list for use with Ecto. datomex - Elixir driver for the Datomic REST API. ddb_client - DalmatinerDB client. defql - Create elixir functions with SQL as a body. dexts - Disk Elixir Terms Storage, dest wrapper. diver - A HBase driver for Erlang/Elixir using Jinterface and the Asynchbase Java client to query the database. dproto - Protocols for DalmatinerDB. dqe - DalmatinerDB query engine. ecto - A database wrapper and language integrated query for Elixir. ecto_cassandra - Cassandra DB Adapter for Ecto. ecto_enum - Ecto extension to support enums in models. ecto_facade - Ecto facade that allows to separate writes and reads to different databases. ecto_factory - Easily generate structs based on your ecto schemas. ecto_fixtures - Fixtures for Elixir apps using Ecto. ecto_lazy_float - Ecto.LazyFloat - An Ecto.Float that accepts binary and integers. ecto_migrate - Ecto auto migration library. It allows to generate and run migrations for initial and update migrations. ecto_mnesia - Ecto adapter for Mnesia Erlang term database. ecto_ordered - Ecto extension for ordered models. ecto_paging - Cursor-based pagination for Ecto. ecto_psql_extras - Ecto PostgreSQL database performance insights. ecto_rut - Simple and Powerful Ecto Shortcuts to simplify and speed up development. ecto_shortcuts - Shortcuts for common operations in ecto. ecto_shortuuid - Ecto type which adds support for ShortUUIDs. ecto_validation_case - Simplify your Ecto model validation tests. Loosely inspired by shoulda matchers, but simpler. ectophile - Ecto extension to instantly support file uploads in models. elastic - A thin-veneer over HTTPotion to help you talk to Elastic Search. elastix - A simple Elastic REST client written in Elixir. eredis - Erlang Redis client. erlastic_search - An Erlang app for communicating with Elastic Search's rest interface. esqlite - Erlang NIF for sqlite. eternal - Keep your ETS tables alive forever, safely and easily. ets_map - An Elixir package that provides a Map-like interface (Map/Access/Enumerable/Collectable) backed by an ETS table. eventstore - A CQRS EventStore using Postgres for persistence, written in Elixir. ex_bitcask - Elixir wrapper of Basho's Bitcask Key/Value store. ex_sider - Elixir Map/List/Set interfaces for Redis data structures (uses Redix, but that is configurable). exleveldb - Elixir wrapper around Basho's eleveldb module for LevelDB. exnumerator - Elixir enumerable type definition in a simple way to be used with any database. exredis - Redis client for Elixir. exseed - An Elixir library that provides a simple DSL for seeding databases through Ecto. exsolr - A Solr wrapper written in Elixir. extreme - An Elixir library using Eventstore for persistence of events generated by aggregates (CQRS). exts - Elixir Terms Storage, ets wrapper. github_ecto - Ecto adapter for GitHub API. gremlex - Apache Tinkerpop Gremlin Elixir Client. hstore - Hstore support for Postgrex. inquisitor - Composable query builder for Ecto. isn - Ecto types for the postgreSQL isn extension. kalecto - Glue between Kalends and Ecto for saving dates, times and datetimes. kvs - Erlang Abstract Term Database. level - Level for Elixir implements various helper functions and data types for working with Googles Level data store. mariaex - MariaDB/MySQL driver for Elixir. memento - Simple Mnesia Interface in Elixir. moebius - A functional query tool for Elixir and PostgreSQL. mongo - MongoDB driver for Elixir. mongodb - MongoDB driver for Elixir. mongodb_driver - Alternative driver for MongoDB with support for recent versions of MongoDB and comprehensive feature list. mongodb_ecto - MongoDB adapter for Ecto. mysql - MySQL/OTP MySQL driver for Erlang/OTP. mysqlex - An Ecto-compatible wrapper around the mysql-otp library. neo4j_sips - Neo4j driver for Elixir. neo4j_sips_models - Minimalistic Model support for the Neo4j.Sips Elixir driver. panoramix - Apache Druid client for Elixir. paper_trail - Ecto plugin for tracking and recording all the changes in your database. pillar - Clickhouse HTTP based client. postgrex - PostgreSQL driver for Elixir. red - Persist relationships between objects in Redis, in a graph-like way. rediscl - A minimal redis client with connection pooling and pipe query builder. redix - Superfast, pipelined, resilient Redis driver for Elixir. redo - Heroku's pipelining redis client for erlang. rethinkdb - Rethinkdb client in pure Elixir using JSON protocol. riak - A Riak client written in Elixir. riak_ecto - Riak adapter for Ecto. shards - Transparent and out-of-box Sharding support for Erlang/Elixir ETS tables. sql_dust - Generate (complex) SQL queries using magical Elixir SQL dust. sqlite_ecto - SQLite3 adapter for Ecto. sqlitex - An Elixir wrapper around esqlite. Allows access to sqlite3 databases. ssdb_elixir - ssdb client for Elixir, with focus on performance. tds - MSSQL / TDS Database driver for Elixir. tds_ecto - MSSQL / TDS Adapter for Ecto. timex_ecto - An adapter for using Timex DateTimes with Ecto. tirexs - An Elixir flavored DSL for building JSON based requests to Elasticsearch engine. triplex - Database multitenancy with postgres schemas for Elixir applications! triton - Pure Elixir Cassandra ORM built on top of Xandra. udpflux - An opinionated InfluxDB UDP only client. xandra - Cassandra driver built natively in Elixir and focused on speed, simplicity, and robustness. yar - Yet another Redis client for Elixir. OTP Libraries for working with OTP related things. core - Library for selective receive OTP processes. erlexec - Execute and control OS processes from Erlang/OTP. immortal - Immortal is a small collection of helper modules intended to make it easier to build a fault-tolerant OTP application. libex_config - Helpers for accessing OTP application configuration. Package Management Libraries and tools for package and dependency management. Hex - A package manager for the Erlang ecosystem. rebar3_hex - Hex.pm plugin for rebar3. PDF Libraries and software for working with PDF files. chromic_pdf - A client for Chrome's DevTools API to generate PDFs (HTML to PDF). gutenex - Native PDF generation for Elixir. pdf2htmlex - Convert PDF docs to beautiful HTML files without losing text or format. pdf_generator - A simple wrapper for wkhtmltopdf or puppeteer (HTML to PDF) for use in Elixir projects. puppeteer_pdf - Another wrapper around puppeteer (HTML to PDF) for use in Elixir projects. Protocols Special protocol and format libraries. elixir_radius - RADIUS Protocol on Elixir. ex_hl7 - Health Level 7 (HL7) is a protocol designed to model and transfer health-related data electronically. ex_marshal - Ruby Marshal format implemented in Elixir. exprotobuf - Protocol Buffers in Elixir, made easy. grpc-elixir - The Elixir implementation of gRPC. message_pack - MessagePack Implementation for Elixir. msgpax - MessagePack (de)serializer implementation for Elixir. protox - Elixir implementation for Protocol Buffers. riffed - Provides idiomatic Elixir bindings for Apache Thrift. Sippet - An Elixir library designed to be used as SIP protocol middleware. SMPPEX - SMPP 3.4 protocol and framework implementation in Elixir. Queue Libraries for working with event and task queues. adap - Create a data stream across your information systems to query, augment and transform data according to Elixir matching rules. amqp - Simple Elixir wrapper for the Erlang RabbitMQ client, based on Langohr. broadway - Concurrent and multi-stage data ingestion and data processing with Elixir. conduit - A framework for working with message queues, with adapters for SQS and AMQP, and plugs for reusable messaging patterns. cspex - Simple, OTP compliant, Elixir implementation of CSP channels. dbus - A dumb message bus for sharing data between microservices decoupled using Redis. ecto_job - A transactional job queue built with Ecto, PostgreSQL and GenStage. elixir_nsq - NSQ client library for Elixir. elixir_talk - An Elixir client for beanstalkd. enm - enm is an Erlang port driver that wraps the nanomsg C library. exdisque - Elixir client for Disque, an in-memory, distributed job queue. exq - Job processing library for Elixir - compatible with Resque/Sidekiq. exrabbit - RabbitMQ bindings and DSL for Elixir. flume - A blazing fast job processing system backed by GenStage & Redis. gen_rmq - Set of behaviours meant to be used to create RabbitMQ consumers and publishers. heapq - A Heap-based Priority Queue Implementation in Elixir. honeydew - Honeydew is a worker pool library for Elixir. hulaaki - An MQTT 3.1.1 client library written in Elixir. kaffe - Kafka client library for Elixir. mqs - RabbitMQ client library, routing keys, RPC over MQ and other stuff. oban - Robust asynchronous job processor powered by Elixir and modern PostgreSQL. opq - A simple, in-memory queue with worker pooling and rate limiting in Elixir. pqueue - Erlang Priority Queue Implementation. que - Simple Background Job Processing with Mnesia. queuex - Priority Queue with multiple backends. RBMQ - Simple API for spawning RabbitMQ Producers and Consumers. Rihanna - High performance postgres-backed job queue for Elixir. stream_weaver - Library for working with streams. task_bunny - background processing application written in Elixir and uses RabbitMQ as a messaging backend. toniq - Simple and reliable background job library for Elixir. verk - Verk is a job processing system backed by Redis. It uses the same job definition of Sidekiq/Resque. work_queue - Simple implementation of the hungry-consumer model in Elixir. Release Management Libraries and tools for release management. changex - Automated changelog generation from GIT logs. distillery - A pure Elixir implementation of release packaging functionality for the Erlang VM. eliver - Interactive semantic versioning for Elixir packages. exrm - Automatically generate a release for your Elixir project. exrm_deb - Create a deb for your Elixir release with ease. exrm_heroku - Publish your Elixir releases to Heroku with ease. exrm_rpm - Create a RPM for your Elixir release with ease. mix_docker - Put your Elixir app production release inside minimal docker image. relex - Erlang/Elixir Release Assembler. renew - Mix task to create mix projects that builds into Docker containers. REST and API Libraries and web tools for developing REST-ful APIs. accent - Plug for handling the conversion of JSON API keys to different cases. detergent - An emulsifying Erlang SOAP library. detergentex - Elixir binding to Detergent erlang library used to call WSDL/SOAP Services. maru - Elixir copy of grape for creating REST-like APIs. mazurka - Hypermedia API toolkit. plug_rest - REST behaviour and Plug router for hypermedia web applications. signaturex - Simple key/secret based authentication for APIs. SOAP client - Hex-documented SOAP client based on HTTPoison. urna - Urna is a simple DSL around cauldron to implement REST services. versionary - API versioning for Elixir Plug and Phoenix. Search Libraries related to search indexing, search algorithms and search clients. elasticsearch - A simple, no-nonsense Elasticsearch library for Elixir. elasticsearch_elixir_bulk_processor - An efficient and flexible way to insert into Elasticsearch. giza_sphinxsearch - Client for Sphinx Search compatible with Manticore. Security Libraries and tools regarding security. ca - Certificate Authority. clamxir - ClamAV wrapper for elixir. code_signing - Signing and verifying BEAM files with Ed25519 signatures. Ockam - A suite of tools, programming libraries and infrastructure that make it easy to build devices that communicate securely, privately and trustfully with cloud services and other devices. Docs . pwned - Check if your password has been pwned. safetybox - Security oriented helper functions for Elixir. sobelow - Security-focused static analysis for the Phoenix Framework. ssl_verify_fun - Collection of ssl verification functions for Erlang. SMS SMS related libraries and tools. exsms - An Elixir library for sending transactional SMS - supports Sendinblue, mailjet, msg91 and textlocal. Static Page Generation Tools and libraries for generating static websites and content. blogit - An OTP application for generating blogs from git repositories containing markdown files. coil - Minimalistic static content engine. glayu - A static site generator for mid-sized sites. medusa - Elixir static site generator that supports Pug. obelisk - Static blog and website generator. serum - A simple static website generator written in Elixir. Statistics Libraries around the topic statistics. descriptive_statistics - Descriptive Statistics for Elixir. mtx - MTX supports front-end API for tracking Histogram, Meter, Counter, Gauge, Timing keys. numerix - A collection of useful mathematical functions with a slant towards statistics, linear algebra and machine learning. simple_stat_ex - Ecto compatible library for simple stat keeping by time period. statistics - Some basic statistical functions for Elixir. Templating Libraries parsing and helping with templates bbmustache - Binary pattern match Based Mustache template engine for Erlang/OTP. calliope - An Elixir HAML parser. eml - Library for writing and manipulating (HTML) markup in Elixir. exgen - A templating library for quickly generating Elixir projects. expug - Pug templates for Elixir. mustache - Mustache templates for Elixir. mustachex - Mustache for Elixir - Logic-less templates. slime - An Elixir library for rendering slim-like templates. taggart - HTML as code in Elixir. templates - Helper library for adding templating to web applications. temple - An HTML DSL for Elixir and Phoenix. Testing Libraries for testing codebases and generating test data. amrita - A polite, well mannered and thoroughly upstanding testing framework for Elixir. apocryphal - Swagger based document driven development for ExUnit. blacksmith - Data generation framework for Elixir. blitzy - A simple HTTP load tester in Elixir. bypass - Bypass provides a quick way to create a mock HTTP server with a custom plug. chaperon - An HTTP service performance & load testing framework written in Elixir. chemistry - Testing Framework for Elixir. cobertura_cover - Writes a coverage.xml from mix test --cover file compatible with Jenkins' Cobertura plugin. definject - Unobtrusive dependency injector for Elixir. double - Create stub dependencies for testing without overwriting global modules. ecto_it - Ecto plugin with default configuration for repos for testing different ecto plugins with databases. efrisby - A REST API testing framework for erlang. elixir-auto-test - Run test when file is saved using inotify-tools. espec - BDD test framework for Elixir inspired by RSpec. espec_phoenix - ESpec for Phoenix web framework. ex_machina - Flexible test factories for Elixir. Works out of the box with Ecto and Ecto associations. ex_parameterized - Simple macro for parameterized testing. ex_spec - BDD-like syntax for ExUnit. ex_unit_fixtures - A library for defining modular dependencies for ExUnit tests. ex_unit_notifier - Desktop notifications for ExUnit. excheck - Property-based testing library for Elixir (QuickCheck style). exkorpion - A BDD library for Elixir developers. factory_girl_elixir - Minimal implementation of Ruby's factory_girl in Elixir. fake_server - FakeServer is an HTTP server that simulates response and makes testing external APIs easier. faker - Faker is a pure Elixir library for generating fake data. faker_elixir - FakerElixir is an Elixir package that generates fake data for you. fqc - FiFo Quickcheck helper, a set of helpers for running EQC. gimei - Gimei is a pure Elixir library for generating Japanese fake data. hound - Elixir library for writing integration tests and browser automation. hypermock - HTTP request stubbing and expectation Elixir library. ignorant - Partial Map comparison that ensures fields are present while ignoring their values. katt - KATT (Klarna API Testing Tool) is an HTTP-based API testing tool for Erlang. kovacs - A simple ExUnit test runner. markdown_test - A library that lets you test the Elixir code in your markdown files. meck - A mocking library for Erlang. mecks_unit - A package to elegantly mock module functions within (asynchronous) ExUnit tests using meck. mix_erlang_tasks - Common tasks for Erlang projects that use Mix. mix_eunit - A Mix task to execute eunit tests. mix_test_interactive - Interactive test runner for mix test with watch mode. mix_test_watch - Automatically run your Elixir project's tests each time you save a file. mixunit - An EUnit task for Mix based projects. mock - Mocking library for the Elixir language. mockery - Simple mocking library for asynchronous testing. mockingbird - A set of helpers to test code that involves http requests. mox - Mocks and explicit contracts for Elixir. pavlov - BDD framework for your Elixir projects. plug_test_helpers - A simple testing DSL for Plugs. ponos - Ponos is an Erlang application that exposes a flexible load generator API. power_assert - Power Assert in Elixir. Shows evaluation results each expression. proper - PropEr (PROPerty-based testing tool for ERlang) is a QuickCheck-inspired open-source property-based testing tool for Erlang. setup_tag - Easily mix and match functions marked with tags to setup your test context. shouldi - Elixir testing libraries with nested contexts, superior readability, and ease of use. test_selector - A set of test helpers that make sure you always select the right elements in your Phoenix app. test_that_json - JSON assertions and helpers for your Elixir testing needs. tuco_tuco - TucoTuco helps you test your web application by running a web browser and simulating user interaction with your application. Walkman - Isolate tests from the real world, inspired by Ruby's VCR. wallaby - Wallaby helps test your web applications by simulating user interactions concurrently and manages browsers. white_bread - Story based BDD in Elixir using the gherkin syntax. Text and Numbers Libraries for parsing and manipulating text and numbers. abacus - Evaluate math terms in Elixir. base58 - Base58 encoding/decoding for Elixir. base58check - Base58Check encoding/decoding for Bitcoin. base62 - Base62 encoder/decoder in pure Elixir. bencode - A Bencode encoder and decoder for Elixir. The decoder will return the checksum value of the info dictionary, if an info dictionary was found in the input. bencoder - bencode in Elixir. bitcoinex - Bitcoin utilities in Elixir. brcpfcnpj - Number format and Validation for Brazilian documents (CPF/CNPJ). caustic - Elixir cryptocurrency library for Bitcoin, Ethereum, and other blockchains. Includes cryptography, number theory (prime, congruence), and general mathematics library for exploratory math. ccc - Character Code Converter. chinese_translation - Translate between traditional chinese and simplified chinese based on wikipedia data, and translate chinese words/characters to pinyin (or slug with or without tone). cidr - Classless Inter-Domain Routing (CIDR) for Elixir. cirru_parser - Cirru Parser in Elixir. colorful - Elixir macros to decorate characters on CUI. colors - Colors util written in Elixir. convertat - An Elixir library for converting from and to arbitrary bases. curtail - HTML tag-safe string truncation. custom_base - Allow you to make custom base conversion in Elixir. decimal - Arbitrary precision decimal arithmetic for Elixir. dicer - A dice roller expression evaluator. eden - EDN encoder/decoder for Elixir. elixilorem - Lorem Ipsum generator for Elixir. elixir-range-extras - Elixir range utilities: constant-time random sampling and set operations. elixir_bencode - Bencode implemented in Elixir. erldn - EDN format parser for the Erlang platform. event_source_encoder - Encode data into EventSource compliant data. ex_brace_expansion - Brace expansion, as known from sh/bash, in Elixir. ex_cldr - Cldr is an Elixir library for the Unicode Consortium's Common Locale Data Repository (CLDR). ex_rfc3966 - Elixir Tel URI parser compatible with RFC3966. ex_rfc3986 - RFC3986 URI/URL parser. ex_uc - Extensible Units Converter for Elixir. exmoji - Emoji encoding Swiss Army knife for Elixir/Erlang. expletive - Profanity filter library for Elixir. expr - An Elixir library for parsing and evaluating mathematical expressions. faust - Markov Text Generator for Elixir. haikunator - Generate Heroku-like memorable random names to use in your apps or anywhere else. hashids - Hashids lets you obfuscate numerical identifiers via reversible mapping. hexate - Simple module for Hex encoding / decoding in Elixir. inet_cidr - Classless Inter-Domain Routing (CIDR) for Elixir that is compatible with :inet and supports both IPv4 and IPv6. inflex - An Inflector library for Elixir. kitsune - An Elixir library for transforming the representation of data. ltsvex - LTSV parser implementation in Elixir. mbcs - Wrapper for erlang-mbcs. This module provides functions for character encoding conversion. mimetype_parser - parse mimetypes. minigen - Random data generators for the Erlang ecosystem. monetized - A lightweight solution for handling and storing money. money - Working with Money safer, easier, and fun, interpretation of the Fowler's Money pattern. mt940 - MT940 (standard structured SWIFT Customer Statement message) parser for Elixir. nanoid - Elixir port of NanoID, a secure and URL-friendly unique ID generator. neotomex - A PEG implementation with a pleasant Elixir DSL. number - Number is a pretentiously-named Elixir library which provides functions to convert numbers into a variety of different formats. numero - A micro library for converting non-english utf-8 digits in elixir. palette - A handy library for colouring strings in Elixir. pinyin - Chinese Pinyin lib for Elixir. porterstemmer - Porter Stemmer in Elixir. pretty_hex - A binary hex dumping library in Elixir. quickrand - Quick Random Number Generation. RandomStringGenerator - A module to generate a random string based on a given string pattern. ref_inspector - Referer parser library in Elixir. Fetching info from URLs. remove_emoji - Emoji text sanitizer in Elixir. It can remove any emoji symbol. secure_random - Convenience library for random base64 strings modeled after my love for Ruby's SecureRandom. sentient - Simple sentiment analysis based on the AFINN-111 wordlist. shortuuid - Generate concise, unambiguous, URL-safe UUIDs. simetric - String similarity metrics for Elixir. slugger - Slugger can generate slugs from given strings that can be used in URLs or file names. smile - Small lib for converting emoji mappers to emoji characters, like in Slack messages. stemmer - An English (Porter2) stemming implementation in Elixir. tau - Provide the famous mathematical constant, tau, = 6.2831.... tomlex - A TOML parser for Elixir. ua_inspector - User agent parser library like piwik/device-detector. ua_parser2 - A port of ua-parser2 to Elixir. User agent parser library. unit_fun - Attempt to add units to numbers in elixir to give some added type safety when dealing with numeric quantities. uuid - UUID generator and utilities for Elixir. uuid_erl - Erlang Native UUID Generation. veritaserum - Sentiment analysis based on afinn-165, emojis and some enhancements. Third Party APIs Libraries for accessing third party APIs. airbax - Exception tracking from Elixir to Airbrake. airbrake - An Elixir notifier for the Airbrake. airbrakex - Elixir client for the Airbrake service. amazon_product_advertising_client - Amazon Product Advertising API client for Elixir. apns - Apple Push Notifications Service client library for elixir. asanaficator - Simple Elixir wrapper for the Asana API. Based on Tentacat. askimet_ex - Elixir client for Askimet Anti-Spam service. assembla_api - Assembla API client for Elixir. balalaika_bear - Simple VK API client for Elixir. balanced - Balanced API Client for Elixir. bandwidth - An Elixir client library for the Bandwidth Application Platform. bing_translator - A simple Elixir interface to Bing's translation API. bitmex - BitMEX client library for Elixir. bitpay - Elixir core library for connecting to bitpay.com. cashier - Payment gateway offering a common interface into multiple payment providers. cleverbot - Simple implementation of the Cleverbot API in Elixir. coinbase - A unofficial Coinbase API v1 Client. commerce_billing - A payment-processing library for Elixir that supports multiple gateways (e.g. Bogus & Stripe). conekta - Elixir wrapper for Conekta API. correios_cep - Find Brazilian addresses by zip code, directly from Correios database. No HTML parsers. currently - A tool to display cards currently assigns on Trello. darkskyx - A Darksky.com (formerly forecast.io) API client for Elixir. digitalocean - Elixir wrapper for the Digital Ocean API v2. digoc - Digital Ocean API v2 Elixir Client. diplomat - A Google Cloud Datastore client. dnsimple - Elixir client for the DNSimple API v2. docker - Elixir client for the Docker Remote API. dockerex - Lightweight Docker Remote API Client with SSL/TLS login/connection support. dogstatsd - An Elixir client for DogStatsd. dpd_client - An API client for the DPD service. dropbox - Dropbox Core API client for Elixir. dublin_bus_api - Access to the Real Time Passenger Information (RTPI) for Dublin Bus services. edgarex - Elixir interface for fetching SEC filings from EDGAR. elixir_authorizenet - Unofficial client for the Authorize.Net merchant API. elixir_ipfs_api - IPFS (InterPlanetary File System) API client for Elixir. elixirfm - Last.fm API wrapper for Elixir. elixtagram - Instagram API client for Elixir. ethereumex - Elixir JSON-RPC client for the Ethereum blockchain. everex - Evernote API client for Elixir. everyoneapi - API Client for EveryoneAPI.com. ex_changerate - Elixir client for exchangerate.host API. ex_codeship - API Client for Codeship. ex_statsd - A statsd client implementation for Elixir. ex_twilio - Twilio API client for Elixir. ex_twiml - Generate TwiML for your Twilio integration, right inside Elixir. exdesk - Elixir library for the Desk.com API. exfacebook - Facebook API, written in Elixir using similar methods like Ruby koala gem. exgenius - Elixir library for the (undocumented) Rap Genius API. exgravatar - An Elixir module for generating Gravatar URLs. exgrid - interact with Sendgrid's API. exjira - JIRA client library for Elixir. exlingr - A Lingr client module. explay - Unofficial Google Play API in Elixir. exstagram - Elixir library for Instagram v1 API. extwitter - Twitter client library for Elixir. exurban - Elixir wrapper for UrbanAirship API. facebook - Facebook Graph API Wrapper written in Elixir. feedlex - Feedly RSS reader client for Elixir. fluent_client - Minimalistic fluentd client. forcex - Elixir library for the Force.com REST API. forecast_io - Simple wrapper for Forecast.IO API. gcmex - Google Cloud Messaging client library for elixir. google-cloud - This repository contains all the client libraries to interact with Google APIs. google_sheets - Elixir library for fetching and polling Google spreadsheet data in CSV format. govtrack - A simple Elixir wrapper for the govtrack.us API. gringotts - A complete payment library for Elixir and Phoenix Framework similar to ActiveMerchant from the Ruby world. hexoku - Heroku API client and Heroku Mix tasks for Elixir projects. honeywell - A client for the Honeywell Lyric, Round and Water Leak & Freeze Detector APIs. kane - A Google Cloud Pub/Sub client. keenex - A Keen.io API Client. link_shrinkex - Elixir library for creating short URLs using Google's URL Shortener API. m2x - Elixir client for the AT&T M2X, a cloud-based fully managed time-series data storage service for network connected machine-to-machine (M2M) devices and the Internet of Things (IoT). (Erlang Version). mailchimp - A basic Elixir wrapper for version 3 of the MailChimp API. mailgun - Elixir Mailgun Client. mandrill - A Mandrill wrapper for Elixir. marvel - CLI and Elixir API Client for the Marvel API. mexpanel - An Elixir client for the Mixpanel HTTP API. mixpanel - An Elixir client for the Mixpanel HTTP API. mixpanel_data_client - Client for interacting with the Mixpanel Data Export API. mmExchangeRate - A simple exchange rate checker and calculator based on Central Bank of Myanmar Api. nadia - Telegram Bot API Wrapper written in Elixir. omise - Omise client library for Elixir. opbeat - Elixir client for Opbeat. pagexduty - A Pagerduty client for Elixir. parse_client - Elixir client for the parse.com REST API. parsex - ParsEx is an Elixir HTTP Client for communicating with Parse.com's Restful API. particle - An Elixir client for the Particle IoT platform's HTTP API. pathway - An Erlang/Elixir client for the Trak.io REST API. pay - An Elixir Lib to deal with Paypal and other payment solutions. pay_pal - Elixir library for working with the PayPal REST API. pigeon - HTTP2-compliant wrapper for sending iOS and Android push notifications. pocketex - Pocketex is an Elixir client for the Pocket read later service getpocket.com. pusher - Elixir library to access the Pusher REST API. qiita_ex - A Qiita API v2 Interface for Elixir. qiniu - Qiniu SDK for Elixir. random_user - An Elixir client for randomuser.me API. random_user_api - Another simple randomuser.me API client. reap - Reap is a simple Elixir library for working with the refheap API. reddhl - An headline and link puller for Reddit and its various subreddits. redtube - Redtube API Wrapper written in Elixir. reporter - Reporter is simple reporting App reviews library. Support AppStore and GooglePlay. riemann - A Riemann client for Elixir. rs_twitter - Low Level Twitter Client for Elixir. semver - Utilities for working with semver.org-compliant version strings. sendgrid - Send composable, transactional emails with SendGrid. shopify - Easily access the Shopify API. sift_ex - A Siftscience API Library for Elixir. simplex - An Elixir library for interacting with the Amazon SimpleDB API. slack - Slack real time messaging client in Elixir. sparkpost - An Elixir library for sending email using SparkPost. statix - Expose app metrics in the StatsD protocol. stripe - An Elixir Library wrapping Stripe's API. stripity_stripe - An Elixir Library for Stripe. tagplay - Elixir client for Tagplay API. telegex - Telegram bot library for Elixir. telephonist - Elixir state machines for Twilio calls. tentacat - Simple Elixir wrapper for the GitHub API. tg_client - An Elixir wrapper which communicates with the Telegram-CLI. traitify_elixir - An Elixir client library for the Traitify Developer's API. ui_faces - UIFaces API client for Elixir applications. unsplash-elixir - An Elixir library for Unsplash. vultr - Simple wrapper for the Vultr API. xe - Real time conversion for currencies. zanox - Zanox API. Translations and Internationalizations Libraries providing translations or internationalizations. exkanji - A Elixir library for translating between hiragana, katakana, romaji and kanji. It uses Mecab. exromaji - A Elixir library for translating between hiragana, katakana and romaji. getatrex - Automatic translation tool of Gettext locales with Google Translate for Elixir/Phoenix projects. gettext - Internationalization and localization support for Elixir. linguist - Elixir Internationalization library. parabaikElixirConverter - ParabaikElixirConverter is just a Elixir version of Parabaik converter. It can convert from Unicode to Zawgyi-One and Zawgyi-One to Unicode vice versa. trans - A Elixir library to manage embedded translations into models leveraging PostgreSQL JSONB datatype. Utilities Utilities libraries. ar2ecto - Ar2ecto is a set of mix tasks to help you migrate from ActiveRecord to Ecto. async_with - A modifier for Elixir's "with" to execute all its clauses in parallel. crutches - Utility library for Elixir, designed to complement the standard library bundled with the language. deppie - Elixir's coolest deprecation logger. dot-notes - Simple dot/bracket notation parsing/conversion for Maps/Lists. dress - Cli app that makes your stdout fancy. erlang-history - Hacks to add shell history to Erlang's shell. erlsh - Family of functions and ports involving interacting with the system shell, paths and external programs. erlware_commons - Additional standard library for Erlang. ex_progress - A library for tracking progress across many tasks and sub-tasks. exjprop - Elixir library for reading Java properties files from various sources. fitex - FitEx is a Macro-Module which provides a bit of sugar for function definitions. global - Wrapper of the Erlang :global module. mandrake - Mandrake is a functional programming library that bring something else magic in elixir. mnemonix - A unified interface to key/value stores. plasm - Plasm is Ecto's composable query multitool, containing higher-level functions such as .count, .random, .first, .last, .find, .inserted_before, .inserted_after, etc. pubsub - A Publish-Subscribe utility library that implements a pub-sub mechanism to ease the burden of communication on the business logic processes. quark - A library for common functional programming idioms: combinators, currying, and partial application. retry - Simple Elixir macros for linear retry, exponential backoff and wait with composable delays. sips_downloader - Elixir module for downloading the ElixirSips episodes and all other files. sitemap - Sitemap is the easiest way to generate Sitemaps in Elixir. uef-lib - Useful Erlang Functions Library that provides modules for manipulating lists, binaries, maps, numbers, date and time. It contains some functions optimized for performance in specific cases (e.g. for file I/O operations or binary transformations). vert.x - Elixir event bus bridge to Vert.x services using TCP socket. Validations Libraries and implementations for validation of data. bankster - A IBAN account number and BIC validation library for Elixir. ex_gtin - A validation library for GTIN codes under GS1 specification. ex_nric - Validation for Singapore National Registration Identity Card numbers (NRIC). exop - A library that allows to encapsulate business logic and validate params with predefined contract. form - Document forms and validation library. is - Fast, extensible and easy to use data structure validation for elixir with nested structures support. jeaux - A light and easy schema validator. optimal - A schema based keyword list option validator. shape - A data validation library for Elixir based on Prismatic Scheme. skooma - Simple data validation library for describing and validating data structures. uk_postcode - UK postcode parsing and validation library. vex - An extensible data validation library for Elixir. voorhees - A library for validating JSON responses. Version Control Working with version control like git, mercury, subversion ... gitex - Elixir implementation of the Git object storage, but with the goal to implement the same semantic with other storage and topics. Video Libraries for working with and manipulating video and multimedia. ffmpex - FFmpeg command line wrapper. silent_video - Convert GIFs and videos to silent videos, optimized for mobile playback. WebAssembly Libraries for running WebAssembly (WASM) in Elixir or running Elixir on WebAssembly. lumen - An alternative BEAM implementation, designed for WebAssembly. wasmex - Execute WebAssembly / WASM binaries from Elixir. XML Libraries and implementations working with XML (for html tools please go to the HTML section). elixir-map-to-xml - Converts an Elixir map to an XML document. elixir-xml-to-map - Creates an Elixir Map data structure from an XML string. erlsom - Erlsom is an Erlang library to parse (and generate) XML documents. exmerl - Elixir wrapper for xmerl. exml - Most simple Elixir wrapper for xmerl xpath. exoml - A module to decode/encode xml into a tree structure. fast_xml - Fast Expat based Erlang XML parsing library. meeseeks - A library for parsing and extracting data from HTML and XML with CSS or XPath selectors. quinn - XML parser for Elixir. saxy - Saxy is an XML parser and encoder in Elixir that focuses on speed and standard compliance. sweet_xml - Query XML simply and effectively. xml_builder - Elixir library for generating xml. xmlrpc - Library for encoding and decoding XML-RPC for clients and servers. YAML Libraries and implementations working with YAML. fast_yaml - Fast YAML is an Erlang wrapper for libyaml "C" library. yamerl - YAML 1.2 parser in Erlang. yaml_elixir - Yaml parser for Elixir based on native Erlang implementation. ymlr - A YAML encoder for Elixir. yomel - libyaml interface for Elixir. Resources Various resources, such as books, websites and articles, for improving your Elixir development skills and knowledge. Books Fantastic books and e-books. Adopting Elixir - Bring Elixir into your company, with real-life strategies from the people who built Elixir and use it successfully at scale. This book has all the information you need to take your application from concept to production (2017). Craft GraphQL APIs in Elixir with Absinthe - Upgrade your web API to GraphQL, leveraging its flexible queries to empower your users, and its declarative structure to simplify your code (2017). Create a cryptocurrency trading bot in Elixir - Looking for a real-world Elixir/OTP project to gain hands-on experience? This book will take you on a journey to create a cryptocurrency trading bot in Elixir. You will be able to see first-hand, how complex systems are designed and developed as we will build them together! (2021). Elixir Cookbook - This book is a set of recipes grouped by topic by Paulo A Pereira (2015). Elixir do zero concorrncia - (Portuguese) The book provides introduction to functional and concurrent programming with Elixir by Tiago Davi(2014). Elixir in Action - A brief intro to the language followed by a more detailed look at building production-ready systems in Elixir by Saa Juri (2015). Erlang and Elixir for Imperative Programmers - Introduction to Erlang and Elixir in the context of functional concepts by Wolfgang Loder (2016). Erlang in Anger - This book intends to be a little guide about how to be the Erlang medic in a time of war by Fred Hebert (2014). Functional Web Development with Elixir, OTP, and Phoenix - Open doors to powerful new techniques that will get you thinking about web development in fundamentally new ways (2017). Getting Started - Elixir - PDF, MOBI, and EPUB documents for Elixir's Getting Started tutorial (2016). Introducing Elixir - A gentle introduction to the language, with lots of code examples and exercises by Simon St. Laurent and J. David Eisenberg (2013). Learn Functional Programming with Elixir - Dont board the Elixir train with an imperative mindset! To get the most out of functional languages, you need to think functionally (2017). Metaprogramming Elixir: Write Less Code, Get More Done (and Have Fun!) - Thorough explanation on how to exploit Elixir's metaprogramming capabilities to improve your Elixir coding by Chris McCord (2015). Phoenix for Rails Developers - This book shows how Rails developers can benefit from their existing knowledge to learn Phoenix. By Elvio Vicosa (2017). Phoenix in Action - builds on your existing web dev skills, teaching you the unique benefits of Phoenix along with just enough Elixir to get the job done. By Geoffrey Lessel (2017). Phoenix Inside Out - The goal of this series is to enable you as a Confident Phoenix developer. There are 3 different editions to address varied needs of devs jumping into Phoenix. Programming Elixir 1.6 - The book provides introduction to functional and concurrent programming with Elixir by Dave Thomas (2014). Programming Phoenix 1.4 - Definitive guide to build web applications with the Phoenix framework by Chris McCord, Jos Valim and Bruce Tate (2015). The Beam Book - A description of the Erlang Runtime System ERTS and the virtual Machine BEAM. The Little Elixir & OTP Guidebook - A book for learning Elixir and OTP through small to medium-sized projects by Benjamin Tan Wei Hao (2014). tudes for Elixir - A collection of exercises to program in Elixir by J. David Eisenberg (2013) (Github Repo). Cheat Sheets Useful Elixir-related cheat sheets. benjamintanweihao/elixir-cheatsheets - GenServer and Supervisor cheatsheets. Community Getting in contact with the community via chat or mailinglist. #elixir-lang - The IRC Channel #elixir-lang on Freenode. Elixir Forum - Community run discussion forums for all things Elixir. elixir-lang-core - Mailinglist for Elixir Core development, use "talk" for questions and general discussions. elixir-lang-talk - Official Elixir Mailinglist for questions and discussions. ElixirSlack - Elixir Slack Community. Editors Editors and IDEs useable for Elixir/Erlang Alchemist - Elixir Tooling Integration Into Emacs. Alchemist-Server - Editor/IDE independent background server to inform about Elixir mix projects. Alchemist.vim - Elixir Tooling Integration Into Vim. Atom - Elixir language support for Atom. atom-elixir - An Atom package for Elixir. atom-iex - Run an IEx session in Atom. elixir-ls - A frontend-independent IDE "smartness" server for Elixir. Implements the JSON-based "Language Server Protocol" standard and provides debugger support via VS Code's debugger protocol. elixir-tmbundle - A TextMate and SublimeText bundle for Elixir. elixir_generator - Vim plugin to generate Elixir module and test files with one command. ElixirSublime - Elixir plugin for SublimeText 3 that provides code completion and linting. ilexir - IDE-like things for Elixir in Neovim. intellij_elixir - Elixir helpers for intellj-elixir, the Elixir plugin for JetBrains IDEs. Jetbrains - Elixir for IntelliJ IDEA, RubyMine, WebStorm, PhpStorm, PyCharm, AppCode, Android Studio, 0xDBE. Notepad++ - Elixir syntax highlighting for Notepad++. Nova Elixir - Syntax highlighting and code completion for Elixir files (.ex, .exs, .eex) in Nova. nvim - Neovim host for writing plugins in Elixir. phoenix-snippets - Phoenix Snippets for Atom. vim-elixir - Vim configuration files for Elixir. vim-ex_test - Vim test runner based on Thoughtbots vim-rspec. vim-mix-format - Async mix format for Vim and Neovim. vscode-elixir - Elixir Support for Visual Studio Code. vscode-elixir-ls - Elixir language support and debugger for VS Code, powered by ElixirLS. Newsletters Useful Elixir-related newsletters. Elixir Digest - A weekly newsletter with the latest articles on Elixir and Phoenix. Elixir Radar - The "official" Elixir newsletter, published weekly via email by Plataformatec. ElixirWeekly - The Elixir community newsletter, covering stuff you easily miss, shared on ElixirStatus and the web. Other Awesome Lists Other amazingly awesome lists can be found at jnv/lists or bayandin/awesome-awesomeness. Awesome Elixir and CQRS - A curated list of awesome Elixir and Command Query Responsibility Segregation (CQRS) and event sourcing resources. Awesome Elixir by LibHunt - A curated list of awesome Elixir and Erlang packages and resources. Awesome Erlang - A curated list of awesome Erlang libraries, resources and shiny things. Curated Elixir Resources - A collection of top recommended Elixir resources. Erlang Bookmarks - A collection of links for Erlang developers. Reading Elixir-related reading materials. Discover Elixir & Phoenix - An online course that teaches both the Elixir language and the Phoenix framework. Elixir Cheat-Sheet - A Elixir cheat sheet, by Andy Hunt & Dave Thomas. Elixir Functional Programming - Material to introduce functional programming using the Elixir language. Elixir School - Lessons about the Elixir programming language. Elixir Tab - Chrome Extension which helps you learn the Elixir core lib. Elixir vs Ruby | How Switching To Elixir Made Our Team Better - Long-form post that explains in detail when and why you should choose Elixir over Ruby. The Little Schemer in Elixir - Exercises and algorithms from the Little Schemer book, ported to Elixir. xElixir - Exercism Exercises in Elixir. Screencasts Cool video tutorials. Alchemist Camp - Alchemist.Camp has many hours of free, project-based Elixir-learning screencasts. Confreaks (Elixir) - Elixir related conference talks. Elixir for Programmers - Functional, Parallel, Reliable (and fun!), taught by Dave Thomas. Elixir Sips - Tiny screencasts for learning Elixir. ElixirCasts.io - Simple screencasts to help you learn Elixir and Phoenix. ExCasts - Elixir and Phoenix screencasts for all skill levels. Frathon's YouTube Channel - YouTube channel dedicated to promote functional programming, publishing "real world" programming videos in Elixir like "Create a cryptocurrency trading bot in Elixir" series. LearnElixir.tv - Beginner friendly, in-depth, step by step screencasts. LearnPhoenix.tv - Learn how to build fast, dependable web apps with Phoenix. Meet Elixir - Walk through some features and concepts of Elixir by Jos Valim. Styleguides Styleguides for ensuring consistency while coding. christopheradams/elixir_style_guide - A community-driven style guide for Elixir. lexmag/elixir-style-guide - An opinionated Elixir style guide. rrrene/elixir-style-guide - Style guide checked by Credo. Websites Useful Elixir-related websites. 30 Days of Elixir - A walk through the Elixir language in 30 exercises. BEAM Community - From distributed systems, to robust servers and language design on the Erlang VM. Benjamin Tan - Learnings & Writings - A blog consisting of mostly Elixir posts. Elixir Career - A job board for Elixir, and community of Elixir developers. Elixir China - Chinese Elixir website elixir-cn.com. Elixir Examples - A collection of small Elixir programming language examples. Elixir Flashcards - Flashcards are a powerful way to improve your knowledge. Elixircards are hand crafted, professionally printed flashcards for levelling up your Elixir. Elixir Fountain - A weekly podcast with news & interviews from around the Elixir community hosted by Johnny Winn. Elixir Github Repository - The project repository. Elixir Github Wiki - The project's wiki, containing much useful information. Elixir Quiz - Weekly programming problems to help you learn Elixir. Elixir Recipes - Collection of patterns & solutions to common problems in Elixir. Hashrocket Today I Learned - Elixir - Small posts about Elixir from the team at Hashrocket. How I start - Elixir - Explanation and intro to Elixir by Jos Valim. Learning Elixir - A blog about a Professional Software Engineer learning Elixir. Contributing Please see CONTRIBUTING for details.

 # # # # # # # # # # # # # # # # # # # #
 Repository: bramp/js-sequence-diagrams, index: 1263, word count: 4971 
 # # # # # # # # # # # # # # # # # # # #

Control and manage Android devices from your browser.Warning This project along with other ones in OpenSTF organisation is provided as is for community, without active development. You can check any other forks that may be actively developed and offer new/different features here. Active development has been moved to DeviceFarmer organisation. Version 3.4.2 is the last release of OpenSTF on DockerHub and 3.4.1 on npmjs. STF (or Smartphone Test Farm) is a web application for debugging smartphones, smartwatches and other gadgets remotely, from the comfort of your browser. STF was originally developed at CyberAgent to control a growing collection of more than 160 devices. As of July 2016 development is mainly sponsored by HeadSpin and other individual contributors. We welcome financial contributions in full transparency on our open collective. Credits Sponsors Thank you to all our sponsors! (please ask your company to also support this open source project by becoming a sponsor) Gold Sponsor HeadSpin provides secure and scalable STF for iOS integrated with Appium/XCTest/Selenium/Espresso, High speed interaction Audio/Video/Game testing and AI based Root cause analysis for Performance Management. It's free to start using HeadSpin in 150+ locations worldwide! Try it out for free. HeadSpin offers a generous monthly contribution towards STF development. Contributors Thank you to all the people who have already contributed to STF! Backers Thank you to all our backers! [Become a backer] How to become a sponsor Please use our open collective or contact us directly for sponsor arrangements. Both recurring and one-time contributions are most welcome. Contributions towards a specific issue or feature are also possible, and can be attributed to your company in our release notes and other related materials. Hardware-only contributions, whether new or used, are also extremely helpful and well received, especially if you find a device that doesn't work. Please see our donation transparency report for past hardware contributions. Features OS support Android Supports versions 2.3.3 (SDK level 10) to 9.0 (SDK level 28) Supports Wear 5.1 (but not 5.0 due to missing permissions) Supports Fire OS, CyanogenMod, and other heavily Android based distributions root is not required for any current functionality Remote control any device from your browser Real-time screen view Refresh speed can reach 30-40 FPS depending on specs and Android version. See minicap for more information. Rotation support Supports typing text from your own keyboard Supports meta keys Copy and paste support (although it can be a bit finicky on older devices, you may need to long-press and select paste manually) May sometimes not work well with non-Latin languages unfortunately. Multitouch support on touch screens via minitouch, two finger pinch/rotate/zoom gesture support on regular screens by pressing Alt while dragging Drag & drop installation and launching of .apk files Launches main launcher activity if specified in the manifest Reverse port forwarding via minirev Access your local server directly from the device, even if it's not on the same network Open websites easily in any browser Installed browsers are detected in real time and shown as selectable options Default browser is detected automatically if selected by the user Execute shell commands and see real-time output Display and filter device logs Use adb connect to connect to a remote device as if it was plugged in to your computer, regardless of ADB mode and whether you're connected to the same network Run any adb command locally, including shell access Android Studio and other IDE support, debug your app while watching the device screen on your browser Supports Chrome remote debug tools File Explorer to access device file system Experimental VNC support (work in progress) Monitor your device inventory See which devices are connected, offline/unavailable (indicating a weak USB connection), unauthorized or unplugged See who's using a device Search devices by phone number, IMEI, ICCID, Android version, operator, product name, group name and/or many other attributes with easy but powerful queries Show a bright red screen with identifying information on a device you need to locate physically Track battery level and health Rudimentary Play Store account management List, remove and add new accounts (adding may not work on all devices) Display hardware specs Use the Booking & Partitioning systems Overview The partitioning system allow you [administrator level] to allocate distinct sets of devices to different projects or organizations (i.e. represented by user sets) for an unlimited period The booking system allows you to reserve a set of devices for a set of users during a limited time (e.g. from 3:00 am to 4:00 am during 5 days) What is common to the booking & partitioning systems is the concept of Group, that is, an association of devices, users and a specification of time Report to GroupFeature.pdf for detailed documentation on how to use this feature Monitor your group inventory See which groups are active, ready or pending, as well as other group properties: name, identifier, owner, devices, users, class, duration, repetition, starting date, expiration date Search groups by their property values Contact by email the owners of the selected groups Manage your groups Create a group by specifying its name, devices, users and schedule Get ready your group in order it is scheduled by the system Search groups by their property values Remove your group or a selection of your groups Contact by email the owners of the selected groups [administrator level] Manage the devices [administrator level] Search the devices by their property values Remove a device or a selection of devices meeting a set of filters: present, booked, annotated, controlled Manage the users [administrator level] Create a user by providing his name and his email Search the users by their property values Remove a user or a selection of users meeting a set of filters: group owner Contact a user or a selection of users by email Set the default groups quotas applicable to all users Set the groups quotas applicable to a specific user Simple REST API Status STF is in continued, active development, but development is still largely funded by individual team members and their unpaid free time, leading to slow progress. While normal for many open source projects, STF is quite heavy on the hardware side, and is therefore somewhat of a money sink. See how to become a sponsor if you or your company would like to support future development. We're also actively working to expand the team, don't be afraid to ask if you're interested. Short term goals Here are some things we are planning to address ASAP. Performance Properly expose the new VNC functionality in the UI Properly reset user data between uses (Android 4.0+) Automated scheduled restarts for devices More! Consulting services We highly encourage open participation in the community. However, if you're running a business that uses STF or would like to use STF, you may sometimes want to have an expert, i.e. one of the original developers or a skilled contributor, work with you to set up a prototype for evaluation purposes, add support for new or old hardware, figure out an issue, fix a bug or add some new feature. Our services are similar to FFmpeg's. Contact us with details and we'll see what we can do. Availability is limited and tied to individual developer's schedules. A quick note about security As the product has evolved from an internal tool running in our internal network, we have made certain assumptions about the trustworthiness of our users. As such, there is little to no security or encryption between the different processes. Furthermore, devices do not get completely reset between uses, potentially leaving accounts logged in or exposing other sensitive data. This is not an issue for us, as all of our devices are test devices and are only used with test accounts, but it may be an issue for you if you plan on deploying STF to a multiuser environment. We welcome contributions in this area. Requirements Node.js 8.x required (some dependencies don't support newer versions) ADB properly set up RethinkDB >= 2.2 GraphicsMagick (for resizing screenshots) ZeroMQ libraries installed Protocol Buffers libraries installed yasm installed (for compiling embedded libjpeg-turbo) pkg-config so that Node.js can find the libraries Note that you need these dependencies even if you've installed STF directly from NPM, because they can't be included in the package. On Mac OS, you can use homebrew to install most of the dependencies: On Windows you're on your own. In theory you might be able to get STF installed via Cygwin or similar, but we've never tried. In principle we will not provide any Windows installation support, but please do send a documentation pull request if you figure out what to do. We also provide a Docker container in the Docker Hub as openstf/stf. You can use our Dockerfile as guidance if you'd prefer to do the installation yourself. You should now be ready to build or run STF. Note that while Mac OS can be used for development, it doesn't provide a very reliable experience in production due to (presumed) bugs in ADB's Mac OS implementation. We use CoreOS but any Linux or BSD distribution should do fine. Installation As mentioned earlier, you must have all of the requirements installed first. Then you can simply install via NPM: Now you're ready to run. For development, though, you should build instead. Building After you've got all the requirements installed, it's time to fetch the rest of the dependencies. First, fetch all NPM and Bower modules: You may also wish to link the module so that you'll be able to access the stf command directly from the command line: You should now have a working installation for local development. Running STF comprises of several independent processes that must normally be launched separately. In our own setup each one these processes is its own systemd unit. See DEPLOYMENT.md and Setup Examples if you're interested. For development purposes, however, there's a helper command to quickly launch all required processes along with a mock login implementation. Note that you must have RethinkDB running first. If you don't have RethinkDB set up yet, to start it up, go to the folder where you'd like RethinkDB to create a rethinkdb_data folder in (perhaps the folder where this repo is) and run the following command: Note: if it takes a long time for RethinkDB to start up, you may be running into rethinkdb/rethinkdb#4600 (or rethinkdb/rethinkdb#6047). This usually happens on macOS Sierra. To fix this on macOS, first run scutil --get HostName to check if the HostName variable is unset. RethinkDB needs it to generate a server name for your instance. If you find that it's empty, running sudo scutil --set HostName $(hostname) has been confirmed to fix the issue on at least one occasion. See the issues for more complete solutions. You should now have RethinkDB running locally. Running the command again in the same folder will reuse the data from the previous session. An administrator level is available in STF in addition of the native user one, with increased rights on some features (e.g. booking & partitioning systems, management of users & devices, ...). The corresponding built-in administrator user has the following default credentials: - name: administrator - email: administrator@fakedomain.com Another built-in object exists, this is the root standard group to which the users and devices belong the first time they register to the STF database, its default name is Common These built-in objects are created in the STF database if they do not already exist Of course, you can override the default values of these built-in objects by settings the following environment variables before to initialize the STF database through stf local or stf migrate commands: - root standard group name: STF_ROOT_GROUP_NAME - administrator user name: STF_ADMIN_NAME - administrator user email: STF_ADMIN_EMAIL You're now ready to start up STF itself: After the webpack build process has finished (which can take a small while) you should have your private STF running on http://localhost:7100. If you had devices connected before running the command, those devices should now be available for use. If not, you should see what went wrong from your console. Feel free to plug in or unplug any devices at any time. Note that if you see your device ready to use but without a name or a proper image, we're probably missing the data for that model in our device database. Everything should work fine either way. If you want to access STF from other machines, you can add the --public-ip option for quick testing. Updating To update your development version, simply pull the repo and run npm install again. You may occasionally have to remove the whole node_modules and res/bower_components folder to prevent NPM or Bower from complaining about version mismatches. FAQ Can I deploy STF to actual servers? Yes, see DEPLOYMENT.md and Setup Examples. Will I have to change battery packs all the time? No, not all the time. Aside from a single early failure we had within only a few months, all of our devices were doing fine for about two years. However, having reached the 2-3 year mark, several devices have started to experience visibly expanded batteries. Expanded batteries should be replaced as soon as possible. Note that this issue isn't specific to STF, it's just what happens over time. You should be prepared to replace the batteries every now and then. In any case, we consider 2 years per battery pack to be fairly good value for a device lab. You should set up your devices so that the display is allowed to turn off entirely after a short timeout. 30 seconds or so should do just fine, STF will wake it up when necessary. Otherwise you risk reducing the lifetime of your device. Note that you may have a problem if your USB hubs are unable to both provide enough power for charging and support a data connection at the same time (data connections require power, too). This can cause a device to stop charging when being used, resulting in many charging cycles. If this happens you will just need to get a better USB hub. Is the system secure? It's possible to run the whole user-facing side behind HTTPS, but that's pretty much it. All internal communication between processes is insecure and unencrypted, which is a problem if you can eavesdrop on the network. See our quick note about security. Can I just put the system online, put a few devices there and start selling it? Yes and no. See "Is the system secure?". The system has been built in an environment where we are able to trust our users and be confident that they're not going to want to mess with others. In the current incarnation of the system a malicious user with knowledge of the inner workings will, for instance, be able to control any device at any time, whether it is being used by someone or not. Pull requests are welcome. Once I've got the system running, can I pretty much leave it like that or is manual intervention required? In our experience the system runs just fine most of the time, and any issues are mostly USB-related. You'll usually have to do something about once a week. The most common issue is that a device will lose all of its active USB connections momentarily. You'll get errors in the logs but the worker process will either recover or get respawned, requiring no action on your side. Below are the most common errors that do require manual intervention. One device worker keeps getting respawned all the time Rebooting the device usually helps. If the device stays online for long enough you might be able to do it from the UI. Otherwise you'll have to SSH into the server and run adb reboot manually. This could be a sign that you're having USB problems, and the device wishes to be moved elsewhere. The less complex your setup is the fewer problems you're going to experience. See troubleshooting. We're working on adding periodic automatic restarts and better graceful recovery to alleviate the issue. A whole group of devices keeps dying at once They're most likely connected to the same USB hub. Either the hub is bad or you have other compatibility issues. In our experience this usually happens with USB 3.0 hubs, or you may have a problem with your USB extension card. See recommended hardware. A device that should be online is not showing up in the list or is showing up as disconnected See troubleshooting. How do I uninstall STF from my device? When you unplug your device, all STF utilities except STFService stop running automatically. It doesn't do any harm to force stop or uninstall it. To uninstall the STFService, run the following command: You may also wish to remove our support binaries, although as mentioned before they won't run unless the device is actually connected to STF. You can do this as follows: Your device is now clean. Troubleshooting I plugged in a new device but it's not showing up in the list. There can be various reasons for this behavior. Some especially common reasons are: USB debugging is not enabled Enable it. USB debugging is enabled but the USB connection mode is wrong Try switching between MTP and PTP modes and see if the device appears. This happens fairly often on Mac OS but almost never on Linux. You don't have the ADB daemon running Make sure ADB is running with adb start-server. You haven't authorized the ADB key yet Check your device for an authentication dialog. You may need to unplug and then plug the device back in to see the dialog. ADB hasn't whitelisted the manufacturer's vendor ID Add it yourself or wait for the new version that removes the stupid whitelisting feature to be deployed. Insufficient power supply If you're using a USB hub, try a powered hub instead (one that comes with a separate AC adapter). Even if you're using a powered hub, there might not actually be enough power for all ports simultaneously. Get a better hub or use fewer ports. Your device is too power hungry, can happen with tablets. Get a better hub. Insufficient USB host controller resources On Linux, use dmesg to check for this error If you've only got 9-12 devices connected and an Intel (Haswell) processor, it's most likely an issue with the processor. If your BIOS has an option to disable USB 3.0, that might help. If not, you're screwed and must get a PCIE extension card with onboard controllers. Your powered USB hub does not support the device Can happen with older devices and newer Battery Charging spec compatible hubs. Get a more compatible hub. The USB cable is bad It happens. Try another one. The USB hub is broken This, too, happens. Just try a new one. The device might not have a unique USB serial number, causing STF to overwrite the other device instead This has never happened to us so far, but we do have one dirt-cheap Android 4.4 device whose serial number is the wonderfully unique "0123456789ABCDEF". Presumably if we had more than one unit we would have a problem. A device that was previously connected no longer shows up in the list. Again, there can be various reasons for this behavior as well. Some common reasons are: The device ran out of power You can see the last reported power level in the device list, unless there was a lengthy power outage preventing the battery level from being reported. Someone accidentally disabled USB debugging remotely Yes, it happens. An OS update disabled USB debugging Yes, it happens. Especially on Fire OS. Someone touched the USB cable just the wrong way causing a disconnection Happens easily. Your PCIE USB extension card died Yes, it happens. Temporary network issues Can't help with that. Someone removed the device physically. Or that. You're on Mac OS There's a bug in ADB's Mac OS implementation that causes devices to be lost on error conditions. The problem is more pronounced when using USB hubs. You have to unplug and then plug it back in again. The USB hub broke Happens. Just try a new one. Remote debugging (i.e. adb connect) disconnects while I'm working. If you're using STF locally, the most common cause is that you're not filtering the devices STF is allowed to connect to. The problem is that once you do adb connect, STF sees a new device and tries to set it up. Unfortunately since it's already connected via USB, setting up the new device causes the worker process handling the original USB device to fail. This is not a problem in production, since the devices should be connected to an entirely different machine anyway. For development it's a bit inconvenient. What you can do is give stf local a list of serials you wish to use. For example, if your device's serial is 0123456789ABCDEF, use stf local 0123456789ABCDEF. Now you can use adb connect and STF will ignore the new device. There's another likely cause if you're running STF locally. Even if you whitelist devices by serial in STF, your IDE (e.g. Android Studio) doesn't know anything about that. From the IDE's point of view, you have two devices connected. When you try to run or debug your application, Android Studio suddenly notices that two devices are now providing JDWP connections and tries to connect to them both. This doesn't really work since the debugger will only allow one simultaneous connection, which causes problems with ADB. It then decides to disconnect the device (or sometimes itself) entirely. One more sad possibility is that your Android Studio likes to restart ADB behind the scenes. Even if you restart ADB, USB devices will soon reappear as they're still connected. The same is not true for remote devices, as ADB never stores the list anywhere. This can sometimes also happen with the Android Device Monitor (monitor). Recommended hardware This is a list of components we are currently using and are proven to work. PC components These components are for the PC where the USB devices are connected. Our operating system of choice is CoreOS, but any other Linux or BSD distribution should do fine. Be sure to use reasonably recent kernels, though, as they often include improvements for the USB subsystem. Our currently favorite build is as follows. It will be able to provide 28 devices using powered USB hubs, and about 10 more if you're willing to use the motherboard's USB ports, which is usually not recommended for stability reasons. Note that our component selection is somewhat limited by their availability in Japan. | Component | Recommendation | How many | |-----------|------|----------| | PC case | XIGMATEK Nebula | x1 | | Motherboard | ASUS H97I-PLUS | x1 | | Processor | Intel Core i5-4460 | x1 | | PSU | Corsair CX Series Modular CX430M ATX Power Supply | x1 | | Memory | Your favorite DDR3 1600 MHz 8GB stick | x1 | | SSD | A-DATA Premier Pro SP900 64GB SSD | x1 | | USB extension card | StarTech.com 4 Port PCI Express (PCIe) SuperSpeed USB 3.0 Card Adapter w/ 4 Dedicated 5Gbps Channels - UASP - SATA / LP4 Power | x1 | | USB hub | Plugable USB 2.0 7 Port Hub with 60W Power Adapter | x4 | | MicroUSB cable | Monoprice.com 1.5ft USB 2.0 A Male to Micro 5pin Male 28/24AWG Cable w/ Ferrite Core (Gold Plated) | x28 | You may also need extension cords for power. Alternatively, if you find that some of your older devices do not support the recommended hub, you may wish to mix the hub selection as follows: | Component | Recommendation | How many | |-----------|------|----------| | USB hub | Plugable USB 2.0 7 Port Hub with 60W Power Adapter | x2 | | USB hub for older devices | System TALKS USB2-HUB4XA-BK | x2-4 | You can connect up to two of the older hubs (providing up to 8 devices total) directly to the motherboard without exhausting USB host controller resources. We also have several "budget builds" with an MSI AM1I motherboard and an AMD Athlon 5350 4-core processor. These builds, while significantly cheaper, sometimes completely lose the USB PCIE extension cards, and even a reboot will not always fix it. This may normally be fixable via BIOS USB settings, but unfortunately the budget motherboard has a complete lack of any useful options. Fortunately the AMD processor does not share Intel's Haswell USB host control resource problem, so you can also just connect your hubs to the motherboard directly if you don't mind sharing the root bus. Below is an incomplete list of some of the components we have tried so far, including unsuitable ones. Tested equipment Note that our hardware score ratings only reflect their use for the purposes of this project, and are not an overall statement about the quality of the product. USB extension cards | Name | Score | Short explanation | |------|-------|-------------------| | StarTech.com 4 Port PCI Express (PCIe) SuperSpeed USB 3.0 Card Adapter w/ 4 Dedicated 5Gbps Channels - UASP - SATA / LP4 Power | 9/10 | Reliable, well supported chipset and good power connections | | StarTech.com 4 Independent Port PCI Express USB 2.0 Adapter Card | 8/10 | Reliable | | USB3.0RX4-P4-PCIE | 4/10 | Well supported chipset but breaks VERY easily | Our current recommendation is StarTech.com's PEXUSB3S44V. It provides an independent Renesas (allegedly Linux-friendliest) PD720202 host controller for each port. Another option from the same maker is PEXUSB400, which also works great but may offer slightly less future proofing. Our USB3.0RX4-P4-PCIE cards have been nothing but trouble and we've mostly phased them out by now. Chipset-wise it's pretty much the same thing as StarTech's offering, but the SATA power connector is awfully flimsy and can actually physically break off. The card is also incredibly sensitive to static electricity and will permanently brick itself, which happened on numerous occasions. USB hubs | Name | Score | Short explanation | |------|-------|-------------------| | Plugable USB 2.0 7 Port Hub with 60W Power Adapter | 8/10 | High power output, high reliability | | Plugable USB 3.0 7-port Charging Hub with 60W Power Adapter | 5/10 | High power output, low reliability | | System TALKS USB2-HUB4XA-BK USB 2.0 hub with power adapter | 7/10 | High power output on two ports which complicates device positioning, low port count | | Anker USB 3.0 9-Port Hub + 5V 2.1A Charging Port | 2/10 | High port count, insufficient power | | ORICO P10-U2 External ABS 10 Port 2.0 USB HUB for Laptop/Desktop-BLACK | 3/10 | High port count, insufficient power | | ORICO BH4-U3-BK ABS 4 Port USB3.0 BC1.2 Charging HUB with 12V3A Power Adapter-BLACK | 5/10 | High power output, low reliability | The best hub we've found so far is Plugable's USB 2.0 7 Port Hub with 60W Power Adapter. It's able to provide 1.5A per port for Battery Charging spec compliant devices, which is enough to both charge and sync even tablets (although charging will not occur at maximum speed, but that's irrelevant to us). Note that even devices that are not compliant will usually charge and sync just fine, albeit slower. The more recent USB 3.0 version has proven unreliable with the rest of our components, causing the whole hub to disconnect at times. Annoyingly the ports face the opposite direction, too. Note that ORICO also provides hubs that are identical to Plugable's offerings, the latter of which seem to be rebrands. Unfortunately Plugable's USB 2.0 hub is not perfect either, at least for our purposes. It includes a physical on/off switch which can be especially annoying if your devices are in a regular office with occasional scheduled power outages. This will shut down the PC too, of course, but the problem is that once power comes back online, the hubs will be unable to switch themselves on and the devices won't charge, leading you to find a bunch of dead devices the next Monday. The System TALKS USB 2.0 hub is very reliable, but has a few annoying drawbacks. First, the power adapter only provides power to two of its four ports, while the other two are powered by the host PC. The problem with this approach is that you must figure out which devices are power hungry yourself and put them on the ports with higher current. This can complicate device setup/positioning quite a bit. Another drawback is that if the host PC is turned off, only the powered ports will keep charging the connected devices. However, the hub is amazingly compatible with pretty much anything, making it the top choice for older devices that do not support the Battery Charging hubs. Most powered USB 3.0 hubs we've tested have had a serious problem: the whole hub occasionally disconnected. This may have been caused by the specific combination of our components and/or OS, but as of yet we don't really know. Disabling USB 3.0 may help if you run into the same problem. Translating Currently STF UI is available in English and Japanese. If you would like translate to any other language, please contribute in the STF Transifex project. For updating the source and all the translation files first you have to install the Transifex client. Then just run: It will do the following: Convert all the jade files to html. Extract with gettext all translatable strings to stf.pot. Push stf.pot to Transifex. Pull from Transifex all po translations. Compile all po files to json. Then in order to add it officially (only needs to be done once): Add the language to res/common/lang/langs.json. Pull the specific language tx pull -l <lang>. Run gulp translate. Testing See TESTING.md. Contributing See CONTRIBUTING.md. License See LICENSE. Copyright 2017 The OpenSTF Project. All Rights Reserved.

 # # # # # # # # # # # # # # # # # # # #
 Repository: OpenRA/OpenRA, index: 1718, word count: 4102 
 # # # # # # # # # # # # # # # # # # # #

a simple and fast JSON logging module for node.js servicesBunyan is a simple and fast JSON logging library for node.js services: and a bunyan CLI tool for nicely viewing those logs: Manifesto: Server logs should be structured. JSON's a good format. Let's do that. A log record is one line of JSON.stringify'd output. Let's also specify some common names for the requisite and common fields for a log record (see below). Table of Contents Current Status Installation Features Introduction Constructor API Log Method API CLI Usage Streams Introduction log.child Serializers Requirements for serializers functions Standard Serializers src Levels Level suggestions Log Record Fields Core fields Recommended/Best Practice Fields Other fields to consider Streams Adding a Stream stream errors stream type: stream stream type: file stream type: rotating-file stream type: raw raw + RingBuffer Stream third-party streams Runtime log snooping via DTrace DTrace examples Runtime environments Browserify Webpack Versioning License See Also Current Status Stable. I do my best to follow semver: i.e. you should only need to worry about code breaking for a major version bump. Bunyan currently supports node 0.10 and greater. Follow @trentmick for updates to Bunyan. There is an email discussion list bunyan-logging@googlegroups.com, also as a forum in the browser. Active branches: - "1.x" is for 1.x maintenance work, if any. 1.x releases are still "latest" in npm. - "master" is currently for coming Bunyan 2.x work. For now, 2.x releases are published to npm with the "beta" tag, meaning that npm install bunyan is still 1.x for now. To install 2.x use npm install bunyan@2 or npm install bunyan@beta. Installation Tip: The bunyan CLI tool is written to be compatible (within reason) with all versions of Bunyan logs. Therefore you might want to npm install -g bunyan to get the bunyan CLI on your PATH, then use local bunyan installs for node.js library usage of bunyan in your apps. Tip: Installing without optional dependencies can dramatically reduce bunyan's install size. dtrace-provider is used for dtrace features, mv is used for RotatingFileStream, and moment is used for local time. If you don't need these features, consider installing with the --no-optional flag. Features elegant log method API extensible streams system for controlling where log records go (to a stream, to a file, log file rotation, etc.) bunyan CLI for pretty-printing and filtering of Bunyan logs simple include of log call source location (file, line, function) with src: true lightweight specialization of Logger instances with log.child custom rendering of logged objects with "serializers" Runtime log snooping via DTrace support Support for a few runtime environments: Node.js, Browserify, Webpack, NW.js. Introduction Like most logging libraries you create a Logger instance and call methods named after the logging levels: All loggers must provide a "name". This is somewhat akin to the log4j logger "name", but Bunyan doesn't do hierarchical logger names. Bunyan log records are JSON. A few fields are added automatically: "pid", "hostname", "time" and "v". Constructor API Log Method API The example above shows two different ways to call log.info(...). The full API is: Note that this implies you cannot blindly pass any object as the first argument to log it because that object might include fields that collide with Bunyan's core record fields. In other words, log.info(mywidget) may not yield what you expect. Instead of a string representation of mywidget that other logging libraries may give you, Bunyan will try to JSON-ify your object. It is a Bunyan best practice to always give a field name to included objects, e.g.: This will dove-tail with Bunyan serializer support, discussed later. The same goes for all of Bunyan's log levels: log.trace, log.debug, log.info, log.warn, log.error, and log.fatal. See the levels section below for details and suggestions. CLI Usage Bunyan log output is a stream of JSON objects. This is great for processing, but not for reading directly. A bunyan tool is provided for pretty-printing bunyan logs and for filtering (e.g. | bunyan -c 'this.foo == "bar"'). Using our example above: See the screenshot above for an example of the default coloring of rendered log output. That example also shows the nice formatting automatically done for some well-known log record fields (e.g. req is formatted like an HTTP request, res like an HTTP response, err like an error stack trace). One interesting feature is filtering of log content, which can be useful for digging through large log files or for analysis. We can filter only records above a certain level: Or filter on the JSON fields in the records (e.g. only showing the French records in our contrived example): See bunyan --help for other facilities. Streams Introduction By default, log output is to stdout and at the "info" level. Explicitly that looks like: That is an abbreviated form for a single stream. You can define multiple streams at different levels. More on streams in the Streams section below. log.child Bunyan has a concept of a child logger to specialize a logger for a sub-component of your application, i.e. to create a new logger with additional bound fields that will be included in its log records. A child logger is created with log.child(...). In the following example, logging on a "Wuzzle" instance's this.log will be exactly as on the parent logger with the addition of the widget_type field: Running that looks like (raw): And with the bunyan CLI (using the "short" output mode): A more practical example is in the node-restify web framework. Restify uses Bunyan for its logging. One feature of its integration, is that if server.use(restify.requestLogger()) is used, each restify request handler includes a req.log logger that is: Apps using restify can then use req.log and have all such log records include the unique request id (as "req_id"). Handy. Serializers Bunyan has a concept of "serializer" functions to produce a JSON-able object from a JavaScript object, so you can easily do the following: and have the req entry in the log record be just a reasonable subset of <request object> fields (or computed data about those fields). A logger instance can have a serializers mapping of log record field name ("req" in this example) to a serializer function. When creating the log record, Bunyan will call the serializer function for top-level fields of that name. An example: Typically serializers are added to a logger at creation time via: Serializers can also be added after creation via <logger>.addSerializers(...), e.g.: Requirements for serializers functions A serializer function is passed unprotected objects that are passed to the log.info, log.debug, etc. call. This means a poorly written serializer function can cause side-effects. Logging shouldn't do that. Here are a few rules and best practices for serializer functions: A serializer function should never throw. The bunyan library does protect somewhat from this: if the serializer throws an error, then bunyan will (a) write an ugly message on stderr (along with the traceback), and (b) the field in the log record will be replaced with a short error message. For example: A serializer function should never mutate the given object. Doing so will change the object in your application. A serializer function should be defensive. In my experience, it is common to set a serializer in an app, say for field name "foo", and then accidentally have a log line that passes a "foo" that is undefined, or null, or of some unexpected type. A good start at defensiveness is to start with this: Standard Serializers Bunyan includes a small set of "standard serializers", exported as bunyan.stdSerializers. Their use is completely optional. An example using all of them: or particular ones: Standard serializers are: | Field | Description | | ----- | ----------- | | err | Used for serializing JavaScript error objects, including traversing an error's cause chain for error objects with a .cause() -- e.g. as from verror. | | req | Common fields from a node.js HTTP request object. | | res | Common fields from a node.js HTTP response object. | Note that the req and res serializers intentionally do not include the request/response body, as that can be prohibitively large. If helpful, the restify framework's audit logger plugin has its own req/res serializers that include more information (optionally including the body). src The source file, line and function of the log call site can be added to log records by using the src: true config option: This adds the call source info with the 'src' field, like this: WARNING: Determining the call source info is slow. Never use this option in production. Levels The log levels in bunyan are as follows. The level descriptions are best practice opinions of the author. "fatal" (60): The service/app is going to stop or become unusable now. An operator should definitely look into this soon. "error" (50): Fatal for a particular request, but the service/app continues servicing other requests. An operator should look at this soon(ish). "warn" (40): A note on something that should probably be looked at by an operator eventually. "info" (30): Detail on regular operation. "debug" (20): Anything else, i.e. too verbose to be included in "info" level. "trace" (10): Logging from external libraries used by your app or very detailed application logging. Setting a logger instance (or one of its streams) to a particular level implies that all log records at that level and above are logged. E.g. a logger set to level "info" will log records at level info and above (warn, error, fatal). While using log level names is preferred, the actual level values are integers internally (10 for "trace", ..., 60 for "fatal"). Constants are defined for the levels: bunyan.TRACE ... bunyan.FATAL. The lowercase level names are aliases supported in the API, e.g. log.level("info"). There is one exception: DTrace integration uses the level names. The fired DTrace probes are named 'bunyan-$levelName'. Here is the API for querying and changing levels on an existing logger. Recall that a logger instance has an array of output "streams": Level suggestions Trent's biased suggestions for server apps: Use "debug" sparingly. Information that will be useful to debug errors post mortem should usually be included in "info" messages if it's generally relevant or else with the corresponding "error" event. Don't rely on spewing mostly irrelevant debug messages all the time and sifting through them when an error occurs. Trent's biased suggestions for node.js libraries: IMHO, libraries should only ever log at trace-level. Fine control over log output should be up to the app using a library. Having a library that spews log output at higher levels gets in the way of a clear story in the app logs. Log Record Fields This section will describe rules for the Bunyan log format: field names, field meanings, required fields, etc. However, a Bunyan library doesn't strictly enforce all these rules while records are being emitted. For example, Bunyan will add a time field with the correct format to your log records, but you can specify your own. It is the caller's responsibility to specify the appropriate format. The reason for the above leniency is because IMO logging a message should never break your app. This leads to this rule of logging: a thrown exception from log.info(...) or equivalent (other than for calling with the incorrect signature) is always a bug in Bunyan. A typical Bunyan log record looks like this: Pretty-printed: Core fields v: Required. Integer. Added by Bunyan. Cannot be overridden. This is the Bunyan log format version (require('bunyan').LOG_VERSION). The log version is a single integer. 0 is until I release a version "1.0.0" of node-bunyan. Thereafter, starting with 1, this will be incremented if there is any backward incompatible change to the log record format. Details will be in "CHANGES.md" (the change log). level: Required. Integer. Added by Bunyan. Cannot be overridden. See the "Levels" section. name: Required. String. Provided at Logger creation. You must specify a name for your logger when creating it. Typically this is the name of the service/app using Bunyan for logging. hostname: Required. String. Provided or determined at Logger creation. You can specify your hostname at Logger creation or it will be retrieved via os.hostname(). pid: Required. Integer. Filled in automatically at Logger creation. time: Required. String. Added by Bunyan. Can be overridden. The date and time of the event in ISO 8601 Extended Format format and in UTC, as from Date.toISOString(). msg: Required. String. Every log.debug(...) et al call must provide a log message. src: Optional. Object giving log call source info. This is added automatically by Bunyan if the "src: true" config option is given to the Logger. Never use in production as this is really slow. Go ahead and add more fields, and nested ones are fine (and recommended) as well. This is why we're using JSON. Some suggestions and best practices follow (feedback from actual users welcome). Recommended/Best Practice Fields err: Object. A caught JS exception. Log that thing with log.info(err) to get: Or use the bunyan.stdSerializers.err serializer in your Logger and do this log.error({err: err}, "oops"). See "examples/err.js". req_id: String. A request identifier. Including this field in all logging tied to handling a particular request to your server is strongly suggested. This allows post analysis of logs to easily collate all related logging for a request. This really shines when you have a SOA with multiple services and you carry a single request ID from the top API down through all APIs (as node-restify facilitates with its 'Request-Id' header). req: An HTTP server request. Bunyan provides bunyan.stdSerializers.req to serialize a request with a suggested set of keys. Example: res: An HTTP server response. Bunyan provides bunyan.stdSerializers.res to serialize a response with a suggested set of keys. Example: Other fields to consider req.username: Authenticated user (or for a 401, the user attempting to auth). Some mechanism to calculate response latency. "restify" users will have an "X-Response-Time" header. A latency custom field would be fine. req.body: If you know that request bodies are small (common in APIs, for example), then logging the request body is good. Streams A "stream" is Bunyan's name for where it outputs log messages (the equivalent to a log4j Appender). Ultimately Bunyan uses a Writable Stream interface, but there are some additional attributes used to create and manage the stream. A Bunyan Logger instance has one or more streams. In general streams are specified with the "streams" option: For convenience, if there is only one stream, it can be specified with the "stream" and "level" options (internally converted to a Logger.streams). Note that "file" streams do not support this shortcut (partly for historical reasons and partly to not make it difficult to add a literal "path" field on log records). If neither "streams" nor "stream" are specified, the default is a stream of type "stream" emitting to process.stdout at the "info" level. Adding a Stream After a bunyan instance has been initialized, you may add additional streams by calling the addStream function. stream errors A Bunyan logger instance can be made to re-emit "error" events from its streams. Bunyan does so by default for type === "file" streams, so you can do this: As of bunyan@1.7.0, the reemitErrorEvents field can be used when adding a stream to control whether "error" events are re-emitted on the Logger. For example: var EventEmitter = require('events').EventEmitter; var util = require('util'); function MyFlakyStream() {} util.inherits(MyFlakyStream, EventEmitter); MyFlakyStream.prototype.write = function (rec) { this.emit('error', new Error('boom')); } var log = bunyan.createLogger({ name: 'this-is-flaky', streams: [ { type: 'raw', stream: new MyFlakyStream(), reemitErrorEvents: true } ] }); log.info('hi there'); The behaviour is as follows: reemitErrorEvents not specified: file streams will re-emit error events on the Logger instance. reemitErrorEvents: true: error events will be re-emitted on the Logger for any stream with a .on() function -- which includes file streams, process.stdout/stderr, and any object that inherits from EventEmitter. reemitErrorEvents: false: error events will not be re-emitted for any streams. Note: "error" events are not related to log records at the "error" level as produced by log.error(...). See the node.js docs on error events for details. stream type: stream A type === 'stream' is a plain ol' node.js Writable Stream. A "stream" (the writable stream) field is required. E.g.: process.stdout, process.stderr. Field Required? Default Description stream Yes - A "Writable Stream", e.g. a std handle or an open file write stream. type No n/a `type == 'stream'` is implied if the `stream` field is given. level No info The level to which logging to this stream is enabled. If not specified it defaults to "info". If specified this can be one of the level strings ("trace", "debug", ...) or constants (`bunyan.TRACE`, `bunyan.DEBUG`, ...). This serves as a severity threshold for that stream so logs of greater severity will also pass through (i.e. If level="warn", error and fatal will also pass through this stream). name No - A name for this stream. This may be useful for usage of `log.level(NAME, LEVEL)`. See the [Levels section](#levels) for details. A stream "name" isn't used for anything else. stream type: file A type === 'file' stream requires a "path" field. Bunyan will open this file for appending. E.g.: Field Required? Default Description path Yes - A file path to which to log. type No n/a `type == 'file'` is implied if the `path` field is given. level No info The level to which logging to this stream is enabled. If not specified it defaults to "info". If specified this can be one of the level strings ("trace", "debug", ...) or constants (`bunyan.TRACE`, `bunyan.DEBUG`, ...). This serves as a severity threshold for that stream so logs of greater severity will also pass through (i.e. If level="warn", error and fatal will also pass through this stream). name No - A name for this stream. This may be useful for usage of `log.level(NAME, LEVEL)`. See the [Levels section](#levels) for details. A stream "name" isn't used for anything else. stream type: rotating-file WARNING on node 0.8 usage: Users of Bunyan's rotating-file should (a) be using at least bunyan 0.23.1 (with the fix for this issue), and (b) should use at least node 0.10 (node 0.8 does not support the unref() method on setTimeout(...) needed for the mentioned fix). The symptom is that process termination will hang for up to a full rotation period. WARNING on cluster usage: Using Bunyan's rotating-file stream with node.js's "cluster" module can result in unexpected file rotation. You must not have multiple processes in the cluster logging to the same file path. In other words, you must have a separate log file path for the master and each worker in the cluster. Alternatively, consider using a system file rotation facility such as logrotate on Linux or logadm on SmartOS/Illumos. See this comment on issue #117 for details. A type === 'rotating-file' is a file stream that handles file automatic rotation. This will rotate '/var/log/foo.log' every day (at midnight) to: Currently, there is no support for providing a template for the rotated files, or for rotating when the log reaches a threshold size. Field Required? Default Description type Yes - "rotating-file" path Yes - A file path to which to log. Rotated files will be "$path.0", "$path.1", ... period No 1d The period at which to rotate. This is a string of the format "$number$scope" where "$scope" is one of "ms" (milliseconds -- only useful for testing), "h" (hours), "d" (days), "w" (weeks), "m" (months), "y" (years). Or one of the following names can be used "hourly" (means 1h), "daily" (1d), "weekly" (1w), "monthly" (1m), "yearly" (1y). Rotation is done at the start of the scope: top of the hour (h), midnight (d), start of Sunday (w), start of the 1st of the month (m), start of Jan 1st (y). count No 10 The number of rotated files to keep. level No info The level at which logging to this stream is enabled. If not specified it defaults to "info". If specified this can be one of the level strings ("trace", "debug", ...) or constants (`bunyan.TRACE`, `bunyan.DEBUG`, ...). name No - A name for this stream. This may be useful for usage of `log.level(NAME, LEVEL)`. See the [Levels section](#levels) for details. A stream "name" isn't used for anything else. Note on log rotation: Often you may be using external log rotation utilities like logrotate on Linux or logadm on SmartOS/Illumos. In those cases, unless you are ensuring "copy and truncate" semantics (via copytruncate with logrotate or -c with logadm) then the fd for your 'file' stream will change. You can tell bunyan to reopen the file stream with code like this in your app: where you'd configure your log rotation to send SIGUSR2 (or some other signal) to your process. Any other mechanism to signal your app to run log.reopenFileStreams() would work as well. stream type: raw raw: Similar to a "stream" writable stream, except that the write method is given raw log record Objects instead of a JSON-stringified string. This can be useful for hooking on further processing to all Bunyan logging: pushing to an external service, a RingBuffer (see below), etc. raw + RingBuffer Stream Bunyan comes with a special stream called a RingBuffer which keeps the last N records in memory and does not write the data anywhere else. One common strategy is to log 'info' and higher to a normal log file but log all records (including 'trace') to a ringbuffer that you can access via a debugger, or your own HTTP interface, or a post-mortem facility like MDB or node-panic. To use a RingBuffer: This example emits: third-party streams See the user-maintained list in the Bunyan wiki. Runtime log snooping via DTrace On systems that support DTrace (e.g., illumos derivatives like SmartOS and OmniOS, FreeBSD, Mac), Bunyan will create a DTrace provider (bunyan) that makes available the following probes: Each of these probes has a single argument: the string that would be written to the log. Note that when a probe is enabled, it will fire whenever the corresponding function is called, even if the level of the log message is less than that of any stream. DTrace examples Trace all log messages coming from any Bunyan module on the system. (The -x strsize=4k is to raise dtrace's default 256 byte buffer size because log messages are longer than typical dtrace probes.) Trace all log messages coming from the "wuzzle" component: Aggregate debug messages from process 1234, by message: Have the bunyan CLI pretty-print the traced logs: A convenience handle has been made for this: On systems that support the jstack action via a node.js helper, get a stack backtrace for any debug message that includes the string "danger!": Output of the above might be: Runtime environments Node-bunyan supports running in a few runtime environments: Node.js Browserify: See the Browserify section below. Webpack: See the Webpack section below. NW.js Support for other runtime environments is welcome. If you have suggestions, fixes, or mentions that node-bunyan already works in some other JavaScript runtime, please open an issue or a pull request. The primary target is Node.js. It is the only environment in which I regularly test. If you have suggestions for how to automate testing for other environments, I'd appreciate feedback on this automated testing issue. Browserify As the Browserify site says it "lets you require('modules') in the browser by bundling up all of your dependencies." It is a build tool to run on your node.js script to bundle up your script and all its node.js dependencies into a single file that is runnable in the browser via: As of version 1.1.0, node-bunyan supports being run via Browserify. The default stream when running in the browser is one that emits raw log records to console.log/info/warn/error. Here is a quick example showing you how you can get this working for your script. Get browserify and bunyan installed in your module: An example script using Bunyan, "play.js": Build this into a bundle to run in the browser, "play.browser.js": Put that into an HTML file, "play.html": Open that in your browser and open your browser console: Here is what it looks like in Firefox's console: For some, the raw log records might not be desired. To have a rendered log line you'll want to add your own stream, starting with something like this: webpack To include bunyan in your webpack bundle you need to tell webpack to ignore the optional dependencies that are unavailable in browser environments. Mark the following dependencies as externals in your webpack configuration file to exclude them from the bundle: Versioning All versions are <major>.<minor>.<patch> which will be incremented for breaking backward compat and major reworks, new features without breaking change, and bug fixes, respectively. tl;dr: Semantic versioning. License MIT. See Also See the user-maintained list of Bunyan-related software in the Bunyan wiki.

 # # # # # # # # # # # # # # # # # # # #
 Repository: pardom/ActiveAndroid, index: 1389, word count: 7812 
 # # # # # # # # # # # # # # # # # # # #

JSON for Modern C++Design goals Sponsors Integration CMake Package Managers Pkg-config Examples JSON as first-class data type Serialization / Deserialization STL-like access Conversion from STL containers JSON Pointer and JSON Patch JSON Merge Patch Implicit conversions Conversions to/from arbitrary types Specializing enum conversion Binary formats (BSON, CBOR, MessagePack, and UBJSON) Supported compilers License Contact Thanks Used third-party tools Projects using JSON for Modern C++ Notes Execute unit tests Design goals There are myriads of JSON libraries out there, and each may even have its reason to exist. Our class had these design goals: Intuitive syntax. In languages such as Python, JSON feels like a first class data type. We used all the operator magic of modern C++ to achieve the same feeling in your code. Check out the examples below and you'll know what I mean. Trivial integration. Our whole code consists of a single header file json.hpp. That's it. No library, no subproject, no dependencies, no complex build system. The class is written in vanilla C++11. All in all, everything should require no adjustment of your compiler flags or project settings. Serious testing. Our class is heavily unit-tested and covers 100% of the code, including all exceptional behavior. Furthermore, we checked with Valgrind and the Clang Sanitizers that there are no memory leaks. Google OSS-Fuzz additionally runs fuzz tests against all parsers 24/7, effectively executing billions of tests so far. To maintain high quality, the project is following the Core Infrastructure Initiative (CII) best practices. Other aspects were not so important to us: Memory efficiency. Each JSON object has an overhead of one pointer (the maximal size of a union) and one enumeration element (1 byte). The default generalization uses the following C++ data types: std::string for strings, int64_t, uint64_t or double for numbers, std::map for objects, std::vector for arrays, and bool for Booleans. However, you can template the generalized class basic_json to your needs. Speed. There are certainly faster JSON libraries out there. However, if your goal is to speed up your development by adding JSON support with a single header, then this library is the way to go. If you know how to use a std::vector or std::map, you are already set. See the contribution guidelines for more information. Sponsors You can sponsor this library at GitHub Sponsors. :label: Named Sponsors Michael Hartmann Stefan Hagen Steve Sperandeo Robert Jefe Lindstdt Steve Wagner Thanks everyone! Integration json.hpp is the single required file in single_include/nlohmann or released here. You need to add to the files you want to process JSON and set the necessary switches to enable C++11 (e.g., -std=c++11 for GCC and Clang). You can further use file include/nlohmann/json_fwd.hpp for forward-declarations. The installation of json_fwd.hpp (as part of cmake's install step), can be achieved by setting -DJSON_MultipleHeaders=ON. CMake You can also use the nlohmann_json::nlohmann_json interface target in CMake. This target populates the appropriate usage requirements for INTERFACE_INCLUDE_DIRECTORIES to point to the appropriate include directories and INTERFACE_COMPILE_FEATURES for the necessary C++11 flags. External To use this library from a CMake project, you can locate it directly with find_package() and use the namespaced imported target from the generated package configuration: The package configuration file, nlohmann_jsonConfig.cmake, can be used either from an install tree or directly out of the build tree. Embedded To embed the library directly into an existing CMake project, place the entire source tree in a subdirectory and call add_subdirectory() in your CMakeLists.txt file: Embedded (FetchContent) Since CMake v3.11, FetchContent can be used to automatically download the repository as a dependency at configure time. Example: Note: The repository https://github.com/nlohmann/json download size is huge. It contains all the dataset used for the benchmarks. You might want to depend on a smaller repository. For instance, you might want to replace the URL above by https://github.com/ArthurSonzogni/nlohmann_json_cmake_fetchcontent Supporting Both To allow your project to support either an externally supplied or an embedded JSON library, you can use a pattern akin to the following: thirdparty/nlohmann_json is then a complete copy of this source tree. Package Managers :beer: If you are using OS X and Homebrew, just type brew tap nlohmann/json and brew install nlohmann-json and you're set. If you want the bleeding edge rather than the latest release, use brew install nlohmann-json --HEAD. If you are using the Meson Build System, add this source tree as a meson subproject. You may also use the include.zip published in this project's Releases to reduce the size of the vendored source tree. Alternatively, you can get a wrap file by downloading it from Meson WrapDB, or simply use meson wrap install nlohmann_json. Please see the meson project for any issues regarding the packaging. The provided meson.build can also be used as an alternative to cmake for installing nlohmann_json system-wide in which case a pkg-config file is installed. To use it, simply have your build system require the nlohmann_json pkg-config dependency. In Meson, it is preferred to use the dependency() object with a subproject fallback, rather than using the subproject directly. If you are using Conan to manage your dependencies, merely add nlohmann_json/x.y.z to your conanfile's requires, where x.y.z is the release version you want to use. Please file issues here if you experience problems with the packages. If you are using Spack to manage your dependencies, you can use the nlohmann-json package. Please see the spack project for any issues regarding the packaging. If you are using hunter on your project for external dependencies, then you can use the nlohmann_json package. Please see the hunter project for any issues regarding the packaging. If you are using Buckaroo, you can install this library's module with buckaroo add github.com/buckaroo-pm/nlohmann-json. Please file issues here. There is a demo repo here. If you are using vcpkg on your project for external dependencies, then you can use the nlohmann-json package. Please see the vcpkg project for any issues regarding the packaging. If you are using cget, you can install the latest development version with cget install nlohmann/json. A specific version can be installed with cget install nlohmann/json@v3.1.0. Also, the multiple header version can be installed by adding the -DJSON_MultipleHeaders=ON flag (i.e., cget install nlohmann/json -DJSON_MultipleHeaders=ON). If you are using CocoaPods, you can use the library by adding pod "nlohmann_json", '~>3.1.2' to your podfile (see an example). Please file issues here. If you are using NuGet, you can use the package nlohmann.json. Please check this extensive description on how to use the package. Please files issues here. If you are using conda, you can use the package nlohmann_json from conda-forge executing conda install -c conda-forge nlohmann_json. Please file issues here. If you are using MSYS2, your can use the mingw-w64-nlohmann-json package, just type pacman -S mingw-w64-i686-nlohmann-json or pacman -S mingw-w64-x86_64-nlohmann-json for installation. Please file issues here if you experience problems with the packages. If you are using build2, you can use the nlohmann-json package from the public repository https://cppget.org or directly from the package's sources repository. In your project's manifest file, just add depends: nlohmann-json (probably with some version constraints). If you are not familiar with using dependencies in build2, please read this introduction. Please file issues here if you experience problems with the packages. If you are using wsjcpp, you can use the command wsjcpp install "https://github.com/nlohmann/json:develop" to get the latest version. Note you can change the branch ":develop" to an existing tag or another branch. If you are using CPM.cmake, you can check this example. After adding CPM script to your project, implement the following snippet to your CMake: Pkg-config If you are using bare Makefiles, you can use pkg-config to generate the include flags that point to where the library is installed: Users of the Meson build system will also be able to use a system wide library, which will be found by pkg-config: Examples Beside the examples below, you may want to check the documentation where each function contains a separate code example (e.g., check out emplace()). All example files can be compiled and executed on their own (e.g., file emplace.cpp). JSON as first-class data type Here are some examples to give you an idea how to use the class. Assume you want to create the JSON object With this library, you could write: Note that in all these cases, you never need to "tell" the compiler which JSON value type you want to use. If you want to be explicit or express some edge cases, the functions json::array() and json::object() will help: Serialization / Deserialization To/from strings You can create a JSON value (deserialization) by appending _json to a string literal: Note that without appending the _json suffix, the passed string literal is not parsed, but just used as JSON string value. That is, json j = "{ \"happy\": true, \"pi\": 3.141 }" would just store the string "{ "happy": true, "pi": 3.141 }" rather than parsing the actual object. The above example can also be expressed explicitly using json::parse(): You can also get a string representation of a JSON value (serialize): Note the difference between serialization and assignment: .dump() returns the originally stored string value. Note the library only supports UTF-8. When you store strings with different encodings in the library, calling dump() may throw an exception unless json::error_handler_t::replace or json::error_handler_t::ignore are used as error handlers. To/from streams (e.g. files, string streams) You can also use streams to serialize and deserialize: These operators work for any subclasses of std::istream or std::ostream. Here is the same example with files: Please note that setting the exception bit for failbit is inappropriate for this use case. It will result in program termination due to the noexcept specifier in use. Read from iterator range You can also parse JSON from an iterator range; that is, from any container accessible by iterators whose value_type is an integral type of 1, 2 or 4 bytes, which will be interpreted as UTF-8, UTF-16 and UTF-32 respectively. For instance, a std::vector<std::uint8_t>, or a std::list<std::uint16_t>: You may leave the iterators for the range [begin, end): Custom data source Since the parse function accepts arbitrary iterator ranges, you can provide your own data sources by implementing the LegacyInputIterator concept. SAX interface The library uses a SAX-like interface with the following functions: The return value of each function determines whether parsing should proceed. To implement your own SAX handler, proceed as follows: Implement the SAX interface in a class. You can use class nlohmann::json_sax<json> as base class, but you can also use any class where the functions described above are implemented and public. Create an object of your SAX interface class, e.g. my_sax. Call bool json::sax_parse(input, &my_sax); where the first parameter can be any input like a string or an input stream and the second parameter is a pointer to your SAX interface. Note the sax_parse function only returns a bool indicating the result of the last executed SAX event. It does not return a json value - it is up to you to decide what to do with the SAX events. Furthermore, no exceptions are thrown in case of a parse error - it is up to you what to do with the exception object passed to your parse_error implementation. Internally, the SAX interface is used for the DOM parser (class json_sax_dom_parser) as well as the acceptor (json_sax_acceptor), see file json_sax.hpp. STL-like access We designed the JSON class to behave just like an STL container. In fact, it satisfies the ReversibleContainer requirement. Conversion from STL containers Any sequence container (std::array, std::vector, std::deque, std::forward_list, std::list) whose values can be used to construct JSON values (e.g., integers, floating point numbers, Booleans, string types, or again STL containers described in this section) can be used to create a JSON array. The same holds for similar associative containers (std::set, std::multiset, std::unordered_set, std::unordered_multiset), but in these cases the order of the elements of the array depends on how the elements are ordered in the respective STL container. Likewise, any associative key-value containers (std::map, std::multimap, std::unordered_map, std::unordered_multimap) whose keys can construct an std::string and whose values can be used to construct JSON values (see examples above) can be used to create a JSON object. Note that in case of multimaps only one key is used in the JSON object and the value depends on the internal order of the STL container. JSON Pointer and JSON Patch The library supports JSON Pointer (RFC 6901) as alternative means to address structured values. On top of this, JSON Patch (RFC 6902) allows to describe differences between two JSON values - effectively allowing patch and diff operations known from Unix. JSON Merge Patch The library supports JSON Merge Patch (RFC 7386) as a patch format. Instead of using JSON Pointer (see above) to specify values to be manipulated, it describes the changes using a syntax that closely mimics the document being modified. Implicit conversions Supported types can be implicitly converted to JSON values. It is recommended to NOT USE implicit conversions FROM a JSON value. You can find more details about this recommendation here. You can switch off implicit conversions by defining JSON_USE_IMPLICIT_CONVERSIONS to 0 before including the json.hpp header. When using CMake, you can also achieve this by setting the option JSON_ImplicitConversions to OFF. Note that char types are not automatically converted to JSON strings, but to integer numbers. A conversion to a string must be specified explicitly: Arbitrary types conversions Every type can be serialized in JSON, not just STL containers and scalar types. Usually, you would do something along those lines: It works, but that's quite a lot of boilerplate... Fortunately, there's a better way: Basic usage To make this work with one of your types, you only need to provide two functions: That's all! When calling the json constructor with your type, your custom to_json method will be automatically called. Likewise, when calling get<your_type>() or get_to(your_type&), the from_json method will be called. Some important things: Those methods MUST be in your type's namespace (which can be the global namespace), or the library will not be able to locate them (in this example, they are in namespace ns, where person is defined). Those methods MUST be available (e.g., proper headers must be included) everywhere you use these conversions. Look at issue 1108 for errors that may occur otherwise. When using get<your_type>(), your_type MUST be DefaultConstructible. (There is a way to bypass this requirement described later.) In function from_json, use function at() to access the object values rather than operator[]. In case a key does not exist, at throws an exception that you can handle, whereas operator[] exhibits undefined behavior. You do not need to add serializers or deserializers for STL types like std::vector: the library already implements these. Simplify your life with macros If you just want to serialize/deserialize some structs, the to_json/from_json functions can be a lot of boilerplate. There are two macros to make your life easier as long as you (1) want to use a JSON object as serialization and (2) want to use the member variable names as object keys in that object: NLOHMANN_DEFINE_TYPE_NON_INTRUSIVE(name, member1, member2, ...) is to be defined inside of the namespace of the class/struct to create code for. NLOHMANN_DEFINE_TYPE_INTRUSIVE(name, member1, member2, ...) is to be defined inside of the class/struct to create code for. This macro can also access private members. In both macros, the first parameter is the name of the class/struct, and all remaining parameters name the members. Examples The to_json/from_json functions for the person struct above can be created with: Here is an example with private members, where NLOHMANN_DEFINE_TYPE_INTRUSIVE is needed: How do I convert third-party types? This requires a bit more advanced technique. But first, let's see how this conversion mechanism works: The library uses JSON Serializers to convert types to json. The default serializer for nlohmann::json is nlohmann::adl_serializer (ADL means Argument-Dependent Lookup). It is implemented like this (simplified): This serializer works fine when you have control over the type's namespace. However, what about boost::optional or std::filesystem::path (C++17)? Hijacking the boost namespace is pretty bad, and it's illegal to add something other than template specializations to std... To solve this, you need to add a specialization of adl_serializer to the nlohmann namespace, here's an example: How can I use get() for non-default constructible/non-copyable types? There is a way, if your type is MoveConstructible. You will need to specialize the adl_serializer as well, but with a special from_json overload: Can I write my own serializer? (Advanced use) Yes. You might want to take a look at unit-udt.cpp in the test suite, to see a few examples. If you write your own serializer, you'll need to do a few things: use a different basic_json alias than nlohmann::json (the last template parameter of basic_json is the JSONSerializer) use your basic_json alias (or a template parameter) in all your to_json/from_json methods use nlohmann::to_json and nlohmann::from_json when you need ADL Here is an example, without simplifications, that only accepts types with a size <= 32, and uses ADL. Be very careful when reimplementing your serializer, you can stack overflow if you don't pay attention: Specializing enum conversion By default, enum values are serialized to JSON as integers. In some cases this could result in undesired behavior. If an enum is modified or re-ordered after data has been serialized to JSON, the later de-serialized JSON data may be undefined or a different enum value than was originally intended. It is possible to more precisely specify how a given enum is mapped to and from JSON as shown below: The NLOHMANN_JSON_SERIALIZE_ENUM() macro declares a set of to_json() / from_json() functions for type TaskState while avoiding repetition and boilerplate serialization code. Usage: Just as in Arbitrary Type Conversions above, - NLOHMANN_JSON_SERIALIZE_ENUM() MUST be declared in your enum type's namespace (which can be the global namespace), or the library will not be able to locate it and it will default to integer serialization. - It MUST be available (e.g., proper headers must be included) everywhere you use the conversions. Other Important points: - When using get<ENUM_TYPE>(), undefined JSON values will default to the first pair specified in your map. Select this default pair carefully. - If an enum or JSON value is specified more than once in your map, the first matching occurrence from the top of the map will be returned when converting to or from JSON. Binary formats (BSON, CBOR, MessagePack, and UBJSON) Though JSON is a ubiquitous data format, it is not a very compact format suitable for data exchange, for instance over a network. Hence, the library supportsBSON (Binary JSON), CBOR (Concise Binary Object Representation), MessagePack, and UBJSON (Universal Binary JSON Specification) to efficiently encode JSON values to byte vectors and to decode such vectors. The library also supports binary types from BSON, CBOR (byte strings), and MessagePack (bin, ext, fixext). They are stored by default as std::vector<std::uint8_t> to be processed outside of the library. Supported compilers Though it's 2021 already, the support for C++11 is still a bit sparse. Currently, the following compilers are known to work: GCC 4.8 - 11.0 (and possibly later) Clang 3.4 - 12.0 (and possibly later) Apple Clang 9.1 - 12.4 (and possibly later) Intel C++ Compiler 17.0.2 (and possibly later) Microsoft Visual C++ 2015 / Build Tools 14.0.25123.0 (and possibly later) Microsoft Visual C++ 2017 / Build Tools 15.5.180.51428 (and possibly later) Microsoft Visual C++ 2019 / Build Tools 16.3.1+1def00d3d (and possibly later) I would be happy to learn about other compilers/versions. Please note: GCC 4.8 has a bug 57824): multiline raw strings cannot be the arguments to macros. Don't use multiline raw strings directly in macros with this compiler. Android defaults to using very old compilers and C++ libraries. To fix this, add the following to your Application.mk. This will switch to the LLVM C++ library, the Clang compiler, and enable C++11 and other features disabled by default. The code compiles successfully with Android NDK, Revision 9 - 11 (and possibly later) and CrystaX's Android NDK version 10. For GCC running on MinGW or Android SDK, the error 'to_string' is not a member of 'std' (or similarly, for strtod or strtof) may occur. Note this is not an issue with the code, but rather with the compiler itself. On Android, see above to build with a newer environment. For MinGW, please refer to this site and this discussion for information on how to fix this bug. For Android NDK using APP_STL := gnustl_static, please refer to this discussion. Unsupported versions of GCC and Clang are rejected by #error directives. This can be switched off by defining JSON_SKIP_UNSUPPORTED_COMPILER_CHECK. Note that you can expect no support in this case. The following compilers are currently used in continuous integration at Travis, AppVeyor, Drone CI, and GitHub Actions: | Compiler | Operating System | CI Provider | |-------------------------------------------------------------------|--------------------|----------------| | Apple Clang 10.0.1 (clang-1001.0.46.4); Xcode 10.2.1 | macOS 10.14.4 | Travis | | Apple Clang 10.0.1 (clang-1001.0.46.4); Xcode 10.3 | macOS 10.15.7 | GitHub Actions | | Apple Clang 11.0.0 (clang-1100.0.33.12); Xcode 11.2.1 | macOS 10.15.7 | GitHub Actions | | Apple Clang 11.0.0 (clang-1100.0.33.17); Xcode 11.3.1 | macOS 10.15.7 | GitHub Actions | | Apple Clang 11.0.3 (clang-1103.0.32.59); Xcode 11.4.1 | macOS 10.15.7 | GitHub Actions | | Apple Clang 11.0.3 (clang-1103.0.32.62); Xcode 11.5 | macOS 10.15.7 | GitHub Actions | | Apple Clang 11.0.3 (clang-1103.0.32.62); Xcode 11.6 | macOS 10.15.7 | GitHub Actions | | Apple Clang 11.0.3 (clang-1103.0.32.62); Xcode 11.7 | macOS 10.15.7 | GitHub Actions | | Apple Clang 12.0.0 (clang-1200.0.32.2); Xcode 12 | macOS 10.15.7 | GitHub Actions | | Apple Clang 12.0.0 (clang-1200.0.32.21); Xcode 12.1 | macOS 10.15.7 | GitHub Actions | | Apple Clang 12.0.0 (clang-1200.0.32.21); Xcode 12.1.1 | macOS 10.15.7 | GitHub Actions | | Apple Clang 12.0.0 (clang-1200.0.32.27); Xcode 12.2 | macOS 10.15.7 | GitHub Actions | | Apple Clang 12.0.0 (clang-1200.0.32.28); Xcode 12.3 | macOS 10.15.7 | GitHub Actions | | Apple Clang 12.0.0 (clang-1200.0.32.29); Xcode 12.4 | macOS 10.15.7 | GitHub Actions | | GCC 4.8.5 (Ubuntu 4.8.5-4ubuntu2) | Ubuntu 20.04.2 LTS | GitHub Actions | | GCC 4.9.3 (Ubuntu 4.9.3-13ubuntu2) | Ubuntu 20.04.2 LTS | GitHub Actions | | GCC 5.4.0 (Ubuntu 5.4.0-6ubuntu1~16.04.12) | Ubuntu 20.04.2 LTS | GitHub Actions | | GCC 6.5.0 (Ubuntu 6.5.0-2ubuntu1~14.04.1) | Ubuntu 14.04.5 LTS | Travis | | GCC 7.5.0 (Ubuntu 7.5.0-6ubuntu2) | Ubuntu 20.04.2 LTS | GitHub Actions | | GCC 8.1.0 (x86_64-posix-seh-rev0, Built by MinGW-W64 project) | Windows-10.0.17763 | GitHub Actions | | GCC 8.1.0 (i686-posix-dwarf-rev0, Built by MinGW-W64 project) | Windows-10.0.17763 | GitHub Actions | | GCC 8.4.0 (Ubuntu 8.4.0-3ubuntu2) | Ubuntu 20.04.2 LTS | GitHub Actions | | GCC 9.3.0 (Ubuntu 9.3.0-17ubuntu1~20.04) | Ubuntu 20.04.2 LTS | GitHub Actions | | GCC 10.2.0 (Ubuntu 10.2.0-5ubuntu1~20.04) | Ubuntu 20.04.2 LTS | GitHub Actions | | GCC 11.0.1 20210321 (experimental) | Ubuntu 20.04.2 LTS | GitHub Actions | | GCC 11.1.0 | Ubuntu (aarch64) | Drone CI | | Clang 3.5.2 (3.5.2-3ubuntu1) | Ubuntu 20.04.2 LTS | GitHub Actions | | Clang 3.6.2 (3.6.2-3ubuntu2) | Ubuntu 20.04.2 LTS | GitHub Actions | | Clang 3.7.1 (3.7.1-2ubuntu2) | Ubuntu 20.04.2 LTS | GitHub Actions | | Clang 3.8.0 (3.8.0-2ubuntu4) | Ubuntu 20.04.2 LTS | GitHub Actions | | Clang 3.9.1 (3.9.1-4ubuntu3\~16.04.2) | Ubuntu 20.04.2 LTS | GitHub Actions | | Clang 4.0.0 (4.0.0-1ubuntu1\~16.04.2) | Ubuntu 20.04.2 LTS | GitHub Actions | | Clang 5.0.0 (5.0.0-3\~16.04.1) | Ubuntu 20.04.2 LTS | GitHub Actions | | Clang 6.0.1 (6.0.1-14) | Ubuntu 20.04.2 LTS | GitHub Actions | | Clang 7.0.1 (7.0.1-12) | Ubuntu 20.04.2 LTS | GitHub Actions | | Clang 8.0.1 (8.0.1-9) | Ubuntu 20.04.2 LTS | GitHub Actions | | Clang 9.0.1 (9.0.1-12) | Ubuntu 20.04.2 LTS | GitHub Actions | | Clang 10.0.0 (10.0.0-4ubuntu1) | Ubuntu 20.04.2 LTS | GitHub Actions | | Clang 10.0.0 with GNU-like command-line | Windows-10.0.17763 | GitHub Actions | | Clang 11.0.0 with GNU-like command-line | Windows-10.0.17763 | GitHub Actions | | Clang 11.0.0 with MSVC-like command-line | Windows-10.0.17763 | GitHub Actions | | Clang 11.0.0 (11.0.0-2~ubuntu20.04.1) | Ubuntu 20.04.2 LTS | GitHub Actions | | Clang 12.1.0 (12.0.1-++20210423082613+072c90a863aa-1~exp1~20210423063319.76 | Ubuntu 20.04.2 LTS | GitHub Actions | | Visual Studio 14 2015 MSVC 19.0.24241.7 (Build Engine version 14.0.25420.1) | Windows-6.3.9600 | AppVeyor | | Visual Studio 15 2017 MSVC 19.16.27035.0 (Build Engine version 15.9.21+g9802d43bc3 for .NET Framework) | Windows-10.0.14393 | AppVeyor | | Visual Studio 15 2017 MSVC 19.16.27045.0 (Build Engine version 15.9.21+g9802d43bc3 for .NET Framework) | Windows-10.0.14393 | GitHub Actions | | Visual Studio 16 2019 MSVC 19.28.29912.0 (Build Engine version 16.9.0+57a23d249 for .NET Framework) | Windows-10.0.17763 | GitHub Actions | | Visual Studio 16 2019 MSVC 19.28.29912.0 (Build Engine version 16.9.0+57a23d249 for .NET Framework) | Windows-10.0.17763 | AppVeyor | License The class is licensed under the MIT License: Copyright 2013-2021 Niels Lohmann Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the Software), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED AS IS, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. The class contains the UTF-8 Decoder from Bjoern Hoehrmann which is licensed under the MIT License (see above). Copyright 2008-2009 Bjrn Hoehrmann bjoern@hoehrmann.de The class contains a slightly modified version of the Grisu2 algorithm from Florian Loitsch which is licensed under the MIT License (see above). Copyright 2009 Florian Loitsch The class contains a copy of Hedley from Evan Nemerson which is licensed as CC0-1.0. The class contains parts of Google Abseil which is licensed under the Apache 2.0 License. Contact If you have questions regarding the library, I would like to invite you to open an issue at GitHub. Please describe your request, problem, or question as detailed as possible, and also mention the version of the library you are using as well as the version of your compiler and operating system. Opening an issue at GitHub allows other users and contributors to this library to collaborate. For instance, I have little experience with MSVC, and most issues in this regard have been solved by a growing community. If you have a look at the closed issues, you will see that we react quite timely in most cases. Only if your request would contain confidential information, please send me an email. For encrypted messages, please use this key. Security Commits by Niels Lohmann and releases are signed with this PGP Key. Thanks I deeply appreciate the help of the following people. Teemperor implemented CMake support and lcov integration, realized escape and Unicode handling in the string parser, and fixed the JSON serialization. elliotgoodrich fixed an issue with double deletion in the iterator classes. kirkshoop made the iterators of the class composable to other libraries. wancw fixed a bug that hindered the class to compile with Clang. Tomas blad found a bug in the iterator implementation. Joshua C. Randall fixed a bug in the floating-point serialization. Aaron Burghardt implemented code to parse streams incrementally. Furthermore, he greatly improved the parser class by allowing the definition of a filter function to discard undesired elements while parsing. Daniel Kopeek fixed a bug in the compilation with GCC 5.0. Florian Weber fixed a bug in and improved the performance of the comparison operators. Eric Cornelius pointed out a bug in the handling with NaN and infinity values. He also improved the performance of the string escaping. implemented a conversion from anonymous enums. kepkin patiently pushed forward the support for Microsoft Visual studio. gregmarr simplified the implementation of reverse iterators and helped with numerous hints and improvements. In particular, he pushed forward the implementation of user-defined types. Caio Luppi fixed a bug in the Unicode handling. dariomt fixed some typos in the examples. Daniel Frey cleaned up some pointers and implemented exception-safe memory allocation. Colin Hirsch took care of a small namespace issue. Huu Nguyen correct a variable name in the documentation. Silverweed overloaded parse() to accept an rvalue reference. dariomt fixed a subtlety in MSVC type support and implemented the get_ref() function to get a reference to stored values. ZahlGraf added a workaround that allows compilation using Android NDK. whackashoe replaced a function that was marked as unsafe by Visual Studio. 406345 fixed two small warnings. Glen Fernandes noted a potential portability problem in the has_mapped_type function. Corbin Hughes fixed some typos in the contribution guidelines. twelsby fixed the array subscript operator, an issue that failed the MSVC build, and floating-point parsing/dumping. He further added support for unsigned integer numbers and implemented better roundtrip support for parsed numbers. Volker Diels-Grabsch fixed a link in the README file. msm- added support for American Fuzzy Lop. Annihil fixed an example in the README file. Themercee noted a wrong URL in the README file. Lv Zheng fixed a namespace issue with int64_t and uint64_t. abc100m analyzed the issues with GCC 4.8 and proposed a partial solution. zewt added useful notes to the README file about Android. Rbert Mrki added a fix to use move iterators and improved the integration via CMake. Chris Kitching cleaned up the CMake files. Tom Needham fixed a subtle bug with MSVC 2015 which was also proposed by Michael K.. Mrio Feroldi fixed a small typo. duncanwerner found a really embarrassing performance regression in the 2.0.0 release. Damien fixed one of the last conversion warnings. Thomas Braun fixed a warning in a test case and adjusted MSVC calls in the CI. Tho DELRIEU patiently and constructively oversaw the long way toward iterator-range parsing. He also implemented the magic behind the serialization/deserialization of user-defined types and split the single header file into smaller chunks. Stefan fixed a minor issue in the documentation. Vasil Dimov fixed the documentation regarding conversions from std::multiset. ChristophJud overworked the CMake files to ease project inclusion. Vladimir Petrigo made a SFINAE hack more readable and added Visual Studio 17 to the build matrix. Denis Andrejew fixed a grammar issue in the README file. Pierre-Antoine Lacaze found a subtle bug in the dump() function. TurpentineDistillery pointed to std::locale::classic() to avoid too much locale joggling, found some nice performance improvements in the parser, improved the benchmarking code, and realized locale-independent number parsing and printing. cgzones had an idea how to fix the Coverity scan. Jared Grubb silenced a nasty documentation warning. Yixin Zhang fixed an integer overflow check. Bosswestfalen merged two iterator classes into a smaller one. Daniel599 helped to get Travis execute the tests with Clang's sanitizers. Jonathan Lee fixed an example in the README file. gnzlbg supported the implementation of user-defined types. Alexej Harm helped to get the user-defined types working with Visual Studio. Jared Grubb supported the implementation of user-defined types. EnricoBilla noted a typo in an example. Martin Hoeovsk found a way for a 2x speedup for the compilation time of the test suite. ukhegg found proposed an improvement for the examples section. rswanson-ihi noted a typo in the README. Mihai Stan fixed a bug in the comparison with nullptrs. Tushar Maheshwari added cotire support to speed up the compilation. TedLyngmo noted a typo in the README, removed unnecessary bit arithmetic, and fixed some -Weffc++ warnings. Krzysztof Wo made exceptions more visible. ftillier fixed a compiler warning. tinloaf made sure all pushed warnings are properly popped. Fytch found a bug in the documentation. Jay Sistar implemented a Meson build description. Henry Lee fixed a warning in ICC and improved the iterator implementation. Vincent Thiery maintains a package for the Conan package manager. Steffen fixed a potential issue with MSVC and std::min. Mike Tzou fixed some typos. amrcode noted a misleading documentation about comparison of floats. Oleg Endo reduced the memory consumption by replacing <iostream> with <iosfwd>. dan-42 cleaned up the CMake files to simplify including/reusing of the library. Nikita Ofitserov allowed for moving values from initializer lists. Greg Hurrell fixed a typo. Dmitry Kukovinets fixed a typo. kbthomp1 fixed an issue related to the Intel OSX compiler. Markus Werle fixed a typo. WebProdPP fixed a subtle error in a precondition check. Alex noted an error in a code sample. Tom de Geus reported some warnings with ICC and helped fixing them. Perry Kundert simplified reading from input streams. Sonu Lohani fixed a small compilation error. Jamie Seward fixed all MSVC warnings. Nate Vargas added a Doxygen tag file. pvleuven helped fixing a warning in ICC. Pavel helped fixing some warnings in MSVC. Jamie Seward avoided unnecessary string copies in find() and count(). Mitja fixed some typos. Jorrit Wronski updated the Hunter package links. Matthias Mller added a .natvis for the MSVC debug view. bogemic fixed some C++17 deprecation warnings. Eren Okka fixed some MSVC warnings. abolz integrated the Grisu2 algorithm for proper floating-point formatting, allowing more roundtrip checks to succeed. Vadim Evard fixed a Markdown issue in the README. zerodefect fixed a compiler warning. Kert allowed to template the string type in the serialization and added the possibility to override the exceptional behavior. mark-99 helped fixing an ICC error. Patrik Huber fixed links in the README file. johnfb found a bug in the implementation of CBOR's indefinite length strings. Paul Fultz II added a note on the cget package manager. Wilson Lin made the integration section of the README more concise. RalfBielig detected and fixed a memory leak in the parser callback. agrianius allowed to dump JSON to an alternative string type. Kevin Tonon overworked the C++11 compiler checks in CMake. Axel Huebl simplified a CMake check and added support for the Spack package manager. Carlos O'Ryan fixed a typo. James Upjohn fixed a version number in the compilers section. Chuck Atkins adjusted the CMake files to the CMake packaging guidelines and provided documentation for the CMake integration. Jan Schppach fixed a typo. martin-mfg fixed a typo. Matthias Mller removed the dependency from std::stringstream. agrianius added code to use alternative string implementations. Daniel599 allowed to use more algorithms with the items() function. Julius Rakow fixed the Meson include directory and fixed the links to cppreference.com. Sonu Lohani fixed the compilation with MSVC 2015 in debug mode. grembo fixed the test suite and re-enabled several test cases. Hyeon Kim introduced the macro JSON_INTERNAL_CATCH to control the exception handling inside the library. thyu fixed a compiler warning. David Guthrie fixed a subtle compilation error with Clang 3.4.2. Dennis Fischer allowed to call find_package without installing the library. Hyeon Kim fixed an issue with a double macro definition. Ben Berman made some error messages more understandable. zakalibit fixed a compilation problem with the Intel C++ compiler. mandreyel fixed a compilation problem. Kostiantyn Ponomarenko added version and license information to the Meson build file. Henry Schreiner added support for GCC 4.8. knilch made sure the test suite does not stall when run in the wrong directory. Antonio Borondo fixed an MSVC 2017 warning. Dan Gendreau implemented the NLOHMANN_JSON_SERIALIZE_ENUM macro to quickly define a enum/JSON mapping. efp added line and column information to parse errors. julian-becker added BSON support. Pratik Chowdhury added support for structured bindings. David Avedissian added support for Clang 5.0.1 (PS4 version). Jonathan Dumaresq implemented an input adapter to read from FILE*. kjpus fixed a link in the documentation. Manvendra Singh fixed a typo in the documentation. ziggurat29 fixed an MSVC warning. Sylvain Corlay added code to avoid an issue with MSVC. mefyl fixed a bug when JSON was parsed from an input stream. Millian Poquet allowed to install the library via Meson. Michael Behrns-Miller found an issue with a missing namespace. Nasztanovics Ferenc fixed a compilation issue with libc 2.12. Andreas Schwab fixed the endian conversion. Mark-Dunning fixed a warning in MSVC. Gareth Sylvester-Bradley added operator/ for JSON Pointers. John-Mark noted a missing header. Vitaly Zaitsev fixed compilation with GCC 9.0. Laurent Stacul fixed compilation with GCC 9.0. Ivor Wanders helped reducing the CMake requirement to version 3.1. njlr updated the Buckaroo instructions. Lion fixed a compilation issue with GCC 7 on CentOS. Isaac Nickaein improved the integer serialization performance and implemented the contains() function. past-due suppressed an unfixable warning. Elvis Oric improved Meson support. Matj Plch fixed an example in the README. Mark Beckwith fixed a typo. scinart fixed bug in the serializer. Patrick Boettcher implemented push_back() and pop_back() for JSON Pointers. Bruno Oliveira added support for Conda. Michele Caini fixed links in the README. Hani documented how to install the library with NuGet. Mark Beckwith fixed a typo. yann-morin-1998 helped reducing the CMake requirement to version 3.1. Konstantin Podsvirov maintains a package for the MSYS2 software distro. remyabel added GNUInstallDirs to the CMake files. Taylor Howard fixed a unit test. Gabe Ron implemented the to_string method. Watal M. Iwasaki fixed a Clang warning. Viktor Kirilov switched the unit tests from Catch to doctest Juncheng E fixed a typo. tete17 fixed a bug in the contains function. Xav83 fixed some cppcheck warnings. 0xflotus fixed some typos. Christian Deneke added a const version of json_pointer::back. Julien Hamaide made the items() function work with custom string types. Evan Nemerson updated fixed a bug in Hedley and updated this library accordingly. Florian Pigorsch fixed a lot of typos. Camille Bgu fixed an issue in the conversion from std::pair and std::tuple to json. Anthony VH fixed a compile error in an enum deserialization. Yuriy Vountesmery noted a subtle bug in a preprocessor check. Chen fixed numerous issues in the library. Antony Kellermann added a CI step for GCC 10.1. Alex fixed an MSVC warning. Rainer proposed an improvement in the floating-point serialization in CBOR. Francois Chabot made performance improvements in the input adapters. Arthur Sonzogni documented how the library can be included via FetchContent. Rimas Miseviius fixed an error message. Alexander Myasnikov fixed some examples and a link in the README. Hubert Chathi made CMake's version config file architecture-independent. OmnipotentEntity implemented the binary values for CBOR, MessagePack, BSON, and UBJSON. ArtemSarmini fixed a compilation issue with GCC 10 and fixed a leak. Evgenii Sopov integrated the library to the wsjcpp package manager. Sergey Linev fixed a compiler warning. Miguel Magalhes fixed the year in the copyright. Gareth Sylvester-Bradley fixed a compilation issue with MSVC. Alexander weej Jones fixed an example in the README. Antoine Cur fixed some typos in the documentation. jothepro updated links to the Hunter package. Dave Lee fixed link in the README. Jol Lamotte added instruction for using Build2's package manager. Paul Jurczak fixed an example in the README. Sonu Lohani fixed a warning. Carlos Gomes Martinho updated the Conan package source. Konstantin Podsvirov fixed the MSYS2 package documentation. Tridacnid improved the CMake tests. Michael fixed MSVC warnings. Quentin Barbarat fixed an example in the documentation. XyFreak fixed a compiler warning. TotalCaesar659 fixed links in the README. Tanuj Garg improved the fuzzer coverage for UBSAN input. AODQ fixed a compiler warning. jwittbrodt made NLOHMANN_DEFINE_TYPE_NON_INTRUSIVE inline. pfeatherstone improved the upper bound of arguments of the NLOHMANN_DEFINE_TYPE_NON_INTRUSIVE/NLOHMANN_DEFINE_TYPE_INTRUSIVE macros. Jan Prochzka fixed a bug in the CBOR parser for binary and string values. T0b1-iOS fixed a bug in the new hash implementation. Matthew Bauer adjusted the CBOR writer to create tags for binary subtypes. gatopeich implemented an ordered map container for nlohmann::ordered_json. rico Nogueira Rolim added support for pkg-config. KonanM proposed an implementation for the NLOHMANN_DEFINE_TYPE_NON_INTRUSIVE/NLOHMANN_DEFINE_TYPE_INTRUSIVE macros. Guillaume Racicot implemented string_view support and allowed C++20 support. Alex Reinking improved CMake support for FetchContent. Hannes Domani provided a GDB pretty printer. Thanks a lot for helping out! Please let me know if I forgot someone. Used third-party tools The library itself consists of a single header file licensed under the MIT license. However, it is built, tested, documented, and whatnot using a lot of third-party tools and services. Thanks a lot! amalgamate.py - Amalgamate C source and header files to create a single header file American fuzzy lop for fuzz testing AppVeyor for continuous integration on Windows Artistic Style for automatic source code indentation Clang for compilation with code sanitizers CMake for build automation Codacity for further code analysis Coveralls to measure code coverage Coverity Scan for static analysis cppcheck for static analysis doctest for the unit tests Doxygen to generate documentation git-update-ghpages to upload the documentation to gh-pages GitHub Changelog Generator to generate the ChangeLog Google Benchmark to implement the benchmarks Hedley to avoid re-inventing several compiler-agnostic feature macros lcov to process coverage information and create a HTML view libFuzzer to implement fuzz testing for OSS-Fuzz OSS-Fuzz for continuous fuzz testing of the library (project repository) Probot for automating maintainer tasks such as closing stale issues, requesting missing information, or detecting toxic comments. send_to_wandbox to send code examples to Wandbox Travis for continuous integration on Linux and macOS Valgrind to check for correct memory management Wandbox for online examples Projects using JSON for Modern C++ The library is currently used in Apple macOS Sierra and iOS 10. I am not sure what they are using the library for, but I am happy that it runs on so many devices. Notes Character encoding The library supports Unicode input as follows: Only UTF-8 encoded input is supported which is the default encoding for JSON according to RFC 8259. std::u16string and std::u32string can be parsed, assuming UTF-16 and UTF-32 encoding, respectively. These encodings are not supported when reading from files or other input containers. Other encodings such as Latin-1 or ISO 8859-1 are not supported and will yield parse or serialization errors. Unicode noncharacters will not be replaced by the library. Invalid surrogates (e.g., incomplete pairs such as \uDEAD) will yield parse errors. The strings stored in the library are UTF-8 encoded. When using the default string type (std::string), note that its length/size functions return the number of stored bytes rather than the number of characters or glyphs. When you store strings with different encodings in the library, calling dump() may throw an exception unless json::error_handler_t::replace or json::error_handler_t::ignore are used as error handlers. Comments in JSON This library does not support comments by default. It does so for three reasons: Comments are not part of the JSON specification. You may argue that // or /* */ are allowed in JavaScript, but JSON is not JavaScript. This was not an oversight: Douglas Crockford wrote on this in May 2012: I removed comments from JSON because I saw people were using them to hold parsing directives, a practice which would have destroyed interoperability. I know that the lack of comments makes some people sad, but it shouldn't. Suppose you are using JSON to keep configuration files, which you would like to annotate. Go ahead and insert all the comments you like. Then pipe it through JSMin before handing it to your JSON parser. It is dangerous for interoperability if some libraries would add comment support while others don't. Please check The Harmful Consequences of the Robustness Principle on this. However, you can pass set parameter ignore_comments to true in the parse function to ignore // or /* */ comments. Comments will then be treated as whitespace. Order of object keys By default, the library does not preserve the insertion order of object elements. This is standards-compliant, as the JSON standard defines objects as "an unordered collection of zero or more name/value pairs". If you do want to preserve the insertion order, you can try the type nlohmann::ordered_json. Alternatively, you can use a more sophisticated ordered map like tsl::ordered_map (integration) or nlohmann::fifo_map (integration). Memory Release We checked with Valgrind and the Address Sanitizer (ASAN) that there are no memory leaks. If you find that a parsing program with this library does not release memory, please consider the following case and it maybe unrelated to this library. Your program is compiled with glibc. There is a tunable threshold that glibc uses to decide whether to actually return memory to the system or whether to cache it for later reuse. If in your program you make lots of small allocations and those small allocations are not a contiguous block and are presumably below the threshold, then they will not get returned to the OS. Here is a related issue #1924. Further notes The code contains numerous debug assertions which can be switched off by defining the preprocessor macro NDEBUG, see the documentation of assert. In particular, note operator[] implements unchecked access for const objects: If the given key is not present, the behavior is undefined (think of a dereferenced null pointer) and yields an assertion failure if assertions are switched on. If you are not sure whether an element in an object exists, use checked access with the at() function. Furthermore, you can define JSON_ASSERT(x) to replace calls to assert(x). As the exact type of a number is not defined in the JSON specification, this library tries to choose the best fitting C++ number type automatically. As a result, the type double may be used to store numbers which may yield floating-point exceptions in certain rare situations if floating-point exceptions have been unmasked in the calling code. These exceptions are not caused by the library and need to be fixed in the calling code, such as by re-masking the exceptions prior to calling library functions. The code can be compiled without C++ runtime type identification features; that is, you can use the -fno-rtti compiler flag. Exceptions are used widely within the library. They can, however, be switched off with either using the compiler flag -fno-exceptions or by defining the symbol JSON_NOEXCEPTION. In this case, exceptions are replaced by abort() calls. You can further control this behavior by defining JSON_THROW_USER (overriding throw), JSON_TRY_USER (overriding try), and JSON_CATCH_USER (overriding catch). Note that JSON_THROW_USER should leave the current scope (e.g., by throwing or aborting), as continuing after it may yield undefined behavior. Execute unit tests To compile and run the tests, you need to execute Note that during the ctest stage, several JSON test files are downloaded from an external repository. If policies forbid downloading artifacts during testing, you can download the files yourself and pass the directory with the test files via -DJSON_TestDataDirectory=path to CMake. Then, no Internet connectivity is required. See issue #2189 for more information. In case you have downloaded the library rather than checked out the code via Git, test cmake_fetch_content_configure. Please execute ctest -LE git_required to skip these tests. See issue #2189 for more information. Some tests change the installed files and hence make the whole process not reproducible. Please execute ctest -LE not_reproducible to skip these tests. See issue #2324 for more information. Note you need to call cmake -LE "not_reproducible|git_required" to exclude both labels. See issue #2596 for more information. As Intel compilers use unsafe floating point optimization by default, the unit tests may fail. Use flag /fp:precise then.

 # # # # # # # # # # # # # # # # # # # #
 Repository: browserstate/history.js, index: 339, word count: 4831 
 # # # # # # # # # # # # # # # # # # # #

The repository for high quality TypeScript type definitions.Definitely Typed The repository for high quality TypeScript type definitions. You can also read this README in Spanish, Korean, Russian, Chinese, Portuguese, Italian and Japanese! Link to Admin manual Contents Current status What are declaration files and how do I get them? How can I contribute? Testing Make a pull request Partial clone Edit an existing package Create a new package Removing a package Running tests Naming <my-package>-tests.ts Linter: tslint.json tsconfig.json package.json OTHER_FILES.txt Common mistakes Definition owners FAQ License Current status This section tracks the health of the repository and publishing process. It may be helpful for contributors experiencing any issues with their PRs and packages. Most recent build type-checked/linted cleanly: All packages are type-checking/linting cleanly on typescript@next: All packages are being published to npm in under an hour: typescript-bot has been active on Definitely Typed Current infrastructure status updates If anything here seems wrong, or any of the above are failing, please let us know in the Definitely Typed channel on the TypeScript Community Discord server. What are declaration files and how do I get them? See the TypeScript handbook. npm This is the preferred method. For example: The types should then be automatically included by the compiler. You may need to add a types reference if you're not using modules: See more in the handbook. For an npm package "foo", typings for it will be at "@types/foo". If you can't find your package, look for it on TypeSearch. If you still can't find it, check if it bundles its own typings. This is usually provided in a "types" or "typings" field in the package.json, or just look for any ".d.ts" files in the package and manually include them with a /// <reference path="" />. Older versions of TypeScript (3.4 and earlier) Definitely Typed only tests packages on versions of TypeScript that are less than 2 years old. Currently versions 3.5 and above are tested. If you're using TypeScript 2.0 to 3.4, you can still try installing @types packages the majority of packages don't use fancy new TypeScript features. But there's no guarantee that they'll work. Here is the support window: | Version | Released | End of Support | | ------- | -------------- | -------------- | | 2.8 | March 2018 | March 2020 | | 2.9 | May 2018 | May 2020 | | 3.0 | July 2018 | August 2020 | | 3.1 | September 2018 | September 2020 | | 3.2 | November 2018 | November 2020 | | 3.3 | January 2019 | January 2021 | | 3.4 | March 2019 | March 2021 | | 3.5 | May 2019 | May 2021 | | 3.6 | August 2019 | August 2021 | | 3.7 | November 2019 | November 2021 | | 3.8 | February 2020 | February 2022 | | 3.9 | May 2020 | May 2022 | | 4.0 | August 2020 | August 2022 | | 4.1 | November 2020 | November 2022 | | 4.2 | February 2021 | February 2023 | @types packages have tags for versions of TypeScript that they explicitly support, so you can usually get older versions of packages that predate the 2-year window. For example, if you run npm dist-tags @types/react, you'll see that TypeScript 2.5 can use types for react@16.0, whereas TypeScript 2.6 and 2.7 can use types for react@16.4: | Tag | Version | | ------ | ------- | | latest | 16.9.23 | | ts2.0 | 15.0.1 | | ... | ... | | ts2.5 | 16.0.36 | | ts2.6 | 16.4.7 | | ts2.7 | 16.4.7 | | ... | ... | TypeScript 1.* Manually download from the master branch of this repository and place them in your project ~~Typings~~ (use preferred alternatives, typings is deprecated) ~~NuGet~~ (use preferred alternatives, nuget DT type publishing has been turned off) You may need to add manual references. How can I contribute? Definitely Typed only works because of contributions by users like you! Testing Before you share your improvement with the world, use it yourself. Test editing an existing package To test local to your app, you can use module augmentation to extend existing types from the DT module you want to work on. Alternatively, you can also edit the types directly in node_modules/@types/foo/index.d.ts to validate your changes, then bring the changes to this repo with the steps below. Adding tests to a new package Add to your tsconfig.json: Create types/foo/index.d.ts containing declarations for the module "foo". You should now be able to import from "foo" in your code and it will route to the new type definition. Then build and run the code to make sure your type definition actually corresponds to what happens at runtime. Once you've tested your definitions with real code, make a PR then follow the instructions to edit an existing package or create a new package. Make a pull request Once you've tested your package, you can share it on Definitely Typed. First, fork this repository, clone it, install node, and run npm install. If using npm v7 you need to add the --legacy-peer-deps flag to the command. We use a bot to let a large number of pull requests to DefinitelyTyped be handled entirely in a self-service manner. You can read more about why and how here. Here is a handy reference showing the life-cycle of a pull request to DT: Partial clone You can clone the entire repository as per usual, but it's large and includes a massive directory of type packages. This will take some time to clone and may be unnecessarily unwieldy. For a more manageable clone that includes only the type packages relevant to you, you can use git's sparse-checkout, --filter, and --depth features. This will reduce clone time and improve git performance. :warning: This requires minimum git version 2.27.0, which is likely newer than the default on most machines. More complicated procedures are available in older versions, but not covered by this guide. git clone --sparse --filter=blob:none --depth=1 <forkedUrl> --sparse initializes the sparse-checkout file so the working directory starts with only the files in the root of the repository. --filter=blob:none will exclude files, fetching them only as needed. --depth=1 will further improve clone speed by truncating commit history, but it may cause issues as summarized here. git sparse-checkout add types/<type> types/<dependency-type> ... Edit an existing package cd types/<package to edit> Make changes. Remember to edit tests. If you make breaking changes, do not forget to update a major version. Run npm test <package to test>. When you make a PR to edit an existing package, dt-bot should @-mention previous authors. If it doesn't, you can do so yourself in the comment associated with the PR. Create a new package If you are the library author and your package is written in TypeScript, bundle the autogenerated declaration files in your package instead of publishing to Definitely Typed. If you are adding typings for an npm package, create a directory with the same name. If the package you are adding typings for is not on npm, make sure the name you choose for it does not conflict with the name of a package on npm. (You can use npm info <my-package> to check for the existence of the <my-package> package.) Your package should have this structure: | File | Purpose | | ------------- | ------- | | index.d.ts | This contains the typings for the package. | | <my-package>-tests.ts | This contains sample code which tests the typings. This code does not run, but it is type-checked. | | tsconfig.json | This allows you to run tsc within the package. | | tslint.json | Enables linting. | Generate these by running npx dts-gen --dt --name <my-package> --template module if you have npm 5.2.0, npm install -g dts-gen and dts-gen --dt --name <my-package> --template module otherwise. See all options at dts-gen. If you have .d.ts files besides index.d.ts, make sure that they are referenced either in index.d.ts or the tests. Definitely Typed members routinely monitor for new PRs, though keep in mind that the number of other PRs may slow things down. For a good example package, see base64-js. Removing a package When a package bundles its own types, types should be removed from Definitely Typed to avoid confusion. You can remove it by running npm run not-needed -- <typingsPackageName> <asOfVersion> [<libraryName>]. * <typingsPackageName>: This is the name of the directory to delete. * <asOfVersion>: A stub will be published to @types/<typingsPackageName> with this version. Should be higher than any currently published version, and should be a version of <libraryName> on npm. * <libraryName>: Name of npm package that replaces the Definitely Typed types. Usually this is identical to <typingsPackageName>, in which case you can omit it. Any other packages in Definitely Typed that referenced the deleted package should be updated to reference the bundled types. You can get this list by looking at the errors from npm run test-all. To fix the errors, add a package.json with "dependencies": { "<libraryName>": "x.y.z" }. For example: When you add a package.json to dependents of <libraryName>, you will also need to open a PR to add <libraryName> to allowedPackageJsonDependencies.txt in DefinitelyTyped-tools. If a package was never on Definitely Typed, it does not need to be added to notNeededPackages.json. Running tests Test your changes by running npm test <package to test> where <package to test> is the name of your package. This script uses dtslint to run the TypeScript compiler against your dts files. Naming If you are adding typings for an npm package, create a directory with the same name. If the package you are adding typings for is not on npm, make sure the name you choose for it does not conflict with the name of a package on npm. (You can use npm info <my-package> to check for the existence of the <my-package> package.) If a non-npm package conflicts with an existing npm package try adding -browser to the end of the name to get <my-package>-browser. <my-package>-tests.ts There should be a <my-package>-tests.ts file, which is considered your test file, along with any *.ts files it imports. If you don't see any test files in the module's folder, create a <my-package>-tests.ts. These files are used to validate the API exported from the *.d.ts files which are shipped as @types/<my-package>. Changes to the *.d.ts files should include a corresponding *.ts file change which shows the API being used, so that someone doesn't accidentally break code you depend on. If you don't see any test files in the module's folder, create a <my-package>-tests.ts For example, this change to a function in a .d.ts file adding a new param to a function: index.d.ts: <my-package>-tests.ts: If you're wondering where to start with test code, the examples in the README of the module are a great place to start. You can validate your changes with npm test <package to test> from the root of this repo, which takes changed files into account. Use $ExpectType to assert that an expression is of a given type, and $ExpectError to assert that a compile error. Examples: For more details, see dtslint readme. Linter: tslint.json The linter configuration file, tslint.json should contain { "extends": "dtslint/dt.json" }, and no additional rules. If for some reason some rule needs to be disabled, disable it for that specific line using // tslint:disable-next-line:[ruleName] not for the whole package, so that disabling can be reviewed. (There are some legacy lint configs that have additional contents, but these should not happen in new work.) tsconfig.json tsconfig.json should have noImplicitAny, noImplicitThis, strictNullChecks, and strictFunctionTypes set to true. You may edit the tsconfig.json to add new test files, to add "target": "es6" (needed for async functions), to add to "lib", or to add the "jsx" compiler option. esModuleInterop/allowSyntheticDefaultImports TL;DR: esModuleInterop and allowSyntheticDefaultImports are not allowed in your tsconfig.json. These options make it possible to write a default import for a CJS export, modeling the built-in interoperability between CJS and ES modules in Node and in some JS bundlers: Since the compile-time validity of the import in index.d.ts is dependent upon specific compilation settings, which users of your types do not inherit, using this pattern in DefinitelyTyped would force users to change their own compilation settings, which might be incorrect for their runtime. Instead, you must write a CJS import for a CJS export to ensure widespread, config-independent compatibility: package.json Usually you won't need this. DefinitelyTyped's package publisher creates a package.json for packages with no dependencies outside Definitely Typed. A package.json may be included to specify dependencies that are not other @types packages. Pikaday is a good example. Even if you write your own package.json, you can only specify dependencies; other fields such as "description" are not allowed. You also need to add the dependency to the list of allowed packages. This list is updated by a human, which gives us the chance to make sure that @types packages don't depend on malicious packages. In the rare case that an @types package is deleted and removed in favor of types shipped by the source package AND you need to depend on the old, removed @types package, you can add a dependency on an @types package. Be sure to explain this when adding to the list of allowed packages so that the human maintainer knows what is happening. OTHER_FILES.txt If a file is neither tested nor referenced in index.d.ts, add it to a file named OTHER_FILES.txt. This file is a list of other files that need to be included in the typings package, one file per line. Common mistakes First, follow advice from the handbook. Formatting: Use 4 spaces. Prettier is set up on this repo, so you can run npm run prettier -- --write path/to/package/**/*.ts. When using assertions, add // prettier-ignore exclusion to mark line(s) of code as excluded from formatting: function sum(nums: number[]): number: Use ReadonlyArray if a function does not write to its parameters. interface Foo { new(): Foo; }: This defines a type of objects that are new-able. You probably want declare class Foo { constructor(); }. const Class: { new(): IClass; }: Prefer to use a class declaration class Class { constructor(); } instead of a new-able constant. getMeAT<T>(): T: If a type parameter does not appear in the types of any parameters, you don't really have a generic function, you just have a disguised type assertion. Prefer to use a real type assertion, e.g. getMeAT() as number. Example where a type parameter is acceptable: function id<T>(value: T): T;. Example where it is not acceptable: function parseJson<T>(json: string): T;. Exception: new Map<string, number>() is OK. Using the types Function and Object is almost never a good idea. In 99% of cases it's possible to specify a more specific type. Examples are (x: number) => number for functions and { x: number, y: number } for objects. If there is no certainty at all about the type, any is the right choice, not Object. If the only known fact about the type is that it's some object, use the type object, not Object or { [key: string]: any }. var foo: string | any: When any is used in a union type, the resulting type is still any. So while the string portion of this type annotation may look useful, it in fact offers no additional typechecking over simply using any. Depending on the intention, acceptable alternatives could be any, string, or string | object. Definition owners DT has the concept of "Definition Owners" which are people who want to maintain the quality of a particular module's types Adding yourself to the list will cause you to be notified (via your GitHub username) whenever someone makes a pull request or issue about the package. Your PR reviews will have a higher precedence of importance to the bot which maintains this repo. The DT maintainers are putting trust in the definition owners to ensure a stable eco-system, please don't add yourself lightly. To Add yourself as a Definition Owner: Adding your name to the end of the line, as in // Definitions by: Alice <https://github.com/alice>, Bob <https://github.com/bob>. Or if there are more people, it can be multiline Once a week the Definition Owners are synced to the file .github/CODEOWNERS which is our source of truth. FAQ What exactly is the relationship between this repository and the @types packages on npm? The master branch is automatically published to the @types scope on npm thanks to DefinitelyTyped-tools. I've submitted a pull request. How long until it is merged? It depends, but most pull requests will be merged within a week. Some PRs can be merged by the owners of a module, and they can be merged much faster. Roughly: PRs which only change the types of a module, and have corresponding tests changes will be merged much faster PRs that have been approved by an author listed in the definition's header are usually merged more quickly; PRs for new definitions will take more time as they require more review from maintainers. Each PR is reviewed by a TypeScript or Definitely Typed team member before being merged, so please be patient as human factors may cause delays. Check the New Pull Request Status Board to see progress as maintainers work through the open PRs. My PR is merged; when will the @types npm package be updated? npm packages should update within a few minutes. If it's been more than an hour, mention the PR number on the Definitely Typed channel on the TypeScript Community Discord server and the current maintainer will get the correct team member to investigate. I'm writing a definition that depends on another definition. Should I use <reference types="" /> or an import? If the module you're referencing is an external module (uses export), use an import. If the module you're referencing is an ambient module (uses declare module, or just declares globals), use <reference types="" />. Some packages have no tslint.json, and some tsconfig.json are missing "noImplicitAny": true, "noImplicitThis": true, or "strictNullChecks": true. Then they are wrong, and we've not noticed yet. You can help by submitting a pull request to fix them. Can I request a definition? Here are the currently requested definitions. What about type definitions for the DOM? If types are part of a web standard, they should be contributed to TSJS-lib-generator so that they can become part of the default lib.dom.d.ts. Should I add an empty namespace to a package that doesn't export a module to use ES6 style imports? Some packages, like chai-http, export a function. Importing this module with an ES6 style import in the form import * as foo from "foo"; leads to the error: error TS2497: Module 'foo' resolves to a non-module entity and cannot be imported using this construct This error can be suppressed by merging the function declaration with an empty namespace of the same name, but this practice is discouraged. This is a commonly cited Stack Overflow answer regarding this matter. It is more appropriate to import the module using the import foo = require("foo"); syntax. Nevertheless, if you want to use a default import like import foo from "foo"; you have two options: - you can use the --allowSyntheticDefaultImports compiler option if your module runtime supports an interop scheme for non-ECMAScript modules, i.e. if default imports work in your environment (e.g. Webpack, SystemJS, esm). - you can use the --esModuleInterop compiler option if you want TypeScript to take care of non-ECMAScript interop (since TypeScript 2.7). A package uses export =, but I prefer to use default imports. Can I change export = to export default? Like in the previous question, refer to using either the --allowSyntheticDefaultImports or --esModuleInterop compiler options. Do not change the type definition if it is accurate. For an npm package, export = is accurate if node -p 'require("foo")' works to import a module, and export default is accurate if node -p 'require("foo").default' works to import a module. I want to use features from very new TypeScript versions. Then you will have to add a comment to the last line of your definition header (after // Definitions: https://github.com/DefinitelyTyped/DefinitelyTyped): // Minimum TypeScript Version: X.Y. This will set the lowest minimum supported version. However, if your project needs to maintain types that are compatible with, say, 3.7 and above at the same time as types that are compatible with 3.6 or below, you will need to use the typesVersions feature. You can find a detailed explanation of this feature in the official TypeScript documentation. Here's a short example to get you started: You'll have to add a package.json file to your package definition, with the following contents: Create the sub-directory mentioned in the typesVersions field inside your types directory (ts3.6/ in this example). ts3.6/ will support TypeScript versions 3.6 and below, so copy the existing types and tests there. You'll need to delete the definition header from ts3.6/index.d.ts since only the root index.d.ts is supposed to have it. Set the baseUrl and typeRoots options in ts3.6/tsconfig.json to the correct paths, which should look something like this: Back in the root of the package, add the TypeScript 3.7 features you want to use. When people install the package, TypeScript 3.6 and below will start from ts3.6/index.d.ts, whereas TypeScript 3.7 and above will start from index.d.ts. You can look at styled-components for an example. I want to add a DOM API not present in TypeScript by default. This may belong in TSJS-Lib-Generator. See the guidelines there. If the standard is still a draft, it belongs here. Use a name beginning with dom- and include a link to the standard as the "Project" link in the header. When it graduates draft mode, we may remove it from Definitely Typed and deprecate the associated @types package. How do Definitely Typed package versions relate to versions of the corresponding library? NOTE: The discussion in this section assumes familiarity with Semantic versioning Each Definitely Typed package is versioned when published to npm. The DefinitelyTyped-tools (the tool that publishes @types packages to npm) will set the declaration package's version by using the major.minor version number listed in the first line of its index.d.ts file. For example, here are the first few lines of Node's type declarations for version 10.12.x at the time of writing: Because 10.12 is at the end of the first line, the npm version of the @types/node package will also be 10.12.x. Note that the first-line comment in the index.d.ts file should only contain the major.minor version (e.g. 10.12) and should not contain a patch version (e.g. 10.12.4). This is because only the major and minor release numbers are aligned between library packages and type declaration packages. The patch release number of the type declaration package (e.g. .0 in 10.12.0) is initialized to zero by Definitely Typed and is incremented each time a new @types/node package is published to npm for the same major/minor version of the corresponding library. Sometimes type declaration package versions and library package versions can get out of sync. Below are a few common reasons why, in order of how much they inconvenience users of a library. Only the last case is typically problematic. As noted above, the patch version of the type declaration package is unrelated to the library patch version. This allows Definitely Typed to safely update type declarations for the same major/minor version of a library. If updating a package for new functionality, don't forget to update the version number to line up with that version of the library. If users make sure versions correspond between JavaScript packages and their respective @types packages, then npm update should typically just work. It's common for type declaration package updates to lag behind library updates because it's often library users, not maintainers, who update Definitely Typed when new library features are released. So there may be a lag of days, weeks, or even months before a helpful community member sends a PR to update the type declaration package for a new library release. If you're impacted by this, you can be the change you want to see in the world and you can be that helpful community member! :exclamation: If you're updating type declarations for a library, always set the major.minor version in the first line of index.d.ts to match the library version that you're documenting! :exclamation: If a library is updated to a new major version with breaking changes, how should I update its type declaration package? Semantic versioning requires that versions with breaking changes must increment the major version number. For example, a library that removes a publicly exported function after its 3.5.8 release must bump its version to 4.0.0 in its next release. Furthermore, when the library's 4.0.0 release is out, its Definitely Typed type declaration package should also be updated to 4.0.0, including any breaking changes to the library's API. Many libraries have a large installed base of developers (including maintainers of other packages using that library as a dependency) who won't move right away to a new version that has breaking changes, because it might be months until a maintainer has time to rewrite code to adapt to the new version. In the meantime, users of old library versions still may want to update type declarations for older versions. If you intend to continue updating the older version of a library's type declarations, you may create a new subfolder (e.g. /v2/) named for the current (soon to be "old") version, and copy existing files from the current version to it. Because the root folder should always contain the type declarations for the latest ("new") version, you'll need to make a few changes to the files in your old-version subdirectory to ensure that relative path references point to the subdirectory, not the root. Update the relative paths in tsconfig.json as well as tslint.json. Add path mapping rules to ensure that tests are running against the intended version. For example, the history library introduced breaking changes between version 2.x and 3.x. Because many users still consumed the older 2.x version, a maintainer who wanted to update the type declarations for this library to 3.x added a v2 folder inside the history repository that contains type declarations for the older version. At the time of writing, the history v2 tsconfig.json looks roughly like: If there are other packages in Definitely Typed that are incompatible with the new version, you will need to add path mappings to the old version. You will also need to do this recursively for packages depending on the old version. For example, react-router depends on history@2, so react-router tsconfig.json has a path mapping to "history": [ "history/v2" ]. Transitively, react-router-bootstrap (which depends on react-router) also needed to add the same path mapping ("history": [ "history/v2" ]) in its tsconfig.json until its react-router dependency was updated to the latest version. Also, /// <reference types=".." /> will not work with path mapping, so dependencies must use import. How do I write definitions for packages that can be used globally and as a module? The TypeScript handbook contains excellent general information about writing definitions, and also this example definition file which shows how to create a definition using ES6-style module syntax, while also specifying objects made available to the global scope. This technique is demonstrated practically in the definition for big.js, which is a library that can be loaded globally via script tag on a web page, or imported via require or ES6-style imports. To test how your definition can be used both when referenced globally or as an imported module, create a test folder, and place two test files in there. Name one YourLibraryName-global.test.ts and the other YourLibraryName-module.test.ts. The global test file should exercise the definition according to how it would be used in a script loaded on a web page where the library is available on the global scope - in this scenario you should not specify an import statement. The module test file should exercise the definition according to how it would be used when imported (including the import statement(s)). If you specify a files property in your tsconfig.json file, be sure to include both test files. A practical example of this is also available on the big.js definition. Please note that it is not required to fully exercise the definition in each test file - it is sufficient to test only the globally-accessible elements on the global test file and fully exercise the definition in the module test file, or vice versa. What about scoped packages? Types for a scoped package @foo/bar should go in types/foo__bar. Note the double underscore. When dts-gen is used to scaffold a scoped package, the paths property has to be manually adapted in the generated tsconfig.json to correctly reference the scoped package: The file history in GitHub looks incomplete. GitHub doesn't support file history for renamed files. Use git log --follow instead. License This project is licensed under the MIT license. Copyrights on the definition files are respective of each contributor listed at the beginning of each definition file.

 # # # # # # # # # # # # # # # # # # # #
 Repository: yhatt/marp, index: 1021, word count: 4175 
 # # # # # # # # # # # # # # # # # # # #

Elegant iOS form builder in Swift Made with by XMARTLABS. This is the re-creation of XLForm in Swift. Overview Contents Requirements Usage How to create a Form Getting row values Operators Using the callbacks Section Header and Footer Dynamically hide and show rows (or sections) List sections Multivalued sections Validations Swipe Actions Custom rows Basic custom rows Custom inline rows Custom presenter rows Row catalog Installation FAQ For more information look at our blog post that introduces Eureka. Requirements (for latest release) Xcode 11+ Swift 5.0+ Example project You can clone and run the Example project to see examples of most of Eureka's features. Usage How to create a form By extending FormViewController you can then simply add sections and rows to the form variable. In the example we create two sections with standard rows, the result is this: You could create a form by just setting up the form property by yourself without extending from FormViewController but this method is typically more convenient. Configuring the keyboard navigation accesory To change the behaviour of this you should set the navigation options of your controller. The FormViewController has a navigationOptions variable which is an enum and can have one or more of the following values: disabled: no view at all enabled: enable view at the bottom stopDisabledRow: if the navigation should stop when the next row is disabled skipCanNotBecomeFirstResponderRow: if the navigation should skip the rows that return false to canBecomeFirstResponder() The default value is enabled & skipCanNotBecomeFirstResponderRow To enable smooth scrolling to off-screen rows, enable it via the animateScroll property. By default, the FormViewController jumps immediately between rows when the user hits the next or previous buttons in the keyboard navigation accesory, including when the next row is off screen. To set the amount of space between the keyboard and the highlighted row following a navigation event, set the rowKeyboardSpacing property. By default, when the form scrolls to an offscreen view no space will be left between the top of the keyboard and the bottom of the row. If you want to change the whole navigation accessory view, you will have to override the navigationAccessoryView variable in your subclass of FormViewController. Getting row values The Row object holds a value of a specific type. For example, a SwitchRow holds a Bool value, while a TextRow holds a String value. Operators Eureka includes custom operators to make form creation easy: +++ Add a section <<< Insert a row += Append an array Using the callbacks Eureka includes callbacks to change the appearance and behavior of a row. Understanding Row and Cell A Row is an abstraction Eureka uses which holds a value and contains the view Cell. The Cell manages the view and subclasses UITableViewCell. Here is an example: Callbacks list onChange() Called when the value of a row changes. You might be interested in adjusting some parameters here or even make some other rows appear or disappear. onCellSelection() Called each time the user taps on the row and it gets selected. cellSetup() Called only once when the cell is first configured. Set permanent settings here. cellUpdate() Called each time the cell appears on screen. You can change the appearance here using variables that may not be present on cellSetup(). onCellHighlightChanged() Called whenever the cell or any subview become or resign the first responder. onRowValidationChanged() Called whenever the the validation errors associated with a row changes. onExpandInlineRow() Called before expanding the inline row. Applies to rows conforming InlineRowType protocol. onCollapseInlineRow() Called before collapsing the inline row. Applies to rows conforming InlineRowType protocol. onPresent() Called by a row just before presenting another view controller. Applies to rows conforming PresenterRowType protocol. Use it to set up the presented controller. Section Header and Footer You can set a title String or a custom View as the header or footer of a Section. String title Custom view You can use a Custom View from a .xib file: Or a custom UIView created programmatically Or just build the view with a Callback Dynamically hide and show rows (or sections) In this case we are hiding and showing whole sections. To accomplish this each row has a hidden variable of optional type Condition which can be set using a function or NSPredicate. Hiding using a function condition Using the function case of Condition: The array of String to pass should contain the tags of the rows this row depends on. Each time the value of any of those rows changes the function is reevaluated. The function then takes the Form and returns a Bool indicating whether the row should be hidden or not. This the most powerful way of setting up the hidden property as it has no explicit limitations of what can be done. Hiding using an NSPredicate The hidden variable can also be set with a NSPredicate. In the predicate string you can reference values of other rows by their tags to determine if a row should be hidden or visible. This will only work if the values of the rows the predicate has to check are NSObjects (String and Int will work as they are bridged to their ObjC counterparts, but enums won't work). Why could it then be useful to use predicates when they are more limited? Well, they can be much simpler, shorter and readable than functions. Look at this example: And we can write it even shorter since Condition conforms to ExpressibleByStringLiteral: Note: we will substitute the value of the row whose tag is 'switchTag' instead of '$switchTag' For all of this to work, all of the implicated rows must have a tag as the tag will identify them. We can also hide a row by doing: as Condition conforms to ExpressibleByBooleanLiteral. Not setting the hidden variable will leave the row always visible. Sections For sections this works just the same. That means we can set up section hidden property to show/hide it dynamically. Disabling rows To disable rows, each row has an disabled variable which is also an optional Condition type property. This variable also works the same as the hidden variable so that it requires the rows to have a tag. Note that if you want to disable a row permanently you can also set disabled variable to true. List Sections To display a list of options, Eureka includes a special section called SelectableSection. When creating one you need to pass the type of row to use in the options and the selectionType. The selectionType is an enum which can be either multipleSelection or singleSelection(enableDeselection: Bool) where the enableDeselection parameter determines if the selected rows can be deselected or not. What kind of rows can be used? To create such a section you have to create a row that conforms the SelectableRowType protocol. This selectableValue is where the value of the row will be permanently stored. The value variable will be used to determine if the row is selected or not, being 'selectableValue' if selected or nil otherwise. Eureka includes the ListCheckRow which is used for example. In the custom rows of the Examples project you can also find the ImageCheckRow. Getting the selected rows To easily get the selected row/s of a SelectableSection there are two methods: selectedRow() and selectedRows() which can be called to get the selected row in case it is a SingleSelection section or all the selected rows if it is a MultipleSelection section. Grouping options in sections Additionally you can setup list of options to be grouped by sections using following properties of SelectorViewController: sectionKeyForValue - a closure that should return key for particular row value. This key is later used to break options by sections. sectionHeaderTitleForKey - a closure that returns header title for a section for particular key. By default returns the key itself. sectionFooterTitleForKey - a closure that returns footer title for a section for particular key. Multivalued Sections Eureka supports multiple values for a certain field (such as telephone numbers in a contact) by using Multivalued sections. It allows us to easily create insertable, deletable and reorderable sections. How to create a multivalued section In order to create a multivalued section we have to use MultivaluedSection type instead of the regular Section type. MultivaluedSection extends Section and has some additional properties to configure multivalued section behavior. let's dive into a code example... Previous code snippet shows how to create a multivalued section. In this case we want to insert, delete and reorder rows as multivaluedOptions argument indicates. addButtonProvider allows us to customize the button row which inserts a new row when tapped and multivaluedOptions contains .Insert value. multivaluedRowToInsertAt closure property is called by Eureka each time a new row needs to be inserted. In order to provide the row to add into multivalued section we should set this property. Eureka passes the index as closure parameter. Notice that we can return any kind of row, even custom rows, even though in most cases multivalued section rows are of the same type. Eureka automatically adds a button row when we create a insertable multivalued section. We can customize how the this button row looks like as we explained before. showInsertIconInAddButton property indicates if plus button (insert style) should appear in the left of the button, true by default. There are some considerations we need to have in mind when creating insertable sections. Any row added to the insertable multivalued section should be placed above the row that Eureka automatically adds to insert new rows. This can be easily achieved by adding these additional rows to the section from inside the section's initializer closure (last parameter of section initializer) so then Eureka adds the adds insert button at the end of the section. Editing mode By default Eureka will set the tableView's isEditing to true only if there is a MultivaluedSection in the form. This will be done in viewWillAppear the first time a form is presented. For more information on how to use multivalued sections please take a look at Eureka example project which contains several usage examples. Custom add button If you want to use an add button which is not a ButtonRow then you can use GenericMultivaluedSection<AddButtonType>, where AddButtonType is the type of the row you want to use as add button. This is useful if you want to use a custom row to change the UI of the button. Example: Validations Eureka 2.0.0 introduces the much requested built-in validations feature. A row has a collection of Rules and a specific configuration that determines when validation rules should be evaluated. There are some rules provided by default, but you can also create new ones on your own. The provided rules are: * RuleRequired * RuleEmail * RuleURL * RuleGreaterThan, RuleGreaterOrEqualThan, RuleSmallerThan, RuleSmallerOrEqualThan * RuleMinLength, RuleMaxLength * RuleClosure Let's see how to set up the validation rules. As you can see in the previous code snippet we can set up as many rules as we want in a row by invoking row's add(rule:) function. Row also provides func remove(ruleWithIdentifier identifier: String) to remove a rule. In order to use it we must assign an id to the rule after creating it. Sometimes the collection of rules we want to use on a row is the same we want to use on many other rows. In this case we can set up all validation rules using a RuleSet which is a collection of validation rules. Eureka allows us to specify when validation rules should be evaluated. We can do it by setting up validationOptions row's property, which can have the following values: .validatesOnChange - Validates whenever a row value changes. .validatesOnBlur - (Default value) validates right after the cell resigns first responder. Not applicable for all rows. .validatesOnChangeAfterBlurred - Validates whenever the row value changes after it resigns first responder for the first time. .validatesOnDemand - We should manually validate the row or form by invoking validate() method. If you want to validate the entire form (all the rows) you can manually invoke Form validate() method. How to get validation errors Each row has the validationErrors property that can be used to retrieve all validation errors. This property just holds the validation error list of the latest row validation execution, which means it doesn't evaluate the validation rules of the row. Note on types As expected, the Rules must use the same types as the Row object. Be extra careful to check the row type used. You might see a compiler error ("Incorrect arugment label in call (have 'rule:' expected 'ruleSet:')" that is not pointing to the problem when mixing types. Swipe Actions By using swipe actions we can define multiple leadingSwipe and trailingSwipe actions per row. As swipe actions depend on iOS system features, leadingSwipe is available on iOS 11.0+ only. Let's see how to define swipe actions. Swipe Actions need tableView.isEditing be set to false. Eureka will set this to true if there is a MultivaluedSection in the form (in the viewWillAppear). If you have both MultivaluedSections and swipe actions in the same form you should set isEditing according to your needs. Custom rows It is very common that you need a row that is different from those included in Eureka. If this is the case you will have to create your own row but this should not be difficult. You can read this tutorial on how to create custom rows to get started. You might also want to have a look at EurekaCommunity which includes some extra rows ready to be added to Eureka. Basic custom rows To create a row with custom behaviour and appearance you'll probably want to create subclasses of Row and Cell. Remember that Row is the abstraction Eureka uses, while the Cell is the actual UITableViewCell in charge of the view. As the Row contains the Cell, both Row and Cell must be defined for the same value type. The result: Custom rows need to subclass Row<CellType> and conform to RowType protocol. Custom cells need to subclass Cell<ValueType> and conform to CellType protocol. Just like the callbacks cellSetup and CellUpdate, the Cell has the setup and update methods where you can customize it. Custom inline rows An inline row is a specific type of row that shows dynamically a row below it, normally an inline row changes between an expanded and collapsed mode whenever the row is tapped. So to create an inline row we need 2 rows, the row that is "always" visible and the row that will expand/collapse. Another requirement is that the value type of these 2 rows must be the same. This means if one row holds a String value then the other must have a String value too. Once we have these 2 rows, we should make the top row type conform to InlineRowType. This protocol requires you to define an InlineRow typealias and a setupInlineRow function. The InlineRow type will be the type of the row that will expand/collapse. Take this as an example: The InlineRowType will also add some methods to your inline row: These methods should work fine but should you want to override them keep in mind that it is toggleInlineRow that has to call expandInlineRow and collapseInlineRow. Finally you must invoke toggleInlineRow() when the row is selected, for example overriding customDidSelect: Custom Presenter rows Note: A Presenter row is a row that presents a new UIViewController. To create a custom Presenter row you must create a class that conforms the PresenterRowType protocol. It is highly recommended to subclass SelectorRow as it does conform to that protocol and adds other useful functionality. The PresenterRowType protocol is defined as follows: The onPresentCallback will be called when the row is about to present another view controller. This is done in the SelectorRow so if you do not subclass it you will have to call it yourself. The presentationMode is what defines how the controller is presented and which controller is presented. This presentation can be using a Segue identifier, a segue class, presenting a controller modally or pushing to a specific view controller. For example a CustomPushRow can be defined like this: Let's see an example.. Subclassing cells using the same row Sometimes we want to change the UI look of one of our rows but without changing the row type and all the logic associated to one row. There is currently one way to do this if you are using cells that are instantiated from nib files. Currently, none of Eureka's core rows are instantiated from nib files but some of the custom rows in EurekaCommunity are, in particular the PostalAddressRow which was moved there. What you have to do is: * Create a nib file containing the cell you want to create. * Then set the class of the cell to be the existing cell you want to modify (if you want to change something more apart from pure UI then you should subclass that cell). Make sure the module of that class is correctly set * Connect the outlets to your class * Tell your row to use the new nib file. This is done by setting the cellProvider variable to use this nib. You should do this in the initialiser, either in each concrete instantiation or using the defaultRowInitializer. For example: You could also create a new row for this. In that case try to inherit from the same superclass as the row you want to change to inherit its logic. There are some things to consider when you do this: * If you want to see an example have a look at the PostalAddressRow or the CreditCardRow which have use a custom nib file in their examples. * If you get an error saying Unknown class <YOUR_CLASS_NAME> in Interface Builder file, it might be that you have to instantiate that new type somewhere in your code to load it in the runtime. Calling let t = YourClass.self helped in my case. Row catalog Controls Rows Label Row Button Row Check Row Switch Row Slider Row Stepper Row Text Area Row Field Rows These rows have a textfield on the right side of the cell. The difference between each one of them consists in a different capitalization, autocorrection and keyboard type configuration. TextRow NameRow URLRow IntRow PhoneRow PasswordRow EmailRow DecimalRow TwitterRow AccountRow ZipCodeRow All of the FieldRow subtypes above have a formatter property of type NSFormatter which can be set to determine how that row's value should be displayed. A custom formatter for numbers with two digits after the decimal mark is included with Eureka (DecimalFormatter). The Example project also contains a CurrencyFormatter which displays a number as currency according to the user's locale. By default, setting a row's formatter only affects how a value is displayed when it is not being edited. To also format the value while the row is being edited, set useFormatterDuringInput to true when initializing the row. Formatting the value as it is being edited may require updating the cursor position and Eureka provides the following protocol that your formatter should conform to in order to handle cursor position: Additionally, FieldRow subtypes have a useFormatterOnDidBeginEditing property. When using a DecimalRow with a formatter that allows decimal values and conforms to the user's locale (e.g. DecimalFormatter), if useFormatterDuringInput is false, useFormatterOnDidBeginEditing must be set to true so that the decimal mark in the value being edited matches the decimal mark on the keyboard. Date Rows Date Rows hold a Date and allow us to set up a new value through UIDatePicker control. The mode of the UIDatePicker and the way how the date picker view is shown is what changes between them. Date Row Picker shown in the keyboard. Date Row (Inline) The row expands. Date Row (Picker) The picker is always visible. With those 3 styles (Normal, Inline & Picker), Eureka includes: DateRow TimeRow DateTimeRow CountDownRow Option Rows These are rows with a list of options associated from which the user must choose. Alert Row Will show an alert with the options to choose from. ActionSheet Row Will show an action sheet with the options to choose from. Push Row Will push to a new controller from where to choose options listed using Check rows. Multiple Selector Row Like PushRow but allows the selection of multiple options. Segmented Row Segmented Row (w/Title) Picker Row Presents options of a generic type through a picker view (There is also Picker Inline Row) Built your own custom row? Let us know about it, we would be glad to mention it here. :) LocationRow (Included as custom row in the example project) Installation CocoaPods CocoaPods is a dependency manager for Cocoa projects. Specify Eureka into your project's Podfile: Then run the following command: Swift Package Manager Swift Package Manager is a tool for managing the distribution of Swift code. After you set up your Package.swift manifest file, you can add Eureka as a dependency by adding it to the dependencies value of your Package.swift. dependencies: [ .package(url: "https://github.com/xmartlabs/Eureka.git", from: "5.3.3") ] Carthage Carthage is a simple, decentralized dependency manager for Cocoa. Specify Eureka into your project's Cartfile: Manually as Embedded Framework Clone Eureka as a git submodule by running the following command from your project root git folder. Open Eureka folder that was created by the previous git submodule command and drag the Eureka.xcodeproj into the Project Navigator of your application's Xcode project. Select the Eureka.xcodeproj in the Project Navigator and verify the deployment target matches with your application deployment target. Select your project in the Xcode Navigation and then select your application target from the sidebar. Next select the "General" tab and click on the + button under the "Embedded Binaries" section. Select Eureka.framework and we are done! Getting involved If you want to contribute please feel free to submit pull requests. If you have a feature request please open an issue. If you found a bug check older issues before submitting an issue. If you need help or would like to ask general question, use StackOverflow. (Tag eureka-forms). Before contribute check the CONTRIBUTING file for more info. If you use Eureka in your app We would love to hear about it! Drop us a line on twitter. Authors Martin Barreto (@mtnBarreto) Mathias Claassen (@mClaassen26) FAQ How to change the text representation of the row value shown in the cell. Every row has the following property: You can set displayValueFor according the string value you want to display. How to get a Row using its tag value We can get a particular row by invoking any of the following functions exposed by the Form class: For instance: How to get a Section using its tag value How to set the form values using a dictionary Invoking setValues(values: [String: Any?]) which is exposed by Form class. For example: Where "IntRowTag", "TextRowTag", "PushRowTag" are row tags (each one uniquely identifies a row) and 8, "Hello world!", Company(name:"Xmartlabs") are the corresponding row value to assign. The value type of a row must match with the value type of the corresponding dictionary value otherwise nil will be assigned. If the form was already displayed we have to reload the visible rows either by reloading the table view tableView.reloadData() or invoking updateCell() to each visible row. Row does not update after changing hidden or disabled condition After setting a condition, this condition is not automatically evaluated. If you want it to do so immediately you can call .evaluateHidden() or .evaluateDisabled(). This functions are just called when a row is added to the form and when a row it depends on changes. If the condition is changed when the row is being displayed then it must be reevaluated manually. onCellUnHighlight doesn't get called unless onCellHighlight is also defined Look at this issue. How to update a Section header/footer Set up a new header/footer data .... Reload the Section to perform the changes How to customize Selector and MultipleSelector option cells selectableRowSetup, selectableRowCellUpdate and selectableRowCellSetup properties are provided to be able to customize SelectorViewController and MultipleSelectorViewController selectable cells. Don't want to use Eureka custom operators? As we've said Form and Section types conform to MutableCollection and RangeReplaceableCollection. A Form is a collection of Sections and a Section is a collection of Rows. RangeReplaceableCollection protocol extension provides many useful methods to modify collection. These methods are used internally to implement the custom operators as shown bellow: You can see how the rest of custom operators are implemented here. It's up to you to decide if you want to use Eureka custom operators or not. How to set up your form from a storyboard The form is always displayed in a UITableView. You can set up your view controller in a storyboard and add a UITableView where you want it to be and then connect the outlet to FormViewController's tableView variable. This allows you to define a custom frame (possibly with constraints) for your form. All of this can also be done by programmatically changing frame, margins, etc. of the tableView of your FormViewController. Donate to Eureka So we can make Eureka even better! Change Log This can be found in the CHANGELOG.md file.

 # # # # # # # # # # # # # # # # # # # #
 Repository: reflux/refluxjs, index: 1070, word count: 5230 
 # # # # # # # # # # # # # # # # # # # #

A minimal Ubuntu base image modified for Docker-friendlinessA minimal Ubuntu base image modified for Docker-friendliness Baseimage-docker only consumes 8.3 MB RAM and is much more powerful than Busybox or Alpine. See why below. Baseimage-docker is a special Docker image that is configured for correct use within Docker containers. It is Ubuntu, plus: Modifications for Docker-friendliness. Administration tools that are especially useful in the context of Docker. Mechanisms for easily running multiple processes, without violating the Docker philosophy. You can use it as a base for your own Docker images. Baseimage-docker is available for pulling from the Docker registry! What are the problems with the stock Ubuntu base image? Ubuntu is not designed to be run inside Docker. Its init system, Upstart, assumes that it's running on either real hardware or virtualized hardware, but not inside a Docker container. But inside a container you don't want a full system; you want a minimal system. Configuring that minimal system for use within a container has many strange corner cases that are hard to get right if you are not intimately familiar with the Unix system model. This can cause a lot of strange problems. Baseimage-docker gets everything right. The "Contents" section describes all the things that it modifies. Why use baseimage-docker? You can configure the stock ubuntu image yourself from your Dockerfile, so why bother using baseimage-docker? Configuring the base system for Docker-friendliness is no easy task. As stated before, there are many corner cases. By the time that you've gotten all that right, you've reinvented baseimage-docker. Using baseimage-docker will save you from this effort. It reduces the time needed to write a correct Dockerfile. You won't have to worry about the base system and you can focus on the stack and the app. It reduces the time needed to run docker build, allowing you to iterate your Dockerfile more quickly. It reduces download time during redeploys. Docker only needs to download the base image once: during the first deploy. On every subsequent deploys, only the changes you make on top of the base image are downloaded. Related resources: Website | Github | Docker registry | Discussion forum | Twitter | Blog Table of contents What's inside the image? Overview Wait, I thought Docker is about running a single process in a container? Does Baseimage-docker advocate "fat containers" or "treating containers as VMs"? Inspecting baseimage-docker Using baseimage-docker as base image Getting started Adding additional daemons Running scripts during container startup Environment variables Centrally defining your own environment variables Environment variable dumps Modifying environment variables Security System logging Upgrading the operating system inside the container Container administration Running a one-shot command in a new container Running a command in an existing, running container Login to the container via docker exec Usage Login to the container via SSH Enabling SSH About SSH keys Using the insecure key for one container only Enabling the insecure key permanently Using your own key The docker-ssh tool Building the image yourself Removing optional services Conclusion What's inside the image? Overview Looking for a more complete base image, one that is ideal for Ruby, Python, Node.js and Meteor web apps? Take a look at passenger-docker. | Component | Why is it included? / Remarks | | ---------------- | ------------------- | | Ubuntu 20.04 LTS | The base system. | | A correct init process | Main article: Docker and the PID 1 zombie reaping problem. According to the Unix process model, the init process -- PID 1 -- inherits all orphaned child processes and must reap them. Most Docker containers do not have an init process that does this correctly. As a result, their containers become filled with zombie processes over time. Furthermore, docker stop sends SIGTERM to the init process, which stops all services. Unfortunately most init systems don't do this correctly within Docker since they're built for hardware shutdowns instead. This causes processes to be hard killed with SIGKILL, which doesn't give them a chance to correctly deinitialize things. This can cause file corruption. Baseimage-docker comes with an init process /sbin/my_init that performs both of these tasks correctly. | | Fixes APT incompatibilities with Docker | See https://github.com/dotcloud/docker/issues/1024. | | syslog-ng | A syslog daemon is necessary so that many services - including the kernel itself - can correctly log to /var/log/syslog. If no syslog daemon is running, a lot of important messages are silently swallowed. Only listens locally. All syslog messages are forwarded to "docker logs".Why syslog-ng?I've had bad experience with rsyslog. I regularly run into bugs with rsyslog, and once in a while it takes my log host down by entering a 100% CPU loop in which it can't do anything. Syslog-ng seems to be much more stable. | | logrotate | Rotates and compresses logs on a regular basis. | | SSH server | Allows you to easily login to your container to inspect or administer things. SSH is disabled by default and is only one of the methods provided by baseimage-docker for this purpose. The other method is through docker exec. SSH is also provided as an alternative because docker exec comes with several caveats.Password and challenge-response authentication are disabled by default. Only key authentication is allowed. | | cron | The cron daemon must be running for cron jobs to work. | | runit | Replaces Ubuntu's Upstart. Used for service supervision and management. Much easier to use than SysV init and supports restarting daemons when they crash. Much easier to use and more lightweight than Upstart. | | setuser | A tool for running a command as another user. Easier to use than su, has a smaller attack vector than sudo, and unlike chpst this tool sets $HOME correctly. Available as /sbin/setuser. | | install_clean | A tool for installing apt packages that automatically cleans up after itself. All arguments are passed to apt-get -y install --no-install-recommends and after installation the apt caches are cleared. To include recommended packages, add --install-recommends. | Baseimage-docker is very lightweight: it only consumes 8.3 MB of memory. Wait, I thought Docker is about running a single process in a container? The Docker developers advocate the philosophy of running a single logical service per container. A logical service can consist of multiple OS processes. Baseimage-docker only advocates running multiple OS processes inside a single container. We believe this makes sense because at the very least it would solve the PID 1 problem and the "syslog blackhole" problem. By running multiple processes, we solve very real Unix OS-level problems, with minimal overhead and without turning the container into multiple logical services. Splitting your logical service into multiple OS processes also makes sense from a security standpoint. By running processes as different users, you can limit the impact of vulnerabilities. Baseimage-docker provides tools to encourage running processes as different users, e.g. the setuser tool. Do we advocate running multiple logical services in a single container? Not necessarily, but we do not prohibit it either. While the Docker developers are very opinionated and have very rigid philosophies about how containers should be built, Baseimage-docker is completely unopinionated. We believe in freedom: sometimes it makes sense to run multiple services in a single container, and sometimes it doesn't. It is up to you to decide what makes sense, not the Docker developers. Does Baseimage-docker advocate "fat containers" or "treating containers as VMs"? There are people who think that Baseimage-docker advocates treating containers as VMs because Baseimage-docker advocates the use of multiple processes. Therefore, they also think that Baseimage-docker does not follow the Docker philosophy. Neither of these impressions are true. The Docker developers advocate running a single logical service inside a single container. But we are not disputing that. Baseimage-docker advocates running multiple OS processes inside a single container, and a single logical service can consist of multiple OS processes. It follows that Baseimage-docker also does not deny the Docker philosophy. In fact, many of the modifications we introduce are explicitly in line with the Docker philosophy. For example, using environment variables to pass parameters to containers is very much the "Docker way", and providing a mechanism to easily work with environment variables in the presence of multiple processes that may run as different users. Inspecting baseimage-docker To look around in the image, run: docker run --rm -t -i phusion/baseimage:<VERSION> /sbin/my_init -- bash -l where <VERSION> is one of the baseimage-docker version numbers. You don't have to download anything manually. The above command will automatically pull the baseimage-docker image from the Docker registry. Using baseimage-docker as base image Getting started The image is called phusion/baseimage, and is available on the Docker registry. # Use phusion/baseimage as base image. To make your builds reproducible, make # sure you lock down to a specific version, not to `latest`! # See https://github.com/phusion/baseimage-docker/blob/master/Changelog.md for # a list of version numbers. FROM phusion/baseimage:<VERSION> # Use baseimage-docker's init system. CMD ["/sbin/my_init"] # ...put your own build instructions here... # Clean up APT when done. RUN apt-get clean && rm -rf /var/lib/apt/lists/* /tmp/* /var/tmp/* Adding additional daemons A daemon is a program which runs in the background of its system, such as a web server. You can add additional daemons (for example, your own app) to the image by creating runit service directories. You only have to write a small shell script which runs your daemon; runsv will start your script, and - by default - restart it upon its exit, after waiting one second. The shell script must be called run, must be executable, and is to be placed in the directory /etc/service/<NAME>. runsv will switch to the directory and invoke ./run after your container starts. Be certain that you do not start your container using interactive mode (-it) with another command, as runit must be the first process to run. If you do this, your runit service directories won't be started. For instance, docker run -it <name> bash will bring you to bash in your container, but you'll lose all your daemons. Here's an example showing you how a runit service directory can be made for a memcached server. In memcached.sh, or whatever you choose to name your file (make sure this file is chmod +x): In an accompanying Dockerfile: A given shell script must run without daemonizing or forking itself; this is because runit will start and restart your script on its own. Usually, daemons provide a command line flag or a config file option for preventing such behavior - essentially, you just want your script to run in the foreground, not the background. Running scripts during container startup The baseimage-docker init system, /sbin/my_init, runs the following scripts during startup, in the following order: All executable scripts in /etc/my_init.d, if this directory exists. The scripts are run in lexicographic order. The script /etc/rc.local, if this file exists. All scripts must exit correctly, e.g. with exit code 0. If any script exits with a non-zero exit code, the booting will fail. Important note: If you are executing the container in interactive mode (i.e. when you run a container with -it), rather than daemon mode, you are sending stdout directly to the terminal (-i interactive -t terminal). If you are not calling /sbin/my_init in your run declaration, /sbin/my_init will not be executed, therefore your scripts will not be called during container startup. The following example shows how you can add a startup script. This script simply logs the time of boot to the file /tmp/boottime.txt. In logtime.sh: #!/bin/sh date > /tmp/boottime.txt In Dockerfile: RUN mkdir -p /etc/my_init.d COPY logtime.sh /etc/my_init.d/logtime.sh RUN chmod +x /etc/my_init.d/logtime.sh Shutting down your process /sbin/my_init handles termination of children processes at shutdown. When it receives a SIGTERM it will pass the signal onto the child processes for correct shutdown. If your process is started with a shell script, make sure you exec the actual process, otherwise the shell will receive the signal and not your process. /sbin/my_init will terminate processes after a 5 second timeout. This can be adjusted by setting environment variables: # Give children processes 5 minutes to timeout ENV KILL_PROCESS_TIMEOUT=300 # Give all other processes (such as those which have been forked) 5 minutes to timeout ENV KILL_ALL_PROCESSES_TIMEOUT=300 Note: Prior to 0.11.1, the default values for KILL_PROCESS_TIMEOUT and KILL_ALL_PROCESSES_TIMEOUT were 5 seconds. In version 0.11.1+ the default process timeout has been adjusted to 30 seconds to allow more time for containers to terminate gracefully. The default timeout of your container runtime may supersede this setting, for example Docker currently applies a 10s timeout by default before sending SIGKILL, upon docker stop or receiving SIGTERM. Environment variables If you use /sbin/my_init as the main container command, then any environment variables set with docker run --env or with the ENV command in the Dockerfile, will be picked up by my_init. These variables will also be passed to all child processes, including /etc/my_init.d startup scripts, Runit and Runit-managed services. There are however a few caveats you should be aware of: Environment variables on Unix are inherited on a per-process basis. This means that it is generally not possible for a child process to change the environment variables of other processes. Because of the aforementioned point, there is no good central place for defining environment variables for all applications and services. Debian has the /etc/environment file but it only works in some situations. Some services change environment variables for child processes. Nginx is one such example: it removes all environment variables unless you explicitly instruct it to retain them through the env configuration option. If you host any applications on Nginx (e.g. using the passenger-docker image, or using Phusion Passenger in your own image) then they will not see the environment variables that were originally passed by Docker. We ignore HOME, SHELL, USER and a bunch of other environment variables on purpose, because not ignoring them will break multi-user containers. See https://github.com/phusion/baseimage-docker/pull/86 -- A workaround for setting the HOME environment variable looks like this: RUN echo /root > /etc/container_environment/HOME. See https://github.com/phusion/baseimage-docker/issues/119 my_init provides a solution for all these caveats. Centrally defining your own environment variables During startup, before running any startup scripts, my_init imports environment variables from the directory /etc/container_environment. This directory contains files named after the environment variable names. The file contents contain the environment variable values. This directory is therefore a good place to centrally define your own environment variables, which will be inherited by all startup scripts and Runit services. For example, here's how you can define an environment variable from your Dockerfile: RUN echo Apachai Hopachai > /etc/container_environment/MY_NAME You can verify that it works, as follows: $ docker run -t -i <YOUR_NAME_IMAGE> /sbin/my_init -- bash -l ... *** Running bash -l... # echo $MY_NAME Apachai Hopachai Handling newlines If you've looked carefully, you'll notice that the 'echo' command actually prints a newline. Why does $MY_NAME not contain a newline then? It's because my_init strips the trailing newline. If you intended on the value having a newline, you should add another newline, like this: RUN echo -e "Apachai Hopachai\n" > /etc/container_environment/MY_NAME Environment variable dumps While the previously mentioned mechanism is good for centrally defining environment variables, itself does not prevent services (e.g. Nginx) from changing and resetting environment variables from child processes. However, the my_init mechanism does make it easy for you to query what the original environment variables are. During startup, right after importing environment variables from /etc/container_environment, my_init will dump all its environment variables (that is, all variables imported from container_environment, as well as all variables it picked up from docker run --env) to the following locations, in the following formats: /etc/container_environment /etc/container_environment.sh - a dump of the environment variables in Bash format. You can source the file directly from a Bash shell script. /etc/container_environment.json - a dump of the environment variables in JSON format. The multiple formats make it easy for you to query the original environment variables no matter which language your scripts/apps are written in. Here is an example shell session showing you how the dumps look like: $ docker run -t -i \ --env FOO=bar --env HELLO='my beautiful world' \ phusion/baseimage:<VERSION> /sbin/my_init -- \ bash -l ... *** Running bash -l... # ls /etc/container_environment FOO HELLO HOME HOSTNAME PATH TERM container # cat /etc/container_environment/HELLO; echo my beautiful world # cat /etc/container_environment.json; echo {"TERM": "xterm", "container": "lxc", "HOSTNAME": "f45449f06950", "HOME": "/root", "PATH": "/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin", "FOO": "bar", "HELLO": "my beautiful world"} # source /etc/container_environment.sh # echo $HELLO my beautiful world Modifying environment variables It is even possible to modify the environment variables in my_init (and therefore the environment variables in all child processes that are spawned after that point in time), by altering the files in /etc/container_environment. After each time my_init runs a startup script, it resets its own environment variables to the state in /etc/container_environment, and re-dumps the new environment variables to container_environment.sh and container_environment.json. But note that: modifying container_environment.sh and container_environment.json has no effect. Runit services cannot modify the environment like that. my_init only activates changes in /etc/container_environment when running startup scripts. Security Because environment variables can potentially contain sensitive information, /etc/container_environment and its Bash and JSON dumps are by default owned by root, and accessible only to the docker_env group (so that any user added this group will have these variables automatically loaded). If you are sure that your environment variables don't contain sensitive data, then you can also relax the permissions on that directory and those files by making them world-readable: RUN chmod 755 /etc/container_environment RUN chmod 644 /etc/container_environment.sh /etc/container_environment.json System logging Baseimage-docker uses syslog-ng to provide a syslog facility to the container. Syslog-ng is not managed as an runit service (see below). Syslog messages are forwarded to the console. Log startup/shutdown sequence In order to ensure that all application log messages are captured by syslog-ng, syslog-ng is started separately before the runit supervisor process, and shutdown after runit exits. This uses the startup script facility provided by this image. This avoids a race condition which would exist if syslog-ng were managed as an runit service, where runit kills syslog-ng in parallel with the container's other services, causing log messages to be dropped during a graceful shutdown if syslog-ng exits while logs are still being produced by other services. Upgrading the operating system inside the container Baseimage-docker images contain an Ubuntu operating system (see OS version at Overview). You may want to update this OS from time to time, for example to pull in the latest security updates. OpenSSL is a notorious example. Vulnerabilities are discovered in OpenSSL on a regular basis, so you should keep OpenSSL up-to-date as much as you can. While we release Baseimage-docker images with the latest OS updates from time to time, you do not have to rely on us. You can update the OS inside Baseimage-docker images yourself, and it is recommended that you do this instead of waiting for us. To upgrade the OS in the image, run this in your Dockerfile: RUN apt-get update && apt-get upgrade -y -o Dpkg::Options::="--force-confold" Container administration One of the ideas behind Docker is that containers should be stateless, easily restartable, and behave like a black box. However, you may occasionally encounter situations where you want to login to a container, or to run a command inside a container, for development, inspection and debugging purposes. This section describes how you can administer the container for those purposes. Running a one-shot command in a new container Note: This section describes how to run a command insider a -new- container. To run a command inside an existing running container, see Running a command in an existing, running container. Normally, when you want to create a new container in order to run a single command inside it, and immediately exit after the command exits, you invoke Docker like this: docker run YOUR_IMAGE COMMAND ARGUMENTS... However the downside of this approach is that the init system is not started. That is, while invoking COMMAND, important daemons such as cron and syslog are not running. Also, orphaned child processes are not properly reaped, because COMMAND is PID 1. Baseimage-docker provides a facility to run a single one-shot command, while solving all of the aforementioned problems. Run a single command in the following manner: docker run YOUR_IMAGE /sbin/my_init -- COMMAND ARGUMENTS ... This will perform the following: Runs all system startup files, such as /etc/my_init.d/* and /etc/rc.local. Starts all runit services. Runs the specified command. When the specified command exits, stops all runit services. For example: $ docker run phusion/baseimage:<VERSION> /sbin/my_init -- ls *** Running /etc/rc.local... *** Booting runit daemon... *** Runit started as PID 80 *** Running ls... bin boot dev etc home image lib lib64 media mnt opt proc root run sbin selinux srv sys tmp usr var *** ls exited with exit code 0. *** Shutting down runit daemon (PID 80)... *** Killing all processes... You may find that the default invocation is too noisy. Or perhaps you don't want to run the startup files. You can customize all this by passing arguments to my_init. Invoke docker run YOUR_IMAGE /sbin/my_init --help for more information. The following example runs ls without running the startup files and with less messages, while running all runit services: $ docker run phusion/baseimage:<VERSION> /sbin/my_init --skip-startup-files --quiet -- ls bin boot dev etc home image lib lib64 media mnt opt proc root run sbin selinux srv sys tmp usr var Running a command in an existing, running container There are two ways to run a command inside an existing, running container. Through the docker exec tool. This is builtin Docker tool, available since Docker 1.4. Internally, it uses Linux kernel system calls in order to execute a command within the context of a container. Learn more in Login to the container, or running a command inside it, via docker exec. Through SSH. This approach requires running an SSH daemon inside the container, and requires you to setup SSH keys. Learn more in Login to the container, or running a command inside it, via SSH. Both way have their own pros and cons, which you can learn in their respective subsections. Login to the container, or running a command inside it, via docker exec You can use the docker exec tool on the Docker host OS to login to any container that is based on baseimage-docker. You can also use it to run a command inside a running container. docker exec works by using Linux kernel system calls. Here's how it compares to using SSH to login to the container or to run a command inside it: Pros Does not require running an SSH daemon inside the container. Does not require setting up SSH keys. Works on any container, even containers not based on baseimage-docker. Cons If the docker exec process on the host is terminated by a signal (e.g. with the kill command or even with Ctrl-C), then the command that is executed by docker exec is not killed and cleaned up. You will either have to do that manually, or you have to run docker exec with -t -i. Requires privileges on the Docker host to be able to access the Docker daemon. Note that anybody who can access the Docker daemon effectively has root access. Not possible to allow users to login to the container without also letting them login to the Docker host. Usage Start a container: docker run YOUR_IMAGE Find out the ID of the container that you just ran: docker ps Now that you have the ID, you can use docker exec to run arbitrary commands in the container. For example, to run echo hello world: docker exec YOUR-CONTAINER-ID echo hello world To open a bash session inside the container, you must pass -t -i so that a terminal is available: docker exec -t -i YOUR-CONTAINER-ID bash -l Login to the container, or running a command inside it, via SSH You can use SSH to login to any container that is based on baseimage-docker. You can also use it to run a command inside a running container. Here's how it compares to using docker exec to login to the container or to run a command inside it: Pros Does not require root privileges on the Docker host. Allows you to let users login to the container, without letting them login to the Docker host. However, this is not enabled by default because baseimage-docker does not expose the SSH server to the public Internet by default. Cons Requires setting up SSH keys. However, baseimage-docker makes this easy for many cases through a pregenerated, insecure key. Read on to learn more. Enabling SSH Baseimage-docker disables the SSH server by default. Add the following to your Dockerfile to enable it: RUN rm -f /etc/service/sshd/down # Regenerate SSH host keys. baseimage-docker does not contain any, so you # have to do that yourself. You may also comment out this instruction; the # init system will auto-generate one during boot. RUN /etc/my_init.d/00_regen_ssh_host_keys.sh Alternatively, to enable sshd only for a single instance of your container, create a folder with a startup script. The contents of that should be ### In myfolder/enable_ssh.sh (make sure this file is chmod +x): #!/bin/sh rm -f /etc/service/sshd/down ssh-keygen -P "" -t dsa -f /etc/ssh/ssh_host_dsa_key Then, you can start your container with docker run -d -v `pwd`/myfolder:/etc/my_init.d my/dockerimage This will initialize sshd on container boot. You can then access it with the insecure key as below, or using the methods to add a secure key. Further, you can publish the port to your machine with -p 2222:22 allowing you to ssh to 127.0.0.1:2222 instead of looking up the ip address of the container. About SSH keys First, you must ensure that you have the right SSH keys installed inside the container. By default, no keys are installed, so nobody can login. For convenience reasons, we provide a pregenerated, insecure key (PuTTY format) that you can easily enable. However, please be aware that using this key is for convenience only. It does not provide any security because this key (both the public and the private side) is publicly available. In production environments, you should use your own keys. Using the insecure key for one container only You can temporarily enable the insecure key for one container only. This means that the insecure key is installed at container boot. If you docker stop and docker start the container, the insecure key will still be there, but if you use docker run to start a new container then that container will not contain the insecure key. Start a container with --enable-insecure-key: docker run YOUR_IMAGE /sbin/my_init --enable-insecure-key Find out the ID of the container that you just ran: docker ps Once you have the ID, look for its IP address with: docker inspect -f "{{ .NetworkSettings.IPAddress }}" <ID> Now that you have the IP address, you can use SSH to login to the container, or to execute a command inside it: # Download the insecure private key curl -o insecure_key -fSL https://github.com/phusion/baseimage-docker/raw/master/image/services/sshd/keys/insecure_key chmod 600 insecure_key # Login to the container ssh -i insecure_key root@<IP address> # Running a command inside the container ssh -i insecure_key root@<IP address> echo hello world Enabling the insecure key permanently It is also possible to enable the insecure key in the image permanently. This is not generally recommended, but is suitable for e.g. temporary development or demo environments where security does not matter. Edit your Dockerfile to install the insecure key permanently: RUN /usr/sbin/enable_insecure_key Instructions for logging into the container is the same as in section Using the insecure key for one container only. Using your own key Edit your Dockerfile to install an SSH public key: ## Install an SSH of your choice. COPY your_key.pub /tmp/your_key.pub RUN cat /tmp/your_key.pub >> /root/.ssh/authorized_keys && rm -f /tmp/your_key.pub Then rebuild your image. Once you have that, start a container based on that image: docker run your-image-name Find out the ID of the container that you just ran: docker ps Once you have the ID, look for its IP address with: docker inspect -f "{{ .NetworkSettings.IPAddress }}" <ID> Now that you have the IP address, you can use SSH to login to the container, or to execute a command inside it: # Login to the container ssh -i /path-to/your_key root@<IP address> # Running a command inside the container ssh -i /path-to/your_key root@<IP address> echo hello world The docker-ssh tool Looking up the IP of a container and running an SSH command quickly becomes tedious. Luckily, we provide the docker-ssh tool which automates this process. This tool is to be run on the Docker host, not inside a Docker container. First, install the tool on the Docker host: curl --fail -L -O https://github.com/phusion/baseimage-docker/archive/master.tar.gz && \ tar xzf master.tar.gz && \ sudo ./baseimage-docker-master/install-tools.sh Then run the tool as follows to login to a container using SSH: docker-ssh YOUR-CONTAINER-ID You can lookup YOUR-CONTAINER-ID by running docker ps. By default, docker-ssh will open a Bash session. You can also tell it to run a command, and then exit: docker-ssh YOUR-CONTAINER-ID echo hello world Building the image yourself If for whatever reason you want to build the image yourself instead of downloading it from the Docker registry, follow these instructions. Clone this repository: git clone https://github.com/phusion/baseimage-docker.git cd baseimage-docker Start a virtual machine with Docker in it. You can use the Vagrantfile that we've already provided. First, install vagrant-disksize plug-in: vagrant plugin install vagrant-disksize: Then, start the virtual machine vagrant up vagrant ssh cd /vagrant Build the image: make build If you want to call the resulting image something else, pass the NAME variable, like this: make build NAME=joe/baseimage You can also change the ubuntu base-image to debian as these distributions are quite similar. make build BASE_IMAGE=debian:stretch The image will be: phusion/baseimage-debian-stretch. Use the NAME variable in combination with the BASE_IMAGE one to call it joe/stretch. make build BASE_IMAGE=debian:stretch NAME=joe/stretch To verify that the various services are started, when the image is run as a container, add test to the end of your make invocations, e.g.: make build BASE_IMAGE=debian:stretch NAME=joe/stretch test Removing optional services The default baseimage-docker installs syslog-ng, cron and sshd services during the build process. In case you don't need one or more of these services in your image, you can disable its installation through the image/buildconfig that is sourced within image/system_services.sh. Do this at build time by passing a variable in with --build-arg as in docker build --build-arg DISABLE_SYSLOG=1 image/, or you may set the variable in image/Dockerfile with an ENV setting above the RUN directive. These represent build-time configuration, so setting them in the shell env at build-time will not have any effect. Setting them in child images' Dockerfiles will also not have any effect.) You can also set them directly as shown in the following example, to prevent sshd from being installed into your image, set 1 to the DISABLE_SSH variable in the ./image/buildconfig file. ### In ./image/buildconfig # ... # Default services # Set 1 to the service you want to disable export DISABLE_SYSLOG=0 export DISABLE_SSH=1 export DISABLE_CRON=0 Then you can proceed with make build command. Conclusion Using baseimage-docker? Tweet about us or follow us on Twitter. Having problems? Want to participate in development? Please post a message at the discussion forum. Looking for a more complete base image, one that is ideal for Ruby, Python, Node.js and Meteor web apps? Take a look at passenger-docker. Need a helping hand? Phusion also offers consulting on a wide range of topics, including Web Development, UI/UX Research & Design, Technology Migration and Auditing. Please enjoy baseimage-docker, a product by Phusion. :-)

 # # # # # # # # # # # # # # # # # # # #
 Repository: realm/realm-cocoa, index: 324, word count: 15519 
 # # # # # # # # # # # # # # # # # # # #

Awesome React Native components, news, tools, and learning material! Awesome React Native is an awesome style list that curates the best React Native libraries, tools, tutorials, articles and more. PRs are welcome! Don't miss out! Subscribe to our weekly newsletter Sponsors Never leave your command line for secrets Teller is an OSS and FREE productivity secret manager for developers made by SpectralOps, supporting cloud-native apps and multiple cloud providers. Mix and match all vaults and other key stores and safely use secrets as you code, test, and build applications. It's quick, easy, and safe. Get Started Now! Categories Buzzing Instabug Categories Conferences Chain React - Portland, OR USA React Native EU - Wroclaw, Poland React Alicante - Alicante, Spain ReactNext - Tel Aviv, Israel React Berlin - Berlin, Germany App.js Conf - Krakow, Poland Chain React - Portland, OR USA React Native EU - Wroclaw, Poland React Berlin - Berlin, Germany ReactEurope - Paris, France Articles Reference Howtos Assorted Continuous Integration Internals Components UI Navigation Navigation/Routing Articles Navigation Demos Deep Linking Text & Rich Content Analytics Utils & Infra Forms Geolocation Internationalization Build & Development Styling System Web Media Storage Backend Integrations Monetization Animation Extension Other Platforms Utilities Seeds Libraries Open Source Apps Frameworks Tutorials Books Videos Talks Training & tutorials Blogs Newsletters Releases Many thanks to everyone on the contributor list\:) Conferences Conferences dedicated to React Native specifically. A listing of React general conferences can be found on the ReactJS site. Chain React - Portland, OR USA http://chainreactconf.com Workshops - July 11th, 2018\ Conference - July 12-13th, 2018 React Native EU - Wroclaw, Poland http://react-native.eu/ Workshops - September 3-4th, 2018\ Conference - September 5-6th, 2018 React Alicante - Alicante, Spain http://reactalicante.es/ Workshops - September 13th, 2018\ Conference - September 14-15th, 2018 ReactNext - Tel Aviv, Israel https://react-next.com/ Conference - November 4th, 2018 App.js Conf - Krakow, Poland https://appjs.co/ Conference - April 4th, 2019 Workshops - April 5th, 2019 Chain React - Portland, OR USA https://infinite.red/ChainReactConf Workshops - July 10th, 2019 Conference - July 11th-12th, 2019 React Native EU - Wroclaw, Poland https://react-native.eu/ Workshops - September 4th, 2019 Conference - September 5th-6th, 2019 React Berlin - Berlin, Germany https://reactday.berlin/ Workshops - December 4th-5th, 2019 Conference - December 6th, 2019 ReactEurope - Paris, France https://www.react-europe.org/ Conference - May 14th-15, 2020 Workshops - May 12th-13th, 2020 Articles Content published on the Web. Reference React Native Styling Cheatsheet 2679 Howtos Add client-side indecent content checking to your React Native app using NSFWJS and TensorFlowJS How to add Firebase Auth with React Native 4 How to get started with Cloud Firestore on React Native How to upgrade React Navigation 1.x to 2.x How to use React Native Navigation v2 with Redux and Google Analytics React-Navigation Drawer Getting Started with React Native Development on Windows Getting Started with React Native Development for Windows Blueprint to becoming a React Native Developer How to Use the ListView Component How to upload photo/file in react-native Change splash screen in React Native Android app Remote Push Notifications with OneSignal Release React Native App to Android Play Store React Native & Apple TV today Record and Upload Videos with React Native How to Setup your First React Native app Using React Native With TypeScript How To Build a News Reader App with React Native and NewsAPI How to Build a Real Time Logo Detection App with React Native Build a Chatbot with Dialogflow and React Native How To Build Your First VR App with ViroReact and React Native React Hooks Basics Building a React Native App with React Hooks How to Build a Web App with React Native Building a React Native Mobile App with AWS Amplify and Expo User Authentication with Amplify in a React Native and Expo app How to build an Email Authentication app with Firebase, Firestore and React Native How to Gracefully Use Environment Variables in a React Native App How to build a xylophone app with Audio API, React Native, and Expo How To Use WebViews in a React Native App Assorted React Native Twitter Clone - React Native Twitter Clone powered by the Cosmic Headless CMS. Read about how it was built. Versioning React Native Application in elegant way (cross-platformely) 10 Best Practices for Building a Large Scale React Application React Native - Nic or Not App React and React Native State Museum Top 15 React Native libraries that I use in my apps Building 3 React Native Apps in One Summer React Native: Bringing modern web techniques to mobile First impressions using React Native Wrapping Cocoapods for React Native React Native: Initial Thoughts (opinion) A Dynamic Crazy Native Mobile Future Powered by Javascript ReactNative NES & More React Native Installation and Setup Diary of Building an iOS App with React Native Reflecting on React Native development React-Native layout examples React Native in Production - notes from Clay Allsop An iOS Developer on React Native React Native and WebRTC How to bridge a Swift view How to select the right React Native database Building a Native SoundCloud Android app with Redux - discussing redux, code reuse and performance on Android. React Native Twitter exploding heart - hardcore animations with Animation and ReactART Using AI to discover UI components - fun image processing / AI assisted process to discover and generate React Native UI Writing Android Components Unit Testing React Native with Mocha and Enzyme React Native's Layout Animation is Awesome Avoiding the Keyboard How To Use OpenCV In React Native For Image Processing Using Styled Components with React Native Create a React Native Image Recognition App with Google Vision API A comprehensive guide on building offline React Native apps with AsyncStorage Build a Chat App with Firebase and React Native Building Stylistic UIs with Emotion-JS for React Native Getting Started with Firestore and React Native React Native: Native Modules made for React developers - on the developer experience with 3rd-party libraries for RN 0.60+ Flutter vs React Native - Choosing your approach - Comparison article to help you choose the best approach depending on your project and experience. Continuous Integration How to build and deploy React Native apps for iOS and Android automatically with Appcircle CI/CD Distributing beta builds with Fastlane on Android and iOS Deploying a React Native App with Fastlane Continuous Integration for React Native Apps With Fastlane and Bitrise (iOS) How to automate Android build process on Bitrise CI fastlane for React Native iOS & Android app DevOps The simplest way to automate delivery of your React Native Application 21 Useful Open Source Packages for React Native Internals Performance React Native Debugger Internals Dirty-up and execute top-down - @vjeux on React's optimizations for background color, layout, and more Optimizing React Native Diving into React Native Performance Wait What Happens When my React Native Application Starts?An In-depth Look Inside React Native Components Components and native modules. UI lottie-react-native 10415 - A mobile library for Android and iOS that parses Adobe After Effects animations exported as JSON with bodymovin and renders them natively on mobile! react-icomoon - With React-Icomoon you can easily use the icons you have selected or created in icomoon. Zero Dependencies and Lightweight. react-native-vector-icons 9985 - Customizable Icons for React Native with support for NavBar/TabBar, image source and full styling. Choose from 3000+ bundled icons or use your own. react-native-maps 8388 - React Native Map components for iOS + Android react-native-swiper 6955 - The best Swiper component for React Native. react-native-gifted-chat 6546 - The most complete chat UI for React Native (formerly known as Gifted Messenger) react-native-scrollable-tab-view 5664 - A scrollable tab-view for React Native react-native-image-picker 4709 - A React Native module that allows you to use the native UIImagePickerController UI to select a photo from the device library or directly from the camera. react-native-material-kit 4124 - Bringing Material Design to React Native react-native-snap-carousel 3959 - Swiper component for React Native with previews, multiple layouts, parallax images, performant handling of huge numbers of items, and RTL support react-native-calendars 3402 - React Native Calendar Components react-native-ui-kitten 3140 - Customizable and reusable react-native component kit react-native-svg 2982 - SVG library that works on both iOS & Android react-native-image-crop-picker 2736 - iOS/Android image picker with support for multiple images and cropping react-native-splash-screen 2663 - A splash screen for react-native, hide when application loaded, it works on iOS and Android. react-native-material-ui 2536 - Highly customizable material design components for React Native react-native-app-intro 2433 - A React Native parallax effect app intro react-native-drawer 2276 - React Native Drawer react-native-typography 2260 Pixelperfect, nativelooking typographic styles for React Native react-native-fast-image 2240 - FastImage, performant React Native image component. react-native-blurhash 105 - Give your users the loading experience they want. react-native-paper 2218 - Material design for React Native react-native-swipeout 2194 - iOS-style swipeout buttons behind component react-native-blur 2172 - React Native Blur component react-native-progress 2069 - Progress indicators and spinners for React Native using ReactART. react-native-textinput-effects 2062 - Text inputs with custom label and icon animations for iOS and Android. Built by react native and inspired by Codrops. react-native-modalbox 2043 - A component for react-native react-native-lightbox 1917 - A very Slick and modern mobile lightbox implementation react-native-action-button 1762 - A customizable Float Button Component for React Native gl-react-native 1750 - Use OpenGL for performant effects on images and videos react-native-modal 1728 - An enhanced, animated and customizable react-native modal nachos-ui 1684 - NACHOS UI kit for React Native. Pick from a bunch of pre-coded UI components ready for your next kick-ass app in JavaScript or React. react-native-mapbox-gl 1663 - A Mapbox GL react native module for creating custom maps react-native-foldview 1616 - Animated FoldingCell implementation in React Native react-native-modern-datepicker 12 - React Native Modern Datepicker react-native-spinkit 1585 - A collection of animated loading indicators for React Native react-native-recyclerlist 1515 - High performance listview for React Native and Web with support for complex layouts. react-native-parallax-scroll-view 1486 - A ScrollView-like component with parallax and sticky header support. react-native-chart 1464 - React-native-chart is a simple module for adding line charts, area charts, or bar charts to your React Native app. react-native-gifted-listview 1443 - A ListView that embed some recurrent features like pull-to-refresh, infinite scrolling and more for Android and iOS React-Native apps react-native-datepicker 1365 - React Native date, datetime and time picker for both Android and IOS react-native-viewpager 1350 - ViewPager component for React Native react-virgin 1319 The react-native UI Kit you've been looking for. react-native-easy-grid 1304 - Easy Responsive Grid Layout for React Native. victory-native 1264 - Victory-native is a collection of components to help you create charts, bar graphs etc. react-native-picker 1238 - react-native-picker react-native-collapsible 1174 - Animated collapsible component for React Native using the new Animated API with fallback. Good for accordions, toggles etc react-native-icons 1168 - Quick and easy icons in React Native video react-native-orientation 1162 - Listen to device orientation changes in react-native and set preferred orientation on screen to screen basis react-native-tableview 1105 - Native iOS TableView wrapper for React Native react-native-keyboard-spacer 1103 - Plug and play react-Native keyboard spacer view. react-native-looped-carousel 1094 - Create looped carousel of views or images react-native-circular-progress 1088 - React Native component for creating animated, circular progress with ReactART react-native-popup-dialog 1088 - A React Native Popup Dialog Easy Use & Support Use Custom Animation. For IOS & Android react-native-largelist 1054 - The best performance large list component for React Native (iOS & Android) react-native-offline 977 - Handy toolbelt to deal nicely with offline/online connectivity in a React Native app. Smooth redux integration. react-native-root-toast 971 - React native toast like component, pure javascript solution react-native-dropdownalert 894 - A simple drop down alert with 4 pre-defined types. react-native-loading-spinner-overlay 885 - The only pure React Native, Native iOS and Android loading spinner (progress bar indicator) overlay react-native-tinder-swipe-cards 881 - Tinder card style swiping. react-native-slider 845 - A pure JavaScript component for react-native react-native-pathjs-charts 842 - Android and iOS charts based on react-native-svg and paths-js react-native-flash-message 810 - React Native flashbar and top notification alert utility react-native-svg-charts 764 - One library to rule all charts for React Native react-native-masonry 758 - A masonry~ish layout for rendering images. react-native-credit-card-input 742 - Easy (and good looking) credit-card input for your React Native Project rn-placeholder 1139 - Display some placeholder stuff before rendering your text or media content in React Native (+ React Native Web!) action-sheet-rn 1 - Probably the most declarative API for ActionSheets in React Native react-native-sglistview 731 - A memory minded implementation of React Native's ListView react-native-modal-dropdown 708 - A react-native dropdown/picker/selector component for both Android & iOS. react-native-button 707 react-native-bottom-sheet-behavior 701 - A react native wrapper for android BottomSheetBehavior. react-native-tabs 687 - React Native platform-independent tabs. Could be used for bottom tab bars as well as sectioned views (with tab buttons) react-native-search-bar 671 - The native search bar for react native. react-native-timeline-listview 665 - Timeline component for React Native App react-native-toastboard - The simplest way to show notification. apsl-react-native-button 653 - React Native button component with rounded corners. react-native-popup-menu 653 - Extensible popup menu component for React Native. react-native-qrcode 644 - react-native qrcode generator react-native-easy-toast 616 - A react native module to show toast like android, it works on iOS and Android. react-router-native 612 - A routing library for React Native that strives for sensible API parity with React Router react-native-copilot 595 - Step-by-step walkthrough for your react native app react-native-photo-browser 565 - Local and remote photo browser with captions, selections and grid view support. react-native-calendar 559 - Calendar Component for React Native react-native-calendar-events 510 react-native-parsed-text 552 - Parse text and make them into multiple React Native Text elements react-native-step-indicator 538 - A simple react-native implementation of step indicator widget compatible with the ViewPager and ListView. react-native-popover-haobtc 514 - A component for react-native react-native-dropdown 507 - A better Select dropdown menu for react-native react-native-star-rating 489 - A React Native component for generating and displaying interactive star ratings react-native-rating-element 8 - A react native rating system supporting: decimal point's rating, direction aware icons like bottom to top or right to left etc, custom icons from Ionicons, custom images and record rating given by users. react-native-parallax 479 - Parallax effects for React Native using Animated API react-native-sketch 467 - A react-native <Sketch /> component to draw with touch events. react-native-dialogs 463 - React Native wrappers for https://github.com/afollestad/material-dialogs galio 458 - A fresh react native UI framework. react-native-root-siblings 452 - Add sibling elements after your app root element. react-native-size-matters 436 - A React-Native utility belt for scaling the size your apps UI across different sized devices. react-native-button-component 434 - A Beautiful, Customizable React Native Button component for iOS & Android react-native-super-grid 434 - Responsive Grid View for React Native. react-native-activity-view 427 - iOS share and action sheets for React Native react-native-canvas 421 - A Canvas element for React Native react-native-refresher 419 - A React Native pull to refresh ListView completely written in js. Also supports custom animations. react-native-sortable-list 412 A sortable list for react native with both vertical and horizontal direction support. react-native-gesture-password 410 - A gesture password component for React Native react-native-carousel 406 - Simple carousel component for react-native react-native-country-picker-modal 403 - Country picker provides a modal allowing a user to select a country from a list. It display a flag next to each country name. react-native-radio-buttons 399 - A react component to implement custom radio buttons-like behaviors: multiple options, only on can be selected at once. react-native-masked-text 392 - A simple masked text and input text component for React Native. react-native-accordion 390 - An Accordion Component for React Native react-native-invertible-scroll-view 388 - An invertible ScrollView for React Native react-native-message-bar 384 - A module for presenting notifications via an animated message bar at the top/bottom of the screen, highly customizable, for React Native (Android and iOS) projects. react-native-fit-image 383 - Responsive image component to fit perfectly itself. react-native-text-input-mask 383 - Text input mask for Android and iOS, native implementation RedMadRobot libraries react-native-alphabetlistview 372 - A ListView with a sidebar to jump to sections directly, based on johanneslumpe's react-native-selectablesectionlistview react-native-check-box 372 - Checkbox component for react native, it works on iOS and Android. react-native-really-awesome-button 370 - RNRAB is a 3D at 60fps, progress enabled, extendable, production ready component that renders an awesome animated set of UI buttons. react-native-autocomplete-input 366 - Pure javascript autocomplete input for react-native react-native-splashscreen 358 - A splash screen for react-native react-native-responsive-image 344 - Most elegant Responsive Image component react-native-pdf-view 338 - View pdf file using react-native react-native-image-header-scroll-view 338 - ScrollView with an image in header which become a navbar react-native-toast 336 - An android like toast for react-native support for iOS and Android react-native-modal-picker 333 - A cross-platform (iOS / Android), selector/picker component for React Native that is highly customizable and supports sections. react-native-off-canvas-menu 327 - Beautifully crafted off canvas menu components for React native applications. rn-sliding-up-panel 321 - React Native draggable sliding up panel purly implemented in Javascript. Works nicely on both iOS and Android. react-native-search-box 319 - A simple search box with animation, inspired from ios search bar. react-native-parallax-swiper 315 - Configurable parallax swiper based on an iOS pattern. Uses Native Driver for super smooth parallax. react-native-gesture-recognizers 313 - Gesture recognizer decorators for react-native react-native-searchbar 313 - An animated search bar for react native with inbuilt search (iOS and Android) react-native-app-auth 310 - React Native bridge for AppAuth - a PKCE-compliant SDK for communicating with OAuth2 providers react-native-circular-action-menu 305 - An animated and customizable circular floating menu. react-native-effects-view 304 - React Native Component that makes easy to use iOS8 UIVisualEffect react-native-root-modal 304 - React native modal component react-native-timeago 278 - Auto-updating timeago component for React Native react-native-grid-view 276 - React Native Grid/Collection View component react-native-md-textinput 275 - React Native TextInput styled with Material Design. react-native-timer-mixin 274 - TimerMixin provides timer functions for executing code in the future that are safely cleaned up when the component unmounts. This is a fork that includes react-native InteractionManager support. react-native-tableview-simple 267 - React Native component for TableView made with pure CSS react-native-keyboard-manager 267 - Library that allows to prevent issues of keyboard sliding up and cover on React-Native iOS projects. react-native-tabbar 261 - Tab bar with more freedom react-native-simple-router 255 - A community maintained router component for React Native react-native-cacheable-image 255 - A filesystem cacheable image component for react-native react-native-segmented-control-tab 252 react-native-segmented-control-tab (for Android/iOS) react-native-modal-selector 249 - A cross-platform (iOS / Android), selector/picker component for React Native that is highly customizable and supports sections. react-native-keyboardevents 247 - Monitors keyboard show/hide notifications react-native-multiselect 246 - Simple multi-select component for react-native. react-native-cardview 239 - CardView for react-native (All Android version and iOS) react-native-shimmer-placeholder 231 - Placeholder of React Native react-native-progress-hud 228 - A clean and lightweight progress HUD for your React Native app react-native-qrcode-svg 228 - A QR Code generator for React Native based on react-native-svg and node-qrcode. react-native-bottom-action-sheet 226 - React Native: Native Bottom Action Sheet react-native-awesome-button 222 - A React Native component rendering a button supporting showing different appearances and functionality given the passed props react-native-mobx 220 - Make your app reactive with MobX and react-native-router-flux react-native-egg 220 - An easter egg component implementation simple gestures detection achieve trigger can make your react native app infinitely more fun. react-native-progress-bar 218 - An animated progress bar component for React Native react-native-tooltip 217 - A react-native wrapper for showing tooltips react-native-emoji 216 - Emoji component for React Native react-native-image-cache-hoc 211 - Higher Order Component that adds advanced caching and persistence functionality to standard Image component. react-native-parallax-scroll 209 - Parallax Scroll component with sticky header, foreground, native-driver and all scrollable components (FlatList, ListView, SectionList, ScrollView) support. react-native-shine-button 205 - React Native for Effects like shining autoresponsive-react-native 201 - A Magical Layout Library For React react-native-autolink 201 - Autolinking component for React Native react-native-carousel-control 199 - React Native Carousel control with support for iOS and Android. react-native-picker-select 199 - A Picker component for React Native which emulates the native <select> interfaces for iOS and Android react-native-calendar-select 195 - A component to select a date period from calendar modal, like Airbnb. react-native-wheel-picker 190 - React native cross platform picker. react-native-grid-component 188 - Easy to use grid component for your react-native project. Supports iOS and Android. react-native-popover-menu 188 - React Native: Native Popover Menu react-native-collapsing-toolbar 185 - wrapper for android CollapsingToolbarLayout react-native-pagination 182 - A Beautiful Pagination Plugin For Lists. react-native-hero 180 - A hero/banner component with support for dynamic or static images, dynamic sizing, color overlays, and more. react-native-selectme 178 - A better Select dropdown menu for react-native react-native-swiper-animated 176 - Tinder-like swiper for react-native react-native-tab 171 - react-native-tab is a simple module for add a "Tab Menu" to your React Native app. react-native-webbrowser 167 - A cross-platform (iOS / Android), full-featured, highly customizable web browser module for React Native apps. react-native-autocomplete 163 - React Native Component for MLPAutoCompleteTextField react-native-segmented-view 159 - Segmented View for React Native (with animation) react-native-cache-image 158 - A cache-image for react-native react-native-pulse-loader 158 - Tinder like loader for your React Native app stacks 156 - Stacks: a set of layout components for building RN views blazingly fast , and with debug mode and design system grid you can investigate non-trivial visual issues. react-native-display 155 - This module brings "Display: none" (css style) to turn on/off components from render. Using this module will improve your app performance and appearance with the enter/exit animations. RNParallax 155 - A react native scroll view component with Parallax header react-native-checkbox 154 - Checkbox component for React native react-native-phone-input 154 - Phone input box for React Native react-native-switch-pro 153 - A pretty nice switch for Android and iOS that have same performance on two platforms and clean code in the library. react-native-popup 153 - Popup for react-native react-native-radial-menu 153 - A Radial Menu optimized for touch interfaces react-native-gestures 152 - Composable gesture system in react native react-native-page-control 151 - React native page control, like ios UIPageControl react-native-iconic 149 - React Native - Animated Icons with different states react-native-google-place-picker 148 - React Native Wrapper of Google Place Picker for both Android and iOS. react-native-scaling-drawer 148 - React native scaling drawer. react-native-image-carousel 148 - Image carousel with support for fullscreen mode, image swiping and pinch-to-zoom in fullscreen mode. react-native-offline-mode 144 - Swap your app with an offline version while there's no connectivity react-native-orientation-listener 141 - A react-native library for obtaining current device orientation react-native-multi-slider 137 - Pure JS slider component with multiple markers for React Native react-native-color-picker 137 - React Native implementation of color picker for both Android and iOS. react-native-android-statusbar 135 - A react native android package to control the status bar. react-native-privacy-snapshot 133 - Obscure passwords and other sensitive personal information when a react-native app transitions to the background react-native-custom-segmented-control 132 - Native UI iOS component for Segmented Control with custom style react-native-map-link 131 - Open a location in the maps app of the user's choice. react-native-sketch-canvas 129 - A React Native component for drawing by touching on iOS and Android. (support drawing on image, text) react-native-floating-labels 126 - Reusabe floating lable component for react native react-native-beautiful-video-recorder 125 - The video recorder component that extends from react-native-camera. It works for both iOS & Android. react-native-cell-components 125 - Awesome react-native cell components! From a Cell to more complex & awesome components. react-native-material-menu 119 - Pure JavaScript material menu component for React Native. react-native-bouncy-drawer 116 - Highly customizable Bouncy Drawer react-native-taptargetview 114 - React Native Bridge for Android KeepSafe/TapTargetView. An implementation of tap targets from the Material Design guidelines for feature discovery. photo-viewer 114 - A photo viewer for react native build on top of NYTPhotoViewer and FrescoImageViewer react-native-switch-selector 112 - A custom Switch Selector component for Android and iOS. react-native-flexi-radio-button 111 - Simple and flexible Radio button for React Native react-native-triangle 108 - Draw triangle views in react native react-native-viewport-units 107 - Incredibly simple utility for (sort of) using viewport units with React Native. react-native-wheel-picker-android 186 - Simple and flexible React native wheel picker for Android, including DatePicker and TimePicker. react-native-device-display 105 - A simple way to create dynamic views through device and display detection, allowing the creation of adaptable and universal apps. react-native-android-kit 104 - A set of native Android UI components and modules for React Native framework (Android Design Support Library, TabLayout, Floating Action Button and more...). react-native-fading-slides 103 - Simple looped fading slides carousel for React Native react-native-scl-alert 102 - React Native implementation of the package SCLAlertView-Swift react-native-card-view 101 - A react native card component react-native-marquee-label 100 - A marquee label for react-native react-native-drawer-menu 97 - React Native Drawer Menu react-native-simple-dialogs 97 - Cross-platform simple dialogs for React Native based on the Modal component. react-native-swipe-a-lot 96 - A swipe component for React Native that works on iOS and Android. react-native-submit-button 96 - Animated Submit button. Works on both android and ios react-native-actions-sheet 94 - A Cross Platform(Android & iOS) ActionSheet with a flexible api, native performance and zero dependency code react-native-dialog 92 - Pure JavaScript React-Native dialog react-native-scrollable-mixin 91 - A standard interface for your scrollable React Native components, making it easier to compose components react-native-open-maps 90 - A simple lib to open up the corresponding map application (Google or Apple Maps) from a set of coordinates (latitude & longitude) within react-native react-native-swiper2 86 - Swiper component for React Native. Supersede react-native-swiper react-native-listitem 86 - iOS-style listitem component for React Native react-native-progressive-input 86 - TextInput with clear button and activity indicator, used as part of autocomplete list. react-native-in-app-notification 86 - Customisable in-app notification component for React Native react-native-shared-preferences 85 - Android's Native key value storage system in React Native react-native-emoji-picker 85 - Simple Emoji picker for react-native with optional modal-like component react-native-scalable-image 85 - React Native Image component which scales width or height automatically to keep the original aspect ratio. react-native-page-swiper 83 - Page Swiper component for React Native. react-native-material-showcase-ios 81 - React Native Bridge for iOS aromajoin/material-showcase-ios. An elegant and beautiful showcase for iOS apps. react-native-label-select 81 - A modal selector for React Native with selected items displayed as labels. react-native-3dcube-navigation 80 - Page Swiper component with 3D cube transition (horizontal and vertical) react-native-keyboard-accessory 80 - Keyboard Accessory (View, Navigation) Component. Sticky views on keyboard. react-native-draggable-grid 79 - A React Native draggable and sortable grid component write by typescript. react-native-textinput-utils 79 - A react native extension which allows you to control TextInput better. react-native-idle-timer 79 - An Objective-C bridge that allows you to enable and disable the screen idle timer in your React Native app react-native-snackbar-component 77 - A snackbar component for Android and iOS, customizable and simple. react-native-charts 76 - Delightfully-animated data visualization. react-native-android-blurryoverlay 75 - A react native android package to show a blurry overlay. react-native-calendar-datepicker 75 - A cross-platform calendar datepicker react-native-scrollview-smart 75 - A Smart ScrollView component for IOS and Android. react-native-zoom-image 75 - An image viewer component for react-native, like twitter's image viewer. react-native-picker-xg 74 - A picker for both Android and iOS react-native-status-bar-height 73 - A small library that helps you to get status bar height easily. It also support iPhone X. react-native-color-wheel 72 - A react native reusable color picker wheel react-native-scrollview-lazyload 71 - react-native scrollview with image lazy load react-native-pure-navigation-bar 71 - A fully customizable navigation bar in React Native. react-native-material-cards 70 - A material design card component, customizable and versatile. react-native-item-cell 69 - React Native default style iOS item cell react-native-calendario 69 - React Native Calendar DatePicker react-native-picker-android 67 - react-native-picker-android react-native-nested-stylesheet 67 - Nestable stylesheets for react-native. react-native-dropdown-android 65 - Simple wrapper for Android's Spinner to use with react-native react-native-slot-machine 65 - A text slot machine component for react-native react-native-swipeview 65 - SwipeView component used to perform actions like swipe to delete, works on iOS and Android react-native-download-button 64 - React Native Download Button: with pretty cool animation react-native-siri-wave-view 64 - React Native: Native Siri Wave View react-native-card-media 63 - Card media component & Support multiple image layout react-native-simple-picker 62 - A simple react-native select picker react-native-view-pdf 62 - PDF viewer for React Native react-native-touchable-bounce 62 - React Native Touchable Bounce react-native-streetview 61 - Google's Panorama/StreetView component for iOS and Android. react-native-thumbnail 60 - Get thumbnail from local media. react-native-simple-stepper 60 - A super simple react-native implementation of the UIStepper iOS control. react-native-phone-picker 58 - a quick phone picker control react-native-infinite-scrollview 58 - ScrollView with infinite paged scrolling (no looping) react-native-select-multiple 58 -A simple and easy to use component for multiple selection of item from List. react-native-easy-content-loader 57 - React-Native light weight skeleton content loading. react-native-multiple-choice 57 - A cross-platform (iOS / Android) single and multiple-choice React Native component. k-react-native-swipe-unlocker 55 - A simple swipe unlock for React Native react-native-walkthrough-tooltip 55 - Highlight a component via tooltip/popover react-native-adbannerview 52 - React Native Bridge for ADBannerView react-native-fxblurview 52 - React Native wrapper for popular FXBlurView library for realtime, fine-tuned blur effects react-native-beautiful-image 52 - The Beautiful Image component that supports fadeIn animation and shows placeholderSource if the main source can't be loaded. react-native-360-image-viewer 100 - The component helps to simulate 360 degrees image from multiple images. react-native-fs-modal 51 - React native full screen modal component. react-native-toast-native 51 React Native Toast component for both Android and iOS. react-native-masked-view 50 - A element for react-native react-native-md-motion-buttons 50 - Material design motion button inspired by inVision app. react-native-drop-refresh 49 - A pull down to refresh control for react native. react-native-pin-view 48 - Easy, convenient, quick-forming PinView component. It runs smoothly for both IOS and Android. react-native-radio-button-classic 47 - Bring Classic Radio to React-Native react-native-image-intent 47 - Image intent receiver for React Native android react-native-dial 47 - A react native reusable and efficient dial knob element. react-native-date 46 - React Native date and time pickers for Android react-native-draggable-drawer 46 - DraggableDrawer component for React Native. react-native-date-picker 46 - A date picker component for Android and iOS react-native-message-composer 45 - React Native module bridge to iOS MFMessageComposeViewController react-native-layout 45 - Semantic JSX layout components for react-native react-native-touch-visualizer 45 - Visualize touches and drags on React Native apps for iOS. react-native-calendar-android 44 - A simple material-themed calendar for react native android react-native-air-progress-bar 44 - React Native progress-bar component, customizable and animated react-native-full-screen 44 - React Native FullScreen api and element react-native-full-image-picker 44 - Support taking photo, video recording or selecting from photo library. react-native-viewport 43 - Viewport dimensions for react-native react-native-progress-circular 43 - A pure React Native Component for circular progress bars for both iOS and Android. react-native-tween-animation 43 - A simple react native state tween animation module. react-native-flanimatedimage 43 - FLAnimatedImage for React Native. react-native-grading 43 - React Native Component for grading scores using ReactART. react-native-auto-typing-text 43 - An auto typing text component for react-native react-native-slack-webhook 42 - Follow some activities (new user, payment,...) from your app via Slack and this webhook lib. react-native-responsive-linechart 41 - Draw Line and Area charts easily. Works responsively. react-native-simpledialog-android 41 - React Native Android module to use Android's AlertDialog - same idea of AlertIOS react-native-toolkit 41 - A collection of common UI components for react native mobile apps. react-native-draggable-grid 41 - A React Native draggable and sortable grid component write by typescript. react-native-sortable-gridview 4 - A React Native sortable and draggable Grid View Component. react-native-elastic-stack 41 - ReactNative component that implements elastic stack effect react-native-big-slider 41 - Yet another, big one, pure JS easily customisable and hackable react-native slider component. react-native-custom-actsheet 40 - A custom ActionSheet for react-native rn-render-perfs 40 - Measure React rendering lifecycles using UI controls react-native-animated-check-mark 40 - A small react component for animated cross-mark transformation. react-native-easy-dnd 39 - Drag and drop component for react-native react-native-fab 39 - A FAB button component for Android and iOS, customizable, simple and as per material design specs. react-native-popupwindow 38 - Android PopupWindow for react-native module react-native-wheel 38 - android wheel view for react-native react-native-bar-collapsible 38 - A Bar component that can be collapsible (toggle/accordion), clickable or text-only. react-native-circle-view 37 - circle progress for react native android using CircleView react-native-slidable-tab-bar 37 - Slidable tab bar for instant view rendering(react-native) react-native-scrollable-decorator 37 - A standard interface for your scrollable React Native components, making it easier to compose components react-native-circle-checkbox 37 - Circle checkbox component for React Native react-native-newsticker 35 - The News Ticker component for React Native react-native-awesome-alert 35 - Customizable modal components with check options in React Native react-native-view 34 - Lightweight View component for quick styling. react-native-draggable-calendar 34 - A calendar component supporting dragging. react-native-countdown 33 - react native countdown button react-native-dashed-border 33 - A element for react-native react-native-writebox 33 - (iOS / Android) Facebook/Twitter textarea that autogrow and count characters. react-native-ibeacon-simulator 32 - React Native Library to simulate device act as an iBeacon react-native-suggester 32 - React-Native package to decorate TextInput and get suggestions with good UX. react-native-photo-grid 31 - React Native component that handles the complexities of building a grid of photos with a flexible number of photos per row. react-native-android-iconify 30 - icons for react native android using android-iconify react-native-touchable-set-active 30 - Touchable component for React Native that enables more advanced styling by setting an active state. Most useful for building your own touchable/button components on top of. react-native-telephone-input 30 - React Native Telephone Input, discover country and mask telephone Input react-native-nmrangeslider-ios 29 - The NMRangeSlider component for React Native react-native-fade-in-view 29 - A simple and lightweight RN component that fades in its children react-native-gl-image-filters 27 - React Native GL Filters for Image implementation. react-native-focus-scroll 26 - react-native-focus-scroll can detect which children are focused when scrolling. react-native-about-libraries 26 - React Native: It offers information about install packages react-native-actionsheet-native 25 - Android ActionSheet support for React Native react-native-comparison-slider 25 - A simple component to display two image in comparison with a slide-over feature. react-native-selectmultiple-button 25 - A button (or a grouped buttons) supporting multiple or radio selection react-native-timeline-theme 25 - Collection of TimeLine theme. This package only use flexbox(without absolute) & FlatList react-native-date-range-picker 25 - Simple date range picker extended from react-native-calendars react-native-circle-progress 24 - A custom Circle Progress Indicator for React Native react-native-app-intro-v2 24 - Latest App intro react-native-starrating 24 - a react-native component for display interactive star ratings react-native-echarts-wrapper 24 - Powerful ECharts wrapper build for React Native react-native-orientation-controller 23 - A react-native library for obtaining and controlling the current device and application orientation react-native-match-media 23 - window.matchMedia mock for React Native react-native-simple-card-view 23 - Easiest way to adding a card view on your screen. monalisa-ui 22 - MonalisaUI is UI component library for React Native to build native mobile apps for iOS and Android platforms react-native-square-view 22 - A square view component for react native. react-native-ichart 22 - ichart for react-native react-native-dropbox-chooser 21 - React Native dropbox chooser module react-native-compress 21 - Compress video for react native. Only for iOS, Android will be coming. react-native-custom-actionsheet 21 - Fully customizable ActionSheet for React Native. react-native-timepicker 20 - React Native timepicker for iOS react-native-custom-checkbox 20 - React Native checkbox that can be customize. Works for both Android and iOS. react-native-tilt 20 - Tilt effect with accelerometer for React Native components. react-native-drawpad 20 - A pad for users to draw by touching rn-ab-hoc 19 - Poor intrusive way to make A/B Testing by using an HoC instead of components. react-native-expand 19 - A react-native expandable component for both Android and iOS react-native-modal-loader 19 - Customizable animated modal progress hud for react apps. react-native-images-collage 19 - Robust interactive image collage component for React Native. react-native-avatar-gravatar 18 - React Native Gravatar component react-native-image-modal 16 - simple full size modal image for iOS and Android. supports zoom-in/out, double-tap zoom-in/out, move and swipe-to-dismiss react-native-notifier 16 - Fast and simple in-app notifications for React Native react-native-grid 15 - The 24-column grid component for react-native react-native-search 15 - Native Search component for react native. rn-displayable 15 - Display your components based on props or a set of rules react-native-custom-picker 15 - React native customizable picker component. react-native-confirmation-code-field 15 - A React Native component to input confirmation code for both Android and IOS react-native-android-circles 14 - A react native android package to show a circle progress view. react-native-anchor-point 14 - Make the fancy 3D transform easier in react native react-native-code-verification 13 - An UI module for user-side pincode verification. react-native-hijri-date-picker 13 - Date Picker Dialog for Hijri calendar for android. react-native-imagewand 13 - image wand for react native react-native-gravatar 13 - react-native wrapper for gravatar-api react-native-rebound-scrollview 12 - React Native Android ReboundScrollView implementation. react-native-calculator 12 - React Native Calculator and Calculator Input Component. react-native-navbar-color 12 - Change Navigationbar Color in Android radio-buttons-react-native 11 - Animated radio buttons component for react native react-native-piechart 10 - A component for React Native react-native-seekbar-android 10 - A React Native wrapper Android's SeekBar react-native-coachmasks 10 - react-native-coachmark! It helps you easily create Coach Marks to enhance user experience! react-native-progress-button 10 - A react native button component that can show progress. react-native-quiltview 9 - Native iOS UICollectionView wrapper with RFQuiltLayout for React Native react-native-relative-units 9 - Relative units for React Native react-native-simple-button 9 - A simple react-native button react-native-styled-toast 9 - A themeable toast component for React Native. react-native-frame-loading 9 - The Loading indicator with frame by frame view animation react-native-rheostat 9 - Inspired by Airbnb's rheostat, a powerful slider with assorted data visualized charts. react-native-country-picker 8 - React Native Country Picker react-native-flex-label 8 - A text label for React Native that handles multiple lines of text with ellipses truncation as well as vertical alignment within it's view container. react-native-link 8 - A link component react-native-stylesheet-xg 8 - extension stylesheet for cross platforms and responsive react-native-censored 8 - React Native component to censor content. react-native-bouncing-ball 8 - React Native component bouncing ball for both iOS and Android. react-native-loading 7 - A lightweight loading for your React Native app. react-native-segment-control 7 - A swipeable SegmentedControl component for React Native apps. react-native-animated-styles 7 - Easily animate/transition react components between two style states. react-native-hide-modal 6 - Modal component that can be hidden react-native-hole-view 6 - Component for cutting out click-through holes in any view. Perfect for making tutorial-like overlay react-native-masonry-brick-list 5 - Staggered Or Masonary List View For React Native Written in pure js react-native-blur-overlay 5 - React Native Blur Overlay Library For Ios And Android react-native-rate-modal 5 - Hackable "rate us" component for React Native. react-native-fancy-carousel-viewpager 4 - React Native Designed View Pager Library (pure js) pinar 4 - Customizable, lightweight React Native carousel component with accessibility support. react-native-svg-transformer 4 - Import SVG files inside React Native components. Uses the react-native-svg library to render SVG images. react-native-progress-steps 4 - A simple and fully customizable React Native component that implements a progress stepper UI. react-native-loader-hud 3 - Loader animation library for React Native react-native-double-buffer 3 - Simple React Native Double Buffer View react-native-fontbase 3 - Defining font sizes in React Native react-native-units 2 - A collection of useful units and a simple grid implementation for responsive layouts in React Native. react-native-easy-checkbox 2 - Simple CheckBox for react-native react-native-scene-manager 2 - Simple Scene Manager for React-Native react-native-rounded-navigation-drawer 2 - React Native Designed Navigation Drawer Library (Pure Js) react-native-expandable-fab-menu 2 - React Native Expandable Fab Menu Component (pure js) react-native-animated-bottom-tabbar 2 - Animated bottom Tab bar for react native react-native-create-new-file-ios 1 - A react-native interface for creating a blank new file on ios. File must not already exist. react-native-picker-module 1 - A different approach for React Native Picker. react-native-countries 1 - This package is provide you directly native countries name & code list from device. react-native-scrubber 1 - A simple audio/video Scrubber for both iOS and Android. react-native-loader-kit 1 - Purely native loading animations for React Native. react-native-new-feature 1 - A simple and lightweight What's New component to show your latest React native Features. react-native-sdr - Server Driven Rendering (SDR) component for React Native react-native-store-view 19 - Wraps SKStoreProductViewController for use in react-native projects react-native-image-container 0 - Image container for React Native react-native-counters 0 - Minus Plus Counter for React Native react-native-gradient-buttons - A lightweight, customizable and haptic Gradient Button component for React Native. react-native-auth-screens - A series of Authentication Views for React Native: Sign In, Social Sign In Sign Up, and Forgot Password. Uses react-native-gradient-buttons. react-native-animated-flatlist - Animated Flatlist for React Native. swipeable-modal-react-native - A 'pop-up' modal that can be swiped away left or right to run different functions. react-native-countdown-text - A React Native component that converts a timestamp of a future date to a readable countdown clock, based on a format. rn-actionsheet-module 0 - BottomsheetDialog & ActionSheetIOS with same props and usage. react-native-animated-loader - A React Native Loader Component which uses Airbnb's Lottie for beautiful loader animations. rn-verifcode - React-Native component to input confirmation code for both Android and IOS react-native-picker-modal-view - React Native Module to select item picker modal. rn-material-textinput - A simple TextInput wrapper for material styling in iOS and Android with Customizable styles & Animated label. rn-action-picker - A simple action picker for iOS and Android. Renders Native ActionSheetIOS Component in iOS and custom ActionSheet lookalike component in Android. rn-collapsible-section - A collapsible section / section list with customizable section body and child body. Supports both iOS and Android. view-on-steroids - React-Native View component with inline styles react-native-eva-icons - Eva Icons implementation for React Native based on react-native-svg elements. react-native-dots-pagination 3 - A simple dot paging for React Native. react-native-gesture-detector - Easily create and detect custom, complex gestures on React Native. react-native-scrollview-header 5 - An animated ScrollView header that transitions from transparent background to opaque upon scrolling. react-native-wizard - Easily navigate your user for next step. Quick-forming Wizard component. react-native-timetable - timetable library for React Native react-native-material-drawer - React Native Material Drawer for iOS, Android, Web, and Electron Navigation react-navigation 14233 - Easy to use Navigation for React Native react-native-navigation 9325 - App-wide support for 100% native navigation with an easy cross-platform interface. react-native-navigation-hooks 109 - A set of React hooks for React Native Navigation. react-native-router-flux 7720 - React Native Router based on new React Native Navigation API kittenTricks 4227 - A react native mobile starter kit with over 40 screens and theme hot reload support native-navigation 3060 - Native navigation library for React Native applications react-native-navbar 1824 - Simple customizable navbar component for react-native react-native-router 1203 - Awesome navigation for your native app. ex-navigation 1019 - A route-centric, batteries-included navigation library for Exponent and React Native that works seamlessly on Android and iOS. react-native-controllers 580 - Truly native no-compromise iOS navigation for React Native. ex-navigator 531 - Route-centric navigation built on top of React Native's Navigator react-native-nav 262 - A cross-platform (iOS / Android), fully customizable, React Native Navigation Bar component react-native-navigation-drawer 98 - A slide menu inspired from Android for React-Native react-native-ya-navigator 88 - Yet another react native navigator component navbar-native 86 - A new, fully customizable Navbar component for React-Native react-native-swiper-flatlist 81 - React Native Swiper component implemented with FlatList react-native-easy-router 78 - React Native router with easy-to-use API react-native-navigator 74 - A simple router for react native react-navigation-magic-move 62 - Bindings for using react-navigation with react-native-magic-move (shared element transitions) react-native-navigation-bar 59 - react-native-navigation-bar react-native-url-handler 37 - Navigate to external URLs, handle in-app URLs, and access system URLs react-native-grid-list 28 - React Native Grid List component react-native-route-navigator 27 - React-Native page navigation using URIs. react-native-transparent-bar 16 - react native navigator transparent bar react-native-email-chip 8 - A simple yet customizable component to display a chip list of emails react-native-invoke-app 8 - Bring React Native App to foreground from Headless JS react-native-keyboard-sticky-view 7 - Keyboar Sticky View with animation and renderProps sajjad-brick-list 5 - Staggered Or Masonary List View For React Native Written in pure js react-native-router-sinux 4 - React Native Router based on new NavigationExperimental that use Sinux as Flux implementation. react-native-simple-slider 3 - This is a simple javascript slider component for react native react-native-header-scroll-view 3 - iOS-style large header scroll view. react-native-navigation-buttons 2 - iOS navigation buttons for the React Native Navigator react-native-hotspot 2 - A React Native component that displays hotspots over desired components to help lead your users through an onboarding flow or direct them towards new UI elements react-native-pointer-interactions 2 - Expose iPad mouse & trackpads interactions to React Native. react-native-yynavigator 1 - custom navigation bar for react-native react-native-telegraph 1 - In-app message orchestration supporting Snackbars, Banners and Dialogs Navigation/Routing Articles Basics of using react-native-router-flux Routing and Navigation in React Native NavigatorIOS: Accessing onRightButtonPress from within child component Navigation Demos movieapp 1441 Discover Movies and TV shows - it uses redux and wix/react-native-navigation ExNavRelay 23 - React Native + Ex-navigation + Relay integration template React Native Drawer & Bottom-Tab Navigation 6 React Native Example App: Navigation Deep Linking react-native-deep-link 36 - React Native library to handle deep links Text & Rich Content react-native-hyperlink 354 - A <Hyperlink /> component for react-native that makes urls, fuzzy links, emails etc clickable and stylable react-native-draftjs-render 253 - A React Native render for Draft.js model react-native-html-to-pdf 171 - Convert html strings to PDF documents using React Native react-native-htmltext 132 - Use HTML like markup to create stylized text in react-native. react-native-html-webview 102 - Display (possibly untrusted) HTML using a UIWebView in React Native. react-native-html-render 98 - A html render for react-native react-native-markdown-display 57 - Highly customizable Markdown renderer using native components for all its elements without any web-view. react-native-measure-text 48 - Measure text height without laying it out. react-native-markdown-editor 47 - Markdown editor like github comment editor (contains preview, markdown buttons) react-native-showdown 43 - React-native component which renders markdown into a webview! react-native-file-viewer 33 - Preview any type of file supported by the mobile device react-native-responsive-fontsize 22 - Provide responsive fontsize based on device height in React-Native react-native-text-size 21 - Measure text accurately before laying it out and get font information from your App. react-native-hypertext 20 - React Native module to render hypertext (text with links) react-native-asciimage 17 - An ASCIImage component for React Native react-native-universal-modal 16 - Universal simple modal component for React Native react-native-html 11 - render html as react native custom elements react-native-responsive-fontsize 83 - Provide responsive fontsize based on device height in React-Native rn-pdf-reader-js 6 - A PDF reader, in JavaScript only, for Expo, Android capable, PDF.JS @typeskill/typer 4 - The Operational-Transform Based (React) Native Rich Text Library Analytics react-native-fabric 1097 - A React Native library for Fabric, Crashlytics and Answers react-native-google-analytics-bridge 1071 - A native Google Analytics bridge for React Native. Uses the official libraries on both iOS and Android. react-native-google-analytics 325 - Google Analytics for React Native! react-native-mixpanel 307 - A React Native wrapper for Mixpanel tracking react-native-ab 160 - A component for rendering A/B tests in React Native react-native-segment-io-analytics 68 - A React Native Segment wrapper! react-native-ux-cam 32 - React Native wrapper for uxcam.com. react-native-td 26 - An unofficial React Native SDK for Treasure Data. react-native-flurry-sdk 15 - Official React Native wrapper for Flurry SDK. Supports Android, iOS and tvOS. Utils & Infra detox 3566 - Graybox End-to-End (functional) Tests and Automation Library for Mobile with first class support for React Native react-native-workers 616 - Background services and web workers for react-native react-native-mock 504 - A fully mocked and test-friendly version of react native loki 395 - Visual Regression Testing for Storybook react-native-slowlog 271 - A high-performance timer based profiler for React Native that helps you track big performance problems react-native-zip-archive 173 - Zip / Unzip archive utility react-native-tips 160 - This module is used to create easily some tips to help your new users to understand how works your app. codemod-RN24-to-RN25 104 - a simple codemod to handle the new import style on >=RN25 react-native-linkedin 101 React-Native LinkedIn, a simple LinkedIn login library for React-Native or Expo with WebView and Modal react-native-eval 75 - Call any JS functions from your native code react-native-device-log 73 - A UI and service for displaying dev-logs on devices. react-native-call-detection 73 - Helps to detect different call states like Incoming, Disconnected, Dialing and Connected react-native-userdefaults-ios 66 - React Native Module for NSUserDefaults react-native-webp 56 - react-native-webp adds support for WebP images for react-native components. react-native-global-event-emitter 50 - Shared event emitter between native and JS for React Native. react-native-user-defaults 48 - ios UserDefaults used by react-native react-native-console-time-polyfill 45 - console.time and console.timeEnd polyfill for react-native react-native-aws-signature 42 - help generate signature required for using AWS API. Necessary to use S3, ec2, or other services. react-native-rsa 41 - RSA crypto lib for react native react-native-html-parser 38 - parse html in react-native pixels-catcher 26 - Library for testing React Native UI components and screens react-native-aes 24 - AES in react-native react-native-network-logger 20 - An HTTP network request monitor for React Native including an in-app interface. eslint-config-kingstinct-react-native 23 - Opinionated ESLint configurarition for React Native and TypeScript react-native-hour-format 20 - Get hour format from OS settings. react-native-des 20 - A des crypto for react-native react-native-babel-jest 15 - Simple testing configuration for React Native with Jest react-native-simple-encryption 14 - Simple XOR and base_64 encryption decryption for react-native react-native-immutable 12 - using immutable.js library with react-native react-native-util 12 - A fork of io.js's util module that works with React Native react-native-referrer 11 - React Native android only library to retrieve campaign referrer. react-native-webpackager-server 6 - react native webpackager server react-native-crypto 6 - implementation of crypto for React Native react-native-fluxbone 5 - A group of libraries that help with the FluxBone pattern in React Native react-native-cross-settings 5 - React Native Settings module for both Android & iOS. react-native-HsvToRgb 3 - a helper to convert HSV(HSB) color to RGB. react-native-use-persist-storage 3 - Persist and rehydrate your context(state) using React Hooks react-native-tools 0 - Tools for react native project development react-native-call-observer - Helps to observe call status like incoming, ended, and connected (iOS). react-native-iphone-se-helper 0 - utils for developing iphone SE size. react-native-native-log 0 - A React Native log function that under the hood calls native logs. react-native-mov-to-mp4 44 - utils for Converting mov file to mp4 for cross-platform playback compatibility. react-native-test-runner 1 - Run unit and integration tests in React Native's environment. Forms formik 10633 - Forms in React, without tears. react-hook-form 9346 - React hooks for forms validation without the hassle. redux-form 4829 - Redux form state management (Web and Native) redux-hook-form 2700 - React hooks for form validation without the hassle. (Web and Native) tcomb-form-native 2831 - Generate React Native forms react-native-gifted-form 1317 - Form component for react-native react-native-clean-form 414 - Good looking form elements with redux-form integration. Stylable with styled-components. react-native-form-generator 354 - Generate amazing React Native forms in a breeze react-native-form 138 - A simple react-native component to wrap your form fields! react-reactive-forms 106 - Angular like reactive forms in React. react-native-forms 86 - A declarative API for creating, validating, and serializing native-looking forms. react-native-formawesome - Complex and simple forms builder. react-native-from-builder 69 - Handle your forms in a smart way. foect 37 - Simple form validation library for React Native react-native-fm-form 13 - Generate list view form of React Native in few line of codes react-native-form-flux 2 - React Native Form management using Flux architecture react-native-form-validator 0 - A simple validation library for react native Geolocation react-native-background-geolocation 1316 - Sophisticated cross-platform background location-tracking & geofencing module with battery-conscious motion-detection intelligence (Android requires paid license). react-native-mauron85-background-geolocation 657 - React Native Android and iOS module for background and foreground geolocation with battery-saving "circular region monitoring" and "stop detection" react-native-geocoder 344 - react native geocoding and reverse geocoding react-native-geo-fencing 100 - Native modules to determine if a location is within defined geographical boundaries using Google Geometry library react-native-fused-location 82 - Finest location for react-native on Android using the new Fused API. react-native-android-geolocation 19 - React Native Module to use Android Geolocation via Google Play API react-native-reverse-geo 18 - React Native module bridge to convert address to geo coordinates. react-native-boundary 12 - React Native module to use geofences. Native implementation for iOS and Android. react-native-geolocation-android 3 - Geolocation module for react native android Internationalization fbt 3202 - A JavaScript Internationalization Framework react-native-localize 603 - React Native Localize react-native-globalize 192 - Globalization helper for React Native redux-react-native-i18n 40 - An i18n solution for React Native apps on Redux react-native-intl 37 - React Native module shipped native Intl implementation and Translation extension rn-translate-template 18 - I18n template for all iOS and Android supported languages ~~react-native-i18n 1778 - React Native + i18n.js~~ Deprecated for react-native-localize ~~react-native-languages 246 - React Native properties and methods related to the language of the device~~ Now called react-native-localize Build & Development reactotron 9198 - Control, monitor, and instrument your React Native apps from the comfort of your terminal. react-native-code-push 5184 - React Native plugin for the CodePush service react-native-webpack-server 935 - Build React Native apps with Webpack generator-rn-toolbox 800 - Yeoman generators to kickstart your project and setup continuous deployment. babel-preset-react-native-stage-0 97 - a Babel preset with latest Javascript goodies react-native-debug-stylesheet 75 - Add coloured borders or backgrounds to all views to make it easier to debug layout issues react-native-console-panel 73 - react native component for display console messages. react-native-css-loader 39 - You can use react-native-css-loader with react-native-webpack-server, which can use webpack to built react-native app better. react-native-assets 31 - Module to manage assets. It allows you download assets from a network and store into a specific local folder on iOS react-native-cosmos 18 - DX tool to test react-native components with defined props/state fixtures. react-native-kill-packager 15 - kill running react native packager. react-native-build-cli 3 - a cli tool for react-native build react-native-react-bridge - A toolset to run React web app in React Native and handle communication between them. Styling styled-components 20064 - Style React and React Native with utilising tagged template literals. emotion 5627 - Style as a function of state. react-native-extended-stylesheet 1689 - Extend React Native stylesheet with variables, relative units, percents, math operations, scaling and other stuff. react-native-css 755 - Style React-Native components with css and built in support for SASS. react-native-style-tachyons 525 - functional, maintainable design for everyone based on tachyons.css. glamorous-native 454 - A React Native version of glamorous - a component styling library. react-native-responsive 295 - The power of Media Queries now in your React Native project (ios and android) ! Responsive Design can now be easily managed ! cairn 110 - Simple, string-based style selector engine with support for basic inheritance. react-native-theme 104 - Theme manager for react native project! react-native-css-modules 44 - Style React-Native components using CSS, Sass, Less or Stylus. rn-less 15 - Style react-native with less (with VS Code extension support) react-native-prism 10 - Minimal, idiomatic style management for React Native react-native-paint 5 - A themeable abstraction over React Native StyleSheet. Read about it here. binstorm 5 - BinStorm is a React Native styling utility for rapidly building custom user interfaces. Read about it here. styled-react-native - Advanced react native styling with simple method (style overwrites, component composition, enhanced style property). Full intro in this Medium article. react-native-tailwindcss - A react native styling system based on TailwindCSS. System react-native-firebase 4192 - A well tested feature rich Firebase implementation for React Native, supporting both iOS & Android platforms for 10+ Firebase modules (including Cloud Firestore). react-native-push-notification 3431 - React Native Local and Remote Notifications react-native-device-info 3145 - Get device information using react-native react-native-fs 2465 - Native filesystem access for react-native react-native-config 1894 - Config variables for React Native apps react-native-ultimate-config - Configure all levels of your react-native app with a single file react-native-fcm 1564 - react native module for firebase cloud messaging and local notification react-native-notifications 1396 - React native notifications react-native-arkit 1290 - React Native binding for iOS ARKit react-native-permissions 1118 - Check and request all permissions with a single api react-native-keychain 992 - Keychain Access for React Native react-native-touch-id 902 - React Native authentication with the native Touch ID popup. react-native-contacts 882 - React Native Contacts (android & ios) react-native-communications 871 - Easily call, email, text or iMessage someone in React Native react-native-onesignal 871 - React Native Library for OneSignal Push Notifications Service (iOS + Android) react-native-in-app-utils 743 - A react-native wrapper for handling in-app payments. react-native-image-resizer 636 - Rescale local image files with React Native. react-native-quick-actions 593 - A react-native interface for 3D Touch home screen quick actions react-native-billing 534 - In-app purchase implementation for React Native on Android. react-native-barcodescanner 491 - A barcode scanner component for react native - not maintained anymore - use react-native-camera. react-native-iap 450 - React-native native module for In-App Purchase. react-native-dotenv 450 - A Babel preset let you import application configs from .env file (zero runtime dependency) react-native-location 425 - Native GPS location support for React Native. react-native-background-fetch 373 - iOS BackgroundFetch API implementation. Awakens a suspended iOS app in the background to execute a callbackFn about every 15 min. react-native-queue 359 - Your swiss army knife for task management in React Native - easily manage background tasks that run periodically when app is closed and dedicated worker threads. react-native-sensors 355 - Platform independent wrapper for sensors like Gyroscope, Accelerometer and Magnetometer with RxJS interface react-native-social-share 347 - Use the iOS native Twitter and Facebook share view from react native react-native-ibeacon 334 - iBeacon support for React Native. The API is very similar to the CoreLocation Objective-C one with the only major difference that regions are plain JavaScript objects. Beacons don't work in the iOS simulator. react-native-lock-ios 291 - Auth0 Lock for React Native (iOS) react-native-motion-manager 223 - A react-native interface for using the Gyroscope, Accelerometer and Magnetometer react-native-android-sms-listener 194 - Allows you to listen for incoming SMS messages react-native-device 185 - UIDevice wrapper for React Native react-native-gcm-android 174 - GCM for Android react-native-sensor-manager 172 - Wrapper for react-native providing native sensors access. (Gyroscope, accelerometer, magnetometer, thermometer...) react-native-ble 157 - React Native BLE using noble api surface react-native-haptic 137 - iOS 10 + haptic feedback for React Native applications react-native-pinch 130 - SSL pinning for react native react-native-unified-contacts 120 - React Native iOS 9+ Contacts (ios) react-native-callkit 94 - iOS 10 CallKit framework for React Native react-native-discovery 89 - Discover nearby devics using BLE. Turn iOS and Android devices into beacons react-native-passcode-auth 87 - React Native authentication with iOS Passcode. react-native-addressbook 81 - AddressBook module for react-native react-native-fingerprint-identify 79 - React Native authentication with the Fingerprint on Android, fingerprint API compatible lib, which also combines Samsung, Xiaomi and MeiZu's official Fingerprint API. react-native-phone-call 76 - A simple way to initiate a phone call in React Native react-native-calendar-reminders 69 - React Native module for IOS EventKit Reminders react-native-bluetooth-state 61 - Answering the question of "Is my bluetooth on?" in React Native react-native-google-nearby-messages 14 - Communicate with nearby devices using Bluetooth, BLE, WiFi and near-ultrasonic audio by using the Google Nearby Messages API react-native-barcode-scanner 60 - Barcode scanner for React Native react-native-haptic-feedback 60 - Trigger Haptic Native Feedback on iOS and Android react-native-clipboard 58 - React Native component for getting or setting clipboard content react-native-media-clipboard - React Native module for getting images, URLs, and strings from the clipboard react-native-nfc-ios 52 - Easy to use CoreNFC for React Native react-native-android-sms 48 - A react native android module to list/send sms. react-native-voip-push-notification 48 - iOS prioritized VoIP Push Notification react-native-android-speech 47 - A text-to-speech library for Android React Native. react-native-app-info 42 - React Native app info and version react-native-icloud-sync 41 - A react-native wrapper for syncing with icloud react-native-carrier-info 41 - React Native module bridge to obtain information about the users home cellular service provider. react-native-sms-android 40 - A react-native module for sending a sms message to a phone number. react-native-touch-id-android 32 - React Native authentication with the Fingerprint on Android. react-native-heading 31 - Get device heading (compass) information on iOS or Android react-native-battery 30 - A React Native module that returns the battery level/status of a device react-native-device-battery 30 - Observe battery state changes in your react native application react-native-device-motion 29 - iOS device motion wrapper for React Native. react-native-wifi-manager 29 - Wifi Connection Manager for React Native on Android react-native-android-sqlite 28 - A react native android wrapper for SQLite react-native-search-api 27 - The SearchApi module gives you a general React Native interface to interact with the iOS Search API, Core Spotlight. react-native-ssl-pinning 20 - React Native SSL pinning using OkHttp 3 on Android, and AFNetworking on iOS react-native-localsearch 17 - React Native Module for MapKit Local Search rn-secure-storage 17 - Secure Storage for React Native (Android & iOS) react-native-contacts-rx 14 - react-native-contacts counterpart that include the support of RxJS. react-native-mipush 13 - MiPush for React Native react-native-device-angles 12 - Get rotation information in degrees (pitch, yaw, roll) - ios react-native-detect-device 11 - Detect a device on iOS or android in react-native. react-native-battery-status 11 - A battery-status for react-native react-native-system-notification 10 - Notification for React Native react-native-home-pressed 8 - Listen to home and recent app events for Android react-native-lock-android 7 - Auth0 Lock for React Native (Android) react-native-push-with-gcm 6 - Register device for GCM push notifications services (supported only for iOS) react-native-device-info-pod 3 - Get device information using react-native react-native-sms-retriever - SMS Retriever API (Android). react-native-background-downloader 93 - Help you download large files on iOS and Android both in the foreground and most importantly in the background. rn-in-app-review - Help you to integrate in-app review for android and iOS react-native-system-setting- Provides some system setting APIs iOS and Android. Web react-native-webrtc 1805 - A WebRTC module for React Native. react-native-webview-bridge 1112 - React Native WebView Javascript Bridge react-native-safari-view 387 - A React Native wrapper for Safari View Controller react-native-webview-android 305 - Simple React Native Android module to use Android's WebView inside your app react-native-for-web 247 - A set of classes and react components to make work your react-native app in a browser. (with some limitations obviously) react-native-browser 107 - Full-featured web browser module for React Native apps, based on TOWebViewController react-native-webview-crosswalk 88 - Crosswalk's WebView for React Native on Android react-native-turbolinks 72 - React Native adapter for building hybrid apps with Turbolinks 5 react-native-webintent 53 - React native android module to open links in the default browser react-native-web-container 36 - A wrapper around the react native WebView to add autoHeight, scrub html, etc react-native-inappbrowser-reborn 30 - InAppBrowser for React Native (Android & iOS) react-native-browser-polyfill 29 - A collection of polyfills for the react-native Javascript environment. react-native-cookiemanager 19 - react-native cookie manager library. react-native-bridgeable-webview 16 - A react-native webview with bridge to react-native code react-native-html2native 3 - A html render for react-native react-native-webview 3 - android webview for react-native Media react-native-camera 6227 - Camera component react-native-video 3470 - A Video component for react-native react-native-sound 1556 - React Native module for playing sound clips react-native-audio 798 - Record and play back audio in your iOS or Android React Native apps. (no longer maintained) react-native-audio-toolkit 764 - Audio playback and recording for react-native. In addition to basic functionality, many useful features are implemented such as seeking, looping and streaming audio files over the network. react-native-camera-kit 701 - Advanced native camera and gallery components and device photos API. react-native-audio-streaming 679 - iOS & Android module to play an audio stream, with background support and media controls :speaker: react-native-video-processing 712 - Native Video editing/trimming/filtering library for React-Native react-native-track-player 441 - A fully fledged audio module created for music apps. Provides audio playback, external media controls, chromecast support and background mode for Android, iOS and Windows. react-native-music-control - React Native module to display Now playing Info on lockscreen and handle control events react-native-camera-roll-picker 312 - A React Native component providing images selection from camera roll react-native-incall-manager 272 - Handling media-routes/sensors/events during a audio/video chat like webrtc react-native-speech 246 - A text-to-speech library for React Native. react-native-screcorder 214 - Capture pictures and record Video with Vine-like tap to record react-native-photos-framework 154 - A modern and comprehensive CameraRoll/iCloud-library for React Native react-native-audioplayer 99 - Small audio player library for react native react-native-player 81 - Media player for react-native react-native-vlc-player 80 - VLC Player for react-native react-native-volume-slider 69 - React Native VolumeView component react-native-sound-demo 63 - react-native-sound demo project react-native-interactive-image-gallery 60 - A React Native component to display a gallery of images. react-native-color-grabber 57 - React native component for finding dominant colors in an image react-native-hue-player 43 - Audio Player to offline/local and online/streaming audio. react-native-media-meta 41 - Get media file metadata in your React Native app react-native-sound-recorder 41 - No-hassle Sound Recorder for React Native. react-native-fullscreen-video 39 - A full-screen video component on top of react-native-video react-native-android-audio-streaming-aac 25 - A react native streaming player react-native-photoeditorsdk 24 - React Native module for PhotoEditor SDK (Android & iOS) react-native-videoeditorsdk 18 - React Native module for VideoEditor SDK (Android & iOS) react-native-true-sight 18 - A cross-platform video player with customizable controls for React Native. react-native-audio-manager 15 - Audio player library for react native Android react-native-safe-image 13 - Really light React-Native package to handle fallback when image is on error react-native-audio-player 12 - A React Native module to play audio on Android react-native-mediaplayer 12 - Simple full screen media player for React Native. react-native-simple-sound 11 - Start, stop, and pause a sound. iOS only. Derived from react-native-sound react-native-tone 7 - Generates simple sine wave, specify a frequency and amplitude. Play sound indefinitely or for a specified time interval (iOS only). react-native-media-capture 6 - A media-capture for react-native react-native-android-video 8 - Android ExoPlayer Video component for react-native. react-native-airplay-button - Native iOS Airplay button component Storage RxDB 12797 - A realtime Database for JavaScript Applications. WatermelonDB 4649 - Next-gen database for powerful React and React Native apps that scales to 10,000s of records and remains fast. realm 3184 - An alternative mobile database to SQLite & key-value stores. react-native-storage 2115 - This is a local storage wrapper for both react-native(AsyncStorage) and browser(localStorage). ES6/babel is needed. react-native-sqlite-storage 1508 - SQLite3 bindings for React Native (Android & iOS) react-native-simple-store 731 - A minimalistic wrapper around React Native's AsyncStorage. react-native-store 561 - A simple database base on react-native AsyncStorage. react-native-db-models 168 - Local DB Models for React Native Apps react-native-sqlite-2 106 - SQLite3 Native Plugin for React Native for both Android and iOS react-native-couchbase-lite 105 - couchbase lite binding for react-native react-native-persistent-job 72 - Run async tasks that retry after a crash, connection loss or exception pouchdb-adapter-react-native-sqlite 49 - PouchDB adapter using ReactNative SQLite as its backing store react-native-pouchdb 38 - Run pouchdb in React Native! react-native-level-fs 20 - fs for react-native using level-filesystem and asyncstorage-down react-native-mongoose 17 - A AsyncStorage based mongoose like storage for react-native react-native-leveldown - Native LevelDB bindings for React Native typed-async-storage - A wrapper for creating a schema for AsyncStorage and validation using React prop-types. Backend react-native-fetch-blob 2299 - A module integrates network and file system. Supports file stream. reactivesearch-native 1218 - appbase.io and Elasticsearch UI components for React Native. react-native-meteor 673 - Full Meteor Client aws-sdk-react-native 650 - AWS SDK for React Native (Official developer preview) react-native-simple-auth 592 - Native social authentication for React Native on iOS react-native-uploader 455 - A React Native module to upload files and camera roll assets. Supports progress notification. react-native-lazyload 342 - lazyload for react native react-native-aws3 293 - Pure JavaScript React Native library for uploading to AWS S3 react-native-background-upload 270 - Upload files in your React Native app even while it's backgrounded. Supports Android and iOS, including iOS Camera Roll assets. react-native-xmpp 256 - XMPP Library for React Native react-native-tcp 199 - node's net API for react-native react-native-udp 147 - node's dgram API for react-native react-native-aws-cognito-js 131 - An adaptation of Amazon Cognito Identity SDK for JavaScript in combination with AWS SDK for JavaScript for React Native. feathers-client 121 - Feathers client that works with React Native, NodeJS and any client framework. react-native-multipeer 117 - Communicate over ad hoc wifi using Multipeer Connectivity react-native-swift-socketio 105 - A react native wrapper for socket.io-client-swift react-native-file-upload 103 - A file upload plugin for react-native react-native-networking 99 - react-native module to download and upload files with AFNetworking react-native-s3 80 - A React Native wrapper for AWS iOS/Android S3 SDK (TransferUtility) react-native-rest-kit 65 - A React Native RESTful API kit that use the fetch method react-native-cognito 63 - AWS Cognito-based authentication module for React Native. react-native-file-download 45 - A simple file download module for react-native react-native-jwt 37 - React native compatible JSON web token utility react-native-sync 28 - Two way, incremental sync between React Native realmjs database and MySQL, Oracle, MS SQL Server and PostgreSQL react-native-ssdp 26 - A React Native fork of the SSDP protocol to discover plug and play devices. react-native-http 13 - React native http react-native-async-http 5 - React Native component for async-http react-native-nchan 3 - Nchan (pub/sub server) module for React Native react-native-blob-courier 8 - Efficiently download and upload blobs on native thread fetch 10 - A fetch API polyfill for React Native with text streaming support. Integrations react-native-wechat 2016 - react-native library for wechat app react-native-facebook-login 1141 - React Native wrapper for native iOS Facebook SDK login button and manager react-native-google-signin 1123 - Google Signin for your react native applications react-native-google-places-autocomplete 846 - Customizable Google Places autocomplete component for iOS and Android React-Native apps react-instantsearch 644 - Lightning-fast search for React and React Native apps, by Algolia react-native-awesome-card-io 331 - A complete and cross-platform card.io component for React Native (iOS and Android) react-native-qq 278 - QQ Login&Share support in React Native. react-native-facebook-account-kit 227 - A Facebook Account Kit SDK wrapper for React Native. react-native-wechat-ios 199 - Wechat SDK for React Native(iOS). react-native-card-io 171 - React Native component for card.io react-native-voximplant 126 - VoxImplant Mobile SDK for embedding voice and video communication into React Native apps. instabug-reactnative 122 - A React Native wrapper for Bug reporting Instabug SDK. react-native-fabric-digits 112 Fabric Digits wrapper for React-Native react-native-braintree 104 - A react native interface for integrating payments using Braintree's v.zero SDK (currently iOS only) react-native-dialogflow 104 - A React-Native bridge for Google's Dialogflow (api.ai) react-native-signalr 100 - SignalR-client for react-native react-native-twilio 87 - A React Native wrapper for the Twilio Client SDK. react-native-twilio-programmable-voice 86 - A React Native wrapper for the Twilio Programmable Voice SDK. react-native-qqsdk 83 - A React Native wrapper around the Tencent QQ SDK for Android and iOS. Provides access to QQ ssoLogin, QQ Sharing, QQ Zone Sharing etc. react-native-braintree-xplat 81 - Cross-platform Braintree v.zero module. react-native-android-vitamio 72 - React-native component for android Vitamio video player react-native-linkedin-login 69 - Linkedin Login for your react native applications react-native-twitter-signin 140 - Login for your react native applications with client Twitter account react-native-spring-scrollview 64 - React Native Spring ScrollView V2 is a high performance cross-platform native bounces ScrollView for React Native.(iOS & Android) react-native-instagram-oauth 63 - react-native instagram login react-native-digits 60 - Digits wrapper to use in React Native react-native-realtimemessaging-android 53 - The Realtime Framework Cloud Messaging Pub/Sub client for React-Native Android react-native-new-relic 53 - New Relic event reporting for react-native. react-native-onepassword 52 - React Native integration with the OnePassword extension. react-native-level 38 - levelup API for react-native AsyncStorage. react-native-instagram-share 28 - A react-native interface to share images and videos within instagram (iOS) react-native-braintree-android 24 - Braintree's native Drop-in Payment UI for Android react-native-amap 21 - A React Native component for building maps with the AMap Android SDK react-native-realtime-pusher 19 - React Native module implementing the Pusher Realtime API react-native-conekta 17 - Conekta SDK for React Native react-native-fitness 17 - A React Native module to interact with Apple Healthkit and Google Fit react-native-woopra 14 - Promise based Woopra library for react-native react-native-sinch-verification 14 - Sinch verification for react native react-native-testfairy 13 - TestFairy for React Native react-native-leancloud 10 - a react native LeanCloud component react-native-flurry 9 - React Native wrapper for Flurry react-native-realtimemessaging-ios 8 - The Realtime Framework Cloud Messaging Pub/Sub client for React-Native react-native-realtimestorage-ios 8 - The Realtime Framework Cloud Storage client for React-Native react-native-axmall-alipay 7 - react-native alipay react-native-youtube-oauth 7 - react-native interface to login to youtube (iOS) react-native-intercom-native 7 - native based Intercom implementation for React Native react-native-hawk 5 - Hawk wrapper for react-native react-native-sumup 5 - A React Native implementation of SumupSDK. react-native-instagram 5 - react-native instagram wrapper api (iOS) react-native-realtimestorage-android 4 - The Realtime Cloud Storage client for React-Native Android react-native-fbintent 4 - A React Native intent for Android Facebook App react-native-onfido 2 - A React Native wrapper for the Onfido Library. react-native-heyzap- Heyzap plugin for React Native react-native-launch-navigator - React Native module to launch popular navigation/ride apps from a single API (Android & iOS) react-native-agora +190 - A React Native Agora WebRTC Wrapper. agora-react-native-rtm +5 - A React Native Agora RealTime-Message Cloud Service Wrapper. react-native-intercom *323 - A React Native Intercom Wrapper. react-native-bugfender *7 - A React Native wrapper for Bugfender log and error reporting. Monetization react-native-admob 713 - A react-native component for Google AdMob banners. react-native-stripe-api 155 - A small React Native library for Stripe Rest API react-native-revmob 15 - RevMob wrapper for React Native. react-native-google-pay 2 - Accept Payments with Google Pay for React Native apps. react-native-apay 2 - React Native bridge for Apple Pay react-native-square-in-app-payments 18 - Square React Native plugin for In-App Payments SDK. Animation react-native-animatable 5787 - Standard set of easy to use animations and declarative transitions for React Native react-native-interactable 4148 - experimental implementation of high performance interactable views in React Native react-native-reanimated 680 - React Native's Animated library reimplemented react-native-spruce 412 - React Native Bridge for Spruce Animation Library react-native-magic-move 402 - Create magical move transitions between scenes in react-native (shared element transitions) react-native-gl-model-view 210 - Display and animate textured Wavefront .OBJ 3D models with 60fps (iOS) react-native-animated-sprite 104 - A feature rich declarative component for animation, tweening, and dragging sprites. react-native-animated-math 54 - An Animated API math extension - implements sin, cos, tan and pow as Animated Nodes with full Native Driver support Extension React Native Today Widget 190 - iOS Today Widget Extension in React Native React Native Android Widget Proof of Concept 127 - Android Widget Proof of Concept in React Native React Native Floating Bubble 14 - A simple Facebook Chat Head like bubble for react native React Native WidgetKit - React Native Library for the iOS WidgetKit Framework Other Platforms react-native-web 10904 - React Native for Web react-native-macos 10453 - React Native for OS X reactxp 7268 - Library for cross-platform app development react-native-windows 5547 - React Native for Universal Windows Platform @areslabs/alita 392 - react native for mini-program() react-native-tvos-controller 15 - TvOS remote controller module for react native. react-native-watchkit 1 - react native for WatchKit Utilities Useful React Native tooling. upgrade-helper 398 - A web interface to support React Native developers in upgrading their apps. Link to tool react-native-debugger 4017 - The standalone app for React Native Debugger, with React DevTools / Redux DevTools haul 2711 - command line tool for developing React Native apps rnpm 2408 - react native package manager generact 1125 - CLI that generates components based on existing ones no matter how you structure your app react-native-rename 901 - Rename react-native app with just one command react-native-exception-handler 504 Avoid silent crash and errors on the production build of your app Electrode Native 439 - A platform to ease the integration of React Native components in existing mobile applications. Ruby React Native (via Opal) 391 - Use Ruby for building React Native apps rn-snoopy 329 - Profiling, monitoring and alerting over the React Native bridge. More here. react-native-snippets 249 - A collection of Sublime Text Snippets for react-native react-native-bundle-visualizer 141 - See what's inside your RN bundle; useful for optimizing the bundle size Makeicon 70 - Generates mobile app icons in all resolutions for both iOS and Android AsyncStorage Dev Menu Item 67 - Adds an option to your dev menu to log the content of your AsyncStorage. rn-diff-purge 64 - The easiest way to upgrade React Native versions. You can find diffs for every React Native version, that are created by diffing the previous version with a newly created app in the new version. React Native Actions 55 - Run React Native actions from within VSCode. rsx 29 - An alternative to the react-native CLI tool ADB Auto Restarter 8 - Restart ADB service Automatically in case of crashing while debugging app with device . rn-nodeify 6 - hack to allow react-native projects to use node core modules react-native-ruler 3 - A devtool for measuring pixel dimensions on your React Native screens BuilderX - A design tool which writes React Native code for you , Desktop Mac app to replace your traditional UX design tools. CodePush - Push code updates to your apps, instantly Storybook - UI development environment for your React components BugSnag - A tool that logs native & JS errors. Has a free tier. Includes useful data about the user, environment, session, release, etc. React Native Playground - Run React Native apps in your browser via real time simulator exponent - Use React Native without XCode (a previewer app + local server infrastructure) Deco IDE - React Native IDE with components manager react-hook-hooker - A nifty little HOC to add hooks to your React components. React Native Elements Playground - Tinker with react-native-elements components in the web. SimpleLocalize CLI - An open source Localization CLI tool for finding i18n keys in project files. Seeds Get a head start on development with an existing seed. Ignite 8832 - An unfair start for React Native - Generator CLI for redux/sagas and more. Pepperoni 4383 - (deprecated) Starter kit for Android & iOS, Redux, Immutable.js, disk-persisted app state Snowflake 4321 - Android & iOS, Redux, Jest (88% coverage), Immutable, Parse.com native-starter-kit 1506 - A Starter Kit for React Native + NativeBase + React Navigation + Redux + CodePush Apps (iOS & Android) React Native Hackathon Starter 732 - React Native Starter Project, great for hackathons or rapid prototyping. Includes tabs, navigation, Redux, React Native Vector Icons, & React Native Elements React Native Boilerplate Typescript - React Native Boilerplate - Redux + Saga + Reselect + redux-persist + react-navigation + TypeScript React Native Meteor Boilerplate 615 :octopus: React Native Boilerplate 551 - React Native boilerplate that promotes a solid architecture via separation of concerns. React Native Seed 504 - A set of React Native Boilerplates to choose from. MobX or Redux for state-management, TypeScript or Flow for static type checking and CRNA or plain React Native for the stack - By the creators of Native Base. React Native Starter 388 - A powerful starter template that bootstraps development of your mobile application. ReactNativeTS 353 - Boilerplate of a React Native project in Typescript. react-native-starter by Ueno 311 - Professional react-native starter kit with everything you'll ever need to deploy rock solid apps react-native-babel 241 react-native-vanilla 185 - Build universal cross-platform apps with React Native. Includes latest iOS, tvOS, Android, Android TV, Android Wear, Web, Tizen TV, Tizen Watch, LG webOS, macOS/OSX, Windows and KaiOS platforms react-native-template-typescript 183 - Clean and minimalist React Native template for a quick start with TypeScript. react-native-template-airbnb - Clean and minimalist React Native template for a quick start with Airbnb (Flow, Prettier). react-native-redux 160 - React Native + Redux + Redux Saga react-native-es6-reflux 145 react-native-hot-redux-starter 135 react-native-typescript-boilerplate 129 - An opinionated boilerplate built with React Native Navigation v3 + Redux + Thunk, in TypeScript. Follows industry best practices. Rhinos-app 81 - Cross-platform React Native boilerplate (iOS, Android, Web) built on react-native-web. react-native-web-boilerplate 72 - A react-native-web stateless hmr boilerplate react-native-boilerplate 61 - Simple boilerplate for mobile development using React Native and Redux react-native-easy-starter 50 - A React-native starter kit using latest react and react-native 0.60.5, easy-peasy state management, hooks workflow, hermes, codepush ready-to-use custom hooks, react-native-paper, contextapis, theming support and much more (android + ios) react-native-web-workspace 58 - A cross platform app with react in a monorepo Baker 46 - An opinionated MVP toolkit that helps you build mobile apps crazy fast using React Native and Parse Server React-Native-Starter-Pack 40 - React Native 0.34 + React-Redux (w/ Redux-Storage) + Native Base + Code Push react-native-relay-example 38 - React Native working with Relay MeteorNative Boilerplate 23 - a React Native and Meteor boilerplate with Redux. rn-mobx-template 17 - React Native with MobX template react-native-boilerplate-chucknorris 15 - A boilerplate for React Native + React Navigation + React Native Elements (iOS & Android) react-native-template-super 7 - A turbo starter template for react-native + React Navigation + Redux + Redux Persist rn-relay-drawer-template 4 - React Native working with RNRF, drawer and relay react-native-community-maps 3 - Boilerplate app for browsing user-generated photos on a map React Native Starter Kit - React Native starter kit with user onboarding elements, including Firebase Auth and Facebook Login integration. Awesome React Native Boilerplates - Effective start for your development with the most popular react-native navigation and UI libraries react-int - A simple way to use react/react-native with redux and redux-saga. RNStarter - A React Native Starter with 10+ commonly used libraries Libraries Libraries / SDK type additions for React Native development. React Native Elements 13599 - a collection of React Native UI Elements and components. Shoutem UI 3802 - a complete UI toolkit for React Native from Shoutem. Panza 243 - a collection of stateless, functional, cross-platform ui components for react-native. BlankApp UI 78 - Highly customizable and theming components for React Native. react-native-easy-app 220 - React Native one-stop solution. React Native Common 49 - UI & API Components Library for React Native. react-native-colibri 5 - React Native Generic UI Components. Statek 3 - Simple & Reactive state management library for React & React Native Open Source Apps Open source React Native apps and other examples. Artsy - The mobile app for artsy.net. Discover fine Art. The Art world in your Pocket. f8app 13070 - Official F8 (Facebook Developer Conference) app of 2017. See blog post. 30-days-of-react-native 5192 - 30 days of React Native examples (inspired by 30DaysofSwift) react-native-nw-react-calculator 4624 - A mobile, desktop and website App with the same code GitPoint 3833 - A mobile GitHub client for both iOS and Android. Hacker News (iOS & Android) 3460 reading 2947 - Reading App Write In React-Native. Status.im 2470 - Ethereum client. GitHub Popular 2452 - This is a GitHub most popular repositories viewer with React Native. Dribbble React Native 1927 react-native-gitfeed 1709 - Yet another Github client written with react-native(iOS & android) Finance React Native 1680 - iOS's stocks app clone written in React Native for demo purpose. Quirk 965 - Cognitive Behavioral Therapy for iOS and Android. TaskRabbit's Sample App 802 - a testing ground for Task Rabbit's app making React Weather 702 - A simple weather app built with React Native Boostnote 630 - Boostnote: open source note taking. react-native-sudoku 540 - a sudoku game written in React Native react-native-hiapp 513 - A simple and Twitter like demo app written in react-native React Native Netflix 489 - A Netflix-like app. what the thing? 430 - Point camera at things to learn how to say them in a different language. react-native-basketball 425 - a clone of the Facebook Basketball game Surmon.me.native 406 A react-native applaction for surmon.me An example React Native project for client login authentication 402 GitterMobile 387 - Gitter (chat for github) client for iOS and Android ReactNativeRedditReader 345 Assemblies 322 - a Meetup clone DuckDuckGo App (Unofficial) 273 Ziliun React Native 266 - Wordpress based article reader built with react native Luno 266 - A ClojureScript React Native app demonstration ReactNativeHackerNews 241 iOS Conference App made with React Native 234 MagicMirror 232 Redux Demo 226 - Minimal implement of redux counter example on ReactNative iOS and Android React Native Embedded App 218 -A collection of examples for using React Native in an existing iOS application React Native Example, Geo and Location 216 uestc-bbs-react-native 216 - An iOS client for http://bbs.uestc.edu.cn/ written in React Native with Redux Sh**t! I Smoke 209 - Know how many cigarettes you smoke based on the pollution of your location. PxView 198 - An unofficial Pixiv app client for Android and iOS BBC News (Unofficial) 187 - a BBC news app HackerBuzz 179 - a Hacker News reader. Vecihi App 170 Build your own photo sharing app. Rocket.Chat 161 - Open Source Team Communication HackerWeb 158 - A simply readable Hacker News web app for iOS & Android. Buyscreen sample 151 NewsWatch video viewer 150 YouTrack Mobile 136 a client for YouTrack issue tracker from JetBrains. ndash 129 - npm dashboard. Look Lock 126 - An app for showing photos without worries. Kakapo - ambient sound mixer 126 Appointments 116 - Full-fledged ReactNative App for Booking Appointments Alt/Flux Demo 106 Buttercup Mobile 103 - Mobile password manager Insta Snap 102 - Image Sharing App live translator 94 - An app that translates in real time what you see from your mobile. Finance MacOS React Native 88 - iOS's Stocks App clone written for MacOS with Touch Bar support. Data is pulled from Yahoo Finance. NBAreact 88 Urban Dictionary 83 - Mobile implementation of the popular Urban Dictionary website. ASOS 83 - E-commerce app for ASOS (clone) Reddit made with React Native and Redux 81 react-native-redux-facebook 79 - A simple React Redux Facebook authentication demo app. Hekla for Hacker News 77 - Hackernews client with TypeScript, mobx-state-tree, native navigation and css modules. QRCode App 74 - application for scanning and generating QR codes. Nearby Live 72 - An unofficial NearbyLive app for Android and iOS SoundcloudMboX 67 SoundcloudMobX is the Soundcloud for iOS, Build with React-Native and MobX. Native iOS font list 60 React Native Chromecast App 56 MoeFM 54 - A light MusicPlayer build with React Native & Redux for both Android and iOS. iTunesConnect 53 - Unofficial iTunes Connect App Sequent 52 - short-term memory training game (W/ Redux). AudienceNetworkReactNative 50 - Facebook Audience Network Performance Tool. rndrawer-implemented-rnrouter 50 - A react-native-drawer implemented example and scaffolding for react-native-router-flux Magento 2 Mobile App 47 - Magento 2.x mobile app built with React Native iOS app that transcript your voice with IBM Watson Cloud 41 Splitcloud 35 - Share listening to two songs at the same time from Soundcloud (by splitting right/left channels). ZudVPN 32 - Deploy private VPN on major Cloud Providers with ZudVPN Todo List 31 - Todo-List app using SwipeView with ES6 standards for iOS and Android. Paramap 30 - Accessability map. React-native with Redux and Firebase. iOS and Android. Confreaks 29 Vocab React Native 27 - Thai Vocabulary Learning App Premier League 25 Roxie 23 - Sound processing and bluetooth hardware control. Roverz 21 - A native mobile chat client library for Rocket.Chat on both iOS and Android. Text Blast 18 - iOS client for MMS text blasting app with analogous ionic version for comparison NewYorkTimesTopStories 14 - Read Topstories of NewYorkTimes using its api written for android in react-native. Quick-Sample 14 - A small and simple example app with navigation, data persistence, redux, listview and animation. iGap Plus 13 - iGap+ is a cross-platform messaging application (Currently Android , iOS and Windows UWP) and has been created using all latest modern technologies. iGap+ is designed to easily support additional platforms like web, macOS and linux. Posters_Galore_Android 11 - An experimental Android application using Redux and a REST API react-native-medium-clap-animation 11 - Medium Clap Animation in React Native HupuApp 9 - A Third-party Hupu App (http://bbs.hupu.com/) client implemented using React Native (Android and iOS). react-native-uber-clone 9 - Uber UI Clone with animations in react native Commit Strip (Unofficial) 8 - A CommitStrip.com reader built in React Native. react-native-otello 6 - a reversi game written in React Native GitHub Jobs Search App (Unofficial) 6 - A GitHub Jobs Search App built in React Native. Minimal Quotes 6 - Mobile app that throws you random quotes in a super clean minimal version. Hello Bemans 5 - Health Trainer Connection App (Android Version) RNV2ex 5 - react-native for v2ex Renote 4 - A simple react-native example app for make notes. Manyverse Social network off the grid (a Scuttlebutt Android client) Bristol Pound - An app for the Bristol Pound, a UK-based local currency. React Native Showcase Instagram clone - an Instagram clone Joplin - A note taking app for desktop, CLI, and mobile (linked here is the mobile app). Cat-or-dog - Simple game with drag'n'drops and animations. Forex Rates - Foreign exchange rates. currency rate converter. Historical exchange rates. Android and iOS. Smog Alert App provides real-time air pollution data all around the world and shows nearby polluters. Audio Book App Completed Audiobook app with some cool animations. FastBuy - App to manage the products from a dummy Store (built with React Native and Redux). Hydropuzzle - Stylish puzzle adventure game. Github-Gist - React native mobile application for github gist Lyrics King - Minimalist and stylish lyrics search app. TensorFlow.js Starter - TensorFlow.js starter app using MobileNet to predict image class. Blog post for additional context. Art Museum - Browse through the endless Harvard's Art Museum collection. NMF.earth 14 - Calculate, understand and reduce your carbon footprint. Available for Android and iOS, using Expo, Redux Toolkit and Typescript. Nyxo 12 - Sleep tracker and sleep coaching app. Available for Android and iOS. Post Card App 1 - Create old style post card and share on whatsapp as image. Built with Expo and available for android. Frameworks NativeBase 10520 - builds a layer on top of React Native that provides you with basic set of components for mobile application development Teaset 1575 - A UI library for react native, provides 20+ pure JS(ES6) components, focusing on content display and action control. Awesome React Native Meteor 152 - An awesome list of resources for using Meteor and React Native together first-born 106 - A UI framework with pre-built components that render separately according to the underlying mobile platform. OsmiCSX 48 - An utility React Native style framework for rapidly building custom user interfaces. React Native Diagnose 13 - A framework to test a React Native app during runtime and production Tutorials Walkthroughs and tutorials that help you learn React Native. Fully-immersive, hands-on, and fun learning experience for React Native 825 React Native with Django backend 12 Setting up background tasks that run periodically when app is closed in React Native Animate React Native UI Elements Build a streaming audio app with React Native Building a Calculator for Android and iOS with React Native Building Custom React Native Components From Scratch Deploying React Native using Fastlane Enabling Live Reload Facebook's F8 App Walkthrough Tutorial: React Native, Redux, Relay, Flow, Jest Facebook Login With React Native Integrating Parse and React Native for iOS Introducing React Native (on Ray Wenderlich's) Leverage Existing iOS Views In Your React Native App Official React Native tutorial React Native Periscope Hearts Animation React Native Youtube Animated Video Slide React Native and Socket.io React-Native Animated with React-Art - Firework Tap To Shoot React-native Animated API Basic Example React-native Animated API with PanResponder React-native Animated ScrollView Row Swipe Actions React-native press and hold button actions React Native Express Simple React Native forms with redux-form, immutable.js and styled-components A Mini-Course on React Native Flexbox The beauty of react-native -Build a stunning wallpaper app Adding and removing custom fonts in React Native IOS Android Adding Custom Fonts to A React Native Application Building a Minimalist Weather App with React Native and Expo Getting Started with Lottie, React Native and Expo How to integrate Redux into your application with React Native and Expo React Native for Designers Start React Native - Animation tutorial series Books Books - free and commercial (but only good ones). Programming React Native - (Free) An in-depth React Native book that you should read after you've done a couple tutorials of the many out there. React Native Animation Book - (Free) React Native Animation. Books - for sale. React Native In Action - Learn how to build applications using React Native from the ground up. React Native - Building Mobile Apps with JavaScript - Your go-to guide to creating truly native iOS and Android mobile applications using React and JavaScript. Fullstack React Native - The up-to-date, in-depth, complete guide to React Native. Videos Assortment of conference and training videos. Talks Chain React 2019: React Native Only Playlist awesome-react-native-talks 312 - A curated list of talks about React Native or topics related to React Native. Actually Building Things In React Native , Jani Evkallio, Futurice Using Redux, Jonas Ohlsson, State Native Testing Reactotron React Native In The Wild - Bonnie Eisenman Chain React 2019: Playlist Chain React 2018: Playlist Chain React 2017: Playlist React Conf 2015: Introducing React Native React Conf 2015: A Deep Dive into React Native F8 2015: React Native and Relay Training & tutorials Awesome React Native Education 455 React Native training 238 Let's build a React Native app in 20 minutes and Gist Mario Dez Channel - Youtube channel in spanish about with a series of videos talking about react native React Native Basics: Build a Currency Converter - (Free) A multi-hour in-depth video course showing you how to build apps with React Native. React Native in Arabic: Build a newspaper app - (Free) A simple to follow video series in Arabic showing you how to build a newspaper app with React Native. Building Youtube UI in 30 Minutes - A quick tutorial showing how to build Youtube Mobile app's UI using React Native. This tutorial helps in getting started with coding designs from scratch. Adding Authentication to a React Native Project - This tutorial shows how to easily add authentication to a React Native application using AWS Mobile Hub Generate React Native Forms with tcomb-form-native Build a chat app with React Native Egghead.io: React Native Fundamentals Pluralsight.com: Build iOS Apps with React Native Udemy.com: Build apps with React Native Udemy.com: Create Your First React Native App - Introduction to building a React Native app and learning the foundational pieces. Handlebarlabs.com: Learn React Native + Meteor - Comprehensive course & community on building an application with React Native and Meteor. Udemy.com: Automate Your React Native Releases with Fastlane & Bitrise - Learn step-by-step how to release your React Native applications into Stores automatically by using Fastlane & Bitrise. Blogs React Native Training Use React Native Blog Facebook Code Blog The Bakery - JavaScript, React, React Native posts. Christopher Chedeau aka Vjeux Brent Vatne Kyle Corbitt - Cofounder at Emberall. Made with React - Showcase of apps using React or React Native. Spencer Carli Official React Native Blog reactnative.gallery - Show and tell for React Native developers Red Shift - Infinite Red - Lots of React Native content Ideamotive's Blog - Blog about React Native Newsletters React Native Now React Native Newsletter Releases Stable: 0.57.0 Next: latest All Versions All Changelogs Upgrading Versions Release Process

 # # # # # # # # # # # # # # # # # # # #
 Repository: react-cosmos/react-cosmos, index: 4491, word count: 5828 
 # # # # # # # # # # # # # # # # # # # #

Neural networks module for RedisNeural Redis Machine learning is like highschool sex. Everyone says they do it, nobody really does, and no one knows what it actually is. -- @Mikettownsend. Neural Redis is a Redis loadable module that implements feed forward neural networks as a native data type for Redis. The project goal is to provide Redis users with an extremely simple to use machine learning experience. Normally machine learning is operated by collecting data, training some system, and finally executing the resulting program in order to solve actual problems. In Neural Redis all this phases are compressed into a single API: the data collection and training all happen inside the Redis server. Neural networks can be executed while there is an ongoing training, and can be re-trained multiple times as new data from the outside is collected (for instance user events). The project starts from the observation that, while complex problems like computer vision need slow to train and complex neural networks setups, many regression and classification problems that are able to enhance the user experience in many applications, are approachable by feed forward fully connected small networks, that are very fast to train, very generic, and robust against non optimal parameters configurations. Neural Redis implements: A very simple to use API. Automatic data normalization. Online training of neural networks in different threads. Ability to use the neural network while the system is training it (we train a copy and only later merge the weights). Fully connected neural networks using the RPROP (Resilient back propagation) learning algorithm. Automatic training with simple overtraining detection. The goal is to help developers, especially of mobile and web applications, to have a simple access to machine learning, in order to answer questions like: What promotion could work most likely with this user? What AD should I display to obtain the best conversion? What template is the user likely to appreciate? What is a likely future trend for this data points? Of course you can do more, since neural networks are pretty flexible. You can even have fun with computer visions datasets like MINST, however keep in mind that the neural networks implemented in Neural Redis are not optimized for complex computer visions tasks like convolutional networks (it will score 2.3%, very far from the state of art!), nor Neural Redis implements the wonders of recurrent neural networks. However you'll be surpirsed by the number of tasks in which a simple neural network that can be trained in minutes, will be able to discover linear ad non linear correlations. Loading the extension To run this extension you need Redis unstable, grab it from Github, it is the default branch. Then compile the extension, and load it starting Redis with: redis-server --loadmodule /path/to/neuralredis.so Alternatively add the following in your redis.conf file: loadmodule /path/to/neuralredis.so WARNING: alpha code WARNING: this is alpha code. It is likely to contain bugs and may easily crash the Redis server. Also note that currently only RDB persistence is implemented in the module, while AOF rewrite is not implemented at all. Use at your own risk. If you are not still scared enough, please consider that I wrote the more than 1000 lines of C code composing this extension, and this README file, in roughly two days. Note that this implementation may be hugely improved. For instance currently only the sigmoid activaction function and the root mean square loss functions are supported: while for the problems this module is willing to address this limited neural network implementation is showing to be quite flexible, it is possible to do much better depending on the problem at hand. Hello World In order to understand how the API works, here is an hello world example where we'll teach our neural network to do... additions :-) To create a new neural network we use the following command: > NR.CREATE net REGRESSOR 2 3 -> 1 NORMALIZE DATASET 50 TEST 10 (integer) 13 The command creates a neural network, configured for regression tasks (as opposed to classification: well'll explain what this means in the course of this tutorial). Note that the command replied with "13". It means that the network has a total of 13 tunable parameters, considering all the weights that go from units or biases to other units. Larger networks will have a lot more parameters. The neural network has 2 inputs, 3 hidden layers, and a single output. Regression means that given certain inputs and desired outputs, we want the neural network to be able to understand the function that given the inputs computes the outputs, and compute this function when new inputs are presented to it. The NORMALIZE option means that it is up to Redis to normalize the data it receives, so there is no need to provide data in the -/+ 1 range. The options DATASET 50 and TEST 10 means that we want an internal memory for the dataset of 50 and 10 items respectively for the training dataset, and the testing dataset. The learning happens using the training dataset, while the testing dataset is used in order to detect if the network is able to generalize, that is, is really able to understand how to approximate a given function. At the same time, the testing dataset is useful to avoid to train the network too much, a problem known as overfitting. Overfitting means that the network becomes too much specific, at the point to be only capable of replying correctly to the inputs and outputs it was presented with. Now it is time to provide the network with some data, so that it can learn the function we want to approximate: > NR.OBSERVE net 1 2 -> 3 1) (integer) 1 2) (integer) 0 We are saying: given the inputs 1 and 2, the output is 3. The reply to the NR.OBSERVE command is the number of data items stored in the neural network memory, respectively in the training and testing data sets. We continue like that with other examples: > NR.OBSERVE net 4 5 -> 9 > NR.OBSERVE net 3 4 -> 7 > NR.OBSERVE net 1 1 -> 2 > NR.OBSERVE net 2 2 -> 4 > NR.OBSERVE net 0 9 -> 9 > NR.OBSERVE net 7 5 -> 12 > NR.OBSERVE net 3 1 -> 4 > NR.OBSERVE net 5 6 -> 11 At this point we need to train the neural network, so that it can learn: > NR.TRAIN net AUTOSTOP The NR.TRAIN command starts a training thread. the AUTOSTOP option means that we want the training to stop before overfitting starts to happen. Using the NR.INFO command you can see if the network is still training. However in this specific case, the network will take a few milliseconds to train, so we can immediately try if it actually learned how to add two numbers: > NR.RUN net 1 1 1) "2.0776522297040843" > NR.RUN net 3 2 1) "5.1765427204933099" Well, more or less it works. Let's look at some internal info now: > NR.INFO net 1) id 2) (integer) 1 3) type 4) regressor 5) auto-normalization 6) (integer) 1 7) training 8) (integer) 0 9) layout 10) 1) (integer) 2 2) (integer) 3 3) (integer) 1 11) training-dataset-maxlen 12) (integer) 50 13) training-dataset-len 14) (integer) 6 15) test-dataset-maxlen 16) (integer) 10 17) test-dataset-len 18) (integer) 2 19) training-total-steps 20) (integer) 1344 21) training-total-seconds 22) 0.00 23) dataset-error 24) "7.5369825612397299e-05" 25) test-error 26) "0.00042670663615723583" 27) classification-errors-perc 28) 0.00 As you can see we have 6 dataset items and 2 test items. We configured the network at creation time to have space for 50 and 10 items. As you add items with NR.OBSERVE the network will put items evenly on both datasets, proportionally to their respective size. Finally when the datasets are full, old random entries are replaced with new ones. We can also see that the network was trained with 1344 steps for 0 seconds (just a few milliseconds). Each step is the training performed with a single data item, so the same 6 items were presented to the network for 244 cycles in total. A few words about normalization If we try to use our network with values outside the range it learned with, we'll see it failing: > NR.RUN net 10 10 1) "12.855978185382257" This happens because the automatic normalization will consider the maximum values seen in the training dataset. So if you plan to use auto normalization, make sure to show the network samples with different values, including inputs at the maximum of the data you'll want to use the network with in the future. Classification tasks Regression approximates a function having certain inputs and outputs in the training data set. Classification instead is the task of, given a set of inputs representing something, to label it with one of a fixed set of labels. For example the inputs may be features of Greek jars, and the classification output could be one of the following three jar types: Type 0: Kylix type A Type 1: Kylix type B Type 2: Kassel cup As a programmer you may think that, the output class, is just a single output number. However neural networks don't work well this way, for example classifying type 0 with an output between 0 and 0.33, type 1 with an output between 0.33 and 0.66, and finally type 2 with an output between 0.66 and 1, will not work well at all. The way to go instead is to use three distinct outputs, where we set two always to 0, and a single one to 1, corresponding to the type the output represents, so: Type 0: [1, 0, 0] Type 1: [0, 1, 0] Type 2: [0, 0, 1] When you create a neural network with the NR.CREATE command, and use as second argument CLASSIFIER instead of REGRESSOR, Neural Redis will do the above transformation for you, so when you train your network with NR.OBSERVE you'll just use, as output, as single number: 0, 1 or 2. Of course, you need to create the network with three outputs like that: > NR.CREATE mynet CLASSIFIER 5 10 -> 3 (integer) 93 Our network is currently untrained, but it can already be run, even if the replies it will provide are totally random: > NR.RUN mynet 0 1 1 0 1 1) "0.50930603602918945" 2) "0.48879876200255651" 3) "0.49534453421381375" As you can see, the network voted for type 0, since the first output is greater than the others. There is a Neural Redis command that saves you the work of finding the greatest output client side in order to interpret the result as a number between 0 and 2. It is identical to NR.RUN but just outputs directly the class ID, and is called NR.CLASS: > NR.CLASS mynet 0 1 1 0 1 (integer) 0 However note that ofter NR.RUN is useful for classification problems. For example a blogging platform may want to train a neural network to predict the template that will appeal more to the user, based on the registration data we just obtained, that include the country, sex, age and category of the blog. While the prediction of the network will be the output with the highest value, if we want to present different templates, it makes sense to present, in the listing, as the second one the one with the second highest output value and so forth. Before diving into a practical classification example, there is a last thing to say. Networks of type CLASSIFIER are also trained in a different way: instead of giving as output a list of zeros and ones you directly provide to NR.OBSERVE the class ID as a number, so in the example of the jars, we don't need to write NR.OBSERVE 1 0.4 .2 0 1 -> 0 0 1 to specify as output of the provided data sample the third class, but we should just write: > NR.OBSERVE mynet 1 0.4 .2 0 1 -> 2 The "2" will be translated into "0 0 1" automatically, as "1" would be translated to "0 1 0" and so forth. A practical example: the Titanic dataset Kaggle.com is hosting a machine learning competition. One of the datasets they use, is the list of the Titanic passengers, their ticket class, fair, number of relatives, age, sex, and other information, and... If they survived or not during the Titanic incident. You can find both the code and a CSV with a reduced dataset of 891 entries in the examples directory of this Github repository. In this example we are going to try to predict, given a few input variables, if a specific person is going to survive or not, so this is a classification task, where we label persons with two different labels: survived or died. This problem is pretty similar, even if a bit more scaring, than the problem of labeling users or predicting their response in some web application according to their behavior and the other data we collected in the past (hint: machine learning is all about collecting data...). In the CSV there are a number of information about each passenger, but here in order to make the example simpler we'll use just the following fields: Ticket class (1st, 2nd, 3rd). Sex. Age. Sibsp (Number of siblings, spouses aboard). Parch (Number of parents and children aboard). Ticket fare. If there is a correlation between this input variables and the ability to survive, our neural network should find it. Note that while we have six inputs, we'll need a total network with 9 total inputs, since sex and ticket class, are actually input classes, so like we did in the output, we'll need to do in the input. Each input will signal if the passenger is in one of the possible classes. This are our nine inputs: Is male? (0 or 1). Is Female? (0 or 1). Traveled in first class? (0 or 1). Traveled in second class? (0 or 1). Traveled in third class? (0 or 1). Age. Number of siblings / spouses. Number of parents / children. Ticket fare. We have a bit less than 900 passengers (I'm using a reduced dataset here), however we want to take about 200 for verification at application side, without sending them to Redis at all. The neural network will also use part of the dataset for verification, since here I'm planning to use the automatic training stop feature, in order to detect overfitting. Such a network can be created with: > NR.CREATE mynet CLASSIFIER 9 15 -> 2 DATASET 1000 TEST 500 NORMALIZE Also note that we are using a neural network with a single hidden layer (the layers between inputs and outputs are called hidden, in case you are new to neural networks). The hidden layer has 15 units. This is still a pretty small network, but we expect that for the amount of data and the kind of correlations that there could be in this data, this could be enough. It's possible to test with different parameters, and I plan to implement a NR.CONFIGURE command so that it will be possible to change this things on the fly. Also note that since we defined a testing dataset maximum size to be half the one of the training dataset (1000 vs 500), NR.OBSERVE will automatically put one third of the entires in the testing dataset. If you check the Ruby program that implements this example inside the source distribution, you'll see how data is fed directly as it is to the network, since we asked for auto normalization: The function is able to both send data or evaluate the error rate. After we load 601 entries from the dataset, before any training, the output of NR.INFO will look like this: > NR.INFO mynet 1) id 2) (integer) 5 3) type 4) classifier 5) auto-normalization 6) (integer) 1 7) training 8) (integer) 0 9) layout 10) 1) (integer) 9 2) (integer) 15 3) (integer) 2 11) training-dataset-maxlen 12) (integer) 1000 13) training-dataset-len 14) (integer) 401 15) test-dataset-maxlen 16) (integer) 500 17) test-dataset-len 18) (integer) 200 19) training-total-steps 20) (integer) 0 21) training-total-seconds 22) 0.00 23) dataset-error 24) "0" 25) test-error 26) "0" 27) classification-errors-perc 28) 0.00 29) overfitting-detected 30) no As expected, we have 401 training items and 200 testing dataset. Note that for networks declared as classifiers, we have an additional field in the info output, which is classification-errors-perc. Once we train the network this field will be populated with the percentage (from 0% to 100%) of items in the testing dataset which were misclassified by the neural network. It's time to train our network: > NR.TRAIN mynet AUTOSTOP Training has started If we check the NR.INFO output after the training, we'll discover a few interesting things (only quoting the relevant part of the output): 19) training-total-steps 20) (integer) 64160 21) training-total-seconds 22) 0.29 23) dataset-error 24) "0.1264141065389438" 25) test-error 26) "0.13803731074639586" 27) classification-errors-perc 28) 19.00 29) overfitting-detected 30) yes The network was trained for 0.29 seconds. At the end of the training, that was stopped for overfitting, the error rate in the testing dataset was 19%. You can also specify to train for a given amonut of seconds or cycles. For now we just use the AUTOSTOP feature since it is simpler. However we'll dig into more details in the next section. We can now show the output of the Ruby program after its full execution: 47 prediction errors on 290 items Does not look too bad, considering how simple is our model and the fact we trained with just 401 data points. Modeling just on the percentage of people that survived VS the ones that died, we could miss-predict more than 100 passengers. We can also play with a few variables interactively in order to check what are the inputs that make a difference according to our trained neural network. Let's start asking the probable outcome for a woman, 30 years old, first class, without siblings and parents: > NR.RUN mynet 1 0 0 0 1 30 0 0 200 1) "0.093071778873849084" 2) "0.90242156736283008" The network is positive she survived, with 90% of probabilities. What if she is a lot older than 30 years old, let's say 70? > NR.RUN mynet 1 0 0 0 1 70 0 0 200 1) "0.11650946245068818" 2) "0.88784839170875851" This lowers her probability to 88.7%. And if she traveled in third class with a very cheap ticket? > NR.RUN mynet 0 0 1 0 1 70 0 0 20 1) "0.53693405013043127" 2) "0.51547605838387811" This time is 50% and 50%... Throw your coin. The gist of this example is that, many problems you face as a developer in order to optimize your application and do better choices in the interaction with your users, are Titanic problems, but not in their size, just in the fact that a simple model can "solve" them. Overfitting detection and training tricks One thing that makes neural networks hard to use in an interactive way like the one they are proposed in this Redis module, is for sure overfitting. If you train too much, the neural network ends to be like that one student that can exactly tell you all the words in the lesson, but if you ask a more generic question about the argument she or he just wonders and can't reply. So the NR.TRAIN command AUTOSTOP option attempts to detect overfitting to stop the training before it's too late. How is this performed? Well the current solution is pretty trivial: as the training happens, we check the current error of the neural network between the training dataset and the testing dataset. When overfitting kicks in, usually what we see is that the network error rate starts to be lower and lower in the training dataset, but instead of also reducing in the testing dataset it inverts the tendency and starts to grow. To detect this turning point is not simple for two reasons: The error may fluctuates as the network learns. The network error may just go higher in the testing dataset since the learning is trapped into a local minima, but then a better solution may be found. So while AUTOSTOP kinda does what it advertises (but I'll work on improving it in the future, and there are neural network experts that know much better than me and can submit a kind Pull Request :-), there are also means to manually train the network, and see how the error changes with training. For instance, this is the error rate in the Titanic dataset after the automatic stop: 21) training-total-seconds 22) 0.17 23) dataset-error 24) "0.13170509045457734" 25) test-error 26) "0.13433443241900492" 27) classification-errors-perc 28) 18.50 We can use the MAXTIME and MAXCYCLES options in order to train for a specific amount of time (note that these options are also applicable when AUTOSTOP is specified). Normally MAXTIME is set to 10000, which are milliseconds, so to 10 seconds of total training before killing the training thread. Let's train our network for 30 seconds, without auto stop. > NR.TRAIN mynet MAXTIME 30000 Training has started As a side note, while one or more trainings are in progress, we can list them: > NR.THREADS 1) nn_id=9 key=mynet db=0 maxtime=30000 maxcycles=0 After the training stops, let's show info again: 21) training-total-seconds 22) 30.17 23) dataset-error 24) "0.0674554189303056" 25) test-error 26) "0.20468644603795394" 27) classification-errors-perc 28) 21.50 You can see that our network overtrained: the error rate of the training dataset is now lower: 0.06. But actually the performances in data it never saw before, that is the testing dataset, is greater at 0.20! And indeed, it classifies in a wrong way 21% of entries instead of 18.50%. However it's not always like that, so to test things manually is a good idea when working at machine learning experiments, especially with this module that is experimental. An interesting example is the iris.rb program inside the examples directory: it will load the Iris.csv dataset into Redis, which is a very popular dataset with three variants of Iris flowers with their sepal and petal features. If you run the program, the percentage of entries classified in a wrong way will be 4%, however if you train the network a few more cycles with: NR.TRAIN iris MAXCYCLES 100 You'll see that often the error will drop to 2%. Better overfitting detection with the BACKTRACK option When using AUTOSTOP, there is an additional option that can be specified (it has no effects alone), that is: BACKTRACK. When backtracking is enabled, while the network is trained, every time there is some hint that the network may start to overfit, the current version of the network is saved. At the end of the training, if the saved network is better (has a smaller error) compared to the current one, it is used instead of the final version of the trained network. This avoids certain pathological runs when AUTOSTOP is used but overfitting is not detected. However, it adds running time since we need to clone the NN from time to time during the training. For example using BACKTRACK with the Iris dataset (see the iris.rb file inside the examples directory) it never overtrains, while without about 2% of the runs may overtrain. A more complex non linear classification example The Titanic example is surely more interesting, however it is possible that most relations between inputs and outputs are linear, so we'll now try a non linear classification task, just for the sake of showing the capabilities of a small neural network. In the examples directory of this source distribution there is an example called circles.rb, we'll use it as a reference. We'll just setup a classification problem where the neural network will be asked to classify two inputs, which are from our point of view two coordinates in a 2D space, into three different classes: 0, 1 and 2. While the neural network does not know this, we'll generate the data so that different classes actually map to three different circles in the 2D space: the circles also contain intersections. The function that generates the dataset is the following: The basic trigonometric function: x = Math.sin(k) y = Math.cos(k) With k going from 0 to 2*PI, is just a circle, so the above functions are just circles, plus the rand() calls in order to introduce noise. Basically if I trace the above three classes of points in a graphical way with load81, I obtain the following image: The program circles.rb, it will generate the same set of points and will feed them into the neural network configured to accept 2 inputs and output one of three possible classes. After about 2 seconds of training, we try to visualize what the neural network has learned (also part of the circles.rb command) in this way: for each point in an 80x80 grid, we ask the network to classify the point. This is the ASCII-artist result: As you can see, while the problem had no linear solution, the neural network was able to split the 2D space into areas, with the holes where there is the intersection between the circles areas, and thiner surfaces where the circles actually cross each other (in the intersection between the two circumferences there are points of two different classes). This example was not practical perhaps but shows well the power of the neural network in non linear tasks. Case study: Sentiment Analysis Neural Redis is not the right tool for advanced NLP tasks, and for sentiment analysis, which is a very hard problem, there are RNNs and other, more complex tools, that can provide state of art results. However exactly for the same reason, SA is a very good example to show how to model problems, and that even the simplest of the intuitions can allow Neural Redis to handle problems in a decent way (even if far from the top specialized systems) after a training of 5 minutes or so. This case study is based on the source code inside the examples directory called sentiment.rb. It uses a very popular dataset used for sentiment analysis benchmarking, composed of 2000 movies reviews, 1000 which are positive, and 1000 negative. The reviews are like the following: It must be some sort of warped critical nightmare: the best movie of the year would be a summer vehicle, a jim carrey vehicle at that. And so it is. The truman show is the most perplexing, crazed, paranoid and rib-tickling morality play i've seen since i-don't-know-when. Normally we should try to do the best we can do in order to pre-process the data, but we are lazy dogs, so we don't do anything at all. However we still need to map our inputs and outputs to meaningful parameters. For the outputs, it's trivial, is a categorization task: negative or positive. But how do we map words to inputs? Normally you assign different words to different IDs, and then use such IDs as indexes. This creates two problems in our case: We need to select a vocabulary. Usually this is done in a pre-processing stage where we potentially examine a non-annotated large corpus of text. But remember that we are lazy? "very good" and "not good" have very different meanings, we can't stop to single words, otherwise our result is likely be disappointing. So I did the following. Let's say our network is composed of 3000 inputs, 100 hidden units, and the 2 outputs for the classification. We split the initial inputs into two sides: 1500 of inputs just take the single words. The other 1500 inputs, we use for combinations of two words. What I did was to just use hashing to map the words in the text to the input units: INDEX_1 = HASH(word) % 1500 INDEX_2 = 1500 + (HASH(word + next_word) % 1500) This is a bit crazy, I'm curious to know if it's something that people tried in the past, since different words and different combinations of words will hash to the same, so we'll get a bit less precise results, however it is unlikely that words highly polarized in the opposite direction (positive VS negative) will hash to the same bucket, if we use enough inputs. So each single word and combination of words is a "vote" in the input unit. As we scan the sentences to give the votes, we also sum all the single votes we gave, so that we finally normalize to make sure all our inputs summed will give "1". This way the sentiment analysis does not depend by the length of the sentence. While this approach is very simple, it works and produces a NN in a matter of seconds that can score 80% in the 2000 movies dataset. I just spent a couple of hours on it, probably it's possible to do much better with a more advanced scheme. However the gist of this use case is: be creative when trying to map your data to the neural network. If you run sentiment.rb you'll see the network quickly converging and at the end, you'll be able to type sentences that the NN will classify as positive or negative: nn_id=7 cycle=61 key=sentiment ... classerr=21.500000 nn_id=7 cycle=62 key=sentiment ... classerr=20.333334 Best net so far can predict sentiment polarity 78.17 of times Imagine and type a film review sentence: > WTF this movie was terrible Negativity: 0.99966669082641602 Positivity: 0.00037576013710349798 > Good one Negativity: 0.28475716710090637 Positivity: 0.73368257284164429 > This is a masterpiece Negativity: 2.219095662781001e-08 Positivity: 0.99999994039535522 Of course you'll find a number of sentences that the net will classify in the wrong way... However the longer sentence you type and more similar to an actual movie review, the more likely it can predict it correctly. API reference In the above tutorial not all the options of all the commands may be covered, so here there is a small reference with all the commands supported by this extension and associated options. NR.CREATE key [CLASSIFIER|REGRESSOR] inputs [hidden-layer-units ...] -> outputs [NORMALIZE] [DATASET maxlen] [TEST maxlen] Create a new neural network if the target key is empty, or returns an error. key - The key name holding the neural network. CLASSIFIER or REGRESSOR is the network type, read this tutorial for more info. inputs - Number of input units hidden-layer-units zero or more arguments indicating the number of hidden units, one number for each layer. outputs - Number of outputs units NORMALIZE - Specify if you want the network to normalize your inputs. Use this if you don't know what we are talking about. DATASET maxlen - Max number of data samples in the training dataset. TEST maxlen - Max number of data samples in the testing dataset. Example: NR.CREATE mynet CLASSIFIER 64 100 -> 10 NORMALIZE DATASET 1000 TEST 500 NR.OBSERVE key i0 i1 i2 i3 i4 ... iN -> o0 o1 o3 ... oN [TRAIN|TEST] Add a data sample into the training or testing dataset (if specified as last argument) or evenly into one or the other, according to their respective sizes, if no target is specified. For neural networks of type CLASSIFIER the output must be just one, in the range from 0 to number-of-outputs - 1. It's up to the network to translate the class ID into a set of zeros and ones. The command returns the number of data samples inside the training and testing dataset. If the target datasets are already full, a random entry is evicted and substituted with the new data. NR.RUN key i0 i1 i2 i3 i4 ... iN Run the network stored at key, returning an array of outputs. NR.CLASS key i0 i1 i2 i3 i4 ... iN Like NR.RUN but can be used only with NNs of type CLASSIFIER. Instead of outputting the raw neural network outputs, the command returns the output class directly, which is, the index of the output with the greatest value. NR.TRAIN key [MAXCYCLES count] [MAXTIME milliseconds] [AUTOSTOP] [BACKTRACK] Train a network in a background thread. When the training finishes automatically updates the weights of the trained networks with the new ones and updates the training statistics. The command works with a copy of the network, so it is possible to use the network while it is undergoing a training. If no AUTOSTOP is specified, trains the network till the maximum number of cycles or milliseconds are reached. If no maximum number of cycles is specified there are no cycles limits. If no milliseconds are specified, the limit is set to 10000 milliseconds (10 seconds). If AUTOSTOP is specified, the training will still stop when the maximum umber of cycles or milliseconds is specified, but will also try to stop the training if overfitting is detected. Check the previous sections for a description of the (still naive) algorithm the implementation uses in order to stop. If BACKTRACK is specified, and AUTOSTOP is also specified, while the network is trained, the trainer thread saves a copy of the neural network every time it has a better score compared to the previously saved one and there are hints suggesting that overfitting may happen soon. This network is used later if it is found to have a smaller error. NR.INFO key Show many internal information about the neural network. Just try it :-) NR.THREADS Show all the active training threads. NR.RESET key Set the neural network weights to random ones (that is, the network will completely unlearn what it learned so far), and reset training statistics. However the datasets are not touched at all. This is useful when you want to retrain a network from scratch. Contributing The main aim of Neural Redis, which is currently just a 48h personal hackatlon, is to show the potential that there is in an accessible API that provides a simple to use machine learning tool, that can be used and trained interactively. However the neural network implementation can be surely improved in different ways, so if you are an expert in this field, feel free to submit changes or ideas. One thing that I want to retain is the simplicity of the outer layer: the API. However the techniques used in the internals can be more complex in order to improve the results. There is to note that, given the API exported, the implementation of the neural network should be, more than state of art in solving a specific problem, more designed in order to work well enough in a large set of conditions. While the current fully connected network has its limits, it together with BPROP learning shows to be quite resistant to misuses. So an improved version should be able to retain, and extend this quality. The simplest way to guarantee this is to have a set of benchmarks of different types using open datasets, and to score different implementations against it. Plans Better overfitting detection. Implement RNNs with a simpler to use API. Use a different loss function for classification NNs. Get some ML expert which is sensible to simple APIs involved. Have fun with machine learning, Salvatore

 # # # # # # # # # # # # # # # # # # # #
 Repository: thx/RAP, index: 1532, word count: 36269 
 # # # # # # # # # # # # # # # # # # # #

Embed the Power of Lua into NGINX HTTP servers Name ngx_http_lua_module - Embed the power of Lua into Nginx HTTP Servers. This module is a core component of OpenResty. If you are using this module, then you are essentially using OpenResty. This module is not distributed with the Nginx source. See the installation instructions. Table of Contents Name Status Version Videos Synopsis Description Typical Uses Nginx Compatibility Installation Building as a dynamic module C Macro Configurations Community English Mailing List Chinese Mailing List Code Repository Bugs and Patches LuaJIT bytecode support System Environment Variable Support HTTP 1.0 support Statically Linking Pure Lua Modules Data Sharing within an Nginx Worker Known Issues TCP socket connect operation issues Lua Coroutine Yielding/Resuming Lua Variable Scope Locations Configured by Subrequest Directives of Other Modules Cosockets Not Available Everywhere Special Escaping Sequences Mixing with SSI Not Supported SPDY Mode Not Fully Supported Missing data on short circuited requests TODO Changes Test Suite Copyright and License See Also Directives Nginx API for Lua Obsolete Sections Special PCRE Sequences Lua/LuaJIT bytecode support Status Production ready. Version This document describes ngx_lua v0.10.19, which was released on 3 Nov, 2020. Videos YouTube video "Hello World HTTP Example with OpenResty/Lua" YouTube video "Write Your Own Lua Modules in OpenResty/Nginx Applications" YouTube video "OpenResty's resty Command-Line Utility Demo" YouTube video "Measure Execution Time of Lua Code Correctly in OpenResty" YouTube video "Precompile Lua Modules into LuaJIT Bytecode to Speedup OpenResty Startup" You are welcome to subscribe to our official YouTube channel, OpenResty. Back to TOC Synopsis Back to TOC Description This module embeds LuaJIT 2.0/2.1 into Nginx. It is a core component of OpenResty. If you are using this module, then you are essentially using OpenResty. Since version v0.10.16 of this module, the standard Lua interpreter (also known as "PUC-Rio Lua") is not supported anymore. This document interchangeably uses the terms "Lua" and "LuaJIT" to refer to the LuaJIT interpreter. By leveraging Nginx's subrequests, this module allows the integration of the powerful Lua threads (known as Lua "coroutines") into the Nginx event model. Unlike Apache's mod_lua and Lighttpd's mod_magnet, Lua code executed using this module can be 100% non-blocking on network traffic as long as the Nginx API for Lua provided by this module is used to handle requests to upstream services such as MySQL, PostgreSQL, Memcached, Redis, or upstream HTTP web services. At least the following Lua libraries and Nginx modules can be used with this module: lua-resty-memcached lua-resty-mysql lua-resty-redis lua-resty-dns lua-resty-upload lua-resty-websocket lua-resty-lock lua-resty-logger-socket lua-resty-lrucache lua-resty-string ngx_memc ngx_postgres ngx_redis2 ngx_redis ngx_proxy ngx_fastcgi Almost any Nginx modules can be used with this ngx_lua module by means of ngx.location.capture or ngx.location.capture_multi but it is recommended to use those lua-resty-* libraries instead of creating subrequests to access the Nginx upstream modules because the former is usually much more flexible and memory-efficient. The Lua interpreter (also known as "Lua State" or "LuaJIT VM instance") is shared across all the requests in a single Nginx worker process to minimize memory use. Request contexts are segregated using lightweight Lua coroutines. Loaded Lua modules persist in the Nginx worker process level resulting in a small memory footprint in Lua even when under heavy loads. This module is plugged into Nginx's "http" subsystem so it can only speaks downstream communication protocols in the HTTP family (HTTP 0.9/1.0/1.1/2.0, WebSockets, etc...). If you want to do generic TCP communications with the downstream clients, then you should use the ngx_stream_lua module instead, which offers a compatible Lua API. Back to TOC Typical Uses Just to name a few: Mashup'ing and processing outputs of various Nginx upstream outputs (proxy, drizzle, postgres, redis, memcached, and etc) in Lua, doing arbitrarily complex access control and security checks in Lua before requests actually reach the upstream backends, manipulating response headers in an arbitrary way (by Lua) fetching backend information from external storage backends (like redis, memcached, mysql, postgresql) and use that information to choose which upstream backend to access on-the-fly, coding up arbitrarily complex web applications in a content handler using synchronous but still non-blocking access to the database backends and other storage, doing very complex URL dispatch in Lua at rewrite phase, using Lua to implement advanced caching mechanism for Nginx's subrequests and arbitrary locations. The possibilities are unlimited as the module allows bringing together various elements within Nginx as well as exposing the power of the Lua language to the user. The module provides the full flexibility of scripting while offering performance levels comparable with native C language programs both in terms of CPU time as well as memory footprint thanks to LuaJIT 2.x. Other scripting language implementations typically struggle to match this performance level. Back to TOC Nginx Compatibility The latest version of this module is compatible with the following versions of Nginx: 1.19.x (last tested: 1.19.3) 1.17.x (last tested: 1.17.8) 1.15.x (last tested: 1.15.8) 1.14.x 1.13.x (last tested: 1.13.6) 1.12.x 1.11.x (last tested: 1.11.2) 1.10.x 1.9.x (last tested: 1.9.15) 1.8.x 1.7.x (last tested: 1.7.10) 1.6.x Nginx cores older than 1.6.0 (exclusive) are not supported. Back to TOC Installation It is highly recommended to use OpenResty releases which bundle Nginx, ngx_lua (this module), LuaJIT, as well as other powerful companion Nginx modules and Lua libraries. It is discouraged to build this module with Nginx yourself since it is tricky to set up exactly right. Note that Nginx, LuaJIT, and OpenSSL official releases have various limitations and long standing bugs that can cause some of this module's features to be disabled, not work properly, or run slower. Official OpenResty releases are recommended because they bundle OpenResty's optimized LuaJIT 2.1 fork and Nginx/OpenSSL patches. Alternatively, ngx_lua can be manually compiled into Nginx: LuaJIT can be downloaded from the latest release of OpenResty's LuaJIT fork. The official LuaJIT 2.x releases are also supported, although performance will be significantly lower for reasons elaborated above Download the latest version of the ngx_devel_kit (NDK) module HERE Download the latest version of ngx_lua HERE Download the latest supported version of Nginx HERE (See Nginx Compatibility) Build the source with this module: Back to TOC Building as a dynamic module Starting from NGINX 1.9.11, you can also compile this module as a dynamic module, by using the --add-dynamic-module=PATH option instead of --add-module=PATH on the ./configure command line above. And then you can explicitly load the module in your nginx.conf via the load_module directive, for example, Back to TOC C Macro Configurations While building this module either via OpenResty or with the Nginx core, you can define the following C macros via the C compiler options: NGX_LUA_USE_ASSERT When defined, will enable assertions in the ngx_lua C code base. Recommended for debugging or testing builds. It can introduce some (small) runtime overhead when enabled. This macro was first introduced in the v0.9.10 release. NGX_LUA_ABORT_AT_PANIC When the LuaJIT VM panics, ngx_lua will instruct the current nginx worker process to quit gracefully by default. By specifying this C macro, ngx_lua will abort the current nginx worker process (which usually result in a core dump file) immediately. This option is useful for debugging VM panics. This option was first introduced in the v0.9.8 release. To enable one or more of these macros, just pass extra C compiler options to the ./configure script of either Nginx or OpenResty. For instance, ./configure --with-cc-opt="-DNGX_LUA_USE_ASSERT -DNGX_LUA_ABORT_AT_PANIC" Back to TOC Community Back to TOC English Mailing List The openresty-en mailing list is for English speakers. Back to TOC Chinese Mailing List The openresty mailing list is for Chinese speakers. Back to TOC Code Repository The code repository of this project is hosted on GitHub at openresty/lua-nginx-module. Back to TOC Bugs and Patches Please submit bug reports, wishlists, or patches by creating a ticket on the GitHub Issue Tracker, or posting to the OpenResty community. Back to TOC LuaJIT bytecode support Watch YouTube video "Measure Execution Time of Lua Code Correctly in OpenResty" As from the v0.5.0rc32 release, all *_by_lua_file configure directives (such as content_by_lua_file) support loading LuaJIT 2.0/2.1 raw bytecode files directly: The -bg option can be used to include debug information in the LuaJIT bytecode file: Please refer to the official LuaJIT documentation on the -b option for more details: https://luajit.org/running.html#opt_b Note that the bytecode files generated by LuaJIT 2.1 is not compatible with LuaJIT 2.0, and vice versa. The support for LuaJIT 2.1 bytecode was first added in ngx_lua v0.9.3. Attempts to load standard Lua 5.1 bytecode files into ngx_lua instances linked to LuaJIT 2.0/2.1 (or vice versa) will result in an Nginx error message such as the one below: [error] 13909#0: *1 failed to load Lua inlined code: bad byte-code header in /path/to/test_file.luac Loading bytecode files via the Lua primitives like require and dofile should always work as expected. Back to TOC System Environment Variable Support If you want to access the system environment variable, say, foo, in Lua via the standard Lua API os.getenv, then you should also list this environment variable name in your nginx.conf file via the env directive. For example, Back to TOC HTTP 1.0 support The HTTP 1.0 protocol does not support chunked output and requires an explicit Content-Length header when the response body is not empty in order to support the HTTP 1.0 keep-alive. So when a HTTP 1.0 request is made and the lua_http10_buffering directive is turned on, ngx_lua will buffer the output of ngx.say and ngx.print calls and also postpone sending response headers until all the response body output is received. At that time ngx_lua can calculate the total length of the body and construct a proper Content-Length header to return to the HTTP 1.0 client. If the Content-Length response header is set in the running Lua code, however, this buffering will be disabled even if the lua_http10_buffering directive is turned on. For large streaming output responses, it is important to disable the lua_http10_buffering directive to minimise memory usage. Note that common HTTP benchmark tools such as ab and http_load issue HTTP 1.0 requests by default. To force curl to send HTTP 1.0 requests, use the -0 option. Back to TOC Statically Linking Pure Lua Modules With LuaJIT 2.x, it is possible to statically link the bytecode of pure Lua modules into the Nginx executable. You can use the luajit executable to compile .lua Lua module files to .o object files containing the exported bytecode data, and then link the .o files directly in your Nginx build. Below is a trivial example to demonstrate this. Consider that we have the following .lua file named foo.lua: And then we compile this .lua file to foo.o file: What matters here is the name of the .lua file, which determines how you use this module later on the Lua land. The file name foo.o does not matter at all except the .o file extension (which tells luajit what output format is used). If you want to strip the Lua debug information from the resulting bytecode, you can just specify the -b option above instead of -bg. Then when building Nginx or OpenResty, pass the --with-ld-opt="foo.o" option to the ./configure script: Finally, you can just do the following in any Lua code run by ngx_lua: And this piece of code no longer depends on the external foo.lua file any more because it has already been compiled into the nginx executable. If you want to use dot in the Lua module name when calling require, as in then you need to rename the foo.lua file to resty_foo.lua before compiling it down to a .o file with the luajit command-line utility. It is important to use exactly the same version of LuaJIT when compiling .lua files to .o files as building nginx + ngx_lua. This is because the LuaJIT bytecode format may be incompatible between different LuaJIT versions. When the bytecode format is incompatible, you will see a Lua runtime error saying that the Lua module is not found. When you have multiple .lua files to compile and link, then just specify their .o files at the same time in the value of the --with-ld-opt option. For instance, If you have too many .o files, then it might not be feasible to name them all in a single command. In this case, you can build a static library (or archive) for your .o files, as in then you can link the myluafiles archive as a whole to your nginx executable: where /path/to/lib is the path of the directory containing the libmyluafiles.a file. It should be noted that the linker option --whole-archive is required here because otherwise our archive will be skipped because no symbols in our archive are mentioned in the main parts of the nginx executable. Back to TOC Data Sharing within an Nginx Worker To globally share data among all the requests handled by the same Nginx worker process, encapsulate the shared data into a Lua module, use the Lua require builtin to import the module, and then manipulate the shared data in Lua. This works because required Lua modules are loaded only once and all coroutines will share the same copy of the module (both its code and data). Note that the use of global Lua variables is strongly discouraged, as it may lead to unexpected race conditions between concurrent requests. Here is a small example on sharing data within an Nginx worker via a Lua module: and then accessing it from nginx.conf: The mydata module in this example will only be loaded and run on the first request to the location /lua, and all subsequent requests to the same Nginx worker process will use the reloaded instance of the module as well as the same copy of the data in it, until a HUP signal is sent to the Nginx master process to force a reload. This data sharing technique is essential for high performance Lua applications based on this module. Note that this data sharing is on a per-worker basis and not on a per-server basis. That is, when there are multiple Nginx worker processes under an Nginx master, data sharing cannot cross the process boundary between these workers. It is usually recommended to share read-only data this way. You can also share changeable data among all the concurrent requests of each Nginx worker process as long as there is no nonblocking I/O operations (including ngx.sleep) in the middle of your calculations. As long as you do not give the control back to the Nginx event loop and ngx_lua's light thread scheduler (even implicitly), there can never be any race conditions in between. For this reason, always be very careful when you want to share changeable data on the worker level. Buggy optimizations can easily lead to hard-to-debug race conditions under load. If server-wide data sharing is required, then use one or more of the following approaches: Use the ngx.shared.DICT API provided by this module. Use only a single Nginx worker and a single server (this is however not recommended when there is a multi core CPU or multiple CPUs in a single machine). Use data storage mechanisms such as memcached, redis, MySQL or PostgreSQL. The OpenResty official releases come with a set of companion Nginx modules and Lua libraries that provide interfaces with these data storage mechanisms. Back to TOC Known Issues Back to TOC TCP socket connect operation issues The tcpsock:connect method may indicate success despite connection failures such as with Connection Refused errors. However, later attempts to manipulate the cosocket object will fail and return the actual error status message generated by the failed connect operation. This issue is due to limitations in the Nginx event model and only appears to affect Mac OS X. Back to TOC Lua Coroutine Yielding/Resuming Because Lua's dofile and require builtins are currently implemented as C functions in LuaJIT 2.0/2.1, if the Lua file being loaded by dofile or require invokes ngx.location.capture*, ngx.exec, ngx.exit, or other API functions requiring yielding in the top-level scope of the Lua file, then the Lua error "attempt to yield across C-call boundary" will be raised. To avoid this, put these calls requiring yielding into your own Lua functions in the Lua file instead of the top-level scope of the file. Back to TOC Lua Variable Scope Care must be taken when importing modules, and this form should be used: instead of the old deprecated form: Here is the reason: by design, the global environment has exactly the same lifetime as the Nginx request handler associated with it. Each request handler has its own set of Lua global variables and that is the idea of request isolation. The Lua module is actually loaded by the first Nginx request handler and is cached by the require() built-in in the package.loaded table for later reference, and the module() builtin used by some Lua modules has the side effect of setting a global variable to the loaded module table. But this global variable will be cleared at the end of the request handler, and every subsequent request handler all has its own (clean) global environment. So one will get Lua exception for accessing the nil value. The use of Lua global variables is a generally inadvisable in the ngx_lua context as: the misuse of Lua globals has detrimental side effects on concurrent requests when such variables should instead be local in scope, Lua global variables require Lua table look-ups in the global environment which is computationally expensive, and some Lua global variable references may include typing errors which make such difficult to debug. It is therefore highly recommended to always declare such within an appropriate local scope instead. To find all instances of Lua global variables in your Lua code, run the lua-releng tool across all .lua source files: $ lua-releng Checking use of Lua global variables in file lib/foo/bar.lua ... 1 [1489] SETGLOBAL 7 -1 ; contains 55 [1506] GETGLOBAL 7 -3 ; setvar 3 [1545] GETGLOBAL 3 -4 ; varexpand The output says that the line 1489 of file lib/foo/bar.lua writes to a global variable named contains, the line 1506 reads from the global variable setvar, and line 1545 reads the global varexpand. This tool will guarantee that local variables in the Lua module functions are all declared with the local keyword, otherwise a runtime exception will be thrown. It prevents undesirable race conditions while accessing such variables. See Data Sharing within an Nginx Worker for the reasons behind this. Back to TOC Locations Configured by Subrequest Directives of Other Modules The ngx.location.capture and ngx.location.capture_multi directives cannot capture locations that include the add_before_body, add_after_body, auth_request, echo_location, echo_location_async, echo_subrequest, or echo_subrequest_async directives. will not work as expected. Back to TOC Cosockets Not Available Everywhere Due to internal limitations in the Nginx core, the cosocket API is disabled in the following contexts: set_by_lua*, log_by_lua*, header_filter_by_lua*, and body_filter_by_lua. The cosockets are currently also disabled in the init_by_lua* and init_worker_by_lua* directive contexts but we may add support for these contexts in the future because there is no limitation in the Nginx core (or the limitation might be worked around). There exists a workaround, however, when the original context does not need to wait for the cosocket results. That is, creating a zero-delay timer via the ngx.timer.at API and do the cosocket results in the timer handler, which runs asynchronously as to the original context creating the timer. Back to TOC Special Escaping Sequences NOTE Following the v0.9.17 release, this pitfall can be avoided by using the *_by_lua_block {} configuration directives. PCRE sequences such as \d, \s, or \w, require special attention because in string literals, the backslash character, \, is stripped out by both the Lua language parser and by the Nginx config file parser before processing if not within a *_by_lua_block {} directive. So the following snippet will not work as expected: To avoid this, double escape the backslash: Here, \\\\d+ is stripped down to \\d+ by the Nginx config file parser and this is further stripped down to \d+ by the Lua language parser before running. Alternatively, the regex pattern can be presented as a long-bracketed Lua string literal by encasing it in "long brackets", [[...]], in which case backslashes have to only be escaped once for the Nginx config file parser. Here, [[\\d+]] is stripped down to [[\d+]] by the Nginx config file parser and this is processed correctly. Note that a longer from of the long bracket, [=[...]=], may be required if the regex pattern contains [...] sequences. The [=[...]=] form may be used as the default form if desired. An alternative approach to escaping PCRE sequences is to ensure that Lua code is placed in external script files and executed using the various *_by_lua_file directives. With this approach, the backslashes are only stripped by the Lua language parser and therefore only need to be escaped once each. Within external script files, PCRE sequences presented as long-bracketed Lua string literals do not require modification. As noted earlier, PCRE sequences presented within *_by_lua_block {} directives (available following the v0.9.17 release) do not require modification. Back to TOC Mixing with SSI Not Supported Mixing SSI with ngx_lua in the same Nginx request is not supported at all. Just use ngx_lua exclusively. Everything you can do with SSI can be done atop ngx_lua anyway and it can be more efficient when using ngx_lua. Back to TOC SPDY Mode Not Fully Supported Certain Lua APIs provided by ngx_lua do not work in Nginx's SPDY mode yet: ngx.location.capture, ngx.location.capture_multi, and ngx.req.socket. Back to TOC Missing data on short circuited requests Nginx may terminate a request early with (at least): 400 (Bad Request) 405 (Not Allowed) 408 (Request Timeout) 413 (Request Entity Too Large) 414 (Request URI Too Large) 494 (Request Headers Too Large) 499 (Client Closed Request) 500 (Internal Server Error) 501 (Not Implemented) This means that phases that normally run are skipped, such as the rewrite or access phase. This also means that later phases that are run regardless, e.g. log_by_lua, will not have access to information that is normally set in those phases. Back to TOC TODO cosocket: implement LuaSocket's unconnected UDP API. cosocket: add support in the context of init_by_lua*. cosocket: implement the bind() method for stream-typed cosockets. cosocket: review and merge aviramc's patch for adding the bsdrecv method. cosocket: add configure options for different strategies of handling the cosocket connection exceeding in the pools. review and apply vadim-pavlov's patch for ngx.location.capture's extra_headers option use ngx_hash_t to optimize the built-in header look-up process for ngx.req.set_header, ngx.header.HEADER, and etc. add directives to run Lua codes when Nginx stops. add ignore_resp_headers, ignore_resp_body, and ignore_resp options to ngx.location.capture and ngx.location.capture_multi methods, to allow micro performance tuning on the user side. add automatic Lua code time slicing support by yielding and resuming the Lua VM actively via Lua's debug hooks. add stat mode similar to mod_lua. cosocket: add client SSL certificate support. Back to TOC Changes The changes made in every release of this module are listed in the change logs of the OpenResty bundle: https://openresty.org/#Changes Back to TOC Test Suite The following dependencies are required to run the test suite: Nginx version >= 1.4.2 Perl modules: Test::Nginx: https://github.com/openresty/test-nginx Nginx modules: ngx_devel_kit ngx_set_misc ngx_auth_request (this is not needed if you're using Nginx 1.5.4+. ngx_echo ngx_memc ngx_srcache ngx_lua (i.e., this module) ngx_lua_upstream ngx_headers_more ngx_drizzle ngx_rds_json ngx_coolkit ngx_redis2 The order in which these modules are added during configuration is important because the position of any filter module in the filtering chain determines the final output, for example. The correct adding order is shown above. 3rd-party Lua libraries: lua-cjson Applications: mysql: create database 'ngx_test', grant all privileges to user 'ngx_test', password is 'ngx_test' memcached: listening on the default port, 11211. redis: listening on the default port, 6379. See also the developer build script for more details on setting up the testing environment. To run the whole test suite in the default testing mode: cd /path/to/lua-nginx-module export PATH=/path/to/your/nginx/sbin:$PATH prove -I/path/to/test-nginx/lib -r t To run specific test files: cd /path/to/lua-nginx-module export PATH=/path/to/your/nginx/sbin:$PATH prove -I/path/to/test-nginx/lib t/002-content.t t/003-errors.t To run a specific test block in a particular test file, add the line --- ONLY to the test block you want to run, and then use the prove utility to run that .t file. There are also various testing modes based on mockeagain, valgrind, and etc. Refer to the Test::Nginx documentation for more details for various advanced testing modes. See also the test reports for the Nginx test cluster running on Amazon EC2: https://qa.openresty.org. Back to TOC Copyright and License This module is licensed under the BSD license. Copyright (C) 2009-2017, by Xiaozhe Wang (chaoslawful) chaoslawful@gmail.com. Copyright (C) 2009-2019, by Yichun "agentzh" Zhang () agentzh@gmail.com, OpenResty Inc. All rights reserved. Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met: Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer. Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution. THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE. Back to TOC See Also Blog posts: Introduction to Lua-Land CPU Flame Graphs How OpenResty and Nginx Allocate and Manage Memory How OpenResty and Nginx Shared Memory Zones Consume RAM Memory Fragmentation in OpenResty and Nginx's Shared Memory Zones Other related modules and libraries: ngx_stream_lua_module for an official port of this module for the Nginx "stream" subsystem (doing generic downstream TCP communications). lua-resty-memcached library based on ngx_lua cosocket. lua-resty-redis library based on ngx_lua cosocket. lua-resty-mysql library based on ngx_lua cosocket. lua-resty-upload library based on ngx_lua cosocket. lua-resty-dns library based on ngx_lua cosocket. lua-resty-websocket library for both WebSocket server and client, based on ngx_lua cosocket. lua-resty-string library based on LuaJIT FFI. lua-resty-lock library for a nonblocking simple lock API. lua-resty-cookie library for HTTP cookie manipulation. Routing requests to different MySQL queries based on URI arguments Dynamic Routing Based on Redis and Lua Using LuaRocks with ngx_lua Introduction to ngx_lua ngx_devel_kit echo-nginx-module drizzle-nginx-module postgres-nginx-module memc-nginx-module The OpenResty bundle Nginx Systemtap Toolkit Back to TOC Directives lua_load_resty_core lua_capture_error_log lua_use_default_type lua_malloc_trim lua_code_cache lua_thread_cache_max_entries lua_regex_cache_max_entries lua_regex_match_limit lua_package_path lua_package_cpath init_by_lua init_by_lua_block init_by_lua_file init_worker_by_lua init_worker_by_lua_block init_worker_by_lua_file exit_worker_by_lua_block exit_worker_by_lua_file set_by_lua set_by_lua_block set_by_lua_file content_by_lua content_by_lua_block content_by_lua_file rewrite_by_lua rewrite_by_lua_block rewrite_by_lua_file access_by_lua access_by_lua_block access_by_lua_file header_filter_by_lua header_filter_by_lua_block header_filter_by_lua_file body_filter_by_lua body_filter_by_lua_block body_filter_by_lua_file log_by_lua log_by_lua_block log_by_lua_file balancer_by_lua_block balancer_by_lua_file lua_need_request_body ssl_certificate_by_lua_block ssl_certificate_by_lua_file ssl_session_fetch_by_lua_block ssl_session_fetch_by_lua_file ssl_session_store_by_lua_block ssl_session_store_by_lua_file lua_shared_dict lua_socket_connect_timeout lua_socket_send_timeout lua_socket_send_lowat lua_socket_read_timeout lua_socket_buffer_size lua_socket_pool_size lua_socket_keepalive_timeout lua_socket_log_errors lua_ssl_ciphers lua_ssl_crl lua_ssl_protocols lua_ssl_trusted_certificate lua_ssl_verify_depth lua_http10_buffering rewrite_by_lua_no_postpone access_by_lua_no_postpone lua_transform_underscores_in_response_headers lua_check_client_abort lua_max_pending_timers lua_max_running_timers lua_sa_restart The basic building blocks of scripting Nginx with Lua are directives. Directives are used to specify when the user Lua code is run and how the result will be used. Below is a diagram showing the order in which directives are executed. Back to TOC lua_load_resty_core syntax: lua_load_resty_core on|off default: lua_load_resty_core on context: http This directive is deprecated since the v0.10.16 release of this module. The resty.core module from lua-resty-core is now mandatorily loaded during the Lua VM initialization. Specifying this directive will have no effect. This directive was first introduced in the v0.10.15 release and used to optionally load the resty.core module. Back to TOC lua_capture_error_log syntax: lua_capture_error_log size default: none context: http Enables a buffer of the specified size for capturing all the Nginx error log message data (not just those produced by this module or the Nginx http subsystem, but everything) without touching files or disks. You can use units like k and m in the size value, as in As a rule of thumb, a 4KB buffer can usually hold about 20 typical error log messages. So do the maths! This buffer never grows. If it is full, new error log messages will replace the oldest ones in the buffer. The size of the buffer must be bigger than the maximum length of a single error log message (which is 4K in OpenResty and 2K in stock NGINX). You can read the messages in the buffer on the Lua land via the get_logs() function of the ngx.errlog module of the lua-resty-core library. This Lua API function will return the captured error log messages and also remove these already read from the global capturing buffer, making room for any new error log data. For this reason, the user should not configure this buffer to be too big if the user read the buffered error log data fast enough. Note that the log level specified in the standard error_log directive does have effect on this capturing facility. It only captures log messages of a level no lower than the specified log level in the error_log directive. The user can still choose to set an even higher filtering log level on the fly via the Lua API function errlog.set_filter_level. So it is more flexible than the static error_log directive. It is worth noting that there is no way to capture the debugging logs without building OpenResty or Nginx with the ./configure option --with-debug. And enabling debugging logs is strongly discouraged in production builds due to high overhead. This directive was first introduced in the v0.10.9 release. Back to TOC lua_use_default_type syntax: lua_use_default_type on | off default: lua_use_default_type on context: http, server, location, location if Specifies whether to use the MIME type specified by the default_type directive for the default value of the Content-Type response header. Deactivate this directive if a default Content-Type response header for Lua request handlers is not desired. This directive is turned on by default. This directive was first introduced in the v0.9.1 release. Back to TOC lua_malloc_trim syntax: lua_malloc_trim <request-count> default: lua_malloc_trim 1000 context: http Asks the underlying libc runtime library to release its cached free memory back to the operating system every N requests processed by the Nginx core. By default, N is 1000. You can configure the request count by using your own numbers. Smaller numbers mean more frequent releases, which may introduce higher CPU time consumption and smaller memory footprint while larger numbers usually lead to less CPU time overhead and relatively larger memory footprint. Just tune the number for your own use cases. Configuring the argument to 0 essentially turns off the periodical memory trimming altogether. The current implementation uses an Nginx log phase handler to do the request counting. So the appearance of the log_subrequest on directives in nginx.conf may make the counting faster when subrequests are involved. By default, only "main requests" count. Note that this directive does not affect the memory allocated by LuaJIT's own allocator based on the mmap system call. This directive was first introduced in the v0.10.7 release. Back to TOC lua_code_cache syntax: lua_code_cache on | off default: lua_code_cache on context: http, server, location, location if Enables or disables the Lua code cache for Lua code in *_by_lua_file directives (like set_by_lua_file and content_by_lua_file) and Lua modules. When turning off, every request served by ngx_lua will run in a separate Lua VM instance, starting from the 0.9.3 release. So the Lua files referenced in set_by_lua_file, content_by_lua_file, access_by_lua_file, and etc will not be cached and all Lua modules used will be loaded from scratch. With this in place, developers can adopt an edit-and-refresh approach. Please note however, that Lua code written inlined within nginx.conf such as those specified by set_by_lua, content_by_lua, access_by_lua, and rewrite_by_lua will not be updated when you edit the inlined Lua code in your nginx.conf file because only the Nginx config file parser can correctly parse the nginx.conf file and the only way is to reload the config file by sending a HUP signal or just to restart Nginx. Even when the code cache is enabled, Lua files which are loaded by dofile or loadfile in *_by_lua_file cannot be cached (unless you cache the results yourself). Usually you can either use the init_by_lua or init_by_lua_file directives to load all such files or just make these Lua files true Lua modules and load them via require. The ngx_lua module does not support the stat mode available with the Apache mod_lua module (yet). Disabling the Lua code cache is strongly discouraged for production use and should only be used during development as it has a significant negative impact on overall performance. For example, the performance of a "hello world" Lua example can drop by an order of magnitude after disabling the Lua code cache. Back to TOC lua_thread_cache_max_entries syntax: lua_thread_cache_max_entries <num> default: lua_thread_cache_max_entries 1024 context: http Specifies the maximum number of entries allowed in the worker process level lua thread object cache. This cache recycles the lua thread GC objects among all our "light threads". A zero value of <num> disables the cache. Note that this feature requires OpenResty's LuaJIT with the new C API lua_resetthread. This feature was first introduced in verson v0.10.9. Back to TOC lua_regex_cache_max_entries syntax: lua_regex_cache_max_entries <num> default: lua_regex_cache_max_entries 1024 context: http Specifies the maximum number of entries allowed in the worker process level compiled regex cache. The regular expressions used in ngx.re.match, ngx.re.gmatch, ngx.re.sub, and ngx.re.gsub will be cached within this cache if the regex option o (i.e., compile-once flag) is specified. The default number of entries allowed is 1024 and when this limit is reached, new regular expressions will not be cached (as if the o option was not specified) and there will be one, and only one, warning in the error.log file: 2011/08/27 23:18:26 [warn] 31997#0: *1 lua exceeding regex cache max entries (1024), ... If you are using the ngx.re.* implementation of lua-resty-core by loading the resty.core.regex module (or just the resty.core module), then an LRU cache is used for the regex cache being used here. Do not activate the o option for regular expressions (and/or replace string arguments for ngx.re.sub and ngx.re.gsub) that are generated on the fly and give rise to infinite variations to avoid hitting the specified limit. Back to TOC lua_regex_match_limit syntax: lua_regex_match_limit <num> default: lua_regex_match_limit 0 context: http Specifies the "match limit" used by the PCRE library when executing the ngx.re API. To quote the PCRE manpage, "the limit ... has the effect of limiting the amount of backtracking that can take place." When the limit is hit, the error string "pcre_exec() failed: -8" will be returned by the ngx.re API functions on the Lua land. When setting the limit to 0, the default "match limit" when compiling the PCRE library is used. And this is the default value of this directive. This directive was first introduced in the v0.8.5 release. Back to TOC lua_package_path syntax: lua_package_path <lua-style-path-str> default: The content of LUA_PATH environment variable or Lua's compiled-in defaults. context: http Sets the Lua module search path used by scripts specified by set_by_lua, content_by_lua and others. The path string is in standard Lua path form, and ;; can be used to stand for the original search paths. As from the v0.5.0rc29 release, the special notation $prefix or ${prefix} can be used in the search path string to indicate the path of the server prefix usually determined by the -p PATH command-line option while starting the Nginx server. Back to TOC lua_package_cpath syntax: lua_package_cpath <lua-style-cpath-str> default: The content of LUA_CPATH environment variable or Lua's compiled-in defaults. context: http Sets the Lua C-module search path used by scripts specified by set_by_lua, content_by_lua and others. The cpath string is in standard Lua cpath form, and ;; can be used to stand for the original cpath. As from the v0.5.0rc29 release, the special notation $prefix or ${prefix} can be used in the search path string to indicate the path of the server prefix usually determined by the -p PATH command-line option while starting the Nginx server. Back to TOC init_by_lua syntax: init_by_lua <lua-script-str> context: http phase: loading-config NOTE Use of this directive is discouraged following the v0.9.17 release. Use the init_by_lua_block directive instead. Runs the Lua code specified by the argument <lua-script-str> on the global Lua VM level when the Nginx master process (if any) is loading the Nginx config file. When Nginx receives the HUP signal and starts reloading the config file, the Lua VM will also be re-created and init_by_lua will run again on the new Lua VM. In case that the lua_code_cache directive is turned off (default on), the init_by_lua handler will run upon every request because in this special mode a standalone Lua VM is always created for each request. Usually you can pre-load Lua modules at server start-up by means of this hook and take advantage of modern operating systems' copy-on-write (COW) optimization. Here is an example for pre-loading Lua modules: You can also initialize the lua_shared_dict shm storage at this phase. Here is an example for this: But note that, the lua_shared_dict's shm storage will not be cleared through a config reload (via the HUP signal, for example). So if you do not want to re-initialize the shm storage in your init_by_lua code in this case, then you just need to set a custom flag in the shm storage and always check the flag in your init_by_lua code. Because the Lua code in this context runs before Nginx forks its worker processes (if any), data or code loaded here will enjoy the Copy-on-write (COW) feature provided by many operating systems among all the worker processes, thus saving a lot of memory. Do not initialize your own Lua global variables in this context because use of Lua global variables have performance penalties and can lead to global namespace pollution (see the Lua Variable Scope section for more details). The recommended way is to use proper Lua module files (but do not use the standard Lua function module() to define Lua modules because it pollutes the global namespace as well) and call require() to load your own module files in init_by_lua or other contexts (require() does cache the loaded Lua modules in the global package.loaded table in the Lua registry so your modules will only loaded once for the whole Lua VM instance). Only a small set of the Nginx API for Lua is supported in this context: Logging APIs: ngx.log and print, Shared Dictionary API: ngx.shared.DICT. More Nginx APIs for Lua may be supported in this context upon future user requests. Basically you can safely use Lua libraries that do blocking I/O in this very context because blocking the master process during server start-up is completely okay. Even the Nginx core does blocking I/O (at least on resolving upstream's host names) at the configure-loading phase. You should be very careful about potential security vulnerabilities in your Lua code registered in this context because the Nginx master process is often run under the root account. This directive was first introduced in the v0.5.5 release. See also the following blog posts for more details on OpenResty and Nginx's shared memory zones: How OpenResty and Nginx Shared Memory Zones Consume RAM Memory Fragmentation in OpenResty and Nginx's Shared Memory Zones Back to TOC init_by_lua_block syntax: init_by_lua_block { lua-script } context: http phase: loading-config Similar to the init_by_lua directive except that this directive inlines the Lua source directly inside a pair of curly braces ({}) instead of in an Nginx string literal (which requires special character escaping). For instance, This directive was first introduced in the v0.9.17 release. Back to TOC init_by_lua_file syntax: init_by_lua_file <path-to-lua-script-file> context: http phase: loading-config Equivalent to init_by_lua, except that the file specified by <path-to-lua-script-file> contains the Lua code or LuaJIT bytecode to be executed. When a relative path like foo/bar.lua is given, they will be turned into the absolute path relative to the server prefix path determined by the -p PATH command-line option while starting the Nginx server. This directive was first introduced in the v0.5.5 release. Back to TOC init_worker_by_lua syntax: init_worker_by_lua <lua-script-str> context: http phase: starting-worker NOTE Use of this directive is discouraged following the v0.9.17 release. Use the init_worker_by_lua_block directive instead. Runs the specified Lua code upon every Nginx worker process's startup when the master process is enabled. When the master process is disabled, this hook will just run after init_by_lua*. This hook is often used to create per-worker reoccurring timers (via the ngx.timer.at Lua API), either for backend health-check or other timed routine work. Below is an example, This directive was first introduced in the v0.9.5 release. This hook no longer runs in the cache manager and cache loader processes since the v0.10.12 release. Back to TOC init_worker_by_lua_block syntax: init_worker_by_lua_block { lua-script } context: http phase: starting-worker Similar to the init_worker_by_lua directive except that this directive inlines the Lua source directly inside a pair of curly braces ({}) instead of in an Nginx string literal (which requires special character escaping). For instance, This directive was first introduced in the v0.9.17 release. This hook no longer runs in the cache manager and cache loader processes since the v0.10.12 release. Back to TOC init_worker_by_lua_file syntax: init_worker_by_lua_file <lua-file-path> context: http phase: starting-worker Similar to init_worker_by_lua, but accepts the file path to a Lua source file or Lua bytecode file. This directive was first introduced in the v0.9.5 release. This hook no longer runs in the cache manager and cache loader processes since the v0.10.12 release. Back to TOC exit_worker_by_lua_block syntax: exit_worker_by_lua_block { lua-script } context: http phase: exiting-worker Runs the specified Lua code upon every Nginx worker process's exit when the master process is enabled. When the master process is disabled, this hook will run before the Nginx process exits. This hook is often used to release resources allocated by each worker (e.g. resources allocated by init_worker_by_lua*), or to prevent workers from exiting abnormally. For example, This directive was first introduced in the v0.10.18 release. Back to TOC exit_worker_by_lua_file syntax: exit_worker_by_lua_file <path-to-lua-script-file> context: http phase: exiting-worker Similar to exit_worker_by_lua_block, but accepts the file path to a Lua source file or Lua bytecode file. This directive was first introduced in the v0.10.18 release. Back to TOC set_by_lua syntax: set_by_lua $res <lua-script-str> [$arg1 $arg2 ...] context: server, server if, location, location if phase: rewrite NOTE Use of this directive is discouraged following the v0.9.17 release. Use the set_by_lua_block directive instead. Executes code specified in <lua-script-str> with optional input arguments $arg1 $arg2 ..., and returns string output to $res. The code in <lua-script-str> can make API calls and can retrieve input arguments from the ngx.arg table (index starts from 1 and increases sequentially). This directive is designed to execute short, fast running code blocks as the Nginx event loop is blocked during code execution. Time consuming code sequences should therefore be avoided. This directive is implemented by injecting custom commands into the standard ngx_http_rewrite_module's command list. Because ngx_http_rewrite_module does not support nonblocking I/O in its commands, Lua APIs requiring yielding the current Lua "light thread" cannot work in this directive. At least the following API functions are currently disabled within the context of set_by_lua: Output API functions (e.g., ngx.say and ngx.send_headers) Control API functions (e.g., ngx.exit) Subrequest API functions (e.g., ngx.location.capture and ngx.location.capture_multi) Cosocket API functions (e.g., ngx.socket.tcp and ngx.req.socket). Sleeping API function ngx.sleep. In addition, note that this directive can only write out a value to a single Nginx variable at a time. However, a workaround is possible using the ngx.var.VARIABLE interface. This directive can be freely mixed with all directives of the ngx_http_rewrite_module, set-misc-nginx-module, and array-var-nginx-module modules. All of these directives will run in the same order as they appear in the config file. As from the v0.5.0rc29 release, Nginx variable interpolation is disabled in the <lua-script-str> argument of this directive and therefore, the dollar sign character ($) can be used directly. This directive requires the ngx_devel_kit module. Back to TOC set_by_lua_block syntax: set_by_lua_block $res { lua-script } context: server, server if, location, location if phase: rewrite Similar to the set_by_lua directive except that this directive inlines the Lua source directly inside a pair of curly braces ({}) instead of in an Nginx string literal (which requires special character escaping), and this directive does not support extra arguments after the Lua script as in set_by_lua. For example, No special escaping is required in the Lua code block. This directive was first introduced in the v0.9.17 release. Back to TOC set_by_lua_file syntax: set_by_lua_file $res <path-to-lua-script-file> [$arg1 $arg2 ...] context: server, server if, location, location if phase: rewrite Equivalent to set_by_lua, except that the file specified by <path-to-lua-script-file> contains the Lua code, or, as from the v0.5.0rc32 release, the LuaJIT bytecode to be executed. Nginx variable interpolation is supported in the <path-to-lua-script-file> argument string of this directive. But special care must be taken for injection attacks. When a relative path like foo/bar.lua is given, they will be turned into the absolute path relative to the server prefix path determined by the -p PATH command-line option while starting the Nginx server. When the Lua code cache is turned on (by default), the user code is loaded once at the first request and cached and the Nginx config must be reloaded each time the Lua source file is modified. The Lua code cache can be temporarily disabled during development by switching lua_code_cache off in nginx.conf to avoid reloading Nginx. This directive requires the ngx_devel_kit module. Back to TOC content_by_lua syntax: content_by_lua <lua-script-str> context: location, location if phase: content NOTE Use of this directive is discouraged following the v0.9.17 release. Use the content_by_lua_block directive instead. Acts as a "content handler" and executes Lua code string specified in <lua-script-str> for every request. The Lua code may make API calls and is executed as a new spawned coroutine in an independent global environment (i.e. a sandbox). Do not use this directive and other content handler directives in the same location. For example, this directive and the proxy_pass directive should not be used in the same location. Back to TOC content_by_lua_block syntax: content_by_lua_block { lua-script } context: location, location if phase: content Similar to the content_by_lua directive except that this directive inlines the Lua source directly inside a pair of curly braces ({}) instead of in an Nginx string literal (which requires special character escaping). For instance, This directive was first introduced in the v0.9.17 release. Back to TOC content_by_lua_file syntax: content_by_lua_file <path-to-lua-script-file> context: location, location if phase: content Equivalent to content_by_lua, except that the file specified by <path-to-lua-script-file> contains the Lua code, or, as from the v0.5.0rc32 release, the LuaJIT bytecode to be executed. Nginx variables can be used in the <path-to-lua-script-file> string to provide flexibility. This however carries some risks and is not ordinarily recommended. When a relative path like foo/bar.lua is given, they will be turned into the absolute path relative to the server prefix path determined by the -p PATH command-line option while starting the Nginx server. When the Lua code cache is turned on (by default), the user code is loaded once at the first request and cached and the Nginx config must be reloaded each time the Lua source file is modified. The Lua code cache can be temporarily disabled during development by switching lua_code_cache off in nginx.conf to avoid reloading Nginx. Nginx variables are supported in the file path for dynamic dispatch, for example: But be very careful about malicious user inputs and always carefully validate or filter out the user-supplied path components. Back to TOC rewrite_by_lua syntax: rewrite_by_lua <lua-script-str> context: http, server, location, location if phase: rewrite tail NOTE Use of this directive is discouraged following the v0.9.17 release. Use the rewrite_by_lua_block directive instead. Acts as a rewrite phase handler and executes Lua code string specified in <lua-script-str> for every request. The Lua code may make API calls and is executed as a new spawned coroutine in an independent global environment (i.e. a sandbox). Note that this handler always runs after the standard ngx_http_rewrite_module. So the following will work as expected: because set $a 12 and set $b "" run before rewrite_by_lua. On the other hand, the following will not work as expected: because if runs before rewrite_by_lua even if it is placed after rewrite_by_lua in the config. The right way of doing this is as follows: Note that the ngx_eval module can be approximated by using rewrite_by_lua. For example, can be implemented in ngx_lua as: Just as any other rewrite phase handlers, rewrite_by_lua also runs in subrequests. Note that when calling ngx.exit(ngx.OK) within a rewrite_by_lua handler, the Nginx request processing control flow will still continue to the content handler. To terminate the current request from within a rewrite_by_lua handler, call ngx.exit with status >= 200 (ngx.HTTP_OK) and status < 300 (ngx.HTTP_SPECIAL_RESPONSE) for successful quits and ngx.exit(ngx.HTTP_INTERNAL_SERVER_ERROR) (or its friends) for failures. If the ngx_http_rewrite_module's rewrite directive is used to change the URI and initiate location re-lookups (internal redirections), then any rewrite_by_lua or rewrite_by_lua_file code sequences within the current location will not be executed. For example, Here the Lua code ngx.exit(503) will never run. This will be the case if rewrite ^ /bar last is used as this will similarly initiate an internal redirection. If the break modifier is used instead, there will be no internal redirection and the rewrite_by_lua code will be executed. The rewrite_by_lua code will always run at the end of the rewrite request-processing phase unless rewrite_by_lua_no_postpone is turned on. Back to TOC rewrite_by_lua_block syntax: rewrite_by_lua_block { lua-script } context: http, server, location, location if phase: rewrite tail Similar to the rewrite_by_lua directive except that this directive inlines the Lua source directly inside a pair of curly braces ({}) instead of in an Nginx string literal (which requires special character escaping). For instance, This directive was first introduced in the v0.9.17 release. Back to TOC rewrite_by_lua_file syntax: rewrite_by_lua_file <path-to-lua-script-file> context: http, server, location, location if phase: rewrite tail Equivalent to rewrite_by_lua, except that the file specified by <path-to-lua-script-file> contains the Lua code, or, as from the v0.5.0rc32 release, the LuaJIT bytecode to be executed. Nginx variables can be used in the <path-to-lua-script-file> string to provide flexibility. This however carries some risks and is not ordinarily recommended. When a relative path like foo/bar.lua is given, they will be turned into the absolute path relative to the server prefix path determined by the -p PATH command-line option while starting the Nginx server. When the Lua code cache is turned on (by default), the user code is loaded once at the first request and cached and the Nginx config must be reloaded each time the Lua source file is modified. The Lua code cache can be temporarily disabled during development by switching lua_code_cache off in nginx.conf to avoid reloading Nginx. The rewrite_by_lua_file code will always run at the end of the rewrite request-processing phase unless rewrite_by_lua_no_postpone is turned on. Nginx variables are supported in the file path for dynamic dispatch just as in content_by_lua_file. Back to TOC access_by_lua syntax: access_by_lua <lua-script-str> context: http, server, location, location if phase: access tail NOTE Use of this directive is discouraged following the v0.9.17 release. Use the access_by_lua_block directive instead. Acts as an access phase handler and executes Lua code string specified in <lua-script-str> for every request. The Lua code may make API calls and is executed as a new spawned coroutine in an independent global environment (i.e. a sandbox). Note that this handler always runs after the standard ngx_http_access_module. So the following will work as expected: That is, if a client IP address is in the blacklist, it will be denied before the MySQL query for more complex authentication is executed by access_by_lua. Note that the ngx_auth_request module can be approximated by using access_by_lua: can be implemented in ngx_lua as: As with other access phase handlers, access_by_lua will not run in subrequests. Note that when calling ngx.exit(ngx.OK) within a access_by_lua handler, the Nginx request processing control flow will still continue to the content handler. To terminate the current request from within a access_by_lua handler, call ngx.exit with status >= 200 (ngx.HTTP_OK) and status < 300 (ngx.HTTP_SPECIAL_RESPONSE) for successful quits and ngx.exit(ngx.HTTP_INTERNAL_SERVER_ERROR) (or its friends) for failures. Starting from the v0.9.20 release, you can use the access_by_lua_no_postpone directive to control when to run this handler inside the "access" request-processing phase of Nginx. Back to TOC access_by_lua_block syntax: access_by_lua_block { lua-script } context: http, server, location, location if phase: access tail Similar to the access_by_lua directive except that this directive inlines the Lua source directly inside a pair of curly braces ({}) instead of in an Nginx string literal (which requires special character escaping). For instance, This directive was first introduced in the v0.9.17 release. Back to TOC access_by_lua_file syntax: access_by_lua_file <path-to-lua-script-file> context: http, server, location, location if phase: access tail Equivalent to access_by_lua, except that the file specified by <path-to-lua-script-file> contains the Lua code, or, as from the v0.5.0rc32 release, the LuaJIT bytecode to be executed. Nginx variables can be used in the <path-to-lua-script-file> string to provide flexibility. This however carries some risks and is not ordinarily recommended. When a relative path like foo/bar.lua is given, they will be turned into the absolute path relative to the server prefix path determined by the -p PATH command-line option while starting the Nginx server. When the Lua code cache is turned on (by default), the user code is loaded once at the first request and cached and the Nginx config must be reloaded each time the Lua source file is modified. The Lua code cache can be temporarily disabled during development by switching lua_code_cache off in nginx.conf to avoid repeatedly reloading Nginx. Nginx variables are supported in the file path for dynamic dispatch just as in content_by_lua_file. Back to TOC header_filter_by_lua syntax: header_filter_by_lua <lua-script-str> context: http, server, location, location if phase: output-header-filter NOTE Use of this directive is discouraged following the v0.9.17 release. Use the header_filter_by_lua_block directive instead. Uses Lua code specified in <lua-script-str> to define an output header filter. Note that the following API functions are currently disabled within this context: Output API functions (e.g., ngx.say and ngx.send_headers) Control API functions (e.g., ngx.redirect and ngx.exec) Subrequest API functions (e.g., ngx.location.capture and ngx.location.capture_multi) Cosocket API functions (e.g., ngx.socket.tcp and ngx.req.socket). Here is an example of overriding a response header (or adding one if absent) in our Lua header filter: This directive was first introduced in the v0.2.1rc20 release. Back to TOC header_filter_by_lua_block syntax: header_filter_by_lua_block { lua-script } context: http, server, location, location if phase: output-header-filter Similar to the header_filter_by_lua directive except that this directive inlines the Lua source directly inside a pair of curly braces ({}) instead of in an Nginx string literal (which requires special character escaping). For instance, This directive was first introduced in the v0.9.17 release. Back to TOC header_filter_by_lua_file syntax: header_filter_by_lua_file <path-to-lua-script-file> context: http, server, location, location if phase: output-header-filter Equivalent to header_filter_by_lua, except that the file specified by <path-to-lua-script-file> contains the Lua code, or as from the v0.5.0rc32 release, the LuaJIT bytecode to be executed. When a relative path like foo/bar.lua is given, they will be turned into the absolute path relative to the server prefix path determined by the -p PATH command-line option while starting the Nginx server. This directive was first introduced in the v0.2.1rc20 release. Back to TOC body_filter_by_lua syntax: body_filter_by_lua <lua-script-str> context: http, server, location, location if phase: output-body-filter NOTE Use of this directive is discouraged following the v0.9.17 release. Use the body_filter_by_lua_block directive instead. Uses Lua code specified in <lua-script-str> to define an output body filter. The input data chunk is passed via ngx.arg[1] (as a Lua string value) and the "eof" flag indicating the end of the response body data stream is passed via ngx.arg[2] (as a Lua boolean value). Behind the scene, the "eof" flag is just the last_buf (for main requests) or last_in_chain (for subrequests) flag of the Nginx chain link buffers. (Before the v0.7.14 release, the "eof" flag does not work at all in subrequests.) The output data stream can be aborted immediately by running the following Lua statement: This will truncate the response body and usually result in incomplete and also invalid responses. The Lua code can pass its own modified version of the input data chunk to the downstream Nginx output body filters by overriding ngx.arg[1] with a Lua string or a Lua table of strings. For example, to transform all the lowercase letters in the response body, we can just write: When setting nil or an empty Lua string value to ngx.arg[1], no data chunk will be passed to the downstream Nginx output filters at all. Likewise, new "eof" flag can also be specified by setting a boolean value to ngx.arg[2]. For example, Then GET /t will just return the output hello world That is, when the body filter sees a chunk containing the word "hello", then it will set the "eof" flag to true immediately, resulting in truncated but still valid responses. When the Lua code may change the length of the response body, then it is required to always clear out the Content-Length response header (if any) in a header filter to enforce streaming output, as in Note that the following API functions are currently disabled within this context due to the limitations in Nginx output filter's current implementation: Output API functions (e.g., ngx.say and ngx.send_headers) Control API functions (e.g., ngx.exit and ngx.exec) Subrequest API functions (e.g., ngx.location.capture and ngx.location.capture_multi) Cosocket API functions (e.g., ngx.socket.tcp and ngx.req.socket). Nginx output filters may be called multiple times for a single request because response body may be delivered in chunks. Thus, the Lua code specified by in this directive may also run multiple times in the lifetime of a single HTTP request. This directive was first introduced in the v0.5.0rc32 release. Back to TOC body_filter_by_lua_block syntax: body_filter_by_lua_block { lua-script-str } context: http, server, location, location if phase: output-body-filter Similar to the body_filter_by_lua directive except that this directive inlines the Lua source directly inside a pair of curly braces ({}) instead of in an Nginx string literal (which requires special character escaping). For instance, This directive was first introduced in the v0.9.17 release. Back to TOC body_filter_by_lua_file syntax: body_filter_by_lua_file <path-to-lua-script-file> context: http, server, location, location if phase: output-body-filter Equivalent to body_filter_by_lua, except that the file specified by <path-to-lua-script-file> contains the Lua code, or, as from the v0.5.0rc32 release, the LuaJIT bytecode to be executed. When a relative path like foo/bar.lua is given, they will be turned into the absolute path relative to the server prefix path determined by the -p PATH command-line option while starting the Nginx server. This directive was first introduced in the v0.5.0rc32 release. Back to TOC log_by_lua syntax: log_by_lua <lua-script-str> context: http, server, location, location if phase: log NOTE Use of this directive is discouraged following the v0.9.17 release. Use the log_by_lua_block directive instead. Runs the Lua source code inlined as the <lua-script-str> at the log request processing phase. This does not replace the current access logs, but runs before. Note that the following API functions are currently disabled within this context: Output API functions (e.g., ngx.say and ngx.send_headers) Control API functions (e.g., ngx.exit) Subrequest API functions (e.g., ngx.location.capture and ngx.location.capture_multi) Cosocket API functions (e.g., ngx.socket.tcp and ngx.req.socket). Here is an example of gathering average data for $upstream_response_time: This directive was first introduced in the v0.5.0rc31 release. Back to TOC log_by_lua_block syntax: log_by_lua_block { lua-script } context: http, server, location, location if phase: log Similar to the log_by_lua directive except that this directive inlines the Lua source directly inside a pair of curly braces ({}) instead of in an Nginx string literal (which requires special character escaping). For instance, This directive was first introduced in the v0.9.17 release. Back to TOC log_by_lua_file syntax: log_by_lua_file <path-to-lua-script-file> context: http, server, location, location if phase: log Equivalent to log_by_lua, except that the file specified by <path-to-lua-script-file> contains the Lua code, or, as from the v0.5.0rc32 release, the LuaJIT bytecode to be executed. When a relative path like foo/bar.lua is given, they will be turned into the absolute path relative to the server prefix path determined by the -p PATH command-line option while starting the Nginx server. This directive was first introduced in the v0.5.0rc31 release. Back to TOC balancer_by_lua_block syntax: balancer_by_lua_block { lua-script } context: upstream phase: content This directive runs Lua code as an upstream balancer for any upstream entities defined by the upstream {} configuration block. For instance, The resulting Lua load balancer can work with any existing Nginx upstream modules like ngx_proxy and ngx_fastcgi. Also, the Lua load balancer can work with the standard upstream connection pool mechanism, i.e., the standard keepalive directive. Just ensure that the keepalive directive is used after this balancer_by_lua_block directive in a single upstream {} configuration block. The Lua load balancer can totally ignore the list of servers defined in the upstream {} block and select peer from a completely dynamic server list (even changing per request) via the ngx.balancer module from the lua-resty-core library. The Lua code handler registered by this directive might get called more than once in a single downstream request when the Nginx upstream mechanism retries the request on conditions specified by directives like the proxy_next_upstream directive. This Lua code execution context does not support yielding, so Lua APIs that may yield (like cosockets and "light threads") are disabled in this context. One can usually work around this limitation by doing such operations in an earlier phase handler (like access_by_lua*) and passing along the result into this context via the ngx.ctx table. This directive was first introduced in the v0.10.0 release. Back to TOC balancer_by_lua_file syntax: balancer_by_lua_file <path-to-lua-script-file> context: upstream phase: content Equivalent to balancer_by_lua_block, except that the file specified by <path-to-lua-script-file> contains the Lua code, or, as from the v0.5.0rc32 release, the LuaJIT bytecode to be executed. When a relative path like foo/bar.lua is given, they will be turned into the absolute path relative to the server prefix path determined by the -p PATH command-line option while starting the Nginx server. This directive was first introduced in the v0.10.0 release. Back to TOC lua_need_request_body syntax: lua_need_request_body <on|off> default: off context: http, server, location, location if phase: depends on usage Determines whether to force the request body data to be read before running rewrite/access/content_by_lua* or not. The Nginx core does not read the client request body by default and if request body data is required, then this directive should be turned on or the ngx.req.read_body function should be called within the Lua code. To read the request body data within the $request_body variable, client_body_buffer_size must have the same value as client_max_body_size. Because when the content length exceeds client_body_buffer_size but less than client_max_body_size, Nginx will buffer the data into a temporary file on the disk, which will lead to empty value in the $request_body variable. If the current location includes rewrite_by_lua* directives, then the request body will be read just before the rewrite_by_lua* code is run (and also at the rewrite phase). Similarly, if only content_by_lua is specified, the request body will not be read until the content handler's Lua code is about to run (i.e., the request body will be read during the content phase). It is recommended however, to use the ngx.req.read_body and ngx.req.discard_body functions for finer control over the request body reading process instead. This also applies to access_by_lua*. Back to TOC ssl_certificate_by_lua_block syntax: ssl_certificate_by_lua_block { lua-script } context: server phase: right-before-SSL-handshake This directive runs user Lua code when Nginx is about to start the SSL handshake for the downstream SSL (https) connections. It is particularly useful for setting the SSL certificate chain and the corresponding private key on a per-request basis. It is also useful to load such handshake configurations nonblockingly from the remote (for example, with the cosocket API). And one can also do per-request OCSP stapling handling in pure Lua here as well. Another typical use case is to do SSL handshake traffic control nonblockingly in this context, with the help of the lua-resty-limit-traffic#readme library, for example. One can also do interesting things with the SSL handshake requests from the client side, like rejecting old SSL clients using the SSLv3 protocol or even below selectively. The ngx.ssl and ngx.ocsp Lua modules provided by the lua-resty-core library are particularly useful in this context. You can use the Lua API offered by these two Lua modules to manipulate the SSL certificate chain and private key for the current SSL connection being initiated. This Lua handler does not run at all, however, when Nginx/OpenSSL successfully resumes the SSL session via SSL session IDs or TLS session tickets for the current SSL connection. In other words, this Lua handler only runs when Nginx has to initiate a full SSL handshake. Below is a trivial example using the ngx.ssl module at the same time: See more complicated examples in the ngx.ssl and ngx.ocsp Lua modules' official documentation. Uncaught Lua exceptions in the user Lua code immediately abort the current SSL session, so does the ngx.exit call with an error code like ngx.ERROR. This Lua code execution context does support yielding, so Lua APIs that may yield (like cosockets, sleeping, and "light threads") are enabled in this context. Note, however, you still need to configure the ssl_certificate and ssl_certificate_key directives even though you will not use this static certificate and private key at all. This is because the NGINX core requires their appearance otherwise you are seeing the following error while starting NGINX: nginx: [emerg] no ssl configured for the server This directive requires OpenSSL 1.0.2e or greater. If you are using the official pre-built packages for OpenResty 1.9.7.2 or later, then everything should work out of the box. If you are not using one of the OpenSSL packages provided by OpenResty, you will need to apply patches to OpenSSL in order to use this directive: https://openresty.org/en/openssl-patches.html Similarly, if you are not using the Nginx core shipped with OpenResty 1.9.7.2 or later, you will need to apply patches to the standard Nginx core: https://openresty.org/en/nginx-ssl-patches.html This directive was first introduced in the v0.10.0 release. Back to TOC ssl_certificate_by_lua_file syntax: ssl_certificate_by_lua_file <path-to-lua-script-file> context: server phase: right-before-SSL-handshake Equivalent to ssl_certificate_by_lua_block, except that the file specified by <path-to-lua-script-file> contains the Lua code, or, as from the v0.5.0rc32 release, the LuaJIT bytecode to be executed. When a relative path like foo/bar.lua is given, they will be turned into the absolute path relative to the server prefix path determined by the -p PATH command-line option while starting the Nginx server. This directive was first introduced in the v0.10.0 release. Back to TOC ssl_session_fetch_by_lua_block syntax: ssl_session_fetch_by_lua_block { lua-script } context: http phase: right-before-SSL-handshake This directive runs Lua code to look up and load the SSL session (if any) according to the session ID provided by the current SSL handshake request for the downstream. The Lua API for obtaining the current session ID and loading a cached SSL session data is provided in the ngx.ssl.session Lua module shipped with the lua-resty-core library. Lua APIs that may yield, like ngx.sleep and cosockets, are enabled in this context. This hook, together with the ssl_session_store_by_lua* hook, can be used to implement distributed caching mechanisms in pure Lua (based on the cosocket API, for example). If a cached SSL session is found and loaded into the current SSL connection context, SSL session resumption can then get immediately initiated and bypass the full SSL handshake process which is very expensive in terms of CPU time. Please note that TLS session tickets are very different and it is the clients' responsibility to cache the SSL session state when session tickets are used. SSL session resumptions based on TLS session tickets would happen automatically without going through this hook (nor the ssl_session_store_by_lua* hook). This hook is mainly for older or less capable SSL clients that can only do SSL sessions by session IDs. When ssl_certificate_by_lua* is specified at the same time, this hook usually runs before ssl_certificate_by_lua*. When the SSL session is found and successfully loaded for the current SSL connection, SSL session resumption will happen and thus bypass the ssl_certificate_by_lua* hook completely. In this case, Nginx also bypasses the ssl_session_store_by_lua* hook, for obvious reasons. To easily test this hook locally with a modern web browser, you can temporarily put the following line in your https server block to disable the TLS session ticket support: ssl_session_tickets off; But do not forget to comment this line out before publishing your site to the world. If you are using the official pre-built packages for OpenResty 1.11.2.1 or later, then everything should work out of the box. If you are not using one of the OpenSSL packages provided by OpenResty, you will need to apply patches to OpenSSL in order to use this directive: https://openresty.org/en/openssl-patches.html Similarly, if you are not using the Nginx core shipped with OpenResty 1.11.2.1 or later, you will need to apply patches to the standard Nginx core: https://openresty.org/en/nginx-ssl-patches.html This directive was first introduced in the v0.10.6 release. Note that this directive can only be used in the http context starting with the v0.10.7 release since SSL session resumption happens before server name dispatch. Back to TOC ssl_session_fetch_by_lua_file syntax: ssl_session_fetch_by_lua_file <path-to-lua-script-file> context: http phase: right-before-SSL-handshake Equivalent to ssl_session_fetch_by_lua_block, except that the file specified by <path-to-lua-script-file> contains the Lua code, or rather, the LuaJIT bytecode to be executed. When a relative path like foo/bar.lua is given, they will be turned into the absolute path relative to the server prefix path determined by the -p PATH command-line option while starting the Nginx server. This directive was first introduced in the v0.10.6 release. Note that: this directive is only allowed to used in http context from the v0.10.7 release (because SSL session resumption happens before server name dispatch). Back to TOC ssl_session_store_by_lua_block syntax: ssl_session_store_by_lua_block { lua-script } context: http phase: right-after-SSL-handshake This directive runs Lua code to fetch and save the SSL session (if any) according to the session ID provided by the current SSL handshake request for the downstream. The saved or cached SSL session data can be used for future SSL connections to resume SSL sessions without going through the full SSL handshake process (which is very expensive in terms of CPU time). Lua APIs that may yield, like ngx.sleep and cosockets, are disabled in this context. You can still, however, use the ngx.timer.at API to create 0-delay timers to save the SSL session data asynchronously to external services (like redis or memcached). The Lua API for obtaining the current session ID and the associated session state data is provided in the ngx.ssl.session Lua module shipped with the lua-resty-core library. To easily test this hook locally with a modern web browser, you can temporarily put the following line in your https server block to disable the TLS session ticket support: ssl_session_tickets off; But do not forget to comment this line out before publishing your site to the world. This directive was first introduced in the v0.10.6 release. Note that: this directive is only allowed to used in http context from the v0.10.7 release (because SSL session resumption happens before server name dispatch). Back to TOC ssl_session_store_by_lua_file syntax: ssl_session_store_by_lua_file <path-to-lua-script-file> context: http phase: right-after-SSL-handshake Equivalent to ssl_session_store_by_lua_block, except that the file specified by <path-to-lua-script-file> contains the Lua code, or rather, the LuaJIT bytecode to be executed. When a relative path like foo/bar.lua is given, they will be turned into the absolute path relative to the server prefix path determined by the -p PATH command-line option while starting the Nginx server. This directive was first introduced in the v0.10.6 release. Note that: this directive is only allowed to used in http context from the v0.10.7 release (because SSL session resumption happens before server name dispatch). Back to TOC lua_shared_dict syntax: lua_shared_dict <name> <size> default: no context: http phase: depends on usage Declares a shared memory zone, <name>, to serve as storage for the shm based Lua dictionary ngx.shared.<name>. Shared memory zones are always shared by all the Nginx worker processes in the current Nginx server instance. The <size> argument accepts size units such as k and m: The hard-coded minimum size is 8KB while the practical minimum size depends on actual user data set (some people start with 12KB). See ngx.shared.DICT for details. This directive was first introduced in the v0.3.1rc22 release. Back to TOC lua_socket_connect_timeout syntax: lua_socket_connect_timeout <time> default: lua_socket_connect_timeout 60s context: http, server, location This directive controls the default timeout value used in TCP/unix-domain socket object's connect method and can be overridden by the settimeout or settimeouts methods. The <time> argument can be an integer, with an optional time unit, like s (second), ms (millisecond), m (minute). The default time unit is s, i.e., "second". The default setting is 60s. This directive was first introduced in the v0.5.0rc1 release. Back to TOC lua_socket_send_timeout syntax: lua_socket_send_timeout <time> default: lua_socket_send_timeout 60s context: http, server, location Controls the default timeout value used in TCP/unix-domain socket object's send method and can be overridden by the settimeout or settimeouts methods. The <time> argument can be an integer, with an optional time unit, like s (second), ms (millisecond), m (minute). The default time unit is s, i.e., "second". The default setting is 60s. This directive was first introduced in the v0.5.0rc1 release. Back to TOC lua_socket_send_lowat syntax: lua_socket_send_lowat <size> default: lua_socket_send_lowat 0 context: http, server, location Controls the lowat (low water) value for the cosocket send buffer. Back to TOC lua_socket_read_timeout syntax: lua_socket_read_timeout <time> default: lua_socket_read_timeout 60s context: http, server, location phase: depends on usage This directive controls the default timeout value used in TCP/unix-domain socket object's receive method and iterator functions returned by the receiveuntil method. This setting can be overridden by the settimeout or settimeouts methods. The <time> argument can be an integer, with an optional time unit, like s (second), ms (millisecond), m (minute). The default time unit is s, i.e., "second". The default setting is 60s. This directive was first introduced in the v0.5.0rc1 release. Back to TOC lua_socket_buffer_size syntax: lua_socket_buffer_size <size> default: lua_socket_buffer_size 4k/8k context: http, server, location Specifies the buffer size used by cosocket reading operations. This buffer does not have to be that big to hold everything at the same time because cosocket supports 100% non-buffered reading and parsing. So even 1 byte buffer size should still work everywhere but the performance could be terrible. This directive was first introduced in the v0.5.0rc1 release. Back to TOC lua_socket_pool_size syntax: lua_socket_pool_size <size> default: lua_socket_pool_size 30 context: http, server, location Specifies the size limit (in terms of connection count) for every cosocket connection pool associated with every remote server (i.e., identified by either the host-port pair or the unix domain socket file path). Default to 30 connections for every pool. When the connection pool exceeds the available size limit, the least recently used (idle) connection already in the pool will be closed to make room for the current connection. Note that the cosocket connection pool is per Nginx worker process rather than per Nginx server instance, so size limit specified here also applies to every single Nginx worker process. This directive was first introduced in the v0.5.0rc1 release. Back to TOC lua_socket_keepalive_timeout syntax: lua_socket_keepalive_timeout <time> default: lua_socket_keepalive_timeout 60s context: http, server, location This directive controls the default maximal idle time of the connections in the cosocket built-in connection pool. When this timeout reaches, idle connections will be closed and removed from the pool. This setting can be overridden by cosocket objects' setkeepalive method. The <time> argument can be an integer, with an optional time unit, like s (second), ms (millisecond), m (minute). The default time unit is s, i.e., "second". The default setting is 60s. This directive was first introduced in the v0.5.0rc1 release. Back to TOC lua_socket_log_errors syntax: lua_socket_log_errors on|off default: lua_socket_log_errors on context: http, server, location This directive can be used to toggle error logging when a failure occurs for the TCP or UDP cosockets. If you are already doing proper error handling and logging in your Lua code, then it is recommended to turn this directive off to prevent data flushing in your Nginx error log files (which is usually rather expensive). This directive was first introduced in the v0.5.13 release. Back to TOC lua_ssl_ciphers syntax: lua_ssl_ciphers <ciphers> default: lua_ssl_ciphers DEFAULT context: http, server, location Specifies the enabled ciphers for requests to a SSL/TLS server in the tcpsock:sslhandshake method. The ciphers are specified in the format understood by the OpenSSL library. The full list can be viewed using the openssl ciphers command. This directive was first introduced in the v0.9.11 release. Back to TOC lua_ssl_crl syntax: lua_ssl_crl <file> default: no context: http, server, location Specifies a file with revoked certificates (CRL) in the PEM format used to verify the certificate of the SSL/TLS server in the tcpsock:sslhandshake method. This directive was first introduced in the v0.9.11 release. Back to TOC lua_ssl_protocols syntax: lua_ssl_protocols [SSLv2] [SSLv3] [TLSv1] [TLSv1.1] [TLSv1.2] [TLSv1.3] default: lua_ssl_protocols SSLv3 TLSv1 TLSv1.1 TLSv1.2 context: http, server, location Enables the specified protocols for requests to a SSL/TLS server in the tcpsock:sslhandshake method. The support for the TLSv1.3 parameter requires version v0.10.12 and OpenSSL 1.1.1. This directive was first introduced in the v0.9.11 release. Back to TOC lua_ssl_trusted_certificate syntax: lua_ssl_trusted_certificate <file> default: no context: http, server, location Specifies a file path with trusted CA certificates in the PEM format used to verify the certificate of the SSL/TLS server in the tcpsock:sslhandshake method. This directive was first introduced in the v0.9.11 release. See also lua_ssl_verify_depth. Back to TOC lua_ssl_verify_depth syntax: lua_ssl_verify_depth <number> default: lua_ssl_verify_depth 1 context: http, server, location Sets the verification depth in the server certificates chain. This directive was first introduced in the v0.9.11 release. See also lua_ssl_trusted_certificate. Back to TOC lua_http10_buffering syntax: lua_http10_buffering on|off default: lua_http10_buffering on context: http, server, location, location-if Enables or disables automatic response buffering for HTTP 1.0 (or older) requests. This buffering mechanism is mainly used for HTTP 1.0 keep-alive which relies on a proper Content-Length response header. If the Lua code explicitly sets a Content-Length response header before sending the headers (either explicitly via ngx.send_headers or implicitly via the first ngx.say or ngx.print call), then the HTTP 1.0 response buffering will be disabled even when this directive is turned on. To output very large response data in a streaming fashion (via the ngx.flush call, for example), this directive MUST be turned off to minimize memory usage. This directive is turned on by default. This directive was first introduced in the v0.5.0rc19 release. Back to TOC rewrite_by_lua_no_postpone syntax: rewrite_by_lua_no_postpone on|off default: rewrite_by_lua_no_postpone off context: http Controls whether or not to disable postponing rewrite_by_lua* directives to run at the end of the rewrite request-processing phase. By default, this directive is turned off and the Lua code is postponed to run at the end of the rewrite phase. This directive was first introduced in the v0.5.0rc29 release. Back to TOC access_by_lua_no_postpone syntax: access_by_lua_no_postpone on|off default: access_by_lua_no_postpone off context: http Controls whether or not to disable postponing access_by_lua* directives to run at the end of the access request-processing phase. By default, this directive is turned off and the Lua code is postponed to run at the end of the access phase. This directive was first introduced in the v0.9.20 release. Back to TOC lua_transform_underscores_in_response_headers syntax: lua_transform_underscores_in_response_headers on|off default: lua_transform_underscores_in_response_headers on context: http, server, location, location-if Controls whether to transform underscores (_) in the response header names specified in the ngx.header.HEADER API to hypens (-). This directive was first introduced in the v0.5.0rc32 release. Back to TOC lua_check_client_abort syntax: lua_check_client_abort on|off default: lua_check_client_abort off context: http, server, location, location-if This directive controls whether to check for premature client connection abortion. When this directive is on, the ngx_lua module will monitor the premature connection close event on the downstream connections and when there is such an event, it will call the user Lua function callback (registered by ngx.on_abort) or just stop and clean up all the Lua "light threads" running in the current request's request handler when there is no user callback function registered. According to the current implementation, however, if the client closes the connection before the Lua code finishes reading the request body data via ngx.req.socket, then ngx_lua will neither stop all the running "light threads" nor call the user callback (if ngx.on_abort has been called). Instead, the reading operation on ngx.req.socket will just return the error message "client aborted" as the second return value (the first return value is surely nil). When TCP keepalive is disabled, it is relying on the client side to close the socket gracefully (by sending a FIN packet or something like that). For (soft) real-time web applications, it is highly recommended to configure the TCP keepalive support in your system's TCP stack implementation in order to detect "half-open" TCP connections in time. For example, on Linux, you can configure the standard listen directive in your nginx.conf file like this: On FreeBSD, you can only tune the system-wide configuration for TCP keepalive, for example: # sysctl net.inet.tcp.keepintvl=2000 # sysctl net.inet.tcp.keepidle=2000 This directive was first introduced in the v0.7.4 release. See also ngx.on_abort. Back to TOC lua_max_pending_timers syntax: lua_max_pending_timers <count> default: lua_max_pending_timers 1024 context: http Controls the maximum number of pending timers allowed. Pending timers are those timers that have not expired yet. When exceeding this limit, the ngx.timer.at call will immediately return nil and the error string "too many pending timers". This directive was first introduced in the v0.8.0 release. Back to TOC lua_max_running_timers syntax: lua_max_running_timers <count> default: lua_max_running_timers 256 context: http Controls the maximum number of "running timers" allowed. Running timers are those timers whose user callback functions are still running. When exceeding this limit, Nginx will stop running the callbacks of newly expired timers and log an error message "N lua_max_running_timers are not enough" where "N" is the current value of this directive. This directive was first introduced in the v0.8.0 release. Back to TOC lua_sa_restart syntax: lua_sa_restart on|off default: lua_sa_restart on context: http When enabled, this module will set the SA_RESTART flag on Nginx workers signal dispositions. This allows Lua I/O primitives to not be interrupted by Nginx's handling of various signals. This directive was first introduced in the v0.10.14 release. Back to TOC Nginx API for Lua Introduction ngx.arg ngx.var.VARIABLE Core constants HTTP method constants HTTP status constants Nginx log level constants print ngx.ctx ngx.location.capture ngx.location.capture_multi ngx.status ngx.header.HEADER ngx.resp.get_headers ngx.req.is_internal ngx.req.start_time ngx.req.http_version ngx.req.raw_header ngx.req.get_method ngx.req.set_method ngx.req.set_uri ngx.req.set_uri_args ngx.req.get_uri_args ngx.req.get_post_args ngx.req.get_headers ngx.req.set_header ngx.req.clear_header ngx.req.read_body ngx.req.discard_body ngx.req.get_body_data ngx.req.get_body_file ngx.req.set_body_data ngx.req.set_body_file ngx.req.init_body ngx.req.append_body ngx.req.finish_body ngx.req.socket ngx.exec ngx.redirect ngx.send_headers ngx.headers_sent ngx.print ngx.say ngx.log ngx.flush ngx.exit ngx.eof ngx.sleep ngx.escape_uri ngx.unescape_uri ngx.encode_args ngx.decode_args ngx.encode_base64 ngx.decode_base64 ngx.crc32_short ngx.crc32_long ngx.hmac_sha1 ngx.md5 ngx.md5_bin ngx.sha1_bin ngx.quote_sql_str ngx.today ngx.time ngx.now ngx.update_time ngx.localtime ngx.utctime ngx.cookie_time ngx.http_time ngx.parse_http_time ngx.is_subrequest ngx.re.match ngx.re.find ngx.re.gmatch ngx.re.sub ngx.re.gsub ngx.shared.DICT ngx.shared.DICT.get ngx.shared.DICT.get_stale ngx.shared.DICT.set ngx.shared.DICT.safe_set ngx.shared.DICT.add ngx.shared.DICT.safe_add ngx.shared.DICT.replace ngx.shared.DICT.delete ngx.shared.DICT.incr ngx.shared.DICT.lpush ngx.shared.DICT.rpush ngx.shared.DICT.lpop ngx.shared.DICT.rpop ngx.shared.DICT.llen ngx.shared.DICT.ttl ngx.shared.DICT.expire ngx.shared.DICT.flush_all ngx.shared.DICT.flush_expired ngx.shared.DICT.get_keys ngx.shared.DICT.capacity ngx.shared.DICT.free_space ngx.socket.udp udpsock:setpeername udpsock:send udpsock:receive udpsock:close udpsock:settimeout ngx.socket.stream ngx.socket.tcp tcpsock:connect tcpsock:sslhandshake tcpsock:send tcpsock:receive tcpsock:receiveany tcpsock:receiveuntil tcpsock:close tcpsock:settimeout tcpsock:settimeouts tcpsock:setoption tcpsock:setkeepalive tcpsock:getreusedtimes ngx.socket.connect ngx.get_phase ngx.thread.spawn ngx.thread.wait ngx.thread.kill ngx.on_abort ngx.timer.at ngx.timer.every ngx.timer.running_count ngx.timer.pending_count ngx.config.subsystem ngx.config.debug ngx.config.prefix ngx.config.nginx_version ngx.config.nginx_configure ngx.config.ngx_lua_version ngx.worker.exiting ngx.worker.pid ngx.worker.count ngx.worker.id ngx.semaphore ngx.balancer ngx.ssl ngx.ocsp ndk.set_var.DIRECTIVE coroutine.create coroutine.resume coroutine.yield coroutine.wrap coroutine.running coroutine.status Back to TOC Introduction The various *_by_lua, *_by_lua_block and *_by_lua_file configuration directives serve as gateways to the Lua API within the nginx.conf file. The Nginx Lua API described below can only be called within the user Lua code run in the context of these configuration directives. The API is exposed to Lua in the form of two standard packages ngx and ndk. These packages are in the default global scope within ngx_lua and are always available within ngx_lua directives. The packages can be introduced into external Lua modules like this: Use of the package.seeall flag is strongly discouraged due to its various bad side-effects. It is also possible to directly require the packages in external Lua modules: The ability to require these packages was introduced in the v0.2.1rc19 release. Network I/O operations in user code should only be done through the Nginx Lua API calls as the Nginx event loop may be blocked and performance drop off dramatically otherwise. Disk operations with relatively small amount of data can be done using the standard Lua io library but huge file reading and writing should be avoided wherever possible as they may block the Nginx process significantly. Delegating all network and disk I/O operations to Nginx's subrequests (via the ngx.location.capture method and similar) is strongly recommended for maximum performance. Back to TOC ngx.arg syntax: val = ngx.arg[index] context: set_by_lua*, body_filter_by_lua* When this is used in the context of the set_by_lua* directives, this table is read-only and holds the input arguments to the config directives: Here is an example that writes out 88, the sum of 32 and 56. When this table is used in the context of body_filter_by_lua*, the first element holds the input data chunk to the output filter code and the second element holds the boolean flag for the "eof" flag indicating the end of the whole output data stream. The data chunk and "eof" flag passed to the downstream Nginx output filters can also be overridden by assigning values directly to the corresponding table elements. When setting nil or an empty Lua string value to ngx.arg[1], no data chunk will be passed to the downstream Nginx output filters at all. Back to TOC ngx.var.VARIABLE syntax: ngx.var.VAR_NAME context: set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, balancer_by_lua* Read and write Nginx variable values. Note that only already defined Nginx variables can be written to. For example: That is, Nginx variables cannot be created on-the-fly. Some special Nginx variables like $args and $limit_rate can be assigned a value, many others are not, like $query_string, $arg_PARAMETER, and $http_NAME. Nginx regex group capturing variables $1, $2, $3, and etc, can be read by this interface as well, by writing ngx.var[1], ngx.var[2], ngx.var[3], and etc. Setting ngx.var.Foo to a nil value will unset the $Foo Nginx variable. CAUTION When reading from an Nginx variable, Nginx will allocate memory in the per-request memory pool which is freed only at request termination. So when you need to read from an Nginx variable repeatedly in your Lua code, cache the Nginx variable value to your own Lua variable, for example, to prevent (temporary) memory leaking within the current request's lifetime. Another way of caching the result is to use the ngx.ctx table. Undefined Nginx variables are evaluated to nil while uninitialized (but defined) Nginx variables are evaluated to an empty Lua string. This API requires a relatively expensive metamethod call and it is recommended to avoid using it on hot code paths. Back to TOC Core constants context: init_by_lua*, set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, *log_by_lua*, ngx.timer.*, balancer_by_lua*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua* Note that only three of these constants are utilized by the Nginx API for Lua (i.e., ngx.exit accepts ngx.OK, ngx.ERROR, and ngx.DECLINED as input). The ngx.null constant is a NULL light userdata usually used to represent nil values in Lua tables etc and is similar to the lua-cjson library's cjson.null constant. This constant was first introduced in the v0.5.0rc5 release. The ngx.DECLINED constant was first introduced in the v0.5.0rc19 release. Back to TOC HTTP method constants context: init_by_lua*, set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, balancer_by_lua*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua* ngx.HTTP_GET ngx.HTTP_HEAD ngx.HTTP_PUT ngx.HTTP_POST ngx.HTTP_DELETE ngx.HTTP_OPTIONS (added in the v0.5.0rc24 release) ngx.HTTP_MKCOL (added in the v0.8.2 release) ngx.HTTP_COPY (added in the v0.8.2 release) ngx.HTTP_MOVE (added in the v0.8.2 release) ngx.HTTP_PROPFIND (added in the v0.8.2 release) ngx.HTTP_PROPPATCH (added in the v0.8.2 release) ngx.HTTP_LOCK (added in the v0.8.2 release) ngx.HTTP_UNLOCK (added in the v0.8.2 release) ngx.HTTP_PATCH (added in the v0.8.2 release) ngx.HTTP_TRACE (added in the v0.8.2 release) These constants are usually used in ngx.location.capture and ngx.location.capture_multi method calls. Back to TOC HTTP status constants context: init_by_lua*, set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, balancer_by_lua*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua* Back to TOC Nginx log level constants context: init_by_lua*, init_worker_by_lua*, set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, balancer_by_lua*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua*, exit_worker_by_lua* These constants are usually used by the ngx.log method. Back to TOC print syntax: print(...) context: init_by_lua*, init_worker_by_lua*, set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, balancer_by_lua*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua*, exit_worker_by_lua* Writes argument values into the Nginx error.log file with the ngx.NOTICE log level. It is equivalent to Lua nil arguments are accepted and result in literal "nil" strings while Lua booleans result in literal "true" or "false" strings. And the ngx.null constant will yield the "null" string output. There is a hard coded 2048 byte limitation on error message lengths in the Nginx core. This limit includes trailing newlines and leading time stamps. If the message size exceeds this limit, Nginx will truncate the message text accordingly. This limit can be manually modified by editing the NGX_MAX_ERROR_STR macro definition in the src/core/ngx_log.h file in the Nginx source tree. Back to TOC ngx.ctx context: init_worker_by_lua*, set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, balancer_by_lua*, exit_worker_by_lua* This table can be used to store per-request Lua context data and has a life time identical to the current request (as with the Nginx variables). Consider the following example, Then GET /test will yield the output That is, the ngx.ctx.foo entry persists across the rewrite, access, and content phases of a request. Every request, including subrequests, has its own copy of the table. For example: Then GET /main will give the output Here, modification of the ngx.ctx.blah entry in the subrequest does not affect the one in the parent request. This is because they have two separate versions of ngx.ctx.blah. Internal redirects (triggered by nginx configuration directives like error_page, try_files, index and etc) will destroy the original request ngx.ctx data (if any) and the new request will have an empty ngx.ctx table. For instance, Then GET /orig will give rather than the original "hello" value. Because HTTP request is created after SSL handshake, the ngx.ctx created in ssl_certificate_by_lua*, ssl_session_store_by_lua* and ssl_session_fetch_by_lua* is not available in the following phases like rewrite_by_lua*. Since dev, the ngx.ctx created during a SSL handshake will be inherited by the requests which share the same TCP connection established by the handshake. Note that overwrite values in ngx.ctx in the http request phases (like rewrite_by_lua*) will only take affect in the current http request. Arbitrary data values, including Lua closures and nested tables, can be inserted into this "magic" table. It also allows the registration of custom meta methods. Overriding ngx.ctx with a new Lua table is also supported, for example, When being used in the context of init_worker_by_lua*, this table just has the same lifetime of the current Lua handler. The ngx.ctx lookup requires relatively expensive metamethod calls and it is much slower than explicitly passing per-request data along by your own function arguments. So do not abuse this API for saving your own function arguments because it usually has quite some performance impact. Because of the metamethod magic, never "local" the ngx.ctx table outside your Lua function scope on the Lua module level due to worker-level data sharing. For example, the following is bad: Use the following instead: That is, let the caller pass the ctx table explicitly via a function argument. Back to TOC ngx.location.capture syntax: res = ngx.location.capture(uri, options?) context: rewrite_by_lua*, access_by_lua*, content_by_lua* Issues a synchronous but still non-blocking Nginx Subrequest using uri. Nginx's subrequests provide a powerful way to make non-blocking internal requests to other locations configured with disk file directory or any other Nginx C modules like ngx_proxy, ngx_fastcgi, ngx_memc, ngx_postgres, ngx_drizzle, and even ngx_lua itself and etc etc etc. Also note that subrequests just mimic the HTTP interface but there is no extra HTTP/TCP traffic nor IPC involved. Everything works internally, efficiently, on the C level. Subrequests are completely different from HTTP 301/302 redirection (via ngx.redirect) and internal redirection (via ngx.exec). You should always read the request body (by either calling ngx.req.read_body or configuring lua_need_request_body on) before initiating a subrequest. This API function (as well as ngx.location.capture_multi) always buffers the whole response body of the subrequest in memory. Thus, you should use cosockets and streaming processing instead if you have to handle large subrequest responses. Here is a basic example: Returns a Lua table with 4 slots: res.status, res.header, res.body, and res.truncated. res.status holds the response status code for the subrequest response. res.header holds all the response headers of the subrequest and it is a normal Lua table. For multi-value response headers, the value is a Lua (array) table that holds all the values in the order that they appear. For instance, if the subrequest response headers contain the following lines: Then res.header["Set-Cookie"] will be evaluated to the table value {"a=3", "foo=bar", "baz=blah"}. res.body holds the subrequest's response body data, which might be truncated. You always need to check the res.truncated boolean flag to see if res.body contains truncated data. The data truncation here can only be caused by those unrecoverable errors in your subrequests like the cases that the remote end aborts the connection prematurely in the middle of the response body data stream or a read timeout happens when your subrequest is receiving the response body data from the remote. URI query strings can be concatenated to URI itself, for instance, Named locations like @foo are not allowed due to a limitation in the Nginx core. Use normal locations combined with the internal directive to prepare internal-only locations. An optional option table can be fed as the second argument, which supports the options: method specify the subrequest's request method, which only accepts constants like ngx.HTTP_POST. body specify the subrequest's request body (string value only). args specify the subrequest's URI query arguments (both string value and Lua tables are accepted) ctx specify a Lua table to be the ngx.ctx table for the subrequest. It can be the current request's ngx.ctx table, which effectively makes the parent and its subrequest to share exactly the same context table. This option was first introduced in the v0.3.1rc25 release. vars take a Lua table which holds the values to set the specified Nginx variables in the subrequest as this option's value. This option was first introduced in the v0.3.1rc31 release. copy_all_vars specify whether to copy over all the Nginx variable values of the current request to the subrequest in question. modifications of the Nginx variables in the subrequest will not affect the current (parent) request. This option was first introduced in the v0.3.1rc31 release. share_all_vars specify whether to share all the Nginx variables of the subrequest with the current (parent) request. modifications of the Nginx variables in the subrequest will affect the current (parent) request. Enabling this option may lead to hard-to-debug issues due to bad side-effects and is considered bad and harmful. Only enable this option when you completely know what you are doing. always_forward_body when set to true, the current (parent) request's request body will always be forwarded to the subrequest being created if the body option is not specified. The request body read by either ngx.req.read_body() or lua_need_request_body on will be directly forwarded to the subrequest without copying the whole request body data when creating the subrequest (no matter the request body data is buffered in memory buffers or temporary files). By default, this option is false and when the body option is not specified, the request body of the current (parent) request is only forwarded when the subrequest takes the PUT or POST request method. Issuing a POST subrequest, for example, can be done as follows See HTTP method constants methods other than POST. The method option is ngx.HTTP_GET by default. The args option can specify extra URI arguments, for instance, is equivalent to that is, this method will escape argument keys and values according to URI rules and concatenate them together into a complete query string. The format for the Lua table passed as the args argument is identical to the format used in the ngx.encode_args method. The args option can also take plain query strings: This is functionally identical to the previous examples. The share_all_vars option controls whether to share Nginx variables among the current request and its subrequests. If this option is set to true, then the current request and associated subrequests will share the same Nginx variable scope. Hence, changes to Nginx variables made by a subrequest will affect the current request. Care should be taken in using this option as variable scope sharing can have unexpected side effects. The args, vars, or copy_all_vars options are generally preferable instead. This option is set to false by default Accessing location /lua gives /other dog: hello world /lua: hello world The copy_all_vars option provides a copy of the parent request's Nginx variables to subrequests when such subrequests are issued. Changes made to these variables by such subrequests will not affect the parent request or any other subrequests sharing the parent request's variables. Request GET /lua will give the output /other dog: hello world /lua: hello Note that if both share_all_vars and copy_all_vars are set to true, then share_all_vars takes precedence. In addition to the two settings above, it is possible to specify values for variables in the subrequest using the vars option. These variables are set after the sharing or copying of variables has been evaluated, and provides a more efficient method of passing specific values to a subrequest over encoding them as URL arguments and unescaping them in the Nginx config file. Accessing /lua will yield the output dog = hello cat = 32 The ctx option can be used to specify a custom Lua table to serve as the ngx.ctx table for the subrequest. Then request GET /lua gives bar nil It is also possible to use this ctx option to share the same ngx.ctx table between the current (parent) request and the subrequest: Request GET /lua yields the output bar Note that subrequests issued by ngx.location.capture inherit all the request headers of the current request by default and that this may have unexpected side effects on the subrequest responses. For example, when using the standard ngx_proxy module to serve subrequests, an "Accept-Encoding: gzip" header in the main request may result in gzipped responses that cannot be handled properly in Lua code. Original request headers should be ignored by setting proxy_pass_request_headers to off in subrequest locations. When the body option is not specified and the always_forward_body option is false (the default value), the POST and PUT subrequests will inherit the request bodies of the parent request (if any). There is a hard-coded upper limit on the number of subrequests possible for every main request. In older versions of Nginx, the limit was 50 concurrent subrequests and in more recent versions, Nginx 1.9.5 onwards, the same limit is changed to limit the depth of recursive subrequests. When this limit is exceeded, the following error message is added to the error.log file: [error] 13983#0: *1 subrequests cycle while processing "/uri" The limit can be manually modified if required by editing the definition of the NGX_HTTP_MAX_SUBREQUESTS macro in the nginx/src/http/ngx_http_request.h file in the Nginx source tree. Please also refer to restrictions on capturing locations configured by subrequest directives of other modules. Back to TOC ngx.location.capture_multi syntax: res1, res2, ... = ngx.location.capture_multi({ {uri, options?}, {uri, options?}, ... }) context: rewrite_by_lua*, access_by_lua*, content_by_lua* Just like ngx.location.capture, but supports multiple subrequests running in parallel. This function issues several parallel subrequests specified by the input table and returns their results in the same order. For example, This function will not return until all the subrequests terminate. The total latency is the longest latency of the individual subrequests rather than the sum. Lua tables can be used for both requests and responses when the number of subrequests to be issued is not known in advance: The ngx.location.capture function is just a special form of this function. Logically speaking, the ngx.location.capture can be implemented like this Please also refer to restrictions on capturing locations configured by subrequest directives of other modules. Back to TOC ngx.status context: set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua* Read and write the current request's response status. This should be called before sending out the response headers. Setting ngx.status after the response header is sent out has no effect but leaving an error message in your Nginx's error log file: attempt to set ngx.status after sending out response headers Back to TOC ngx.header.HEADER syntax: ngx.header.HEADER = VALUE syntax: value = ngx.header.HEADER context: rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua* Set, add to, or clear the current request's HEADER response header that is to be sent. Underscores (_) in the header names will be replaced by hyphens (-) by default. This transformation can be turned off via the lua_transform_underscores_in_response_headers directive. The header names are matched case-insensitively. Multi-value headers can be set this way: will yield in the response headers. Only Lua tables are accepted (Only the last element in the table will take effect for standard headers such as Content-Type that only accept a single value). is equivalent to Setting a slot to nil effectively removes it from the response headers: The same applies to assigning an empty table: Setting ngx.header.HEADER after sending out response headers (either explicitly with ngx.send_headers or implicitly with ngx.print and similar) will log an error message. Reading ngx.header.HEADER will return the value of the response header named HEADER. Underscores (_) in the header names will also be replaced by dashes (-) and the header names will be matched case-insensitively. If the response header is not present at all, nil will be returned. This is particularly useful in the context of header_filter_by_lua*, for example, For multi-value headers, all of the values of header will be collected in order and returned as a Lua table. For example, response headers Foo: bar Foo: baz will result in to be returned when reading ngx.header.Foo. Note that ngx.header is not a normal Lua table and as such, it is not possible to iterate through it using the Lua ipairs function. Note: this function throws a Lua error if HEADER or VALUE contain unsafe characters (control characters). For reading request headers, use the ngx.req.get_headers function instead. Back to TOC ngx.resp.get_headers syntax: headers, err = ngx.resp.get_headers(max_headers?, raw?) context: set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, balancer_by_lua* Returns a Lua table holding all the current response headers for the current request. This function has the same signature as ngx.req.get_headers except getting response headers instead of request headers. Note that a maximum of 100 response headers are parsed by default (including those with the same name) and that additional response headers are silently discarded to guard against potential denial of service attacks. Since v0.10.13, when the limit is exceeded, it will return a second value which is the string "truncated". This API was first introduced in the v0.9.5 release. Back to TOC ngx.req.is_internal syntax: is_internal = ngx.req.is_internal() context: set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua* Returns a boolean indicating whether the current request is an "internal request", i.e., a request initiated from inside the current Nginx server instead of from the client side. Subrequests are all internal requests and so are requests after internal redirects. This API was first introduced in the v0.9.20 release. Back to TOC ngx.req.start_time syntax: secs = ngx.req.start_time() context: set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua* Returns a floating-point number representing the timestamp (including milliseconds as the decimal part) when the current request was created. The following example emulates the $request_time variable value (provided by ngx_http_log_module) in pure Lua: This function was first introduced in the v0.7.7 release. See also ngx.now and ngx.update_time. Back to TOC ngx.req.http_version syntax: num = ngx.req.http_version() context: set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua* Returns the HTTP version number for the current request as a Lua number. Current possible values are 2.0, 1.0, 1.1, and 0.9. Returns nil for unrecognized values. This method was first introduced in the v0.7.17 release. Back to TOC ngx.req.raw_header syntax: str = ngx.req.raw_header(no_request_line?) context: set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua* Returns the original raw HTTP protocol header received by the Nginx server. By default, the request line and trailing CR LF terminator will also be included. For example, gives something like this: GET /t HTTP/1.1 Host: localhost Connection: close Foo: bar You can specify the optional no_request_line argument as a true value to exclude the request line from the result. For example, outputs something like this: Host: localhost Connection: close Foo: bar This method was first introduced in the v0.7.17 release. This method does not work in HTTP/2 requests yet. Back to TOC ngx.req.get_method syntax: method_name = ngx.req.get_method() context: set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, balancer_by_lua*, log_by_lua* Retrieves the current request's request method name. Strings like "GET" and "POST" are returned instead of numerical method constants. If the current request is an Nginx subrequest, then the subrequest's method name will be returned. This method was first introduced in the v0.5.6 release. See also ngx.req.set_method. Back to TOC ngx.req.set_method syntax: ngx.req.set_method(method_id) context: set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua* Overrides the current request's request method with the method_id argument. Currently only numerical method constants are supported, like ngx.HTTP_POST and ngx.HTTP_GET. If the current request is an Nginx subrequest, then the subrequest's method will be overridden. This method was first introduced in the v0.5.6 release. See also ngx.req.get_method. Back to TOC ngx.req.set_uri syntax: ngx.req.set_uri(uri, jump?, binary?) context: set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua* Rewrite the current request's (parsed) URI by the uri argument. The uri argument must be a Lua string and cannot be of zero length, or a Lua exception will be thrown. The optional boolean jump argument can trigger location rematch (or location jump) as ngx_http_rewrite_module's rewrite directive, that is, when jump is true (default to false), this function will never return and it will tell Nginx to try re-searching locations with the new URI value at the later post-rewrite phase and jumping to the new location. Location jump will not be triggered otherwise, and only the current request's URI will be modified, which is also the default behavior. This function will return but with no returned values when the jump argument is false or absent altogether. For example, the following Nginx config snippet can be coded in Lua like this: Similarly, Nginx config can be coded in Lua as or equivalently, The jump argument can only be set to true in rewrite_by_lua*. Use of jump in other contexts is prohibited and will throw out a Lua exception. A more sophisticated example involving regex substitutions is as follows which is functionally equivalent to Note: this function throws a Lua error if the uri argument contains unsafe characters (control characters). Note that it is not possible to use this interface to rewrite URI arguments and that ngx.req.set_uri_args should be used for this instead. For instance, Nginx config can be coded as or Starting from 0.10.16 of this module, this function accepts an optional boolean binary argument to allow arbitrary binary URI data. By default, this binary argument is false and this function will throw out a Lua error such as the one below when the uri argument contains any control characters (ASCII Code 0 ~ 0x08, 0x0A ~ 0x1F and 0x7F). [error] 23430#23430: *1 lua entry thread aborted: runtime error: content_by_lua(nginx.conf:44):3: ngx.req.set_uri unsafe byte "0x00" in "\x00foo" (maybe you want to set the 'binary' argument?) This interface was first introduced in the v0.3.1rc14 release. Back to TOC ngx.req.set_uri_args syntax: ngx.req.set_uri_args(args) context: set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua* Rewrite the current request's URI query arguments by the args argument. The args argument can be either a Lua string, as in or a Lua table holding the query arguments' key-value pairs, as in In the former case, i.e., when the whole query-string is provided directly, the input Lua string should already be well-formed with the URI encoding. For security considerations, this method will automatically escape any control and whitespace characters (ASCII code 0x00 ~ 0x20 and 0x7F) in the Lua string. In the latter case, this method will escape argument keys and values according to the URI escaping rule. Multi-value arguments are also supported: which will result in a query string like a=3&b=5&b=6. This interface was first introduced in the v0.3.1rc13 release. See also ngx.req.set_uri. Back to TOC ngx.req.get_uri_args syntax: args, err = ngx.req.get_uri_args(max_args?) context: set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, balancer_by_lua* Returns a Lua table holding all the current request URL query arguments. Then GET /test?foo=bar&bar=baz&bar=blah will yield the response body Multiple occurrences of an argument key will result in a table value holding all the values for that key in order. Keys and values are unescaped according to URI escaping rules. In the settings above, GET /test?a%20b=1%61+2 will yield: Arguments without the =<value> parts are treated as boolean arguments. GET /test?foo&bar will yield: That is, they will take Lua boolean values true. However, they are different from arguments taking empty string values. GET /test?foo=&bar= will give something like Empty key arguments are discarded. GET /test?=hello&=world will yield an empty output for instance. Updating query arguments via the Nginx variable $args (or ngx.var.args in Lua) at runtime is also supported: Here the args table will always look like regardless of the actual request query string. Note that a maximum of 100 request arguments are parsed by default (including those with the same name) and that additional request arguments are silently discarded to guard against potential denial of service attacks. Since v0.10.13, when the limit is exceeded, it will return a second value which is the string "truncated". However, the optional max_args function argument can be used to override this limit: This argument can be set to zero to remove the limit and to process all request arguments received: Removing the max_args cap is strongly discouraged. Back to TOC ngx.req.get_post_args syntax: args, err = ngx.req.get_post_args(max_args?) context: rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua* Returns a Lua table holding all the current request POST query arguments (of the MIME type application/x-www-form-urlencoded). Call ngx.req.read_body to read the request body first or turn on the lua_need_request_body directive to avoid errors. Then will yield the response body like Multiple occurrences of an argument key will result in a table value holding all of the values for that key in order. Keys and values will be unescaped according to URI escaping rules. With the settings above, will yield: Arguments without the =<value> parts are treated as boolean arguments. POST /test with the request body foo&bar will yield: That is, they will take Lua boolean values true. However, they are different from arguments taking empty string values. POST /test with request body foo=&bar= will return something like Empty key arguments are discarded. POST /test with body =hello&=world will yield empty outputs for instance. Note that a maximum of 100 request arguments are parsed by default (including those with the same name) and that additional request arguments are silently discarded to guard against potential denial of service attacks. Since v0.10.13, when the limit is exceeded, it will return a second value which is the string "truncated". However, the optional max_args function argument can be used to override this limit: This argument can be set to zero to remove the limit and to process all request arguments received: Removing the max_args cap is strongly discouraged. Back to TOC ngx.req.get_headers syntax: headers, err = ngx.req.get_headers(max_headers?, raw?) context: set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua* Returns a Lua table holding all the current request headers. To read an individual header: Note that the ngx.var.HEADER API call, which uses core $http_HEADER variables, may be more preferable for reading individual request headers. For multiple instances of request headers such as: the value of ngx.req.get_headers()["Foo"] will be a Lua (array) table such as: Note that a maximum of 100 request headers are parsed by default (including those with the same name) and that additional request headers are silently discarded to guard against potential denial of service attacks. Since v0.10.13, when the limit is exceeded, it will return a second value which is the string "truncated". However, the optional max_headers function argument can be used to override this limit: This argument can be set to zero to remove the limit and to process all request headers received: Removing the max_headers cap is strongly discouraged. Since the 0.6.9 release, all the header names in the Lua table returned are converted to the pure lower-case form by default, unless the raw argument is set to true (default to false). Also, by default, an __index metamethod is added to the resulting Lua table and will normalize the keys to a pure lowercase form with all underscores converted to dashes in case of a lookup miss. For example, if a request header My-Foo-Header is present, then the following invocations will all pick up the value of this header correctly: The __index metamethod will not be added when the raw argument is set to true. Back to TOC ngx.req.set_header syntax: ngx.req.set_header(header_name, header_value) context: set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua* Set the current request's request header named header_name to value header_value, overriding any existing ones. The input Lua string header_name and header_value should already be well-formed with the URI encoding. For security considerations, this method will automatically escape " ", """, "(", ")", ",", "/", ":", ";", "?", "<", "=", ">", "?", "@", "[", "]", "\", "{", "}", 0x00-0x1F, 0x7F-0xFF in header_name and automatically escape "0x00-0x08, 0x0A-0x0F, 0x7F in header_value. By default, all the subrequests subsequently initiated by ngx.location.capture and ngx.location.capture_multi will inherit the new header. Here is an example of setting the Content-Type header: The header_value can take an array list of values, for example, will produce two new request headers: and old Foo headers will be overridden if there is any. When the header_value argument is nil, the request header will be removed. So is equivalent to Note: this function throws a Lua error if header_name or header_value contain unsafe characters (control characters). Back to TOC ngx.req.clear_header syntax: ngx.req.clear_header(header_name) context: set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua* Clears the current request's request header named header_name. None of the current request's existing subrequests will be affected but subsequently initiated subrequests will inherit the change by default. Back to TOC ngx.req.read_body syntax: ngx.req.read_body() context: rewrite_by_lua*, access_by_lua*, content_by_lua* Reads the client request body synchronously without blocking the Nginx event loop. If the request body is already read previously by turning on lua_need_request_body or by using other modules, then this function does not run and returns immediately. If the request body has already been explicitly discarded, either by the ngx.req.discard_body function or other modules, this function does not run and returns immediately. In case of errors, such as connection errors while reading the data, this method will throw out a Lua exception or terminate the current request with a 500 status code immediately. The request body data read using this function can be retrieved later via ngx.req.get_body_data or, alternatively, the temporary file name for the body data cached to disk using ngx.req.get_body_file. This depends on whether the current request body is already larger than the client_body_buffer_size, and whether client_body_in_file_only has been switched on. In cases where current request may have a request body and the request body data is not required, The ngx.req.discard_body function must be used to explicitly discard the request body to avoid breaking things under HTTP 1.1 keepalive or HTTP 1.1 pipelining. This function was first introduced in the v0.3.1rc17 release. Back to TOC ngx.req.discard_body syntax: ngx.req.discard_body() context: rewrite_by_lua*, access_by_lua*, content_by_lua* Explicitly discard the request body, i.e., read the data on the connection and throw it away immediately (without using the request body by any means). This function is an asynchronous call and returns immediately. If the request body has already been read, this function does nothing and returns immediately. This function was first introduced in the v0.3.1rc17 release. See also ngx.req.read_body. Back to TOC ngx.req.get_body_data syntax: data = ngx.req.get_body_data() context: rewrite_by_lua*, access_by_lua*, content_by_lua*, log_by_lua* Retrieves in-memory request body data. It returns a Lua string rather than a Lua table holding all the parsed query arguments. Use the ngx.req.get_post_args function instead if a Lua table is required. This function returns nil if the request body has not been read, the request body has been read into disk temporary files, or the request body has zero size. If the request body has not been read yet, call ngx.req.read_body first (or turn on lua_need_request_body to force this module to read the request body. This is not recommended however). If the request body has been read into disk files, try calling the ngx.req.get_body_file function instead. To force in-memory request bodies, try setting client_body_buffer_size to the same size value in client_max_body_size. Note that calling this function instead of using ngx.var.request_body or ngx.var.echo_request_body is more efficient because it can save one dynamic memory allocation and one data copy. This function was first introduced in the v0.3.1rc17 release. See also ngx.req.get_body_file. Back to TOC ngx.req.get_body_file syntax: file_name = ngx.req.get_body_file() context: rewrite_by_lua*, access_by_lua*, content_by_lua* Retrieves the file name for the in-file request body data. Returns nil if the request body has not been read or has been read into memory. The returned file is read only and is usually cleaned up by Nginx's memory pool. It should not be manually modified, renamed, or removed in Lua code. If the request body has not been read yet, call ngx.req.read_body first (or turn on lua_need_request_body to force this module to read the request body. This is not recommended however). If the request body has been read into memory, try calling the ngx.req.get_body_data function instead. To force in-file request bodies, try turning on client_body_in_file_only. This function was first introduced in the v0.3.1rc17 release. See also ngx.req.get_body_data. Back to TOC ngx.req.set_body_data syntax: ngx.req.set_body_data(data) context: rewrite_by_lua*, access_by_lua*, content_by_lua* Set the current request's request body using the in-memory data specified by the data argument. If the request body has not been read yet, call ngx.req.read_body first (or turn on lua_need_request_body to force this module to read the request body. This is not recommended however). Additionally, the request body must not have been previously discarded by ngx.req.discard_body. Whether the previous request body has been read into memory or buffered into a disk file, it will be freed or the disk file will be cleaned up immediately, respectively. This function was first introduced in the v0.3.1rc18 release. See also ngx.req.set_body_file. Back to TOC ngx.req.set_body_file syntax: ngx.req.set_body_file(file_name, auto_clean?) context: rewrite_by_lua*, access_by_lua*, content_by_lua* Set the current request's request body using the in-file data specified by the file_name argument. If the request body has not been read yet, call ngx.req.read_body first (or turn on lua_need_request_body to force this module to read the request body. This is not recommended however). Additionally, the request body must not have been previously discarded by ngx.req.discard_body. If the optional auto_clean argument is given a true value, then this file will be removed at request completion or the next time this function or ngx.req.set_body_data are called in the same request. The auto_clean is default to false. Please ensure that the file specified by the file_name argument exists and is readable by an Nginx worker process by setting its permission properly to avoid Lua exception errors. Whether the previous request body has been read into memory or buffered into a disk file, it will be freed or the disk file will be cleaned up immediately, respectively. This function was first introduced in the v0.3.1rc18 release. See also ngx.req.set_body_data. Back to TOC ngx.req.init_body syntax: ngx.req.init_body(buffer_size?) context: set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua* Creates a new blank request body for the current request and inializes the buffer for later request body data writing via the ngx.req.append_body and ngx.req.finish_body APIs. If the buffer_size argument is specified, then its value will be used for the size of the memory buffer for body writing with ngx.req.append_body. If the argument is omitted, then the value specified by the standard client_body_buffer_size directive will be used instead. When the data can no longer be hold in the memory buffer for the request body, then the data will be flushed onto a temporary file just like the standard request body reader in the Nginx core. It is important to always call the ngx.req.finish_body after all the data has been appended onto the current request body. Also, when this function is used together with ngx.req.socket, it is required to call ngx.req.socket before this function, or you will get the "request body already exists" error message. The usage of this function is often like this: This function can be used with ngx.req.append_body, ngx.req.finish_body, and ngx.req.socket to implement efficient input filters in pure Lua (in the context of rewrite_by_lua* or access_by_lua*), which can be used with other Nginx content handler or upstream modules like ngx_http_proxy_module and ngx_http_fastcgi_module. This function was first introduced in the v0.5.11 release. Back to TOC ngx.req.append_body syntax: ngx.req.append_body(data_chunk) context: set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua* Append new data chunk specified by the data_chunk argument onto the existing request body created by the ngx.req.init_body call. When the data can no longer be hold in the memory buffer for the request body, then the data will be flushed onto a temporary file just like the standard request body reader in the Nginx core. It is important to always call the ngx.req.finish_body after all the data has been appended onto the current request body. This function can be used with ngx.req.init_body, ngx.req.finish_body, and ngx.req.socket to implement efficient input filters in pure Lua (in the context of rewrite_by_lua* or access_by_lua*), which can be used with other Nginx content handler or upstream modules like ngx_http_proxy_module and ngx_http_fastcgi_module. This function was first introduced in the v0.5.11 release. See also ngx.req.init_body. Back to TOC ngx.req.finish_body syntax: ngx.req.finish_body() context: set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua* Completes the construction process of the new request body created by the ngx.req.init_body and ngx.req.append_body calls. This function can be used with ngx.req.init_body, ngx.req.append_body, and ngx.req.socket to implement efficient input filters in pure Lua (in the context of rewrite_by_lua* or access_by_lua*), which can be used with other Nginx content handler or upstream modules like ngx_http_proxy_module and ngx_http_fastcgi_module. This function was first introduced in the v0.5.11 release. See also ngx.req.init_body. Back to TOC ngx.req.socket syntax: tcpsock, err = ngx.req.socket() syntax: tcpsock, err = ngx.req.socket(raw) context: rewrite_by_lua*, access_by_lua*, content_by_lua* Returns a read-only cosocket object that wraps the downstream connection. Only receive, receiveany and receiveuntil methods are supported on this object. In case of error, nil will be returned as well as a string describing the error. The socket object returned by this method is usually used to read the current request's body in a streaming fashion. Do not turn on the lua_need_request_body directive, and do not mix this call with ngx.req.read_body and ngx.req.discard_body. If any request body data has been pre-read into the Nginx core request header buffer, the resulting cosocket object will take care of this to avoid potential data loss resulting from such pre-reading. Chunked request bodies are not yet supported in this API. Since the v0.9.0 release, this function accepts an optional boolean raw argument. When this argument is true, this function returns a full-duplex cosocket object wrapping around the raw downstream connection socket, upon which you can call the receive, receiveany, receiveuntil, and send methods. When the raw argument is true, it is required that no pending data from any previous ngx.say, ngx.print, or ngx.send_headers calls exists. So if you have these downstream output calls previously, you should call ngx.flush(true) before calling ngx.req.socket(true) to ensure that there is no pending output data. If the request body has not been read yet, then this "raw socket" can also be used to read the request body. You can use the "raw request socket" returned by ngx.req.socket(true) to implement fancy protocols like WebSocket, or just emit your own raw HTTP response header or body data. You can refer to the lua-resty-websocket library for a real world example. This function was first introduced in the v0.5.0rc1 release. Back to TOC ngx.exec syntax: ngx.exec(uri, args?) context: rewrite_by_lua*, access_by_lua*, content_by_lua* Does an internal redirect to uri with args and is similar to the echo_exec directive of the echo-nginx-module. The optional second args can be used to specify extra URI query arguments, for example: Alternatively, a Lua table can be passed for the args argument for ngx_lua to carry out URI escaping and string concatenation. The result is exactly the same as the previous example. The format for the Lua table passed as the args argument is identical to the format used in the ngx.encode_args method. Named locations are also supported but the second args argument will be ignored if present and the querystring for the new target is inherited from the referring location (if any). GET /foo/file.php?a=hello will return "hello" and not "goodbye" in the example below Note that the ngx.exec method is different from ngx.redirect in that it is purely an internal redirect and that no new external HTTP traffic is involved. Also note that this method call terminates the processing of the current request and that it must be called before ngx.send_headers or explicit response body outputs by either ngx.print or ngx.say. It is recommended that a coding style that combines this method call with the return statement, i.e., return ngx.exec(...) be adopted when this method call is used in contexts other than header_filter_by_lua* to reinforce the fact that the request processing is being terminated. Back to TOC ngx.redirect syntax: ngx.redirect(uri, status?) context: rewrite_by_lua*, access_by_lua*, content_by_lua* Issue an HTTP 301 or 302 redirection to uri. Note: this function throws a Lua error if the uri argument contains unsafe characters (control characters). The optional status parameter specifies the HTTP status code to be used. The following status codes are supported right now: 301 302 (default) 303 307 308 It is 302 (ngx.HTTP_MOVED_TEMPORARILY) by default. Here is an example assuming the current server name is localhost and that it is listening on port 1984: which is equivalent to Redirecting arbitrary external URLs is also supported, for example: We can also use the numerical code directly as the second status argument: This method is similar to the rewrite directive with the redirect modifier in the standard ngx_http_rewrite_module, for example, this nginx.conf snippet is equivalent to the following Lua code while is equivalent to URI arguments can be specified as well, for example: Note that this method call terminates the processing of the current request and that it must be called before ngx.send_headers or explicit response body outputs by either ngx.print or ngx.say. It is recommended that a coding style that combines this method call with the return statement, i.e., return ngx.redirect(...) be adopted when this method call is used in contexts other than header_filter_by_lua* to reinforce the fact that the request processing is being terminated. Back to TOC ngx.send_headers syntax: ok, err = ngx.send_headers() context: rewrite_by_lua*, access_by_lua*, content_by_lua* Explicitly send out the response headers. Since v0.8.3 this function returns 1 on success, or returns nil and a string describing the error otherwise. Note that there is normally no need to manually send out response headers as ngx_lua will automatically send headers out before content is output with ngx.say or ngx.print or when content_by_lua* exits normally. Back to TOC ngx.headers_sent syntax: value = ngx.headers_sent context: set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua* Returns true if the response headers have been sent (by ngx_lua), and false otherwise. This API was first introduced in ngx_lua v0.3.1rc6. Back to TOC ngx.print syntax: ok, err = ngx.print(...) context: rewrite_by_lua*, access_by_lua*, content_by_lua* Emits arguments concatenated to the HTTP client (as response body). If response headers have not been sent, this function will send headers out first and then output body data. Since v0.8.3 this function returns 1 on success, or returns nil and a string describing the error otherwise. Lua nil values will output "nil" strings and Lua boolean values will output "true" and "false" literal strings respectively. Nested arrays of strings are permitted and the elements in the arrays will be sent one by one: will yield the output Non-array table arguments will cause a Lua exception to be thrown. The ngx.null constant will yield the "null" string output. This is an asynchronous call and will return immediately without waiting for all the data to be written into the system send buffer. To run in synchronous mode, call ngx.flush(true) after calling ngx.print. This can be particularly useful for streaming output. See ngx.flush for more details. Please note that both ngx.print and ngx.say will always invoke the whole Nginx output body filter chain, which is an expensive operation. So be careful when calling either of these two in a tight loop; buffer the data yourself in Lua and save the calls. Back to TOC ngx.say syntax: ok, err = ngx.say(...) context: rewrite_by_lua*, access_by_lua*, content_by_lua* Just as ngx.print but also emit a trailing newline. Back to TOC ngx.log syntax: ngx.log(log_level, ...) context: init_by_lua*, init_worker_by_lua*, set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, balancer_by_lua*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua*, exit_worker_by_lua* Log arguments concatenated to error.log with the given logging level. Lua nil arguments are accepted and result in literal "nil" string while Lua booleans result in literal "true" or "false" string outputs. And the ngx.null constant will yield the "null" string output. The log_level argument can take constants like ngx.ERR and ngx.WARN. Check out Nginx log level constants for details. There is a hard coded 2048 byte limitation on error message lengths in the Nginx core. This limit includes trailing newlines and leading time stamps. If the message size exceeds this limit, Nginx will truncate the message text accordingly. This limit can be manually modified by editing the NGX_MAX_ERROR_STR macro definition in the src/core/ngx_log.h file in the Nginx source tree. Back to TOC ngx.flush syntax: ok, err = ngx.flush(wait?) context: rewrite_by_lua*, access_by_lua*, content_by_lua* Flushes response output to the client. ngx.flush accepts an optional boolean wait argument (Default: false) first introduced in the v0.3.1rc34 release. When called with the default argument, it issues an asynchronous call (Returns immediately without waiting for output data to be written into the system send buffer). Calling the function with the wait argument set to true switches to synchronous mode. In synchronous mode, the function will not return until all output data has been written into the system send buffer or until the send_timeout setting has expired. Note that using the Lua coroutine mechanism means that this function does not block the Nginx event loop even in the synchronous mode. When ngx.flush(true) is called immediately after ngx.print or ngx.say, it causes the latter functions to run in synchronous mode. This can be particularly useful for streaming output. Note that ngx.flush is not functional when in the HTTP 1.0 output buffering mode. See HTTP 1.0 support. Since v0.8.3 this function returns 1 on success, or returns nil and a string describing the error otherwise. Back to TOC ngx.exit syntax: ngx.exit(status) context: rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, ngx.timer.*, balancer_by_lua*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua* When status >= 200 (i.e., ngx.HTTP_OK and above), it will interrupt the execution of the current request and return status code to Nginx. When status == 0 (i.e., ngx.OK), it will only quit the current phase handler (or the content handler if the content_by_lua* directive is used) and continue to run later phases (if any) for the current request. The status argument can be ngx.OK, ngx.ERROR, ngx.HTTP_NOT_FOUND, ngx.HTTP_MOVED_TEMPORARILY, or other HTTP status constants. To return an error page with custom contents, use code snippets like this: The effect in action: Number literals can be used directly as the argument, for instance, Note that while this method accepts all HTTP status constants as input, it only accepts ngx.OK and ngx.ERROR of the core constants. Also note that this method call terminates the processing of the current request and that it is recommended that a coding style that combines this method call with the return statement, i.e., return ngx.exit(...) be used to reinforce the fact that the request processing is being terminated. When being used in the contexts of header_filter_by_lua*, balancer_by_lua*, and ssl_session_store_by_lua*, ngx.exit() is an asynchronous operation and will return immediately. This behavior may change in future and it is recommended that users always use return in combination as suggested above. Back to TOC ngx.eof syntax: ok, err = ngx.eof() context: rewrite_by_lua*, access_by_lua*, content_by_lua* Explicitly specify the end of the response output stream. In the case of HTTP 1.1 chunked encoded output, it will just trigger the Nginx core to send out the "last chunk". When you disable the HTTP 1.1 keep-alive feature for your downstream connections, you can rely on well written HTTP clients to close the connection actively for you when you call this method. This trick can be used do back-ground jobs without letting the HTTP clients to wait on the connection, as in the following example: But if you create subrequests to access other locations configured by Nginx upstream modules, then you should configure those upstream modules to ignore client connection abortions if they are not by default. For example, by default the standard ngx_http_proxy_module will terminate both the subrequest and the main request as soon as the client closes the connection, so it is important to turn on the proxy_ignore_client_abort directive in your location block configured by ngx_http_proxy_module: A better way to do background jobs is to use the ngx.timer.at API. Since v0.8.3 this function returns 1 on success, or returns nil and a string describing the error otherwise. Back to TOC ngx.sleep syntax: ngx.sleep(seconds) context: rewrite_by_lua*, access_by_lua*, content_by_lua*, ngx.timer.*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua* Sleeps for the specified seconds without blocking. One can specify time resolution up to 0.001 seconds (i.e., one millisecond). Behind the scene, this method makes use of the Nginx timers. Since the 0.7.20 release, The 0 time argument can also be specified. This method was introduced in the 0.5.0rc30 release. Back to TOC ngx.escape_uri syntax: newstr = ngx.escape_uri(str, type?) context: init_by_lua*, init_worker_by_lua*, set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, balancer_by_lua*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua*, exit_worker_by_lua* Since v0.10.16, this function accepts an optional type argument. It accepts the following values (defaults to 2): 0: escapes str as a full URI. And the characters (space), #, %, ?, 0x00 ~ 0x1F, 0x7F ~ 0xFF will be escaped. 2: escape str as a URI component. All characters except alphabetic characters, digits, -, ., _, ~ will be encoded as %XX. Back to TOC ngx.unescape_uri syntax: newstr = ngx.unescape_uri(str) context: init_by_lua*, init_worker_by_lua*, set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, balancer_by_lua*, ssl_certificate_by_lua*, exit_worker_by_lua* Unescape str as an escaped URI component. For example, gives the output b r56 7 Invalid escaping sequences are handled in a conventional way: %s are left unchanged. Also, characters that should not appear in escaped string are simply left unchanged. For example, gives the output try %search% %again% (Note that %20 following % got unescaped, even it can be considered a part of invalid sequence.) Back to TOC ngx.encode_args syntax: str = ngx.encode_args(table) context: set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, balancer_by_lua*, ssl_certificate_by_lua* Encode the Lua table to a query args string according to the URI encoded rules. For example, yields foo=3&b%20r=hello%20world The table keys must be Lua strings. Multi-value query args are also supported. Just use a Lua table for the argument's value, for example: gives baz=32&baz=hello If the value table is empty and the effect is equivalent to the nil value. Boolean argument values are also supported, for instance, yields a&b=1 If the argument value is false, then the effect is equivalent to the nil value. This method was first introduced in the v0.3.1rc27 release. Back to TOC ngx.decode_args syntax: table, err = ngx.decode_args(str, max_args?) context: set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, balancer_by_lua*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua* Decodes a URI encoded query-string into a Lua table. This is the inverse function of ngx.encode_args. The optional max_args argument can be used to specify the maximum number of arguments parsed from the str argument. By default, a maximum of 100 request arguments are parsed (including those with the same name) and that additional URI arguments are silently discarded to guard against potential denial of service attacks. Since v0.10.13, when the limit is exceeded, it will return a second value which is the string "truncated". This argument can be set to zero to remove the limit and to process all request arguments received: Removing the max_args cap is strongly discouraged. This method was introduced in the v0.5.0rc29. Back to TOC ngx.encode_base64 syntax: newstr = ngx.encode_base64(str, no_padding?) context: set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, balancer_by_lua*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua* Encodes str to a base64 digest. Since the 0.9.16 release, an optional boolean-typed no_padding argument can be specified to control whether the base64 padding should be appended to the resulting digest (default to false, i.e., with padding enabled). Back to TOC ngx.decode_base64 syntax: newstr = ngx.decode_base64(str) context: set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, balancer_by_lua*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua* Decodes the str argument as a base64 digest to the raw form. Returns nil if str is not well formed. Back to TOC ngx.crc32_short syntax: intval = ngx.crc32_short(str) context: set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, balancer_by_lua*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua* Calculates the CRC-32 (Cyclic Redundancy Code) digest for the str argument. This method performs better on relatively short str inputs (i.e., less than 30 ~ 60 bytes), as compared to ngx.crc32_long. The result is exactly the same as ngx.crc32_long. Behind the scene, it is just a thin wrapper around the ngx_crc32_short function defined in the Nginx core. This API was first introduced in the v0.3.1rc8 release. Back to TOC ngx.crc32_long syntax: intval = ngx.crc32_long(str) context: set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, balancer_by_lua*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua* Calculates the CRC-32 (Cyclic Redundancy Code) digest for the str argument. This method performs better on relatively long str inputs (i.e., longer than 30 ~ 60 bytes), as compared to ngx.crc32_short. The result is exactly the same as ngx.crc32_short. Behind the scene, it is just a thin wrapper around the ngx_crc32_long function defined in the Nginx core. This API was first introduced in the v0.3.1rc8 release. Back to TOC ngx.hmac_sha1 syntax: digest = ngx.hmac_sha1(secret_key, str) context: set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, balancer_by_lua*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua* Computes the HMAC-SHA1 digest of the argument str and turns the result using the secret key <secret_key>. The raw binary form of the HMAC-SHA1 digest will be generated, use ngx.encode_base64, for example, to encode the result to a textual representation if desired. For example, yields the output R/pvxzHC4NLtj7S+kXFg/NePTmk= This API requires the OpenSSL library enabled in the Nginx build (usually by passing the --with-http_ssl_module option to the ./configure script). This function was first introduced in the v0.3.1rc29 release. Back to TOC ngx.md5 syntax: digest = ngx.md5(str) context: set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, balancer_by_lua*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua* Returns the hexadecimal representation of the MD5 digest of the str argument. For example, yields the output 5d41402abc4b2a76b9719d911017c592 See ngx.md5_bin if the raw binary MD5 digest is required. Back to TOC ngx.md5_bin syntax: digest = ngx.md5_bin(str) context: set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, balancer_by_lua*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua* Returns the binary form of the MD5 digest of the str argument. See ngx.md5 if the hexadecimal form of the MD5 digest is required. Back to TOC ngx.sha1_bin syntax: digest = ngx.sha1_bin(str) context: set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, balancer_by_lua*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua* Returns the binary form of the SHA-1 digest of the str argument. This function requires SHA-1 support in the Nginx build. (This usually just means OpenSSL should be installed while building Nginx). This function was first introduced in the v0.5.0rc6. Back to TOC ngx.quote_sql_str syntax: quoted_value = ngx.quote_sql_str(raw_value) context: set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, balancer_by_lua*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua* Returns a quoted SQL string literal according to the MySQL quoting rules. Back to TOC ngx.today syntax: str = ngx.today() context: init_worker_by_lua*, set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, balancer_by_lua*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua*, exit_worker_by_lua* Returns current date (in the format yyyy-mm-dd) from the Nginx cached time (no syscall involved unlike Lua's date library). This is the local time. Back to TOC ngx.time syntax: secs = ngx.time() context: init_worker_by_lua*, set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, balancer_by_lua*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua*, exit_worker_by_lua* Returns the elapsed seconds from the epoch for the current time stamp from the Nginx cached time (no syscall involved unlike Lua's date library). Updates of the Nginx time cache can be forced by calling ngx.update_time first. Back to TOC ngx.now syntax: secs = ngx.now() context: init_worker_by_lua*, set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, balancer_by_lua*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua*, exit_worker_by_lua* Returns a floating-point number for the elapsed time in seconds (including milliseconds as the decimal part) from the epoch for the current time stamp from the Nginx cached time (no syscall involved unlike Lua's date library). You can forcibly update the Nginx time cache by calling ngx.update_time first. This API was first introduced in v0.3.1rc32. Back to TOC ngx.update_time syntax: ngx.update_time() context: init_worker_by_lua*, set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, balancer_by_lua*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua*, exit_worker_by_lua* Forcibly updates the Nginx current time cache. This call involves a syscall and thus has some overhead, so do not abuse it. This API was first introduced in v0.3.1rc32. Back to TOC ngx.localtime syntax: str = ngx.localtime() context: init_worker_by_lua*, set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, balancer_by_lua*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua*, exit_worker_by_lua* Returns the current time stamp (in the format yyyy-mm-dd hh:mm:ss) of the Nginx cached time (no syscall involved unlike Lua's os.date function). This is the local time. Back to TOC ngx.utctime syntax: str = ngx.utctime() context: init_worker_by_lua*, set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, balancer_by_lua*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua*, exit_worker_by_lua* Returns the current time stamp (in the format yyyy-mm-dd hh:mm:ss) of the Nginx cached time (no syscall involved unlike Lua's os.date function). This is the UTC time. Back to TOC ngx.cookie_time syntax: str = ngx.cookie_time(sec) context: init_worker_by_lua*, set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, balancer_by_lua*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua*, exit_worker_by_lua* Returns a formatted string can be used as the cookie expiration time. The parameter sec is the time stamp in seconds (like those returned from ngx.time). Back to TOC ngx.http_time syntax: str = ngx.http_time(sec) context: init_worker_by_lua*, set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, balancer_by_lua*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua*, exit_worker_by_lua* Returns a formated string can be used as the http header time (for example, being used in Last-Modified header). The parameter sec is the time stamp in seconds (like those returned from ngx.time). Back to TOC ngx.parse_http_time syntax: sec = ngx.parse_http_time(str) context: init_worker_by_lua*, set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, balancer_by_lua*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua*, exit_worker_by_lua* Parse the http time string (as returned by ngx.http_time) into seconds. Returns the seconds or nil if the input string is in bad forms. Back to TOC ngx.is_subrequest syntax: value = ngx.is_subrequest context: set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua* Returns true if the current request is an Nginx subrequest, or false otherwise. Back to TOC ngx.re.match syntax: captures, err = ngx.re.match(subject, regex, options?, ctx?, res_table?) context: init_worker_by_lua*, set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, balancer_by_lua*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua*, exit_worker_by_lua* Matches the subject string using the Perl compatible regular expression regex with the optional options. Only the first occurrence of the match is returned, or nil if no match is found. In case of errors, like seeing a bad regular expression or exceeding the PCRE stack limit, nil and a string describing the error will be returned. When a match is found, a Lua table captures is returned, where captures[0] holds the whole substring being matched, and captures[1] holds the first parenthesized sub-pattern's capturing, captures[2] the second, and so on. Named captures are also supported since the v0.7.14 release and are returned in the same Lua table as key-value pairs as the numbered captures. Unmatched subpatterns will have false values in their captures table fields. Specify options to control how the match operation will be performed. The following option characters are supported: a anchored mode (only match from the beginning) d enable the DFA mode (or the longest token match semantics). this requires PCRE 6.0+ or else a Lua exception will be thrown. first introduced in ngx_lua v0.3.1rc30. D enable duplicate named pattern support. This allows named subpattern names to be repeated, returning the captures in an array-like Lua table. for example, local m = ngx.re.match("hello, world", "(?<named>\w+), (?<named>\w+)", "D") -- m["named"] == {"hello", "world"} this option was first introduced in the v0.7.14 release. this option requires at least PCRE 8.12. i case insensitive mode (similar to Perl's /i modifier) j enable PCRE JIT compilation, this requires PCRE 8.21+ which must be built with the --enable-jit option. for optimum performance, this option should always be used together with the 'o' option. first introduced in ngx_lua v0.3.1rc30. J enable the PCRE Javascript compatible mode. this option was first introduced in the v0.7.14 release. this option requires at least PCRE 8.12. m multi-line mode (similar to Perl's /m modifier) o compile-once mode (similar to Perl's /o modifier), to enable the worker-process-level compiled-regex cache s single-line mode (similar to Perl's /s modifier) u UTF-8 mode. this requires PCRE to be built with the --enable-utf8 option or else a Lua exception will be thrown. U similar to "u" but disables PCRE's UTF-8 validity check on the subject string. first introduced in ngx_lua v0.8.1. x extended mode (similar to Perl's /x modifier) These options can be combined: The o option is useful for performance tuning, because the regex pattern in question will only be compiled once, cached in the worker-process level, and shared among all requests in the current Nginx worker process. The upper limit of the regex cache can be tuned via the lua_regex_cache_max_entries directive. The optional fourth argument, ctx, can be a Lua table holding an optional pos field. When the pos field in the ctx table argument is specified, ngx.re.match will start matching from that offset (starting from 1). Regardless of the presence of the pos field in the ctx table, ngx.re.match will always set this pos field to the position after the substring matched by the whole pattern in case of a successful match. When match fails, the ctx table will be left intact. The ctx table argument combined with the a regex modifier can be used to construct a lexer atop ngx.re.match. Note that, the options argument is not optional when the ctx argument is specified and that the empty Lua string ("") must be used as placeholder for options if no meaningful regex options are required. This method requires the PCRE library enabled in Nginx (Known Issue With Special Escaping Sequences). To confirm that PCRE JIT is enabled, activate the Nginx debug log by adding the --with-debug option to Nginx or OpenResty's ./configure script. Then, enable the "debug" error log level in error_log directive. The following message will be generated if PCRE JIT is enabled: pcre JIT compiling result: 1 Starting from the 0.9.4 release, this function also accepts a 5th argument, res_table, for letting the caller supply the Lua table used to hold all the capturing results. Starting from 0.9.6, it is the caller's responsibility to ensure this table is empty. This is very useful for recycling Lua tables and saving GC and table allocation overhead. This feature was introduced in the v0.2.1rc11 release. Back to TOC ngx.re.find syntax: from, to, err = ngx.re.find(subject, regex, options?, ctx?, nth?) context: init_worker_by_lua*, set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, balancer_by_lua*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua*, exit_worker_by_lua* Similar to ngx.re.match but only returns the beginning index (from) and end index (to) of the matched substring. The returned indexes are 1-based and can be fed directly into the string.sub API function to obtain the matched substring. In case of errors (like bad regexes or any PCRE runtime errors), this API function returns two nil values followed by a string describing the error. If no match is found, this function just returns a nil value. Below is an example: This example produces the output from: 8 to: 11 matched: 1234 Because this API function does not create new Lua strings nor new Lua tables, it is much faster than ngx.re.match. It should be used wherever possible. Since the 0.9.3 release, an optional 5th argument, nth, is supported to specify which (submatch) capture's indexes to return. When nth is 0 (which is the default), the indexes for the whole matched substring is returned; when nth is 1, then the 1st submatch capture's indexes are returned; when nth is 2, then the 2nd submatch capture is returned, and so on. When the specified submatch does not have a match, then two nil values will be returned. Below is an example for this: This API function was first introduced in the v0.9.2 release. Back to TOC ngx.re.gmatch syntax: iterator, err = ngx.re.gmatch(subject, regex, options?) context: init_worker_by_lua*, set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, balancer_by_lua*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua*, exit_worker_by_lua* Similar to ngx.re.match, but returns a Lua iterator instead, so as to let the user programmer iterate all the matches over the <subject> string argument with the PCRE regex. In case of errors, like seeing an ill-formed regular expression, nil and a string describing the error will be returned. Here is a small example to demonstrate its basic usage: More often we just put it into a Lua loop: The optional options argument takes exactly the same semantics as the ngx.re.match method. The current implementation requires that the iterator returned should only be used in a single request. That is, one should not assign it to a variable belonging to persistent namespace like a Lua package. This method requires the PCRE library enabled in Nginx (Known Issue With Special Escaping Sequences). This feature was first introduced in the v0.2.1rc12 release. Back to TOC ngx.re.sub syntax: newstr, n, err = ngx.re.sub(subject, regex, replace, options?) context: init_worker_by_lua*, set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, balancer_by_lua*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua*, exit_worker_by_lua* Substitutes the first match of the Perl compatible regular expression regex on the subject argument string with the string or function argument replace. The optional options argument has exactly the same meaning as in ngx.re.match. This method returns the resulting new string as well as the number of successful substitutions. In case of failures, like syntax errors in the regular expressions or the <replace> string argument, it will return nil and a string describing the error. When the replace is a string, then it is treated as a special template for string replacement. For example, where $0 referring to the whole substring matched by the pattern and $1 referring to the first parenthesized capturing substring. Curly braces can also be used to disambiguate variable names from the background string literals: Literal dollar sign characters ($) in the replace string argument can be escaped by another dollar sign, for instance, Do not use backlashes to escape dollar signs; it will not work as expected. When the replace argument is of type "function", then it will be invoked with the "match table" as the argument to generate the replace string literal for substitution. The "match table" fed into the replace function is exactly the same as the return value of ngx.re.match. Here is an example: The dollar sign characters in the return value of the replace function argument are not special at all. This method requires the PCRE library enabled in Nginx (Known Issue With Special Escaping Sequences). This feature was first introduced in the v0.2.1rc13 release. Back to TOC ngx.re.gsub syntax: newstr, n, err = ngx.re.gsub(subject, regex, replace, options?) context: init_worker_by_lua*, set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, balancer_by_lua*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua*, exit_worker_by_lua* Just like ngx.re.sub, but does global substitution. Here is some examples: This method requires the PCRE library enabled in Nginx (Known Issue With Special Escaping Sequences). This feature was first introduced in the v0.2.1rc15 release. Back to TOC ngx.shared.DICT syntax: dict = ngx.shared.DICT syntax: dict = ngx.shared[name_var] context: init_by_lua*, init_worker_by_lua*, set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, balancer_by_lua*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua*, exit_worker_by_lua* Fetching the shm-based Lua dictionary object for the shared memory zone named DICT defined by the lua_shared_dict directive. Shared memory zones are always shared by all the Nginx worker processes in the current Nginx server instance. The resulting object dict has the following methods: get get_stale set safe_set add safe_add replace delete incr lpush rpush lpop rpop llen ttl expire flush_all flush_expired get_keys capacity free_space All these methods are atomic operations, that is, safe from concurrent accesses from multiple Nginx worker processes for the same lua_shared_dict zone. Here is an example: Let us test it: The number 8 will be consistently output when accessing /get regardless of how many Nginx workers there are because the dogs dictionary resides in the shared memory and visible to all of the worker processes. The shared dictionary will retain its contents through a server config reload (either by sending the HUP signal to the Nginx process or by using the -s reload command-line option). The contents in the dictionary storage will be lost, however, when the Nginx server quits. This feature was first introduced in the v0.3.1rc22 release. Back to TOC ngx.shared.DICT.get syntax: value, flags = ngx.shared.DICT:get(key) context: set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, balancer_by_lua*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua* Retrieving the value in the dictionary ngx.shared.DICT for the key key. If the key does not exist or has expired, then nil will be returned. In case of errors, nil and a string describing the error will be returned. The value returned will have the original data type when they were inserted into the dictionary, for example, Lua booleans, numbers, or strings. The first argument to this method must be the dictionary object itself, for example, or use Lua's syntactic sugar for method calls: These two forms are fundamentally equivalent. If the user flags is 0 (the default), then no flags value will be returned. This feature was first introduced in the v0.3.1rc22 release. See also ngx.shared.DICT. Back to TOC ngx.shared.DICT.get_stale syntax: value, flags, stale = ngx.shared.DICT:get_stale(key) context: set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, balancer_by_lua*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua* Similar to the get method but returns the value even if the key has already expired. Returns a 3rd value, stale, indicating whether the key has expired or not. Note that the value of an expired key is not guaranteed to be available so one should never rely on the availability of expired items. This method was first introduced in the 0.8.6 release. See also ngx.shared.DICT. Back to TOC ngx.shared.DICT.set syntax: success, err, forcible = ngx.shared.DICT:set(key, value, exptime?, flags?) context: init_by_lua*, set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, balancer_by_lua*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua* Unconditionally sets a key-value pair into the shm-based dictionary ngx.shared.DICT. Returns three values: success: boolean value to indicate whether the key-value pair is stored or not. err: textual error message, can be "no memory". forcible: a boolean value to indicate whether other valid items have been removed forcibly when out of storage in the shared memory zone. The value argument inserted can be Lua booleans, numbers, strings, or nil. Their value type will also be stored into the dictionary and the same data type can be retrieved later via the get method. The optional exptime argument specifies expiration time (in seconds) for the inserted key-value pair. The time resolution is 0.001 seconds. If the exptime takes the value 0 (which is the default), then the item will never expire. The optional flags argument specifies a user flags value associated with the entry to be stored. It can also be retrieved later with the value. The user flags is stored as an unsigned 32-bit integer internally. Defaults to 0. The user flags argument was first introduced in the v0.5.0rc2 release. When it fails to allocate memory for the current key-value item, then set will try removing existing items in the storage according to the Least-Recently Used (LRU) algorithm. Note that, LRU takes priority over expiration time here. If up to tens of existing items have been removed and the storage left is still insufficient (either due to the total capacity limit specified by lua_shared_dict or memory segmentation), then the err return value will be no memory and success will be false. If the sizes of items in the dictionary are not multiples or even powers of a certain value (like 2), it is easier to encounter no memory error because of memory fragmentation. It is recommended to use different dictionaries for different sizes of items. When you encounter no memory error, you can also evict more least-recently-used items by retrying this method call more times to to make room for the current item. If this method succeeds in storing the current item by forcibly removing other not-yet-expired items in the dictionary via LRU, the forcible return value will be true. If it stores the item without forcibly removing other valid items, then the return value forcible will be false. The first argument to this method must be the dictionary object itself, for example, or use Lua's syntactic sugar for method calls: These two forms are fundamentally equivalent. This feature was first introduced in the v0.3.1rc22 release. Please note that while internally the key-value pair is set atomically, the atomicity does not go across the method call boundary. See also ngx.shared.DICT. Back to TOC ngx.shared.DICT.safe_set syntax: ok, err = ngx.shared.DICT:safe_set(key, value, exptime?, flags?) context: init_by_lua*, set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, balancer_by_lua*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua* Similar to the set method, but never overrides the (least recently used) unexpired items in the store when running out of storage in the shared memory zone. In this case, it will immediately return nil and the string "no memory". This feature was first introduced in the v0.7.18 release. See also ngx.shared.DICT. Back to TOC ngx.shared.DICT.add syntax: success, err, forcible = ngx.shared.DICT:add(key, value, exptime?, flags?) context: init_by_lua*, set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, balancer_by_lua*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua* Just like the set method, but only stores the key-value pair into the dictionary ngx.shared.DICT if the key does not exist. If the key argument already exists in the dictionary (and not expired for sure), the success return value will be false and the err return value will be "exists". This feature was first introduced in the v0.3.1rc22 release. See also ngx.shared.DICT. Back to TOC ngx.shared.DICT.safe_add syntax: ok, err = ngx.shared.DICT:safe_add(key, value, exptime?, flags?) context: init_by_lua*, set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, balancer_by_lua*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua* Similar to the add method, but never overrides the (least recently used) unexpired items in the store when running out of storage in the shared memory zone. In this case, it will immediately return nil and the string "no memory". This feature was first introduced in the v0.7.18 release. See also ngx.shared.DICT. Back to TOC ngx.shared.DICT.replace syntax: success, err, forcible = ngx.shared.DICT:replace(key, value, exptime?, flags?) context: init_by_lua*, set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, balancer_by_lua*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua* Just like the set method, but only stores the key-value pair into the dictionary ngx.shared.DICT if the key does exist. If the key argument does not exist in the dictionary (or expired already), the success return value will be false and the err return value will be "not found". This feature was first introduced in the v0.3.1rc22 release. See also ngx.shared.DICT. Back to TOC ngx.shared.DICT.delete syntax: ngx.shared.DICT:delete(key) context: init_by_lua*, set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, balancer_by_lua*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua* Unconditionally removes the key-value pair from the shm-based dictionary ngx.shared.DICT. It is equivalent to ngx.shared.DICT:set(key, nil). This feature was first introduced in the v0.3.1rc22 release. See also ngx.shared.DICT. Back to TOC ngx.shared.DICT.incr syntax: newval, err, forcible? = ngx.shared.DICT:incr(key, value, init?, init_ttl?) context: init_by_lua*, set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, balancer_by_lua*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua* optional requirement: resty.core.shdict or resty.core Increments the (numerical) value for key in the shm-based dictionary ngx.shared.DICT by the step value value. Returns the new resulting number if the operation is successfully completed or nil and an error message otherwise. When the key does not exist or has already expired in the shared dictionary, if the init argument is not specified or takes the value nil, this method will return nil and the error string "not found", or if the init argument takes a number value, this method will create a new key with the value init + value. Like the add method, it also overrides the (least recently used) unexpired items in the store when running out of storage in the shared memory zone. The optional init_ttl argument specifies expiration time (in seconds) of the value when it is initialized via the init argument. The time resolution is 0.001 seconds. If init_ttl takes the value 0 (which is the default), then the item will never expire. This argument cannot be provided without providing the init argument as well, and has no effect if the value already exists (e.g., if it was previously inserted via set or the likes). Note: Usage of the init_ttl argument requires the resty.core.shdict or resty.core modules from the lua-resty-core library. Example: The forcible return value will always be nil when the init argument is not specified. If this method succeeds in storing the current item by forcibly removing other not-yet-expired items in the dictionary via LRU, the forcible return value will be true. If it stores the item without forcibly removing other valid items, then the return value forcible will be false. If the original value is not a valid Lua number in the dictionary, it will return nil and "not a number". The value argument and init argument can be any valid Lua numbers, like negative numbers or floating-point numbers. This method was first introduced in the v0.3.1rc22 release. The optional init parameter was first added in the v0.10.6 release. The optional init_ttl parameter was introduced in the v0.10.12rc2 release. See also ngx.shared.DICT. Back to TOC ngx.shared.DICT.lpush syntax: length, err = ngx.shared.DICT:lpush(key, value) context: init_by_lua*, set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, balancer_by_lua*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua* Inserts the specified (numerical or string) value at the head of the list named key in the shm-based dictionary ngx.shared.DICT. Returns the number of elements in the list after the push operation. If key does not exist, it is created as an empty list before performing the push operation. When the key already takes a value that is not a list, it will return nil and "value not a list". It never overrides the (least recently used) unexpired items in the store when running out of storage in the shared memory zone. In this case, it will immediately return nil and the string "no memory". This feature was first introduced in the v0.10.6 release. See also ngx.shared.DICT. Back to TOC ngx.shared.DICT.rpush syntax: length, err = ngx.shared.DICT:rpush(key, value) context: init_by_lua*, set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, balancer_by_lua*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua* Similar to the lpush method, but inserts the specified (numerical or string) value at the tail of the list named key. This feature was first introduced in the v0.10.6 release. See also ngx.shared.DICT. Back to TOC ngx.shared.DICT.lpop syntax: val, err = ngx.shared.DICT:lpop(key) context: init_by_lua*, set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, balancer_by_lua*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua* Removes and returns the first element of the list named key in the shm-based dictionary ngx.shared.DICT. If key does not exist, it will return nil. When the key already takes a value that is not a list, it will return nil and "value not a list". This feature was first introduced in the v0.10.6 release. See also ngx.shared.DICT. Back to TOC ngx.shared.DICT.rpop syntax: val, err = ngx.shared.DICT:rpop(key) context: init_by_lua*, set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, balancer_by_lua*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua* Removes and returns the last element of the list named key in the shm-based dictionary ngx.shared.DICT. If key does not exist, it will return nil. When the key already takes a value that is not a list, it will return nil and "value not a list". This feature was first introduced in the v0.10.6 release. See also ngx.shared.DICT. Back to TOC ngx.shared.DICT.llen syntax: len, err = ngx.shared.DICT:llen(key) context: init_by_lua*, set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, balancer_by_lua*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua* Returns the number of elements in the list named key in the shm-based dictionary ngx.shared.DICT. If key does not exist, it is interpreted as an empty list and 0 is returned. When the key already takes a value that is not a list, it will return nil and "value not a list". This feature was first introduced in the v0.10.6 release. See also ngx.shared.DICT. Back to TOC ngx.shared.DICT.ttl syntax: ttl, err = ngx.shared.DICT:ttl(key) context: init_by_lua*, set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, balancer_by_lua*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua* requires: resty.core.shdict or resty.core Retrieves the remaining TTL (time-to-live in seconds) of a key-value pair in the shm-based dictionary ngx.shared.DICT. Returns the TTL as a number if the operation is successfully completed or nil and an error message otherwise. If the key does not exist (or has already expired), this method will return nil and the error string "not found". The TTL is originally determined by the exptime argument of the set, add, replace (and the likes) methods. It has a time resolution of 0.001 seconds. A value of 0 means that the item will never expire. Example: This feature was first introduced in the v0.10.11 release. Note: This method requires the resty.core.shdict or resty.core modules from the lua-resty-core library. See also ngx.shared.DICT. Back to TOC ngx.shared.DICT.expire syntax: success, err = ngx.shared.DICT:expire(key, exptime) context: init_by_lua*, set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, balancer_by_lua*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua* requires: resty.core.shdict or resty.core Updates the exptime (in second) of a key-value pair in the shm-based dictionary ngx.shared.DICT. Returns a boolean indicating success if the operation completes or nil and an error message otherwise. If the key does not exist, this method will return nil and the error string "not found". The exptime argument has a resolution of 0.001 seconds. If exptime is 0, then the item will never expire. Example: This feature was first introduced in the v0.10.11 release. Note: This method requires the resty.core.shdict or resty.core modules from the lua-resty-core library. See also ngx.shared.DICT. Back to TOC ngx.shared.DICT.flush_all syntax: ngx.shared.DICT:flush_all() context: init_by_lua*, set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, balancer_by_lua*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua* Flushes out all the items in the dictionary. This method does not actually free up all the memory blocks in the dictionary but just marks all the existing items as expired. This feature was first introduced in the v0.5.0rc17 release. See also ngx.shared.DICT.flush_expired and ngx.shared.DICT. Back to TOC ngx.shared.DICT.flush_expired syntax: flushed = ngx.shared.DICT:flush_expired(max_count?) context: init_by_lua*, set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, balancer_by_lua*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua* Flushes out the expired items in the dictionary, up to the maximal number specified by the optional max_count argument. When the max_count argument is given 0 or not given at all, then it means unlimited. Returns the number of items that have actually been flushed. Unlike the flush_all method, this method actually frees up the memory used by the expired items. This feature was first introduced in the v0.6.3 release. See also ngx.shared.DICT.flush_all and ngx.shared.DICT. Back to TOC ngx.shared.DICT.get_keys syntax: keys = ngx.shared.DICT:get_keys(max_count?) context: init_by_lua*, set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, balancer_by_lua*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua* Fetch a list of the keys from the dictionary, up to <max_count>. By default, only the first 1024 keys (if any) are returned. When the <max_count> argument is given the value 0, then all the keys will be returned even there is more than 1024 keys in the dictionary. CAUTION Avoid calling this method on dictionaries with a very large number of keys as it may lock the dictionary for significant amount of time and block Nginx worker processes trying to access the dictionary. This feature was first introduced in the v0.7.3 release. Back to TOC ngx.shared.DICT.capacity syntax: capacity_bytes = ngx.shared.DICT:capacity() context: init_by_lua*, set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, balancer_by_lua*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua* requires: resty.core.shdict or resty.core Retrieves the capacity in bytes for the shm-based dictionary ngx.shared.DICT declared with the lua_shared_dict directive. Example: This feature was first introduced in the v0.10.11 release. Note: This method requires the resty.core.shdict or resty.core modules from the lua-resty-core library. This feature requires at least Nginx core version 0.7.3. See also ngx.shared.DICT. Back to TOC ngx.shared.DICT.free_space syntax: free_page_bytes = ngx.shared.DICT:free_space() context: init_by_lua*, set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, balancer_by_lua*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua* requires: resty.core.shdict or resty.core Retrieves the free page size in bytes for the shm-based dictionary ngx.shared.DICT. Note: The memory for ngx.shared.DICT is allocated via the Nginx slab allocator which has each slot for data size ranges like \~8, 9\~16, 17\~32, ..., 1025\~2048, 2048\~ bytes. And pages are assigned to a slot if there is no room in already assigned pages for the slot. So even if the return value of the free_space method is zero, there may be room in already assigned pages, so you may successfully set a new key value pair to the shared dict without getting true for forcible or non nil err from the ngx.shared.DICT.set. On the other hand, if already assigned pages for a slot are full and a new key value pair is added to the slot and there is no free page, you may get true for forcible or non nil err from the ngx.shared.DICT.set method. Example: This feature was first introduced in the v0.10.11 release. Note: This method requires the resty.core.shdict or resty.core modules from the lua-resty-core library. This feature requires at least Nginx core version 1.11.7. See also ngx.shared.DICT. Back to TOC ngx.socket.udp syntax: udpsock = ngx.socket.udp() context: rewrite_by_lua*, access_by_lua*, content_by_lua*, ngx.timer.*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua* Creates and returns a UDP or datagram-oriented unix domain socket object (also known as one type of the "cosocket" objects). The following methods are supported on this object: setpeername send receive close settimeout It is intended to be compatible with the UDP API of the LuaSocket library but is 100% nonblocking out of the box. This feature was first introduced in the v0.5.7 release. See also ngx.socket.tcp. Back to TOC udpsock:setpeername syntax: ok, err = udpsock:setpeername(host, port) syntax: ok, err = udpsock:setpeername("unix:/path/to/unix-domain.socket") context: rewrite_by_lua*, access_by_lua*, content_by_lua*, ngx.timer.*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua* Attempts to connect a UDP socket object to a remote server or to a datagram unix domain socket file. Because the datagram protocol is actually connection-less, this method does not really establish a "connection", but only just set the name of the remote peer for subsequent read/write operations. Both IP addresses and domain names can be specified as the host argument. In case of domain names, this method will use Nginx core's dynamic resolver to parse the domain name without blocking and it is required to configure the resolver directive in the nginx.conf file like this: If the nameserver returns multiple IP addresses for the host name, this method will pick up one randomly. In case of error, the method returns nil followed by a string describing the error. In case of success, the method returns 1. Here is an example for connecting to a UDP (memcached) server: Since the v0.7.18 release, connecting to a datagram unix domain socket file is also possible on Linux: assuming the datagram service is listening on the unix domain socket file /tmp/some-datagram-service.sock and the client socket will use the "autobind" feature on Linux. Calling this method on an already connected socket object will cause the original connection to be closed first. This method was first introduced in the v0.5.7 release. Back to TOC udpsock:send syntax: ok, err = udpsock:send(data) context: rewrite_by_lua*, access_by_lua*, content_by_lua*, ngx.timer.*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua* Sends data on the current UDP or datagram unix domain socket object. In case of success, it returns 1. Otherwise, it returns nil and a string describing the error. The input argument data can either be a Lua string or a (nested) Lua table holding string fragments. In case of table arguments, this method will copy all the string elements piece by piece to the underlying Nginx socket send buffers, which is usually optimal than doing string concatenation operations on the Lua land. This feature was first introduced in the v0.5.7 release. Back to TOC udpsock:receive syntax: data, err = udpsock:receive(size?) context: rewrite_by_lua*, access_by_lua*, content_by_lua*, ngx.timer.*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua* Receives data from the UDP or datagram unix domain socket object with an optional receive buffer size argument, size. This method is a synchronous operation and is 100% nonblocking. In case of success, it returns the data received; in case of error, it returns nil with a string describing the error. If the size argument is specified, then this method will use this size as the receive buffer size. But when this size is greater than 8192, then 8192 will be used instead. If no argument is specified, then the maximal buffer size, 8192 is assumed. Timeout for the reading operation is controlled by the lua_socket_read_timeout config directive and the settimeout method. And the latter takes priority. For example: It is important here to call the settimeout method before calling this method. This feature was first introduced in the v0.5.7 release. Back to TOC udpsock:close syntax: ok, err = udpsock:close() context: rewrite_by_lua*, access_by_lua*, content_by_lua*, ngx.timer.*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua* Closes the current UDP or datagram unix domain socket. It returns the 1 in case of success and returns nil with a string describing the error otherwise. Socket objects that have not invoked this method (and associated connections) will be closed when the socket object is released by the Lua GC (Garbage Collector) or the current client HTTP request finishes processing. This feature was first introduced in the v0.5.7 release. Back to TOC udpsock:settimeout syntax: udpsock:settimeout(time) context: rewrite_by_lua*, access_by_lua*, content_by_lua*, ngx.timer.*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua* Set the timeout value in milliseconds for subsequent socket operations (like receive). Settings done by this method takes priority over those config directives, like lua_socket_read_timeout. This feature was first introduced in the v0.5.7 release. Back to TOC ngx.socket.stream Just an alias to ngx.socket.tcp. If the stream-typed cosocket may also connect to a unix domain socket, then this API name is preferred. This API function was first added to the v0.10.1 release. Back to TOC ngx.socket.tcp syntax: tcpsock = ngx.socket.tcp() context: rewrite_by_lua*, access_by_lua*, content_by_lua*, ngx.timer.*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua* Creates and returns a TCP or stream-oriented unix domain socket object (also known as one type of the "cosocket" objects). The following methods are supported on this object: connect sslhandshake send receive close settimeout settimeouts setoption receiveany receiveuntil setkeepalive getreusedtimes It is intended to be compatible with the TCP API of the LuaSocket library but is 100% nonblocking out of the box. Also, we introduce some new APIs to provide more functionalities. The cosocket object created by this API function has exactly the same lifetime as the Lua handler creating it. So never pass the cosocket object to any other Lua handler (including ngx.timer callback functions) and never share the cosocket object between different Nginx requests. For every cosocket object's underlying connection, if you do not explicitly close it (via close) or put it back to the connection pool (via setkeepalive), then it is automatically closed when one of the following two events happens: the current request handler completes, or the Lua cosocket object value gets collected by the Lua GC. Fatal errors in cosocket operations always automatically close the current connection (note that, read timeout error is the only error that is not fatal), and if you call close on a closed connection, you will get the "closed" error. Starting from the 0.9.9 release, the cosocket object here is full-duplex, that is, a reader "light thread" and a writer "light thread" can operate on a single cosocket object simultaneously (both "light threads" must belong to the same Lua handler though, see reasons above). But you cannot have two "light threads" both reading (or writing or connecting) the same cosocket, otherwise you might get an error like "socket busy reading" when calling the methods of the cosocket object. This feature was first introduced in the v0.5.0rc1 release. See also ngx.socket.udp. Back to TOC tcpsock:connect syntax: ok, err = tcpsock:connect(host, port, options_table?) syntax: ok, err = tcpsock:connect("unix:/path/to/unix-domain.socket", options_table?) context: rewrite_by_lua*, access_by_lua*, content_by_lua*, ngx.timer.*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua* Attempts to connect a TCP socket object to a remote server or to a stream unix domain socket file without blocking. Before actually resolving the host name and connecting to the remote backend, this method will always look up the connection pool for matched idle connections created by previous calls of this method (or the ngx.socket.connect function). Both IP addresses and domain names can be specified as the host argument. In case of domain names, this method will use Nginx core's dynamic resolver to parse the domain name without blocking and it is required to configure the resolver directive in the nginx.conf file like this: If the nameserver returns multiple IP addresses for the host name, this method will pick up one randomly. In case of error, the method returns nil followed by a string describing the error. In case of success, the method returns 1. Here is an example for connecting to a TCP server: Connecting to a Unix Domain Socket file is also possible: assuming memcached (or something else) is listening on the unix domain socket file /tmp/memcached.sock. Timeout for the connecting operation is controlled by the lua_socket_connect_timeout config directive and the settimeout method. And the latter takes priority. For example: It is important here to call the settimeout method before calling this method. Calling this method on an already connected socket object will cause the original connection to be closed first. An optional Lua table can be specified as the last argument to this method to specify various connect options: pool specify a custom name for the connection pool being used. If omitted, then the connection pool name will be generated from the string template "<host>:<port>" or "<unix-socket-path>". pool_size specify the size of the connection pool. If omitted and no backlog option was provided, no pool will be created. If omitted but backlog was provided, the pool will be created with a default size equal to the value of the lua_socket_pool_size directive. The connection pool holds up to pool_size alive connections ready to be reused by subsequent calls to connect, but note that there is no upper limit to the total number of opened connections outside of the pool. If you need to restrict the total number of opened connections, specify the backlog option. When the connection pool would exceed its size limit, the least recently used (kept-alive) connection already in the pool will be closed to make room for the current connection. Note that the cosocket connection pool is per Nginx worker process rather than per Nginx server instance, so the size limit specified here also applies to every single Nginx worker process. Also note that the size of the connection pool cannot be changed once it has been created. This option was first introduced in the v0.10.14 release. backlog if specified, this module will limit the total number of opened connections for this pool. No more connections than pool_size can be opened for this pool at any time. If the connection pool is full, subsequent connect operations will be queued into a queue equal to this option's value (the "backlog" queue). If the number of queued connect operations is equal to backlog, subsequent connect operations will fail and return nil plus the error string "too many waiting connect operations". The queued connect operations will be resumed once the number of connections in the pool is less than pool_size. The queued connect operation will abort once they have been queued for more than connect_timeout, controlled by settimeouts, and will return nil plus the error string "timeout". This option was first introduced in the v0.10.14 release. The support for the options table argument was first introduced in the v0.5.7 release. This method was first introduced in the v0.5.0rc1 release. Back to TOC tcpsock:sslhandshake syntax: session, err = tcpsock:sslhandshake(reused_session?, server_name?, ssl_verify?, send_status_req?) context: rewrite_by_lua*, access_by_lua*, content_by_lua*, ngx.timer.*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua* Does SSL/TLS handshake on the currently established connection. The optional reused_session argument can take a former SSL session userdata returned by a previous sslhandshake call for exactly the same target. For short-lived connections, reusing SSL sessions can usually speed up the handshake by one order by magnitude but it is not so useful if the connection pool is enabled. This argument defaults to nil. If this argument takes the boolean false value, no SSL session userdata would return by this call and only a Lua boolean will be returned as the first return value; otherwise the current SSL session will always be returned as the first argument in case of successes. The optional server_name argument is used to specify the server name for the new TLS extension Server Name Indication (SNI). Use of SNI can make different servers share the same IP address on the server side. Also, when SSL verification is enabled, this server_name argument is also used to validate the server name specified in the server certificate sent from the remote. The optional ssl_verify argument takes a Lua boolean value to control whether to perform SSL verification. When set to true, the server certificate will be verified according to the CA certificates specified by the lua_ssl_trusted_certificate directive. You may also need to adjust the lua_ssl_verify_depth directive to control how deep we should follow along the certificate chain. Also, when the ssl_verify argument is true and the server_name argument is also specified, the latter will be used to validate the server name in the server certificate. The optional send_status_req argument takes a boolean that controls whether to send the OCSP status request in the SSL handshake request (which is for requesting OCSP stapling). For connections that have already done SSL/TLS handshake, this method returns immediately. This method was first introduced in the v0.9.11 release. Back to TOC tcpsock:send syntax: bytes, err = tcpsock:send(data) context: rewrite_by_lua*, access_by_lua*, content_by_lua*, ngx.timer.*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua* Sends data without blocking on the current TCP or Unix Domain Socket connection. This method is a synchronous operation that will not return until all the data has been flushed into the system socket send buffer or an error occurs. In case of success, it returns the total number of bytes that have been sent. Otherwise, it returns nil and a string describing the error. The input argument data can either be a Lua string or a (nested) Lua table holding string fragments. In case of table arguments, this method will copy all the string elements piece by piece to the underlying Nginx socket send buffers, which is usually optimal than doing string concatenation operations on the Lua land. Timeout for the sending operation is controlled by the lua_socket_send_timeout config directive and the settimeout method. And the latter takes priority. For example: It is important here to call the settimeout method before calling this method. In case of any connection errors, this method always automatically closes the current connection. This feature was first introduced in the v0.5.0rc1 release. Back to TOC tcpsock:receive syntax: data, err, partial = tcpsock:receive(size) syntax: data, err, partial = tcpsock:receive(pattern?) context: rewrite_by_lua*, access_by_lua*, content_by_lua*, ngx.timer.*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua* Receives data from the connected socket according to the reading pattern or size. This method is a synchronous operation just like the send method and is 100% nonblocking. In case of success, it returns the data received; in case of error, it returns nil with a string describing the error and the partial data received so far. If a number-like argument is specified (including strings that look like numbers), then it is interpreted as a size. This method will not return until it reads exactly this size of data or an error occurs. If a non-number-like string argument is specified, then it is interpreted as a "pattern". The following patterns are supported: '*a': reads from the socket until the connection is closed. No end-of-line translation is performed; '*l': reads a line of text from the socket. The line is terminated by a Line Feed (LF) character (ASCII 10), optionally preceded by a Carriage Return (CR) character (ASCII 13). The CR and LF characters are not included in the returned line. In fact, all CR characters are ignored by the pattern. If no argument is specified, then it is assumed to be the pattern '*l', that is, the line reading pattern. Timeout for the reading operation is controlled by the lua_socket_read_timeout config directive and the settimeout method. And the latter takes priority. For example: It is important here to call the settimeout method before calling this method. Since the v0.8.8 release, this method no longer automatically closes the current connection when the read timeout error happens. For other connection errors, this method always automatically closes the connection. This feature was first introduced in the v0.5.0rc1 release. Back to TOC tcpsock:receiveany syntax: data, err = tcpsock:receiveany(max) context: rewrite_by_lua*, access_by_lua*, content_by_lua*, ngx.timer.*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua* Returns any data received by the connected socket, at most max bytes. This method is a synchronous operation just like the send method and is 100% nonblocking. In case of success, it returns the data received; in case of error, it returns nil with a string describing the error. If the received data is more than this size, this method will return with exactly this size of data. The remaining data in the underlying receive buffer could be returned in the next reading operation. Timeout for the reading operation is controlled by the lua_socket_read_timeout config directive and the settimeouts method. And the latter takes priority. For example: This method doesn't automatically close the current connection when the read timeout error occurs. For other connection errors, this method always automatically closes the connection. This feature was first introduced in the v0.10.14 release. Back to TOC tcpsock:receiveuntil syntax: iterator = tcpsock:receiveuntil(pattern, options?) context: rewrite_by_lua*, access_by_lua*, content_by_lua*, ngx.timer.*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua* This method returns an iterator Lua function that can be called to read the data stream until it sees the specified pattern or an error occurs. Here is an example for using this method to read a data stream with the boundary sequence --abcedhb: When called without any argument, the iterator function returns the received data right before the specified pattern string in the incoming data stream. So for the example above, if the incoming data stream is 'hello, world! -agentzh\r\n--abcedhb blah blah', then the string 'hello, world! -agentzh' will be returned. In case of error, the iterator function will return nil along with a string describing the error and the partial data bytes that have been read so far. The iterator function can be called multiple times and can be mixed safely with other cosocket method calls or other iterator function calls. The iterator function behaves differently (i.e., like a real iterator) when it is called with a size argument. That is, it will read that size of data on each invocation and will return nil at the last invocation (either sees the boundary pattern or meets an error). For the last successful invocation of the iterator function, the err return value will be nil too. The iterator function will be reset after the last successful invocation that returns nil data and nil error. Consider the following example: Then for the incoming data stream 'hello, world! -agentzh\r\n--abcedhb blah blah', we shall get the following output from the sample code above: read chunk: [hell] read chunk: [o, w] read chunk: [orld] read chunk: [! -a] read chunk: [gent] read chunk: [zh] read done Note that, the actual data returned might be a little longer than the size limit specified by the size argument when the boundary pattern has ambiguity for streaming parsing. Near the boundary of the data stream, the data string actually returned could also be shorter than the size limit. Timeout for the iterator function's reading operation is controlled by the lua_socket_read_timeout config directive and the settimeout method. And the latter takes priority. For example: It is important here to call the settimeout method before calling the iterator function (note that the receiveuntil call is irrelevant here). As from the v0.5.1 release, this method also takes an optional options table argument to control the behavior. The following options are supported: inclusive The inclusive takes a boolean value to control whether to include the pattern string in the returned data string. Default to false. For example, Then for the input data stream "hello world _END_ blah blah blah", then the example above will output hello world _END_, including the pattern string _END_ itself. Since the v0.8.8 release, this method no longer automatically closes the current connection when the read timeout error happens. For other connection errors, this method always automatically closes the connection. This method was first introduced in the v0.5.0rc1 release. Back to TOC tcpsock:close syntax: ok, err = tcpsock:close() context: rewrite_by_lua*, access_by_lua*, content_by_lua*, ngx.timer.*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua* Closes the current TCP or stream unix domain socket. It returns the 1 in case of success and returns nil with a string describing the error otherwise. Note that there is no need to call this method on socket objects that have invoked the setkeepalive method because the socket object is already closed (and the current connection is saved into the built-in connection pool). Socket objects that have not invoked this method (and associated connections) will be closed when the socket object is released by the Lua GC (Garbage Collector) or the current client HTTP request finishes processing. This feature was first introduced in the v0.5.0rc1 release. Back to TOC tcpsock:settimeout syntax: tcpsock:settimeout(time) context: rewrite_by_lua*, access_by_lua*, content_by_lua*, ngx.timer.*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua* Set the timeout value in milliseconds for subsequent socket operations (connect, receive, and iterators returned from receiveuntil). Settings done by this method take priority over those specified via config directives (i.e. lua_socket_connect_timeout, lua_socket_send_timeout, and lua_socket_read_timeout). Note that this method does not affect the lua_socket_keepalive_timeout setting; the timeout argument to the setkeepalive method should be used for this purpose instead. This feature was first introduced in the v0.5.0rc1 release. Back to TOC tcpsock:settimeouts syntax: tcpsock:settimeouts(connect_timeout, send_timeout, read_timeout) context: rewrite_by_lua*, access_by_lua*, content_by_lua*, ngx.timer.*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua* Respectively sets the connect, send, and read timeout thresholds (in milliseconds) for subsequent socket operations (connect, send, receive, and iterators returned from receiveuntil). Settings done by this method take priority over those specified via config directives (i.e. lua_socket_connect_timeout, lua_socket_send_timeout, and lua_socket_read_timeout). It is recommended to use settimeouts instead of settimeout. Note that this method does not affect the lua_socket_keepalive_timeout setting; the timeout argument to the setkeepalive method should be used for this purpose instead. This feature was first introduced in the v0.10.7 release. Back to TOC tcpsock:setoption syntax: ok, err = tcpsock:setoption(option, value?) context: rewrite_by_lua*, access_by_lua*, content_by_lua*, ngx.timer.*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua* This function is added for LuaSocket API compatibility and does nothing for now. Its functionality is implemented v0.10.18. This feature was first introduced in the v0.5.0rc1 release. In case of success, it returns true. Otherwise, it returns nil and a string describing the error. The option is a string with the option name, and the value depends on the option being set: keepalive Setting this option to true enables sending of keep-alive messages on connection-oriented sockets. Make sure the connect function had been called before, for example, reuseaddr Enabling this option indicates that the rules used in validating addresses supplied in a call to bind should allow reuse of local addresses. Make sure the connect function had been called before, for example, tcp-nodelay Setting this option to true disables the Nagle's algorithm for the connection. Make sure the connect function had been called before, for example, sndbuf Sets the maximum socket send buffer in bytes. The kernel doubles this value (to allow space for bookkeeping overhead) when it is set using setsockopt(). Make sure the connect function had been called before, for example, rcvbuf Sets the maximum socket receive buffer in bytes. The kernel doubles this value (to allow space for bookkeeping overhead) when it is set using setsockopt. Make sure the connect function had been called before, for example, NOTE: Once the option is set, it will become effective until the connection is closed. If you know the connection is from the connection pool and all the in-pool connections already have called the setoption() method with the desired socket option state, then you can just skip calling setoption() again to avoid the overhead of repeated calls, for example, These options described above are supported in v0.10.18, and more options will be implemented in future. Back to TOC tcpsock:setkeepalive syntax: ok, err = tcpsock:setkeepalive(timeout?, size?) context: rewrite_by_lua*, access_by_lua*, content_by_lua*, ngx.timer.*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua* Puts the current socket's connection immediately into the cosocket built-in connection pool and keep it alive until other connect method calls request it or the associated maximal idle timeout is expired. The first optional argument, timeout, can be used to specify the maximal idle timeout (in milliseconds) for the current connection. If omitted, the default setting in the lua_socket_keepalive_timeout config directive will be used. If the 0 value is given, then the timeout interval is unlimited. The second optional argument size is considered deprecated since the v0.10.14 release of this module, in favor of the pool_size option of the connect method. Since the v0.10.14 release, this option will only take effect if the call to connect did not already create a connection pool. When this option takes effect (no connection pool was previously created by connect), it will specify the size of the connection pool, and create it. If omitted (and no pool was previously created), the default size is the value of the lua_socket_pool_size directive. The connection pool holds up to size alive connections ready to be reused by subsequent calls to connect, but note that there is no upper limit to the total number of opened connections outside of the pool. When the connection pool would exceed its size limit, the least recently used (kept-alive) connection already in the pool will be closed to make room for the current connection. Note that the cosocket connection pool is per Nginx worker process rather than per Nginx server instance, so the size limit specified here also applies to every single Nginx worker process. Also note that the size of the connection pool cannot be changed once it has been created. If you need to restrict the total number of opened connections, specify both the pool_size and backlog option in the call to connect. In case of success, this method returns 1; otherwise, it returns nil and a string describing the error. When the system receive buffer for the current connection has unread data, then this method will return the "connection in dubious state" error message (as the second return value) because the previous session has unread data left behind for the next session and the connection is not safe to be reused. This method also makes the current cosocket object enter the "closed" state, so there is no need to manually call the close method on it afterwards. This feature was first introduced in the v0.5.0rc1 release. Back to TOC tcpsock:getreusedtimes syntax: count, err = tcpsock:getreusedtimes() context: rewrite_by_lua*, access_by_lua*, content_by_lua*, ngx.timer.*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua* This method returns the (successfully) reused times for the current connection. In case of error, it returns nil and a string describing the error. If the current connection does not come from the built-in connection pool, then this method always returns 0, that is, the connection has never been reused (yet). If the connection comes from the connection pool, then the return value is always non-zero. So this method can also be used to determine if the current connection comes from the pool. This feature was first introduced in the v0.5.0rc1 release. Back to TOC ngx.socket.connect syntax: tcpsock, err = ngx.socket.connect(host, port) syntax: tcpsock, err = ngx.socket.connect("unix:/path/to/unix-domain.socket") context: rewrite_by_lua*, access_by_lua*, content_by_lua*, ngx.timer.* This function is a shortcut for combining ngx.socket.tcp() and the connect() method call in a single operation. It is actually implemented like this: There is no way to use the settimeout method to specify connecting timeout for this method and the lua_socket_connect_timeout directive must be set at configure time instead. This feature was first introduced in the v0.5.0rc1 release. Back to TOC ngx.get_phase syntax: str = ngx.get_phase() context: init_by_lua*, init_worker_by_lua*, set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, balancer_by_lua*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua*, exit_worker_by_lua* Retrieves the current running phase name. Possible return values are init for the context of init_by_lua*. init_worker for the context of init_worker_by_lua*. ssl_cert for the context of ssl_certificate_by_lua*. ssl_session_fetch for the context of ssl_session_fetch_by_lua*. ssl_session_store for the context of ssl_session_store_by_lua*. set for the context of set_by_lua*. rewrite for the context of rewrite_by_lua*. balancer for the context of balancer_by_lua*. access for the context of access_by_lua*. content for the context of content_by_lua*. header_filter for the context of header_filter_by_lua*. body_filter for the context of body_filter_by_lua*. log for the context of log_by_lua*. timer for the context of user callback functions for ngx.timer.*. exit_worker for the context of exit_worker_by_lua*. This API was first introduced in the v0.5.10 release. Back to TOC ngx.thread.spawn syntax: co = ngx.thread.spawn(func, arg1, arg2, ...) context: rewrite_by_lua*, access_by_lua*, content_by_lua*, ngx.timer.*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua* Spawns a new user "light thread" with the Lua function func as well as those optional arguments arg1, arg2, and etc. Returns a Lua thread (or Lua coroutine) object represents this "light thread". "Light threads" are just a special kind of Lua coroutines that are scheduled by the ngx_lua module. Before ngx.thread.spawn returns, the func will be called with those optional arguments until it returns, aborts with an error, or gets yielded due to I/O operations via the Nginx API for Lua (like tcpsock:receive). After ngx.thread.spawn returns, the newly-created "light thread" will keep running asynchronously usually at various I/O events. All the Lua code chunks running by rewrite_by_lua, access_by_lua, and content_by_lua are in a boilerplate "light thread" created automatically by ngx_lua. Such boilerplate "light thread" are also called "entry threads". By default, the corresponding Nginx handler (e.g., rewrite_by_lua handler) will not terminate until both the "entry thread" and all the user "light threads" terminates, a "light thread" (either the "entry thread" or a user "light thread") aborts by calling ngx.exit, ngx.exec, ngx.redirect, or ngx.req.set_uri(uri, true), or the "entry thread" terminates with a Lua error. When the user "light thread" terminates with a Lua error, however, it will not abort other running "light threads" like the "entry thread" does. Due to the limitation in the Nginx subrequest model, it is not allowed to abort a running Nginx subrequest in general. So it is also prohibited to abort a running "light thread" that is pending on one ore more Nginx subrequests. You must call ngx.thread.wait to wait for those "light thread" to terminate before quitting the "world". A notable exception here is that you can abort pending subrequests by calling ngx.exit with and only with the status code ngx.ERROR (-1), 408, 444, or 499. The "light threads" are not scheduled in a pre-emptive way. In other words, no time-slicing is performed automatically. A "light thread" will keep running exclusively on the CPU until a (nonblocking) I/O operation cannot be completed in a single run, it calls coroutine.yield to actively give up execution, or it is aborted by a Lua error or an invocation of ngx.exit, ngx.exec, ngx.redirect, or ngx.req.set_uri(uri, true). For the first two cases, the "light thread" will usually be resumed later by the ngx_lua scheduler unless a "stop-the-world" event happens. User "light threads" can create "light threads" themselves. And normal user coroutines created by coroutine.create can also create "light threads". The coroutine (be it a normal Lua coroutine or a "light thread") that directly spawns the "light thread" is called the "parent coroutine" for the "light thread" newly spawned. The "parent coroutine" can call ngx.thread.wait to wait on the termination of its child "light thread". You can call coroutine.status() and coroutine.yield() on the "light thread" coroutines. The status of the "light thread" coroutine can be "zombie" if the current "light thread" already terminates (either successfully or with an error), its parent coroutine is still alive, and its parent coroutine is not waiting on it with ngx.thread.wait. The following example demonstrates the use of coroutine.yield() in the "light thread" coroutines to do manual time-slicing: Then it will generate the output 0 1 f 1 2 f 2 3 f 3 4 "Light threads" are mostly useful for making concurrent upstream requests in a single Nginx request handler, much like a generalized version of ngx.location.capture_multi that can work with all the Nginx API for Lua. The following example demonstrates parallel requests to MySQL, Memcached, and upstream HTTP services in a single Lua handler, and outputting the results in the order that they actually return (similar to Facebook's BigPipe model): This API was first enabled in the v0.7.0 release. Back to TOC ngx.thread.wait syntax: ok, res1, res2, ... = ngx.thread.wait(thread1, thread2, ...) context: rewrite_by_lua*, access_by_lua*, content_by_lua*, ngx.timer.*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua* Waits on one or more child "light threads" and returns the results of the first "light thread" that terminates (either successfully or with an error). The arguments thread1, thread2, and etc are the Lua thread objects returned by earlier calls of ngx.thread.spawn. The return values have exactly the same meaning as coroutine.resume, that is, the first value returned is a boolean value indicating whether the "light thread" terminates successfully or not, and subsequent values returned are the return values of the user Lua function that was used to spawn the "light thread" (in case of success) or the error object (in case of failure). Only the direct "parent coroutine" can wait on its child "light thread", otherwise a Lua exception will be raised. The following example demonstrates the use of ngx.thread.wait and ngx.location.capture to emulate ngx.location.capture_multi: Here it essentially implements the "wait all" model. And below is an example demonstrating the "wait any" model: And it will generate the following output: f thread created: running g thread created: running g: hello res: g done This API was first enabled in the v0.7.0 release. Back to TOC ngx.thread.kill syntax: ok, err = ngx.thread.kill(thread) context: rewrite_by_lua*, access_by_lua*, content_by_lua*, ngx.timer.*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua* Kills a running "light thread" created by ngx.thread.spawn. Returns a true value when successful or nil and a string describing the error otherwise. According to the current implementation, only the parent coroutine (or "light thread") can kill a thread. Also, a running "light thread" with pending Nginx subrequests (initiated by ngx.location.capture for example) cannot be killed due to a limitation in the Nginx core. This API was first enabled in the v0.9.9 release. Back to TOC ngx.on_abort syntax: ok, err = ngx.on_abort(callback) context: rewrite_by_lua*, access_by_lua*, content_by_lua* Registers a user Lua function as the callback which gets called automatically when the client closes the (downstream) connection prematurely. Returns 1 if the callback is registered successfully or returns nil and a string describing the error otherwise. All the Nginx API for Lua can be used in the callback function because the function is run in a special "light thread", just as those "light threads" created by ngx.thread.spawn. The callback function can decide what to do with the client abortion event all by itself. For example, it can simply ignore the event by doing nothing and the current Lua request handler will continue executing without interruptions. And the callback function can also decide to terminate everything by calling ngx.exit, for example, When lua_check_client_abort is set to off (which is the default), then this function call will always return the error message "lua_check_client_abort is off". According to the current implementation, this function can only be called once in a single request handler; subsequent calls will return the error message "duplicate call". This API was first introduced in the v0.7.4 release. See also lua_check_client_abort. Back to TOC ngx.timer.at syntax: hdl, err = ngx.timer.at(delay, callback, user_arg1, user_arg2, ...) context: init_worker_by_lua*, set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, balancer_by_lua*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua*, exit_worker_by_lua* Creates an Nginx timer with a user callback function as well as optional user arguments. The first argument, delay, specifies the delay for the timer, in seconds. One can specify fractional seconds like 0.001 to mean 1 millisecond here. 0 delay can also be specified, in which case the timer will immediately expire when the current handler yields execution. The second argument, callback, can be any Lua function, which will be invoked later in a background "light thread" after the delay specified. The user callback will be called automatically by the Nginx core with the arguments premature, user_arg1, user_arg2, and etc, where the premature argument takes a boolean value indicating whether it is a premature timer expiration or not, and user_arg1, user_arg2, and etc, are those (extra) user arguments specified when calling ngx.timer.at as the remaining arguments. Premature timer expiration happens when the Nginx worker process is trying to shut down, as in an Nginx configuration reload triggered by the HUP signal or in an Nginx server shutdown. When the Nginx worker is trying to shut down, one can no longer call ngx.timer.at to create new timers with nonzero delays and in that case ngx.timer.at will return a "conditional false" value and a string describing the error, that is, "process exiting". Starting from the v0.9.3 release, it is allowed to create zero-delay timers even when the Nginx worker process starts shutting down. When a timer expires, the user Lua code in the timer callback is running in a "light thread" detached completely from the original request creating the timer. So objects with the same lifetime as the request creating them, like cosockets, cannot be shared between the original request and the timer user callback function. Here is a simple example: One can also create infinite re-occurring timers, for instance, a timer getting triggered every 5 seconds, by calling ngx.timer.at recursively in the timer callback function. Here is such an example, It is recommended, however, to use the ngx.timer.every API function instead for creating recurring timers since it is more robust. Because timer callbacks run in the background and their running time will not add to any client request's response time, they can easily accumulate in the server and exhaust system resources due to either Lua programming mistakes or just too much client traffic. To prevent extreme consequences like crashing the Nginx server, there are built-in limitations on both the number of "pending timers" and the number of "running timers" in an Nginx worker process. The "pending timers" here mean timers that have not yet been expired and "running timers" are those whose user callbacks are currently running. The maximal number of pending timers allowed in an Nginx worker is controlled by the lua_max_pending_timers directive. The maximal number of running timers is controlled by the lua_max_running_timers directive. According to the current implementation, each "running timer" will take one (fake) connection record from the global connection record list configured by the standard worker_connections directive in nginx.conf. So ensure that the worker_connections directive is set to a large enough value that takes into account both the real connections and fake connections required by timer callbacks (as limited by the lua_max_running_timers directive). A lot of the Lua APIs for Nginx are enabled in the context of the timer callbacks, like stream/datagram cosockets (ngx.socket.tcp and ngx.socket.udp), shared memory dictionaries (ngx.shared.DICT), user coroutines (coroutine.*), user "light threads" (ngx.thread.*), ngx.exit, ngx.now/ngx.time, ngx.md5/ngx.sha1_bin, are all allowed. But the subrequest API (like ngx.location.capture), the ngx.req.* API, the downstream output API (like ngx.say, ngx.print, and ngx.flush) are explicitly disabled in this context. You must notice that each timer will be based on a fake request (this fake request is also based on a fake connection). Because Nginx's memory release is based on the connection closure, if you run a lot of APIs that apply for memory resources in a timer, such as tcpsock:connect, will cause the accumulation of memory resources. So it is recommended to create a new timer after running several times to release memory resources. You can pass most of the standard Lua values (nils, booleans, numbers, strings, tables, closures, file handles, and etc) into the timer callback, either explicitly as user arguments or implicitly as upvalues for the callback closure. There are several exceptions, however: you cannot pass any thread objects returned by coroutine.create and ngx.thread.spawn or any cosocket objects returned by ngx.socket.tcp, ngx.socket.udp, and ngx.req.socket because these objects' lifetime is bound to the request context creating them while the timer callback is detached from the creating request's context (by design) and runs in its own (fake) request context. If you try to share the thread or cosocket objects across the boundary of the creating request, then you will get the "no co ctx found" error (for threads) or "bad request" (for cosockets). It is fine, however, to create all these objects inside your timer callback. Please note that the timer Lua handler has its own copy of the ngx.ctx magic table. It won't share the same ngx.ctx with the Lua handler creating the timer. If you need to pass data from the timer creator to the timer handler, please use the extra parameters of ngx.timer.at(). This API was first introduced in the v0.8.0 release. Back to TOC ngx.timer.every syntax: hdl, err = ngx.timer.every(delay, callback, user_arg1, user_arg2, ...) context: init_worker_by_lua*, set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, balancer_by_lua*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua*, exit_worker_by_lua* Similar to the ngx.timer.at API function, but delay cannot be zero, timer will be created every delay seconds until the current Nginx worker process starts exiting. Like ngx.timer.at, the callback argument will be called automatically with the arguments premature, user_arg1, user_arg2, etc. When success, returns a "conditional true" value (but not a true). Otherwise, returns a "conditional false" value and a string describing the error. This API also respect the lua_max_pending_timers and lua_max_running_timers. This API was first introduced in the v0.10.9 release. Back to TOC ngx.timer.running_count syntax: count = ngx.timer.running_count() context: init_worker_by_lua*, set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, balancer_by_lua*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua*, exit_worker_by_lua* Returns the number of timers currently running. This directive was first introduced in the v0.9.20 release. Back to TOC ngx.timer.pending_count syntax: count = ngx.timer.pending_count() context: init_worker_by_lua*, set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, balancer_by_lua*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua*, exit_worker_by_lua* Returns the number of pending timers. This directive was first introduced in the v0.9.20 release. Back to TOC ngx.config.subsystem syntax: subsystem = ngx.config.subsystem context: set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, init_by_lua*, init_worker_by_lua*, exit_worker_by_lua* This string field indicates the Nginx subsystem the current Lua environment is based on. For this module, this field always takes the string value "http". For ngx_stream_lua_module, however, this field takes the value "stream". This field was first introduced in the 0.10.1. Back to TOC ngx.config.debug syntax: debug = ngx.config.debug context: set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, init_by_lua*, init_worker_by_lua*, exit_worker_by_lua* This boolean field indicates whether the current Nginx is a debug build, i.e., being built by the ./configure option --with-debug. This field was first introduced in the 0.8.7. Back to TOC ngx.config.prefix syntax: prefix = ngx.config.prefix() context: set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, init_by_lua*, init_worker_by_lua*, exit_worker_by_lua* Returns the Nginx server "prefix" path, as determined by the -p command-line option when running the Nginx executable, or the path specified by the --prefix command-line option when building Nginx with the ./configure script. This function was first introduced in the 0.9.2. Back to TOC ngx.config.nginx_version syntax: ver = ngx.config.nginx_version context: set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, init_by_lua*, init_worker_by_lua*, exit_worker_by_lua* This field take an integral value indicating the version number of the current Nginx core being used. For example, the version number 1.4.3 results in the Lua number 1004003. This API was first introduced in the 0.9.3 release. Back to TOC ngx.config.nginx_configure syntax: str = ngx.config.nginx_configure() context: set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, init_by_lua* This function returns a string for the Nginx ./configure command's arguments string. This API was first introduced in the 0.9.5 release. Back to TOC ngx.config.ngx_lua_version syntax: ver = ngx.config.ngx_lua_version context: set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, init_by_lua* This field take an integral value indicating the version number of the current ngx_lua module being used. For example, the version number 0.9.3 results in the Lua number 9003. This API was first introduced in the 0.9.3 release. Back to TOC ngx.worker.exiting syntax: exiting = ngx.worker.exiting() context: set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, init_by_lua*, init_worker_by_lua*, exit_worker_by_lua* This function returns a boolean value indicating whether the current Nginx worker process already starts exiting. Nginx worker process exiting happens on Nginx server quit or configuration reload (aka HUP reload). This API was first introduced in the 0.9.3 release. Back to TOC ngx.worker.pid syntax: pid = ngx.worker.pid() context: set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, init_by_lua*, init_worker_by_lua*, exit_worker_by_lua* This function returns a Lua number for the process ID (PID) of the current Nginx worker process. This API is more efficient than ngx.var.pid and can be used in contexts where the ngx.var.VARIABLE API cannot be used (like init_worker_by_lua). This API was first introduced in the 0.9.5 release. Back to TOC ngx.worker.count syntax: count = ngx.worker.count() context: set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, init_by_lua*, init_worker_by_lua*, exit_worker_by_lua* Returns the total number of the Nginx worker processes (i.e., the value configured by the worker_processes directive in nginx.conf). This API was first introduced in the 0.9.20 release. Back to TOC ngx.worker.id syntax: id = ngx.worker.id() context: set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, init_worker_by_lua*, exit_worker_by_lua* Returns the ordinal number of the current Nginx worker processes (starting from number 0). So if the total number of workers is N, then this method may return a number between 0 and N - 1 (inclusive). This function returns meaningful values only for Nginx 1.9.1+. With earlier versions of Nginx, it always returns nil. See also ngx.worker.count. This API was first introduced in the 0.9.20 release. Back to TOC ngx.semaphore syntax: local semaphore = require "ngx.semaphore" This is a Lua module that implements a classic-style semaphore API for efficient synchronizations among different "light threads". Sharing the same semaphore among different "light threads" created in different (request) contexts are also supported as long as the "light threads" reside in the same Nginx worker process and the lua_code_cache directive is turned on (which is the default). This Lua module does not ship with this ngx_lua module itself rather it is shipped with the lua-resty-core library. Please refer to the documentation for this ngx.semaphore Lua module in lua-resty-core for more details. This feature requires at least ngx_lua v0.10.0. Back to TOC ngx.balancer syntax: local balancer = require "ngx.balancer" This is a Lua module that provides a Lua API to allow defining completely dynamic load balancers in pure Lua. This Lua module does not ship with this ngx_lua module itself rather it is shipped with the lua-resty-core library. Please refer to the documentation for this ngx.balancer Lua module in lua-resty-core for more details. This feature requires at least ngx_lua v0.10.0. Back to TOC ngx.ssl syntax: local ssl = require "ngx.ssl" This Lua module provides API functions to control the SSL handshake process in contexts like ssl_certificate_by_lua*. This Lua module does not ship with this ngx_lua module itself rather it is shipped with the lua-resty-core library. Please refer to the documentation for this ngx.ssl Lua module for more details. This feature requires at least ngx_lua v0.10.0. Back to TOC ngx.ocsp syntax: local ocsp = require "ngx.ocsp" This Lua module provides API to perform OCSP queries, OCSP response validations, and OCSP stapling planting. Usually, this module is used together with the ngx.ssl module in the context of ssl_certificate_by_lua*. This Lua module does not ship with this ngx_lua module itself rather it is shipped with the lua-resty-core library. Please refer to the documentation for this ngx.ocsp Lua module for more details. This feature requires at least ngx_lua v0.10.0. Back to TOC ndk.set_var.DIRECTIVE syntax: res = ndk.set_var.DIRECTIVE_NAME context: init_worker_by_lua*, set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, balancer_by_lua*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua*, exit_worker_by_lua* This mechanism allows calling other Nginx C modules' directives that are implemented by Nginx Devel Kit (NDK)'s set_var submodule's ndk_set_var_value. For example, the following set-misc-nginx-module directives can be invoked this way: set_quote_sql_str set_quote_pgsql_str set_quote_json_str set_unescape_uri set_escape_uri set_encode_base32 set_decode_base32 set_encode_base64 set_decode_base64 set_encode_hex set_decode_hex set_sha1 set_md5 For instance, Similarly, the following directives provided by encrypted-session-nginx-module can be invoked from within Lua too: set_encrypt_session set_decrypt_session This feature requires the ngx_devel_kit module. Back to TOC coroutine.create syntax: co = coroutine.create(f) context: rewrite_by_lua*, access_by_lua*, content_by_lua*, init_by_lua*, ngx.timer.*, header_filter_by_lua*, body_filter_by_lua*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua* Creates a user Lua coroutines with a Lua function, and returns a coroutine object. Similar to the standard Lua coroutine.create API, but works in the context of the Lua coroutines created by ngx_lua. This API was first usable in the context of init_by_lua* since the 0.9.2. This API was first introduced in the v0.6.0 release. Back to TOC coroutine.resume syntax: ok, ... = coroutine.resume(co, ...) context: rewrite_by_lua*, access_by_lua*, content_by_lua*, init_by_lua*, ngx.timer.*, header_filter_by_lua*, body_filter_by_lua*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua* Resumes the executation of a user Lua coroutine object previously yielded or just created. Similar to the standard Lua coroutine.resume API, but works in the context of the Lua coroutines created by ngx_lua. This API was first usable in the context of init_by_lua* since the 0.9.2. This API was first introduced in the v0.6.0 release. Back to TOC coroutine.yield syntax: ... = coroutine.yield(...) context: rewrite_by_lua*, access_by_lua*, content_by_lua*, init_by_lua*, ngx.timer.*, header_filter_by_lua*, body_filter_by_lua*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua* Yields the execution of the current user Lua coroutine. Similar to the standard Lua coroutine.yield API, but works in the context of the Lua coroutines created by ngx_lua. This API was first usable in the context of init_by_lua* since the 0.9.2. This API was first introduced in the v0.6.0 release. Back to TOC coroutine.wrap syntax: co = coroutine.wrap(f) context: rewrite_by_lua*, access_by_lua*, content_by_lua*, init_by_lua*, ngx.timer.*, header_filter_by_lua*, body_filter_by_lua*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua* Similar to the standard Lua coroutine.wrap API, but works in the context of the Lua coroutines created by ngx_lua. This API was first usable in the context of init_by_lua* since the 0.9.2. This API was first introduced in the v0.6.0 release. Back to TOC coroutine.running syntax: co = coroutine.running() context: rewrite_by_lua*, access_by_lua*, content_by_lua*, init_by_lua*, ngx.timer.*, header_filter_by_lua*, body_filter_by_lua*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua* Identical to the standard Lua coroutine.running API. This API was first usable in the context of init_by_lua* since the 0.9.2. This API was first enabled in the v0.6.0 release. Back to TOC coroutine.status syntax: status = coroutine.status(co) context: rewrite_by_lua*, access_by_lua*, content_by_lua*, init_by_lua*, ngx.timer.*, header_filter_by_lua*, body_filter_by_lua*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua* Identical to the standard Lua coroutine.status API. This API was first usable in the context of init_by_lua* since the 0.9.2. This API was first enabled in the v0.6.0 release. Back to TOC Obsolete Sections This section is just holding obsolete documentation sections that have been either renamed or removed so that existing links over the web are still valid. Back to TOC Special PCRE Sequences This section has been renamed to Special Escaping Sequences. Back to TOC Lua/LuaJIT bytecode support This section has been renamed to LuaJIT bytecode support. As of version v0.10.16 of this module, the standard Lua interpreter (also known as "PUC-Rio Lua") is not supported anymore.

 # # # # # # # # # # # # # # # # # # # #
 Repository: JakeWharton/hugo, index: 1396, word count: 5250 
 # # # # # # # # # # # # # # # # # # # #

Slim is a template language whose goal is to reduce the syntax to the essential parts without becoming cryptic.Slim Slim is a template language whose goal is to reduce the view syntax to the essential parts without becoming cryptic. It started as an exercise to see how much could be removed from a standard html template (<, >, closing tags, etc...). As more people took an interest in Slim, the functionality grew and so did the flexibility of the syntax. A short list of the features... Elegant syntax Short syntax without closing tags (Using indentation instead) HTML style mode with closing tags Configurable shortcut tags (# for <div id="..."> and . for <div class="..."> in the default configuration) Safety Automatic HTML escaping by default Support for Rails' html_safe? Highly configurable Extensible via the following plugins: Logic less mode similar to Mustache Includes Translator/I18n High performance Comparable speed to ERB/Erubis Streaming support in Rails Supported by all major frameworks (Rails, Sinatra, ...) Full Unicode support for tags and attributes Embedded engines like Markdown and Textile Links Homepage: http://slim-lang.com Source: http://github.com/slim-template/slim Bugs: http://github.com/slim-template/slim/issues List: http://groups.google.com/group/slim-template API documentation: Latest Gem: http://rubydoc.info/gems/slim/frames https://www.omniref.com/ruby/gems/slim GitHub master: http://rubydoc.info/github/slim-template/slim/master/frames https://www.omniref.com/github/slim-template/slim Introduction What is Slim? Slim is a fast, lightweight templating engine with support for Rails 3 and later. It has been heavily tested on all major ruby implementations. We use continuous integration (travis-ci). Slim's core syntax is guided by one thought: "What's the minimum required to make this work". As more people have contributed to Slim, there have been syntax additions influenced from their use of Haml and Jade. The Slim team is open to these additions because we know beauty is in the eye of the beholder. Slim uses Temple for parsing/compilation and is also integrated into Tilt, so it can be used together with Sinatra or plain Rack. The architecture of Temple is very flexible and allows the extension of the parsing and compilation process without monkey-patching. This is used by the logic less plugin and the translator plugin which provides I18n. In logic-less mode you can use Slim if you like the Slim syntax to build your HTML but don't want to write Ruby in your templates. Why use Slim? Slim allows you to write very minimal templates which are easy to maintain and pretty much guarantees that you write well-formed HTML and XML The Slim syntax is aesthetic and makes it more fun to write templates. Since you can use Slim as a drop-in replacement in all the major frameworks it is easy to adopt. The Slim architecture is very flexible and allows you to write syntax extensions and plugins. Yes, Slim is speedy! Slim was developed right from the start with performance in mind. Benchmarks are done for every commit at http://travis-ci.org/slim-template/slim. Don't trust the numbers? That's as it should be. Please try the benchmark rake task yourself! However in our opinion you should use Slim because of its features and syntax. We just ensure that Slim doesn't have a negative impact on the performance of your application. How to start? Install Slim as a gem: ~~~ gem install slim ~~~ Include Slim in your Gemfile with gem 'slim' or require it with require 'slim'. That's it! Now, just use the .slim extension and you're good to go. Syntax example Here's a quick example to demonstrate what a Slim template looks like: ~~~ slim doctype html html head title Slim Examples meta name="keywords" content="template language" meta name="author" content=author link rel="icon" type="image/png" href=file_path("favicon.png") javascript: alert('Slim supports embedded javascript!') body h1 Markup examples #content p This example shows you how a basic Slim file looks. == yield - if items.any? table#items - for item in items tr td.name = item.name td.price = item.price - else p No items found. Please add some inventory. Thank you! div id="footer" == render 'footer' | Copyright &copy; #{@year} #{@author} ~~~ Indentation matters, but the indentation depth can be chosen as you like. If you want to first indent 2 spaces, then 5 spaces, it's your choice. To nest markup you only need to indent by one space, the rest is gravy. Line indicators Verbatim text | The pipe tells Slim to just copy the line. It essentially escapes any processing. Each following line that is indented greater than the pipe is copied over. ~~~ slim body p | This is a test of the text block. ~~~ The parsed result of the above: ~~~ html This is a test of the text block. ~~~ If the text starts on the same line, the left margin is set at the indent of the pipe + one space. Any additional spaces will be copied over. ~~~ slim body p | This line is on the left margin. This line will have one space in front of it. This line will have two spaces in front of it. And so on... ~~~ You can also embed html in the text line ~~~ slim - articles.each do |a| | #{a.name}#{a.description} ~~~ Verbatim text with trailing white space ' The single quote tells Slim to copy the line (similar to |), but makes sure that a single trailing white space is appended. Inline html < You can write html tags directly in Slim which allows you to write your templates in a more html like style with closing tags or mix html and Slim style. The leading < works like an implicit |: ~~~ slim head title Example - if articles.empty? - else table - articles.each do |a| #{a.name}#{a.description} ~~~ Control code - The dash denotes control code. Examples of control code are loops and conditionals. end is forbidden behind -. Blocks are defined only by indentation. If your ruby code needs to use multiple lines, append a backslash \ at the end of the lines. If your line ends with comma , (e.g because of a method call) you don't need the additional backslash before the linebreak. ~~~ slim body - if articles.empty? | No inventory ~~~ Output = The equals sign tells Slim it's a Ruby call that produces output to add to the buffer. If your ruby code needs to use multiple lines, append a backslash \ at the end of the lines. For example: ~~~ slim = javascript_include_tag \ "jquery", "application" ~~~ If your line ends with comma , (e.g because of a method call) you don't need the additional backslash before the linebreak. For trailing or leading whitespace the modifiers > and < are supported. Output with trailing white space =>. Same as the single equals sign (=), except that it adds a trailing white space. Output with leading white space =<. Same as the single equals sign (=), except that it adds a leading white space. Output without HTML escaping == Same as the single equals sign (=), but does not go through the escape_html method. For trailing or leading whitespace the modifiers > and < are supported. Output without HTML escaping and trailing white space ==>. Same as the double equals sign (==), except that it adds a trailing white space. Output without HTML escaping and leading white space ==<. Same as the double equals sign (==), except that it adds a leading white space. Code comment / Use the forward slash for code comments - anything after it won't get displayed in the final render. Use / for code comments and /! for html comments ~~~ slim body p / This line won't get displayed. Neither does this line. /! This will get displayed as html comments. ~~~ The parsed result of the above: ~~~ html ~~~ HTML comment /! Use the forward slash immediately followed by an exclamation mark for html comments (<!-- ... -->). IE conditional comment /[...] ~~~ slim /[if IE] p Get a better browser. ~~~ This renders as: ~~~ html ~~~ HTML tags declaration The doctype keyword can be used to generate the complex doctypes in a very simple manner. XML VERSION ~~~ slim doctype xml doctype xml ISO-8859-1 ~~~ XHTML DOCTYPES ~~~ slim doctype html doctype 5 doctype 1.1 doctype strict doctype frameset doctype mobile doctype basic doctype transitional ~~~ HTML 4 DOCTYPES ~~~ slim doctype strict doctype frameset doctype transitional ~~~ Closed tags (trailing /) You can close tags explicitly by appending a trailing /. ~~~ slim img src="image.png"/ ~~~ Note, that this is usually not necessary since the standard html tags (img, br, ...) are closed automatically. Trailing and leading whitespace (<, >) You can force Slim to add a trailing whitespace after a tag by adding a >. ~~~ slim a> href='url1' Link1 a> href='url2' Link2 ~~~ You can add a leading whitespace by adding <. ~~~ slim a< href='url1' Link1 a< href='url2' Link2 ~~~ You can also combine both. ~~~ slim a<> href='url1' Link1 ~~~ Inline tags Sometimes you may want to be a little more compact and inline the tags. ~~~ slim ul li.first: a href="/a" A link li: a href="/b" B link ~~~ For readability, don't forget you can wrap the attributes. ~~~ slim ul li.first: a[href="/a"] A link li: a[href="/b"] B link ~~~ Text content Either start on the same line as the tag ~~~ slim body h1 id="headline" Welcome to my site. ~~~ Or nest it. You must use a pipe or an apostrophe to escape processing ~~~ slim body h1 id="headline" | Welcome to my site. ~~~ Or enable and rely on smart text instead ~~~ slim body h1 id="headline" Welcome to my site. ~~~ Dynamic content (= and ==) Can make the call on the same line ~~~ slim body h1 id="headline" = page_headline ~~~ Or nest it. ~~~ slim body h1 id="headline" = page_headline ~~~ Attributes You write attributes directly after the tag. For normal text attributes you must use double " or single quotes ' (Quoted attributes). ~~~ slim a href="http://slim-lang.com" title='Slim Homepage' Goto the Slim homepage ~~~ You can use text interpolation in the quoted attributes. Attributes wrapper If a delimiter makes the syntax more readable for you, you can use the characters {...}, (...), [...] to wrap the attributes. You can configure these symbols (See option :attr_list_delims). ~~~ slim body h1(id="logo") = page_logo h2[id="tagline" class="small tagline"] = page_tagline ~~~ If you wrap the attributes, you can spread them across multiple lines: ~~~ slim h2[id="tagline" class="small tagline"] = page_tagline ~~~ You may use spaces around the wrappers and assignments: ~~~ slim h1 id = "logo" = page_logo h2 [ id = "tagline" ] = page_tagline ~~~ Quoted attributes Example: ~~~ slim a href="http://slim-lang.com" title='Slim Homepage' Goto the Slim homepage ~~~ You can use text interpolation in the quoted attributes: ~~~ slim a href="http://#{url}" Goto the #{url} ~~~ The attribute value will be escaped by default. Use == if you want to disable escaping in the attribute. ~~~ slim a href=="&" ~~~ You can break quoted attributes with backslash \ ~~~ slim a data-title="help" data-content="extremely long help text that goes on\ and on and on and then starts over...." ~~~ Ruby attributes Write the ruby code directly after the =. If the code contains spaces you have to wrap the code into parentheses (...). You can also directly write hashes {...} and arrays [...]. ~~~ slim body table - for user in users td id="user_#{user.id}" class=user.role a href=user_action(user, :edit) Edit #{user.name} a href=(path_to_user user) = user.name ~~~ The attribute value will be escaped by default. Use == if you want to disable escaping in the attribute. ~~~ slim a href==action_path(:start) ~~~ You can also break ruby attributes with backslash \ or trailing , as described for control sections. Boolean attributes The attribute values true, false and nil are interpreted as booleans. If you use the attribute wrapper you can omit the attribute assigment. ~~~ slim input type="text" disabled="disabled" input type="text" disabled=true input(type="text" disabled) input type="text" input type="text" disabled=false input type="text" disabled=nil ~~~ Attribute merging You can configure attributes to be merged if multiple are given (See option :merge_attrs). In the default configuration this is done for class attributes with the white space as delimiter. ~~~ slim a.menu class="highlight" href="http://slim-lang.com/" Slim-lang.com ~~~ This renders as: ~~~ html Slim-lang.com ~~~ You can also use an Array as attribute value and the array elements will be merged using the delimiter. ~~~ slim a class=["menu","highlight"] a class=:menu,:highlight ~~~ Splat attributes * The splat shortcut allows you to turn a hash into attribute/value pairs. ~~~ slim .card*{'data-url'=>place_path(place), 'data-id'=>place.id} = place.name ~~~ This renders as: ~~~ html Slim's house ~~~ You can also use methods or instance variables which return a hash as shown here: ~~~ slim .card method_which_returns_hash = place.name .card @hash_instance_variable = place.name ~~~ The hash attributes which support attribute merging (see Slim option :merge_attrs) can be given as an Array ~~~ slim .first *{class: [:second, :third]} Text ~~~ This renders as: ~~~ html div class="first second third" ~~~ Splat attributes prefix may be configured via splat_prefix option. Default value is '*' Dynamic tags * You can create completely dynamic tags using the splat attributes. Just create a method which returns a hash with the :tag key. ~~~ slim ruby: def a_unless_current @page_current ? {tag: 'span'} : {tag: 'a', href: 'http://slim-lang.com/'} end - @page_current = true a_unless_current Link - @page_current = false a_unless_current Link ~~~ This renders as: ~~~ html LinkLink ~~~ Shortcuts Tag shortcuts You can define custom tag shortcuts by setting the option :shortcut. In Rails apps, you need to put this code for your shortcuts into an initializer like config/initializers/slim.rb. In Sinatra, you simply add the same configuration anywhere below the line where you require 'slim'. ~~~ ruby Slim::Engine.set_options shortcut: {'c' => {tag: 'container'}, '#' => {attr: 'id'}, '.' => {attr: 'class'} } ~~~ We can use it in Slim code like this ~~~ slim c.content Text ~~~ which renders to ~~~ html Text ~~~ Attribute shortcuts You can define custom shortcuts (Similar to # for id and . for class). In this example we add & to create a shortcut for the input elements with type attribute. ~~~ ruby Slim::Engine.set_options shortcut: {'&' => {tag: 'input', attr: 'type'}, '#' => {attr: 'id'}, '.' => {attr: 'class'}} ~~~ We can use it in Slim code like this ~~~ slim &text name="user" &password name="pw" &submit ~~~ which renders to ~~~ html ~~~ In another example we add @ to create a shortcut for the role attribute. ~~~ ruby Slim::Engine.set_options shortcut: {'@' => {attr: 'role'}, '#' => {attr: 'id'}, '.' => {attr: 'class'}} ~~~ We can use it in Slim code like this ~~~ slim .person@admin = person.name ~~~ which renders to ~~~ html Daniel ~~~ You can also set multiple attributes with same value at once using one shortcut. ~~~ ruby Slim::Engine.set_options shortcut: {'@' => {attr: %w(data-role role)}} ~~~ We can use it in Slim code like this ~~~ slim .person@admin = person.name ~~~ which renders to ~~~ html Daniel ~~~ You can also set additional fixed value attributes to a shortcut. ~~~ ruby Slim::Engine.set_options shortcut: {'^' => {tag: 'script', attr: 'data-binding', additional_attrs: { type: "text/javascript" }}} ~~~ Then ~~~ slim ^products == @products.to_json ~~~ which renders to ~~~ html [{"name": "product1", "price": "$100"}, {"name": "prodcut2", "price": "$200"}] ~~~ ID shortcut # and class shortcut . You can specify the id and class attributes in the following shortcut form ~~~ slim body h1#headline = page_headline h2#tagline.small.tagline = page_tagline .content = show_content ~~~ This is the same as ~~~ slim body h1 id="headline" = page_headline h2 id="tagline" class="small tagline" = page_tagline div class="content" = show_content ~~~ Helpers, capturing and includes If you use Slim you might want to extend your template with some helpers. Assume that you have the following helper ~~~ruby module Helpers def headline(&block) if defined?(::Rails) # In Rails we have to use capture! "#{capture(&block)}" else # If we are using Slim without a framework (Plain Tilt), # this works directly. "#{yield}" end end end ~~~ which is included in the scope that executes the Slim template code. The helper can then be used in the Slim template as follows ~~~ slim p = headline do ' Hello = user.name ~~~ The content in the do block is then captured automatically and passed to the helper via yield. As a syntactic sugar you can omit the do keyword and write only ~~~ slim p = headline ' Hello = user.name ~~~ Capturing to local variables Using the Binding you can capture to local variables as follows: ~~~ruby module Helpers def capture_to_local(var, &block) set_var = block.binding.eval("lambda {|x| #{var} = x }") # In Rails we have to use capture! # If we are using Slim without a framework (Plain Tilt), # you can just yield to get the captured block. set_var.call(defined?(::Rails) ? capture(&block) : yield) end end ~~~ The helper can then be used in the Slim template as follows ~~~ slim / The captured_content variable must be known by the Binding beforehand. = capture_to_local captured_content=:captured_content p This will be captured in the variable captured_content = captured_content ~~~ Another interesting use case is to use an enumerable and capture for each element. The helper could look like this ~~~ ruby module Capture def capture(var, enumerable = nil, &block) value = enumerable ? enumerable.map(&block) : yield block.binding.eval("lambda {|x| #{var} = x }").call(value) nil end end ~~~ and it would be used as follows ~~~ slim - links = { 'http://slim-lang.com' => 'The Slim Template Language' } = capture link_list=:link_list, links do |url, text| a href=url = text ~~~ Afterwards, link_list contains the captured content. Include helper If you want includes which are processed at compile time, you can take a look at Include partials. However you can also execute subtemplates at runtime (similar to Rails' #render). You have to write your own include helper: ~~~ ruby module Helpers def include_slim(name, options = {}, &block) Slim::Template.new("#{name}.slim", options).render(self, &block) end end ~~~ This helper can then be used as follows ~~~ slim nav = include_slim 'menu' section = include_slim 'content' ~~~ However this helper doesn't do any caching. You should therefore implement a more intelligent version of the helper which fits your purposes. You should also be aware that most frameworks already bring their own include helper, e.g. Rails has render. Text interpolation Use standard Ruby interpolation. The text will be html escaped by default, but you can avoid escaping by using double braces. ~~~ slim body h1 Welcome #{current_user.name} to the show. | Unescaped #{{content}} is also possible. ~~~ To escape the interpolation (i.e. render as is) ~~~ slim body h1 Welcome #{current_user.name} to the show. ~~~ Embedded engines (Markdown, ...) Thanks to Tilt, Slim has extensive support for embedding other template engines. Examples: ~~~ slim coffee: square = (x) -> x * x markdown: #Header Hello from #{"Markdown!"} Second Line! p: markdown: Tag with inline markdown! ~~~ Supported engines: | Filter | Required gems | Type | Description | | ------ | ------------- | ---- | ----------- | | ruby: | none | Shortcut | Shortcut to embed ruby code | | javascript: | none | Shortcut | Shortcut to embed javascript code and wrap in script tag | | css: | none | Shortcut | Shortcut to embed css code and wrap in style tag | | sass: | sass | Compile time | Embed sass code and wrap in style tag | | scss: | sass | Compile time | Embed scss code and wrap in style tag | | less: | less | Compile time | Embed less css code and wrap in style tag | | coffee: | coffee-script | Compile time | Compile coffee script code and wrap in script tag | | markdown: | redcarpet/rdiscount/kramdown | Compile time + Interpolation | Compile markdown code and interpolate #{variables} in text | | textile: | redcloth | Compile time + Interpolation | Compile textile code and interpolate #{variables} in text | | rdoc: | rdoc | Compile time + Interpolation | Compile rdoc code and interpolate #{variables} in text | The embedded engines can be configured in Slim by setting the options directly on the Slim::Embedded filter. Example: ~~~ ruby Slim::Embedded.options[:markdown] = {auto_ids: false} ~~~ You can also specify HTML attributes for the following embedded engines: * Javascript * CSS * CoffeeScript * LESS * SASS * SCSS Example: ~~~ scss scss class="myClass": $color: #f00; body { color: $color; } ~~~ This will generate the following HTML: ~~~ html body{color:red} ~~~ Configuring Slim Slim and the underlying Temple framework are highly configurable. The way how you configure Slim depends a bit on the compilation mechanism (Rails or Tilt). It is always possible to set default options per Slim::Engine class. This can be done in Rails' environment files. For instance, in config/environments/development.rb you probably want: Default options ~~~ ruby Indent html for pretty debugging and do not sort attributes Slim::Engine.set_options pretty: true, sort_attrs: false ~~~ You can also access the option hash directly: ~~~ ruby Slim::Engine.options[:pretty] = true ~~~ Setting options at runtime There are two ways to set options at runtime. For Tilt templates (Slim::Template) you can set the options when you instantiate the template: ~~~ ruby Slim::Template.new('template.slim', optional_option_hash).render(scope) ~~~ The other possibility is to set the options per thread which is interesting mostly for Rails: ~~~ ruby Slim::Engine.with_options(option_hash) do # Any Slim engines which are created here use the option_hash # For example in Rails: render :page, layout: true end ~~~ You have to be aware that the compiled engine code and the options are cached per template in Rails and you cannot change the option afterwards. ~~~ ruby First render call Slim::Engine.with_options(pretty: true) do render :page, layout: true end Second render call Slim::Engine.with_options(pretty: false) do render :page, layout: true # :pretty is still true because it is cached end ~~~ Available options The following options are exposed by the Slim::Engine and can be set with Slim::Engine.set_options. There are a lot of them but the good thing is, that Slim checks the configuration keys and reports an error if you try to use an invalid configuration key. | Type | Name | Default | Purpose | | ---- | ---- | ------- | ------- | | String | :file | nil | Name of parsed file, set automatically by Slim::Template | | Integer | :tabsize | 4 | Number of white spaces per tab (used by the parser) | | String | :encoding | "utf-8" | Set encoding of template | | String | :default_tag | "div" | Default tag to be used if tag name is omitted | | Hash | :shortcut | {'.' => {attr: 'class'}, '#' => {attr: 'id'}} | Attribute shortcuts | | Hash | :code_attr_delims | {'(' => ')', '[' => ']', '{' => '}'} | Attribute delimiters for Ruby code attributes | | Hash | :attr_list_delims | {'(' => ')', '[' => ']', '{' => '}'} | Attribute list delimiter | | Array<Symbol,String> | :enable_engines | nil (All enabled) | List of enabled embedded engines (whitelist) | | Array<Symbol,String> | :disable_engines | nil (None disabled) | List of disabled embedded engines (blacklist) | | Boolean | :disable_capture | false (true in Rails) | Disable capturing in blocks (blocks write to the default buffer | | Boolean | :disable_escape | false | Disable automatic escaping of strings | | Boolean | :use_html_safe | false (true in Rails) | Use String#html_safe? from ActiveSupport (Works together with :disable_escape) | | Symbol | :format | :xhtml | HTML output format (Possible formats :html, :xhtml, :xml) | | String | :attr_quote | '"' | Character to wrap attributes in html (can be ' or ") | | Hash | :merge_attrs | {'class' => ' '} | Joining character used if multiple html attributes are supplied (e.g. class="class1 class2") | | Array<String> | :hyphen_attrs | %w(data) | Attributes which will be hyphenated if a Hash is given (e.g. data={a_foo:1,b:2} will render as data-a_foo="1" data-b="2") | | Boolean | :hyphen_underscore_attrs | false | Attributes that have underscores in their names will be hyphenated (e.g. data={a_foo:1,b_bar:2} will render as data-a-foo="1" data-b-bar="2") | | Boolean | :sort_attrs | true | Sort attributes by name | | Symbol | :js_wrapper | nil | Wrap javascript by :comment, :cdata or :both. You can also :guess the wrapper based on :format. | | Boolean | :pretty | false | Pretty HTML indenting, only block level tags are indented (This is slower!) | | String | :indent | ' ' | Indentation string | | Boolean | :streaming | false (true in Rails, see below how to disable it!) | Enable output streaming, improves the perceived performance | | Class | :generator | Temple::Generators::StringBuffer/ RailsOutputBuffer | Temple code generator (default generator generates string buffer) | | String | :buffer | '_buf' ('@output_buffer' in Rails) | Variable used for buffer | | String | :splat_prefix | '*' | Prefix used for splat attributes | There are more options which are supported by the Temple filters but which are not exposed and are not officially supported. You have to take a look at the Slim and Temple code for that. Option priority and inheritance For developers who know more about Slim and Temple architecture it is possible to override default options at different positions. Temple uses an inheritance mechanism to allow subclasses to override options of the superclass. The option priorities are as follows: Slim::Template options passed at engine instantiation Slim::Template.options Slim::Engine.thread_options, Slim::Engine.options Parser/Filter/Generator thread_options, options (e.g Slim::Parser, Slim::Compiler) It is also possible to set options for superclasses like Temple::Engine. But this will affect all temple template engines then. ~~~ ruby Slim::Engine < Temple::Engine Slim::Compiler < Temple::Filter ~~~ Plugins Slim currently provides plugins for logic less mode, includes and I18n. See the plugin documentation. Logic less mode Include partials Translator/I18n Smart text mode Framework support Tilt Slim uses Tilt to compile the generated code. If you want to use the Slim template directly, you can use the Tilt interface. ~~~ ruby Tilt.new['template.slim'].render(scope) Slim::Template.new('template.slim', optional_option_hash).render(scope) Slim::Template.new(optional_option_hash) { source }.render(scope) ~~~ The optional option hash can have to options which were documented in the section above. The scope is the object in which the template code is executed. Sinatra ~~~ ruby require 'sinatra' require 'slim' get('/') { slim :index } END @@ index doctype html html head title Sinatra With Slim body h1 Slim Is Fun! ~~~ Rails Rails generators are provided by slim-rails. slim-rails is not necessary to use Slim in Rails though. Just install Slim and add it to your Gemfile with gem 'slim'. Then just use the .slim extension and you're good to go. Streaming HTTP streaming is enabled by default if you use a Rails version which supports it. However you have to be aware that streaming only improves the perceived performance. The rendering time in total will increase. If you want to disable it use: ~~~ ruby Slim::RailsTemplate.set_options streaming: false ~~~ Angular2 Slim now supports Angular2 syntax. But you need to set some configuration options: splat_prefix option This option tells parser what syntax to use for splat attributes. Default value is asterisk: splat_prefix: '*' Asterisk is also used in Angular2 for structural directives such as *ngIf and others, so default configuration causes a conflict between slim and angular2 syntax. There are two ways to resolve it: Set splat_prefix to any custom value, double asterisk, for example: splat_prefix: '**'. Now structural directives should work as expected. Remember that now splat attributes should be written with new custom prefix before them. Use alternative directive syntax without asterisk. Attribute delimeters Angular and slim both uses brackets in their syntax. So there are also two ways: * Use alternative syntax for binding (bind-... and so on) * Limit attribute delimeters to curly braces only: Now you can use something like this: Will be compiled to: Tools Slim Command 'slimrb' The gem 'slim' comes with the small tool 'slimrb' to test Slim from the command line. $ slimrb --help Usage: slimrb [options] -s, --stdin Read input from standard input instead of an input file --trace Show a full traceback on error -c, --compile Compile only but do not run -e, --erb Convert to ERB --rails Generate rails compatible code (Implies --compile) -r, --require library Load library or plugin with -r slim/plugin -p, --pretty Produce pretty html for debugging purposes -o, --option name=code Set slim option -l, --locals Hash|YAML|JSON Set local variables -h, --help Show this message -v, --version Print version Start 'slimrb', type your code and press Ctrl-d to send EOF. In Windows Command Prompt press Ctrl-z, Enter to send EOF. Example usage: $ slimrb markdown: First paragraph. Second paragraph. * one * two * three //Enter Ctrl-d <p>First paragraph </p> <p>Second paragraph </p> <ul> <li>one</li> <li>two</li> <li>three</li> </ul> Syntax Highlighters There are plugins for various text editors (including the most important ones - Vim, Emacs and Textmate): Vim Emacs Textmate / Sublime Text Espresso text editor Coda Atom Template Converters (HAML, ERB, ...) Slim can be converted to ERB using slimrb or `Slim::ERBConverter' which are both included in the Slim gem Haml2Slim converter ERB2Slim, HTML2Slim converter Testing Benchmarks Yes, Slim is one of the fastest Ruby template engines out there! In production mode Slim is nearly as fast as Erubis (which is the fastest template engine). But we would be happy if you chose Slim also for any other reason, we assure you performance will not be an obstacle. Run the benchmarks with rake bench. You can add the option slow to run the slow parsing benchmark which needs more time. You can also increase the number of iterations. ~~~ $ rake bench slow=1 iterations=1000 ~~~ We run the benchmarks for every commit on Travis-CI. Take a look at the newest benchmarking results: http://travis-ci.org/slim-template/slim Test suite and continuous integration Slim provides an extensive test-suite based on minitest. You can run the tests with 'rake test' and the rails integration tests with 'rake test:rails'. We are currently experimenting with human-readable literate tests which are written as markdown files: TESTS.md Travis-CI is used for continuous integration testing: http://travis-ci.org/slim-template/slim Slim is working well on all major Ruby implementations: Ruby 2.0, 2.1, 2.2 and 2.3 JRuby 1.9 mode Rubinius 2.0 Contributing If you'd like to help improve Slim, clone the project with Git by running: ~~~ $ git clone git://github.com/slim-template/slim ~~~ Work your magic and then submit a pull request. We love pull requests! Please remember to keep the compatibility with Ruby versions 2.0.0, 2.1.0, 2.2.0 and 2.3.0. If you find the documentation lacking, help us out and update this README.md. If you don't have the time to work on Slim, but found something we should know about, please submit an issue. License Slim is released under the MIT license. Authors Daniel Mendler (Lead developer) Andrew Stone Fred Wu Donations and sponsoring If you want to support this project please visit the Gittip and Flattr pages. Currently the donations will be used to cover the hosting costs (domain name etc). Discuss Google Group Related projects Template compilation framework: Temple Framework support: Rails generators (slim-rails) slimkeyfy - Translation string extraction Syntax highlighting: Vim Emacs Textmate / Sublime Text Espresso text editor Coda Atom Static code analysis: Slim-Lint SublimeLinter-slim-lint Template Converters (HAML, ERB, ...): ERB 2 Slim Haml2Slim converter ERB2Slim, HTML2Slim converter Language ports/Similar languages: Sliq (Slim/Liquid integration) Slm (Slim port to Javascript) Coffee script plugin for Slim Clojure port of Slim Hamlet.rb (Similar template language) Plim (Python port of Slim) Skim (Slim for Javascript) Emblem.js (Javascript, similar to Slim) Hamlit (High performance Haml implementation, based on Temple like Slim) Faml (Faster Haml implementation, also using Temple like Slim) Haml (Older engine which inspired Slim) Pug (Similar engine for javascript) Sweet (Similar engine which also allows to write classes and functions) Amber (Similar engine for Go) Slang (Slim-inspired templating language for Crystal)

 # # # # # # # # # # # # # # # # # # # #
 Repository: dimsemenov/Magnific-Popup, index: 383, word count: 6691 
 # # # # # # # # # # # # # # # # # # # #

A simple HTML5, YouTube and Vimeo playerPlyr is a simple, lightweight, accessible and customizable HTML5, YouTube and Vimeo media player that supports modern browsers. Checkout the demo - Donate - Slack Features HTML Video & Audio, YouTube & Vimeo - support for the major formats Accessible - full support for VTT captions and screen readers Customizable - make the player look how you want with the markup you want Clean HTML - uses the right elements. <input type="range"> for volume and <progress> for progress and well, <button>s for buttons. There's no <span> or <a href="#"> button hacks Responsive - works with any screen size Monetization - make money from your videos Streaming - support for hls.js, Shaka and dash.js streaming playback API - toggle playback, volume, seeking, and more through a standardized API Events - no messing around with Vimeo and YouTube APIs, all events are standardized across formats Fullscreen - supports native fullscreen with fallback to "full window" modes Shortcuts - supports keyboard shortcuts Picture-in-Picture - supports picture-in-picture mode Playsinline - supports the playsinline attribute Speed controls - adjust speed on the fly Multiple captions - support for multiple caption tracks i18n support - support for internationalization of controls Preview thumbnails - support for displaying preview thumbnails No frameworks - written in "vanilla" ES6 JavaScript, no jQuery required SASS - to include in your build processes Demos You can try Plyr in Codepen using our minimal templates: HTML5 video, HTML5 audio, YouTube, Vimeo. For Streaming we also have example integrations with: Dash.js, Hls.js and Shaka Player Quick setup HTML Plyr extends upon the standard HTML5 media element markup so that's all you need for those types. HTML5 Video Note: The poster image should be specified using data-poster. This is to prevent it being downloaded twice. If you're sure the image will be cached, you can still use the poster attribute for true progressive enhancement. HTML5 Audio For YouTube and Vimeo players, Plyr uses progressive enhancement to enhance the default <iframe> embeds. Below are some examples. The plyr__video-embed classname will make the embed responsive. You can add the autoplay, loop, hl (YouTube only) and playsinline (YouTube only) query parameters to the URL and they will be set as config options automatically. For YouTube, the origin should be updated to reflect the domain you're hosting the embed on, or you can opt to omit it. YouTube We recommend progressive enhancement with the embedded players. You can elect to use an <iframe> as the source element (which Plyr will progressively enhance) or a bog standard <div> with two essential data attributes - data-plyr-provider and data-plyr-embed-id. Note: The plyr__video-embed classname will make the player a responsive 16:9 (most common) iframe embed. When plyr itself kicks in, your custom ratio config option will be used. Or the <div> non progressively enhanced method: Note: The data-plyr-embed-id can either be the video ID or URL for the media. Vimeo Much the same as YouTube above. Or the <div> non progressively enhanced method: JavaScript You can use Plyr as an ES6 module as follows: Alternatively you can include the plyr.js script before the closing </body> tag and then in your JS create a new instance of Plyr as below. See initialising for more information on advanced setups. You can use our CDN (provided by Fastly) for the JavaScript. There's 2 versions; one with and one without polyfills. My recommendation would be to manage polyfills seperately as part of your application but to make life easier you can use the polyfilled build. ...or... CSS Include the plyr.css stylsheet into your <head>. If you want to use our CDN (provided by Fastly) for the default CSS, you can use the following: SVG Sprite The SVG sprite is loaded automatically from our CDN (provided by Fastly). To change this, see the options below. For reference, the CDN hosted SVG sprite can be found at https://cdn.plyr.io/3.6.8/plyr.svg. Ads Plyr has partnered up with vi.ai to offer monetization options for your videos. Getting setup is easy: Sign up for a vi.ai account Grab your publisher ID from the code snippet Enable ads in the config options and enter your publisher ID Any questions regarding the ads can be sent straight to vi.ai and any issues with rendering raised through GitHub issues. If you do not wish to use Vi, you can set your own ads.tagUrl option. Advanced Customizing the CSS If you want to change any design tokens used for the rendering of the player, you can do so using CSS Custom Properties. Here's a list of the properties and what they are used for: | Name | Description | Default / Fallback | | ---------------------------------------------- | ------------------------------------------------------------------------------------------------------- | --------------------------------------------------------------------- | | --plyr-color-main | The primary UI color. | #00b3ff | | --plyr-video-background | The background color of video and poster wrappers for using alpha channel videos and poster images. | rgba(0, 0, 0, 1) | | --plyr-tab-focus-color | The color used for the dotted outline when an element is :focus-visible (equivalent) keyboard focus. | --plyr-color-main | | --plyr-badge-background | The background color for badges in the menu. | #4a5464 | | --plyr-badge-text-color | The text color for badges. | #ffffff | | --plyr-badge-border-radius | The border radius used for badges. | 2px | | --plyr-tab-focus-color | The color used to highlight tab (keyboard) focus. | --plyr-color-main | | --plyr-captions-background | The color for the background of captions. | rgba(0, 0, 0, 0.8) | | --plyr-captions-text-color | The color used for the captions text. | #ffffff | | --plyr-control-icon-size | The size of the icons used in the controls. | 18px | | --plyr-control-spacing | The space between controls (sometimes used in a multiple - e.g. 10px / 2 = 5px). | 10px | | --plyr-control-padding | The padding inside controls. | --plyr-control-spacing * 0.7 (7px) | | --plyr-control-radius | The border radius used on controls. | 3px | | --plyr-control-toggle-checked-background | The background color used for checked menu items. | --plyr-color-main | | --plyr-video-controls-background | The background for the video controls. | linear-gradient(rgba(0, 0, 0, 0), rgba(0, 0, 0, 0.75)) | | --plyr-video-control-color | The text/icon color for video controls. | #ffffff | | --plyr-video-control-color-hover | The text/icon color used when video controls are :hover, :focus and :focus-visible (equivalent). | #ffffff | | --plyr-video-control-background-hover | The background color used when video controls are :hover, :focus and :focus-visible (equivalent). | --plyr-color-main | | --plyr-audio-controls-background | The background for the audio controls. | #ffffff | | --plyr-audio-control-color | The text/icon color for audio controls. | #4a5464 | | --plyr-audio-control-color-hover | The text/icon color used when audio controls are :hover, :focus and :focus-visible (equivalent). | #ffffff | | --plyr-audio-control-background-hover | The background color used when video controls are :hover, :focus and :focus-visible (equivalent). | --plyr-color-main | | --plyr-menu-background | The background color for menus. | rgba(255, 255, 255, 0.9) | | --plyr-menu-color | The text/icon color for menu items. | #4a5464 | | --plyr-menu-shadow | The shadow used on menus. | 0 1px 2px rgba(0, 0, 0, 0.15) | | --plyr-menu-radius | The border radius on the menu. | 4px | | --plyr-menu-arrow-size | The size of the arrow on the bottom of the menu. | 6px | | --plyr-menu-item-arrow-color | The color of the arrows in the menu. | #728197 | | --plyr-menu-item-arrow-size | The size of the arrows in the menu. | 4px | | --plyr-menu-border-color | The border color for the bottom of the back button in the top of the sub menu pages. | #dcdfe5 | | --plyr-menu-border-shadow-color | The shadow below the border of the back button in the top of the sub menu pages. | #ffffff | | --plyr-progress-loading-size | The size of the stripes in the loading state in the scrubber. | 25px | | --plyr-progress-loading-background | The background color on the loading state in the scrubber. | rgba(35, 40, 47, 0.6) | | --plyr-video-progress-buffered-background | The fill color for the buffer indication in the scrubber for video. | rgba(255, 255, 255, 0.25) | | --plyr-audio-progress-buffered-background | The fill color for the buffer indication in the scrubber for audio. | rgba(193, 200, 209, 0.6) | | --plyr-range-thumb-height | The height of the scrubber handle/thumb. | 13px | | --plyr-range-thumb-background | The background of the scrubber handle/thumb. | #ffffff | | --plyr-range-thumb-shadow | The shadow of the scrubber handle/thumb. | 0 1px 1px rgba(215, 26, 18, 0.15), 0 0 0 1px rgba(215, 26, 18, 0.2) | | --plyr-range-thumb-active-shadow-width | The width of the shadow when the scrubber handle/thumb is :active (pressed). | 3px | | --plyr-range-track-height | The height of the scrubber/progress track. | 5px | | --plyr-range-fill-background | The fill color of the scrubber/progress. | --plyr-color-main | | --plyr-video-range-track-background | The background of the scrubber/progress. | --plyr-video-progress-buffered-background | | --plyr-video-range-thumb-active-shadow-color | The color of the shadow when the video scrubber handle/thumb is :active (pressed). | rgba(255, 255, 255, 0.5) | | --plyr-audio-range-track-background | The background of the scrubber/progress. | --plyr-video-progress-buffered-background | | --plyr-audio-range-thumb-active-shadow-color | The color of the shadow when the audio scrubber handle/thumb is :active (pressed). | rgba(215, 26, 18, 0.1) | | --plyr-tooltip-background | The background color for tooltips. | rgba(255, 255, 255, 0.9) | | --plyr-tooltip-color | The text color for tooltips. | #4a5464 | | --plyr-tooltip-padding | The padding for tooltips. | calc(var(--plyr-control-spacing) / 2)) | | --plyr-tooltip-arrow-size | The size of the arrow under tooltips. | 4px | | --plyr-tooltip-radius | The border radius on tooltips. | 3px | | --plyr-tooltip-shadow | The shadow on tooltips. | 0 1px 2px rgba(0, 0, 0, 0.15) | | --plyr-font-family | The font family used in the player. | | | --plyr-font-size-base | The base font size. Mainly used for captions. | 15px | | --plyr-font-size-small | The smaller font size. Mainly used for captions. | 13px | | --plyr-font-size-large | The larger font size. Mainly used for captions. | 18px | | --plyr-font-size-xlarge | The even larger font size. Mainly used for captions. | 21px | | --plyr-font-size-time | The font size for the time. | --plyr-font-size-small | | --plyr-font-size-menu | The font size used in the menu. | --plyr-font-size-small | | --plyr-font-size-badge | The font size used for badges. | 9px | | --plyr-font-weight-regular | The regular font weight. | 400 | | --plyr-font-weight-bold | The bold font weight. | 600 | | --plyr-line-height | The line height used within the player. | 1.7 | | --plyr-font-smoothing | Whether to enable font antialiasing within the player. | false | You can set them in your CSS for all players: ...or for a specific class name: ...or in your HTML: SASS You can use plyr.scss file included in /src/sass as part of your build and change variables to suit your design. The SASS requires you to use autoprefixer (you should be already!) as all declarations use the W3C definitions. The HTML markup uses the BEM methodology with plyr as the block, e.g. .plyr__controls. You can change the class hooks in the options to match any custom CSS you write. Check out the JavaScript source for more on this. SVG The icons used in the Plyr controls are loaded in an SVG sprite. The sprite is automatically loaded from our CDN by default. If you already have an icon build system in place, you can include the source plyr icons (see /src/sprite for source icons). Using the iconUrl option You can however specify your own iconUrl option and Plyr will determine if the url is absolute and requires loading by AJAX/CORS due to current browser limitations or if it's a relative path, just use the path directly. If you're using the <base> tag on your site, you may need to use something like this: svgfixer.js More info on SVG sprites here: http://css-tricks.com/svg-sprites-use-better-icon-fonts/ and the AJAX technique here: http://css-tricks.com/ajaxing-svg-sprite/ Cross Origin (CORS) You'll notice the crossorigin attribute on the example <video> elements. This is because the TextTrack captions are loaded from another domain. If your TextTrack captions are also hosted on another domain, you will need to add this attribute and make sure your host has the correct headers setup. For more info on CORS checkout the MDN docs: https://developer.mozilla.org/en-US/docs/Web/HTTP/Access_control_CORS Captions WebVTT captions are supported. To add a caption track, check the HTML example above and look for the <track> element. Be sure to validate your caption files. JavaScript Initialising You can specify a range of arguments for the constructor to use: A CSS string selector A HTMLElement A jQuery object Note: If a NodeList, Array, or jQuery object are passed, the first element will be used for setup. To setup multiple players, see multiple players below. Single player Passing a CSS string selector that's compatible with querySelector: Passing a HTMLElement: The HTMLElement or string selector can be the target <video>, <audio>, or <div> wrapper for embeds. Multiple players You have two choices here. You can either use a simple array loop to map the constructor: ...or use a static method where you can pass a CSS string selector, a NodeList, an Array of HTMLElement, or a JQuery object: Both options will also return an array of instances in the order of they were in the DOM for the string selector or the source NodeList or Array. Options The second argument for the constructor is the options object: Options can be passed as an object to the constructor as above or as JSON in data-plyr-config attribute on each of your target elements: Note the single quotes encapsulating the JSON and double quotes on the object keys. Only string values need double quotes. | Option | Type | Default | Description | | -------------------- | -------------------------- | ------------------------------------------------------------------------------------------------------------------------------ | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | | enabled | Boolean | true | Completely disable Plyr. This would allow you to do a User Agent check or similar to programmatically enable or disable Plyr for a certain UA. Example below. | | debug | Boolean | false | Display debugging information in the console | | controls | Array, Function or Element | ['play-large', 'play', 'progress', 'current-time', 'mute', 'volume', 'captions', 'settings', 'pip', 'airplay', 'fullscreen'] | If a function is passed, it is assumed your method will return either an element or HTML string for the controls. Three arguments will be passed to your function; id (the unique id for the player), seektime (the seektime step in seconds), and title (the media title). See CONTROLS.md for more info on how the html needs to be structured. | | settings | Array | ['captions', 'quality', 'speed', 'loop'] | If the default controls are used, you can specify which settings to show in the menu | | i18n | Object | See defaults.js | Used for internationalization (i18n) of the text within the UI. | | loadSprite | Boolean | true | Load the SVG sprite specified as the iconUrl option (if a URL). If false, it is assumed you are handling sprite loading yourself. | | iconUrl | String | null | Specify a URL or path to the SVG sprite. See the SVG section for more info. | | iconPrefix | String | plyr | Specify the id prefix for the icons used in the default controls (e.g. "plyr-play" would be "plyr"). This is to prevent clashes if you're using your own SVG sprite but with the default controls. Most people can ignore this option. | | blankVideo | String | https://cdn.plyr.io/static/blank.mp4 | Specify a URL or path to a blank video file used to properly cancel network requests. | | autoplay | Boolean | false | Autoplay the media on load. If the autoplay attribute is present on a <video> or <audio> element, this will be automatically set to true. | | autopause | Boolean | true | Only allow one player playing at once. | | seekTime | Number | 10 | The time, in seconds, to seek when a user hits fast forward or rewind. | | volume | Number | 1 | A number, between 0 and 1, representing the initial volume of the player. | | muted | Boolean | false | Whether to start playback muted. If the muted attribute is present on a <video> or <audio> element, this will be automatically set to true. | | clickToPlay | Boolean | true | Click (or tap) of the video container will toggle play/pause. | | disableContextMenu | Boolean | true | Disable right click menu on video to help as very primitive obfuscation to prevent downloads of content. | | hideControls | Boolean | true | Hide video controls automatically after 2s of no mouse or focus movement, on control element blur (tab out), on playback start or entering fullscreen. As soon as the mouse is moved, a control element is focused or playback is paused, the controls reappear instantly. | | resetOnEnd | Boolean | false | Reset the playback to the start once playback is complete. | | keyboard | Object | { focused: true, global: false } | Enable keyboard shortcuts for focused players only or globally | | tooltips | Object | { controls: false, seek: true } | controls: Display control labels as tooltips on :hover & :focus (by default, the labels are screen reader only). seek: Display a seek tooltip to indicate on click where the media would seek to. | | duration | Number | null | Specify a custom duration for media. | | displayDuration | Boolean | true | Displays the duration of the media on the "metadataloaded" event (on startup) in the current time display. This will only work if the preload attribute is not set to none (or is not set at all) and you choose not to display the duration (see controls option). | | invertTime | Boolean | true | Display the current time as a countdown rather than an incremental counter. | | toggleInvert | Boolean | true | Allow users to click to toggle the above. | | listeners | Object | null | Allows binding of event listeners to the controls before the default handlers. See the defaults.js for available listeners. If your handler prevents default on the event (event.preventDefault()), the default handler will not fire. | | captions | Object | { active: false, language: 'auto', update: false } | active: Toggles if captions should be active by default. language: Sets the default language to load (if available). 'auto' uses the browser language. update: Listen to changes to tracks and update menu. This is needed for some streaming libraries, but can result in unselectable language options). | | fullscreen | Object | { enabled: true, fallback: true, iosNative: false, container: null } | enabled: Toggles whether fullscreen should be enabled. fallback: Allow fallback to a full-window solution (true/false/'force'). iosNative: whether to use native iOS fullscreen when entering fullscreen (no custom controls). container: A selector for an ancestor of the player element, allows contextual content to remain visual in fullscreen mode. Non-ancestors are ignored. | | ratio | String | null | Force an aspect ratio for all videos. The format is 'w:h' - e.g. '16:9' or '4:3'. If this is not specified then the default for HTML5 and Vimeo is to use the native resolution of the video. As dimensions are not available from YouTube via SDK, 16:9 is forced as a sensible default. | | storage | Object | { enabled: true, key: 'plyr' } | enabled: Allow use of local storage to store user settings. key: The key name to use. | | speed | Object | { selected: 1, options: [0.5, 0.75, 1, 1.25, 1.5, 1.75, 2] } | selected: The default speed for playback. options: The speed options to display in the UI. YouTube and Vimeo will ignore any options outside of the 0.5-2 range, so options outside of this range will be hidden automatically. | | quality | Object | { default: 576, options: [4320, 2880, 2160, 1440, 1080, 720, 576, 480, 360, 240] } | default is the default quality level (if it exists in your sources). options are the options to display. This is used to filter the available sources. | | loop | Object | { active: false } | active: Whether to loop the current video. If the loop attribute is present on a <video> or <audio> element, this will be automatically set to true This is an object to support future functionality. | | ads | Object | { enabled: false, publisherId: '', tagUrl: '' } | enabled: Whether to enable advertisements. publisherId: Your unique vi.ai publisher ID. tagUrl is a URL for a custom VAST tag if you're not using Vi. | | urls | Object | See source. | If you wish to override any API URLs then you can do so here. You can also set a custom download URL for the download button. | | vimeo | Object | { byline: false, portrait: false, title: false, speed: true, transparent: false } | See Vimeo embed options. Some are set automatically based on other config options, namely: loop, autoplay, muted, gesture, playsinline | | youtube | Object | { noCookie: false, rel: 0, showinfo: 0, iv_load_policy: 3, modestbranding: 1 } | See YouTube embed options. The only custom option is noCookie to use an alternative to YouTube that doesn't use cookies (useful for GDPR, etc). Some are set automatically based on other config options, namely: autoplay, hl, controls, disablekb, playsinline, cc_load_policy, cc_lang_pref, widget_referrer | | previewThumbnails | Object | { enabled: false, src: '' } | enabled: Whether to enable the preview thumbnails (they must be generated by you). src must be either a string or an array of strings representing URLs for the VTT files containing the image URL(s). Learn more about preview thumbnails below. | Vimeo only Autoplay is generally not recommended as it is seen as a negative user experience. It is also disabled in many browsers. Before raising issues, do your homework. More info can be found here: https://webkit.org/blog/6784/new-video-policies-for-ios/ https://developers.google.com/web/updates/2017/09/autoplay-policy-changes https://hacks.mozilla.org/2019/02/firefox-66-to-block-automatically-playing-audible-video-and-audio/ API There are methods, setters and getters on a Plyr object. Object The easiest way to access the Plyr object is to set the return value from your call to the constructor to a variable. For example: You can also access the object through any events: Methods Example method use: | Method | Parameters | Description | | -------------------------- | ---------------- | ---------------------------------------------------------------------------------------------------------- | | play() | - | Start playback. | | pause() | - | Pause playback. | | togglePlay(toggle) | Boolean | Toggle playback, if no parameters are passed, it will toggle based on current status. | | stop() | - | Stop playback and reset to start. | | restart() | - | Restart playback. | | rewind(seekTime) | Number | Rewind playback by the specified seek time. If no parameter is passed, the default seek time will be used. | | forward(seekTime) | Number | Fast forward by the specified seek time. If no parameter is passed, the default seek time will be used. | | increaseVolume(step) | Number | Increase volume by the specified step. If no parameter is passed, the default step will be used. | | decreaseVolume(step) | Number | Increase volume by the specified step. If no parameter is passed, the default step will be used. | | toggleCaptions(toggle) | Boolean | Toggle captions display. If no parameter is passed, it will toggle based on current status. | | fullscreen.enter() | - | Enter fullscreen. If fullscreen is not supported, a fallback "full window/viewport" is used instead. | | fullscreen.exit() | - | Exit fullscreen. | | fullscreen.toggle() | - | Toggle fullscreen. | | airplay() | - | Trigger the airplay dialog on supported devices. | | toggleControls(toggle) | Boolean | Toggle the controls (video only). Takes optional truthy value to force it on/off. | | on(event, function) | String, Function | Add an event listener for the specified event. | | once(event, function) | String, Function | Add an event listener for the specified event once. | | off(event, function) | String, Function | Remove an event listener for the specified event. | | supports(type) | String | Check support for a mime type. | | destroy() | - | Destroy the instance and garbage collect any elements. | For HTML5 players, play() will return a Promise for most browsers - e.g. Chrome, Firefox, Opera, Safari and Edge according to MDN at time of writing. Getters and Setters Example setters: Example getters: | Property | Getter | Setter | Description | | -------------------- | ------ | ------ | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | | isHTML5 | | - | Returns a boolean indicating if the current player is HTML5. | | isEmbed | | - | Returns a boolean indicating if the current player is an embedded player. | | playing | | - | Returns a boolean indicating if the current player is playing. | | paused | | - | Returns a boolean indicating if the current player is paused. | | stopped | | - | Returns a boolean indicating if the current player is stopped. | | ended | | - | Returns a boolean indicating if the current player has finished playback. | | buffered | | - | Returns a float between 0 and 1 indicating how much of the media is buffered | | currentTime | | | Gets or sets the currentTime for the player. The setter accepts a float in seconds. | | seeking | | - | Returns a boolean indicating if the current player is seeking. | | duration | | - | Returns the duration for the current media. | | volume | | | Gets or sets the volume for the player. The setter accepts a float between 0 and 1. | | muted | | | Gets or sets the muted state of the player. The setter accepts a boolean. | | hasAudio | | - | Returns a boolean indicating if the current media has an audio track. | | speed | | | Gets or sets the speed for the player. The setter accepts a value in the options specified in your config. Generally the minimum should be 0.5. | | quality | | | Gets or sets the quality for the player. The setter accepts a value from the options specified in your config. | | loop | | | Gets or sets the current loop state of the player. The setter accepts a boolean. | | source | | | Gets or sets the current source for the player. The setter accepts an object. See source setter below for examples. | | poster | | | Gets or sets the current poster image for the player. The setter accepts a string; the URL for the updated poster image. | | autoplay | | | Gets or sets the autoplay state of the player. The setter accepts a boolean. | | currentTrack | | | Gets or sets the caption track by index. -1 means the track is missing or captions is not active | | language | | | Gets or sets the preferred captions language for the player. The setter accepts an ISO two-letter language code. Support for the languages is dependent on the captions you include. If your captions don't have any language data, or if you have multiple tracks with the same language, you may want to use currentTrack instead. | | fullscreen.active | | - | Returns a boolean indicating if the current player is in fullscreen mode. | | fullscreen.enabled | | - | Returns a boolean indicating if the current player has fullscreen enabled. | | pip | | | Gets or sets the picture-in-picture state of the player. The setter accepts a boolean. This currently only supported on Safari 10+ (on MacOS Sierra+ and iOS 10+) and Chrome 70+. | | ratio | | | Gets or sets the video aspect ratio. The setter accepts a string in the same format as the ratio option. | | download | | | Gets or sets the URL for the download button. The setter accepts a string containing a valid absolute URL. | HTML5 only The .source setter This allows changing the player source and type on the fly. Video example: Audio example: YouTube example: Vimeo example Note: src property for YouTube and Vimeo can either be the video ID or the whole URL. | Property | Type | Description | | ------------------------- | ------ | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | | type | String | Either video or audio. Note: YouTube and Vimeo are currently not supported as audio sources. | | title | String | Optional. Title of the new media. Used for the aria-label attribute on the play button, and outer container. YouTube and Vimeo are populated automatically. | | sources | Array | This is an array of sources. For HTML5 media, the properties of this object are mapped directly to HTML attributes so more can be added to the object if required. | | poster | String | The URL for the poster image (HTML5 video only). | | tracks | String | An array of track objects. Each element in the array is mapped directly to a track element and any keys mapped directly to HTML attributes so as in the example above, it will render as <track kind="captions" label="English" srclang="en" src="https://cdn.selz.com/plyr/1.0/example_captions_en.vtt" default> and similar for the French version. Booleans are converted to HTML5 value-less attributes. | | previewThumbnails | Object | The same object like in the previewThumbnails constructor option. This means you can either change the thumbnails vtt via the src key or disable the thumbnails plugin for the next video by passing { enabled: false }. | HTML5 only Events You can listen for events on the target element you setup Plyr on (see example under the table). Some events only apply to HTML5 audio and video. Using your reference to the instance, you can use the on() API method or addEventListener(). Access to the API can be obtained this way through the event.detail.plyr property. Here's an example: Standard Media Events | Event Type | Description | | ------------------ | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | | progress | Sent periodically to inform interested parties of progress downloading the media. Information about the current amount of the media that has been downloaded is available in the media element's buffered attribute. | | playing | Sent when the media begins to play (either for the first time, after having been paused, or after ending and then restarting). | | play | Sent when playback of the media starts after having been paused; that is, when playback is resumed after a prior pause event. | | pause | Sent when playback is paused. | | timeupdate | The time indicated by the element's currentTime attribute has changed. | | volumechange | Sent when the audio volume changes (both when the volume is set and when the muted state is changed). | | seeking | Sent when a seek operation begins. | | seeked | Sent when a seek operation completes. | | ratechange | Sent when the playback speed changes. | | ended | Sent when playback completes. Note: This does not fire if autoplay is true. | | enterfullscreen | Sent when the player enters fullscreen mode (either the proper fullscreen or full-window fallback for older browsers). | | exitfullscreen | Sent when the player exits fullscreen mode. | | captionsenabled | Sent when captions are enabled. | | captionsdisabled | Sent when captions are disabled. | | languagechange | Sent when the caption language is changed. | | controlshidden | Sent when the controls are hidden. | | controlsshown | Sent when the controls are shown. | | ready | Triggered when the instance is ready for API calls. | HTML5 only | Event Type | Description | | ---------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | | loadstart | Sent when loading of the media begins. | | loadeddata | The first frame of the media has finished loading. | | loadedmetadata | The media's metadata has finished loading; all attributes now contain as much useful information as they're going to. | | qualitychange | The quality of playback has changed. | | canplay | Sent when enough data is available that the media can be played, at least for a couple of frames. This corresponds to the HAVE_ENOUGH_DATA readyState. | | canplaythrough | Sent when the ready state changes to CAN_PLAY_THROUGH, indicating that the entire media can be played without interruption, assuming the download rate remains at least at the current level. Note: Manually setting the currentTime will eventually fire a canplaythrough event in firefox. Other browsers might not fire this event. | | stalled | Sent when the user agent is trying to fetch media data, but data is unexpectedly not forthcoming. | | waiting | Sent when the requested operation (such as playback) is delayed pending the completion of another operation (such as a seek). | | emptied | he media has become empty; for example, this event is sent if the media has already been loaded (or partially loaded), and the load() method is called to reload it. | | cuechange | Sent when a TextTrack has changed the currently displaying cues. | | error | Sent when an error occurs. The element's error attribute contains more information. | YouTube only | Event Type | Description | | ------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | | statechange | The state of the player has changed. The code can be accessed via event.detail.code. Possible values are -1: Unstarted, 0: Ended, 1: Playing, 2: Paused, 3: Buffering, 5: Video cued. See the YouTube Docs for more information. | Note: These events also bubble up the DOM. The event target will be the container element. Some event details borrowed from MDN. Embeds YouTube and Vimeo are currently supported and function much like a HTML5 video. Similar events and API methods are available for all types. However if you wish to access the API's directly. You can do so via the embed property of your player object - e.g. player.embed. You can then use the relevant methods from the third party APIs. More info on the respective API's here: YouTube iframe API Reference Vimeo player.js Reference Note: Not all API methods may work 100%. Your mileage may vary. It's better to use the Plyr API where possible. Shortcuts By default, a player will bind the following keyboard shortcuts when it has focus. If you have the global option to true and there's only one player in the document then the shortcuts will work when any element has focus, apart from an element that requires input. | Key | Action | | ---------- | -------------------------------------- | | 0 to 9 | Seek from 0 to 90% respectively | | space | Toggle playback | | K | Toggle playback | | | Seek backward by the seekTime option | | | Seek forward by the seekTime option | | | Increase volume | | | Decrease volume | | M | Toggle mute | | F | Toggle fullscreen | | C | Toggle captions | | L | Toggle loop | Preview thumbnails It's possible to display preview thumbnails as per the demo when you hover over the scrubber or while you are scrubbing in the main video area. This can be used for all video types but is easiest with HTML5 of course. You will need to generate the sprite or images yourself. This is possible using something like AWS transcoder to generate the frames and then combine them into a sprite image. Sprites are recommended for performance reasons - they will be much faster to download and easier to compress into a small file size making them load faster. You can see the example VTT files here and here for how the sprites are done. The coordinates are set as the xywh hash on the URL in the order X Offset, Y Offset, Width, Height (e.g. 240p-00001.jpg#xywh=1708,480,427,240 is offset 1708px from the left, 480px from the top and is 427x240px. If you want to include images per frame, this is also possible but will be slower, resulting in a degraded experience. Fullscreen Fullscreen in Plyr is supported by all browsers that currently support it. Browser support Plyr supports the last 2 versions of most modern browsers. | Browser | Supported | | ------------- | --------------- | | Safari | | | Mobile Safari | | | Firefox | | | Chrome | | | Opera | | | Edge | | | IE11 | | | IE10 | 2,3 | Mobile Safari on the iPhone forces the native player for <video> unless the playsinline attribute is present. Volume controls are also disabled as they are handled device wide. Native player used (no support for <progress> or <input type="range">) but the API is supported. No native fullscreen support, fallback can be used (see options). Polyfills required. See below. Polyfills Plyr uses ES6 which isn't supported in all browsers quite yet. This means some features will need to be polyfilled to be available otherwise you'll run into issues. We've elected to not burden the ~90% of users that do support these features with extra JS and instead leave polyfilling to you to work out based on your needs. The easiest method I've found is to use polyfill.io which provides polyfills based on user agent. This is the method the demo uses. Checking for support You can use the static method to check for support. For example The arguments are: Media type (audio or video) Provider (html5, youtube or vimeo) Whether the player has the playsinline attribute (only applicable to iOS 10+) Disable support programmatically The enabled option can be used to disable certain User Agents. For example, if you don't want to use Plyr for smartphones, you could use: If a User Agent is disabled but supports <video> and <audio> natively, it will use the native player. Plugins & Components Some awesome folks have made plugins for CMSs and Components for JavaScript frameworks: | Type | Maintainer | Link | | --------- | ------------------------------------------------------------------------- | -------------------------------------------------------------------------------------------- | | WordPress | Brandon Lavigne (@drrobotnik) | https://wordpress.org/plugins/plyr/ | | Angular | Simon Bobrov (@smnbbrv) | https://github.com/smnbbrv/ngx-plyr | | React | Chintan Prajapati (@chintan9) | https://github.com/chintan9/plyr-react | | Vue | Gabe Dunn (@redxtech) | https://github.com/redxtech/vue-plyr | | Neos | Jon Uhlmann (@jonnitto) | https://packagist.org/packages/jonnitto/plyr | | Kirby | Dominik Pschenitschni (@dpschen) | https://github.com/dpschen/kirby-plyrtag | | REDAXO | FriendsOfRedaxo / skerbis (@skerbis) | https://github.com/FriendsOfREDAXO/plyr | | svelte-plyr | Ben Woodward / benwoodward (@benwoodward) | https://github.com/benwoodward | Issues If you find anything weird with Plyr, please let us know using the GitHub issues tracker. Author Plyr is developed by @sam_potts / sampotts.me with help from the awesome contributors Donate Plyr costs money to run, not only my time. I donate my time for free as I enjoy building Plyr but unfortunately have to pay for domains, hosting, and more. Any help with costs is appreciated... Donate via Patreon Donate via PayPal Mentions ProductHunt The Changelog HTML5 Weekly #177 Responsive Design #149 Web Design Weekly #174 Front End Focus #177 Hacker News Web Platform Daily LayerVault Designer News The Treehouse Show #131 noupe.com Used by Selz.com Peugeot.fr Peugeot.de TomTom.com DIGBMX Grime Archive koel - A personal music streaming server that works. Oscar Radio Sparkk TV @halfhalftravel BitChute Rutheneum-Bote pressakey.com | Blog-Magazin fr Videospiele STROLLN: Work with a View CFDA Runway360 If you want to be added to the list, open a pull request. It'd be awesome to see how you're using Plyr Useful links and credits PayPal's Accessible HTML5 Video Player (which Plyr was originally ported from) An awesome guide for Plyr in Japanese! by @arayutw Thanks Massive thanks to Fastly for providing the CDN services. Massive thanks to Sentry for providing the logging services for the demo site. Contributors Code Contributors This project exists thanks to all the people who contribute. [Contribute]. Financial Contributors Become a financial contributor and help us sustain our community. [Contribute] Individuals Organizations Support this project with your organization. Your logo will show up here with a link to your website. [Contribute] Copyright and License The MIT license

 # # # # # # # # # # # # # # # # # # # #
 Repository: vinta/awesome-python, index: 33, word count: 8023 
 # # # # # # # # # # # # # # # # # # # #

A curated list of awesome Python frameworks, libraries, software and resourcesAwesome Python A curated list of awesome Python frameworks, libraries, software and resources. Inspired by awesome-php. Awesome Python Admin Panels Algorithms and Design Patterns ASGI Servers Asynchronous Programming Audio Authentication Build Tools Built-in Classes Enhancement Caching ChatOps Tools CMS Code Analysis Command-line Interface Development Command-line Tools Compatibility Computer Vision Concurrency and Parallelism Configuration Cryptography Data Analysis Data Validation Data Visualization Database Drivers Database Date and Time Debugging Tools Deep Learning DevOps Tools Distributed Computing Distribution Documentation Downloader E-commerce Editor Plugins and IDEs Email Enterprise Application Integrations Environment Management Files Foreign Function Interface Forms Functional Programming Game Development Geolocation GUI Development Hardware HTML Manipulation HTTP Clients Image Processing Implementations Interactive Interpreter Internationalization Job Scheduler Logging Machine Learning Miscellaneous Natural Language Processing Network Virtualization News Feed ORM Package Management Package Repositories Penetration testing Permissions Processes Recommender Systems Refactoring RESTful API Robotics RPC Servers Science Search Serialization Serverless Frameworks Shell Specific Formats Processing Static Site Generator Tagging Task Queues Template Engine Testing Text Processing Third-party APIs URL Manipulation Video Web Asset Management Web Content Extracting Web Crawling Web Frameworks WebSocket WSGI Servers Resources Books Newsletters Podcasts Websites Contributing Admin Panels Libraries for administrative interfaces. ajenti - The admin panel your servers deserve. django-grappelli - A jazzy skin for the Django Admin-Interface. django-jet - Modern responsive template for the Django admin interface with improved functionality. django-suit - Alternative Django Admin-Interface (free only for Non-commercial use). django-xadmin - Drop-in replacement of Django admin comes with lots of goodies. flask-admin - Simple and extensible administrative interface framework for Flask. flower - Real-time monitor and web admin for Celery. jet-bridge - Admin panel framework for any application with nice UI (ex Jet Django) wooey - A Django app which creates automatic web UIs for Python scripts. Algorithms and Design Patterns Python implementation of data structures, algorithms and design patterns. Also see awesome-algorithms. Algorithms algorithms - Minimal examples of data structures and algorithms. python-ds - A collection of data structure and algorithms for coding interviews. sortedcontainers - Fast and pure-Python implementation of sorted collections. TheAlgorithms - All Algorithms implemented in Python. Design Patterns PyPattyrn - A simple yet effective library for implementing common design patterns. python-patterns - A collection of design patterns in Python. transitions - A lightweight, object-oriented finite state machine implementation. ASGI Servers ASGI-compatible web servers. daphne - A HTTP, HTTP2 and WebSocket protocol server for ASGI and ASGI-HTTP. uvicorn - A lightning-fast ASGI server implementation, using uvloop and httptools. Asynchronous Programming asyncio - (Python standard library) Asynchronous I/O, event loop, coroutines and tasks. awesome-asyncio trio - A friendly library for async concurrency and I/O. Twisted - An event-driven networking engine. uvloop - Ultra fast asyncio event loop. Audio Libraries for manipulating audio and its metadata. Audio audioread - Cross-library (GStreamer + Core Audio + MAD + FFmpeg) audio decoding. dejavu - Audio fingerprinting and recognition. kapre - Keras Audio Preprocessors librosa - Python library for audio and music analysis matchering - A library for automated reference audio mastering. mingus - An advanced music theory and notation package with MIDI file and playback support. pyAudioAnalysis - Audio feature extraction, classification, segmentation and applications. pydub - Manipulate audio with a simple and easy high level interface. TimeSide - Open web audio processing framework. Metadata beets - A music library manager and MusicBrainz tagger. eyeD3 - A tool for working with audio files, specifically MP3 files containing ID3 metadata. mutagen - A Python module to handle audio metadata. tinytag - A library for reading music meta data of MP3, OGG, FLAC and Wave files. Authentication Libraries for implementing authentications schemes. OAuth authlib - JavaScript Object Signing and Encryption draft implementation. django-allauth - Authentication app for Django that "just works." django-oauth-toolkit - OAuth 2 goodies for Django. oauthlib - A generic and thorough implementation of the OAuth request-signing logic. python-oauth2 - A fully tested, abstract interface to creating OAuth clients and servers. python-social-auth - An easy-to-setup social authentication mechanism. JWT pyjwt - JSON Web Token implementation in Python. python-jose - A JOSE implementation in Python. python-jwt - A module for generating and verifying JSON Web Tokens. Build Tools Compile software from source code. BitBake - A make-like build tool for embedded Linux. buildout - A build system for creating, assembling and deploying applications from multiple parts. PlatformIO - A console tool to build code with different development platforms. pybuilder - A continuous build tool written in pure Python. SCons - A software construction tool. Built-in Classes Enhancement Libraries for enhancing Python built-in classes. attrs - Replacement for __init__, __eq__, __repr__, etc. boilerplate in class definitions. bidict - Efficient, Pythonic bidirectional map data structures and related functionality.. Box - Python dictionaries with advanced dot notation access. dataclasses - (Python standard library) Data classes. DottedDict - A library that provides a method of accessing lists and dicts with a dotted path notation. CMS Content Management Systems. django-cms - An Open source enterprise CMS based on the Django. feincms - One of the most advanced Content Management Systems built on Django. indico - A feature-rich event management system, made @ CERN. Kotti - A high-level, Pythonic web application framework built on Pyramid. mezzanine - A powerful, consistent, and flexible content management platform. plone - A CMS built on top of the open source application server Zope. quokka - Flexible, extensible, small CMS powered by Flask and MongoDB. wagtail - A Django content management system. Caching Libraries for caching data. beaker - A WSGI middleware for sessions and caching. django-cache-machine - Automatic caching and invalidation for Django models. django-cacheops - A slick ORM cache with automatic granular event-driven invalidation. dogpile.cache - dogpile.cache is next generation replacement for Beaker made by same authors. HermesCache - Python caching library with tag-based invalidation and dogpile effect prevention. pylibmc - A Python wrapper around the libmemcached interface. python-diskcache - SQLite and file backed cache backend with faster lookups than memcached and redis. ChatOps Tools Libraries for chatbot development. errbot - The easiest and most popular chatbot to implement ChatOps. Code Analysis Tools of static analysis, linters and code quality checkers. Also see awesome-static-analysis. Code Analysis coala - Language independent and easily extendable code analysis application. code2flow - Turn your Python and JavaScript code into DOT flowcharts. prospector - A tool to analyse Python code. pycallgraph - A library that visualises the flow (call graph) of your Python application. vulture - A tool for finding and analysing dead Python code. Code Linters flake8 - A wrapper around pycodestyle, pyflakes and McCabe. awesome-flake8-extensions pylama - A code audit tool for Python and JavaScript. pylint - A fully customizable source code analyzer. wemake-python-styleguide - The strictest and most opinionated python linter ever. Code Formatters black - The uncompromising Python code formatter. isort - A Python utility / library to sort imports. yapf - Yet another Python code formatter from Google. Static Type Checkers, also see awesome-python-typing mypy - Check variable types during compile time. pyre-check - Performant type checking. typeshed - Collection of library stubs for Python, with static types. Static Type Annotations Generators MonkeyType - A system for Python that generates static type annotations by collecting runtime types. pyannotate - Auto-generate PEP-484 annotations. pytype - Pytype checks and infers types for Python code - without requiring type annotations. Command-line Interface Development Libraries for building command-line applications. Command-line Application Development cement - CLI Application Framework for Python. click - A package for creating beautiful command line interfaces in a composable way. cliff - A framework for creating command-line programs with multi-level commands. docopt - Pythonic command line arguments parser. python-fire - A library for creating command line interfaces from absolutely any Python object. python-prompt-toolkit - A library for building powerful interactive command lines. Terminal Rendering alive-progress - A new kind of Progress Bar, with real-time throughput, eta and very cool animations. asciimatics - A package to create full-screen text UIs (from interactive forms to ASCII animations). bashplotlib - Making basic plots in the terminal. colorama - Cross-platform colored terminal text. rich - Python library for rich text and beautiful formatting in the terminal. Also provides a great RichHandler log handler. tqdm - Fast, extensible progress bar for loops and CLI. Command-line Tools Useful CLI-based tools for productivity. Productivity Tools copier - A library and command-line utility for rendering projects templates. cookiecutter - A command-line utility that creates projects from cookiecutters (project templates). doitlive - A tool for live presentations in the terminal. howdoi - Instant coding answers via the command line. Invoke - A tool for managing shell-oriented subprocesses and organizing executable Python code into CLI-invokable tasks. PathPicker - Select files out of bash output. percol - Adds flavor of interactive selection to the traditional pipe concept on UNIX. thefuck - Correcting your previous console command. tmuxp - A tmux session manager. try - A dead simple CLI to try out python packages - it's never been easier. CLI Enhancements httpie - A command line HTTP client, a user-friendly cURL replacement. iredis - Redis CLI with autocompletion and syntax highlighting. kube-shell - An integrated shell for working with the Kubernetes CLI. litecli - SQLite CLI with autocompletion and syntax highlighting. mycli - MySQL CLI with autocompletion and syntax highlighting. pgcli - PostgreSQL CLI with autocompletion and syntax highlighting. saws - A Supercharged aws-cli. Compatibility Libraries for migrating from Python 2 to 3. python-future - The missing compatibility layer between Python 2 and Python 3. modernize - Modernizes Python code for eventual Python 3 migration. six - Python 2 and 3 compatibility utilities. Computer Vision Libraries for Computer Vision. EasyOCR - Ready-to-use OCR with 40+ languages supported. Face Recognition - Simple facial recognition library. Kornia - Open Source Differentiable Computer Vision Library for PyTorch. OpenCV - Open Source Computer Vision Library. pytesseract - A wrapper for Google Tesseract OCR. SimpleCV - An open source framework for building computer vision applications. tesserocr - Another simple, Pillow-friendly, wrapper around the tesseract-ocr API for OCR. Concurrency and Parallelism Libraries for concurrent and parallel execution. Also see awesome-asyncio. concurrent.futures - (Python standard library) A high-level interface for asynchronously executing callables. eventlet - Asynchronous framework with WSGI support. gevent - A coroutine-based Python networking library that uses greenlet. multiprocessing - (Python standard library) Process-based parallelism. scoop - Scalable Concurrent Operations in Python. uvloop - Ultra fast implementation of asyncio event loop on top of libuv. Configuration Libraries for storing and parsing configuration options. configobj - INI file parser with validation. configparser - (Python standard library) INI file parser. hydra - Hydra is a framework for elegantly configuring complex applications. profig - Config from multiple formats with value conversion. python-decouple - Strict separation of settings from code. Cryptography cryptography - A package designed to expose cryptographic primitives and recipes to Python developers. paramiko - The leading native Python SSHv2 protocol library. passlib - Secure password storage/hashing library, very high level. pynacl - Python binding to the Networking and Cryptography (NaCl) library. Data Analysis Libraries for data analyzing. AWS Data Wrangler - Pandas on AWS. Blaze - NumPy and Pandas interface to Big Data. Open Mining - Business Intelligence (BI) in Pandas interface. Optimus - Agile Data Science Workflows made easy with PySpark. Orange - Data mining, data visualization, analysis and machine learning through visual programming or scripts. Pandas - A library providing high-performance, easy-to-use data structures and data analysis tools. Data Validation Libraries for validating data. Used for forms in many cases. Cerberus - A lightweight and extensible data validation library. colander - Validating and deserializing data obtained via XML, JSON, an HTML form post. jsonschema - An implementation of JSON Schema for Python. schema - A library for validating Python data structures. Schematics - Data Structure Validation. valideer - Lightweight extensible data validation and adaptation library. voluptuous - A Python data validation library. Data Visualization Libraries for visualizing data. Also see awesome-javascript. Altair - Declarative statistical visualization library for Python. Bokeh - Interactive Web Plotting for Python. bqplot - Interactive Plotting Library for the Jupyter Notebook Cartopy - A cartographic python library with matplotlib support Dash - Built on top of Flask, React and Plotly aimed at analytical web applications. awesome-dash diagrams - Diagram as Code. Matplotlib - A Python 2D plotting library. plotnine - A grammar of graphics for Python based on ggplot2. Pygal - A Python SVG Charts Creator. PyGraphviz - Python interface to Graphviz. PyQtGraph - Interactive and realtime 2D/3D/Image plotting and science/engineering widgets. Seaborn - Statistical data visualization using Matplotlib. VisPy - High-performance scientific visualization based on OpenGL. Database Databases implemented in Python. pickleDB - A simple and lightweight key-value store for Python. tinydb - A tiny, document-oriented database. ZODB - A native object database for Python. A key-value and object graph database. Database Drivers Libraries for connecting and operating databases. MySQL - awesome-mysql mysqlclient - MySQL connector with Python 3 support (mysql-python fork). PyMySQL - A pure Python MySQL driver compatible to mysql-python. PostgreSQL - awesome-postgres psycopg2 - The most popular PostgreSQL adapter for Python. queries - A wrapper of the psycopg2 library for interacting with PostgreSQL. SQlite - awesome-sqlite sqlite3 - (Python standard library) SQlite interface compliant with DB-API 2.0 SuperSQLite - A supercharged SQLite library built on top of apsw. Other Relational Databases pymssql - A simple database interface to Microsoft SQL Server. clickhouse-driver - Python driver with native interface for ClickHouse. NoSQL Databases cassandra-driver - The Python Driver for Apache Cassandra. happybase - A developer-friendly library for Apache HBase. kafka-python - The Python client for Apache Kafka. py2neo - A client library and toolkit for working with Neo4j. pymongo - The official Python client for MongoDB. redis-py - The Python client for Redis. Asynchronous Clients motor - The async Python driver for MongoDB. Date and Time Libraries for working with dates and times. Arrow - A Python library that offers a sensible and human-friendly approach to creating, manipulating, formatting and converting dates, times and timestamps. Chronyk - A Python 3 library for parsing human-written times and dates. dateutil - Extensions to the standard Python datetime module. delorean - A library for clearing up the inconvenient truths that arise dealing with datetimes. maya - Datetimes for Humans. moment - A Python library for dealing with dates/times. Inspired by Moment.js. Pendulum - Python datetimes made easy. PyTime - An easy-to-use Python module which aims to operate date/time/datetime by string. pytz - World timezone definitions, modern and historical. Brings the tz database into Python. when.py - Providing user-friendly functions to help perform common date and time actions. Debugging Tools Libraries for debugging code. pdb-like Debugger ipdb - IPython-enabled pdb. pdb++ - Another drop-in replacement for pdb. pudb - A full-screen, console-based Python debugger. wdb - An improbable web debugger through WebSockets. Tracing lptrace - strace for Python programs. manhole - Debugging UNIX socket connections and present the stacktraces for all threads and an interactive prompt. pyringe - Debugger capable of attaching to and injecting code into Python processes. python-hunter - A flexible code tracing toolkit. Profiler line_profiler - Line-by-line profiling. memory_profiler - Monitor Memory usage of Python code. py-spy - A sampling profiler for Python programs. Written in Rust. pyflame - A ptracing profiler For Python. vprof - Visual Python profiler. Others django-debug-toolbar - Display various debug information for Django. django-devserver - A drop-in replacement for Django's runserver. flask-debugtoolbar - A port of the django-debug-toolbar to flask. icecream - Inspect variables, expressions, and program execution with a single, simple function call. pyelftools - Parsing and analyzing ELF files and DWARF debugging information. Deep Learning Frameworks for Neural Networks and Deep Learning. Also see awesome-deep-learning. caffe - A fast open framework for deep learning.. keras - A high-level neural networks library and capable of running on top of either TensorFlow or Theano. mxnet - A deep learning framework designed for both efficiency and flexibility. pytorch - Tensors and Dynamic neural networks in Python with strong GPU acceleration. SerpentAI - Game agent framework. Use any video game as a deep learning sandbox. tensorflow - The most popular Deep Learning framework created by Google. Theano - A library for fast numerical computation. DevOps Tools Software and libraries for DevOps. Configuration Management ansible - A radically simple IT automation platform. cloudinit - A multi-distribution package that handles early initialization of a cloud instance. OpenStack - Open source software for building private and public clouds. pyinfra - A versatile CLI tools and python libraries to automate infrastructure. saltstack - Infrastructure automation and management system. SSH-style Deployment cuisine - Chef-like functionality for Fabric. fabric - A simple, Pythonic tool for remote execution and deployment. fabtools - Tools for writing awesome Fabric files. Process Management honcho - A Python clone of Foreman, for managing Procfile-based applications. supervisor - Supervisor process control system for UNIX. Monitoring psutil - A cross-platform process and system utilities module. Backup BorgBackup - A deduplicating archiver with compression and encryption. Others docker-compose - Fast, isolated development environments using Docker. Distributed Computing Frameworks and libraries for Distributed Computing. Batch Processing dask - A flexible parallel computing library for analytic computing. luigi - A module that helps you build complex pipelines of batch jobs. mrjob - Run MapReduce jobs on Hadoop or Amazon Web Services. PySpark - Apache Spark Python API. Ray - A system for parallel and distributed Python that unifies the machine learning ecosystem. Stream Processing faust - A stream processing library, porting the ideas from Kafka Streams to Python. streamparse - Run Python code against real-time streams of data via Apache Storm. Distribution Libraries to create packaged executables for release distribution. dh-virtualenv - Build and distribute a virtualenv as a Debian package. Nuitka - Compile scripts, modules, packages to an executable or extension module. py2app - Freezes Python scripts (Mac OS X). py2exe - Freezes Python scripts (Windows). pyarmor - A tool used to obfuscate python scripts, bind obfuscated scripts to fixed machine or expire obfuscated scripts. PyInstaller - Converts Python programs into stand-alone executables (cross-platform). pynsist - A tool to build Windows installers, installers bundle Python itself. shiv - A command line utility for building fully self-contained zipapps (PEP 441), but with all their dependencies included. Documentation Libraries for generating project documentation. sphinx - Python Documentation generator. awesome-sphinxdoc pdoc - Epydoc replacement to auto generate API documentation for Python libraries. pycco - The literate-programming-style documentation generator. Downloader Libraries for downloading. akshare - A financial data interface library, built for human beings! s3cmd - A command line tool for managing Amazon S3 and CloudFront. s4cmd - Super S3 command line tool, good for higher performance. you-get - A YouTube/Youku/Niconico video downloader written in Python 3. youtube-dl - A small command-line program to download videos from YouTube. E-commerce Frameworks and libraries for e-commerce and payments. alipay - Unofficial Alipay API for Python. Cartridge - A shopping cart app built using the Mezzanine. django-oscar - An open-source e-commerce framework for Django. django-shop - A Django based shop system. forex-python - Foreign exchange rates, Bitcoin price index and currency conversion. merchant - A Django app to accept payments from various payment processors. money - Money class with optional CLDR-backed locale-aware formatting and an extensible currency exchange. python-currencies - Display money format and its filthy currencies. saleor - An e-commerce storefront for Django. shoop - An open source E-Commerce platform based on Django. Editor Plugins and IDEs Emacs elpy - Emacs Python Development Environment. Sublime Text anaconda - Anaconda turns your Sublime Text 3 in a full featured Python development IDE. SublimeJEDI - A Sublime Text plugin to the awesome auto-complete library Jedi. Vim jedi-vim - Vim bindings for the Jedi auto-completion library for Python. python-mode - An all in one plugin for turning Vim into a Python IDE. YouCompleteMe - Includes Jedi-based completion engine for Python. Visual Studio PTVS - Python Tools for Visual Studio. Visual Studio Code Python - The official VSCode extension with rich support for Python. IDE PyCharm - Commercial Python IDE by JetBrains. Has free community edition available. spyder - Open Source Python IDE. Email Libraries for sending and parsing email. Mail Servers modoboa - A mail hosting and management platform including a modern Web UI. salmon - A Python Mail Server. Clients imbox - Python IMAP for Humans. yagmail - Yet another Gmail/SMTP client. Others flanker - An email address and Mime parsing library. mailer - High-performance extensible mail delivery framework. Enterprise Application Integrations Platforms and tools for systems integrations in enterprise environments Zato - ESB, SOA, REST, APIs and Cloud Integrations in Python. Environment Management Libraries for Python version and virtual environment management. pyenv - Simple Python version management. virtualenv - A tool to create isolated Python environments. Files Libraries for file manipulation and MIME type detection. mimetypes - (Python standard library) Map filenames to MIME types. path.py - A module wrapper for os.path. pathlib - (Python standard library) An cross-platform, object-oriented path library. PyFilesystem2 - Python's filesystem abstraction layer. python-magic - A Python interface to the libmagic file type identification library. Unipath - An object-oriented approach to file/directory operations. watchdog - API and shell utilities to monitor file system events. Foreign Function Interface Libraries for providing foreign function interface. cffi - Foreign Function Interface for Python calling C code. ctypes - (Python standard library) Foreign Function Interface for Python calling C code. PyCUDA - A Python wrapper for Nvidia's CUDA API. SWIG - Simplified Wrapper and Interface Generator. Forms Libraries for working with forms. Deform - Python HTML form generation library influenced by the formish form generation library. django-bootstrap3 - Bootstrap 3 integration with Django. django-bootstrap4 - Bootstrap 4 integration with Django. django-crispy-forms - A Django app which lets you create beautiful forms in a very elegant and DRY way. django-remote-forms - A platform independent Django form serializer. WTForms - A flexible forms validation and rendering library. Functional Programming Functional Programming with Python. Coconut - A variant of Python built for simple, elegant, Pythonic functional programming. CyToolz - Cython implementation of Toolz: High performance functional utilities. fn.py - Functional programming in Python: implementation of missing features to enjoy FP. funcy - A fancy and practical functional tools. more-itertools - More routines for operating on iterables, beyond itertools. returns - A set of type-safe monads, transformers, and composition utilities. Toolz - A collection of functional utilities for iterators, functions, and dictionaries. GUI Development Libraries for working with graphical user interface applications. curses - Built-in wrapper for ncurses used to create terminal GUI applications. Eel - A library for making simple Electron-like offline HTML/JS GUI apps. enaml - Creating beautiful user-interfaces with Declarative Syntax like QML. Flexx - Flexx is a pure Python toolkit for creating GUI's, that uses web technology for its rendering. Gooey - Turn command line programs into a full GUI application with one line. kivy - A library for creating NUI applications, running on Windows, Linux, Mac OS X, Android and iOS. pyglet - A cross-platform windowing and multimedia library for Python. PyGObject - Python Bindings for GLib/GObject/GIO/GTK+ (GTK+3). PyQt - Python bindings for the Qt cross-platform application and UI framework. PySimpleGUI - Wrapper for tkinter, Qt, WxPython and Remi. pywebview - A lightweight cross-platform native wrapper around a webview component. Tkinter - Tkinter is Python's de-facto standard GUI package. Toga - A Python native, OS native GUI toolkit. urwid - A library for creating terminal GUI applications with strong support for widgets, events, rich colors, etc. wxPython - A blending of the wxWidgets C++ class library with the Python. DearPyGui - A Simple GPU accelerated Python GUI framework GraphQL Libraries for working with GraphQL. graphene - GraphQL framework for Python. tartiflette-aiohttp - An aiohttp-based wrapper for Tartiflette to expose GraphQL APIs over HTTP. tartiflette-asgi - ASGI support for the Tartiflette GraphQL engine. tartiflette - SDL-first GraphQL engine implementation for Python 3.6+ and asyncio. Game Development Awesome game development libraries. Arcade - Arcade is a modern Python framework for crafting games with compelling graphics and sound. Cocos2d - cocos2d is a framework for building 2D games, demos, and other graphical/interactive applications. Harfang3D - Python framework for 3D, VR and game development. Panda3D - 3D game engine developed by Disney. Pygame - Pygame is a set of Python modules designed for writing games. PyOgre - Python bindings for the Ogre 3D render engine, can be used for games, simulations, anything 3D. PyOpenGL - Python ctypes bindings for OpenGL and it's related APIs. PySDL2 - A ctypes based wrapper for the SDL2 library. RenPy - A Visual Novel engine. Geolocation Libraries for geocoding addresses and working with latitudes and longitudes. django-countries - A Django app that provides a country field for models and forms. GeoDjango - A world-class geographic web framework. GeoIP - Python API for MaxMind GeoIP Legacy Database. geojson - Python bindings and utilities for GeoJSON. geopy - Python Geocoding Toolbox. HTML Manipulation Libraries for working with HTML and XML. BeautifulSoup - Providing Pythonic idioms for iterating, searching, and modifying HTML or XML. bleach - A whitelist-based HTML sanitization and text linkification library. cssutils - A CSS library for Python. html5lib - A standards-compliant library for parsing and serializing HTML documents and fragments. lxml - A very fast, easy-to-use and versatile library for handling HTML and XML. MarkupSafe - Implements a XML/HTML/XHTML Markup safe string for Python. pyquery - A jQuery-like library for parsing HTML. untangle - Converts XML documents to Python objects for easy access. WeasyPrint - A visual rendering engine for HTML and CSS that can export to PDF. xmldataset - Simple XML Parsing. xmltodict - Working with XML feel like you are working with JSON. HTTP Clients Libraries for working with HTTP. grequests - requests + gevent for asynchronous HTTP requests. httplib2 - Comprehensive HTTP client library. httpx - A next generation HTTP client for Python. requests - HTTP Requests for Humans. treq - Python requests like API built on top of Twisted's HTTP client. urllib3 - A HTTP library with thread-safe connection pooling, file post support, sanity friendly. Hardware Libraries for programming with hardware. ino - Command line toolkit for working with Arduino. keyboard - Hook and simulate global keyboard events on Windows and Linux. mouse - Hook and simulate global mouse events on Windows and Linux. Pingo - Pingo provides a uniform API to program devices like the Raspberry Pi, pcDuino, Intel Galileo, etc. PyUserInput - A module for cross-platform control of the mouse and keyboard. scapy - A brilliant packet manipulation library. wifi - A Python library and command line tool for working with WiFi on Linux. Image Processing Libraries for manipulating images. hmap - Image histogram remapping. imgSeek - A project for searching a collection of images using visual similarity. nude.py - Nudity detection. pagan - Retro identicon (Avatar) generation based on input string and hash. pillow - Pillow is the friendly PIL fork. python-barcode - Create barcodes in Python with no extra dependencies. pygram - Instagram-like image filters. PyMatting - A library for alpha matting. python-qrcode - A pure Python QR Code generator. pywal - A tool that generates color schemes from images. pyvips - A fast image processing library with low memory needs. Quads - Computer art based on quadtrees. scikit-image - A Python library for (scientific) image processing. thumbor - A smart imaging service. It enables on-demand crop, re-sizing and flipping of images. wand - Python bindings for MagickWand, C API for ImageMagick. Implementations Implementations of Python. CLPython - Implementation of the Python programming language written in Common Lisp. CPython - Default, most widely used implementation of the Python programming language written in C. Cython - Optimizing Static Compiler for Python. Grumpy - More compiler than interpreter as more powerful CPython2.7 replacement (alpha). IronPython - Implementation of the Python programming language written in C#. Jython - Implementation of Python programming language written in Java for the JVM. MicroPython - A lean and efficient Python programming language implementation. Numba - Python JIT compiler to LLVM aimed at scientific Python. PeachPy - x86-64 assembler embedded in Python. Pyjion - A JIT for Python based upon CoreCLR. PyPy - A very fast and compliant implementation of the Python language. Pyston - A Python implementation using JIT techniques. Stackless Python - An enhanced version of the Python programming language. Interactive Interpreter Interactive Python interpreters (REPL). bpython - A fancy interface to the Python interpreter. Jupyter Notebook (IPython) - A rich toolkit to help you make the most out of using Python interactively. awesome-jupyter ptpython - Advanced Python REPL built on top of the python-prompt-toolkit. Internationalization Libraries for working with i18n. Babel - An internationalization library for Python. PyICU - A wrapper of International Components for Unicode C++ library (ICU). Job Scheduler Libraries for scheduling jobs. Airflow - Airflow is a platform to programmatically author, schedule and monitor workflows. APScheduler - A light but powerful in-process task scheduler that lets you schedule functions. django-schedule - A calendaring app for Django. doit - A task runner and build tool. gunnery - Multipurpose task execution tool for distributed systems with web-based interface. Joblib - A set of tools to provide lightweight pipelining in Python. Plan - Writing crontab file in Python like a charm. Prefect - A modern workflow orchestration framework that makes it easy to build, schedule and monitor robust data pipelines. schedule - Python job scheduling for humans. Spiff - A powerful workflow engine implemented in pure Python. TaskFlow - A Python library that helps to make task execution easy, consistent and reliable. Logging Libraries for generating and working with logs. logbook - Logging replacement for Python. logging - (Python standard library) Logging facility for Python. loguru - Library which aims to bring enjoyable logging in Python. sentry-python - Sentry SDK for Python. structlog - Structured logging made easy. Machine Learning Libraries for Machine Learning. Also see awesome-machine-learning. gym - A toolkit for developing and comparing reinforcement learning algorithms. H2O - Open Source Fast Scalable Machine Learning Platform. Metrics - Machine learning evaluation metrics. NuPIC - Numenta Platform for Intelligent Computing. scikit-learn - The most popular Python library for Machine Learning. Spark ML - Apache Spark's scalable Machine Learning library. vowpal_porpoise - A lightweight Python wrapper for Vowpal Wabbit. xgboost - A scalable, portable, and distributed gradient boosting library. MindsDB - MindsDB is an open source AI layer for existing databases that allows you to effortlessly develop, train and deploy state-of-the-art machine learning models using standard queries. Microsoft Windows Python programming on Microsoft Windows. Python(x,y) - Scientific-applications-oriented Python Distribution based on Qt and Spyder. pythonlibs - Unofficial Windows binaries for Python extension packages. PythonNet - Python Integration with the .NET Common Language Runtime (CLR). PyWin32 - Python Extensions for Windows. WinPython - Portable development environment for Windows 7/8. Miscellaneous Useful libraries or tools that don't fit in the categories above. blinker - A fast Python in-process signal/event dispatching system. boltons - A set of pure-Python utilities. itsdangerous - Various helpers to pass trusted data to untrusted environments. magenta - A tool to generate music and art using artificial intelligence. pluginbase - A simple but flexible plugin system for Python. tryton - A general purpose business framework. Natural Language Processing Libraries for working with human languages. General gensim - Topic Modeling for Humans. langid.py - Stand-alone language identification system. nltk - A leading platform for building Python programs to work with human language data. pattern - A web mining module. polyglot - Natural language pipeline supporting hundreds of languages. pytext - A natural language modeling framework based on PyTorch. PyTorch-NLP - A toolkit enabling rapid deep learning NLP prototyping for research. spacy - A library for industrial-strength natural language processing in Python and Cython. Stanza - The Stanford NLP Group's official Python library, supporting 60+ languages. Chinese funNLP - A collection of tools and datasets for Chinese NLP. jieba - The most popular Chinese text segmentation library. pkuseg-python - A toolkit for Chinese word segmentation in various domains. snownlp - A library for processing Chinese text. Network Virtualization Tools and libraries for Virtual Networking and SDN (Software Defined Networking). mininet - A popular network emulator and API written in Python. napalm - Cross-vendor API to manipulate network devices. pox - A Python-based SDN control applications, such as OpenFlow SDN controllers. News Feed Libraries for building user's activities. django-activity-stream - Generating generic activity streams from the actions on your site. Stream Framework - Building news feed and notification systems using Cassandra and Redis. ORM Libraries that implement Object-Relational Mapping or data mapping techniques. Relational Databases Django Models - The Django ORM. SQLAlchemy - The Python SQL Toolkit and Object Relational Mapper. awesome-sqlalchemy dataset - Store Python dicts in a database - works with SQLite, MySQL, and PostgreSQL. orator - The Orator ORM provides a simple yet beautiful ActiveRecord implementation. orm - An async ORM. peewee - A small, expressive ORM. pony - ORM that provides a generator-oriented interface to SQL. pydal - A pure Python Database Abstraction Layer. NoSQL Databases hot-redis - Rich Python data types for Redis. mongoengine - A Python Object-Document-Mapper for working with MongoDB. PynamoDB - A Pythonic interface for Amazon DynamoDB. redisco - A Python Library for Simple Models and Containers Persisted in Redis. Package Management Libraries for package and dependency management. pip - The package installer for Python. pip-tools - A set of tools to keep your pinned Python dependencies fresh. PyPI conda - Cross-platform, Python-agnostic binary package manager. poetry - Python dependency management and packaging made easy. Package Repositories Local PyPI repository server and proxies. bandersnatch - PyPI mirroring tool provided by Python Packaging Authority (PyPA). devpi - PyPI server and packaging/testing/release tool. localshop - Local PyPI server (custom packages and auto-mirroring of pypi). warehouse - Next generation Python Package Repository (PyPI). Penetration Testing Frameworks and tools for penetration testing. fsociety - A Penetration testing framework. setoolkit - A toolkit for social engineering. sqlmap - Automatic SQL injection and database takeover tool. Permissions Libraries that allow or deny users access to data or functionality. django-guardian - Implementation of per object permissions for Django 1.2+ django-rules - A tiny but powerful app providing object-level permissions to Django, without requiring a database. Processes Libraries for starting and communicating with OS processes. delegator.py - Subprocesses for Humans 2.0. sarge - Yet another wrapper for subprocess. sh - A full-fledged subprocess replacement for Python. Recommender Systems Libraries for building recommender systems. annoy - Approximate Nearest Neighbors in C++/Python optimized for memory usage. fastFM - A library for Factorization Machines. implicit - A fast Python implementation of collaborative filtering for implicit datasets. libffm - A library for Field-aware Factorization Machine (FFM). lightfm - A Python implementation of a number of popular recommendation algorithms. spotlight - Deep recommender models using PyTorch. Surprise - A scikit for building and analyzing recommender systems. tensorrec - A Recommendation Engine Framework in TensorFlow. Refactoring Refactoring tools and libraries for Python Bicycle Repair Man - Bicycle Repair Man, a refactoring tool for Python. Bowler - Safe code refactoring for modern Python. Rope - Rope is a python refactoring library. RESTful API Libraries for building RESTful APIs. Django django-rest-framework - A powerful and flexible toolkit to build web APIs. django-tastypie - Creating delicious APIs for Django apps. Flask eve - REST API framework powered by Flask, MongoDB and good intentions. flask-api - Browsable Web APIs for Flask. flask-restful - Quickly building REST APIs for Flask. Pyramid cornice - A RESTful framework for Pyramid. Framework agnostic apistar - A smart Web API framework, designed for Python 3. falcon - A high-performance framework for building cloud APIs and web app backends. fastapi - A modern, fast, web framework for building APIs with Python 3.6+ based on standard Python type hints. hug - A Python 3 framework for cleanly exposing APIs. sandman2 - Automated REST APIs for existing database-driven systems. sanic - A Python 3.6+ web server and web framework that's written to go fast. vibora - Fast, efficient and asynchronous Web framework inspired by Flask. Robotics Libraries for robotics. PythonRobotics - This is a compilation of various robotics algorithms with visualizations. rospy - This is a library for ROS (Robot Operating System). RPC Servers RPC-compatible servers. RPyC (Remote Python Call) - A transparent and symmetric RPC library for Python zeroRPC - zerorpc is a flexible RPC implementation based on ZeroMQ and MessagePack. Science Libraries for scientific computing. Also see Python-for-Scientists. astropy - A community Python library for Astronomy. bcbio-nextgen - Providing best-practice pipelines for fully automated high throughput sequencing analysis. bccb - Collection of useful code related to biological analysis. Biopython - Biopython is a set of freely available tools for biological computation. cclib - A library for parsing and interpreting the results of computational chemistry packages. Colour - Implementing a comprehensive number of colour theory transformations and algorithms. Karate Club - Unsupervised machine learning toolbox for graph structured data. NetworkX - A high-productivity software for complex networks. NIPY - A collection of neuroimaging toolkits. NumPy - A fundamental package for scientific computing with Python. ObsPy - A Python toolbox for seismology. Open Babel - A chemical toolbox designed to speak the many languages of chemical data. PyDy - Short for Python Dynamics, used to assist with workflow in the modeling of dynamic motion. PyMC - Markov Chain Monte Carlo sampling toolkit. QuTiP - Quantum Toolbox in Python. RDKit - Cheminformatics and Machine Learning Software. SciPy - A Python-based ecosystem of open-source software for mathematics, science, and engineering. SimPy - A process-based discrete-event simulation framework. statsmodels - Statistical modeling and econometrics in Python. SymPy - A Python library for symbolic mathematics. Zipline - A Pythonic algorithmic trading library. Search Libraries and software for indexing and performing search queries on data. django-haystack - Modular search for Django. elasticsearch-dsl-py - The official high-level Python client for Elasticsearch. elasticsearch-py - The official low-level Python client for Elasticsearch. pysolr - A lightweight Python wrapper for Apache Solr. whoosh - A fast, pure Python search engine library. Serialization Libraries for serializing complex data types marshmallow - A lightweight library for converting complex objects to and from simple Python datatypes. pysimdjson - A Python bindings for simdjson. python-rapidjson - A Python wrapper around RapidJSON. ultrajson - A fast JSON decoder and encoder written in C with Python bindings. Serverless Frameworks Frameworks for developing serverless Python code. python-lambda - A toolkit for developing and deploying Python code in AWS Lambda. Zappa - A tool for deploying WSGI applications on AWS Lambda and API Gateway. Shell Shells based on Python. xonsh - A Python-powered, cross-platform, Unix-gazing shell language and command prompt. Specific Formats Processing Libraries for parsing and manipulating specific text formats. General tablib - A module for Tabular Datasets in XLS, CSV, JSON, YAML. Office docxtpl - Editing a docx document by jinja2 template openpyxl - A library for reading and writing Excel 2010 xlsx/xlsm/xltx/xltm files. pyexcel - Providing one API for reading, manipulating and writing csv, ods, xls, xlsx and xlsm files. python-docx - Reads, queries and modifies Microsoft Word 2007/2008 docx files. python-pptx - Python library for creating and updating PowerPoint (.pptx) files. unoconv - Convert between any document format supported by LibreOffice/OpenOffice. XlsxWriter - A Python module for creating Excel .xlsx files. xlwings - A BSD-licensed library that makes it easy to call Python from Excel and vice versa. xlwt / xlrd - Writing and reading data and formatting information from Excel files. PDF PDFMiner - A tool for extracting information from PDF documents. PyPDF2 - A library capable of splitting, merging and transforming PDF pages. ReportLab - Allowing Rapid creation of rich PDF documents. Markdown Mistune - Fastest and full featured pure Python parsers of Markdown. Python-Markdown - A Python implementation of John Grubers Markdown. YAML PyYAML - YAML implementations for Python. CSV csvkit - Utilities for converting to and working with CSV. Archive unp - A command line tool that can unpack archives easily. Static Site Generator Static site generator is a software that takes some text + templates as input and produces HTML files on the output. lektor - An easy to use static CMS and blog engine. mkdocs - Markdown friendly documentation generator. makesite - Simple, lightweight, and magic-free static site/blog generator (< 130 lines). nikola - A static website and blog generator. pelican - Static site generator that supports Markdown and reST syntax. Tagging Libraries for tagging items. django-taggit - Simple tagging for Django. Task Queues Libraries for working with task queues. celery - An asynchronous task queue/job queue based on distributed message passing. dramatiq - A fast and reliable background task processing library for Python 3. huey - Little multi-threaded task queue. mrq - A distributed worker task queue in Python using Redis & gevent. rq - Simple job queues for Python. Template Engine Libraries and tools for templating and lexing. Genshi - Python templating toolkit for generation of web-aware output. Jinja2 - A modern and designer friendly templating language. Mako - Hyperfast and lightweight templating for the Python platform. Testing Libraries for testing codebases and generating test data. Testing Frameworks hypothesis - Hypothesis is an advanced Quickcheck style property based testing library. nose2 - The successor to nose, based on `unittest2. pytest - A mature full-featured Python testing tool. Robot Framework - A generic test automation framework. unittest - (Python standard library) Unit testing framework. Test Runners green - A clean, colorful test runner. mamba - The definitive testing tool for Python. Born under the banner of BDD. tox - Auto builds and tests distributions in multiple Python versions GUI / Web Testing locust - Scalable user load testing tool written in Python. PyAutoGUI - PyAutoGUI is a cross-platform GUI automation Python module for human beings. Schemathesis - A tool for automatic property-based testing of web applications built with Open API / Swagger specifications. Selenium - Python bindings for Selenium WebDriver. sixpack - A language-agnostic A/B Testing framework. splinter - Open source tool for testing web applications. Mock doublex - Powerful test doubles framework for Python. freezegun - Travel through time by mocking the datetime module. httmock - A mocking library for requests for Python 2.6+ and 3.2+. httpretty - HTTP request mock tool for Python. mock - (Python standard library) A mocking and patching library. mocket - A socket mock framework with gevent/asyncio/SSL support. responses - A utility library for mocking out the requests Python library. VCR.py - Record and replay HTTP interactions on your tests. Object Factories factory_boy - A test fixtures replacement for Python. mixer - Another fixtures replacement. Supports Django, Flask, SQLAlchemy, Peewee and etc. model_mommy - Creating random fixtures for testing in Django. Code Coverage coverage - Code coverage measurement. Fake Data fake2db - Fake database generator. faker - A Python package that generates fake data. mimesis - is a Python library that help you generate fake data. radar - Generate random datetime / time. Text Processing Libraries for parsing and manipulating plain texts. General chardet - Python 2/3 compatible character encoding detector. difflib - (Python standard library) Helpers for computing deltas. ftfy - Makes Unicode text less broken and more consistent automagically. fuzzywuzzy - Fuzzy String Matching. Levenshtein - Fast computation of Levenshtein distance and string similarity. pangu.py - Paranoid text spacing. pyfiglet - An implementation of figlet written in Python. pypinyin - Convert Chinese hanzi () to pinyin (). textdistance - Compute distance between sequences with 30+ algorithms. unidecode - ASCII transliterations of Unicode text. Slugify awesome-slugify - A Python slugify library that can preserve unicode. python-slugify - A Python slugify library that translates unicode to ASCII. unicode-slugify - A slugifier that generates unicode slugs with Django as a dependency. Unique identifiers hashids - Implementation of hashids in Python. shortuuid - A generator library for concise, unambiguous and URL-safe UUIDs. Parser ply - Implementation of lex and yacc parsing tools for Python. pygments - A generic syntax highlighter. pyparsing - A general purpose framework for generating parsers. python-nameparser - Parsing human names into their individual components. python-phonenumbers - Parsing, formatting, storing and validating international phone numbers. python-user-agents - Browser user agent parser. sqlparse - A non-validating SQL parser. Third-party APIs Libraries for accessing third party services APIs. Also see List of Python API Wrappers and Libraries. apache-libcloud - One Python library for all clouds. boto3 - Python interface to Amazon Web Services. django-wordpress - WordPress models and views for Django. facebook-sdk - Facebook Platform Python SDK. google-api-python-client - Google APIs Client Library for Python. gspread - Google Spreadsheets Python API. twython - A Python wrapper for the Twitter API. URL Manipulation Libraries for parsing URLs. furl - A small Python library that makes parsing and manipulating URLs easy. purl - A simple, immutable URL class with a clean API for interrogation and manipulation. pyshorteners - A pure Python URL shortening lib. webargs - A friendly library for parsing HTTP request arguments with built-in support for popular web frameworks. Video Libraries for manipulating video and GIFs. moviepy - A module for script-based movie editing with many formats, including animated GIFs. scikit-video - Video processing routines for SciPy. vidgear - Most Powerful multi-threaded Video Processing framework. Web Asset Management Tools for managing, compressing and minifying website assets. django-compressor - Compresses linked and inline JavaScript or CSS into a single cached file. django-pipeline - An asset packaging library for Django. django-storages - A collection of custom storage back ends for Django. fanstatic - Packages, optimizes, and serves static file dependencies as Python packages. fileconveyor - A daemon to detect and sync files to CDNs, S3 and FTP. flask-assets - Helps you integrate webassets into your Flask app. webassets - Bundles, optimizes, and manages unique cache-busting URLs for static resources. Web Content Extracting Libraries for extracting web contents. html2text - Convert HTML to Markdown-formatted text. lassie - Web Content Retrieval for Humans. micawber - A small library for extracting rich content from URLs. newspaper - News extraction, article extraction and content curation in Python. python-readability - Fast Python port of arc90's readability tool. requests-html - Pythonic HTML Parsing for Humans. sumy - A module for automatic summarization of text documents and HTML pages. textract - Extract text from any document, Word, PowerPoint, PDFs, etc. toapi - Every web site provides APIs. Web Crawling Libraries to automate web scraping. cola - A distributed crawling framework. feedparser - Universal feed parser. grab - Site scraping framework. MechanicalSoup - A Python library for automating interaction with websites. portia - Visual scraping for Scrapy. pyspider - A powerful spider system. robobrowser - A simple, Pythonic library for browsing the web without a standalone web browser. scrapy - A fast high-level screen scraping and web crawling framework. Web Frameworks Traditional full stack web frameworks. Also see RESTful API. Synchronous Django - The most popular web framework in Python. awesome-django awesome-django Flask - A microframework for Python. awesome-flask Pyramid - A small, fast, down-to-earth, open source Python web framework. awesome-pyramid Masonite - The modern and developer centric Python web framework. Asynchronous Tornado - A web framework and asynchronous networking library. WebSocket Libraries for working with WebSocket. autobahn-python - WebSocket & WAMP for Python on Twisted and asyncio. channels - Developer-friendly asynchrony for Django. websockets - A library for building WebSocket servers and clients with a focus on correctness and simplicity. WSGI Servers WSGI-compatible web servers. bjoern - Asynchronous, very fast and written in C. gunicorn - Pre-forked, ported from Ruby's Unicorn project. uWSGI - A project aims at developing a full stack for building hosting services, written in C. waitress - Multi-threaded, powers Pyramid. werkzeug - A WSGI utility library for Python that powers Flask and can easily be embedded into your own projects. Resources Where to discover learning resources or new Python libraries. Books Fluent Python Think Python Websites Tutorials Full Stack Python Python Cheatsheet Real Python The Hitchhikers Guide to Python Ultimate Python study guide Libraries Awesome Python @LibHunt Others Python ZEEF Pythonic News What the f*ck Python! Newsletters Awesome Python Newsletter Pycoder's Weekly Python Tricks Python Weekly Podcasts Django Chat Podcast.__init__ Python Bytes Running in Production Talk Python To Me Test and Code The Real Python Podcast Contributing Your contributions are always welcome! Please take a look at the contribution guidelines first. I will keep some pull requests open if I'm not sure whether those libraries are awesome, you could vote for them by adding :+1: to them. Pull requests will be merged when their votes reach 20. If you have any question about this opinionated list, do not hesitate to contact me @VintaChen on Twitter or open an issue on GitHub.

