,0
3437,"Small library of visual debugging tools for iOS.DCIntrospect Twitter: @patr Our commercial apps: domesticcat.com.au Introspect is small set of tools for iOS that aid in debugging user interfaces built with UIKit. It's especially useful for UI layouts that are dynamically created or can change during runtime, or for tuning performance by finding non-opaque views or views that are re-drawing unnecessarily. It's designed for use in the iPhone simulator, but can also be used on a device. It uses keyboard shortcuts to handle starting, ending and other commands. It can also be invoked via an app-wide UIGestureRecognizer if it is to be used on the device. Features: Simple to setup and use Controlled via app-wide keyboard commands Highlighting of view frames Displays a views origin & size, including distances to edges of main window Move and resize view frames during runtime using shortcut keys Logging of properties of a view, including subclass properties, actions and targets (see below for an example) Logging of accessibility properties useful for UI automation scripts Manually call setNeedsDisplay, setNeedsLayout and reloadData (for UITableView) Highlight all view outlines Highlight all views that are non-opaque Shows warning for views that are positioned on non-integer origins (will cause blurriness when drawn) Print a views hierarchy to console (via private method recursiveDescription) to console Usage Before you start make sure the DEBUG environment variable is set. DCIntrospect will not run without that set to prevent it being left in for production use. Add the DCIntrospect class files to your project, add the QuartzCore framework if needed. To start: [window makeKeyAndDisplay] // always call after makeKeyAndDisplay. #if TARGET_IPHONE_SIMULATOR [[DCIntrospect sharedIntrospector] start]; #endif The #if to target the simulator is not required but is a good idea to further prevent leaving it on in production code. Once setup, simply push the space bar to invoke the introspect or then start clicking on views to get info. You can also tap and drag around the interface. A a small demo app is included to test it out. Selected keyboard shortcuts Start/Stop: spacebar Help: ? Print properties and actions of selected view to console: p Print accessibility properties and actions of selected view to console: a Toggle all view outlines: o Toggle highlighting non-opaque views: O Nudge view left, right, up & down: 4 6 8 2 (use the numeric pad) or Print out the selected views' new frame to console after nudge/resize: 0 Print selected views recursive description to console: v Logging selected views properties Pushing p will log out the available properties about the selected view. DCIntrospect will try to make sense of the values it can and show more useful info. An example from a UIButton: ** UIRoundedRectButton : UIButton : UIControl : UIView : UIResponder : NSObject ** ** UIView properties ** tag: 1 frame: {{21, 331}, {278, 37}} | bounds: {{0, 0}, {278, 37}} | center: {160, 349.5} transform: [1, 0, 0, 1, 0, 0] autoresizingMask: UIViewAutoresizingFlexibleRightMargin | UIViewAutoresizingFlexibleTopMargin autoresizesSubviews: YES contentMode: UIViewContentModeScaleToFill | contentStretch: {{0, 0}, {1, 1}} backgroundColor: nil alpha: 1.00 | opaque: NO | hidden: NO | clips to bounds: NO | clearsContextBeforeDrawing: YES userInteractionEnabled: YES | multipleTouchEnabled: NO gestureRecognizers: nil ** UIRoundedRectButton properties ** ** Targets & Actions ** target: <DCIntrospectDemoViewController: 0x4c8c0e0> action: buttonTapped: Customizing Key Bindings Edit the file DCIntrospectSettings.h to change key bindings. You might want to change the key bindings if your using a laptop/wireless keyboard for development. License Made available under the MIT License. Collaboration If you have any feature requests/bugfixes etc. feel free to help out and send a pull request, or create a new issue."
79,"One framework. Mobile & desktop.Angular - The modern web developer's platform. Angular is a development platform for building mobile and desktop web applications using Typescript/JavaScript and other languages. www.angular.io Contributing Guidelines Submit an Issue Blog Documentation Get started with Angular, learn the fundamentals and explore advanced topics on our documentation website. Getting Started Architecture Components and Templates Forms API Advanced Angular Elements Server Side Rendering Schematics Lazy Loading Development Setup Prerequisites Install Node.js which includes Node Package Manager Setting Up a Project Install the Angular CLI globally: Create workspace: Run the application: Angular is cross-platform, fast, scalable, has incredible tooling, and is loved by millions. Quickstart Get started in 5 minutes. Ecosystem Angular Command Line (CLI) Angular Material Changelog Learn about the latest improvements. Upgrading Check out our upgrade guide to find out the best way to upgrade your project. Contributing Contributing Guidelines Read through our contributing guidelines to learn about our submission process, coding rules and more. Want to Help? Want to file a bug, contribute some code, or improve documentation? Excellent! Read up on our guidelines for contributing and then check out one of our issues labeled as help wanted or good first issue. Code of Conduct Help us keep Angular open and inclusive. Please read and follow our Code of Conduct. Community Join the conversation and help the community. Twitter Discord Gitter YouTube StackOverflow Find a Local Meetup Love Angular? Give our repo a star :star: :arrow_up:."
1767,"Commenting without the commentsEchochamber.js All of the commenting, none of the comments. alpha af Echochamber.js is a third-party script you can install to add a simple comment form to your blog post or website. why not just use disqus? Because then there'd be a chance that someone would read the comments. You might have to read those comments. You don't want that. When a user submits a comment, echochamber.js will save the comment to the user's LocalStorage, so when they return to the page, they can be confident that their voice is being heard, and feel engaged with your very engaging content. It does not make any HTTP requests. Since LocalStorage is only local, you and your database need not be burdened with other people's opinions. Features No server required! 100% spam-proof! Compatible with most blog and static site software Styles itself nicely to match your site's colours and fonts Installation Copy and paste the following code where you want your comments to appear: Screenshot Contributing Requirements: node 1.Fork the repo * clone the fork * run npm install Local dev: If you want to work with the iframe environment, there are some steps: So you want the widget running on one server, and the host on another. I do this locally by messing with /etc/hosts like so: modify your httpd.conf file (in /etc/apache2) restart apache run ./script/watch.sh during dev (unix only) run ./script/build.sh before making a pull request make a pull request against the main repo referencing an issue if possible"
812,"Mobile ShellMosh: the mobile shell Mosh is a remote terminal application that supports intermittent connectivity, allows roaming, and provides speculative local echo and line editing of user keystrokes. It aims to support the typical interactive uses of SSH, plus: Mosh keeps the session alive if the client goes to sleep and wakes up later, or temporarily loses its Internet connection. Mosh allows the client and server to ""roam"" and change IP addresses, while keeping the connection alive. Unlike SSH, Mosh can be used while switching between Wi-Fi networks or from Wi-Fi to cellular data to wired Ethernet. The Mosh client runs a predictive model of the server's behavior in the background and tries to guess intelligently how each keystroke will affect the screen state. When it is confident in its predictions, it will show them to the user while waiting for confirmation from the server. Most typing and uses of the left- and right-arrow keys can be echoed immediately. As a result, Mosh is usable on high-latency links, e.g. on a cellular data connection or spotty Wi-Fi. In distinction from previous attempts at local echo modes in other protocols, Mosh works properly with full-screen applications such as emacs, vi, alpine, and irssi, and automatically recovers from occasional prediction errors within an RTT. On high-latency links, Mosh underlines its predictions while they are outstanding and removes the underline when they are confirmed by the server. Mosh does not support X forwarding or the non-interactive uses of SSH, including port forwarding. Other features Mosh adjusts its frame rate so as not to fill up network queues on slow links, so ""Control-C"" always works within an RTT to halt a runaway process. Mosh warns the user when it has not heard from the server in a while. Mosh supports lossy links that lose a significant fraction of their packets. Mosh handles some Unicode edge cases better than SSH and existing terminal emulators by themselves, but requires a UTF-8 environment to run. Mosh leverages SSH to set up the connection and authenticate users. Mosh does not contain any privileged (root) code. Getting Mosh The Mosh web site has information about packages for many operating systems, as well as instructions for building from source. Note that mosh-client receives an AES session key as an environment variable. If you are porting Mosh to a new operating system, please make sure that a running process's environment variables are not readable by other users. We have confirmed that this is the case on GNU/Linux, OS X, and FreeBSD. Usage The mosh-client binary must exist on the user's machine, and the mosh-server binary on the remote host. The user runs: $ mosh [user@]host If the mosh-client or mosh-server binaries live outside the user's $PATH, mosh accepts the arguments --client=PATH and --server=PATH to select alternate locations. More options are documented in the mosh(1) manual page. There are more examples and a FAQ on the Mosh web site. How it works The mosh program will SSH to user@host to establish the connection. SSH may prompt the user for a password or use public-key authentication to log in. From this point, mosh runs the mosh-server process (as the user) on the server machine. The server process listens on a high UDP port and sends its port number and an AES-128 secret key back to the client over SSH. The SSH connection is then shut down and the terminal session begins over UDP. If the client changes IP addresses, the server will begin sending to the client on the new IP address within a few seconds. To function, Mosh requires UDP datagrams to be passed between client and server. By default, mosh uses a port number between 60000 and 61000, but the user can select a particular port with the -p option. Please note that the -p option has no effect on the port used by SSH. Advice to distributors A note on compiler flags: Mosh is security-sensitive code. When making automated builds for a binary package, we recommend passing the option --enable-compile-warnings=error to ./configure. On GNU/Linux with g++ or clang++, the package should compile cleanly with -Werror. Please report a bug if it doesn't. Where available, Mosh builds with a variety of binary hardening flags such as -fstack-protector-all, -D_FORTIFY_SOURCE=2, etc. These provide proactive security against the possibility of a memory corruption bug in Mosh or one of the libraries it uses. For a full list of flags, search for HARDEN in configure.ac. The configure script detects which flags are supported by your compiler, and enables them automatically. To disable this detection, pass --disable-hardening to ./configure. Please report a bug if you have trouble with the default settings; we would like as many users as possible to be running a configuration as secure as possible. Mosh ships with a default optimization setting of -O2. Some distributors have asked about changing this to -Os (which causes a compiler to prefer space optimizations to time optimizations). We have benchmarked with the included src/examples/benchmark program to test this. The results are that -O2 is 40% faster than -Os with g++ 4.6 on GNU/Linux, and 16% faster than -Os with clang++ 3.1 on Mac OS X. In both cases, -Os did produce a smaller binary (by up to 40%, saving almost 200 kilobytes on disk). While Mosh is not especially CPU intensive and mostly sits idle when the user is not typing, we think the results suggest that -O2 (the default) is preferable. Our Debian and Fedora packaging presents Mosh as a single package. Mosh has a Perl dependency that is only required for client use. For some platforms, it may make sense to have separate mosh-server and mosh-client packages to allow mosh-server usage without Perl. More info Mosh Web site: https://mosh.org mosh-devel@mit.edu mailing list: https://mailman.mit.edu/mailman/listinfo/mosh-devel mosh-users@mit.edu mailing list: https://mailman.mit.edu/mailman/listinfo/mosh-users #mosh channel on Freenode IRC https://webchat.freenode.net/?channels=mosh"
2890,MIT Licensed Open Source version of Torque 3D from GarageGamesTorque 3D MIT Licensed Open Source version of Torque 3D from GarageGames More Information Homepage Torque 3D wiki Community forum GarageGames forum GarageGames professional services Pre-compiled Version In addition to GitHub we also have a couple of pre-packaged files for you to download if you would prefer to not compile the code yourself. They are available from the downloads page on the wiki. Related repositories Project Manager repository Offline documentation repository License All assets and code are under the
350,"Free Bootstrap 4 Admin Dashboard Templategentelella Gentelella Admin is a free to use Bootstrap admin template. This template uses the default Bootstrap 4 styles along with a variety of powerful jQuery plugins and tools to create a powerful framework for creating admin panels or back-end dashboards. Theme uses several libraries for charts, calendar, form validation, wizard style interface, off-canvas navigation menu, text forms, date range, upload area, form autocomplete, range slider, progress bars, notifications and much more. We would love to see how you use this awesome admin template. You can notify us about your site, app or service by tweeting to @colorlib. Once the list will grown long enough we will write a post similar to this to showcase the best examples. Theme Demo Template Demo Documentation Documentation Installation via Package Manager Our goal is to make it installable on different Package Manager! Do you want to use it on your favorite Package Manager and you know how? Pull request all the way! As of now, this is some installation available: Bower npm yarn How to contribute To contribute, please ensure that you have stable Node.js and npm installed. Test if Gulp CLI is installed by running gulp --version. If the command isn't found, run npm install -g gulp. For more information about installing Gulp, see the Gulp's Getting Started. To have all gulp dependencies run If gulp is installed, follow the steps below. Fork and clone the repo. Run gulp, this will open gentelella on your default browser Now you can code, code and code! Submit a pull request Gentelella for other platforms and frameworks Gentelella on Ruby on Rails 4 thanks to Israel Ogbole. Gentelella on Rails 5.x thanks to Michael Lang Gentelella on Smarty 3 with one time password generator, validator, and QR code generator that has no web dependencies (self-contained) in PHP thanks to MicroVB INC Gentelella integrated into Symfony 5 full stack PHP framework thanks to Mamour Wane. Gentelella on Yii framework 2 with an asset bundle, a layout template and some widgets. Gentelella on Angular 2 Angular Webpack Starter modified to utilize the Gentelella. Gentelella on Aurelia Typescript webpack skeleton modified to utilize the Gentelella. Gentelella on Laravel PHP / Laravel 5 boilerplate project with Gentelella Admin theme support. Gentelella on Django Gentelella modified to fit as a Django app Gentelella on Flask Gentelella modified to fit as a Flask app Gentelella on CakePHP 3 Gentelella modified to work on CakePHP Gentelella right to left Gentelella modified to work with right to left languages like Persian Gentelella-rtl on Yii framework 2 with an asset bundle, a layout template and some widgets. inspired from Gentelella on Yii framework 2 Gentelella by React Gentelella realized by React Let us know if you have done integration for this admin template on other platforms and frameworks and we'll be happy to share your work. Scripts included: Bootstrap Font Awesome jQuery-Autocomplete FullCalendar Charts.js Bootstrap Colorpicker Cropper dataTables Date Range Picker for Bootstrap Dropzone easyPieChart ECharts bootstrap-wysiwyg Flot - Javascript plotting library for jQuery. gauge.js iCheck jquery.inputmask plugin Ion.RangeSlider jQuery jVectorMap moment.js Morris.js - pretty time-series line graphs PNotify - Awesome JavaScript notifications NProgress Pace Parsley bootstrap-progressbar select2 Sidebar Transitions - simple off-canvas navigations Skycons - canvas based wather icons jQuery Sparklines plugin switchery - Turns HTML checkbox inputs into beautiful iOS style switches jQuery Tags Input Plugin Autosize - resizes text area to fit text validator - HTML from validator using jQuery jQuery Smart Wizard Other templates and useful resources Free Bootstrap Admin Templates - List of the best Free Bootstrap admin dashboard templates that are available for free for personal and commercial use. Free Admin Templates - Long list of the best free HTML5 powered admin dashboard templates. Available for personal and commercial use. Angular Templates - List of the most popular admin templates based on AngularJS. HTML Admin Templates - Most of these templates are based on AngularJS and uses a stunning Material design. Bootstrap Admin Templates - List of premium Bootstrap admin templates that uses a minimal flat or material design. Majority of these themes uses AngularJS but HTML5 versions are also available. WordPress Admin Templates - List of the best WordPress admin dashboard templates and plugins that will add a personal touch to your WordPress dashboard. WordPress Themes - A huge selection of the best free WordPress themes that are all licensed under GPL and are available for personal and commercial use without restrictions. License information Gentelella is licensed under The MIT License (MIT). Which means that you can use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software. But you always need to state that Colorlib is the original author of this template. Project is developed and maintained by Colorlib and Aigars Silkalns"
4083,"jQuery matchers and fixture loader for Jasmine framework!!! IMPORTANT: WE NEED A NEW MAINTAINER !!! Neither me (the original lib author) nor Travis (the current lib maintainer) can maintain this library any longer as actively as the GREAT community around it deserves. So, we're looking for a new maintainer for this lib - if you're interested, ping me on Twitter or through a comment in this GitHub issue. jasmine-jquery jasmine-jquery provides two extensions for the Jasmine JavaScript Testing Framework: a set of custom matchers for jQuery framework an API for handling HTML, CSS, and JSON fixtures in your specs Installation Choose one of the following options: Simply download jasmine-jquery.js from here and include it in your Jasmine's test runner file (or add it to jasmine.yml file if you're using Ruby with jasmine-gem). Remember to also include the jQuery library as jasmine-jquery relies on it. Using bower by running For Ruby on Rails, use this gem or I recommend complying with the standard RSpec and Jasmine frameworks dir structure and keep your tests in spec/javascripts/ dir. I put jasmine-jquery (and other libraries like jasmine-ajax) into spec/javascripts/helpers dir (so they are automatically loaded) and fixtures into spec/javascripts/fixtures dir. jQuery matchers jasmine-jquery provides the following custom matchers (in alphabetical order): toBeChecked() only for tags that have checked attribute e.g. expect($('<input type=""checkbox"" checked=""checked""/>')).toBeChecked() toBeDisabled() e.g. expect('<input type=""submit"" disabled=""disabled""/>').toBeDisabled() toBeEmpty() Checks for child DOM elements or text. toBeFocused() e.g. expect($('<input type=""text"" />').focus()).toBeFocused() toBeHidden() Elements can be considered hidden for several reasons: They have a CSS display value of none. They are form elements with type equal to hidden. Their width and height are explicitly set to 0. An ancestor element is hidden, so the element is not shown on the page. toBeInDOM() Checks to see if the matched element is attached to the DOM e.g. expect($('#id-name')[0]).toBeInDOM() toBeMatchedBy(jQuerySelector) Check to see if the set of matched elements matches the given selector e.g. expect($('<span></span>').addClass('js-something')).toBeMatchedBy('.js-something') true if the dom contains the element toBeSelected() only for tags that have selected attribute e.g. expect($('<option selected=""selected""></option>')).toBeSelected() toBeVisible() Elements are considered visible if they consume space in the document. Visible elements have a width or height that is greater than zero. toContain(string) e.g. expect($('<div><span class=""some-class""></span></div>')).toContain('some-class') toContainElement(jQuerySelector) e.g. expect($('<div><span class=""some-class""></span></div>')).toContainElement('span.some-class') toContainHtml(string) e.g. expect($('<div><ul></ul><h1>header</h1></div>')).toContainHtml('<ul></ul>') toContainText(string) e.g. expect($('<div><ul></ul><h1>header</h1></div>')).toContainText('header') toEqual(jQuerySelector) e.g. expect($('<div id=""some-id""></div>')).toEqual('div') e.g. expect($('<div id=""some-id""></div>')).toEqual('div#some-id') toExist() true if element exists in or out of the dom toHandle(eventName) e.g. expect($form).toHandle(""submit"") toHandleWith(eventName, eventHandler) e.g. expect($form).toHandleWith(""submit"", yourSubmitCallback) toHaveAttr(attributeName, attributeValue) attribute value is optional, if omitted it will check only if attribute exists toHaveBeenTriggeredOn(selector) if event has been triggered on selector (see ""Event Spies"", below) toHaveBeenTriggered() if event has been triggered on selector (see ""Event Spies"", below) toHaveBeenTriggeredOnAndWith(selector, extraParameters) if event has been triggered on selector and with extraParameters toHaveBeenPreventedOn(selector) if event has been prevented on selector (see ""Event Spies"", below) toHaveBeenPrevented() if event has been prevented on selector (see ""Event Spies"", below) toHaveClass(className) e.g. expect($('<div class=""some-class""></div>')).toHaveClass(""some-class"") toHaveCss(css) e.g. expect($('<div style=""display: none; margin: 10px;""></div>')).toHaveCss({display: ""none"", margin: ""10px""}) e.g. expect($('<div style=""display: none; margin: 10px;""></div>')).toHaveCss({margin: ""10px""}) toHaveData(key, value) value is optional, if omitted it will check only if an entry for that key exists toHaveHtml(string) e.g. expect($('<div><span></span></div>')).toHaveHtml('<span></span>') toHaveId(id) e.g. expect($('<div id=""some-id""></div>')).toHaveId(""some-id"") toHaveLength(value) e.g. expect($('ul > li')).toHaveLength(3) toHaveProp(propertyName, propertyValue) property value is optional, if omitted it will check only if property exists toHaveText(string) accepts a String or regular expression e.g. expect($('<div>some text</div>')).toHaveText('some text') toHaveValue(value) only for elements on which val can be called (input, textarea, etc) e.g. expect($('<input type=""text"" value=""some text""/>')).toHaveValue('some text') The same as with standard Jasmine matchers, all of the above custom matchers may be inverted by using .not prefix, e.g.: HTML Fixtures The Fixture module of jasmine-jquery allows you to load HTML content to be used by your tests. The overall workflow is as follows: In myfixture.html file: Inside your test: By default, fixtures are loaded from spec/javascripts/fixtures. You can configure this path: jasmine.getFixtures().fixturesPath = 'my/new/path';. Note: If you are running your test with Karma, remember that your files are served from a base/ directory, so your path should be configured to: jasmine.getFixtures().fixturesPath = 'base/my/new/path';. Your fixture is being loaded into the <div id=""jasmine-fixtures""></div> container that is automatically added to the DOM by the Fixture module (If you REALLY must change the id of this container, try: jasmine.getFixtures().containerId = 'my-new-id'; in your test runner). To make tests fully independent, fixtures container is automatically cleaned-up between tests, so you don't have to worry about left-overs from fixtures loaded in preceeding test. Also, fixtures are internally cached by the Fixture module, so you can load the same fixture file in several tests without penalty to your test suite's speed. To invoke fixture related methods, obtain Fixtures singleton through a factory and invoke a method on it: There are also global shortcut functions available for the most used methods, so the above example can be rewritten to just: Several methods for loading fixtures are provided: load(fixtureUrl[, fixtureUrl, ...]) Loads fixture(s) from one or more files and automatically appends them to the DOM (to the fixtures container). appendLoad(fixtureUrl[, fixtureUrl, ...]) Same as load, but adds the fixtures to the pre-existing fixture container. read(fixtureUrl[, fixtureUrl, ...]) Loads fixture(s) from one or more files but instead of appending them to the DOM returns them as a string (useful if you want to process fixture's content directly in your test). set(html) Doesn't load fixture from file, but instead gets it directly as a parameter (html parameter may be a string or a jQuery element, so both set('<div></div>') and set($('<div/>')) will work). Automatically appends fixture to the DOM (to the fixtures container). It is useful if your fixture is too simple to keep it in an external file or is constructed procedurally, but you still want Fixture module to automatically handle DOM insertion and clean-up between tests for you. appendSet(html) Same as set, but adds the fixtures to the pre-existing fixture container. preload(fixtureUrl[, fixtureUrl, ...]) Pre-loads fixture(s) from one or more files and stores them into cache, without returning them or appending them to the DOM. All subsequent calls to load or read methods will then get fixtures content from cache, without making any AJAX calls (unless cache is manually purged by using clearCache method). Pre-loading all fixtures before a test suite is run may be useful when working with libraries like jasmine-ajax that block or otherwise modify the inner workings of JS or jQuery AJAX calls. All of above methods have matching global shortcuts: loadFixtures(fixtureUrl[, fixtureUrl, ...]) appendLoadFixtures(fixtureUrl[, fixtureUrl, ...]) readFixtures(fixtureUrl[, fixtureUrl, ...]) setFixtures(html) appendSetFixtures(html) Also, a helper method for creating HTML elements for your tests is provided: sandbox([{attributeName: value[, attributeName: value, ...]}]) It creates an empty DIV element with a default id=""sandbox"". If a hash of attributes is provided, they will be set for this DIV tag. If a hash of attributes contains id attribute it will override the default value. Custom attributes can also be set. So e.g.: Will return: And: Will return: Sandbox method is useful if you want to quickly create simple fixtures in your tests without polluting them with HTML strings: This method also has a global shortcut available: sandbox([{attributeName: value[, attributeName: value, ...]}]) Additionally, two clean up methods are provided: clearCache() purges Fixture module internal cache (you should need it only in very special cases; typically, if you need to use it, it may indicate a smell in your test code) cleanUp() cleans-up fixtures container (this is done automatically between tests by Fixtures module, so there is no need to ever invoke this manually, unless you're testing a really fancy special case and need to clean-up fixtures in the middle of your test) These two methods do not have global shortcut functions. Style Fixtures The StyleFixtures module is pretty much like the Fixtures module, but it allows you to load CSS content on the page while testing. It may be useful if your tests expect that certain css rules are applied to elements that you are testing. The overall workflow is typically the same: In mycssfixture.css file: Inside your test: Notice that if you haven't applied the position: absolute rule to the .elem and try to test its left position in some browsers (e.g. GoogleChrome) you will allways get the value auto even if your plugin did everything correct and applied positioning. So that's why you might need to load style fixtures. In Firefox though you will get the correct value even without the position: absolute. By default, style fixtures are loaded from spec/javascripts/fixtures. You can configure this path: jasmine.getStyleFixtures().fixturesPath = 'my/new/path';. Like in Fixtures module, StyleFixtures are also automatically cleaned-up between tests and are internally cached, so you can load the same fixture file in several tests without penalty to your test suite's speed. To invoke fixture related methods, obtain StyleFixtures singleton through a factory and invoke a method on it: There are also global shortcut functions available for the most used methods, so the above example can be rewritten to just: Several methods for loading fixtures are provided: load(fixtureUrl[, fixtureUrl, ...]) Loads fixture(s) from one or more files and automatically appends them to the DOM into the HEAD element. This method will remove all existing fixtures loaded previously, if any. appendLoad(fixtureUrl[, fixtureUrl, ...]) Same as load, but it won't remove fixtures you added earlier. set(css) Doesn't load fixture from file, but instead gets it directly as a parameter (e.g. set('body {background: red}')). Automatically appends style to the DOM. It is useful if your css fixture is too simple to keep it in an external file. This method will remove all existing fixtures loaded previously, if any. appendSet(css) Same as set, but it won't remove fixtures you added earlier. preload(fixtureUrl[, fixtureUrl, ...]) Pre-loads fixture(s) from one or more files and stores them into cache, without returning them or appending them to the DOM. All subsequent calls to load methods will then get fixtures content from cache, without making any AJAX calls (unless cache is manually purged by using clearCache method). All of above methods have matching global shortcuts: loadStyleFixtures(fixtureUrl[, fixtureUrl, ...]) appendLoadStyleFixtures(fixtureUrl[, fixtureUrl, ...]) setStyleFixtures(css) appendSetStyleFixtures(css) Additionally, two clean up methods are provided: clearCache() purges StyleFixture module internal cache (you should need it only in very special cases; typically, if you need to use it, it may indicate a smell in your test code) cleanUp() cleans-up all existing style fixtures (this is done automatically between tests, so there is no need to ever invoke this manually, unless you're testing a really fancy special case and need to clean-up fixtures in the middle of your test) These two methods do not have global shortcut functions. JSON Fixtures The JSONFixtures modules allows you to load JSON data from file (instead of putting huge blocks of data in the spec files). In myjsonfixture.json file: Inside your test: By default, fixtures are loaded from spec/javascripts/fixtures/json. You can configure this path: jasmine.getJSONFixtures().fixturesPath = 'my/new/path';. Your fixture data is loaded into an object stashed by the JSONFixtures structure. You fetch the data using the filename as the key. This allows you to load multiple chunks of test data in a spec. Because a deep copy of Javascript objects can be a little tricky, this module will refetch data each time you call load. If you modify the data within a spec, you must call load or loadJSONFixtures again to repopulate the data. To invoke fixture related methods, obtain Fixtures singleton through a factory and invoke a method on it: There are also global shortcut functions available for the most used methods, so the above example can be rewritten to just: Several methods for loading fixtures are provided: load(fixtureUrl[, fixtureUrl, ...]) Loads fixture(s) from one or more files and automatically adds them to the fixture list. This method returns the entire set of fixtures keyed by their filename. All of above methods have matching global shortcuts: loadJSONFixtures(fixtureUrl[, fixtureUrl, ...]) getJSONFixture(fixtureUrl) After you've loaded fixture files, this global helper will retrieve the fixture data given the fixtureUrl Event Spies Spying on jQuery events can be done with spyOnEvent and expect(eventName).toHaveBeenTriggeredOn(selector) or expect(spyEvent).toHaveBeenTriggered() . First, spy on the event: You can reset spy events You can similarly check if triggered event was prevented: You can also check if the triggered event was stopped: Many thanks to Luiz Fernando Ribeiro for his article on Jasmine event spies. Dependencies jasmine-jquery v2.0.0+ is to be used with jasmine v2.0.0+. jasmine-jquery v1.7.0 is to be used with jasmine < v2.0.0. jasmine-jquery is tested with jQuery 2.0 on IE, FF, Chrome, and Safari. There is a high chance it will work with older versions and other browsers as well, but I don't typically run test suite against them when adding new features. Cross domain policy problems under Chrome Newer versions of Chrome don't allow file:// URIs read other file:// URIs. In effect, jasmine-jquery cannot properly load fixtures under some versions of Chrome. An override for this is to run Chrome with a switch --allow-file-access-from-files. (https://github.com/velesin/jasmine-jquery/issues/4). Quit open Chromes before running Chrome with that switch. (https://github.com/velesin/jasmine-jquery/issues/179). Under Windows 7, you have to launch C:\Users\[UserName]\AppData\Local\Google\Chrome[ SxS]\Application\chrome.exe --allow-file-access-from-files Mocking with jasmine-ajax jasmine-ajax library doesn't let user to manually start / stop XMLHttpRequest mocking, but instead it overrides XMLHttpRequest automatically when loaded. This breaks jasmine-jquery fixtures as fixture loading mechanism uses jQuery.ajax, that stops to function the very moment jasmine-ajax is loaded. A workaround for this may be to invoke jasmine-jquery preloadFixtures function (specifying all required fixtures) before jasmine-ajax is loaded. This way subsequent calls to loadFixtures or readFixtures methods will get fixtures content from cache, without need to use jQuery.ajax and thus will work correctly even after jasmine-ajax is loaded. Testing with Javascript Test Driver When using jstd and the jasmine adapter you will need to include jasmine-jquery.js after your jasmine-jstd-adapter files, otherwise jasmine-jquery matchers will not be available when tests are executed. Check out this issue for a thorough configuration example too. Maintainer Travis Jeffery: Twitter, GitHub. Contributing"
4342,"The stream database optimised for event sourcingEventStoreDB The open-source, functional database with Complex Event Processing in JavaScript. This is the repository for the open source version of EventStoreDB, which includes the clustering implementation for high availability. Support Information on support and commercial tools such as LDAP authentication can be found here: Event Store Support. CI Status Documentation Documentation is located in the docs folder. It's orchestrated in the separate documentation repository. It's available online at https://developers.eventstore.com/. Read more in the documentation contribution guidelines. Community We have a community discussion space at Event Store Discuss. If you prefer Slack, there is also an #eventstore channel in the DDD-CQRS-ES Slack community. Release Packages The latest release packages are hosted in the downloads section on the Event Store website: Event Store Downloads We also host native packages for Linux on Package Cloud and Windows packages can be installed via Chocolatey (4.0.0 onwards only). Building EventStoreDB EventStoreDB is written in a mixture of C#, C++ and JavaScript. It can run on Windows, Linux and macOS using the .NET Core runtime. However, the projections library (which uses the V8 javascript engine) contains platform specific code and it must be built for the platform on which you intend to run it. Windows / Linux / macOS Prerequisites - [.NET Core SDK 5.0] (https://dotnet.microsoft.com/download/dotnet/5.0) Build EventStoreDB Once you've installed the prerequisites for your system, you can launch a Release build of EventStore as follows: where <runtime identifier> needs to be replaced by the RID of the platform you want to build for. The build scripts: build.sh and build.ps1 are also available for Linux/macOS and Windows respectively to simplify the build process. To start a single node, you can then run: Note: The build system has changed after version 5.0.5, therefore the above instructions will not work for older releases. Running the tests You can launch the tests as follows: Building the EventStoreDB Client / Grpc Client / Embedded Client You can build the different clients by following the steps below. This will generate a nuget package file (.nupkg) that you can include in your project. Client Grpc Client Embedded Client Building the EventStoreDB web UI The web UI repository is a git submodule of the current repository located under src/EventStore.UI. The web UI is prebuilt and the files are located in src/EventStore.ClusterNode.Web/clusternode-web. However, if you still want to build the latest web UI, there is a parameter in the build.sh ([<build_ui=yes|no>]) and build.ps1 (-BuildUI) scripts to allow you to do so. Building the Projections Library The list of precompiled projections libraries can be found in src/libs/x64. If you still want to build the projections library please follow the links below. - Windows - Linux - macOS Contributing Development is done on the master branch. We attempt to do our best to ensure that the history remains clean and to do so, we generally ask contributors to squash their commits into a set or single logical commit. If you want to switch to a particular release, you can check out the tag for this particular version. For example: git checkout oss-v6.0.0-preview1 Read more in the contribution guidelines. Proto Changes If you update the protos, continuous integration will fail. After ensuring the proto change is backwards compatible, please run ./protolock.sh commit at the root of this repository."
2662,"A PHP parser written in PHPPHP Parser This is a PHP 5.2 to PHP 8.0 parser written in PHP. Its purpose is to simplify static code analysis and manipulation. Documentation for version 4.x (stable; for running on PHP >= 7.0; for parsing PHP 5.2 to PHP 8.0). Documentation for version 3.x (unsupported; for running on PHP >= 5.5; for parsing PHP 5.2 to PHP 7.2). Features The main features provided by this library are: Parsing PHP 5, PHP 7, and PHP 8 code into an abstract syntax tree (AST). Invalid code can be parsed into a partial AST. The AST contains accurate location information. Dumping the AST in human-readable form. Converting an AST back to PHP code. Experimental: Formatting can be preserved for partially changed ASTs. Infrastructure to traverse and modify ASTs. Resolution of namespaced names. Evaluation of constant expressions. Builders to simplify AST construction for code generation. Converting an AST into JSON and back. Quick Start Install the library using composer: php composer.phar require nikic/php-parser Parse some PHP code into an AST and dump the result in human-readable form: This dumps an AST looking something like this: Let's traverse the AST and perform some kind of modification. For example, drop all function bodies: This gives us an AST where the Function_::$stmts are empty: Finally, we can convert the new AST back to PHP code: This gives us our original code, minus the var_dump() call inside the function: For a more comprehensive introduction, see the documentation. Documentation Introduction Usage of basic components Component documentation: Walking the AST Node visitors Modifying the AST from a visitor Short-circuiting traversals Interleaved visitors Simple node finding API Parent and sibling references Name resolution Name resolver options Name resolution context Pretty printing Converting AST back to PHP code Customizing formatting Formatting-preserving code transformations AST builders Fluent builders for AST nodes Lexer Lexer options Token and file positions for nodes Custom attributes Error handling Column information for errors Error recovery (parsing of syntactically incorrect code) Constant expression evaluation Evaluating constant/property/etc initializers Handling errors and unsupported expressions JSON representation JSON encoding and decoding of ASTs Performance Disabling XDebug Reusing objects Garbage collection impact Frequently asked questions Parent and sibling references"
4257,"Persona is a secure, distributed, and easy to use identification system. This repository contains the core Mozilla Persona services. Persona is a login system based on the BrowserID protocol. To learn about using Persona on your site, check out our documentation on MDN. Repository Contents This repository contains several projects related to Persona: The Persona Fallback IdP: A fallback Identity Provider (IdP) for users without native support for Persona via their email provider. Written in node.js, hosted at https://login.persona.org. The Persona Remote Verification Service: A stateless node.js server which handles cryptographic verification of identity assertions. Hosted at verifier.login.persona.org, but easy to run locally. The Cross-Browser Persona Support Library: The include.js file that provides the navigator.id API for browsers without native support for Persona. This also includes the code for the dialog shown to users of those browsers. Sample and Test Code: For all of the above. Getting Started The Persona team uses Git and GitHub for all of our development and issue tracking. If you'd like to contribute code back to us, please do so using a Pull Request. If you get stuck and need help, you can find the core team on our public mailing list or in #identity on irc.mozilla.org. Install Dependencies BrowserID needs the following dependencies before it can run: node.js (>= 0.8.11) libgmp3 g++ For detailed instructions for your specific operating system, check out the SETUP docs in the docs/ folder. Running BrowserID Locally To run the BrowserID service locally: Clone the repository to your machine. Run npm install from the root of your clone. Run npm start from the root of your clone. When you run npm start, it will print several URLs to your terminal. You can test that everything is working by visiting the URL for the example (RP) site. Look for a line like this in the terminal: example (10361): running on http://127.0.0.1:10001 You can stop the services by typing Control-C in the terminal. Staying Up to Date To stay up to date with BrowserID: Use git pull to retrieve new changes. Delete both the var and node_modules folders in the root of your local clone. Run npm install from the root of your local clone. Testing Local testing: Unit tests can be run by invoking npm test at the top level. At present, there are three classes of unit tests to be run: Backend unit tests against a custom, zero-dependency JSON database. Backend unit tests against MySQL, what we use in production. Frontend unit tests run headlessly against PhantomJS. You can control which tests are run using the WHAT_TESTS env var, see scripts/test for details. Continuous Integration Testing: Integration tests are done with Travis-CI. It is recommended that you setup Travis-CI for your BrowserID fork so that tests are automatically run when you push changes. This will give the BrowserID team confidence that your changes both function correctly and do not cause regressions in other parts of the code. Configuration files are already included in the repo but some setup is necessary. Sign in to GitHub Open Travis-CI Click ""Sign in with GitHub"" if you are not signed in. If you are signed in, click on your username then ""Profile"" and go to step 5. Click ""Allow"" if this is your first time signing in. Find ""browserid"" in ""Your Repositories"" Move the switch from ""OFF"" to ""ON"" Open your fork of BrowserID on GitHub Click the ""Settings"" button Click ""Service Hooks"" and find the ""Travis"" Service Hook Paste in your ""Token"" which you can find it on your Travis-CI Profile. Ensure that ""Travis"" has a green radio button Push to your fork and return to Travis-CI. Watch the tests run. LICENSE All source code here is available under the MPL 2.0 license, unless otherwise indicated."
1049,"A distribution of Nginx with some advanced featuresIntroduction Tengine is a web server originated by Taobao, the largest e-commerce website in Asia. It is based on the Nginx HTTP server and has many advanced features. Tengine has proven to be very stable and efficient on some of the top 100 websites in the world, including taobao.com and tmall.com. Tengine has been an open source project since December 2011. It is being actively developed by the Tengine team, whose core members are from Taobao, Sogou and other Internet companies. Tengine is a community effort and everyone is encouraged to get involved. Features All features of nginx-1.18.0 are inherited, i.e., it is 100% compatible with nginx. Support the CONNECT HTTP method for forward proxy. Support asynchronous OpenSSL, using hardware such as QAT for HTTPS acceleration. Enhanced operations monitoring, such as asynchronous log & rollback, DNS caching, memory usage, etc. Support server_name in Stream module. More load balancing methods, e.g., consistent hashing, and session persistence. Input body filter support. It's quite handy to write Web Application Firewalls using this mechanism. Dynamic scripting language (Lua) support, which is very efficient and makes it easy to extend core functionalities. Limits retries for upstream servers (proxy, memcached, fastcgi, scgi, uwsgi). Includes a mechanism to support standalone processes. Protects the server in case system load or memory use goes too high. Multiple CSS or JavaScript requests can be combined into one request to reduce download time. Removes unnecessary white spaces and comments to reduce the size of a page. Proactive health checks of upstream servers can be performed. The number of worker processes and CPU affinities can be set automatically. The limit_req module is enhanced with whitelist support and more conditions are allowed in a single location. Enhanced diagnostic information makes it easier to troubleshoot errors. More user-friendly command lines, e.g., showing all compiled-in modules and supported directives. Expiration times can be specified for certain MIME types. Error pages can be reset to 'default'. ... Installation Tengine can be downloaded at http://tengine.taobao.org/download/tengine.tar.gz. You can also checkout the latest source code from GitHub at https://github.com/alibaba/tengine To install Tengine, just follow these three steps: $ ./configure $ make # make install By default, it will be installed to /usr/local/nginx. You can use the '--prefix' option to specify the root directory. If you want to know all the 'configure' options, you should run './configure --help' for help. Documentation The homepage of Tengine is at http://tengine.taobao.org/ You can access http://tengine.taobao.org/documentation.html for more information. Contact https://github.com/alibaba/tengine/issues Dingtalk user group: 23394285"
4327,"Statsmodels: statistical modeling and econometrics in Python|PyPI Version| |Conda Version| |License| |Azure CI Build Status| |Codecov Coverage| |Coveralls Coverage| |PyPI downloads| |Conda downloads| About statsmodels statsmodels is a Python package that provides a complement to scipy for statistical computations including descriptive statistics and estimation and inference for statistical models. Documentation The documentation for the latest release is at https://www.statsmodels.org/stable/ The documentation for the development version is at https://www.statsmodels.org/dev/ Recent improvements are highlighted in the release notes https://www.statsmodels.org/stable/release/ Backups of documentation are available at https://statsmodels.github.io/stable/ and https://statsmodels.github.io/dev/. Main Features Linear regression models: Ordinary least squares Generalized least squares Weighted least squares Least squares with autoregressive errors Quantile regression Recursive least squares Mixed Linear Model with mixed effects and variance components GLM: Generalized linear models with support for all of the one-parameter exponential family distributions Bayesian Mixed GLM for Binomial and Poisson GEE: Generalized Estimating Equations for one-way clustered or longitudinal data Discrete models: Logit and Probit Multinomial logit (MNLogit) Poisson and Generalized Poisson regression Negative Binomial regression Zero-Inflated Count models RLM: Robust linear models with support for several M-estimators. Time Series Analysis: models for time series analysis Complete StateSpace modeling framework Seasonal ARIMA and ARIMAX models VARMA and VARMAX models Dynamic Factor models Unobserved Component models Markov switching models (MSAR), also known as Hidden Markov Models (HMM) Univariate time series analysis: AR, ARIMA Vector autoregressive models, VAR and structural VAR Vector error correction model, VECM exponential smoothing, Holt-Winters Hypothesis tests for time series: unit root, cointegration and others Descriptive statistics and process models for time series analysis Survival analysis: Proportional hazards regression (Cox models) Survivor function estimation (Kaplan-Meier) Cumulative incidence function estimation Multivariate: Principal Component Analysis with missing data Factor Analysis with rotation MANOVA Canonical Correlation Nonparametric statistics: Univariate and multivariate kernel density estimators Datasets: Datasets used for examples and in testing Statistics: a wide range of statistical tests diagnostics and specification tests goodness-of-fit and normality tests functions for multiple testing various additional statistical tests Imputation with MICE, regression on order statistic and Gaussian imputation Mediation analysis Graphics includes plot functions for visual analysis of data and model results I/O Tools for reading Stata .dta files, but pandas has a more recent version Table output to ascii, latex, and html Miscellaneous models Sandbox: statsmodels contains a sandbox folder with code in various stages of development and testing which is not considered ""production ready"". This covers among others Generalized method of moments (GMM) estimators Kernel regression Various extensions to scipy.stats.distributions Panel data models Information theoretic measures How to get it The main branch on GitHub is the most up to date code https://www.github.com/statsmodels/statsmodels Source download of release tags are available on GitHub https://github.com/statsmodels/statsmodels/tags Binaries and source distributions are available from PyPi https://pypi.org/project/statsmodels/ Binaries can be installed in Anaconda conda install statsmodels Installing from sources See INSTALL.txt for requirements or see the documentation https://statsmodels.github.io/dev/install.html Contributing Contributions in any form are welcome, including: Documentation improvements Additional tests New features to existing models New models https://www.statsmodels.org/stable/dev/test_notes for instructions on installing statsmodels in editable mode. License Modified BSD (3-clause) Discussion and Development Discussions take place on the mailing list https://groups.google.com/group/pystatsmodels and in the issue tracker. We are very interested in feedback about usability and suggestions for improvements. Bug Reports Bug reports can be submitted to the issue tracker at https://github.com/statsmodels/statsmodels/issues .. |Azure CI Build Status| image:: https://dev.azure.com/statsmodels/statsmodels-testing/_apis/build/status/statsmodels.statsmodels?branchName=main :target: https://dev.azure.com/statsmodels/statsmodels-testing/_build/latest?definitionId=1&branchName=main .. |Codecov Coverage| image:: https://codecov.io/gh/statsmodels/statsmodels/branch/main/graph/badge.svg :target: https://codecov.io/gh/statsmodels/statsmodels .. |Coveralls Coverage| image:: https://coveralls.io/repos/github/statsmodels/statsmodels/badge.svg?branch=main :target: https://coveralls.io/github/statsmodels/statsmodels?branch=main .. |PyPI downloads| image:: https://img.shields.io/pypi/dm/statsmodels?label=PyPI%20Downloads :alt: PyPI - Downloads :target: https://pypi.org/project/statsmodels/ .. |Conda downloads| image:: https://img.shields.io/conda/dn/conda-forge/statsmodels.svg?label=Conda%20downloads :target: https://anaconda.org/conda-forge/statsmodels/ .. |PyPI Version| image:: https://img.shields.io/pypi/v/statsmodels.svg :target: https://pypi.org/project/statsmodels/ .. |Conda Version| image:: https://anaconda.org/conda-forge/statsmodels/badges/version.svg :target: https://anaconda.org/conda-forge/statsmodels/ .. |License| image:: https://img.shields.io/pypi/l/statsmodels.svg :target: https://github.com/statsmodels/statsmodels/blob/main/LICENSE.txt"
290,"Server-side Swift. The Perfect core toolset and framework for Swift Developers. (For mobile back-end development, website and API development, and more)Perfect: Server-Side Swift Perfect: Server-Side Swift Perfect is a complete and powerful toolbox, framework, and application server for Linux, iOS, and macOS (OS X). It provides everything a Swift engineer needs for developing lightweight, maintainable, and scalable apps and other REST services entirely in the Swift programming language for both client-facing and server-side applications. Perfect includes a suite of tools that will enhance your productivity as you use only one programming language to build your apps: Swift. The global development communitys most dynamic and popular server-side toolbox and framework available today, Perfect is the backbone for many live web applications and apps available on iTunes. This guide is designed for developers at all levels of experience to get Perfect up and running quickly. Working with Perfect Compatibility with Swift The master branch of this project currently compiles with Xcode 11 or the Swift 5 toolchain on Ubuntu. Getting Started Access a tutorial to help you get started using Perfect quickly. It includes straightforward examples of how Perfect can be used. Documentation Get started working with Perfect, deploy your apps, and find more detailed help by consulting our reference library. We welcome contributions to Perfects documentation. If you spot a typo, bug, or other errata, or have additions or suggestions to recommend, please create a pull request or issue in Github. Community We all need a little help now and then. If you do too, dont be shy, ask us or the friendly and supportive Perfect community: Slack | Twitter Deployment Your Perfect project can be deployed to any Swift compatible Linux server. We provide a macOS desktop application, Perfect Assistant, to help with AWS and Google Cloud deployments. Additional deployment options are in the works. Samples, Examples, and Tutorials Our library continues to grow as members of the Swift-Perfect development community have shared many samples and examples of their projects in Perfect. Examples include: WebSockets Server URL Routing Upload Enumerator There are many more examples you can explore. Please share yours! Core Perfect Modules Perfect project is divided into several repositories to make it easy for you to find, download, and install the components you need: Perfect This repository contains the core PerfectLib and will continue to be the main landing point for the project Perfect Docs Contains all API reference-related material Examples Perfect Template- A simple starter project which compiles with the Swift Package Manager into a standalone executable HTTP server. This repository is ideal for starting a Perfect-based project Perfect Examples- All the Perfect example projects DataSources Perfect Redis- The Redis database connector Perfect SQLite- SQLite3 database connector Perfect PostgreSQL- PostgreSQL database connector Perfect MySQL- MySQL database connector Perfect MongoDB- MongoDB database connector Perfect FileMaker - FileMaker Server database connector Utilities Perfect FastCGI Apache 2.4- Apache 2.4 FastCGI module; required for the Perfect FastCGI server variant Perfect XML - DOM Core level 2 read-only APIs and XPath support Perfect HTTP Server - HTTP 1.1 server for Perfect Perfect Mustache - Mustache template support for Perfect Perfect CURL - cURL support for Perfect Perfect WebSockets - WebSockets support for Perfect Perfect Zip - provides simple zip and unzip functionality Perfect Notifications - provides support for Apple Push Notification Service (APNS). More about Perfect Perfect operates using either a standalone HTTP server, HTTPS server, or through FastCGI server. It provides a system for loading your Swift-based modules at startup, for interfacing those modules with its request/response objects, or to the built-in Mustache template processing system. Perfect is built on a completely asynchronous, high-performance networking engine to provide a scalable option for internet services. It supports Secure Sockets Layer (SSL) encryption, and it features a suite of tools commonly required by internet servers such as WebSockets and iOS push notifications, but you are not limited to those options. Feel free to use your favourite JSON or templating systems, etc. Join and Contribute to the Community The Swift-Perfect developer community is vital to improving Perfect and supporting one another. You can help other developers by sharing your expertise and tips, as well as learn from others, by joining the Perfect Slack channel. Contributions of all kinds are welcome: reporting issues, updating documentation, fixing bugs, building examples, sharing projects, and any other tips that may help the Swift-Perfect community. If you would like to share your example project, tutorial, or video, please share the URL of your work on GitHub and Twitter, and the Perfect team will highlight it to the community. Code of Conduct The Perfect team welcomes people of all ethnicities, nationalities, ages, gender, disability, levels of experience, and religious beliefs to use and contribute to the Perfect project. We pledge to foster and enforce a harassment-free environment of openness, respect, and cooperation for everyone in all project and public spaces online or offline. Please report any behaviour that violates our Code of Conduct to info@perfect.org. The Perfect team is committed to enforcing this Code of Conduct to ensure everyone who wishes to use, contribute to, and comment on the Perfect project may do so freely and openly and without fear of reprisal. We will investigate all complaints of unacceptable or abusive behaviour or comments expediently, and we will maintain the confidentiality of the person who reports any perceived infraction or wrongdoing to us. We will not tolerate any form of direct or indirect harassment or discrimination within the Swift-Perfect community, and will take appropriate, fair, and corrective action to any instance of inappropriate behaviour. The Perfect team maintains the right to remove, edit, or reject any comments, code, edits, or issues that do not align with our Code of Conduct."
1952,"A shell console with GUI featuresXiki expands your command line Xiki makes the command line friendlier and more powerful. Xiki Shell (xsh) lets you use Xiki from command line, in a way that augments your current favorite shell (bash or zsh). $ xsh Install One-line installer If you want a one-line installer, this should do the trick. Copy and paste it into your shell console. curl -L https://xiki.com/install_xsh -o ~/install_xsh; bash ~/install_xsh It will walk you through a couple setup steps. Manual install You can download Xiki from: https://github.com/trogdoro/xiki/archive/master.tar.gz. Extract it into your home dir, or some other dir where you keep projects or downloaded things. Then, to run (and optionally install xsh) just execute the 'xsh' command, located in the 'bin' dir: $ ./install Git Install Or, if you have git, you can get Xiki from github via ""git clone https://github.com/trogdoro/xiki.git"". Then run ""./install"" from inside the dir. Tutorial Try typing ""xsh --tutorial"", or ""xsh --help"" on the command line. Or, get help from a human: Getting in touch Tweet to @xiki: http://twitter.com/xiki Join the google group for help with installing: http://groups.google.com/group/xiki Or, jump into the xiki chat room to chat about Xiki! Use this link to jump right in, or use your own irc client to join: http://webchat.freenode.net/?channels=xiki Troubleshooting If you run into trouble, try running ""bin/xsh --d"", which may give better error messages. Also, not that there's a cached ""xsh forker"" process that stays alive to speed up execution. Try ""ps aux|grep forker"" to find it. During trouble-shooting you may need to kill it. Supported platforms Supported platforms: MacOS and Linux. Pair with me if you want to see Windows support, support for your text editor, or just to hack on Xiki! (find me at twitter.com/xiki)."
896,"Dapper - a simple object mapper for .NetDapper - a simple object mapper for .Net Release Notes Located at dapperlib.github.io/Dapper Packages MyGet Pre-release feed: https://www.myget.org/gallery/dapper | Package | NuGet Stable | NuGet Pre-release | Downloads | MyGet | | ------- | ------------ | ----------------- | --------- | ----- | | Dapper | | | | | | Dapper.EntityFramework | | | | | | Dapper.EntityFramework.StrongName | | | | | | Dapper.Rainbow | | | | | | Dapper.SqlBuilder | | | | | | Dapper.StrongName | | | | | Features Dapper is a NuGet library that you can add in to your project that will extend your IDbConnection interface. It provides 3 helpers: Execute a query and map the results to a strongly typed List Example usage: Execute a query and map it to a list of dynamic objects This method will execute SQL and return a dynamic list. Example usage: Execute a Command that returns no results Example usage: Execute a Command multiple times The same signature also allows you to conveniently and efficiently execute a command multiple times (for example to bulk-load data) Example usage: This works for any parameter that implements IEnumerable for some T. Performance A key feature of Dapper is performance. The following metrics show how long it takes to execute a SELECT statement against a DB (in various config, each labeled) and map the data returned to objects. The benchmarks can be found in Dapper.Tests.Performance (contributions welcome!) and can be run via: Output from the latest run is: | ORM | Method | Return | Mean | StdDev | Error | Gen 0 | Gen 1 | Gen 2 | Allocated | |--------------- |------------------------------ |-------- |----------:|----------:|----------:|--------:|-------:|-------:|----------:| | Belgrade | ExecuteReader | Post | 94.46 s | 8.115 s | 12.268 s | 1.7500 | 0.5000 | - | 8.42 KB | | Hand Coded | DataTable | dynamic | 105.43 s | 0.998 s | 1.508 s | 3.0000 | - | - | 9.37 KB | | Hand Coded | SqlCommand | Post | 106.58 s | 1.191 s | 1.801 s | 1.5000 | 0.7500 | 0.1250 | 7.42 KB | | Dapper | QueryFirstOrDefault<dynamic> | dynamic | 119.52 s | 1.320 s | 2.219 s | 3.6250 | - | - | 11.39 KB | | Dapper | 'Query<dynamic> (buffered)' | dynamic | 119.93 s | 1.943 s | 2.937 s | 2.3750 | 1.0000 | 0.2500 | 11.73 KB | | Massive | 'Query (dynamic)' | dynamic | 120.31 s | 1.340 s | 2.252 s | 2.2500 | 1.0000 | 0.1250 | 12.07 KB | | Dapper | QueryFirstOrDefault<T> | Post | 121.57 s | 1.564 s | 2.364 s | 1.7500 | 0.7500 | - | 11.35 KB | | Dapper | 'Query<T> (buffered)' | Post | 121.67 s | 2.913 s | 4.403 s | 1.8750 | 0.8750 | - | 11.65 KB | | PetaPoco | 'Fetch<T> (Fast)' | Post | 124.91 s | 4.015 s | 6.747 s | 2.0000 | 1.0000 | - | 11.5 KB | | Mighty | Query<T> | Post | 125.23 s | 2.932 s | 4.433 s | 2.2500 | 1.0000 | - | 12.6 KB | | LINQ to DB | Query<T> | Post | 125.76 s | 2.038 s | 3.081 s | 2.2500 | 0.7500 | 0.2500 | 10.62 KB | | PetaPoco | Fetch<T> | Post | 127.48 s | 4.283 s | 6.475 s | 2.0000 | 1.0000 | - | 12.18 KB | | LINQ to DB | 'First (Compiled)' | Post | 128.89 s | 2.627 s | 3.971 s | 2.5000 | 0.7500 | - | 10.92 KB | | Mighty | Query<dynamic> | dynamic | 129.20 s | 2.577 s | 3.896 s | 2.0000 | 1.0000 | - | 12.43 KB | | Mighty | SingleFromQuery<T> | Post | 129.41 s | 2.094 s | 3.166 s | 2.2500 | 1.0000 | - | 12.6 KB | | Mighty | SingleFromQuery<dynamic> | dynamic | 130.59 s | 2.432 s | 3.677 s | 2.0000 | 1.0000 | - | 12.43 KB | | Dapper | 'Contrib Get<T>' | Post | 134.74 s | 1.816 s | 2.746 s | 2.5000 | 1.0000 | 0.2500 | 12.29 KB | | ServiceStack | SingleById<T> | Post | 135.01 s | 1.213 s | 2.320 s | 3.0000 | 1.0000 | 0.2500 | 15.27 KB | | LINQ to DB | First | Post | 151.87 s | 3.826 s | 5.784 s | 3.0000 | 1.0000 | 0.2500 | 13.97 KB | | EF 6 | SqlQuery | Post | 171.00 s | 1.460 s | 2.791 s | 3.7500 | 1.0000 | - | 23.67 KB | | DevExpress.XPO | GetObjectByKey<T> | Post | 172.36 s | 3.758 s | 5.681 s | 5.5000 | 1.2500 | - | 29.06 KB | | Dapper | 'Query<T> (unbuffered)' | Post | 174.40 s | 3.296 s | 4.983 s | 2.0000 | 1.0000 | - | 11.77 KB | | Dapper | 'Query<dynamic> (unbuffered)' | dynamic | 174.45 s | 1.988 s | 3.340 s | 2.0000 | 1.0000 | - | 11.81 KB | | DevExpress.XPO | FindObject<T> | Post | 181.76 s | 5.554 s | 9.333 s | 8.0000 | - | - | 27.15 KB | | DevExpress.XPO | Query<T> | Post | 189.81 s | 4.187 s | 8.004 s | 10.0000 | - | - | 31.61 KB | | EF Core | 'First (Compiled)' | Post | 199.72 s | 3.983 s | 7.616 s | 4.5000 | - | - | 13.8 KB | | NHibernate | Get<T> | Post | 248.71 s | 6.604 s | 11.098 s | 5.0000 | 1.0000 | - | 29.79 KB | | EF Core | First | Post | 253.20 s | 3.033 s | 5.097 s | 5.5000 | - | - | 17.7 KB | | NHibernate | HQL | Post | 258.70 s | 11.716 s | 17.712 s | 5.0000 | 1.0000 | - | 32.1 KB | | EF Core | SqlQuery | Post | 268.89 s | 19.349 s | 32.516 s | 6.0000 | - | - | 18.5 KB | | EF 6 | First | Post | 278.46 s | 12.094 s | 18.284 s | 13.5000 | - | - | 44.18 KB | | EF Core | 'First (No Tracking)' | Post | 280.88 s | 8.192 s | 13.765 s | 3.0000 | 0.5000 | - | 19.38 KB | | NHibernate | Criteria | Post | 304.90 s | 2.232 s | 4.267 s | 11.0000 | 1.0000 | - | 60.29 KB | | EF 6 | 'First (No Tracking)' | Post | 316.55 s | 7.667 s | 11.592 s | 8.5000 | 1.0000 | - | 50.95 KB | | NHibernate | SQL | Post | 335.41 s | 3.111 s | 4.703 s | 19.0000 | 1.0000 | - | 78.86 KB | | NHibernate | LINQ | Post | 807.79 s | 27.207 s | 45.719 s | 8.0000 | 2.0000 | - | 53.65 KB | Feel free to submit patches that include other ORMs - when running benchmarks, be sure to compile in Release and not attach a debugger (Ctrl+F5). Alternatively, you might prefer Frans Bouma's RawDataAccessBencher test suite or OrmBenchmark. Parameterized queries Parameters are passed in as anonymous classes. This allow you to name your parameters easily and gives you the ability to simply cut-and-paste SQL snippets and run them in your db platform's Query analyzer. List Support Dapper allows you to pass in IEnumerable<int> and will automatically parameterize your query. For example: Will be translated to: Literal replacements Dapper supports literal replacements for bool and numeric types. The literal replacement is not sent as a parameter; this allows better plans and filtered index usage but should usually be used sparingly and after testing. This feature is particularly useful when the value being injected is actually a fixed value (for example, a fixed ""category id"", ""status code"" or ""region"" that is specific to the query). For live data where you are considering literals, you might also want to consider and test provider-specific query hints like OPTIMIZE FOR UNKNOWN with regular parameters. Buffered vs Unbuffered readers Dapper's default behavior is to execute your SQL and buffer the entire reader on return. This is ideal in most cases as it minimizes shared locks in the db and cuts down on db network time. However when executing huge queries you may need to minimize memory footprint and only load objects as needed. To do so pass, buffered: false into the Query method. Multi Mapping Dapper allows you to map a single row to multiple objects. This is a key feature if you want to avoid extraneous querying and eager load associations. Example: Consider 2 classes: Post and User Now let us say that we want to map a query that joins both the posts and the users table. Until now if we needed to combine the result of 2 queries, we'd need a new object to express it but it makes more sense in this case to put the User object inside the Post object. This is the use case for multi mapping. You tell dapper that the query returns a Post and a User object and then give it a function describing what you want to do with each of the rows containing both a Post and a User object. In our case, we want to take the user object and put it inside the post object. So we write the function: The 3 type arguments to the Query method specify what objects dapper should use to deserialize the row and what is going to be returned. We're going to interpret both rows as a combination of Post and User and we're returning back a Post object. Hence the type declaration becomes Everything put together, looks like this: Dapper is able to split the returned row by making an assumption that your Id columns are named Id or id. If your primary key is different or you would like to split the row at a point other than Id, use the optional splitOn parameter. Multiple Results Dapper allows you to process multiple result grids in a single query. Example: Stored Procedures Dapper fully supports stored procs: If you want something more fancy, you can do: Ansi Strings and varchar Dapper supports varchar params, if you are executing a where clause on a varchar column using a param be sure to pass it in this way: On SQL Server it is crucial to use the unicode when querying unicode and ANSI when querying non unicode. Type Switching Per Row Usually you'll want to treat all rows from a given table as the same data type. However, there are some circumstances where it's useful to be able to parse different rows as different data types. This is where IDataReader.GetRowParser comes in handy. Imagine you have a database table named ""Shapes"" with the columns: Id, Type, and Data, and you want to parse its rows into Circle, Square, or Triangle objects based on the value of the Type column. User Defined Variables in MySQL In order to use Non-parameter SQL variables with MySql Connector, you have to add the following option to your connection string: Allow User Variables=True Make sure you don't provide Dapper with a property to map. Limitations and caveats Dapper caches information about every query it runs, this allows it to materialize objects quickly and process parameters quickly. The current implementation caches this information in a ConcurrentDictionary object. Statements that are only used once are routinely flushed from this cache. Still, if you are generating SQL strings on the fly without using parameters it is possible you may hit memory issues. Dapper's simplicity means that many feature that ORMs ship with are stripped out. It worries about the 95% scenario, and gives you the tools you need most of the time. It doesn't attempt to solve every problem. Will Dapper work with my DB provider? Dapper has no DB specific implementation details, it works across all .NET ADO providers including SQLite, SQL CE, Firebird, Oracle, MySQL, PostgreSQL and SQL Server. Do you have a comprehensive list of examples? Dapper has a comprehensive test suite in the test project. Who is using this? Dapper is in production use at Stack Overflow."
157,"How to Make a Computer Operating System in C++How to Make a Computer Operating System Online book about how to write a computer operating system in C/C++ from scratch. Caution: This repository is a remake of my old course. It was written several years ago as one of my first projects when I was in High School, I'm still refactoring some parts. The original course was in French and I'm not an English native. I'm going to continue and improve this course in my free-time. Book: An online version is available at http://samypesse.gitbooks.io/how-to-create-an-operating-system/ (PDF, Mobi and ePub). It was generated using GitBook. Source Code: All the system source code will be stored in the src directory. Each step will contain links to the different related files. Contributions: This course is open to contributions, feel free to signal errors with issues or directly correct the errors with pull-requests. Questions: Feel free to ask any questions by adding issues or commenting sections. You can follow me on Twitter @SamyPesse or GitHub. What kind of OS are we building? The goal is to build a very simple UNIX-based operating system in C++, not just a ""proof-of-concept"". The OS should be able to boot, start a userland shell, and be extensible."
1504,"enjoy live editing (+markdown)Pen Editor LIVE DEMO: http://sofish.github.io/pen Markdown is supported Build status: 0. source code You can clone the source code from github, or using bower. 1. installation 1.1 init with id attribute 1.2 init with an element 1.3 init with options 2. configure The following object sets up the default settings of Pen: If you want to customize the toolbar to fit your own project, you can instanciate Pen constructor with an options object like #1.3: init with options: 2.1 Fallback for old browser You can set defaults.textarea to a piece of HTML string, by default, it's <textarea name=""content""></textarea>This will be set as innerHTML of your #editor. 2.2 Change the editor class Pen will add .pen to your editor by default, if you want to change the class, make sure to replace the class name pen to your own in src/pen.css. 2.3 Enable debug mode If options.debug is set to true, Pen will output logs to the Console of your browser. 2.4 Customize the toolbar You can set options.list to an Array, add the following strings to make your own: blockquote, h2, h3, p, pre: create a tag as its literal meaning insertorderedlist: create an ol>li list insertunorderedlist: create a ul>li list indent: indent list / blockquote block outdent: outdent list / blockquote block bold: wrap the text selection in a b tag italic: wrap the text selection in an i tag underline: wrap the text selection in a u tag createlink: insert link to the text selection inserthorizontalrule: insert a hr tag insertimage: insert an image (img) tag 2.5 Add tooltips to the toolbar icons You can set options.titles to an object with properties that match the toolbar actions. The value of each property will be used as the title attribute on the icon. Most browsers will display the title attribute as a tooltip when the mouse hovers over the icon. If you are using Bootstrap or jQueryUI, you can standardize the tooltip style by adding $('i.pen-icon').tooltip() to your JavaScript. 2.6 Prevent unsafe page redirect By default, Pen will prevent unsafe page redirect when editing, to shut down it, specific options.stay to false. NOTE: if defaults.debug is set to true and default.stay is not set: defaults.stay == !defaults.debug. 2.7 Disable and Re-enable editor You can disable the pen editor by call destroy() method of the var pen = new Pen(options) object. like: And, there's a corresponding method called rebuild() to re-enable the editor: 2.8 Export content as markdown It's an experimental feature 3. markdown syntax support 3.1 install The syntax convertor will be enabled automatically by linking markdown.js after `pen.js: 3.2 usage To use it, you can type action cmd + space key at a line start. like: The following cmds are allowed: Headings: type 1~6 # at the line start Unordered List: type - or * Ordered List: type 1. Code block: type ``` Block Quote: type > Horizontal Rule: more than 3 -, *, . will create a <hr />, like ...... 4. license Licensed under MIT. 5. trusted by *"
2533,"Integrated set of Django applications addressing authentication, registration, account management as well as 3rd party (social) account authentication.========================== Welcome to django-allauth! ========================== .. image:: https://travis-ci.org/pennersr/django-allauth.svg :target: http://travis-ci.org/pennersr/django-allauth .. image:: https://img.shields.io/pypi/v/django-allauth.svg :target: https://pypi.python.org/pypi/django-allauth .. image:: https://coveralls.io/repos/pennersr/django-allauth/badge.svg?branch=master :alt: Coverage Status :target: https://coveralls.io/r/pennersr/django-allauth .. image:: https://pennersr.github.io/img/bitcoin-badge.svg :target: https://blockchain.info/address/1AJXuBMPHkaDCNX2rwAy34bGgs7hmrePEr .. image:: https://img.shields.io/badge/code%20style-pep8-green.svg :target: https://www.python.org/dev/peps/pep-0008/ .. image:: https://img.shields.io/badge/code_style-standard-brightgreen.svg :target: http://standardjs.com .. image:: https://pennersr.github.io/img/emacs-badge.svg :target: https://www.gnu.org/software/emacs/ Integrated set of Django applications addressing authentication, registration, account management as well as 3rd party (social) account authentication. Home page http://www.intenct.nl/projects/django-allauth/ Source code http://github.com/pennersr/django-allauth Mailing list http://groups.google.com/group/django-allauth Documentation https://django-allauth.readthedocs.io/en/latest/ Stack Overflow http://stackoverflow.com/questions/tagged/django-allauth Rationale Most existing Django apps that address the problem of social authentication focus on just that. You typically need to integrate another app in order to support authentication via a local account. This approach separates the worlds of local and social authentication. However, there are common scenarios to be dealt with in both worlds. For example, an e-mail address passed along by an OpenID provider is not guaranteed to be verified. So, before hooking an OpenID account up to a local account the e-mail address must be verified. So, e-mail verification needs to be present in both worlds. Integrating both worlds is quite a tedious process. It is definitely not a matter of simply adding one social authentication app, and one local account registration app to your INSTALLED_APPS list. This is the reason this project got started -- to offer a fully integrated authentication app that allows for both local and social authentication, with flows that just work. Commercial Support This project is sponsored by IntenCT_. If you require assistance on your project(s), please contact us: info@intenct.nl. .. _IntenCT: http://www.intenct.info Cross-Selling If you like this, you may also like: django-trackstats: https://github.com/pennersr/django-trackstats netwell: https://github.com/pennersr/netwell"
1433,"A running-jumping-swordfighting game I made on the Apple II from 1985-89Prince of Persia Apple II Some background: This archive contains the source code for the original Prince of Persia game that I wrote on the Apple II, in 6502 assembly language, between 1985-89. The game was first released by Broderbund Software in 1989, and is part of the ongoing Ubisoft game franchise. For a capsule summary of Prince of Persia's 25-year history, and my involvement with its various incarnations, see jordanmechner.com/prince-of-persia and jordanmechner.com/bio. For those interested in a fuller understanding of the context -- creative, business, personal, and technical -- in which this source code was created, I've published my dev journals from that period as a print book, ebook, and in blog form. Take your pick at jordanmechner.com/ebook. For those who'd like to dig into the source code itself, I've posted an explanatory technical document at jordanmechner.com/downloads/popsource which should help. This is a package I put together in October 1989 for the benefit of the teams that were undertaking the ports of POP to various platforms such as PC, Amiga, Sega, Genesis, etc. Beyond that, please don't ask me to explain anything about the source code, because I don't remember! I hung up my 6502 programming guns in October 1989, and after two decades working primarily as a writer, game designer, and creative director, to say my coding skills are rusty would be an understatement. Thanks to Jason Scott and Tony Diaz for successfully extracting the source code from a 22-year-old 3.5"" floppy disk archive, a task that took most of a long day and night, and would have taken much longer if not for Tony's incredible expertise, perseverence, and well-maintained collection of vintage Apple hardware. We extracted and posted the 6502 code because it was a piece of computer history that could be of interest to others, and because if we hadn't, it might have been lost for all time. We did this for fun, not profit. As the author and copyright holder of this source code, I personally have no problem with anyone studying it, modifying it, attempting to run it, etc. Please understand that this does NOT constitute a grant of rights of any kind in Prince of Persia, which is an ongoing Ubisoft game franchise. Ubisoft alone has the right to make and distribute Prince of Persia games. That's about all I know. If additional information becomes available, I'll post and/or tweet about it (@jmechner). In the meantime, if you have questions -- technical, legal, or otherwise -- I recommend that you direct them to the community at large, whose collective knowledge and expertise far exceeds mine, and will only increase as more people get their eyes on this code. As for me, it's time to get back to my day job of making new games and making up stories. Have fun! -- Jordan Mechner"
1187,"CSS3 Animations with special effects:tophat: magic CSS3 Animations with special effects. ( 3.1 kB gzip) Demo Checkout the demo for the animations here Table of Contents Installation Getting Started Usage with JavaScript Usage with jQuery HTML & CSS tips :tada: Gulp and SCSS (SASS) compiling :white_check_mark: Browser Support Installation GitHub Package Registry - Package url NPM - Package url YARN - Package url Getting Started Include the file magic.css or include the minified version magic.min.css or Usage with JavaScript This is a sample code for on hover effect with JavaScript. First, Include the class magictime and then a desired animation class. If you want to load the animation after certain time, you can use this example: If you want to load the animation after certain time but with an infinite loop, you can use this example: Usage with jQuery This is a sample code for on hover effect with jQuery. First, Include the class magictime and then the desired animation class. If you want to load the animation after certain time, you can use this example: If you want to load the animation after certain time but with infinite loop, you can use this example: HTML & CSS tips You can change the time of the animation by setting the class magictime for example: Default CSS timing is: If you want to assign the timing to a specific animation, you can use the following code (use 2 class): Animation Classes | MAGIC EFFECTS | BLING | STATIC EFFECTS | STATIC EFFECTS OUT | PERSPECTIVE | ROTATE | |---------------|-----------|---------------------|--------------------|------------------------|-------------| | magic | puffIn | openDownLeft | openDownLeftOut | perspectiveDown | rotateDown | | twisterInDown | puffOut | openDownRight | openDownRightOut | perspectiveUp | rotateUp | | twisterInUp | vanishIn | openUpLeft | openUpLeftOut | perspectiveLeft | rotateLeft | | swap | vanishOut | openUpRight | openUpRightOut | perspectiveRight | rotateRight | | | | openDownLeftReturn | | perspectiveDownReturn | | | | | openDownRightReturn | | perspectiveUpReturn | | | | | openUpLeftReturn | | perspectiveLeftReturn | | | | | openUpRightReturn | | perspectiveRightReturn | | | SLIDE | MATH | TIN | BOMB | BOING | ON THE SPACE | |------------------|-----------|-------------|--------------|--------------|---------------| | slideDown | swashOut | tinRightOut | bombRightOut | boingInUp | spaceOutUp | | slideUp | swashIn | tinLeftOut | bombLeftOut | boingOutDown | spaceOutRight | | slideLeft | foolishIn | tinUpOut | | | spaceOutDown | | slideRight | holeOut | tinDownOut | | | spaceOutLeft | | slideDownReturn | | tinRightIn | | | spaceInUp | | slideUpReturn | | tinLeftIn | | | spaceInRight | | slideLeftReturn | | tinUpIn | | | spaceInDown | | slideRightReturn | | tinDownIn | | | spaceInLeft | :tada: Gulp and SCSS (SASS) compiling If you want to customize the CSS files, now you will have the chance. For example, if you want to include only certain animations, you will have to go to this file: Comment or uncomment your desired file and run from terminal the following commands: and last command: Automatically this generate the new files! :white_check_mark: Browser Support Browser | Chrome | Firefox | Safari | iOS Safari | Opera | Android | Android Chrome | IE | Opera Mini --- | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: Version | 31+ | 31+ | 7+ | 7.1+ | 27+ | 4.1+ | 42+ | 10+ | :x:"
555,"A Java serialization/deserialization library to convert Java Objects into JSON and backGson Gson is a Java library that can be used to convert Java Objects into their JSON representation. It can also be used to convert a JSON string to an equivalent Java object. Gson can work with arbitrary Java objects including pre-existing objects that you do not have source-code of. There are a few open-source projects that can convert Java objects to JSON. However, most of them require that you place Java annotations in your classes; something that you can not do if you do not have access to the source-code. Most also do not fully support the use of Java Generics. Gson considers both of these as very important design goals. Goals Provide simple toJson() and fromJson() methods to convert Java objects to JSON and vice-versa Allow pre-existing unmodifiable objects to be converted to and from JSON Extensive support of Java Generics Allow custom representations for objects Support arbitrarily complex objects (with deep inheritance hierarchies and extensive use of generic types) Download Gradle: Maven: Gson jar downloads are available from Maven Central. Documentation API Javadoc: Documentation for the current release User guide: This guide contains examples on how to use Gson in your code. Change log: Changes in the recent versions Design document: This document discusses issues we faced while designing Gson. It also includes a comparison of Gson with other Java libraries that can be used for Json conversion Please use the 'gson' tag on StackOverflow or the google-gson Google group to discuss Gson or to post questions. Related Content Created by Third Parties Gson Tutorial by StudyTrails Gson Tutorial Series by Future Studio Gson API Report License Gson is released under the Apache 2.0 license. Disclaimer This is not an officially supported Google product."
4445,"An Open-Source subdivision surface library.OpenSubdiv OpenSubdiv is a set of open source libraries that implement high performance subdivision surface (subdiv) evaluation on massively parallel CPU and GPU architectures. This codepath is optimized for drawing deforming subdivs with static topology at interactive framerates. The resulting limit surface matches Pixar's Renderman to numerical precision. OpenSubdiv is covered by the Apache license, and is free to use for commercial or non-commercial use. This is the same code that Pixar uses internally for animated film production. Our intent is to encourage high performance accurate subdiv drawing by giving away the ""good stuff"". Feel free to use it and let us know what you think. For more details about OpenSubdiv, see Pixar Graphics Technologies. | | Linux | Windows | macOS | |:-------:|:---------:|:---------:|:---------:| | dev | | | | | release | | | | Documents User Documents Doxygen API Documents Release Notes Forum OpenSubdiv Google Groups Prerequisite For complete information, please refer OpenSubdiv documents: Building with CMake General requirements: | Lib | Min Version | Note | | ----------------------------- | ----------- | ---------- | | CMake | 2.8.6 | Required | Osd optional requirements: | Lib | Min Version | Note | | ------------------------------------------------------------------ | ----------- | ----------------------------| | CUDA | 4.0 | cuda backend | | TBB | 4.0 | TBB backend | | OpenCL | 1.1 | CL backend | | DX11 SDK | | DX backend | | Metal | 1.2 | Metal backend | Requirements for building optional examples: | Lib | Min Version | Note | | -------------------------------------| ----------- | --------------------------------- | | GLFW | 3.0.0 | GL examples | | Ptex | 2.0 | ptex viewers | | Zlib | | (required for Ptex under windows) | Requirements for building documentation: | Lib | | ------------------------------------------- | | Docutils | | Doxygen | | Graphviz | Build example to run glViewer and other example programs with minimal dependency All platforms: Install cmake and GLFW make sure GLFW install directories are configured as follows: Clone OpenSubdiv repository, and create a build directory. Windows (Visual Studio) Linux macOS iOS Because OpenSubdiv uses a self-built build tool (stringify) as part of the build process, you'll want to build for macOS and build the stringify target This will produce an ""OpenSubdiv.xcodeproj"" that can be open and the targets 'mtlViewer' and 'mtlPtexViewer' (if NO_PTEX is ommitted and libPtex.a is installed in the iOS SDK) that can be run Useful cmake options and environment variables `"
794,"Swipe is the most accurate touch slider.Usage Swipe only needs to follow a simple pattern. Here is an example: Above is the initial required structure a series of elements wrapped in two containers. Place any content you want within the items. The containing div will need to be passed to the Swipe function like so: I always place this at the bottom of the page, externally, to verify the page is ready. Also Swipe needs just a few styles added to your stylesheet: Config Options Swipe can take an optional second parameter an object of key/value settings: startSlide Integer (default:0) - index position Swipe should start at speed Integer (default:300) - speed of prev and next transitions in milliseconds. auto Integer - begin with auto slideshow (time in milliseconds between slides) continuous Boolean (default:true) - create an infinite feel with no endpoints disableScroll Boolean (default:false) - stop any touches on this container from scrolling the page stopPropagation Boolean (default:false) - stop event propagation callback Function - runs at slide change. transitionEnd Function - runs at the end slide transition. Example Swipe API Swipe exposes a few functions that can be useful for script control of your slider. prev() slide to prev next() slide to next getPos() returns current slide index position getNumSlides() returns the total amount of slides slide(index, duration) slide to set index position (duration: speed of transition in milliseconds) Browser Support Swipe is now compatible with all browsers, including IE7+. Swipe works best on devices that support CSS transforms and touch, but can be used without these as well. A few helper methods determine touch and CSS transition support and choose the proper animation methods accordingly. Who's using Swipe CNN Craigslist Airbnb NHL many more License Copyright (c) 2013 Brad Birdsall Licensed under the The MIT License (MIT)."
3492,"Powerful data driven content manager for UITableView.RETableViewManager Powerful data driven content manager for UITableView. RETableViewManager allows to manage the content of any UITableView with ease, both forms and lists. RETableViewManager is built on top of reusable cells technique and provides APIs for mapping any object class to any custom cell subclass. The general idea is to allow developers to use their own UITableView and UITableViewController instances (and even subclasses), providing a layer that synchronizes data with the cell appearance. It fully implements UITableViewDelegate and UITableViewDataSource protocols so you don't have to. Quick Example Get your UITableView up and running in several lines of code: RETableViewManager comes pre-packaged with extensible and ready-to-use in production components: Text Bool Number Float Date/Time Long Text Radio option selector Multiple option selector Credit card and expiration date Also RETableViewManager provides APIs for super easy cell styling. Requirements Xcode 5 or higher Apple LLVM compiler iOS 7.0 or higher ARC Demo Build and run the RETableViewManagerExample.xcworkspace in Xcode to see RETableViewManager in action. Installation 1) CocoaPods The recommended approach for installing RETableViewManager is via the CocoaPods package manager, as it provides flexible dependency management and dead simple installation. For best results, it is recommended that you install via CocoaPods >= 0.28.0 using Git >= 1.8.0 installed via Homebrew. Install CocoaPods if not already available: Change to the directory of your Xcode project: Edit your Podfile and add RETableViewManager: Install into your Xcode project: Open your project in Xcode from the .xcworkspace file (not the usual project file) Please note that if your installation fails, it may be because you are installing with a version of Git lower than CocoaPods is expecting. Please ensure that you are running Git >= 1.8.0 by executing git --version. You can get a full picture of the installation details by executing pod install --verbose. 2) Include Source Code Include RETableViewManager, REValidation, Resources, REFormattedNumberField folders in your source code API Quickstart Key Classes RETableViewManager The manager class. Each manager has multiple RETableViewSection sections. RETableViewSection Represents sections in RETableViewManager, each section has multiple RETableViewItem items. RETableViewItem RETableViewItem is the root class of most RETableViewManager item hierarchies. Through RETableViewItem, items inherit a basic interface that communicates with RETableViewCell and RETableViewManager. RETableViewCell The RETableViewCell class defines the attributes and behavior of the cells that appear in UITableView objects. You should subclass RETableViewCell to obtain cell characteristics and behavior specific to your application's needs. By default, RETableViewCell is being mapped with RETableViewItem. Styling RETableViewCellStyle Provides style for RETableViewCell subclasses. You can define such properties as backgroundImageMargin, cellHeight, contentViewMargin and more. Helper Controllers RETableViewOptionsController Performs selection based on user input and provides result on completion. Should be used with RERadioItem. RETableViewManager includes a number of built-in items and cells that perform common tasks (text input, date input and so on). Built-in Items and Cells Item Class Cell Class Description RETextItem RETableViewTextCell Provides convenience for a user text input. You can set a bunch of properties through RETextItem that you would normally find in UITextField. RELongTextItem RETableViewLongTextCell Provides convenience for a multiline user text input. You can set a bunch of properties through RELongTextItem that you would normally find in UITextView. RENumberItem RETableViewNumberCell Provides convenience for a user number input using REFormattedNumberField. REBoolItem RETableViewBoolCell Provides convenience for a user boolean input using UISwitch. RERadioItem RETableViewCell Provides convenience for selecting a single option using RETableViewOptionsController. REMultipleChoiceItem RETableViewCell Provides convenience for selecting multiple options using RETableViewOptionsController. REFloatItem RETableViewFloatCell Provides convenience for adjusting float values ranging from 0.0 to 1.0. REDateTimeItem RETableViewDateTimeCell Provides convenience for modifying date in NSDate objects. REPickerItem RETableViewPickerCell Provides convenience for selecting multiple options using UIPickerView. RESegmentedItem RETableViewSegmentedCell Provides convenience for working with UISegmentedControl. RECreditCardItem RETableViewCreditCardCell Provides convenience for a user credit card input. Allows to enter a credit card number, expiration date and security code, all in a single table view cell. Examples Creating Sections Example Section without a title: Section with a title: Section with a title and a footer: Section with a custom header view: Section with a custom header and footer view: Text (UITextField) and Number (REFormattedNumberField) Item Example You can read self.textItem.value and self.numberItem.value later whenever you need them. Bool Item (UISwitch) Example Radio (RETableViewOptionsController) Item Example Float Item (UISlider) Example Date Item Example Picker Item Example Segmented Item Example Validations Validations are performed using REValidation library. Example: Each item, each section and the manager have property errors. This property is always up to date with errors on each level. For example, an RETableViewItem would only have its own validation errors, RETableViewSection would have all errors that occured in that section (one per item). RETableViewManager's property errors would reflect all errors. Custom Cells RETableViewManager allows to map custom objects to custom cells. In order to map your custom object (an item) to a cell, simply write: If you take a look at RETableViewManager Source Code you may find out how default mapping is being performed: Your custom items should be subclassed from RETableViewItem. Custom cells should be subclassed from RETableViewCell. These are 2 base classes that provide all necessary logic to bound your subclasses together. In your RETableViewCell subclass you need to link an item object with your item. This could be simply done by declaring it: After that your custom object (item) is ready to use within the cell. There are 3 basic methods of RETableViewCell that you need to implement: Class method to adjust cell size: Your custom item will be passed to this method in order to determine cell size. You need to return the calculated size. Instance method that is being fired when the cell is being created. You might want to create cell subviews here. This method will be called only once, after that the cell will be reused. Instance method that is being fired each time the cell is being reused. cellWillAppear is a great place to assign values to labels (from your custom item), adjust colors, etc. Quick example: Interface Builder Support Interface builder cells are supported out of the box, no special set up needed. Cells and items are being automatically registered like any other custom cells in RETableViewManager: Here XIBTestItem would be your cell identifier and you should have the XIBTestCell.xib file in your bundle. That's it. Styling It's super easy to customize different offsets and cell background images of the entire UITableView (or any particular section) with RETableViewManager. RETableViewManager and RETableViewSection both have the style property (an instance of the RETableViewCellStyle class). Here's the quick example of how the custom styling works: Contact Roman Efimov https://github.com/romaonthego https://twitter.com/romaonthego romefimov@gmail.com License RETableViewManager is available under the MIT license. Copyright 2013 Roman Efimov. Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the ""Software""), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
3586,"A library for creating dropdowns and other floating elements. #hubspot-open-sourceDrop Drop.js is a powerful Javascript and CSS library for creating dropdowns and other floating displays. Install Dependencies Tether npm bower Usage API documentation Demo Contributing We encourage contributions of all kinds. If you would like to contribute in some way, please review our guidelines for contributing. License Copyright 2015 HubSpot - MIT License"
1375,"Swarm Classic: a container clustering system. Not to be confused with Docker Swarm which is at https://github.com/docker/swarmkitClassic Swarm: a Docker-native clustering system Classic Swarm has been archived and is no longer actively developed. You may want to use the Swarm mode built into the Docker Engine instead, or another orchestration system. Docker Swarm ""Classic"" is native clustering for Docker. It turns a pool of Docker hosts into a single, virtual host. Swarm Disambiguation Docker Swarm ""Classic"" standalone: This project. A native clustering system for Docker. It turns a pool of Docker hosts into a single, virtual host using an API proxy system. See Docker Swarm overview. It was Docker's first container orchestration project that began in 2014. Swarmkit: Cluster management and orchestration features in Docker Engine 1.12 or later. When Swarmkit is enabled we call Docker Engine running in swarm mode. See the feature list: Swarm mode overview. This project focuses on micro-service architecture. It supports service reconciliation, load balancing, service discovery, built-in certificate rotation, etc. Copyright and license Copyright 2014-2018 Docker, Inc. All rights reserved, except as follows. Code is released under the Apache 2.0 license. The README.md file, and files in the ""docs"" folder are licensed under the Creative Commons Attribution-ShareAlike 4.0 International License under the terms and conditions set forth in the file ""LICENSE.docs"". You may obtain a duplicate copy of the same license, titled CC-BY-SA-4.0, at https://creativecommons.org/licenses/by-sa/4.0/."
3463,"A cloud service that enables Cordova and React Native developers to deploy mobile app updates directly to their users devices.Sign up With App Center to use CodePush CodePush CodePush is a cloud service that enables Cordova and React Native developers to deploy mobile app updates directly to their users' devices. It works by acting as a central repository that developers can publish updates to (JS, HTML, CSS and images), and that apps can query for updates from (using provided client SDK for Cordova and React Native). This allows you to have a more deterministic and direct engagement model with your userbase, when addressing bugs and/or adding small features that don't require you to re-build a binary and re-distribute it through the respective app stores. To get started using CodePush, refer to our documentation, otherwise, read the following steps if you'd like to build/contribute to the project from source. NOTE: If you need information about code-push management CLI, you can find it in v3.0.1. Dev Setup Install Node.js Install Git Clone the Repository: git clone https://github.com/Microsoft/code-push.git Building Run npm run setup to install the NPM dependencies of management SDK. Run npm run build to build the management SDK for testing. Run npm run build:release to build the release version of management SDK. Running Tests To run tests, run npm run test from the root of the project. You can use debug mode for tests with .vscode/launch.json file. Coding Conventions Use double quotes for strings Use four space tabs Use camelCase for local variables and imported modules, PascalCase for types, and dash-case for file names This project has adopted the Microsoft Open Source Code of Conduct. For more information see the Code of Conduct FAQ or contact opencode@microsoft.com with any additional questions or comments. CodePush Management SDK (Node.js) A JavaScript library for programmatically managing your CodePush account (e.g. creating apps, promoting releases), which allows authoring Node.js-based build and/or deployment scripts, without needing to shell out to the App Center CLI. Getting Started Create a token to authenticate with the CodePush server using the following App Center CLI command: Please copy your API Token and keep it secret. You won't be able to see it again. Install the management SDK by running npm install code-push --save Import it using one of the following statement: (using ES6 syntax as applicable): On commonjs environments: Using ES6 syntax with tsconfig.json: Create an instance of the CodePush class, passing it the API Token you created or retrieved in step #1: Begin automating the management of your account! For more details on what you can do with this codePush object, refer to the API reference section below. API Reference The code-push module exports a single class (typically referred to as CodePush), which represents a proxy to the CodePush account management REST API. This class has a single constructor for authenticating with the CodePush service, and a collection of instance methods that correspond to the commands in the App Center CLI, which allow you to programmatically control every aspect of your CodePush account. Constructors CodePush(accessKey: string) - Creates a new instance of the CodePush management SDK, using the specified access key to authenticated with the server. Methods Note: access key here refers to an AppCenter API Token. addAccessKey(description: string): Promise<AccessKey> - Creates a new access key with the specified description (e.g. ""VSTS CI""). addApp(name: string, os: string, platform: string, manuallyProvisionDeployments: boolean = false): Promise<App> - Creates a new CodePush app with the specified name, os, and platform. If the default deployments of ""Staging"" and ""Production"" are not desired, pass a value of true for the manuallyProvisionDeployments parameter. addCollaborator(appName: string, email: string): Promise<void> - Adds the specified CodePush user as a collaborator to the specified CodePush app. addDeployment(appName: string, deploymentName: string): Promise<Deployment> - Creates a new deployment with the specified name, and associated with the specified app. clearDeploymentHistory(appName: string, deploymentName: string): Promise<void> - Clears the release history associated with the specified app deployment. getAccessKey(accessKey: string): Promise<AccessKey> - Retrieves the metadata about the specific access key. getAccessKeys(): Promise<AccessKey[]> - Retrieves the list of access keys associated with your CodePush account. getApp(appName: string): Promise<App> - Retrieves the metadata about the specified app. getApps(): Promise<App[]> - Retrieves the list of apps associated with your CodePush account. getCollaborators(appName: string): Promise<CollaboratorMap> - Retrieves the list of collaborators associated with the specified app. getDeployment(appName: string, deploymentName: string): Promise<Deployment> - Retrieves the metadata for the specified app deployment. getDeploymentHistory(appName: string, deploymentName: string): Promise<Package[]> - Retrieves the list of releases that have been made to the specified app deployment. getDeploymentMetrics(appName: string, deploymentName: string): Promise<DeploymentMetrics> - Retrieves the installation metrics for the specified app deployment. getDeployments(appName: string): Promise<Deployment[]> - Retrieves the list of deployments associated with the specified app. patchRelease(appName: string, deploymentName: string, label: string, updateMetadata: PackageInfo): Promise<void> - Updates the specified release's metadata with the given information. promote(appName: string, sourceDeploymentName: string, destinationDeploymentName: string, updateMetadata: PackageInfo): Promise<Package> - Promotes the latest release from one deployment to another for the specified app and updates the release with the given metadata. release(appName: string, deploymentName: string, updateContentsPath: string, targetBinaryVersion: string, updateMetadata: PackageInfo): Promise<Package> - Releases a new update to the specified deployment with the given metadata. removeAccessKey(accessKey: string): Promise<void> - Removes the specified access key from your CodePush account. removeApp(appName: string): Promise<void> - Deletes the specified CodePush app from your account. removeCollaborator(appName: string, email: string): Promise<void> - Removes the specified account as a collaborator from the specified app. removeDeployment(appName: string, deploymentName: string): Promise<void> - Removes the specified deployment from the specified app. renameApp(oldAppName: string, newAppName: string): Promise<void> - Renames an existing app. renameDeployment(appName: string, oldDeploymentName: string, newDeploymentName: string): Promise<void> - Renames an existing deployment within the specified app. rollback(appName: string, deploymentName: string, targetRelease?: string): Promise<void> - Rolls back the latest release within the specified deployment. Optionally allows you to target a specific release in the deployment's history, as opposed to rolling to the previous release. transferApp(appName: string, email: string): Promise<void> - Transfers the ownership of the specified app to the specified account. Error Handling When an error occurs in any of the methods, the promise will be rejected with a CodePushError object with the following properties: message: A user-friendly message that describes the error. statusCode: An HTTP response code that identifies the category of error: CodePush.ERROR_GATEWAY_TIMEOUT: A network error prevented you from connecting to the CodePush server. CodePush.ERROR_INTERNAL_SERVER: An error occurred internally on the CodePush server. CodePush.ERROR_NOT_FOUND: The resource you are attempting to retrieve does not exist. CodePush.ERROR_CONFLICT: The resource you are attempting to create already exists. CodePush.ERROR_UNAUTHORIZED: The access key you configured is invalid or expired."
2195,"Javascript tutorial bookImportant : The repo is depreciated, please visit the new tutorial. https://github.com/wangdoc/javascript-tutorial An open JavaScript tutorial book, focusing on client devices, written in Chinese."
2417,"Vim motions on speed!Vim motion on speed! About the authors | Authors | | |------------------|-------------------------------| | Kim Silkebkken | https://github.com/Lokaltog | | haya14busa | https://github.com/haya14busa | The EasyMotion project, revived! Starting from version 2.0 haya14busa will be taking over the project from Lokaltog. He's improved the default motions, implemented many useful new features, and fixed some bugs. EasyMotion is now completely: Well-behaved: It's consistent with the default motions of Vim and works well in all modes. And it now supports repeating with the dot operator. Configurable: You can easily configure its behavior and map it to any key Sophisticated: Provide flawless, smooth and fast motions with minimal keystrokes Even though some default behaviors were modified and many new features were added, I carefully considered backward compatibility. So those of you updating from older versions can do so without worry and start benefiting immediately from all the new features! Introduction EasyMotion provides a much simpler way to use some motions in vim. It takes the <number> out of <number>w or <number>f{char} by highlighting all possible choices and allowing you to press one key to jump directly to the target. When one of the available motions is triggered, all visible text preceding or following the cursor is faded, and motion targets are highlighted. EasyMotion is triggered by the provided mappings. This readme only covers the basics; please refer to :help easymotion.txt to see all the available mappings. Important notes Default bindings The default leader has been changed to <Leader><Leader> to avoid conflicts with other plugins you may have installed. This can easily be changed back to pre-1.3 behavior by rebinding the leader in your vimrc: All motions will then be triggered with <Leader> by default, e.g. <Leader>s, <Leader>gE. For users of the forked version SelectLines and SelectPhrase are not actually motions, so I've moved them into separate plugins. https://github.com/haya14busa/vim-easyoperator-line https://github.com/haya14busa/vim-easyoperator-phrase Usage example for the base features <cursor>Lorem ipsum dolor sit amet. Type <Leader><Leader>w(<Plug>(easymotion-w)) to trigger the word motion w. When the motion is triggered, the text is updated (no braces are actually added, the text is highlighted in red by default): <cursor>Lorem {a}psum {b}olor {c}it {d}met. Press c to jump to the beginning of the word ""sit"": Lorem ipsum dolor <cursor>sit amet. Similarly, if you're looking for an ""o"", you can use the f motion. Type <Leader><Leader>fo, and all ""o"" characters are highlighted: <cursor>L{a}rem ipsum d{b}l{c}r sit amet. Press b to jump to the second ""o"": Lorem ipsum d<cursor>olor sit amet. Jeffrey Way of Nettuts+ has also written a tutorial about EasyMotion. New features in version 3.0 Overwin motions EasyMotion now supports moving cursor across/over window. Since it doesn't make sense that moving cursor to other window while Visual or Operator-pending mode, overwin motions only provides mappings for Normal mode. Please use nmap to use overwin motions. Overwin motions only supports bi-directional motions. Example configuration Integration with incsearch.vim haya14busa/incsearch.vim haya14busa/incsearch-easymotion.vim Bonus fuzzy-search with EasyMotion haya14busa/incsearch.vim haya14busa/incsearch-fuzzy.vim haya14busa/incsearch-easymotion.vim New features in version 2.0 Two key highlighting When EasyMotion runs out of single characters to highlight movement targets, it immediately shows you the keys you have to press. In previous versions you could not see the next character you would need to press until you entered the first one. This made movement over long distances less fluid. Now you can see at a glance exactly which characters to select to get to your destination. Bidirectional motions All motions now come in bidirectional variants (e.g. <Plug>(easymotion-s), <Plug>(easymotion-bd-w) and so forth). By default, you can already jump forward or backward with <Leader>s. A useful trick is to map nmap s <Plug>(easymotion-s) to use s instead and save one keystroke! 2-character search motion You can now also perform a 2-character search, similar to vim-seek/vim-sneak with <Plug>(easymotion-s2). For example, you can highlight all words that start with fu. n-character search motion You can also search for n characters, which can be used to replace the default search of Vim. It supports incremental highlighting and you can use <Tab> and <S-Tab> to scroll down/up a page. If you press <CR>, you get the usual EasyMotion highlighting and can jump to any matching target destination with a single keystroke. What sounds complicated should become clear if you look at the following examples. Within line motion Every motion also has variants that are restricted to just the current line (e.g. <Plug>(easymotion-sl), <Plug>(easymotion-bd-wl), etc...). This can be helpful if you find the full search distracting or slows down vim. hjkl motions EasyMotion can be configured to avoid repetitive use of the h j k and l keys. Smartcase & Smartsign This setting makes EasyMotion work similarly to Vim's smartcase option for global searches. With this option set, v will match both v and V, but V will match V only. Default: 0. This applies the same concept, but for symbols and numerals. 1 will match 1 and !; ! matches ! only. Default: 0. Migemo feature (for Japanese user) Easymotion can match multibyte Japanese characters with alphabetical input. For example, <Leader><Leader>sa can search ''. This feature doesn't require cmigemo because Easymotion includes regex patterns generated by cmigemo. However, installing cmigemo will make 2-character and n-character search motions to also support the migemo feature. Default:0 Repeat motions Repeat the last motion <Plug>(easymotion-repeat) Repeat the last find motion In a find motion (e.g. <Plug>(easymotion-s)), type <CR> without input characters to find the last motion again. Jump to next/previous match (even on next/previous page) <Plug>(easymotion-next) <Plug>(easymotion-prev) Support for dot repeat This requires https://github.com/tpope/vim-repeat. You can use EasyMotion with operators and press . to repeat! It is well-behaved and consistent with the default behavior of Vim. Installation Pathogen (https://github.com/tpope/vim-pathogen) Vundle (https://github.com/gmarik/vundle) NeoBundle (https://github.com/Shougo/neobundle.vim) Minimal Configuration Tutorial I recommend configuring and map keys by yourself if you are true Vimmer. Please do not be satisfied with just installing vim-easymotion, configuring it yourself boost your productivity more and more! Default <Leader><Leader> prefix isn't easy to press, and I leave them just for backwards compatibility. You should at least change the prefix key like this map <Leader> <Plug>(easymotion-prefix) Minimal but useful vimrc example: Now, all you need to remember is s and JK motions bindings, and it's good enough to boost your cursor speed! s is bidirectional find motion, you can move to anywhere with it. <Leader>j & <Leader>k make it easy to move to the lines. Of course, you can use any key you want instead of s such as <Space>, <Leader>s, etc... If you want to use more useful mappings, please see :h easymotion.txt for more detail."
2755,"Simple table with sorting and filtering on AngularJSTable + AngularJS Code licensed under New BSD License. This directive enhances your HTML tables. It support sorting, filtering and pagination. Header row with titles and filters automatic generated. Installing NPM Install the current stable release: Or install the latest beta release: note: when to use next? see this issue-comment CDN You can download the distribution files directly from unpkg Bower: NO LONGER SUPPORTED Getting started Please follow the getting started steps here Examples Demo site Sample apps: ES5 ES2015 + SystemJS ES2015 + Webpack Typescript + Webpack Codepen examples (Tip: fork these to create your own examples); ngTable: inmemory list ngTable: server-side list ngTableDynamic: inmemory list ngTableDynamic: server-side list Using Typescript? As of v2.0.0 ngTable is written in typescript and so you do NOT have to install external type declarations for this library. By installing the ng-table package from npm, you will get typescript intellisense for all ng-table exported types. WARNING:. The type definitions on DefinitelyTyped are depreciated. Upgrading from an earlier version? Upgrade from 0.8.3 It's recommended to upgrade in two jumps: Upgrade to version 1.0.0-beta.9, making any changes to your application code neccessary to work with this version EG: bower install ng-table#1.0.0-beta.9 --save Refactor your application to remove any code that depended on depreciated behaviours that where removed in the 1.0.0 release Install 1.0.0 (should now be a drop in replacement for 1.0.0-beta.9) Bower: bower install ng-table#1.0.0 --save NPM: npm i ng-table@1.0.0 --save Upgrade from version earlier than 0.8.3 It's recommended to upgrade in three jumps: Upgrade to version 0.8.3, making any changes to your application code neccessary to work with this version EG: bower install ng-table#0.8.3 --save Follow the guide above to upgrade from 0.8.3 -> 1.0.0-beta.9 -> 1.0.0 Tips * Read the notes in github releases. Each release details the breaking changes and migration guidance Compatibility For work in IE < 9 need jQuery, just add: Building from sources Clone: git clone https://github.com/esvit/ng-table.git Install: npm install Build: npm run build:full To locally build and serve docs site: npm run doc && npm run serve:docs-site To locally serve the demo: npm run serve:demo Want to contribute? See the contributing guidelines. This project is part of Bazalt CMS."
3478,"Simple HTML5 drag-drop zone with React.js.react-dropzone Simple React hook to create a HTML5-compliant drag'n'drop zone for files. Documentation and examples at https://react-dropzone.js.org. Source code at https://github.com/react-dropzone/react-dropzone/. Installation Install it from npm and include it in your React build process (using Webpack, Browserify, etc). or: Usage You can either use the hook: IMPORTANT: Under the hood, this lib makes use of hooks, therefore, using it requires React >= 16.8. Or the wrapper component for the hook: Warning: On most recent browsers versions, the files given by onDrop won't have properties path or fullPath, see this SO question and this issue. Furthermore, if you want to access file contents you have to use the FileReader API: Dropzone Props Getters The dropzone property getters are just two functions that return objects with properties which you need to use to create the drag 'n' drop zone. The root properties can be applied to whatever element you want, whereas the input properties must be applied to an <input>: Note that whatever other props you want to add to the element where the props from getRootProps() are set, you should always pass them through that function rather than applying them on the element itself. This is in order to avoid your props being overridden (or overriding the props returned by getRootProps()): In the example above, the provided {onClick} handler will be invoked before the internal one, therefore, internal callbacks can be prevented by simply using stopPropagation. See Events for more examples. Important: if you ommit rendering an <input> and/or binding the props from getInputProps(), opening a file dialog will not be possible. Refs Both getRootProps and getInputProps accept a custom refKey (defaults to ref) as one of the attributes passed down in the parameter. This can be useful when the element you're trying to apply the props from either one of those fns does not expose a reference to the element, e.g.: If you're working with Material UI and would like to apply the root props on some component that does not expose a ref, use RootRef: Important: do not set the ref prop on the elements where getRootProps()/getInputProps() props are set, instead, get the refs from the hook itself: If you're using the <Dropzone> component, though, you can set the ref prop on the component itself which will expose the {open} prop that can be used to open the file dialog programmatically: Testing Important: react-dropzone makes some of its drag 'n' drop callbacks asynchronous to enable promise based getFilesFromEvent() functions. In order to test components that use this library, you may want to use the react-testing-library: Note: using Enzyme for testing is not supported at the moment, see #2011. More examples for this can be found in react-dropzones own test suites. Need image editing? React Dropzone integrates perfectly with Doka Image Editor, creating a modern image editing experience. Doka supports crop aspect ratios, resizing, rotating, cropping, annotating, filtering, and much more. Checkout the integration example. Supported Browsers We use browserslist config to state the browser support for this lib, so check it out on browserslist.dev. Support Backers Support us with a monthly donation and help us continue our activities. [Become a backer] Sponsors Become a sponsor and get your logo on our README on Github with a link to your site. [Become a sponsor] License MIT"
657,"Streisand sets up a new server running your choice of WireGuard, OpenConnect, OpenSSH, OpenVPN, Shadowsocks, sslh, Stunnel, or a Tor bridge. It also generates custom instructions for all of these services. At the end of the run you are given an HTML file with instructions that can be shared with friends, family members, and fellow activists.Streisand English, Franais, , | Mirror Streisand Silence censorship. Automate the effect. The Internet can be a little unfair. It's way too easy for ISPs, telecoms, politicians, and corporations to block access to the sites and information that you care about. But breaking through these restrictions is tough. Or is it? If you have an account with a cloud computing provider, Streisand can set up a new node with many censorship-resistant VPN services nearly automatically. You'll need a little experience with a Unix command-line. (But without Streisand, it could take days for a skilled Unix administrator to configure these services securely!) At the end, you'll have a private website with software and instructions. Here's what a sample Streisand server looks like. There's a list of supported cloud providers; experts may be able to use Streisand to install on many other cloud providers. VPN services One type of tool that people use to avoid network censorship is a Virtual Private Network (VPN). There are many kinds of VPNs. Not all network censorship is alike; in some places, it changes from day to day. Streisand provides many different VPN services to try. (You don't have to install them all, though.) Some Streisand services include add-ons for further censorship and throttling resistance: OpenSSH Tinyproxy may be used as an HTTP proxy. OpenConnect / Cisco AnyConnect This protocol is widely used by multi-national corporations, and might not be blocked. OpenVPN Stunnel add-on available. Shadowsocks, The V2ray-plugin is installed to provide robust traffic evasion on hostile networks (especially those implementing quality of service (QOS) throttling). A private Tor bridge relay Obfsproxy with obfs4 available as an add-on. WireGuard, a modern high-performance protocol. See also: * A more technical list of features * A more technical list of services Cloud providers Amazon Web Services (AWS) Microsoft Azure Digital Ocean Google Compute Engine (GCE) Linode Rackspace Other providers We recommend using one of the above providers. If you are an expert and can set up a fresh Ubuntu 16.04 server elsewhere, there are ""localhost"" and ""existing remote server"" installation methods. For more information, see the advanced installation instructions. Installation You need command-line access to a Unix system. You can use Linux, BSD, or macOS; on Windows 10, the Windows Subsystem for Linux (WSL) counts as Linux. Once you're ready, see the full installation instructions. Things we want to do better Aside from a good deal of cleanup, we could really use: Easier setup. Faster adoption of new censorship-avoidance tools We're looking for help with both. If there is something that you think Streisand should do, or if you find a bug in its documentation or execution, please file a report on the Issue Tracker. Core Contributors Jay Carlson (@nopdotcom) Nick Clarke (@nickolasclarke) Joshua Lund (@jlund) Ali Makki (@alimakki) Daniel McCarney (@cpu) Corban Raun (@CorbanR) Acknowledgements Jason A. Donenfeld deserves a lot of credit for being brave enough to reimagine what a modern VPN should look like and for coming up with something as good as WireGuard. He has our sincere thanks for all of his patient help and high-quality feedback. We are grateful to Trevor Smith for his massive contributions. He suggested the Gateway approach, provided tons of invaluable feedback, made everything look better, and developed the HTML template that served as the inspiration to take things to the next level before Streisand's public release. Huge thanks to Paul Wouters of The Libreswan Project for his generous help troubleshooting the L2TP/IPsec setup. Starcadian's 'Sunset Blood' album was played on repeat approximately 300 times during the first few months of work on the project in early 2014."
3758,":musical_keyboard: Making life easy to create a MIDI-app on the web. Includes a library to program synesthesia into your app for memory recognition or for creating trippy effects. Convert soundfonts for Guitar, Bass, Drums, ect. into code that can be read by the browser. Supports multiple simultaneous instruments and perfect timing.Code examples - from the repo Basic - the most basic implementation. MIDIPlayer - how to parse MIDI files, and interact with the data stream. WhitneyMusicBox - a audio/visual experiment by Jim Bumgardner Demos 3D Piano Player w/ Three.js by Borja Morales @reality3d Brite Lite by Daniel Christopher @uxmonk Color Piano by Michael Deal @mudcube Euphony 3D Piano by Xueqiao Xu @qiao Gbloink! by Phil Jones Piano Typewriter by Andrew Levine Ragamroll by Mani Balasubramanian Simon Says by Daniel Christopher @uxmonk Spiral Keyboard by Patrick Snels VexFlow by Mohit Muthanna @11111110b Related repositories MIDI Pictures: Pictures of the 128 standard instruments on MIDI piano keyboards MIDI Soundfonts: Pre-rendered General MIDI soundfonts that can be used immediately with MIDI.js Generating Base64 Soundfonts There is two generators for MIDI.js soundfonts: NodeJS package for creating soundfonts from WAV files - by Patrick Wolleb Ruby package for creating soundsfonts from SF2 files - by Mohit Muthanna To dive in quickly Benjamin Gleitzman has created a package of pre-rendered sound fonts. API MIDI.loadPlugin.js - Decides which framework is best to use MIDI.Plugin.js - Controls MIDI output MIDI.Player.js - Plays MIDI stream Listener for when notes are played Smooth animation interpolating between onMidiEvent calls Effects available for WebAudioContext via Tuna.js Libraries colorspace.js: Color conversions, music isnt complete without! Color.Space(0xff0000, ""HEX>RGB>HSL""); dom_request_script.js: Loads scripts in synchronously, or asynchronously. DOMLoader.script.add(src, onsuccess); dom_request_xhr.js: Cross-browser XMLHttpd request. DOMLoader.sendRequest(src, onsuccess); synesthesia.js: Note-to-color mappings (from Isaac Newton onwards). Many thanks to the authors of these libraries Web MIDI API: W3C proposal by Jussi Kalliokoski & Chris Wilson Web Audio API: W3C proposal by Chris Rogers <audio>: HTML5 specs Flash package: SoundManager2 by Scott Schiller jasmid: Reads MIDI file byte-code, and translats into a Javascript array. base642binary.js: Cleans up XML base64-requests for Web Audio API. Similar projects Wild Web MIDI by @BlurSpline"
1321,SUI Mobile (MSUI)UEDUISUI Mobile(MSUI) UI SUI Mobile UED UI Framework7 RatchetIonicOnsenCDN iOS 6.0+ Android 4.0+ FAQ issue ____issue 1278550944 itaofe@gmail.com Issue Pull Request PR develop.md
2846,"Open Broadcaster Software (Deprecated: See OBS Studio repository instead)Open Broadcaster Software This is the repository for OBS, an open source live streaming / recording app for Windows. Development on this version of OBS has mostly stopped. All future work is being focused on a rewrite of OBS called OBS Studio. OBS Studio has an improved core, cross-platform Windows / Mac / Linux support and a better plugin API. Please visit https://github.com/jp9000/obs-studio for the OBS Studio repository. Outside of simple and specific bug fixes, pull requests for this version of OBS are unlikely to receive review - we encourage you to spend your time developing for OBS Studio instead. Downloadable binaries for Windows can be found on our website, https://obsproject.com/"
4849,"Infrared remote library for Arduino: send and receive infrared signals with multiple protocolsIRremote Arduino Library Available as Arduino library ""IRremote"" Version 3.3.1 - work in progress This library enables you to send and receive using infra-red signals on an Arduino. API A Doxygen documentation of the sources is available on the project homepage. Installation Click on the LibraryManager badge above to see the instructions. Supported IR Protocols Denon / Sharp, JVC, LG, NEC / Onkyo / Apple, Panasonic / Kaseikyo, RC5, RC6, Samsung, Sony, (Pronto), BoseWave, Lego, Whynter, MagiQuest. Protocols can be switched off and on by defining macros before the line #include <IRremote.h> like here: Wiki This is a quite old but maybe useful wiki for this library. Features of the 3.x version You can use any pin for sending now, like you are used with receiving. Simultaneous sending and receiving. See the UnitTest example. No more need to use 32 bit hex values in your code. Instead a (8 bit) command value is provided for decoding (as well as an 16 bit address and a protocol number). Protocol values comply to protocol standards, i.e. NEC, Panasonic, Sony, Samsung and JVC decode and send LSB first. Supports more protocols, since adding a protocol is quite easy now. Better documentation and more examples :-). Compatible with tone() library, see ReceiveDemo. Supports more platforms, since the new structure allows to easily add a new platform. Feedback LED also for sending. Ability to generate a non PWM signal to just simulate an active low receiver signal for direct connect to existent receiving devices without using IR. Easy configuration of protocols required, directly in your [source code[(https://github.com/Arduino-IRremote/Arduino-IRremote/blob/master/examples/SimpleReceiver/SimpleReceiver.ino#L18-L34). This reduces the memory footprint and increases decoding time. Converting your program to the 3.1 version This must be done also for all versions > 3.0.1 if USE_NO_SEND_PWM is defined. Starting with this version, the generation of PWM is done by software, thus saving the hardware timer and enabling arbitrary output pins. Therefore you must change all IrSender.begin(true); by IrSender.begin(IR_SEND_PIN, ENABLE_LED_FEEDBACK);. If you use a core that does not use the -flto flag for compile, you can activate the line #define SUPPRESS_ERROR_MESSAGE_FOR_BEGIN in IRRemote.h, if you get false error messages regarding begin() during compilation. Converting your 2.x program to the 3.x version Now there is an IRreceiver and IRsender object like the well known Arduino Serial object. Just remove the line IRrecv IrReceiver(IR_RECEIVE_PIN); and/or IRsend IrSender; in your program, and replace all occurrences of IRrecv. or irrecv. with IrReceiver. Since the decoded values are now in IrReceiver.decodedIRData and not in results any more, remove the line decode_results results or similar. Like for the Serial object, call IrReceiver.begin(IR_RECEIVE_PIN, ENABE_ED_FEEDBACK); or IrReceiver.begin(IR_RECEIVE_PIN, DISABLE_LED_FEEDBACK); instead of the IrReceiver.enableIRIn(); or irrecv.enableIRIn(); in setup(). Old decode(decode_results *aResults) function is replaced by simple decode(). So if you have a statement if(irrecv.decode(&results)) replace it with if (IrReceiver.decode()). The decoded result is now in in IrReceiver.decodedIRData and not in results any more, therefore replace any occurrences of results.value and results.decode_type (and similar) to IrReceiver.decodedIRData.decodedRawData and IrReceiver.decodedIRData.protocol. Overflow, Repeat and other flags are now in IrReceiver.receivedIRData.flags. Seldom used: results.rawbuf and results.rawlen must be replaced by IrReceiver.decodedIRData.rawDataPtr->rawbuf and IrReceiver.decodedIRData.rawDataPtr->rawlen. Running your 2.x program with the 3.x library version If you program is like: it should run on the 3.1.1 version as before. The following decoders are available: Denon, JVC, LG, NEC, Panasonic, RC5, RC6, Samsung, Sony. The results.value is set by the decoders for NEC, Panasonic, Sony, Samsung and JVC as MSB first like in 2.x. - The old functions sendNEC() and sendJVC() are deprecated and renamed to sendNECMSB() and sendJVCMSB() to make it clearer that they send data with MSB first, which is not the standard for NEC and JVC. Use them to send your old MSB-first 32 bit IR data codes. In the new version you will send NEC commands not by 32 bit codes but by a (constant) 8 bit address and an 8 bit command. Convert old MSB first 32 bit IR data codes to new LSB first 32 bit IR data codes The new decoders for NEC, Panasonic, Sony, Samsung and JVC IrReceiver.decodedIRData.decodedRawData is now LSB-first, as the definition of these protocols suggests! To convert one into the other, you must reverse the byte positions and then reverse all bit positions of each byte or write it as one binary string and reverse/mirror it. Example: 0xCB340102 byte reverse -> 02 01 34 CB bit reverse-> 40 80 2C D3. 0xCB340102 is binary 11001011001101000000000100000010. 0x40802CD3 is binary 01000000100000000010110011010011. If you read the first binary sequence backwards (right to left), you get the second sequence. FAQ IR does not work right when I use Neopixels (aka WS2811/WS2812/WS2812B) or other libraries blocking interrupts for a longer time (> 50 us). Whether you use the Adafruit Neopixel lib, or FastLED, interrupts get disabled on many lower end CPUs like the basic Arduinos for longer than 50 s. In turn, this stops the IR interrupt handler from running when it needs to. There are some solutions to this on some processors, see this page from Marc MERLIN The default IR timer on AVR's is timer 2. Since the Arduino Tone library as well as analogWrite() for pin 3 and pin 11 requires timer 2, this functionality cannot be used simultaneously. You can use tone() but after the tone has stopped, you must call IrReceiver.start() or better IrReceiver.start(<microsecondsOfToneDuration>) to restore the timer settings for receive. Or you change the timer to timer 1 in private/IRTimer.cpp.h. If you can live with the NEC protocol, you can try the MinimalReceiver example, it requires no timer. You can use multiple IR receiver by just connecting the output pins of several IR receivers together. The IR receivers use an NPN transistor as output device with just a 30k resistor to VCC. This is almost ""open collector"" and allows connecting of several output pins to one Arduino input pin. The minimal CPU frequency for receiving is 4 MHz, since the 50 us timer ISR takes around 12 us on a 16 MHz ATmega. Minimal version For applications only requiring NEC protocol, there is a receiver which has very small codesize of 500 bytes and does NOT require any timer. See the MinimalReceiver and IRDispatcherDemo example how to use it. Mapping of pins to interrupts can be found here. Handling unknown Protocols Disclaimer This library was never designed to handle long codes like the ones used by air conditioners. See Recording long Infrared Remote control signals with Arduino. The main reason is, that it was designed to fit inside MCUs with relatively low levels of resources and was intended to work as a library together with other applications which also require some resources of the MCU to operate. Protocol=UNKNOWN If you see something like Protocol=UNKNOWN Hash=0x13BD886C 35 bits received as output of e.g. the ReceiveDemo example, you either have a problem with decoding a protocol, or an unsupported protocol. If you have an odd number of bits received, it is likely, that your receiver circuit has problems. Maybe because the IR signal is too weak. If you see timings like + 600,- 600 + 550,- 150 + 200,- 100 + 750,- 550 then one 450 s space was split into two 150 and 100 s spaces with a spike / error signal of 200 s between. Maybe because of a defective receiver or a weak signal in conjunction with another light emitting source nearby. If you see timings like + 500,- 550 + 450,- 550 + 500,- 500 + 500,-1550, then marks are generally shorter than spaces and therefore MARK_EXCESS_MICROS (specified in your ino file) should be negative to compensate for this at decoding. If you see Protocol=UNKNOWN Hash=0x0 1 bits received it may be that the space after the initial mark is longer than RECORD_GAP_MICROS. This was observed for some LG air conditioner protocols. Try again with a line e.g. #define RECORD_GAP_MICROS 12000 before the line #include <IRremote.h> in your ino file. To see more info supporting you to find the reason for your UNKNOWN protocol, you must enable the line //#define DEBUG in IRremoteInt.h. How to deal with protocols not supported by IRremote If you do not know which protocol your IR transmitter uses, you have several choices. - Use the IRreceiveDump example to dump out the IR timing. You can then reproduce/send this timing with the SendRawDemo example. For long codes with more than 48 bits like from air conditioners, you can change the length of the input buffer in IRremote.h. - The IRMP AllProtocol example prints the protocol and data for one of the 40 supported protocols. The same library can be used to send this codes. - If you have a bigger Arduino board at hand (> 100 kByte program space) you can try the IRremoteDecode example of the Arduino library DecodeIR. - Use IrScrutinizer. It can automatically generate a send sketch for your protocol by exporting as ""Arduino Raw"". It supports IRremote, the old IRLib and Infrared4Arduino. Hints To increase strength of sent output signal you can increase the current through the send diode, and/or use 2 diodes in series, since one IR diode requires only 1.5 volt. The line #include ""ATtinySerialOut.h"" in PinDefinitionsAndMore.h (requires the library to be installed) saves 370 bytes program space and 38 bytes RAM for Digispark boards as well as enables serial output at 8MHz. The default software generated PWM has problems on AVR running with 8 MHz. The PWM frequency is around 30 instead of 38 kHz and RC6 is not reliable. You can switch to timer PWM generation by #define SEND_PWM_BY_TIMER. Examples In order to fit the examples to the 8K flash of ATtiny85 and ATtiny88, the Arduino library ATtinySerialOut is required for this CPU's. SimpleReceiver + SimpleSender This examples are a good starting point. ReceiveDemo + SendDemo More complete examples for the advanced user. ReceiveAndSend + UnitTest ReceiveDemo + SendDemo in one program. Receiving while sending. ReceiveAndSend Record and play back last received IR signal at button press. MinimalReceiver + SmallReceiver If code size matters, look at these examples. IRDispatcherDemo Framework for calling different functions for different IR codes. IRrelay Control a relay (connected to an output pin) with your remote. IRremoteExtensionTest Example for a user defined class, which itself uses the IRrecv class from IRremote. Compile options / macros for this library To customize the library to different requirements, there are some compile options / macros available. Modify it by commenting them out or in, or change the values if applicable. Or define the macro with the -D compiler option for global compile (the latter is not possible with the Arduino IDE, so consider using Sloeber. | Name | File | Default value | Description | |-|-|-|-| | SEND_PWM_BY_TIMER | Before #include <IRremote.h> | disabled | Disable carrier PWM generation in software and use (restricted) hardware PWM except for ESP32 where both modes are using the flexible hw_timer_t. | | USE_NO_SEND_PWM | Before #include <IRremote.h> | disabled | Use no carrier PWM, just simulate an active low receiver signal. Overrides SEND_PWM_BY_TIMER definition. | | NO_LEGACY_COMPATIBILITY | IRremoteInt.h | disabled | Disables the old decoder for version 2.x compatibility, where all protocols -especially NEC, Panasonic, Sony, Samsung and JVC- were MSB first. Saves around 60 bytes program space and 14 bytes RAM. | | EXCLUDE_EXOTIC_PROTOCOLS | Before #include <IRremote.h> | disabled | If activated, BOSEWAVE, MAGIQUEST,WHYNTER and LEGO_PF are excluded in decode() and in sending with IrSender.write(). Saves up to 650 bytes program space. | | EXCLUDE_UNIVERSAL_PROTOCOLS | Before #include <IRremote.h> | disabled | If activated, the universal decoder for pulse width or pulse distance protocols and decodeHash (special decoder for all protocols) are excluded in decode(). Saves up to 1000 bytes program space. | | MARK_EXCESS_MICROS | Before #include <IRremote.h> | 20 | MARK_EXCESS_MICROS is subtracted from all marks and added to all spaces before decoding, to compensate for the signal forming of different IR receiver modules. | | RECORD_GAP_MICROS | Before #include <IRremote.h> | 5000 | Minimum gap between IR transmissions, to detect the end of a protocol.Must be greater than any space of a protocol e.g. the NEC header space of 4500 us.Must be smaller than any gap between a command and a repeat; e.g. the retransmission gap for Sony is around 24 ms.Keep in mind, that this is the delay between the end of the received command and the start of decoding. | | FEEDBACK_LED_IS_ACTIVE_LOW | Before #include <IRremote.h> | disabled | Required on some boards (like my BluePill and my ESP8266 board), where the feedback LED is active low. | | DISABLE_LED_FEEDBACK_FOR_RECEIVE | Before #include <IRremote.h> | disabled | This completely disables the LED feedback code for receive, thus saving around 108 bytes program space and halving the receiver ISR processing time. | | IR_INPUT_IS_ACTIVE_HIGH | Before #include <IRremote.h> | disabled | Enable it if you use a RF receiver, which has an active HIGH output signal. | | RAW_BUFFER_LENGTH | IRremoteInt.h | 101 | Buffer size of raw input buffer. Must be odd! | | DEBUG | IRremoteInt.h | disabled | Enables lots of lovely debug output. | | IR_SEND_DUTY_CYCLE | IRremoteInt.h | 30 | Duty cycle of IR send signal. | | MICROS_PER_TICK | IRremoteInt.h | 50 | Resolution of the raw input buffer data. | |-|-|-|-| | IR_INPUT_PIN | TinyIRReceiver.h | 2 | The pin number for TinyIRReceiver IR input, which gets compiled in. | | IR_FEEDBACK_LED_PIN | TinyIRReceiver.h | LED_BUILTIN | The pin number for TinyIRReceiver feedback LED, which gets compiled in. | | DO_NOT_USE_FEEDBACK_LED | TinyIRReceiver.h | disabled | Enable it to disable the feedback LED function. | Modifying compile options with Arduino IDE First, use Sketch > Show Sketch Folder (Ctrl+K). If you did not yet stored the example as your own sketch, then you are instantly in the right library folder. Otherwise you have to navigate to the parallel libraries folder and select the library you want to access. In both cases the library files itself are located in the src directory. Modifying compile options with Sloeber IDE If you are using Sloeber as your IDE, you can easily define global symbols with Properties > Arduino > CompileOptions. Supported Boards Arduino Uno / Mega / Leonardo / Duemilanove / Diecimila / LilyPad / Mini / Fio / Nano etc. Teensy 1.0 / 1.0++ / 2.0 / 2++ / 3.0 / 3.1 / Teensy-LC; Credits: PaulStoffregen (Teensy Team) Sanguino ATmega8, 48, 88, 168, 328 ATmega8535, 16, 32, 164, 324, 644, 1284, ATmega64, 128 ATmega4809 (Nano every) ATtiny84, 85 SAMD21 (DUE, Zero) ESP32 ESP8266. This fork supports an impressive set of protocols. Sparkfun Pro Micro Nano Every, Uno WiFi Rev2, nRF5 BBC MicroBit, Nano33_BLE We are open to suggestions for adding support to new boards, however we highly recommend you contact your supplier first and ask them to provide support from their side. Timer and pin usage The receiver sample interval is generated by a timer. On many boards this must be a hardware timer, on some a software timer is available and used. The code for the timer and the timer selection is located in private/IRTimer.cpp.h. Every pin can be used for receiving. The send PWM signal is by default generated by software. Therefore every pin can be used for sending. The PWM pulse length is guaranteed to be constant by using delayMicroseconds(). Take care not to generate interrupts during sending with software generated PWM, otherwise you will get jitter in the generated PWM. E.g. wait for a former Serial.print() statement to be finished by Serial.flush(). Since the Arduino micros() function has a resolution of 4 us at 16 MHz, we always see a small jitter in the signal, which seems to be OK for the receivers. | Software generated PWM showing small jitter because of the limited resolution of 4 us of the Arduino core micros() function for an ATmega328 | Detail (ATmega328 generated) showing 33% Duty cycle | |-|-| | | | Hardware-PWM signal generation for sending If you define SEND_PWM_BY_TIMER, the send PWM signal is generated by a hardware timer. The same timer as for the receiver is used. Since each hardware timer has its dedicated output pins, you must change timer to change PWN output. The timer and the pin usage can be adjusted in private/IRTimer.cpp.h | Board/CPU | Hardware-PWM Pin | Timers | |--------------------------------------------------------------------------|---------------------|-------------------| | ATtiny84 | 6 | 1 | | ATtiny85 > 4 MHz | 1, 4 | 0, 1 | | ATtiny1604 | PA05 | TCB0 | | ATmega8 | 9 | 1 | | ATmega48, ATmega88, ATmega168, ATmega328 | 3, 9 | 1, 2 | | ATmega1284 | 13, 14, 6 | 1, 2, 3 | | ATmega164, ATmega324, ATmega644 | 13, 14 | 1, 2 | | ATmega8535 ATmega16, ATmega32 | 13 | 1 | | ATmega64, ATmega128, ATmega1281, ATmega2561 | 13 | 1 | | ATmega8515, ATmega162 | 13 | 1 | | ATmega1280, ATmega2560 | 5, 6, 9, 11, 46 | 1, 2, 3, 4, 5 | | ATmega4809 | A4 | TCB0 | | Leonardo (Atmega32u4) | 5, 9, 13 | 1, 3, 4_HS | | Zero (SAMD) | *, 9 | TC3 | | ESP32 | 4, all pins | 1 | | Sparkfun Pro Micro | 5, 9 | 1, 3 | | Teensy 1.0 | 17 | 1 | | Teensy 2.0 | 9, 10, 14 | 1, 3, 4_HS | | Teensy++ 1.0 / 2.0 | 1, 16, 25 | 1, 2, 3 | | Teensy 3.0 / 3.1 | 5 | CMT | | Teensy-LC | 16 | TPM1 | Adding new protocols To add a new protocol is quite straightforward. Best is too look at the existing protocols to find a similar one and modify it. As a rule of thumb, it is easier to work with a description of the protocol rather than trying to entirely reverse-engineer the protocol. Please include a link to the description in the header, if you found one. The durations you receive are likely to be longer for marks and shorter for spaces than the protocol suggests, but this depends on the receiver circuit in use. Most protocols use multiples of one time-unit for marks and spaces like e.g. NEC. It's easy to be off-by-one with the last bit, since the last space is not recorded by IRremote. Try to make use of the template functions decodePulseDistanceData() and sendPulseDistanceData(). If your protocol supports address and code fields, try to reflect this in your api like it is done in sendNEC(uint16_t aAddress, uint8_t aCommand, uint_fast8_t aNumberOfRepeats, bool aIsRepeat) and decodeNEC(). Integration To integrate your protocol, you need to extend the two functions decode() and getProtocolString() in IRreceice.cpp, add macros and function declarations for sending and receiving and extend the enum decode_type_t in IRremote.h. And at least it would be wonderful if you can provide an example how to use the new protocol. A detailed description can be found in the ir_Template.cpp file. NEC encoding 8 bit address NEC code 16 bit address NEC code Revision History Please see changelog.md. API documentation See API reference in wiki. To generate the API documentation, Doxygen, as well as Graphviz should be installed. (Note that on Windows, it is useful to specify the installer to add Graphviz to PATH or to do it manually. With Doxygen and Graphviz installed, issue the command doxygen from the command line in the main project directory, which will generate the API documentation in HTML format. The just generated docs/index.html can now be opened in a browser. Why do we use 33% duty cycle We do it according to the statement in the Vishay datasheet: - Carrier duty cycle 50 %, peak current of emitter IF = 200 mA, the resulting transmission distance is 25 m. - Carrier duty cycle 10 %, peak current of emitter IF = 800 mA, the resulting transmission distance is 29 m. - Factor 1.16 The reason is, that it is not the pure energy of the fundamental which is responsible for the receiver to detect a signal. Due to automatic gain control and other bias effects high intensity and lower energy (duty cycle) of the 38 kHz pulse counts more than high low intensity and higher energy. BTW, the best way to increase the IR power is to use 2 or 3 IR diodes in series. One diode requires 1.1 to 1.5 volt so you can supply 3 diodes with a 5 volt output. To keep the current, you must reduce the resistor by (5 - 1.3) / (5 - 2.6) = 1.5 e.g. from 150 ohm to 100 ohm for 25 mA and 2 diodes with 1.3 volt and a 5 volt supply. For 3 diodes it requires factor 2.5 e.g. from 150 ohm to 60 ohm. Quick comparison of 4 Arduino IR receiving libraries Here you find an ESP8266/ESP32 version of IRremote with an impressive list of supported protocols. This is a short comparison and may not be complete or correct I created this comparison matrix for myself in order to choose a small IR lib for my project and to have a quick overview, when to choose which library. It is dated from 03.02.2021. If you have complains about the data or request for extensions, please send a PM or open a discussion. | Subject | IRMP | IRLremote | IRLib2mostly unmaintained | IRremote | Minimal NEC | |---------|------|-----------|--------|----------|----------| | Number of protocols | 50 | Nec + Panasonic + Hash * | 12 + Hash * | 17 + Hash * | NEC | | 3.Party libs needed| % | PinChangeInterrupt if not pin 2 or 3 | % | % | % | | Timing method receive | Timer2 or interrupt for pin 2 or 3 | Interrupt | Timer2 or interrupt for pin 2 or 3 | Timer2 or interrupt for NEC | Interrupt | | Timing method send | PWM and timing with Timer2 interrupts | Timer2 interrupts | Timer2 and blocking wait | PWM with Timer2 and blocking wait with delayMicroseconds() | % | | Send pins| All | All | All ? | Timer dependent | % | | Decode method | OnTheFly | OnTheFly | RAM | RAM | OnTheFly | | Encode method | OnTheFly | OnTheFly | OnTheFly | OnTheFly or RAM | % | | Callback suppport | x | % | % | % | x | | Repeat handling | Receive + Send (partially) | % | ? | Receive + Send | x | | LED feedback | x | % | x | x | x | | FLASH usage (simple NEC example with 5 prints) | 1820(4300 for 15 main / 8000 for all 40 protocols)(+200 for callback)(+80 for interrupt at pin 2+3)| 1270(1400 for pin 2+3) | 4830 | 1770 | 900 | | RAM usage | 52(73 / 100 for 15 (main) / 40 protocols) | 62 | 334 | 227 | 19 | | Supported platforms | avr, megaAVR, attiny, Digispark (Pro), esp8266, ESP32, STM32, SAMD 21, Apollo3(plus arm and pic for non Arduino IDE) | avr, esp8266 | avr, SAMD 21, SAMD 51 | avr, attiny, esp8266, esp32, SAM, SAMD | All platforms with attachInterrupt() | | Last library update | 2/2021 | 4/2018 | 9/2019 | 2/2021 | 2/2021 | | Remarks | Decodes 40 protocols concurrently.39 Protocols to send.Work in progress. | Only one protocol at a time. | Consists of 5 libraries. Project containing bugs - 45 issues, no reaction for at least one year. | Decoding and sending are easy to extend.Supports Pronto codes. | Requires no timer. | * The Hash protocol gives you a hash as code, which may be sufficient to distinguish your keys on the remote, but may not work with some protocols like Mitsubishi Contributing If you want to contribute to this project: - Report bugs and errors - Ask for enhancements - Create issues and pull requests - Tell other people about this library - Contribute new protocols Check here for some guidelines. Contributors Check here Contact Email: zetoslab@gmail.com Please only email me if it is more appropriate than creating an Issue / PR. I will not respond to requests for adding support for particular boards, unless of course you are the creator of the board and would like to cooperate on the project. I will also ignore any emails asking me to tell you how to implement your ideas. However, if you have a private inquiry that you would only apply to you and you would prefer it to be via email, by all means. License Up to the version 2.7.0 the License is GPLv2. From the version 2.8.0 the license is the MIT license. Copyright Initially coded 2009 Ken Shirriff http://www.righto.com Copyright (c) 2016 Rafi Khan Copyright (c) 2020-2021 Armin Joachimsmeyer"
4645,"Factory Bot Railsfactory_bot_rails factory_bot is a fixtures replacement with a straightforward definition syntax, support for multiple build strategies (saved instances, unsaved instances, attribute hashes, and stubbed objects), and support for multiple factories for the same class (user, admin_user, and so on), including factory inheritance. Transitioning from factory_girl_rails? Check out the guide. Rails factory_bot_rails provides Rails integration for factory_bot. Supported Rails versions are listed in Appraisals. Supported Ruby versions are listed in .travis.yml. Download Github: http://github.com/thoughtbot/factory_bot_rails Gem: $ gem install factory_bot_rails Configuration Add factory_bot_rails to your Gemfile in both the test and development groups: You may want to configure your test suite to include factory_bot methods; see configuration. Automatic Factory Definition Loading By default, factory_bot_rails will automatically load factories defined in the following locations, relative to the root of the Rails project: You can configure by adding the following to config/application.rb or the appropriate environment configuration in config/environments: This will cause factory_bot_rails to automatically load factories in custom/factories.rb and custom/factories/*.rb. It is possible to use this setting to share factories from a gem: You can also disable automatic factory definition loading entirely by using an empty array: Generators Including factory_bot_rails in the development group of your Gemfile will cause Rails to generate factories instead of fixtures. If you want to disable this feature, you can either move factory_bot_rails out of the development group of your Gemfile, or add the following configuration: If fixture replacement is enabled and you already have a test/factories.rb file (or spec/factories.rb if using rspec_rails), generated factories will be inserted at the top of the existing file. Otherwise, factories will be generated in the test/factories directory (spec/factories if using rspec_rails), in a file matching the name of the table (e.g. test/factories/users.rb). To generate factories in a different directory, you can use the following configuration: Note that factory_bot_rails will not automatically load files in custom locations unless you add them to config.factory_bot.definition_file_paths as well. The suffix option allows you to customize the name of the generated file with a suffix: This will generate test/factories/users_factory.rb instead of test/factories/users.rb. For even more customization, use the filename_proc option: To override the default factory template, define your own template in lib/templates/factory_bot/model/factories.erb. This template will have access to any methods available in FactoryBot::Generators::ModelGenerator. Note that factory_bot_rails will only use this custom template if you are generating each factory in a separate file; it will have no effect if you are generating all of your factories in test/factories.rb or spec/factories.rb. Contributing Please see CONTRIBUTING.md. factory_bot_rails was originally written by Joe Ferris and is maintained by thoughtbot. Many improvements and bugfixes were contributed by the open source community. License factory_bot_rails is Copyright 2008-2020 Joe Ferris and thoughtbot. It is free software, and may be redistributed under the terms specified in the LICENSE file. About thoughtbot factory_bot_rails is maintained and funded by thoughtbot, inc. The names and logos for thoughtbot are trademarks of thoughtbot, inc. We are passionate about open source software. See our other projects. We are available for hire."
2692,"Colored logcat script which only shows log entries for a specific application package.PID Cat An update to Jeff Sharkey's excellent logcat color script which only shows log entries for processes from a specific application package. During application development you often want to only display log messages coming from your app. Unfortunately, because the process ID changes every time you deploy to the phone it becomes a challenge to grep for the right thing. This script solves that problem by filtering by application package. Supply the target package as the sole argument to the python script and enjoy a more convenient development process. pidcat com.oprah.bees.android Here is an example of the output when running for the Google Plus app: Install Get the script: OS X: Use Homebrew. brew install pidcat If you need to install the latest development version brew unlink pidcat brew install --HEAD pidcat Arch Linux : Install the package called pidcat-git from the AUR. Others: Download the pidcat.py and place it on your PATH. Make sure that adb from the Android SDK is on your PATH. This script will not work unless this is that case. That means, when you type adb and press enter into your terminal something actually happens. To include adb and other android tools on your path: export PATH=$PATH:<path to Android SDK>/platform-tools export PATH=$PATH:<path to Android SDK>/tools Include these lines in your .bashrc or .zshrc. Note: <path to Android SDK> should be absolute and not relative. pidcat requires at least version 8.30 of coreutils. Ubuntu 20.04 LTS already ships with it, for 18.04 and below, coreutils can be upgraded from the focal repo by running the following:"
584,"JavaScript Robotics and IoT programming framework, developed at Bocoup.Johnny-Five The JavaScript Robotics Programming Framework Artwork by Mike Sgier Johnny-Five is an Open Source, Firmata Protocol based, IoT and Robotics programming framework, developed at Bocoup. Johnny-Five programs can be written for Arduino (all models), Electric Imp, Beagle Bone, Intel Galileo & Edison, Linino One, Pinoccio, pcDuino3, Raspberry Pi, Particle/Spark Core & Photon, Tessel 2, TI Launchpad and more! Johnny-Five has grown from a passion project into a tool for inspiring learning and creativity for people of all ages, backgrounds, and from all across the world. Just interested in learning and building awesome things? You might want to start with the official Johnny-Five website. The website combines content from this repo, the wiki, tutorials from the Bocoup blog and several third-party websites into a single, easily-discoverable source: If you want to find the API documentation, thats right here. Need to figure out what platform to use for a project? We put that stuff here. Need inspiration for your next NodeBot? Check out the examples. Want to stay up-to-date with projects in the community? Check this out. Need NodeBots community or Johnny-Five project updates and announcements? This is what youre looking for. Johnny-Five does not attempt to provide ""all the things"", but instead focuses on delivering robust, reality tested, highly composable APIs that behave consistently across all supported hardware platforms. Johnny-Five wants to be a baseline control kit for hardware projects, allowing you the freedom to build, grow and experiment with diverse JavaScript libraries of your own choice. Johnny-Five couples comfortably with: Popular application libraries such as Express.js and Socket.io. Fellow hardware projects like ar-drone, Aerogel and Spheron Bluetooth game controllers like XBox Controller and DualShock IoT frameworks, such as Octoblu ...And that's only a few of the many explorable possibilities. Check out these exciting projects: node-pulsesensor, footballbot-workshop-ui, nodebotui, dublin-disco, node-slot-car-bot, servo-calibrator, node-ardx, nodebot-workshop, phone-home, purple-unicorn, webduino, leapduino, lasercat-workshop, simplesense, five-redbot, robotnik, the-blender Why JavaScript? NodeBots: The Rise of JavaScript Robotics Hello Johnny The ubiquitous ""Hello World"" program of the microcontroller and SoC world is ""blink an LED"". The following code demonstrates how this is done using the Johnny-Five framework. Note: Node will crash if you try to run johnny-five in the node REPL, but board instances will create their own contextual REPL. Put your script in a file. Supported Hardware Johnny-Five has been tested on a variety of Arduino-compatible Boards. For non-Arduino based projects, a number of platform-specific IO Plugins are available. IO Plugins allow Johnny-Five code to communicate with any non-Arduino based hardware in whatever language that platforms speaks! Documentation Documentation for the Johnny-Five API can be found here and example programs here. Guidance Need help? Ask a question on the NodeBots Community Forum. If you just have a quick question or are interested in ongoing design discussions, join us in the Johnny-Five Gitter Chat. For step-by-step examples, including an electronics primer, check out Arduino Experimenter's Guide for NodeJS by @AnnaGerber Here is a list of prerequisites for Linux, OSX or Windows. Check out the bluetooth guide if you want to remotely control your robot. Setup and Assemble Arduino Recommended Starting Kit: Sparkfun Inventor's Kit Download Arduino IDE Plug in your Arduino or Arduino compatible microcontroller via USB Open the Arduino IDE, select: File > Examples > Firmata > StandardFirmataPlus StandardFirmataPlus is available in Firmata v2.5.0 or greater Click the ""Upload"" button. If the upload was successful, the board is now prepared and you can close the Arduino IDE. For non-Arduino projects, each IO Plugin's repo will provide its own platform specific setup instructions. Hey you, here's Johnny! Source Code: npm package: Install the module with: Example Programs To get you up and running quickly, we provide a variety of examples for using each Johnny-Five component. One thing were especially excited about is the extensive collection of Fritzing diagrams youll find throughout the site. A huge part of doing any Johnny-Five project is handling the actual hardware, and weve included these as part of the documentation because we realised that instructions on how to write code to control a servo are insufficient without instructions on how to connect a servo! To interactively navigate the examples, visit the Johnny-Five examples page on the official website. If you want to link directly to the examples in this repo, you can use one of the following links. There are presently 362 example programs with code and diagrams! Board Board - Basic Initialization Board - Cleanup in 'exit' event Board - Multiple in one program Board - Specify Sampling Interval Board - Specify port Custom Data Properties Pin REPL LED LED LED - Blink LED - Demo sequence LED - Fade LED - Fade callback LED - Fade with animation LED - PCA9685 LED - Pulse LED - Pulse with animation LED - Slider LED - Tessel Servo Module LEDs - An array of LEDs LEDs - Controlling an array of LEDs LED: RGB LED - RGB (Common Anode) LED - RGB (Common Anode) PCA9685 LED - RGB Intensity LED - Rainbow LED - Rainbow BlinkM LED: Digits & Matrix LED - Digital Clock LED - Digital Clock, Dual Displays LED - Digital Clock, HT16K33 LED - Draw Matrix Characters Demo LED - Enumerate Matrix Characters & Symbols LED - Matrix LED - Matrix Demo LED - Matrix HT16K33 LED - Matrix HT16K33 16x8 Servo Servo Servo - Continuous Servo - Drive Servo - Multi-Turn Servo - PCA9685 Servo - Prompt Servo - Slider control Servo - Tessel Servo Module Servos - An array of servos GPS GPS - Adafruit Ultimate GPS Breakout GPS - Default GPS GPS - Hardware Serial GPS - Sparkfun GP-20U7 Servo Animation Servo - Animation Servo - Leg Animation Color Color - EVShield EV3 (Code) Color - EVShield EV3 (Raw) Color - EVShield NXT (Code) Color - ISL29125 Motor Motor Motor - 3 pin Motor - Adafruit DRV8871 DC Motor Driver Breakout Motor - Brake Motor - Current Motor - Directional Motor - EVShield EV3 Motor - EVShield NXT Motor - Enable Pin Motor - GROVE_I2C_MOTOR_DRIVER Motor - H-Bridge Motor - LUDUS Motor - PCA9685 Motor - Pololu VNH5019 Dual Motor Driver Breakout Motor - Sparkfun Dual H-bridge Edison Block Motor - Sparkfun TB6612FNG Motor - l298 Breakout Motors - Dual H-Bridge Stepper Motor Stepper - Driver Stepper - Four Wire Stepper - Sweep ESC & Brushless Motor ESC - Bidirectional ESC - Keypress controlled ESCs ESC - PCA9685 Button / Switch Button Button - Bumper Button - EVShield EV3 Button - EVShield NXT Button - Options Button - Pullup Buttons - Collection w/ AT42QT1070 Switch Switch - Magnetic Door Switch - Tilt SW-200D Toggle Switch Keypad Keypad - 3x4 I2C Nano Backpack Keypad - 4x4 I2C Nano Backpack Keypad - VKEY Keypad - Waveshare AD Touchpad - Grove QTouch Touchpad - MPR121 Touchpad - MPR121, Sensitivity Touchpad - MPR121QR2_SHIELD Touchpad - MPR121_KEYPAD Touchpad - MPR121_SHIELD Relay Relay Relay - Collection Relay On Analog Pin Shift Register Shift Register Shift Register - Common Anode Seven Segment controller Shift Register - Common Anode Seven segments, Chained Shift Register - Seven Segment controller Shift Register - Seven segments, Chained Infrared Reflectance IR Motion IR Proximity IR Reflectance IR Reflectance Array Proximity Proximity Proximity - EVShield EV3 (IR) Proximity - EVShield EV3 (IR) Proximity - EVShield EV3 (Ultrasonic) Proximity - EVShield EV3 (Ultrasonic) Proximity - GP2Y0A710K0F Proximity - HC-SR04 Proximity - HC-SR04 (Analog) Proximity - HC-SR04 I2C Backpack Proximity - LIDAR-Lite Proximity - MB1000 Proximity - MB1003 Proximity - MB1010 Proximity - MB1230 Proximity - SRF10 Motion Motion Motion - GP2Y0A60SZLF Motion - GP2Y0D805Z0F Motion - GP2Y0D810Z0F Motion - GP2Y0D810Z0F Joystick Joystick Joystick - Esplora Joystick - Pan + Tilt control Joystick - Sparkfun Shield LCD Grove - RGB LCD Color Previewer LCD LCD - Enumerate characters LCD - I2C LCD - I2C PCF8574 LCD - I2C Runner LCD - Runner 16x2 LCD - Runner 20x4 LCD - Tessel 2 16x2 Tessel 2 + Grove - RGB LCD Color Previewer Tessel 2 + Grove - RGB LCD Display Compass/Magnetometer Compass - Find north Compass - HMC5883L Compass - HMC6352 Compass - Logger Compass - MAG3110 Compass - MAG3110 on Tessel 2 Compass / Magnetometer Piezo Piezo IMU/Multi IMU - BNO055 IMU - BNO055 (Orientation) IMU - LSM303C IMU - MPU6050 Multi - BME280 Multi - BMP085 Multi - BMP180 Multi - DHT11_I2C_NANO_BACKPACK Multi - DHT21_I2C_NANO_BACKPACK Multi - DHT22_I2C_NANO_BACKPACK Multi - HIH6130 Multi - HTU21D Multi - MPL115A2 Multi - MPL3115A2 Multi - MS5611 Multi - SHT31D Multi - SI7020 Multi - SI7021 Multi - TH02 Sensors Accelerometer Accelerometer - ADXL335 Accelerometer - ADXL345 Accelerometer - LIS3DH Accelerometer - MMA7361 Accelerometer - MMA8452 Accelerometer - MPU6050 Accelerometer - Pan + Tilt Altimeter - BMP085 Altimeter - BMP180 Altimeter - MPL3115A2 Altimeter - MS5611 Barometer - BMP085 Barometer - BMP180 Barometer - MPL115A2 Barometer - MPL3115A2 Barometer - MS5611 Gyro Gyro - Analog LPR5150AL Gyro - I2C MPU6050 Hygrometer - DHT11_I2C_NANO_BACKPACK Hygrometer - DHT21_I2C_NANO_BACKPACK Hygrometer - DHT22_I2C_NANO_BACKPACK Hygrometer - HIH6130 Hygrometer - HTU21D Hygrometer - SHT31D Hygrometer - SI7021 Hygrometer - TH02 Sensor Sensor - Digital Microwave Sensor - Flex sensor Sensor - Force sensitive resistor Sensor - Microphone Sensor - Photoresistor Sensor - Potentiometer Sensor - Slide potentiometer Thermometer - BMP085 Thermometer - BMP180 Thermometer - DHT11_I2C_NANO_BACKPACK Thermometer - DHT21_I2C_NANO_BACKPACK Thermometer - DHT22_I2C_NANO_BACKPACK Thermometer - DS18B20 Thermometer - Dual DS18B20 Thermometer - HIH6130 Thermometer - HTU21D Thermometer - LM335 Thermometer - LM35 Thermometer - MAX31850 Thermometer - MCP9808 Thermometer - MPL115A2 Thermometer - MPL3115A2 Thermometer - MPU6050 Thermometer - MS5611 Thermometer - SHT31D Thermometer - SI7020 Thermometer - SI7021 Thermometer - TH02 Thermometer - TMP102 Thermometer - TMP36 Expander Expander - 74HC595 Expander - CD74HC4067, 16 Channel Analog Input Breakout Expander - LIS3DH Expander - MCP23008 Expander - MCP23017 Expander - MUXSHIELD2, Analog Sensors Expander - MUXSHIELD2, Digital Input and Output Expander - PCA9685 Expander - PCF8574 Expander - PCF8575 Expander - PCF8591 Photon Weather Shield Photon Weather Shield: Moisture Lego EVShield Button - EVShield EV3 Button - EVShield NXT Color - EVShield EV3 (Code) Color - EVShield EV3 (Raw) Color - EVShield NXT (Code) Light - BH1750 Light - EVShield EV3 (Ambient) Light - EVShield EV3 (Reflected) Light - EVShield NXT (Ambient) Light - EVShield NXT (Reflected) Light - TSL2561 Motor - EVShield EV3 Motor - EVShield NXT Proximity - EVShield EV3 (IR) Proximity - EVShield EV3 (Ultrasonic) Intel Edison + Grove IoT Kit Intel Edison + Grove - Accelerometer (ADXL345) Intel Edison + Grove - Accelerometer (MMA7660) Intel Edison + Grove - Air quality sensor Intel Edison + Grove - Barometer (BMP180) Intel Edison + Grove - Button Intel Edison + Grove - Compass (HMC588L) Intel Edison + Grove - Flame Sensor Intel Edison + Grove - Gas (MQ2) Intel Edison + Grove - Humidity & Temperature (TH02) Intel Edison + Grove - I2C Motor Driver Intel Edison + Grove - Joystick Intel Edison + Grove - LED Intel Edison + Grove - Light Sensor (TSL2561) Intel Edison + Grove - Moisture Sensor Intel Edison + Grove - Q Touch Intel Edison + Grove - RGB LCD Intel Edison + Grove - RGB LCD Color Previewer Intel Edison + Grove - RGB LCD temperature display Intel Edison + Grove - Relay Intel Edison + Grove - Rotary Potentiometer Intel Edison + Grove - Servo Intel Edison + Grove - Touch Grove IoT Kit (Seeed Studio) Grove - Button Grove - Joystick Grove - LED Grove - Motor (I2C Driver) Grove - RGB LCD Grove - RGB LCD temperature display Grove - Rotary Potentiometer Grove - Servo Grove - Touch Micro Magician V2 Micro Magician V2 - Accelerometer Micro Magician V2 - Motor Micro Magician V2 - Servo TinkerKit TinkerKit - Accelerometer TinkerKit - Blink TinkerKit - Button TinkerKit - Combo TinkerKit - Continuous servo TinkerKit - Gyro TinkerKit - Joystick TinkerKit - Linear potentiometer TinkerKit - Rotary potentiometer TinkerKit - Temperature TinkerKit - Tilt TinkerKit - Touch Wii Wii Classic Controller Wii Nunchuck Complete Bots / Projects Bug Kinect Robotic Arm Controller Laser Trip Wire Line Follower Lynxmotion Biped BRAT Motobot Navigator Nodebot Phoenix Hexapod Radar Robotic Claw Whisker Component Plugin Template Example plugin IO Plugins Led Blink on Electric Imp Led Blink on Intel Edison Arduino Board Led Blink on Intel Edison Mini Board Led Blink on Intel Galileo Gen 2 Led Blink on Raspberry Pi Led Blink on Spark Core Led Blink on pcDuino3 Many fragments. Some large, some small. Wireless Nodebot Kinect Controlled Robot Arm Biped Nodebot LCD Running Man Slider Controlled Panning Servo Joystick Controlled Laser (pan/tilt) 1 Joystick Controlled Laser (pan/tilt) 2 Joystick Controlled Claw Robot Claw Joystick, Motor & Led Build you own drone Make: JavaScript Robotics Contributing All contributions must adhere to the Idiomatic.js Style Guide, by maintaining the existing coding style. Add unit tests for any new or changed functionality. Lint and test your code using grunt. License Copyright (c) 2012, 2013, 2014 Rick Waldron waldron.rick@gmail.com Licensed under the MIT license. Copyright (c) 2014, 2015 The Johnny-Five Contributors Licensed under the MIT license."
367,"Lovely console emulator package for WindowsCmder Cmder is a software package created out of pure frustration over absence of usable console emulator on Windows. It is based on ConEmu with major config overhaul, comes with a Monokai color scheme, amazing clink (further enhanced by clink-completions) and a custom prompt layout. Why use it The main advantage of Cmder is portability. It is designed to be totally self-contained with no external dependencies, which makes it great for USB Sticks or cloud storage. So you can carry your console, aliases and binaries (like wget, curl and git) with you anywhere. The Cmder's user interface is also designed to be more eye pleasing, and you can compare the main differences between Cmder and ConEmu here. Installation Single User Portable Config Download the latest release Extract the archive. Note: This path should not be C:\Program Files or anywhere else that would require Administrator access for modifying configuration files (optional) Place your own executable files into the %cmder_root%\bin folder to be injected into your PATH. Run Cmder.exe Shared Cmder install with Non-Portable Individual User Config Download the latest release Extract the archive to a shared location. (optional) Place your own executable files and custom app folders into the %cmder_root%\bin. See: bin/README.md This folder to be injected into your PATH by default. See /max_depth [1-5] in 'Command Line Arguments for init.bat' table to add subdirectories recursively. (optional) Place your own custom app folders into the %cmder_root%\opt. See: opt/README.md This folder will NOT be injected into your PATH so you have total control of what gets added. Run Cmder.exe with /C command line argument. Example: cmder.exe /C %userprofile%\cmder_config This will create the following directory structure if it is missing. (optional) Place your own executable files and custom app folders into %userprofile%\cmder_config\bin. This folder to be injected into your PATH by default. See /max_depth [1-5] in 'Command Line Arguments for init.bat' table to add subdirectories recursively. (optional) Place your own custom app folders into the %user_profile%\cmder_config\opt. This folder will NOT be injected into your PATH so you have total control of what gets added. Both the shared install and the individual user config locations can contain a full set of init and profile.d scripts enabling shared config with user overrides. See below. Cmder.exe Command Line Arguments | Argument | Description | | ------------------- | ----------------------------------------------------------------------- | | /C [user_root_path] | Individual user Cmder root folder. Example: %userprofile%\cmder_config | | /M | Use conemu-%computername%.xml for ConEmu settings storage instead of user_conemu.xml | | /REGISTER [ALL, USER] | Register a Windows Shell Menu shortcut. | | /UNREGISTER [ALL, USER] | Un-register a Windows Shell Menu shortcut. | | /SINGLE | Start Cmder in single mode. | | /START [start_path] | Folder path to start in. | | /TASK [task_name] | Task to start after launch. | | /X [ConEmu extras pars] | Forwads parameters to ConEmu | Context Menu Integration So you've experimented with Cmder a little and want to give it a shot in a more permanent home; Shortcut to open Cmder in a chosen folder Open a terminal as an Administrator Navigate to the directory you have placed Cmder Execute .\cmder.exe /REGISTER ALL If you get a message ""Access Denied"" ensure you are executing the command in an Administrator prompt. In a file explorer window right click in or on a directory to see ""Cmder Here"" in the context menu. Keyboard shortcuts Tab manipulation Ctrl + T : New tab dialog (maybe you want to open cmd as admin?) Ctrl + W : Close tab Ctrl + D : Close tab (if pressed on empty command) Shift + Alt + #Number : Fast new tab: 1 - CMD, 2 - PowerShell Ctrl + Tab : Switch to next tab Ctrl + Shift + Tab : Switch to previous tab Ctrl + #Number : Switch to tab #Number Alt + Enter: Fullscreen Shell Ctrl + Alt + U : Traverse up in directory structure (lovely feature!) End, Home, Ctrl : Traversing text with as usual on Windows Ctrl + R : History search Shift + Mouse : Select and copy text from buffer (Some shortcuts are not yet documented, though they exist - please document them here) Features Access to multiple shells in one window using tabs You can open multiple tabs each containing one of the following shells: | Task | Shell | Description | | ---- | ----- | ----------- | | Cmder | cmd.exe | Windows cmd.exe shell enhanced with Git, Git aware prompt, Clink (GNU Readline), and Aliases. | | Cmder as Admin | cmd.exe | Administrative Windows cmd.exe Cmder shell. | | PowerShell | powershell.exe | Windows PowerShell enhanced with Git and Git aware prompt . | | PowerShell as Admin | powershell.exe | Administrative Windows powershell.exe Cmder shell. | | Bash | bash.exe | Unix/Linux like bash shell running on Windows. | | Bash as Admin | bash.exe | Administrative Unix/Linux like bash shell running on Windows. | | Mintty | bash.exe | Unix/Linux like bash shell running on Windows. See below for Mintty configuration differences | | Mintty as Admin | bash.exe | Administrative Unix/Linux like bash shell running on Windows. See below for Mintty configuration differences | Cmder, PowerShell, and Bash tabs all run on top of the Windows Console API and work as you might expect in Cmder with access to use ConEmu's color schemes, key bindings and other settings defined in the ConEmu Settings dialog. NOTE: Only the full edition of Cmder comes with a pre-installed bash, using a vendored git-for-windows installation. The pre-configured Bash tabs may not work on Cmder mini edition without additional configuration. You may however, choose to use an external installation of bash, such as Microsoft's Subsystem for Linux (called WSL) or the Cygwin project which provides POSIX support on windows. NOTE: Mintty tabs use a program called 'mintty' as the terminal emulator that is not based on the Windows Console API, rather it's rendered graphically by ConEmu. Mintty differs from the other tabs in that it supports xterm/xterm-256color TERM types, and does not work with ConEmu settings like color schemes and key bindings. As such, some differences in functionality are to be expected, such as Cmder not being able to apply a system-wide configuration to it. As a result mintty specific config is done via the [%USERPROFILE%|$HOME]/.minttyrc file. You may read more about Mintty and its config file here. An example of setting Cmder portable terminal colors for mintty: From a bash/mintty shell: You may find some Monokai color schemes for mintty to match Cmder here. Changing Cmder Default cmd.exe Shell Startup Behaviour Using Task Arguments Press Win + Alt + T Click either: 1. {cmd::Cmder as Admin} 2. {cmd::Cmder} Add command line arguments where specified below: Note: Pay attention to the quotes! Command Line Arguments for init.bat | Argument | Description | Default | | ----------------------------- | ---------------------------------------------------------------------------------------------- | ------------------------------------- | | /c [user cmder root] | Enables user bin and config folders for 'Cmder as admin' sessions due to non-shared environment. | not set | | /d | Enables debug output. | not set | | /f | Enables Cmder Fast Init Mode. This disables some features, see pull request #1492 for more details. | not set | | /t | Enables Cmder Timed Init Mode. This displays the time taken run init scripts | not set | | /git_install_root [file path] | User specified Git installation root path. | %CMDER_ROOT%\vendor\Git-for-Windows | | /home [home folder] | User specified folder path to set %HOME% environment variable. | %userprofile% | | /max_depth [1-5] | Define max recurse depth when adding to the path for %cmder_root%\bin and %cmder_user_bin% | 1 | | /nix_tools [0-2] | Define how *nix tools are added to the path. Prefer Windows Tools: 1, Prefer *nix Tools: 2, No /usr/bin in %PATH%: 0 | 1 | | /svn_ssh [path to ssh.exe] | Define %SVN_SSH% so we can use git svn with ssh svn repositories. | %GIT_INSTALL_ROOT%\bin\ssh.exe | | /user_aliases [file path] | File path pointing to user aliases. | %CMDER_ROOT%\config\user_aliases.cmd | | /v | Enables verbose output. | not set | | (custom arguments) | User defined arguments processed by cexec. Type cexec /? for more useage. | not set | Cmder Shell User Config Single user portable configuration is possible using the cmder specific shell config files. Edit the below files to add your own configuration: | Shell | Cmder Portable User Config | | ------------- | ----------------------------------------- | | Cmder | %CMDER_ROOT%\config\user_profile.cmd | | PowerShell | $ENV:CMDER_ROOT\config\user_profile.ps1 | | Bash/Mintty | $CMDER_ROOT/config/user_profile.sh | Note: Bash and Mintty sessions will also source the $HOME/.bashrc file if it exists after it sources $CMDER_ROOT/config/user_profile.sh. You can write *.cmd|*.bat, *.ps1, and *.sh scripts and just drop them in the %CMDER_ROOT%\config\profile.d folder to add startup config to Cmder. | Shell | Cmder Profile.d Scripts | | ------------- | -------------------------------------------------- | | Cmder | %CMDER_ROOT%\config\profile.d\*.bat and *.cmd | | PowerShell | $ENV:CMDER_ROOT\config\profile.d\*.ps1 | | Bash/Mintty | $CMDER_ROOT/config/profile.d/*.sh | Git Status Opt-Out To disable Cmder prompt git status globally add the following to ~/.gitconfig or locally for a single repo [repo]/.git/config and start a new session. Note: This configuration is not portable Aliases Cmder(Cmd.exe) Aliases You can define simple aliases for cmd.exe sessions with a command like alias name=command. Cmd.exe aliases support optional parameters through the $1-9 or the $* special characters so the alias vi=vim.exe $* typed as vi [filename] will open [filename] in vim.exe. Cmd.exe aliases can also be more complex. See: DOSKEY.EXE documentation for additional details on complex aliases/macros for cmd.exe Aliases defined using the alias.bat command will automatically be saved in the %CMDER_ROOT%\config\user_aliases.cmd file To make an alias and/or any other profile settings permanent add it to one of the following: Note: These are loaded in this order by $CMDER_ROOT/vendor/init.bat. Anything stored in %CMDER_ROOT% will be a portable setting and will follow cmder to another machine. %CMDER_ROOT%\config\profile.d\*.cmd and \*.bat %CMDER_ROOT%\config\user_aliases.cmd %CMDER_ROOT%\config\user_profile.cmd Bash.exe|Mintty.exe Aliases Bash shells support simple and complex aliases with optional parameters natively so they work a little different. Typing alias name=command will create an alias only for the current running session. To make an alias and/or any other profile settings permanent add it to one of the following: Note: These are loaded in this order by $CMDER_ROOT/vendor/git-for-windows/etc/profile.d/cmder.sh. Anything stored in $CMDER_ROOT will be a portable setting and will follow cmder to another machine. $CMDER_ROOT/config/profile.d/*.sh $CMDER_ROOT/config/user_profile.sh $HOME/.bashrc If you add bash aliases to $CMDER_ROOT/config/user_profile.sh they will be portable and follow your Cmder folder if you copy it to another machine. $HOME/.bashrc defined aliases are not portable. PowerShell.exe Aliases PowerShell has native simple alias support, for example [new-alias | set-alias] alias command, so complex aliases with optional parameters are not supported in PowerShell sessions. Type get-help [new-alias|set-alias] -full for help on PowerShell aliases. To make an alias and/or any other profile settings permanent add it to one of the following: Note: These are loaded in this order by $ENV:CMDER_ROOT\vendor\user_profile.ps1. Anything stored in $ENV:CMDER_ROOT will be a portable setting and will follow cmder to another machine. $ENV:CMDER_ROOT\config\profile.d\*.ps1 $ENV:CMDER_ROOT\config\user_profile.ps1 SSH Agent To start the vendored SSH agent simply call start-ssh-agent, which is in the vendor/git-for-windows/cmd folder. If you want to run SSH agent on startup, include the line @call ""%GIT_INSTALL_ROOT%/cmd/start-ssh-agent.cmd"" in %CMDER_ROOT%/config/user_profile.cmd (usually just uncomment it). Vendored Git Cmder is by default shipped with a vendored Git installation. On each instance of launching Cmder, an attempt is made to locate any other user provided Git binaries. Upon finding a git.exe binary, Cmder further compares its version against the vendored one by executing it. The vendored git.exe binary is only used when it is more recent than the user-installed one. You may use your favorite version of Git by including its path in the %PATH% enviroment variable. Moreover, the Mini edition of Cmder (found on the downloads page) excludes any vendored Git binaries. Using external Cygwin/Babun, MSys2, WSL, or Git for Windows SDK with Cmder. You may run bash (the default shell used on Linux, macOS and GNU/Hurd) externally on Cmder, using the following instructions: Setup a new task by pressing Win +Alt + T. Click the + button to add a task. Name the new task in the top text box. Provide task parameters, this is optional. Add cmd /c ""[path_to_external_env]\bin\bash --login -i"" -new_console to the Commands text box. Recommended Optional Steps: Copy the vendor/cmder_exinit file to the Cygwin/Babun, MSys2, or Git for Windows SDK environments /etc/profile.d/ folder to use portable settings in the $CMDER_ROOT/config folder. Note: MinGW could work if the init scripts include profile.d but this has not been tested. The destination file extension depends on the shell you use in that environment. For example: bash - Copy to /etc/profile.d/cmder_exinit.sh zsh - Copy to /etc/profile.d/cmder_exinit.zsh Uncomment and edit the below line in the script to use Cmder config even when launched from outside Cmder. Customizing user sessions using init.bat custom arguments. You can pass custom arguments to init.bat and use cexec.cmd in your user_profile.cmd to evaluate these arguments then execute commands based on a particular flag being detected or not. init.bat creates two shortcuts for using cexec.cmd in your profile scripts. %ccall% - Evaluates flags, runs commands if found, and returns to the calling script and continues. Example: %ccall% /startnotepad start notepad.exe %cexec% - Evaluates flags, runs commands if found, and does not return to the calling script. Example: %cexec% /startnotepad start notepad.exe It is useful when you have multiple tasks to execute cmder and need it to initialize the session differently depending on the task chosen. To conditionally start notepad.exe when you start a specific cmder task: Press win+alt+t Click + to add a new task. Add the below to the Commands block: Add the below to your %cmder_root%\config\user_profile.cmd To see detailed usage of cexec, type cexec /? in cmder. Integrating Cmder with Hyper, Microsoft VS Code, and your favorite IDEs Cmder by default comes with a vendored ConEmu installation as the underlying terminal emulator, as stated here. However, Cmder can in fact run in a variety of other terminal emulators, and even integrated IDEs. Assuming you have the latest version of Cmder, follow the following instructions to get Cmder working with your own terminal emulator. For instructions on how to integrate Cmder with your IDE, please read our Wiki section. Upgrading The process of upgrading Cmder depends on the version/build you are currently running. If you have a [cmder_root]/config/user[-|_]conemu.xml, you are running a newer version of Cmder, follow the below process: Exit all Cmder sessions and relaunch [cmder_root]/cmder.exe, this backs up your existing [cmder_root]/vendor/conemu-maximus5/conemu.xml to [cmder_root]/config/user[-|_]conemu.xml. The [cmder_root]/config/user[-|_]conemu.xml contains any custom settings you have made using the 'Setup Tasks' settings dialog. Exit all Cmder sessions and backup any files you have manually edited under [cmder_root]/vendor. Editing files under [cmder_root]/vendor is not recommended since you will need to re-apply these changes after any upgrade. All user customizations should go in [cmder_root]/config folder. Delete the [cmder_root]/vendor folder. Extract the new cmder.zip or cmder_mini.zip into [cmder_root]/ overwriting all files when prompted. If you do not have a [cmder_root]/config/user[-|_]conemu.xml, you are running an older version of cmder, follow the below process: Exit all Cmder sessions and backup [cmder_root]/vendor/conemu-maximus5/conemu.xml to [cmder_root]/config/user[-|_]conemu.xml. Backup any files you have manually edited under [cmder_root]/vendor. Editing files under [cmder_root]/vendor is not recommended since you will need to re-apply these changes after any upgrade. All user customizations should go in [cmder_root]/config folder. Delete the [cmder_root]/vendor folder. Extract the new cmder.zip or cmder_mini.zip into [cmder_root]/ overwriting all files when prompted. Current development builds You can download builds of the current development branch by going to AppVeyor via the following link: License All software included is bundled with own license The MIT License (MIT) Copyright (c) 2016 Samuel Vasko Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the ""Software""), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
1406,"OpenRefine is a free, open source power tool for working with messy data and improving itOpenRefine OpenRefine is a Java-based power tool that allows you to load data, understand it, clean it up, reconcile it, and augment it with data coming from the web. All from a web browser and the comfort and privacy of your own computer. Download OpenRefine Releases Run from source If you have cloned this repository to your computer, you can run OpenRefine with: ./refine on Mac OS and Linux refine.bat on Windows This requires JDK 8 and Apache Maven. Documentation and Videos User Manual FAQ Official Website and tutorial videos Contributing to the project Developers Guide & Architecture Contributing Guide Project Governance Contact us Mailing List Twitter Gitter Matrix (bridged from Gitter) Licensing and legal issues OpenRefine is open source software and is licensed under the BSD license located in the LICENSE.txt. See the folder licenses for information on open source libraries that OpenRefine depends on. Credits This software was created by Metaweb Technologies, Inc. and originally written and conceived by David Huynh dfhuynh@google.com. Metaweb Technologies, Inc. was acquired by Google, Inc. in July 2010 and the product was renamed Google Refine. In October 2012, it was renamed OpenRefine as it transitioned to a community-supported product. See AUTHORS.md for the list of OpenRefine contributors and CONTRIBUTING.md for instructions on how to contribute yourself."
179,"Expressive middleware for node.js using ES2017 async functions Expressive HTTP middleware framework for node.js to make web applications and APIs more enjoyable to write. Koa's middleware stack flows in a stack-like manner, allowing you to perform actions downstream then filter and manipulate the response upstream. Only methods that are common to nearly all HTTP servers are integrated directly into Koa's small ~570 SLOC codebase. This includes things like content negotiation, normalization of node inconsistencies, redirection, and a few others. Koa is not bundled with any middleware. Installation Koa requires node v7.6.0 or higher for ES2015 and async function support. Hello Koa Getting started Kick-Off-Koa - An intro to Koa via a set of self-guided workshops. Workshop - A workshop to learn the basics of Koa, Express' spiritual successor. Introduction Screencast - An introduction to installing and getting started with Koa Middleware Koa is a middleware framework that can take two different kinds of functions as middleware: async function common function Here is an example of logger middleware with each of the different functions: async functions (node v7.6+) Common function Koa v1.x Middleware Signature The middleware signature changed between v1.x and v2.x. The older signature is deprecated. Old signature middleware support will be removed in v3 Please see the Migration Guide for more information on upgrading from v1.x and using v1.x middleware with v2.x. Context, Request and Response Each middleware receives a Koa Context object that encapsulates an incoming http message and the corresponding response to that message. ctx is often used as the parameter name for the context object. Koa provides a Request object as the request property of the Context. Koa's Request object provides helpful methods for working with http requests which delegate to an IncomingMessage from the node http module. Here is an example of checking that a requesting client supports xml. Koa provides a Response object as the response property of the Context. Koa's Response object provides helpful methods for working with http responses which delegate to a ServerResponse . Koa's pattern of delegating to Node's request and response objects rather than extending them provides a cleaner interface and reduces conflicts between different middleware and with Node itself as well as providing better support for stream handling. The IncomingMessage can still be directly accessed as the req property on the Context and ServerResponse can be directly accessed as the res property on the Context. Here is an example using Koa's Response object to stream a file as the response body. The Context object also provides shortcuts for methods on its request and response. In the prior examples, ctx.type can be used instead of ctx.response.type and ctx.accepts can be used instead of ctx.request.accepts. For more information on Request, Response and Context, see the Request API Reference, Response API Reference and Context API Reference. Koa Application The object created when executing new Koa() is known as the Koa application object. The application object is Koa's interface with node's http server and handles the registration of middleware, dispatching to the middleware from http, default error handling, as well as configuration of the context, request and response objects. Learn more about the application object in the Application API Reference. Documentation Usage Guide Error Handling Koa for Express Users FAQ API documentation Troubleshooting Check the Troubleshooting Guide or Debugging Koa in the general Koa guide. Running tests Reporting vulnerabilities To report a security vulnerability, please do not open an issue, as this notifies attackers of the vulnerability. Instead, please email dead_horse, jonathanong, and niftylettuce to disclose. Authors See AUTHORS. Community Badgeboard and list of official modules Examples Middleware list Wiki Reddit Community Mailing list v1.x v2.x #koajs on freenode Job Board Looking for a career upgrade? Backers Support us with a monthly donation and help us continue our activities. Sponsors Become a sponsor and get your logo on our README on Github with a link to your site. License MIT"
2092,"DEPRECATED: Data collection and processing made easy.This project is deprecated. Please see this email for more details. Heka Data Acquisition and Processing Made Easy Heka is a tool for collecting and collating data from a number of different sources, performing ""in-flight"" processing of collected data, and delivering the results to any number of destinations for further analysis. Heka is written in Go, but Heka plugins can be written in either Go or Lua. The easiest way to compile Heka is by sourcing (see below) the build script in the root directory of the project, which will set up a Go environment, verify the prerequisites, and install all required dependencies. The build process also provides a mechanism for easily integrating external plug-in packages into the generated hekad. For more details and additional installation options see Installing. WARNING: YOU MUST SOURCE THE BUILD SCRIPT (i.e. source build.sh) TO BUILD HEKA. Setting up the Go build environment requires changes to the shell environment, if you simply execute the script (i.e. ./build.sh) these changes will not be made. Resources: * Heka project docs: https://hekad.readthedocs.io/ * GoDoc package docs: http://godoc.org/github.com/mozilla-services/heka * Mailing list: https://mail.mozilla.org/listinfo/heka * IRC: #heka on irc.mozilla.org"
1209,"Redefined chart library built with React and D3Recharts Introduction Recharts is a Redefined chart library built with React and D3. The main purpose of this library is to help you to write charts in React applications without any pain. Main principles of Recharts are: Simply deploy with React components. Native SVG support, lightweight depending only on some D3 submodules. Declarative components, components of charts are purely presentational. Examples All the components of Recharts are clearly separated. The lineChart is composed of x axis, tooltip, grid, and line items, and each of them is an independent React Component. The clear separation and composition of components is one of the principle Recharts follows. Installation npm NPM is the easiest and fastest way to get started using Recharts. It is also the recommended installation method when building single-page applications (SPAs). It pairs nicely with a CommonJS module bundler such as Webpack. umd The UMD build is also available on unpkg.com: Then you can find the library on window.Recharts. dev build Demo To examine the demos in your local build, execute: and then browse to http://localhost:3000. Module Formats babel-plugin-recharts A simple transform to cherry-pick Recharts modules so you dont have to. Contribution We'd love :heart: to hear what you think we should build. Please create an issue to write your usage or ideas. We are looking for like-minded people who share the same idea about Recharts. The goal of this project is to create a more flexible charting library for the React community. Backers Become a backer and get your image on our README on Github with a link to your site. Sponsoring Most of the core team members do this open source work in their free time. If you use recharts for a important work, and you'd like us to invest more time on it, please donate. Thanks! License MIT Copyright (c) 2015-2021 Recharts Group."
624,"node.js command-line interfaces made easyCommander.js The complete solution for node.js command-line interfaces. Read this in other languages: English | Commander.js Installation Declaring program variable Options Common option types, boolean and value Default option value Other option types, negatable boolean and boolean|value Required option Variadic option Version option More configuration Custom option processing Commands Specify the argument syntax Action handler Stand-alone executable (sub)commands Automated help Custom help Display help from code .usage and .name .helpOption(flags, description) .addHelpCommand() More configuration Custom event listeners Bits and pieces .parse() and .parseAsync() Parsing Configuration Legacy options as properties TypeScript createCommand() Node options such as --harmony Debugging stand-alone executable subcommands Override exit and output handling Additional documentation Examples Support Commander for enterprise For information about terms used in this document see: terminology Installation Declaring program variable Commander exports a global object which is convenient for quick programs. This is used in the examples in this README for brevity. For larger programs which may use commander in multiple ways, including unit testing, it is better to create a local Command object to use. For named imports in ECMAScript modules, import from commander/esm.mjs. And in TypeScript: Options Options are defined with the .option() method, also serving as documentation for the options. Each option can have a short flag (single character) and a long name, separated by a comma or space or vertical bar ('|'). The parsed options can be accessed by calling .opts() on a Command object, and are passed to the action handler. Multi-word options such as ""--template-engine"" are camel-cased, becoming program.opts().templateEngine etc. Multiple short flags may optionally be combined in a single argument following the dash: boolean flags, followed by a single option taking a value (possibly followed by the value). For example -a -b -p 80 may be written as -ab -p80 or even -abp80. You can use -- to indicate the end of the options, and any remaining arguments will be used without being interpreted. By default options on the command line are not positional, and can be specified before or after other arguments. Common option types, boolean and value The two most used option types are a boolean option, and an option which takes its value from the following argument (declared with angle brackets like --expect <value>). Both are undefined unless specified on command line. Example file: options-common.js program.parse(arguments) processes the arguments, leaving any args not consumed by the program options in the program.args array. The parameter is optional and defaults to process.argv. Default option value You can specify a default value for an option which takes a value. Example file: options-defaults.js Other option types, negatable boolean and boolean|value You can define a boolean option long name with a leading no- to set the option value to false when used. Defined alone this also makes the option true by default. If you define --foo first, adding --no-foo does not change the default value from what it would otherwise be. You can specify a default boolean value for a boolean option and it can be overridden on command line. Example file: options-negatable.js You can specify an option which may be used as a boolean option but may optionally take an option-argument (declared with square brackets like --optional [value]). Example file: options-boolean-or-value.js For information about possible ambiguous cases, see options taking varying arguments. Required option You may specify a required (mandatory) option using .requiredOption. The option must have a value after parsing, usually specified on the command line, or perhaps from a default value (say from environment). The method is otherwise the same as .option in format, taking flags and description, and optional default value or custom processing. Example file: options-required.js Variadic option You may make an option variadic by appending ... to the value placeholder when declaring the option. On the command line you can then specify multiple option-arguments, and the parsed option value will be an array. The extra arguments are read until the first argument starting with a dash. The special argument -- stops option processing entirely. If a value is specified in the same argument as the option then no further values are read. Example file: options-variadic.js For information about possible ambiguous cases, see options taking varying arguments. Version option The optional version method adds handling for displaying the command version. The default option flags are -V and --version, and when present the command prints the version number and exits. You may change the flags and description by passing additional parameters to the version method, using the same syntax for flags as the option method. More configuration You can add most options using the .option() method, but there are some additional features available by constructing an Option explicitly for less common cases. Example file: options-extra.js Custom option processing You may specify a function to do custom processing of option-arguments. The callback function receives two parameters, the user specified option-argument and the previous value for the option. It returns the new value for the option. This allows you to coerce the option-argument to the desired type, or accumulate values, or do entirely custom processing. You can optionally specify the default/starting value for the option after the function parameter. Example file: options-custom-processing.js Commands You can specify (sub)commands using .command() or .addCommand(). There are two ways these can be implemented: using an action handler attached to the command, or as a stand-alone executable file (described in more detail later). The subcommands may be nested (example). In the first parameter to .command() you specify the command name and any command-arguments. The arguments may be <required> or [optional], and the last argument may also be variadic.... You can use .addCommand() to add an already configured subcommand to the program. For example: Configuration options can be passed with the call to .command() and .addCommand(). Specifying hidden: true will remove the command from the generated help output. Specifying isDefault: true will run the subcommand if no other subcommand is specified (example). Specify the argument syntax You use .arguments to specify the expected command-arguments for the top-level command, and for subcommands they are usually included in the .command call. Angled brackets (e.g. <required>) indicate required command-arguments. Square brackets (e.g. [optional]) indicate optional command-arguments. You can optionally describe the arguments in the help by supplying a hash as second parameter to .description(). Example file: arguments.js The last argument of a command can be variadic, and only the last argument. To make an argument variadic you append ... to the argument name. For example: The variadic argument is passed to the action handler as an array. Action handler The action handler gets passed a parameter for each command-argument you declared, and two additional parameters which are the parsed options and the command object itself. Example file: thank.js You may supply an async action handler, in which case you call .parseAsync rather than .parse. A command's options and arguments on the command line are validated when the command is used. Any unknown options or missing arguments will be reported as an error. You can suppress the unknown option checks with .allowUnknownOption(). By default it is not an error to pass more arguments than declared, but you can make this an error with .allowExcessArguments(false). Stand-alone executable (sub)commands When .command() is invoked with a description argument, this tells Commander that you're going to use stand-alone executables for subcommands. Commander will search the executables in the directory of the entry script (like ./examples/pm) with the name program-subcommand, like pm-install, pm-search. You can specify a custom name with the executableFile configuration option. You handle the options for an executable (sub)command in the executable, and don't declare them at the top-level. Example file: pm If the program is designed to be installed globally, make sure the executables have proper modes, like 755. Automated help The help information is auto-generated based on the information commander already knows about your program. The default help option is -h,--help. Example file: pizza A help command is added by default if your command has subcommands. It can be used alone, or with a subcommand name to show further help for the subcommand. These are effectively the same if the shell program has implicit help: Custom help You can add extra text to be displayed along with the built-in help. Example file: custom-help Yields the following help output: The positions in order displayed are: beforeAll: add to the program for a global banner or header before: display extra information before built-in help after: display extra information after built-in help afterAll: add to the program for a global footer (epilog) The positions ""beforeAll"" and ""afterAll"" apply to the command and all its subcommands. The second parameter can be a string, or a function returning a string. The function is passed a context object for your convenience. The properties are: error: a boolean for whether the help is being displayed due to a usage error command: the Command which is displaying the help Display help from code .help(): display help information and exit immediately. You can optionally pass { error: true } to display on stderr and exit with an error status. .outputHelp(): output help information without exiting. You can optionally pass { error: true } to display on stderr. .helpInformation(): get the built-in command help information as a string for processing or displaying yourself. .usage and .name These allow you to customise the usage description in the first line of the help. The name is otherwise deduced from the (full) program arguments. Given: The help will start with: .helpOption(flags, description) By default every command has a help option. Override the default help flags and description. Pass false to disable the built-in help option. .addHelpCommand() A help command is added by default if your command has subcommands. You can explicitly turn on or off the implicit help command with .addHelpCommand() and .addHelpCommand(false). You can both turn on and customise the help command by supplying the name and description: More configuration The built-in help is formatted using the Help class. You can configure the Help behaviour by modifying data properties and methods using .configureHelp(), or by subclassing using .createHelp() if you prefer. The data properties are: helpWidth: specify the wrap width, useful for unit tests sortSubcommands: sort the subcommands alphabetically sortOptions: sort the options alphabetically There are methods getting the visible lists of arguments, options, and subcommands. There are methods for formatting the items in the lists, with each item having a term and description. Take a look at .formatHelp() to see how they are used. Example file: configure-help.js Custom event listeners You can execute custom actions by listening to command and option events. Bits and pieces .parse() and .parseAsync() The first argument to .parse is the array of strings to parse. You may omit the parameter to implicitly use process.argv. If the arguments follow different conventions than node you can pass a from option in the second parameter: 'node': default, argv[0] is the application and argv[1] is the script being run, with user parameters after that 'electron': argv[1] varies depending on whether the electron application is packaged 'user': all of the arguments from the user For example: Parsing Configuration If the default parsing does not suit your needs, there are some behaviours to support other usage patterns. By default program options are recognised before and after subcommands. To only look for program options before subcommands, use .enablePositionalOptions(). This lets you use an option for a different purpose in subcommands. Example file: positional-options.js With positional options, the -b is a program option in the first line and a subcommand option in the second line: By default options are recognised before and after command-arguments. To only process options that come before the command-arguments, use .passThroughOptions(). This lets you pass the arguments and following options through to another program without needing to use -- to end the option processing. To use pass through options in a subcommand, the program needs to enable positional options. Example file: pass-through-options.js With pass through options, the --port=80 is a program option in the first line and passed through as a command-argument in the second line: By default the option processing shows an error for an unknown option. To have an unknown option treated as an ordinary command-argument and continue looking for options, use .allowUnknownOption(). This lets you mix known and unknown options. By default the argument processing does not display an error for more command-arguments than expected. To display an error for excess arguments, use.allowExcessArguments(false). Legacy options as properties Before Commander 7, the option values were stored as properties on the command. This was convenient to code but the downside was possible clashes with existing properties of Command. You can revert to the old behaviour to run unmodified legacy code by using .storeOptionsAsProperties(). TypeScript If you use ts-node and stand-alone executable subcommands written as .ts files, you need to call your program through node to get the subcommands called correctly. e.g. createCommand() This factory function creates a new command. It is exported and may be used instead of using new, like: createCommand is also a method of the Command object, and creates a new command rather than a subcommand. This gets used internally when creating subcommands using .command(), and you may override it to customise the new subcommand (example file custom-command-class.js). Node options such as --harmony You can enable --harmony option in two ways: Use #! /usr/bin/env node --harmony in the subcommands scripts. (Note Windows does not support this pattern.) Use the --harmony option when call the command, like node --harmony examples/pm publish. The --harmony option will be preserved when spawning subcommand process. Debugging stand-alone executable subcommands An executable subcommand is launched as a separate child process. If you are using the node inspector for debugging executable subcommands using node --inspect et al, the inspector port is incremented by 1 for the spawned subcommand. If you are using VSCode to debug executable subcommands you need to set the ""autoAttachChildProcesses"": true flag in your launch.json configuration. Override exit and output handling By default Commander calls process.exit when it detects errors, or after displaying the help or version. You can override this behaviour and optionally supply a callback. The default override throws a CommanderError. The override callback is passed a CommanderError with properties exitCode number, code string, and message. The default override behaviour is to throw the error, except for async handling of executable subcommand completion which carries on. The normal display of error messages or version or help is not affected by the override which is called after the display. By default Commander is configured for a command-line application and writes to stdout and stderr. You can modify this behaviour for custom applications. In addition, you can modify the display of error messages. Example file: configure-output.js Additional documentation There is more information available about: deprecated features still supported for backwards compatibility options taking varying arguments Examples In a single command program, you might not need an action handler. Example file: pizza In a multi-command program, you will have action handlers for each command (or stand-alone executables for the commands). Example file: deploy More samples can be found in the examples directory. Support The current version of Commander is fully supported on Long Term Support versions of node, and requires at least node v10. (For older versions of node, use an older version of Commander. Commander version 2.x has the widest support.) The main forum for free and community support is the project Issues on GitHub. Commander for enterprise Available as part of the Tidelift Subscription The maintainers of Commander and thousands of other packages are working with Tidelift to deliver commercial support and maintenance for the open source dependencies you use to build your applications. Save time, reduce risk, and improve code health, while paying the maintainers of the exact dependencies you use. Learn more."
1425,"Docker + Minecraft = DockercraftDockercraft A simple Minecraft Docker client, to visualize and manage Docker containers. YouTube video WARNING: Please use Dockercraft on your local machine only. It currently doesn't support authentication. Every player should be considered a root user! How to run Dockercraft Install Minecraft: minecraft.net The Minecraft client hasn't been modified, just get the official release. Pull or build Dockercraft image: (an official image will be available soon) or Run Dockercraft container: Mounting /var/run/docker.sock inside the container is necessary to send requests to the Docker remote API. The default port for a Minecraft server is 25565, if you prefer a different one: -p <port>:25565 Open Minecraft > Multiplayer > Add Server The server address is the IP of Docker host. No need to specify a port if you used the default one. If you're using Docker Machine: docker-machine ip <machine_name> Join Server! You should see at least one container in your world, which is the one hosting your Dockercraft server. You can start, stop and remove containers interacting with levers and buttons. Some Docker commands are also supported directly via Minecraft's chat window, which is displayed by pressing the T key (default) or / key. A command always starts with a /. If you open the prompt using the / key, it will be prefilled with a / character, but if you open it with the T key, it will not be prefilled and you will have to type a / yourself before typing your docker command. example: /docker run redis. Customizing Dockercraft Do you find the plains too plain? If so, you are in luck! Dockercraft can be customised to use any of the Biomes and Finishers supported by Cuberite! You can pass these additional arguments to your docker run command: Here are some examples: Do you long for the calm of the oceans? Try Ocean 50 63, or for a more frozen alternative, FrozenOcean 50 63 Ice Or perhaps the heat of the desert? Then Desert 63 0 DeadBushes is what you need Are you pining for the... Pines? We have you covered. Try Forest 63 0 Trees Or maybe you are looking for fun and games? If so, Welcome to the Jungle. Jungle 63 0 Trees Upcoming features This is just the beginning for Dockercraft! We should be able to support a lot more Docker features like: List Docker Machines and use portals to see what's inside Support more Docker commands Display logs (for each container, pushing a simple button) Represent links Docker networking Docker volumes ... If you're interested about Dockercraft's design, discussions happen in that issue. Also, we're using Magicavoxel to do these nice prototypes: You can find our Magicavoxel patterns in that folder. To get fresh news, follow our Twitter account: @dockercraft. How it works The Minecraft client itself remains unmodified. All operations are done server side. The Minecraft server we use is http://cuberite.org. A custom Minecraft compatible game server written in C++. github repo This server accepts plugins, scripts written in Lua. So we did one for Docker. (world/Plugins/Docker) Unfortunately, there's no nice API to communicate with these plugins. But there's a webadmin, and plugins can be responsible for ""webtabs"". Basically it means the plugin can catch POST requests sent to http://127.0.0.1:8080/webadmin/Docker/Docker. Goproxy Events from the Docker remote API are transmitted to the Lua plugin by a small daemon (written in Go). (go/src/goproxy) The goproxy binary can also be executed with parameters from the Lua plugin, to send requests to the daemon: Contributing Want to hack on Dockercraft? Docker's contributions guidelines apply."
2850,"A Grunt workflow for designing and testing responsive HTML email templates with SCSS.Grunt Email Design Workflow Designing and testing emails is a pain. HTML tables, inline CSS, various devices and clients to test, and varying support for the latest web standards. This Grunt task helps simplify things. Compiles your SCSS to CSS Builds your HTML email templates Inlines your CSS Compresses and uploads images to a CDN such as Rackspace Cloud or AWS S3 (optional) Replaces the image URLs with the urls that point to the CDN images (optional) Sends a test email to your inbox or Litmus (optional) Requirements You may already have these installed on your system. If not, you'll have to install them. Node.js - Install Node.js NVM - Install node version manager Grunt-cli and Grunt (npm install grunt-cli -g) Mailgun (optional) - Sends the email Litmus (optional) - Tests the email across all clients/browsers/devices Rackspace Cloud (optional) - Uses Cloud Files as a CDN Getting started If you haven't used Grunt before check out Chris Coyier's post on getting started with Grunt. 1. Setup Clone this repo, cd to the directory, run nvm use (to set correct node version) and npm install to install the necessary packages. 2. Create secrets.json Create a secrets.json file in your project root as outlined below under ""Sensitive Information"". 3. Run Grunt Run grunt in command line and check out your /dist folder to see your compiled and inlined email templates. Sensitive information We encourage you not to store sensitive data in your git repository. If you must, please look into git-encrypt or some other method of encrypting your configuration secrets. Create a file secrets.json in your project root. Paste the following sample code in secrets.json and enter the appropriate credentials for the services you want to connect with. If you don't use or need these services it's ok to leave these defaults, but they should exist for this to work. After this you should be good to go. Run grunt and your email templates should appear automagically in a /dist folder. How it works CSS This project uses SCSS. You don't need to touch the .css files, these are compiled automatically. For changes to CSS, modify the .scss files. Media queries and responsive styles are in a separate style sheet so that they don't get inlined. Note that only a few clients support media queries e.g. iOS Mail app. Email templates and content Handlebars and Assemble are used for templating. /layouts contains the standard header/footer HTML wrapper markup. You most likely will only need one layout template, but you can have as many as you like. /emails is where your email content will go. To start you off I've included example transactional emails based on my simple HTML email template. /data contains optional .yml or .json data files that can be used in your templates. It's a good way to store commonly used strings and variables. See /data/default.yml and /partials/follow_lee.hbs for an example. /partials contains optional .hbs files that can be thought of like includes. To use a partial, for example /partials/follow_lee.hbs you would use the following code in your emails template: /partials/components contains optional .hbs files that can help generate your markup. Each component will typically have a corresponding Sass file in src/css/sass/<component_name>.scss. To use a component, for example /partials/components/button.hbs you would use the following code in your emails template. (note: You can use single -or- double quotes for attributes) Generate your email templates In Terminal/command-line, run grunt. This will: Compile your SCSS to CSS Generate your email layout and content Inline your CSS Compress your images See the output HTML in the dist folder. Open them and preview it the browser. Alternatively run grunt serve. This will check for any changes you make to your .scss and .hbs templates, automatically run the tasks, and serve you a preview in the browser on http://localhost:4000. Saves you having to run grunt every time you make a change. Browser-based previews In terminal, run grunt serve. This will run the default tasks grunt + the watch task will be initiated A preview UI will automagically open on http://localhost:4000 and you can review your templates Go about your business editing templates and see your template changes live-reload NOTE: The express server stops working when the watch task is not running Send the email to yourself Sign up for a Mailgun account (it's free) Insert your Mailgun API key, either in Gruntfile.js or secrets.json Change the sender and recipient to your own email address (or whoever you want to send it to) Run grunt send --template=TEMPLATE_NAME.html. This will email out the template you specify. Change 'transaction.html' to the name of the email template you want to send. If the email contains images, you will need to pass an additional directive to grunt to have it first upload the images to a CDN and replace the image urls in the email template. See the CDN and working with image assets section below. How to test with Litmus If you have a Litmus account and want to test the email in multiple clients/devices: Open up Gruntfile.js or secrets.json Replace username, password and yourcompany under the Litmus task with your credentials Run grunt litmus --template=TEMPLATE_NAME.html to send the email to Litmus. This will create a new test using the <title> value of your template. See the Litmus results for the simple transactional email template that is included. Using Rackspace Cloud as a CDN to serve image assets If your email contains images you'll want to serve them from a CDN. This Gruntfile has support for Rackspace Cloud Files (pricing) and AWS S3. Sign up for a Rackspace Cloud account (use the Developer Discount for $300 credit) Create a new Cloud Files container Open up Gruntfile.js or secrets.json Change 'cloudfiles' settings to your settings (you can find your Rackspace API key under your account settings) Make any other config changes as per grunt-cloudfiles instructions Run grunt rsupload to run the default tasks as well as upload any images to your CDN. Run grunt rsupload send --template=branded.html to send the email to yourself with the 'CDNified' images. Using Amazon S3 as a CDN to serve image assets Another option for serving images is to use Amazon S3. Basic service is free of charge. For more information on setting up an account, visit Amazon. The Gruntfile uses grunt-aws-s3. Once your AWS account is setup, create a Bucket within S3. You will need to ensure your Bucket has a policy setup under Permissions. Below is a very loose sample policy for testing purposes. You should read up on AWS Identity and Access Management for more information. Sample S3 Bucket Policy Run grunt s3upload to upload images to your S3 Bucket. This will also run a replace task to change image paths within the destination directory to use the new S3 path. Run grunt s3upload send --template=branded.html to send the email to yourself with the 'CDNified' images. Sample email templates I've added a few templates here to help you get started. Simple transactional email template Branded email via CDN Email with components More resources For more transactional email templates check out HTML Email templates Things I've learned about sending email Things I've learned about building email templates Things I've learned about responsive email Prefer Gulp? Daryll Doyle has created a Gulp email creator"
296,"A collection of design patterns/idioms in Pythonpython-patterns A collection of design patterns and idioms in Python. Current Patterns Creational Patterns: | Pattern | Description | |:-------:| ----------- | | abstract_factory | use a generic function with specific factories | | borg | a singleton with shared-state among instances | | builder | instead of using multiple constructors, builder object receives parameters and returns constructed objects | | factory | delegate a specialized function/method to create instances | | lazy_evaluation | lazily-evaluated property pattern in Python | | pool | preinstantiate and maintain a group of instances of the same type | | prototype | use a factory and clones of a prototype for new instances (if instantiation is expensive) | Structural Patterns: | Pattern | Description | |:-------:| ----------- | | 3-tier | data<->business logic<->presentation separation (strict relationships) | | adapter | adapt one interface to another using a white-list | | bridge | a client-provider middleman to soften interface changes | | composite | lets clients treat individual objects and compositions uniformly | | decorator | wrap functionality with other functionality in order to affect outputs | | facade | use one class as an API to a number of others | | flyweight | transparently reuse existing instances of objects with similar/identical state | | front_controller | single handler requests coming to the application | | mvc | model<->view<->controller (non-strict relationships) | | proxy | an object funnels operations to something else | Behavioral Patterns: | Pattern | Description | |:-------:| ----------- | | chain_of_responsibility | apply a chain of successive handlers to try and process the data | | catalog | general methods will call different specialized methods based on construction parameter | | chaining_method | continue callback next object method | | command | bundle a command and arguments to call later | | iterator | traverse a container and access the container's elements | | iterator (alt. impl.)| traverse a container and access the container's elements | | mediator | an object that knows how to connect other objects and act as a proxy | | memento | generate an opaque token that can be used to go back to a previous state | | observer | provide a callback for notification of events/changes to data | | publish_subscribe | a source syndicates events/data to 0+ registered listeners | | registry | keep track of all subclasses of a given class | | specification | business rules can be recombined by chaining the business rules together using boolean logic | | state | logic is organized into a discrete number of potential states and the next state that can be transitioned to | | strategy | selectable operations over the same data | | template | an object imposes a structure but takes pluggable components | | visitor | invoke a callback for all items of a collection | Design for Testability Patterns: | Pattern | Description | |:-------:| ----------- | | dependency_injection | 3 variants of dependency injection | Fundamental Patterns: | Pattern | Description | |:-------:| ----------- | | delegation_pattern | an object handles a request by delegating to a second object (the delegate) | Others: | Pattern | Description | |:-------:| ----------- | | blackboard | architectural model, assemble different sub-system knowledge to build a solution, AI approach - non gang of four pattern | | graph_search | graphing algorithms - non gang of four pattern | | hsm | hierarchical state machine - non gang of four pattern | Videos Design Patterns in Python by Peter Ullrich Sebastian Buczyski - Why you don't need design patterns in Python? You Don't Need That! Pluggable Libs Through Design Patterns Contributing When an implementation is added or modified, please review the following guidelines: Output All files with example patterns have ### OUTPUT ### section at the bottom (migration to OUTPUT = """"""..."""""" is in progress). Run append_output.sh (e.g. ./append_output.sh borg.py) to generate/update it. Docstrings Add module level description in form of a docstring with links to corresponding references or other useful information. Add ""Examples in Python ecosystem"" section if you know some. It shows how patterns could be applied to real-world problems. facade.py has a good example of detailed description, but sometimes the shorter one as in template.py would suffice. In some cases class-level docstring with doctest would also help (see adapter.py) but readable OUTPUT section is much better. Python 2 compatibility To see Python 2 compatible versions of some patterns please check-out the legacy tag. Update README When everything else is done - update corresponding part of README. Travis CI Please run tox or tox -e ci37 before submitting a patch to be sure your changes will pass CI. You can also run flake8 or pytest commands manually. Examples can be found in tox.ini. Contributing via issue triage You can triage issues and pull requests which may include reproducing bug reports or asking for vital information, such as version numbers or reproduction instructions. If you would like to start triaging issues, one easy way to get started is to subscribe to python-patterns on CodeTriage."
2586,"Angular.js Mobile UI Framework with Bootstrap 3Mobile Angular UI Angular & Bootstrap 3 for Mobile web and applications Mobile Angular UI is an HTML5 mobile UI framework that will let you use Angular Js and Bootstrap 3 for mobile app development. Getting Started, Demo, Docs at http://mobileangularui.com. Support development Released Under MIT License."
4750,"[DEPRECATED] A repository for sharing D3.js V3 plugins.D3 Plugins These plugins are not compatible with the latest version of D3, V4. For the latest versions, see: d3-hexbin d3-sankey Please note: the plugins in this repository will soon be broken up into separate repositories for easier distributed ownership. If you have a new plugin youd like to share, please add a link to it from the D3 plugins wiki."
1041,"Rails for API only applicationsRails::API IMPORTANT: Rails::API has been merged into Rails Rails::API is a subset of a normal Rails application, created for applications that don't require all functionality that a complete Rails application provides. It is a bit more lightweight, and consequently a bit faster than a normal Rails application. The main example for its usage is in API applications only, where you usually don't need the entire Rails middleware stack nor template generation. Using Rails for API-only Apps This is a quick walk-through to help you get up and running with Rails::API to create API-only Apps, covering: What Rails::API provides for API-only applications How to decide which middlewares you will want to include How to decide which modules to use in your controller What is an API app? Traditionally, when people said that they used Rails as an ""API"", they meant providing a programmatically accessible API alongside their web application. For example, GitHub provides an API that you can use from your own custom clients. With the advent of client-side frameworks, more developers are using Rails to build a backend that is shared between their web application and other native applications. For example, Twitter uses its public API in its web application, which is built as a static site that consumes JSON resources. Instead of using Rails to generate dynamic HTML that will communicate with the server through forms and links, many developers are treating their web application as just another client, consuming a simple JSON API. This guide covers building a Rails application that serves JSON resources to an API client or client-side framework. Why use Rails for JSON APIs? The first question a lot of people have when thinking about building a JSON API using Rails is: ""isn't using Rails to spit out some JSON overkill? Shouldn't I just use something like Sinatra?"" For very simple APIs, this may be true. However, even in very HTML-heavy applications, most of an application's logic is actually outside of the view layer. The reason most people use Rails is that it provides a set of defaults that allows us to get up and running quickly without having to make a lot of trivial decisions. Let's take a look at some of the things that Rails provides out of the box that are still applicable to API applications. Handled at the middleware layer: Reloading: Rails applications support transparent reloading. This works even if your application gets big and restarting the server for every request becomes non-viable. Development Mode: Rails application come with smart defaults for development, making development pleasant without compromising production-time performance. Test Mode: Ditto test mode. Logging: Rails applications log every request, with a level of verbosity appropriate for the current mode. Rails logs in development include information about the request environment, database queries, and basic performance information. Security: Rails detects and thwarts IP spoofing attacks and handles cryptographic signatures in a timing attack aware way. Don't know what an IP spoofing attack or a timing attack is? Exactly. Parameter Parsing: Want to specify your parameters as JSON instead of as a URL-encoded String? No problem. Rails will decode the JSON for you and make it available in params. Want to use nested URL-encoded params? That works too. Conditional GETs: Rails handles conditional GET, (ETag and Last-Modified), processing request headers and returning the correct response headers and status code. All you need to do is use the stale? check in your controller, and Rails will handle all of the HTTP details for you. Caching: If you use dirty? with public cache control, Rails will automatically cache your responses. You can easily configure the cache store. HEAD requests: Rails will transparently convert HEAD requests into GET requests, and return just the headers on the way out. This makes HEAD work reliably in all Rails APIs. While you could obviously build these up in terms of existing Rack middlewares, I think this list demonstrates that the default Rails middleware stack provides a lot of value, even if you're ""just generating JSON"". Handled at the ActionPack layer: Resourceful Routing: If you're building a RESTful JSON API, you want to be using the Rails router. Clean and conventional mapping from HTTP to controllers means not having to spend time thinking about how to model your API in terms of HTTP. URL Generation: The flip side of routing is URL generation. A good API based on HTTP includes URLs (see the GitHub gist API for an example). Header and Redirection Responses: head :no_content and redirect_to user_url(current_user) come in handy. Sure, you could manually add the response headers, but why? Basic, Digest and Token Authentication: Rails comes with out-of-the-box support for three kinds of HTTP authentication. Instrumentation: Rails 3.0 added an instrumentation API that will trigger registered handlers for a variety of events, such as action processing, sending a file or data, redirection, and database queries. The payload of each event comes with relevant information (for the action processing event, the payload includes the controller, action, params, request format, request method and the request's full path). Generators: This may be pass for advanced Rails users, but it can be nice to generate a resource and get your model, controller, test stubs, and routes created for you in a single command. Plugins: Many third-party libraries come with support for Rails that reduces or eliminates the cost of setting up and gluing together the library and the web framework. This includes things like overriding default generators, adding rake tasks, and honoring Rails choices (like the logger and cache backend). Of course, the Rails boot process also glues together all registered components. For example, the Rails boot process is what uses your config/database.yml file when configuring ActiveRecord. The short version is: you may not have thought about which parts of Rails are still applicable even if you remove the view layer, but the answer turns out to be ""most of it"". The Basic Configuration If you're building a Rails application that will be an API server first and foremost, you can start with a more limited subset of Rails and add in features as needed. NOTE: rails-api only supports Ruby 1.9.3 and above. For new apps Install the gem if you haven't already: gem install rails-api Then generate a new Rails::API app: rails-api new my_api This will do two main things for you: Make ApplicationController inherit from ActionController::API instead of ActionController::Base. As with middleware, this will leave out any ActionController modules that provide functionality primarily used by browser applications. Configure the generators to skip generating views, helpers and assets when you generate a new resource. Rails includes all of the sub-frameworks (ActiveRecord, ActionMailer, etc) by default. Some API projects won't need them all, so at the top of config/application.rb, you can replace require 'rails/all' with specific sub-frameworks: # config/application.rb # require ""active_record/railtie"" require ""action_controller/railtie"" require ""action_mailer/railtie"" # require ""sprockets/railtie"" require ""rails/test_unit/railtie"" This can also be achieved with flags when creating a new Rails::API app: rails-api new my_api --skip-active-record --skip-sprockets Note: There are references to ActionMailer and ActiveRecord in the various config/environment files. If you decide to exclude any of these from your project its best to comment these out in case you need them later. # comment out this in config/environments/development.rb config.active_record.migration_error = :page_load config.action_mailer.raise_delivery_errors = false # comment out this in config/environments/test.rb config.action_mailer.delivery_method = :test For already existing apps If you want to take an existing app and make it a Rails::API app, you'll have to do some quick setup manually. Add the gem to your Gemfile: gem 'rails-api' And run bundle to install the gem. Change app/controllers/application_controller.rb: And comment out the protect_from_forgery call if you are using it. (You aren't using cookie-based authentication for your API, are you?) If you want to use the Rails default middleware stack (avoid the reduction that rails-api does), you can just add config.api_only = false to config/application.rb file. Serialization We suggest using ActiveModel::Serializers to serialize your ActiveModel/ActiveRecord objects into the desired response format (e.g. JSON). Choosing Middlewares An API application comes with the following middlewares by default. ActionDispatch::DebugExceptions: Log exceptions. ActionDispatch::ParamsParser: Parse XML, YAML and JSON parameters when the request's Content-Type is one of those. ActionDispatch::Reloader: In development mode, support code reloading. ActionDispatch::RemoteIp: Protect against IP spoofing attacks. ActionDispatch::RequestId: Makes a unique request id available, sending the id to the client via the X-Request-Id header. The unique request id can be used to trace a request end-to-end and would typically end up being part of log files from multiple pieces of the stack. ActionDispatch::ShowExceptions: Rescue exceptions and re-dispatch them to an exception handling application. Rack::Cache: Caches responses with public Cache-Control headers using HTTP caching semantics. Rack::Head: Dispatch HEAD requests as GET requests, and return only the status code and headers. Rack::ConditionalGet: Supports the stale? feature in Rails controllers. Rack::ETag: Automatically set an ETag on all string responses. This means that if the same response is returned from a controller for the same URL, the server will return a 304 Not Modified, even if no additional caching steps are taken. This is primarily a client-side optimization; it reduces bandwidth costs but not server processing time. Rack::Lock: If your application is not marked as threadsafe (config.threadsafe!), this middleware will add a mutex around your requests. Rack::Runtime: Adds a header to the response listing the total runtime of the request. Rack::Sendfile: Uses a front-end server's file serving support from your Rails application. Rails::Rack::Logger: Log the request started and flush all loggers after it. Other plugins, including ActiveRecord, may add additional middlewares. In general, these middlewares are agnostic to the type of app you are building, and make sense in an API-only Rails application. You can get a list of all middlewares in your application via: rake middleware Other Middlewares Rails ships with a number of other middlewares that you might want to use in an API app, especially if one of your API clients is the browser: Rack::MethodOverride: Allows the use of the _method hack to route POST requests to other verbs. ActionDispatch::Cookies: Supports the cookie method in ActionController, including support for signed and encrypted cookies. ActionDispatch::Flash: Supports the flash mechanism in ActionController. ActionDispatch::BestStandards: Tells Internet Explorer to use the most standards-compliant available renderer. In production mode, if ChromeFrame is available, use ChromeFrame. Session Management: If a config.session_store is supplied and config.api_only = false, this middleware makes the session available as the session method in ActionController. Any of these middlewares can be added via: Removing Middlewares If you don't want to use a middleware that is included by default in the API middleware set, you can remove it using config.middleware.delete: Keep in mind that removing these features may remove support for certain features in ActionController. Choosing Controller Modules An API application (using ActionController::API) comes with the following controller modules by default: ActionController::UrlFor: Makes url_for and friends available ActionController::Redirecting: Support for redirect_to ActionController::Rendering: Basic support for rendering ActionController::Renderers::All: Support for render :json and friends ActionController::ConditionalGet: Support for stale? ActionController::ForceSSL: Support for force_ssl ActionController::RackDelegation: Support for the request and response methods returning ActionDispatch::Request and ActionDispatch::Response objects. ActionController::DataStreaming: Support for send_file and send_data AbstractController::Callbacks: Support for before_filter and friends ActionController::Instrumentation: Support for the instrumentation hooks defined by ActionController (see the source for more). ActionController::Rescue: Support for rescue_from. Other plugins may add additional modules. You can get a list of all modules included into ActionController::API in the rails console: Adding Other Modules All Action Controller modules know about their dependent modules, so you can feel free to include any modules into your controllers, and all dependencies will be included and set up as well. Some common modules you might want to add: AbstractController::Translation: Support for the l and t localization and translation methods. These delegate to I18n.translate and I18n.localize. ActionController::HttpAuthentication::Basic::ControllerMethods (or Digest or Token): Support for basic, digest or token HTTP authentication. ActionView::Layouts: Support for layouts when rendering. ActionController::MimeResponds (and ActionController::ImplicitRender for Rails 4): Support for content negotiation (respond_to, respond_with). ActionController::Cookies: Support for cookies, which includes support for signed and encrypted cookies. This requires the cookie middleware. The best place to add a module is in your ApplicationController. You can also add modules to individual controllers. Contributing Fork it Create your feature branch (git checkout -b my-new-feature) Commit your changes (git commit -am 'Added some feature') Push to the branch (git push origin my-new-feature) Create new Pull Request Maintainers Santiago Pastorino (https://github.com/spastorino) Carlos Antonio da Silva (https://github.com/carlosantoniodasilva) Steve Klabnik (https://github.com/steveklabnik) License MIT License. Mailing List https://groups.google.com/forum/?fromgroups#!forum/rails-api-core"
2423,"Gmail JavaScript APIGmail.js - JavaScript API for Gmail What Gmail.js is and isn't Gmail.js is meant to be used for creating WebExtension-based browser-extensions, for Chrome, Firefox and other compatible browsers. It cannot be used server-side with Node, or from another web-app to interface with Gmail. Note: This is not an official Gmail API, and isn't affiliated with Google. Note: Gmail.js requires jQuery to work TL;DR Summary Lots of API methods to work with gmail. See documentation below. Easy to use API. Data & DOM. Reasonably complete TypeScript-support. Many methods are contextual and will work with whatever is on screen when no arguments are given. Obtain email data, react to event, etc. No need for OAuth! Main methods allow you to observe certain events with gmail.observe.on('lots_of_actions_here', callback()) or similar gmail.observe.before(...) and gmail.observe.after(...) Create an issue/pull request for feedback, requests and fixes. See CONTRIBUTING.md for more details. Using Gmail.js If you know how to create WebExtensions-based extensions for Firefox and Chrome, you can get started by pulling Gmail.js like this: Note: Please ensure that Gmail.js is injected into the regular DOM. Content-scripts which launch injected script must be configured with ""run_at"": ""document_start"". It's recommended to split injected script to have only gmail.js load first because the size of the injected script impacts the loading time. Gmail.js must be injected and loaded before Gmail loads embedded data. Gmail.js does not work as a content-script. For a ready to use example/boilerplate repo, look no further: GmailJS Node Boilerplate - Example for how to create a browser-extension using GmailJS and modern javascript with NodeJS and script-bundling for instant load-times. Content Security Policy (legacy advice) In earlier advice given w.r.t. deployment of GmailJS, where scripts were injected one by one, with cumbersome loading and probing mechanisms, CSP could be an problem causing your extension to fail if GmailJS was injected incorrectly. If you use modern javascript and script-bundling in your extension (like in the boilerplate example), CSP will not interfere with loading of your extension, nor GmailJS. If you have any issues with CSP, the general advice is to build your extension using script-bundling and eliminate the cause of the error all together. While you may be able to make it work, legacy loading is no longer considered supported by GmailJS. Setup Gmail.js requires jQuery to work Quick Usage - Chrome Console Typescript Using gmail-js with TypeScript is relatively easy, but if you use normal import syntax it will fail. Instead you need to use require-syntax to load it: ` Methods Summary (click for more info) GET gmail.get.user_email() gmail.get.manager_email() gmail.get.current_page() gmail.get.new.email_id() gmail.get.new.email_data() gmail.get.new.thread_id() gmail.get.new.thread_data() gmail.get.email_subject() gmail.get.compose_ids() gmail.get.email_source_async(identifier=undefined, callback, error_callback, preferBinary) gmail.get.email_source_promise(identifier=undefined, preferBinary) gmail.get.search_query() gmail.get.unread_emails() gmail.get.unread_inbox_emails() gmail.get.unread_draft_emails() gmail.get.unread_spam_emails() gmail.get.unread_forum_emails() gmail.get.unread_update_emails() gmail.get.unread_promotion_emails() gmail.get.unread_social_emails() gmail.get.last_active() gmail.get.storage_info() gmail.get.loggedin_accounts() gmail.get.beta() gmail.get.localization() GET (deprecated methods) gmail.get.thread_id() gmail.get.email_id() gmail.get.email_ids() gmail.get.email_data(email_id=undefined) gmail.get.email_data_async(email_id=undefined, callback) gmail.get.displayed_email_data() gmail.get.displayed_email_data_async(callback) gmail.get.selected_emails_data() gmail.get.visible_emails() gmail.get.visible_emails_async(callback) CHECK gmail.check.is_new_data_layer() gmail.check.is_new_gui() gmail.check.is_thread() gmail.check.is_inside_email() gmail.check.is_plain_text() gmail.check.is_preview_pane() gmail.check.is_multiple_inbox() gmail.check.is_horizontal_split() gmail.check.are_shortcuts_enabled() gmail.check.is_vertical_split() gmail.check.is_tabbed_inbox() gmail.check.is_right_side_chat() gmail.check.should_compose_fullscreen() gmail.check.is_conversation_view() gmail.check.is_google_apps_user() gmail.check.is_priority_inbox() gmail.check.is_rapportive_installed() gmail.check.is_streak_installed() gmail.check.is_anydo_installed() gmail.check.is_boomerang_installed() gmail.check.is_xobni_installed() gmail.check.is_signal_installed() CHAT gmail.chat.is_hangouts() COMPOSE gmail.compose.start_compose() OBSERVE It is considered best practice to wait for the gmail interface to be loaded before observing any XHR actions. gmail.observe.http_requests() gmail.observe.actions() gmail.observe.register(action, class/args, parent) - registers a custom DOM observer gmail.observe.off(action,type) gmail.observe.on(action, callback) XHR observers load - When the gmail interface has finished loading http_event - When gmail any CRUD operation happens on gmail poll - When gmail automatically polls the server to check for new emails every few seconds new_email - When a new email appears in the inbox open_email - When an email is opened from the inbox view refresh - When you click the refresh button unread - When a conversation(s) is marked unread read - When a conversation(s) is marked read delete - When a conversation(s) is deleted delete_message_in_thread - When a conversation(s) is deleted inside a thread mark_as_spam - When a conversation(s) is marked as spam mark_as_not_spam - When a conversation(s) is unchecked as spam label - When a conversation(s) get applied a label archive - When a conversation(s) is archieved move_to_inbox - When a conversation(s) is moved to the inbox delete_forever - When a conversation(s) is deleted forever star - When a conversation(s) is starred unstar - When a conversation(s) is unstarred undo_send - When the Undo Send button is clicked after trying to send a new email mark_as_important - When a conversation(s) is marked as important mark_as_not_important - When a conversation(s) is marked as not important filter_messages_like_these - When a filter button is triggered for a conversation mute - When a conversation(s) is muted unmute - When a conversation(s) is unmuted add_to_tasks - When an item is added to google tasks move_label - When a conversation(s) is moved to a label folder save_draft - When a draft is saved discard_draft - When a draft is dicarded send_message - When a message is sent (except scheduled messages) send_scheduled_message - When a message is scheduled for sending (but not actually sent) expand_categories - When a category is expanded from the left nav sidebar restore_message_in_thread - When a deleted message is restored inside a thread delete_label - When a label is deleted show_newly_arrived_message - When inside an email and a new email arrives in the thread upload_attachment - When an attachment is being uploaded to an email being composed DOM observers compose - When a new compose window is opened, or a message is replied to or forwarded recipient_change - When an email being written (either new compose, reply or forward) has its to, cc or bcc recipients updated view_thread - When a conversation thread is opened to read *view_email - When an individual email is loaded within a conversation thread. It's worth noting this event is only triggered when the email is actually rendered in the DOM. Gmail tends to cache the rendered emails, so it should not be expected to fire reliably for every viewing of the same email. It will most likely fire once, for the initial and possibly only rendering. load_email_menu - When the dropdown menu next to the reply button is clicked gmail.observe.before(action, callback) gmail.observe.after(action, callback) gmail.observe.bind(type, action, callback) - implements the on, after, before callbacks gmail.observe.on_dom(action, callback) - implements the DOM observers - called by gmail.observe.on gmail.observe.bound(action, type) - checks if a specific action and/or type has any bound observers gmail.observe.trigger(type, events, xhr) - fires any specified events for this type (on, after, before) with specified parameters DOM These methods return the DOM data itself gmail.dom.inboxes() gmail.dom.inbox_content() gmail.dom.visible_messages() gmail.dom.email_subject() gmail.dom.email_body() gmail.dom.email_contents() gmail.dom.get_left_sidebar_links() gmail.dom.header() gmail.dom.search_bar() gmail.dom.toolbar() gmail.dom.right_toolbar() gmail.dom.compose() - compose dom object - receives the DOM element for the compose window and provides methods to interact gmail.dom.composes() - retrieves an array of gmail.dom.compose objects representing any open compose windows gmail.dom.email() - email dom object - receives an email DOM element or email id for an email currently being viewed. Abstracts interaction with that email. gmail.dom.thread() - thread dom object - receives a conversation thread DOM element currently being viewed. Abstracts interaction with that thread. TOOLS These are some helper functions that the rest of the methods use. See source for input params gmail.tools.infobox(message, time) Adds the yellow info box on top of gmail with the given message gmail.tools.rerender(callback) Re-renders the UI using the available data. gmail.tools.xhr_watcher() gmail.tools.parse_url() gmail.tools.deparam() gmail.tools.parse_view_data() gmail.tools.parse_email_data() gmail.tools.extract_email_address(str) gmail.tools.extract_name(str) gmail.tools.make_request() gmail.tools.make_request_async() gmail.tools.make_request_download_promise(url, preferBinary) - function specialized for downloading email MIME messages or attachments. gmail.tools.sleep(ms) gmail.tools.multitry(ms_delay, tries, func, bool_success_check) gmail.tools.i18n(label) gmail.tools.toggle_minimize() gmail.tools.add_toolbar_button(content_html, onclick_action, custom_style_class) gmail.tools.add_right_toolbar_button(content_html, onclick_action, custom_style_class) gmail.tools.add_compose_button(compose_ref, content_html, onclick_action, custom_style_class) gmail.tools.add_modal_window(title, content_html, onClickOk, onClickCancel, onClickClose) gmail.tools.remove_modal_window() TRACKER These are some of the variables that are tracked and kept in memory while the rest of the methods are in use. gmail.version gmail.tracker.events gmail.tracker.xhr_init gmail.tracker.xhr_open gmail.tracker.xhr_send gmail.tracker.watchdog gmail.tracker.view_data gmail.tracker.email_data gmail.tracker.ik gmail.tracker.rid Details gmail.new.get.email_id() Obtains the new-style email-ID from the email currently on screen. Extracted via DOM. This ID can only be used by gmail.new.get.*-functions. Can be provided email-element from HTML DOM, or Gmail DOMEmail object to look up specific email ID. gmail.new.get.thread_id() Obtains the new-style thread-ID from the email currently on screen. Extracted via DOM. This ID can only be used by gmail.new.get.*-functions. gmail.new.get.email_data(identifier) Returns a data-object for the requested email, if found in the email-cache. identifier must be an object or string which uniquely identifies an email: new-style email-id legacy-style email-id (will cause warning) DomEmail instance EmailData instance If no email-data can be found in Gmail.JS email-cache, null or undefined is returned instead. This method returns immediately, uses no XHR, and has no async-equivalent. Please note: Email-data is intercepted and stored in the cache only when Gmail itself has requested or used and email. This typically happens when loading a label (pre-loading all emails in view) or when navigating to view a full thread. That means that calling the same method later may return data even if the first invocation returned null. gmail.new.get.thread_data(identifier) Returns a data-object for the requested email-thread, if found in the email-cache. identifier must be an object or string which uniquely identifies a thread: a new-style thread-id new-style email-id legacy-style email-id (will cause warning) DomEmail instance DomThread instance EmailData instance If no thread-data can be found in Gmail.JS email-cache, null or undefined is returned instead. This method returns immediately, uses no XHR, and has no async-equivalent. Please note: Email-data is intercepted and stored in the cache only when Gmail itself has requested or used and email. This typically happens when loading a label (pre-loading all emails in view) or when navigating to view a full thread. That means that calling the same method later may return data even if the first invocation returned null. gmail.get.email_source(identifier=undefined) Deprecated function. Will be removed. Migrate to gmail.get.email_source_async or gmail.get.email_source_promise instead. gmail.get.email_source_async(identifier=undefined, callback, error_callback, preferBinary=false) Retrieves raw MIME message source from the gmail server for the specified email identifier. identifier must be an object or string which uniquely identifies an email: new-style email-id legacy-style email-id (will cause warning) DomEmail instance EmailData instance If not specified, current email will be resolved automatically. By default, once retrieved the resulting data will be passed to callback in text-format. This may corrupt the actual email MIME-data, by causing irreversible content-encoding consistency-errors. If you need to parse this data in a proper MIME-parser later, the only way to avoid this kind of error is to download the data in binary format and do your own decoding inside your own MIME-parser. To get the email-source in binary form, you must set the preferBinary-parameter to true. gmail.get.email_source_promise(identifier=undefined, preferBinary=false) Does the same as above but implements it using ES6 promises. gmail.get.user_email() Returns the current user's email address gmail.get.manager_email() Returns the email address of the user currently managing the account (if the inbox is used by the owner, this function returns the same value as gmail.get.user_email()) gmail.get.delegated_to_email() Returns the email address of the user the account is currently delegated to (if the inbox is used by the owner, this function returns null) gmail.get.storage_info() Returns current user's file storage stats gmail.get.current_page() Returns what page of gmail the user is currently on. These are the possible responses gmail.get.email_subject() Returns the opened email's subject from the DOM gmail.get.compose_ids() Returns the latest/last email id of emails that have been saved as drafts (currently open) gmail.get.search_query() Returns the search bar data gmail.get.unread_emails() Returns a count of total unread emails for the current account. You can also request the data individually gmail.get.unread_inbox_emails() gmail.get.unread_draft_emails() gmail.get.unread_spam_emails() gmail.get.unread_forum_emails() gmail.get.unread_update_emails() gmail.get.unread_promotion_emails() gmail.get.unread_social_emails() gmail.get.last_active() Gets user's account activity data gmail.get.loggedin_accounts() Returns a list of signed-in accounts (multiple user accounts setup in gmail) gmail.get.beta() Although hand picked, this method returns the checks on beta features and deployments gmail.get.localization() Returns the Gmail localization, e.g. 'US'. gmail.check.is_new_data_layer() Returns True if the user is running Gmail with the new 2018 data-layer False otherwise gmail.check.is_new_gui() Returns True if the user is running Gmail with the new 2018 GUI False otherwise gmail.check.is_thread() Returns True if the conversation is threaded False otherwise gmail.check.is_preview_pane() Returns True if gmail is in split pane mode (vertical or horizontal) False otherwise gmail.check.is_multiple_inbox() Returns True if user has multiple inbox lab enabled, False otherwise gmail.check.is_horizontal_split() Returns True if the pane split mode is horiontal False otherwise gmail.check.are_shortcuts_enabled() Returns True if user has enabled mail action shortcuts, False otherwise gmail.check.is_vertical_split() Returns True if the pane mode is vertical False otherwise gmail.check.is_tabbed_inbox() Returns True if tabbed inbox view is enabled False otherwise gmail.check.is_right_side_chat() Returns True if chat is on the right sidebar False otherwise gmail.check.should_compose_fullscreen() Returns True if compose is in fullscreen mode False otherwise gmail.check.is_conversation_view() Returns True if emails are displayed as threads, False otherwise (i.e. displayed individually) gmail.check.is_google_apps_user() Returns True if the current user is google apps user (email not ending in gmail.com) False otherwise gmail.check.is_inside_email() Returns True if you are currently inside an email conversation False otherwise gmail.check.is_plain_text() Returns True if compose is in plain text mode, False if in rich text mode gmail.check.is_priority_inbox() Returns True if priority inbox is enabled False otherwise gmail.check.is_rapportive_installed() Returns True if rapportive chrome extension is installed False otherwise gmail.check.is_streak_installed() Returns True if streak chrome extension is installed False otherwise gmail.check.is_anydo_installed() Returns True if any.do chrome extension is installed False otherwise gmail.check.is_boomerang_installed() Returns True if boomerang chrome extension is installed False otherwise gmail.check.is_xobni_installed() Returns True if xobni chrome extension is installed False otherwise gmail.check.is_signal_installed() Returns True if Signal chrome extension is installed False otherwise gmail.chat.is_hangouts() Returns True if the account supports the new hangout UI for chat False otherwise (native chat window) gmail.compose.start_compose() -Clicks on the compose button making the inbox compose view to popup gmail.observe.http_requests() After an observer has been bound through gmail.observe.bind() (via a call to events gmail.observe.before(), gmail.observe.on(), or gmail.observe.after()), this method keeps track of the last 50 http events. The items contain the sent requested parameterized data gmail.observe.actions() Similar to gmail.observe.http_requests() this keeps track of the last 10 gmail actions (vs all http requests). Actions here correspond to things like clicking refres, archiving, deleting, starring etc. gmail.observe.on(action, callback) This is the key feature of gmail.js. This method allows you to add triggers to all of these actions so you can build your custom extension/tool with this library. You simply specify the action name and your function that the method will return data to when the actions are triggered and it does the rest. You can have multiple triggers Your callback will be fired directly after Gmail's XMLHttpRequest has been sent off the the Gmail servers. Available Actions http_event - When gmail any CRUD operation happens on gmail poll - When gmail automatically polls the server to check for new emails every few seconds new_email - When a new email appears in the inbox open_email - When an email is opened from the inbox view refresh - When you click the refresh button unread - When a conversation(s) is marked unread read - When a conversation(s) is marked read delete - When a conversation(s) is deleted delete_message_in_thread - When a conversation(s) is deleted inside and is part of a thread mark_as_spam - When a conversation(s) is marked as spam mark_as_not_spam - When a conversation(s) is unchecked as spam label - When a conversation(s) get applied a label archive - When a conversation(s) is archieved move_to_inbox - When a conversation(s) is moved to the inbox delete_forever - When a conversation(s) is deleted forever star - When a conversation(s) is starred unstar - When a conversation(s) is unstarred undo_send - When the Undo Send button is clicked after trying to send a new email mark_as_important - When a conversation(s) is marked as important mark_as_not_important - When a conversation(s) is marked as not important filter_messages_like_these - When a filter button is triggered for a conversation mute - When a conversation(s) is muted unmute - When a conversation(s) is unmuted add_to_tasks - When an item is added to google tasks move_label - When a conversation(s) is moved to a label folder save_draft - When a draft is saved discard_draft - When a draft is dicarded send_message - When a message is sent (except scheduled messages) send_scheduled_message - When a message is scheduled for sending (but not actually sent) expand_categories - When a category is expanded from the left nav sidebar restore_message_in_thread - When a deleted message is restored inside a thread delete_label - When a label is deleted show_newly_arrived_message - When inside an email and a new email arrives in the thread The on method also supports observering specific DOM events in the Gmail Interface (for example when a new compose window is opened). These are only available via the on method (not the before or after methods). Available DOM Actions/Observers load - When the gmail interface has completed loading compose - When a new compose window opens, or a message is replied to or forwarded compose_cancelled - When an existing compose window is closed. recipient_change - When the recipient (to, cc or bcc) is changed when composing a new email or replying/forwarding an email view_thread - When a new coversation thread is opened view_email - When an individual email is loaded within a thread (also fires when thread loads displaying the latest email) load_email_menu - When the dropdown menu next to the reply button is clicked gmail.observe.before(action, callback) Similar to gmail.observe.on, this method allows you to bind callbacks to specific events. All of the standard actions in gmail.observe.on work here, with the exception of the DOM actions The main difference between on and before is that these callbacks are fired before Gmail's XMLHttpRequest has been sent off the the Gmail servers.This means, where relevant, your callback function can change it prior to it departing by editing the xhrParams.body_params object in the passed xhr parameter. gmail.observe.after(action, callback) Similar to gmail.observe.on, this method allows you to bind callbacks to specific events. All of the standard actions in gmail.observe.on work here, with the exception of the DOM actions The main difference between on and after is that these callbacks are fired once Gmail's XMLHttpRequest has returned from the Gmail servers (on the XMLHttpRequest onreadystatechange event). In addition to the usual parameters received by a callback, callbacks you define for an after event receive an additional response parameter prior to the last xhr parameter. This response parameter is a parsed object representation of the response from the Gmail servers. So for example, the send_message action would receive: gmail.observe.off(action=null,type=null) Turn off an observe action. Providing it no argument will disable all observers. Type is either before, after, on or dom. If not specified will disable all types of specified observer. gmail.observe.register(action, class/args) Allow an application to register a custom DOM observer specific to their application. Adds it to the configured DOM observers that will then be supported by the dom insertion observer. Note this method must be called prior to binding any handlers to specific actions/observers using on, before or after. Once you start binding handlers, you cannot register any further custom observers. This method can be called two different ways: Simple: - action - the name of the new DOM observer - class - the class of an inserted DOM element that identifies that this action should be triggered Complex: - action - the name of the new DOM observer - args - an object containin properties for each of the supported DOM observer configuration agruments: - class - the class of an inserted DOM element that identifies that this action should be triggered - selector - if you need to match more than just the className of a specific element to indicate a match, you can use this selector for further checking (uses element.is(selector) on matched element). E.g. if there are multiple elements with a class indicating an observer should fire, but you only want it to fire on a specific id, then you would use this - sub_selector - if specified, we do a jquery element.find for the passed selector on the inserted element and ensure we can find a match - handler - if specified this handler is called if a match is found. Otherwise default calls the callback & passes the jQuery matchElement gmail.dom.visible_messages() Returns basic data for all the messages currently visible in the messages view. Taken from the DOM. gmail.dom.compose(compose_el) An object used to abstract interation with a compose popup. Represents a compose window in the DOM and provides a bunch of methods and properties to access & interact with the window. Expects a jQuery DOM element for the compose div. Compose methods: .id() - retrieve the compose id .email_id() - retrieve the draft email id .is_inline() - is this compose instance inline (as with reply & forwards) or a popup (as with a new compose) .recipients(options) - retrieves to, cc, bcc and returns them in a hash of arrays. Options: .type - string to, cc, or bcc to check a specific one .flat - boolean if true will just return an array of all recipients instead of splitting out into to, cc, and bcc .to() - retrieve the current to recipients .cc() - retrieve the current cc recipients .bcc() - retrieve the current bcc recipients .subject(subject) - get/set the current subject .from() - get the from email, if user only has one email account they can send from, returns that email address .body(body) - get/set the email body .send() - triggers the same action as clicking the ""send"" button would do. .find(selector) - map find through to jquery element .close() - close compose window .dom(lookup) - retrieve preconfigured dom elements for this compose window. Lookup can be one of 'to' | 'cc' | 'bcc' | 'id' | 'draft' | 'subject' | 'subjectbox' | 'all_subjects' | 'body' | 'quoted_reply' | 'reply' | 'forward' | 'from' | 'send_button' gmail.dom.email(email_el or email_id) An object for interacting with an email currently present in the DOM. Represents an individual email message within a thread, and provides a number of methods and properties to access & interact with the interface and email data. Expects a jQuery DOM element for the email div (div.adn as returned by the view_email observer), or an email_id .id - property storing the id of the email .email_id() - draft id of the email .body([body]) - allows get/set the html body in the DOM .to([to_array]) - allows retrieve or updating to/from DOM who the email is addressed to .from([email_address],name) - allows get/set who the email is from in the DOM .attachments() - retrieves the attachments for the email in the DOM .data() - retrieves object of email data from the Gmail servers .source() - retrieves the email raw source from the Gmail servers .dom() - retrieves the primary element, or other defined elements from the DOM gmail.dom.email.body([body=null]) Get/Set the full email body as it sits in the DOM. Note: This gets & sets the body html after it has been parsed & marked up by GMAIL. To retrieve it as it exists in the email message source, use a call to .data() If you want the actual DOM element use .dom('body'); Receives optional argument containing html to update the email body with. gmail.dom.email.to([to_array=null]) Get/Set who the email is showing as To. Optionally receives an array of objects containing email and/or name properties. If received replaces the values in the DOM. Returns an array of objects containing email & name of who is showing in the DOM as the email is to. gmail.dom.email.from([email_address=null], [display_name=null]) Get/Set the sender of the email that is displayed in the interface. Optionally receives email and name properties. If received updates the values in the DOM Returns an object containing email & name of the sender and dom element gmail.dom.email.data() Retrieve relevant email data from the Gmail servers for this email Makes use of the gmail.get.email_data() method Returns an object containing the email data. Caches email data for all emails in the thread gmail.dom.email.source() Retrieve email source for this email from the Gmail servers Makes use of the gmail.get.email_source() method Returns string of email raw source gmail.dom.email.dom([lookup=null]) Retrieve preconfigured dom elements for this email Abstracts relevant dom elements so code can be centralized - making it easier to update if Gmail updates its interface Retrieves the primary DOM element if you pass no lookup Supported lookups: - null (primary element) - body - from - to - to_wrapper - timestamp - star - reply_button - menu_button - details_button gmail.dom.thread(thread_el) An object for interacting with a conversation thread currently present in the DOM. Provides methods to access & interact with the interface. Expects a jQuery DOM element for the thread wrapper div (div.if as returned by the view_thread observer) .dom() - retrieves the primary element, or other defined elements from the DOM gmail.dom.thread.dom([lookup=null]) Retrieve preconfigured dom elements for this conversation thread Abstracts relevant dom elements so code can be centralized - making it easier to update if Gmail updates its interface Retrieves the primary DOM element if you pass no lookup Supported lookups: - null (primary element) - opened_email - subject - labels gmail.tools.add_toolbar_button(content_html, onclick_action, custom_style_class) Add a new button to Gmail Toolbar gmail.tools.add_right_toolbar_button(content_html, onclick_action, custom_style_class) Add a new button to Gmail Toolbar on the right hand side gmail.tools.add_compose_button(compose_ref, content_html, onclick_action, custom_style_class) Add button to compose window. You can use gmail.dom.composes() to get compose reference. gmail.tools.add_attachment_button(attachment_ref, content_html, customCssClass, tooltip, onclick_action) Add a button to an attachment in email-view. gmail.tools.add_modal_window(title, content_html, onClickOk, onClickCancel, onClickClose) Create a modal window with specified title, content and callback functions. triggers when the user clicks the OK button on the modal window. triggers when the user clicks the Cancel button on the modal window. triggers when the user clicks the X in the upper right hand side of the modal window. By default, if or are left blank, their corresponding buttons will remove the modal window by calling . gmail.tools.remove_modal_window() Removes a modal window created using . gmail.tools.toggle_minimize() Show/Hide compose window . Details - Deprecated methods gmail.get.thread_id() Note: This method can only be used with other deprecated methods, and is itself deprecated. Use gmail.new.get.thread_id() instead. Gets current email-thread's ID. This can be used together with gmail.get.email_data() to obtain individual email IDs. gmail.get.email_id() Note: This method can only be used with other deprecated methods, and is itself deprecated. Use gmail.new.get.email_id() instead. Same as gmail.get.thread_id(), but kept for compatibilty. Using this method generates a warning! gmail.get.email_ids() Note: This method can only be used with other deprecated methods, and is itself deprecated. Use gmail.new.get.thread_id() and gmail.new.get.thread_data() instead. Returns a list of email IDs for each thread in the conversation gmail.get.visible_emails() DEPRECATED! This function relies on XHR-invocation against a deprecated Gmail API and is is very likely to fail. Migrate to gmail.new.get.*-API instead. Returns a list of emails from the server that are currently visible in the inbox view. The data does not come from the DOM gmail.get.visible_emails_async(callback) DEPRECATED! This function relies on XHR-invocation against a deprecated Gmail API and is is very likely to fail. Migrate to gmail.new.get.*-API instead. Does the same as above but accepts a callback function gmail.get.selected_emails_data() DEPRECATED! This function relies on XHR-invocation against a deprecated Gmail API and is is very likely to fail. Migrate to gmail.new.get.*-API instead. Returns a list of object representation from emails that are currently selected in the inbox view. The data does not come from the DOM gmail.get.email_data(thread_id=undefined) DEPRECATED! This function relies on XHR-invocation against a deprecated Gmail API and is is very likely to fail. Use gmail.new.get.email_data() and gmail.new.get.thread_data() instead! Returns an object representation of the opened email contents and metadata. It takes the optional thread_id parameter where the data for the specified thread is returned instead of the email-thread currently visible in the dom. thread_id is added for updated gmail thread behaviour which adds support for emails created in inbox. first_email remains as the first message in the thread. gmail.get.email_data_async(email_id=undefined, callback) DEPRECATED! This function relies on XHR-invocation against a deprecated Gmail API and is is very likely to fail. Use gmail.new.get.email_data() and gmail.new.get.thread_data() instead! Does the same as above but accepts a callback function. gmail.get.displayed_email_data() DEPRECATED! This function relies on XHR-invocation against a deprecated Gmail API and is is very likely to fail. Migrate to gmail.new.get.*-API instead. Returns an object representation of the emails that are being displayed. gmail.get.displayed_email_data_async(callback) DEPRECATED! This function relies on XHR-invocation against a deprecated Gmail API and is is very likely to fail. Migrate to gmail.new.get.*-API instead. Does the same as above but accepts a callback function. Author and Licensing | | Inspired by gmailr.js | |---| --- | | Kartik Talwar | See License.md |"
1204,"Offline documentation browser inspired by DashZeal Zeal is a simple offline documentation browser inspired by Dash. Download Get binary builds for Windows and Linux from the download page. How to use After installing Zeal go to Tools->Docsets, select the ones you want, and click the Download button. How to compile Build dependencies CMake. Qt version 5.9.5 or above. Required module: Qt WebEngine Widgets. libarchive. SQLite. X11 platforms only: Qt X11 Extras and xcb-util-keysyms. Build instructions More detailed instructions are available in the wiki. Query & Filter docsets You can limit the search scope by using ':' to indicate the desired docsets: java:BaseDAO You can also search multiple docsets separating them with a comma: python,django:string Command line If you prefer, you can start Zeal with a query from the command line: zeal python:pprint Create your own docsets Follow instructions in the Dash docset generation guide. Contact and Support We want your feedback! Here's a list of different ways to contact developers and request help: * Report bugs and submit feature requests to GitHub issues. * Reach developers and other Zeal users on Gitter or IRC channel #zealdocs on Freenode. * Ask any questions in our Google Group. You can send an email to zealdocs@googlegroups.com. * Do not forget to follow @zealdocs on Twitter! * Finally, for private communications email us at zeal@zealdocs.org. License This software is licensed under the terms of the GNU General Public License version 3 (GPLv3). Full text of the license is available in the COPYING file and online."
889,"Used to integrate the Facebook Platform with your iOS & tvOS apps.Facebook SDK for iOS This open-source library allows you to integrate Facebook into your iOS app. Learn more about the provided samples, documentation, integrating the SDK into your app, accessing source code, and more at https://developers.facebook.com/docs/ios Please take a moment and subscribe to releases so that you can be notified about new features, deprecations, and critical fixes. To see information about the latest release, consult our changelog. TRY IT OUT Swift Package Manager (available Xcode 11.2 and forward) In Xcode, select File > Swift Packages > Add Package Dependency. Follow the prompts using the URL for this repository and a minimum semantic version of v5.10.0 Check-out the tutorials available online at: https://developers.facebook.com/docs/ios/getting-started Start coding! Visit https://developers.facebook.com/docs/ios for tutorials and reference documentation. Note for Swift Package Manager Users: If you explicitly DO NOT want to include Swift, import FBSDKCoreKit FBSDKLoginKit and FBSDKShareKit For projects that include Swift, use FacebookCore, FacebookLogin, and FacebookShare CocoaPods Add the following to your Podfile: pod 'FBSDKCoreKit' pod 'FBSDKLoginKit' pod 'FBSDKShareKit' Test your install by adding import FBSDKCoreKit to your AppDelegate Check-out the tutorials available online at: https://developers.facebook.com/docs/ios/getting-started Start coding! Visit https://developers.facebook.com/docs/ios for tutorials and reference documentation. iOS 14 CHANGES Data Disclosure Due to the release of iOS 14, tracking events that your app collects and sends to Facebook may require you to disclosed these data types in the App Store Connect questionnaire. It is your responsibility to ensure this is reflected in your applications privacy policy. Visit our blogpost for information on affected Facebook SDKs, APIs, and products and the Apple App Store Privacy Details article to learn more about the data types you will need to disclose. link to FB blogpost https://developers.facebook.com/blog/post/2020/10/22/preparing-for-apple-app-store-data-disclosure-requirements/ apple store details https://developer.apple.com/app-store/app-privacy-details/ FEATURES Login - https://developers.facebook.com/docs/facebook-login Sharing - https://developers.facebook.com/docs/sharing App Links - https://developers.facebook.com/docs/applinks Graph API - https://developers.facebook.com/docs/ios/graph Analytics - https://developers.facebook.com/docs/analytics GIVE FEEDBACK Please report bugs or issues to our designated developer support team -- https://developers.facebook.com/support/bugs/ -- as this will help us resolve them more quickly. You can also visit our Facebook Developer Community Forum, join the Facebook Developers Group on Facebook, ask questions on Stack Overflow, or open an issue in this repository. LICENSE See the LICENSE file. SECURITY POLICY See the SECURITY POLICY for more info on our bug bounty program. DEVELOPER TERMS By enabling Facebook integrations, including through this SDK, you can share information with Facebook, including information about peoples use of your app. Facebook will use information received in accordance with our Data Use Policy, including to provide you with insights about the effectiveness of your ads and the use of your app. These integrations also enable us and our partners to serve ads on and off Facebook. You may limit your sharing of information with us by updating the Insights control in the developer tool https://developers.facebook.com/apps/{app_id}/settings/advanced. If you use a Facebook integration, including to share information with us, you agree and confirm that you have provided appropriate and sufficiently prominent notice to and obtained the appropriate consent from your users regarding such collection, use, and disclosure (including, at a minimum, through your privacy policy). You further agree that you will not share information with us about children under the age of 13. You agree to comply with all applicable laws and regulations and also agree to our Terms https://www.facebook.com/policies/, including our Platform Policies https://developers.facebook.com/policy/.and Advertising Guidelines, as applicable https://www.facebook.com/ad_guidelines.php. By using the Facebook SDK for iOS you agree to these terms."
3431,"Ajax Autocomplete for jQuery allows you to easily create autocomplete/autosuggest boxes for text input fieldsDevbridge Group accelerates software to market for enterprise clients through dedicated product teams, user experience and software engineering expertise. www.devbridge.com Ajax Autocomplete for jQuery Ajax Autocomplete for jQuery allows you to easily create autocomplete/autosuggest boxes for text input fields. It has no dependencies other than jQuery. The standard jquery.autocomplete.js file is around 13KB when minified. API The following sets up autocomplete for input fields where options is an object literal that defines the settings to use for the autocomplete plugin. All available option settings are shown in the tables below. General settings (local and Ajax) | Setting | Default | Description | | :--- | :--- | :--- | | noCache | false | Boolean value indicating whether to cache suggestion results | | delimiter | optional | String or RegExp, that splits input value and takes last part to as query for suggestions. Useful when for example you need to fill list of comma separated values. | | minChars | 1 | Minimum number of characters required to trigger autosuggest | | triggerSelectOnValidInput | true | Boolean value indicating if select should be triggered if it matches suggestion | | preventBadQueries | true | Boolean value indicating if it should prevent future Ajax requests for queries with the same root if no results were returned. E.g. if Jam returns no suggestions, it will not fire for any future query that starts with Jam | | autoSelectFirst | false | If set to true, first item will be selected when showing suggestions | | beforeRender | optional | function (container, suggestions) {} called before displaying the suggestions. You may manipulate suggestions DOM before it is displayed | | formatResult | optional | function (suggestion, currentValue) {} custom function to format suggestion entry inside suggestions container | | formatGroup | optional | function (suggestion, category) {} custom function to format group header | | groupBy | optional | property name of the suggestion data object, by which results should be grouped | | maxHeight | 300 | Maximum height of the suggestions container in pixels | | width | auto | Suggestions container width in pixels, e.g.: 300, flex for max suggestion size and auto takes input field width | | zIndex | 9999 | 'z-index' for suggestions container | | appendTo | optional | Container where suggestions will be appended. Default value document.body. Can be jQuery object, selector or HTML element. Make sure to set position: absolute or position: relative for that element | | forceFixPosition | false | Suggestions are automatically positioned when their container is appended to body (look at appendTo option), in other cases suggestions are rendered but no positioning is applied. Set this option to force auto positioning in other cases | | orientation | bottom | Vertical orientation of the displayed suggestions, available values are auto, top, bottom. If set to auto, the suggestions will be orientated it the way that place them closer to middle of the view port | | preserveInput | false | If true, input value stays the same when navigating over suggestions | | showNoSuggestionNotice | false | When no matching results, display a notification label | | noSuggestionNotice | No results | Text or htmlString or Element or jQuery object for no matching results label | | onInvalidateSelection | optional | function () {} called when input is altered after selection has been made. this is bound to input element | | tabDisabled | false | Set to true to leave the cursor in the input field after the user tabs to select a suggestion | Event function settings (local and Ajax) | Event setting | Function description | | :--- | :--- | | onSearchStart | function (params) {} called before Ajax request. this is bound to input element | | onHint | function (hint) {} used to change input value to first suggestion automatically. this is bound to input element | | onSearchComplete | function (query, suggestions) {} called after Ajax response is processed. this is bound to input element. suggestions is an array containing the results | | transformResult | function(response, originalQuery) {} called after the result of the query is ready. Converts the result into response.suggestions format | | onSelect | function (suggestion) {} Callback function invoked when user selects suggestion from the list. this inside callback refers to input HtmlElement.| | onSearchError | function (query, jqXHR, textStatus, errorThrown) {} called if Ajax request fails. this is bound to input element | | onHide | function (container) {} called before container will be hidden | Local only settings | Setting | Default | Description | | :--- | :--- | :--- | | lookupLimit | no limit | Number of maximum results to display for local lookup | | lookup | n/a | Callback function or lookup array for the suggestions. It may be array of strings or suggestion object literals | | suggestion | n/a | Not a settings, but in the context of above row, a suggestion is an object literal with the following format: { value: 'string', data: any } | | lookupFilter | n/a | function (suggestion, query, queryLowerCase) {} filter function for local lookups. By default it does partial string match (case insensitive) | Ajax only settings | Setting | Default | Description | | :--- | :--- | :--- | | serviceUrl | n/a | Server side URL or callback function that returns serviceUrl string | | type | GET | Ajax request type to get suggestions | | dataType | text | type of data returned from server. Either text, json or jsonp, which will cause the autocomplete to use jsonp. You may return a json object in your callback when using jsonp | | paramName | query | The name of the request parameter that contains the query | | params | optional | Additional parameters to pass with the request | | deferRequestBy | 0 | Number of miliseconds to defer Ajax request | | ajaxSettings | optional | Any additional Ajax Settings that configure the jQuery Ajax request | Default Options Default options for all instances can be accessed via $.Autocomplete.defaults. Instance Methods Autocomplete instance has following methods: setOptions(options): you may update any option at any time. Options are listed above. clear: clears suggestion cache and current suggestions. clearCache: clears suggestion cache. disable: deactivate autocomplete. enable: activates autocomplete if it was deactivated before. hide: hides suggestions. dispose: destroys autocomplete instance. All events are detached and suggestion containers removed. There are two ways that you can invoke Autocomplete method. One is calling autocomplete on jQuery object and passing method name as string literal. If method has arguments, arguments are passed as consecutive parameters: Or you can get Autocomplete instance by calling autcomplete on jQuery object without any parameters and then invoke desired method. Usage Html: Ajax lookup: Local lookup (no Ajax): Custom lookup function: Styling Generated HTML markup for suggestions is displayed below. You may style it any way you'd like. Style sample: Response Format Response from the server must be JSON formatted following JavaScript object: Data can be any value or object. Data object is passed to formatResults function and onSelect callback. Alternatively, if there is no data you can supply just a string array for suggestions: Non standard query/results If your Ajax service expects the query in a different format, and returns data in a different format than the standard response, you can supply the ""paramName"" and ""transformResult"" options: Grouping Results Specify groupBy option of you data property if you wish results to be displayed in groups. For example, set groupBy: 'category' if your suggestion data format is: Results will be formatted into two groups NHL and NBA. Known Issues If you use it with jQuery UI library it also has plugin named autocomplete. In this case you can use plugin alias devbridgeAutocomplete: It seems that for mobile Safari click events are only triggered if the CSS of the object being tapped has the cursor set to pointer: .autocomplete-suggestion { cursor: pointer; } See issue #542 License Ajax Autocomplete for jQuery is freely distributable under the terms of an MIT-style license. Copyright notice and permission notice shall be included in all copies or substantial portions of the Software. Authors Tomas Kirda / @tkirda"
465,"Simple, Pythonic remote execution and deployment.Welcome to Fabric! Fabric is a high level Python (2.7, 3.4+) library designed to execute shell commands remotely over SSH, yielding useful Python objects in return. It builds on top of Invoke <http://pyinvoke.org> (subprocess command execution and command-line features) and Paramiko <http://paramiko.org> (SSH protocol implementation), extending their APIs to complement one another and provide additional functionality. For a high level introduction, including example code, please see our main project website <http://fabfile.org>; or for detailed API docs, see the versioned API website <http://docs.fabfile.org>."
2710,"The implementation of https://dribbble.com/shots/2067564-ReplaceFlyRefresh The Android implementation of Replace, designed by Zee Youn. I implement this as a FlyRefresh layout. The content of the layout can be any NestedScrollingChild, such as a RecyclerView, NestedScrollView, VerticalGridView, etc. This library can also work with NestedScrollingParent as parent, such as CoordinatorLayout. How it looks Features Work with all NestedScrollingParent and NestedScrollingChild Default minimize configuration for Replace animation Expendable/Shrinkable header Support custom header view Support custom refresh animation How to use Add Gradle dependency: An example of basic usage in layout.xml: Or you can use PullHeaderLayout for more configurations, you can set custom attributes as shown below: For more, please turn to the source code. License FlyRefresh is available under the MIT license."
3996,"A JavaScript application framework emphasizing modularity and encapsulationLooking for the issue tracker? It's moved to https://enyojs.atlassian.net. Quick Info Core This repository contains Enyo core. We've pared it down to the essentials, so folks can work at the metal. Widget sets, localization code, and other fancy bits are in separate repos. Warning about file:// Note: In Chrome, various samples will not work from file:// URLs because of Chrome's security policy. To work around this, run your app from a local http server, use the --allow-file-access-from-files flag when starting Chrome, or use the online samples at http://enyojs.com. What Is Enyo? Enyo is an object-oriented JavaScript application framework emphasizing modularity and encapsulation. Enyo is suitable for both small- and large-scale applications. Enyo 1.x was the underlying framework used to develop applications for HP's TouchPad tablet. Enyo as shipped on the TouchPad included an complete set of user interface components and service wrappers. What you will find here is Enyo 2, what we informally call core: the primary infrastructure needed to support any number of Enyo-based libraries. Enyo 1.x is now available under an open-source license. Enyo was designed from the beginning to be highly extensible. This repository reflects a small working set of code that may be expanded with any number of libraries or plugins. Enyo 2 is lightweight, easy to digest, and powerful. What Do I Get? The core code includes the Enyo kernel, the DOM extensions, some Ajax (XHR) tools, and basic wrapper kinds for a lot of DOM form elements. We believe this is a useful working set of tools. Enyo 2 provides a modularity concept (Component) and a view concept (UiComponent). The DOM aspect includes a widget concept (Control) and an extensible event system (Dispatcher). Ajax resources include basic XHR functionality and an implementation of XHR as a Component (Ajax). In the UI arena, Enyo offers base kinds for common controls like buttons and popups, along with layout-oriented kinds, such as platform-optimized scrollers. By themselves, these pieces are sufficient to create large applications using the Enyo encapsulation model. Developers who only want this low-level code are encouraged to roll-their-own application and UI layers. For those who want a richer set of tools, we have several pre-built libraries available. Why Do I Care? First is our emphasis on cross-platform compatibility: Enyo core works on both desktop and mobile browsers. Second is Enyo's building block approach to applications. Each piece of an application is a Component, and Components are constructed out of other Components. For example, it's easy to define the combination of an <input> tag and a <label> tag in one LabeledInput Component. Now I can use (and re-use) LabeledInput as one atomic piece. But that's just the beginning. Ultimately, large pieces of functionality may be exposed as single Components--for example, a fancy report generator, or a color picker, or an entire painting application. Use the Enyo encapsulation model to divide and conquer large projects. No particular piece of an application need be especially complex. Because the combining of pieces is central, factoring complex functionality into smaller pieces comes naturally. Moreover, because of the modularity, all these pieces tend to be reusable--in the same project, in other projects, or even by the public at large. This is all part of our strategy to allow developers to focus on creativity and Avoid Repeating Themselves. That's a Lot of Talk The core Enyo design was proven out by the complex applications HP developed for the TouchPad platform. We don't claim that this was particularly easy; there were a lot of hardworking developers on the apps teams, but we are confident in the efficacy of Enyo's guiding principles on a large scale. But don't take our word for it; see for yourself. Samples All samples reside in a consolidated sample app for Enyo and its libraries: enyo-strawman. Copyright and License Information Unless otherwise specified, all content, including all source code files and documentation files in this repository are: Copyright (c) 2012-2015 LG Electronics Unless otherwise specified or set forth in the NOTICE file, all content, including all source code files and documentation files in this repository are: Licensed under the Apache License, Version 2.0 (the ""License""); you may not use this content except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
8,"JavaScript Style GuideAirbnb JavaScript Style Guide() { A mostly reasonable approach to JavaScript Note: this guide assumes you are using Babel, and requires that you use babel-preset-airbnb or the equivalent. It also assumes you are installing shims/polyfills in your app, with airbnb-browser-shims or the equivalent. This guide is available in other languages too. See Translation Other Style Guides ES5 (Deprecated) React CSS-in-JavaScript CSS & Sass Ruby Table of Contents Types References Objects Arrays Destructuring Strings Functions Arrow Functions Classes & Constructors Modules Iterators and Generators Properties Variables Hoisting Comparison Operators & Equality Blocks Control Statements Comments Whitespace Commas Semicolons Type Casting & Coercion Naming Conventions Accessors Events jQuery ECMAScript 5 Compatibility ECMAScript 6+ (ES 2015+) Styles Standard Library Testing Performance Resources In the Wild Translation The JavaScript Style Guide Guide Chat With Us About JavaScript Contributors License Amendments Types - 1.1 Primitives: When you access a primitive type you work directly on its value. - `string` - `number` - `boolean` - `null` - `undefined` - `symbol` - `bigint` - Symbols and BigInts cannot be faithfully polyfilled, so they should not be used when targeting browsers/environments that dont support them natively. - 1.2 Complex: When you access a complex type you work on a reference to its value. - `object` - `array` - `function` back to top References - 2.1 Use const for all of your references; avoid using var. eslint: prefer-const, no-const-assign > Why? This ensures that you cant reassign your references, which can lead to bugs and difficult to comprehend code. - 2.2 If you must reassign references, use let instead of var. eslint: no-var > Why? `let` is block-scoped rather than function-scoped like `var`. - 2.3 Note that both let and const are block-scoped, whereas var is function-scoped. In the above code, you can see that referencing `a` and `b` will produce a ReferenceError, while `c` contains the number. This is because `a` and `b` are block scoped, while `c` is scoped to the containing function. back to top Objects - 3.1 Use the literal syntax for object creation. eslint: no-new-object - 3.2 Use computed property names when creating objects with dynamic property names. > Why? They allow you to define all the properties of an object in one place. - 3.3 Use object method shorthand. eslint: object-shorthand - 3.4 Use property value shorthand. eslint: object-shorthand > Why? It is shorter and descriptive. - 3.5 Group your shorthand properties at the beginning of your object declaration. > Why? Its easier to tell which properties are using the shorthand. - 3.6 Only quote properties that are invalid identifiers. eslint: quote-props > Why? In general we consider it subjectively easier to read. It improves syntax highlighting, and is also more easily optimized by many JS engines. - 3.7 Do not call Object.prototype methods directly, such as hasOwnProperty, propertyIsEnumerable, and isPrototypeOf. eslint: no-prototype-builtins > Why? These methods may be shadowed by properties on the object in question - consider `{ hasOwnProperty: false }` - or, the object may be a null object (`Object.create(null)`). - 3.8 Prefer the object spread syntax over Object.assign to shallow-copy objects. Use the object rest operator to get a new object with certain properties omitted. eslint: prefer-object-spread back to top Arrays - 4.1 Use the literal syntax for array creation. eslint: no-array-constructor - 4.2 Use Array#push instead of direct assignment to add items to an array. - 4.3 Use array spreads ... to copy arrays. - 4.4 To convert an iterable object to an array, use spreads ... instead of Array.from. - 4.5 Use Array.from for converting an array-like object to an array. - 4.6 Use Array.from instead of spread ... for mapping over iterables, because it avoids creating an intermediate array. - 4.7 Use return statements in array method callbacks. Its ok to omit the return if the function body consists of a single statement returning an expression without side effects, following 8.2. eslint: array-callback-return - 4.8 Use line breaks after open and before close array brackets if an array has multiple lines back to top Destructuring - 5.1 Use object destructuring when accessing and using multiple properties of an object. eslint: prefer-destructuring > Why? Destructuring saves you from creating temporary references for those properties, and from repetitive access of the object. Repeating object access creates more repetitive code, requires more reading, and creates more opportunities for mistakes. Destructuring objects also provides a single site of definition of the object structure that is used in the block, rather than requiring reading the entire block to determine what is used. - 5.2 Use array destructuring. eslint: prefer-destructuring - 5.3 Use object destructuring for multiple return values, not array destructuring. > Why? You can add new properties over time or change the order of things without breaking call sites. back to top Strings - 6.1 Use single quotes '' for strings. eslint: quotes - 6.2 Strings that cause the line to go over 100 characters should not be written across multiple lines using string concatenation. > Why? Broken strings are painful to work with and make code less searchable. - 6.3 When programmatically building up strings, use template strings instead of concatenation. eslint: prefer-template template-curly-spacing > Why? Template strings give you a readable, concise syntax with proper newlines and string interpolation features. - 6.4 Never use eval() on a string, it opens too many vulnerabilities. eslint: no-eval - 6.5 Do not unnecessarily escape characters in strings. eslint: no-useless-escape > Why? Backslashes harm readability, thus they should only be present when necessary. back to top Functions - 7.1 Use named function expressions instead of function declarations. eslint: func-style > Why? Function declarations are hoisted, which means that its easy - too easy - to reference the function before it is defined in the file. This harms readability and maintainability. If you find that a functions definition is large or complex enough that it is interfering with understanding the rest of the file, then perhaps its time to extract it to its own module! Dont forget to explicitly name the expression, regardless of whether or not the name is inferred from the containing variable (which is often the case in modern browsers or when using compilers such as Babel). This eliminates any assumptions made about the Errors call stack. ([Discussion](https://github.com/airbnb/javascript/issues/794)) - 7.2 Wrap immediately invoked function expressions in parentheses. eslint: wrap-iife > Why? An immediately invoked function expression is a single unit - wrapping both it, and its invocation parens, in parens, cleanly expresses this. Note that in a world with modules everywhere, you almost never need an IIFE. - 7.3 Never declare a function in a non-function block (if, while, etc). Assign the function to a variable instead. Browsers will allow you to do it, but they all interpret it differently, which is bad news bears. eslint: no-loop-func - 7.4 Note: ECMA-262 defines a block as a list of statements. A function declaration is not a statement. - 7.5 Never name a parameter arguments. This will take precedence over the arguments object that is given to every function scope. - 7.6 Never use arguments, opt to use rest syntax ... instead. eslint: prefer-rest-params > Why? `...` is explicit about which arguments you want pulled. Plus, rest arguments are a real Array, and not merely Array-like like `arguments`. - 7.7 Use default parameter syntax rather than mutating function arguments. - 7.8 Avoid side effects with default parameters. > Why? They are confusing to reason about. - 7.9 Always put default parameters last. eslint: default-param-last - 7.10 Never use the Function constructor to create a new function. eslint: no-new-func > Why? Creating a function in this way evaluates a string similarly to `eval()`, which opens vulnerabilities. - 7.11 Spacing in a function signature. eslint: space-before-function-paren space-before-blocks > Why? Consistency is good, and you shouldnt have to add or remove a space when adding or removing a name. - 7.12 Never mutate parameters. eslint: no-param-reassign > Why? Manipulating objects passed in as parameters can cause unwanted variable side effects in the original caller. - 7.13 Never reassign parameters. eslint: no-param-reassign > Why? Reassigning parameters can lead to unexpected behavior, especially when accessing the `arguments` object. It can also cause optimization issues, especially in V8. - 7.14 Prefer the use of the spread syntax ... to call variadic functions. eslint: prefer-spread > Why? Its cleaner, you dont need to supply a context, and you can not easily compose `new` with `apply`. - 7.15 Functions with multiline signatures, or invocations, should be indented just like every other multiline list in this guide: with each item on a line by itself, with a trailing comma on the last item. eslint: function-paren-newline back to top Arrow Functions - 8.1 When you must use an anonymous function (as when passing an inline callback), use arrow function notation. eslint: prefer-arrow-callback, arrow-spacing > Why? It creates a version of the function that executes in the context of `this`, which is usually what you want, and is a more concise syntax. > Why not? If you have a fairly complicated function, you might move that logic out into its own named function expression. - 8.2 If the function body consists of a single statement returning an expression without side effects, omit the braces and use the implicit return. Otherwise, keep the braces and use a return statement. eslint: arrow-parens, arrow-body-style > Why? Syntactic sugar. It reads well when multiple functions are chained together. - 8.3 In case the expression spans over multiple lines, wrap it in parentheses for better readability. > Why? It shows clearly where the function starts and ends. - 8.4 Always include parentheses around arguments for clarity and consistency. eslint: arrow-parens > Why? Minimizes diff churn when adding or removing arguments. - 8.5 Avoid confusing arrow function syntax (=>) with comparison operators (<=, >=). eslint: no-confusing-arrow - 8.6 Enforce the location of arrow function bodies with implicit returns. eslint: implicit-arrow-linebreak back to top Classes & Constructors - 9.1 Always use class. Avoid manipulating prototype directly. > Why? `class` syntax is more concise and easier to reason about. - 9.2 Use extends for inheritance. > Why? It is a built-in way to inherit prototype functionality without breaking `instanceof`. - 9.3 Methods can return this to help with method chaining. - 9.4 Its okay to write a custom toString() method, just make sure it works successfully and causes no side effects. - 9.5 Classes have a default constructor if one is not specified. An empty constructor function or one that just delegates to a parent class is unnecessary. eslint: no-useless-constructor - 9.6 Avoid duplicate class members. eslint: no-dupe-class-members > Why? Duplicate class member declarations will silently prefer the last one - having duplicates is almost certainly a bug. - 9.7 Class methods should use this or be made into a static method unless an external library or framework requires to use specific non-static methods. Being an instance method should indicate that it behaves differently based on properties of the receiver. eslint: class-methods-use-this back to top Modules - 10.1 Always use modules (import/export) over a non-standard module system. You can always transpile to your preferred module system. > Why? Modules are the future, lets start using the future now. - 10.2 Do not use wildcard imports. > Why? This makes sure you have a single default export. - 10.3 And do not export directly from an import. > Why? Although the one-liner is concise, having one clear way to import and one clear way to export makes things consistent. - 10.4 Only import from a path in one place. eslint: no-duplicate-imports > Why? Having multiple lines that import from the same path can make code harder to maintain. - 10.5 Do not export mutable bindings. eslint: import/no-mutable-exports > Why? Mutation should be avoided in general, but in particular when exporting mutable bindings. While this technique may be needed for some special cases, in general, only constant references should be exported. - 10.6 In modules with a single export, prefer default export over named export. eslint: import/prefer-default-export > Why? To encourage more files that only ever export one thing, which is better for readability and maintainability. - 10.7 Put all imports above non-import statements. eslint: import/first > Why? Since imports are hoisted, keeping them all at the top prevents surprising behavior. - 10.8 Multiline imports should be indented just like multiline array and object literals. eslint: object-curly-newline > Why? The curly braces follow the same indentation rules as every other curly brace block in the style guide, as do the trailing commas. - 10.9 Disallow Webpack loader syntax in module import statements. eslint: import/no-webpack-loader-syntax > Why? Since using Webpack syntax in the imports couples the code to a module bundler. Prefer using the loader syntax in webpack.config.js. - 10.10 Do not include JavaScript filename extensions eslint: import/extensions > Why? Including extensions inhibits refactoring, and inappropriately hardcodes implementation details of the module you're importing in every consumer. back to top Iterators and Generators - 11.1 Dont use iterators. Prefer JavaScripts higher-order functions instead of loops like for-in or for-of. eslint: no-iterator no-restricted-syntax > Why? This enforces our immutable rule. Dealing with pure functions that return values is easier to reason about than side effects. > Use `map()` / `every()` / `filter()` / `find()` / `findIndex()` / `reduce()` / `some()` / ... to iterate over arrays, and `Object.keys()` / `Object.values()` / `Object.entries()` to produce arrays so you can iterate over objects. - 11.2 Dont use generators for now. > Why? They dont transpile well to ES5. - 11.3 If you must use generators, or if you disregard our advice, make sure their function signature is spaced properly. eslint: generator-star-spacing > Why? `function` and `*` are part of the same conceptual keyword - `*` is not a modifier for `function`, `function*` is a unique construct, different from `function`. back to top Properties - 12.1 Use dot notation when accessing properties. eslint: dot-notation - 12.2 Use bracket notation [] when accessing properties with a variable. - 12.3 Use exponentiation operator ** when calculating exponentiations. eslint: no-restricted-properties. back to top Variables - 13.1 Always use const or let to declare variables. Not doing so will result in global variables. We want to avoid polluting the global namespace. Captain Planet warned us of that. eslint: no-undef prefer-const - 13.2 Use one const or let declaration per variable or assignment. eslint: one-var > Why? Its easier to add new variable declarations this way, and you never have to worry about swapping out a `;` for a `,` or introducing punctuation-only diffs. You can also step through each declaration with the debugger, instead of jumping through all of them at once. - 13.3 Group all your consts and then group all your lets. > Why? This is helpful when later on you might need to assign a variable depending on one of the previously assigned variables. - 13.4 Assign variables where you need them, but place them in a reasonable place. > Why? `let` and `const` are block scoped and not function scoped. - 13.5 Dont chain variable assignments. eslint: no-multi-assign > Why? Chaining variable assignments creates implicit global variables. - 13.6 Avoid using unary increments and decrements (++, --). eslint no-plusplus > Why? Per the eslint documentation, unary increment and decrement statements are subject to automatic semicolon insertion and can cause silent errors with incrementing or decrementing values within an application. It is also more expressive to mutate your values with statements like `num += 1` instead of `num++` or `num ++`. Disallowing unary increment and decrement statements also prevents you from pre-incrementing/pre-decrementing values unintentionally which can also cause unexpected behavior in your programs. - 13.7 Avoid linebreaks before or after = in an assignment. If your assignment violates max-len, surround the value in parens. eslint operator-linebreak. > Why? Linebreaks surrounding `=` can obfuscate the value of an assignment. - 13.8 Disallow unused variables. eslint: no-unused-vars > Why? Variables that are declared and not used anywhere in the code are most likely an error due to incomplete refactoring. Such variables take up space in the code and can lead to confusion by readers. back to top Hoisting - 14.1 var declarations get hoisted to the top of their closest enclosing function scope, their assignment does not. const and let declarations are blessed with a new concept called Temporal Dead Zones (TDZ). Its important to know why typeof is no longer safe. - 14.2 Anonymous function expressions hoist their variable name, but not the function assignment. - 14.3 Named function expressions hoist the variable name, not the function name or the function body. - 14.4 Function declarations hoist their name and the function body. For more information refer to JavaScript Scoping & Hoisting by Ben Cherry. back to top Comparison Operators & Equality - 15.1 Use === and !== over == and !=. eslint: eqeqeq - 15.2 Conditional statements such as the if statement evaluate their expression using coercion with the ToBoolean abstract method and always follow these simple rules: - **Objects** evaluate to **true** - **Undefined** evaluates to **false** - **Null** evaluates to **false** - **Booleans** evaluate to **the value of the boolean** - **Numbers** evaluate to **false** if **+0, -0, or NaN**, otherwise **true** - **Strings** evaluate to **false** if an empty string `''`, otherwise **true** - 15.3 Use shortcuts for booleans, but explicit comparisons for strings and numbers. - 15.4 For more information see Truth Equality and JavaScript by Angus Croll. - 15.5 Use braces to create blocks in case and default clauses that contain lexical declarations (e.g. let, const, function, and class). eslint: no-case-declarations > Why? Lexical declarations are visible in the entire `switch` block but only get initialized when assigned, which only happens when its `case` is reached. This causes problems when multiple `case` clauses attempt to define the same thing. - 15.6 Ternaries should not be nested and generally be single line expressions. eslint: no-nested-ternary - 15.7 Avoid unneeded ternary statements. eslint: no-unneeded-ternary - 15.8 When mixing operators, enclose them in parentheses. The only exception is the standard arithmetic operators: +, -, and ** since their precedence is broadly understood. We recommend enclosing / and * in parentheses because their precedence can be ambiguous when they are mixed. eslint: no-mixed-operators > Why? This improves readability and clarifies the developers intention. back to top Blocks - 16.1 Use braces with all multiline blocks. eslint: nonblock-statement-body-position - 16.2 If youre using multiline blocks with if and else, put else on the same line as your if blocks closing brace. eslint: brace-style - 16.3 If an if block always executes a return statement, the subsequent else block is unnecessary. A return in an else if block following an if block that contains a return can be separated into multiple if blocks. eslint: no-else-return back to top Control Statements - 17.1 In case your control statement (if, while etc.) gets too long or exceeds the maximum line length, each (grouped) condition could be put into a new line. The logical operator should begin the line. > Why? Requiring operators at the beginning of the line keeps the operators aligned and follows a pattern similar to method chaining. This also improves readability by making it easier to visually follow complex logic. - 17.2 Don't use selection operators in place of control statements. back to top Comments - 18.1 Use /** ... */ for multiline comments. - 18.2 Use // for single line comments. Place single line comments on a newline above the subject of the comment. Put an empty line before the comment unless its on the first line of a block. - 18.3 Start all comments with a space to make it easier to read. eslint: spaced-comment - 18.4 Prefixing your comments with FIXME or TODO helps other developers quickly understand if youre pointing out a problem that needs to be revisited, or if youre suggesting a solution to the problem that needs to be implemented. These are different than regular comments because they are actionable. The actions are FIXME: -- need to figure this out or TODO: -- need to implement. - 18.5 Use // FIXME: to annotate problems. - 18.6 Use // TODO: to annotate solutions to problems. back to top Whitespace - 19.1 Use soft tabs (space character) set to 2 spaces. eslint: indent - 19.2 Place 1 space before the leading brace. eslint: space-before-blocks - 19.3 Place 1 space before the opening parenthesis in control statements (if, while etc.). Place no space between the argument list and the function name in function calls and declarations. eslint: keyword-spacing - 19.4 Set off operators with spaces. eslint: space-infix-ops - 19.5 End files with a single newline character. eslint: eol-last - 19.6 Use indentation when making long method chains (more than 2 method chains). Use a leading dot, which emphasizes that the line is a method call, not a new statement. eslint: newline-per-chained-call no-whitespace-before-property - 19.7 Leave a blank line after blocks and before the next statement. - 19.8 Do not pad your blocks with blank lines. eslint: padded-blocks - 19.9 Do not use multiple blank lines to pad your code. eslint: no-multiple-empty-lines <!-- markdownlint-disable MD012 --> - 19.10 Do not add spaces inside parentheses. eslint: space-in-parens - 19.11 Do not add spaces inside brackets. eslint: array-bracket-spacing - 19.12 Add spaces inside curly braces. eslint: object-curly-spacing - 19.13 Avoid having lines of code that are longer than 100 characters (including whitespace). Note: per above, long strings are exempt from this rule, and should not be broken up. eslint: max-len > Why? This ensures readability and maintainability. - 19.14 Require consistent spacing inside an open block token and the next token on the same line. This rule also enforces consistent spacing inside a close block token and previous token on the same line. eslint: block-spacing - 19.15 Avoid spaces before commas and require a space after commas. eslint: comma-spacing - 19.16 Enforce spacing inside of computed property brackets. eslint: computed-property-spacing - 19.17 Avoid spaces between functions and their invocations. eslint: func-call-spacing - 19.18 Enforce spacing between keys and values in object literal properties. eslint: key-spacing - 19.19 Avoid trailing spaces at the end of lines. eslint: no-trailing-spaces - 19.20 Avoid multiple empty lines, only allow one newline at the end of files, and avoid a newline at the beginning of files. eslint: no-multiple-empty-lines <!-- markdownlint-disable MD012 --> <!-- markdownlint-enable MD012 --> back to top Commas - 20.1 Leading commas: Nope. eslint: comma-style - 20.2 Additional trailing comma: Yup. eslint: comma-dangle > Why? This leads to cleaner git diffs. Also, transpilers like Babel will remove the additional trailing comma in the transpiled code which means you dont have to worry about the [trailing comma problem](https://github.com/airbnb/javascript/blob/es5-deprecated/es5/README.md#commas) in legacy browsers. back to top Semicolons - 21.1 Yup. eslint: semi > Why? When JavaScript encounters a line break without a semicolon, it uses a set of rules called [Automatic Semicolon Insertion](https://tc39.github.io/ecma262/#sec-automatic-semicolon-insertion) to determine whether or not it should regard that line break as the end of a statement, and (as the name implies) place a semicolon into your code before the line break if it thinks so. ASI contains a few eccentric behaviors, though, and your code will break if JavaScript misinterprets your line break. These rules will become more complicated as new features become a part of JavaScript. Explicitly terminating your statements and configuring your linter to catch missing semicolons will help prevent you from encountering issues. [Read more](https://stackoverflow.com/questions/7365172/semicolon-before-self-invoking-function/7365214#7365214). back to top Type Casting & Coercion - 22.1 Perform type coercion at the beginning of the statement. - 22.2 Strings: eslint: no-new-wrappers - 22.3 Numbers: Use Number for type casting and parseInt always with a radix for parsing strings. eslint: radix no-new-wrappers > Why? The `parseInt` function produces an integer value dictated by interpretation of the contents of the string argument according to the specified radix. Leading whitespace in string is ignored. If radix is `undefined` or `0`, it is assumed to be `10` except when the number begins with the character pairs `0x` or `0X`, in which case a radix of 16 is assumed. This differs from ECMAScript 3, which merely discouraged (but allowed) octal interpretation. Many implementations have not adopted this behavior as of 2013. And, because older browsers must be supported, always specify a radix. - 22.4 If for whatever reason you are doing something wild and parseInt is your bottleneck and need to use Bitshift for performance reasons, leave a comment explaining why and what youre doing. - 22.5 Note: Be careful when using bitshift operations. Numbers are represented as 64-bit values, but bitshift operations always return a 32-bit integer (source). Bitshift can lead to unexpected behavior for integer values larger than 32 bits. Discussion. Largest signed 32-bit Int is 2,147,483,647: - 22.6 Booleans: eslint: no-new-wrappers back to top Naming Conventions - 23.1 Avoid single letter names. Be descriptive with your naming. eslint: id-length - 23.2 Use camelCase when naming objects, functions, and instances. eslint: camelcase - 23.3 Use PascalCase only when naming constructors or classes. eslint: new-cap - 23.4 Do not use trailing or leading underscores. eslint: no-underscore-dangle > Why? JavaScript does not have the concept of privacy in terms of properties or methods. Although a leading underscore is a common convention to mean private, in fact, these properties are fully public, and as such, are part of your public API contract. This convention might lead developers to wrongly think that a change wont count as breaking, or that tests arent needed. tl;dr: if you want something to be private, it must not be observably present. - 23.5 Dont save references to this. Use arrow functions or Function#bind. - 23.6 A base filename should exactly match the name of its default export. - 23.7 Use camelCase when you export-default a function. Your filename should be identical to your functions name. - 23.8 Use PascalCase when you export a constructor / class / singleton / function library / bare object. - 23.9 Acronyms and initialisms should always be all uppercased, or all lowercased. > Why? Names are for readability, not to appease a computer algorithm. - 23.10 You may optionally uppercase a constant only if it (1) is exported, (2) is a const (it can not be reassigned), and (3) the programmer can trust it (and its nested properties) to never change. > Why? This is an additional tool to assist in situations where the programmer would be unsure if a variable might ever change. UPPERCASE_VARIABLES are letting the programmer know that they can trust the variable (and its properties) not to change. - What about all `const` variables? - This is unnecessary, so uppercasing should not be used for constants within a file. It should be used for exported constants however. - What about exported objects? - Uppercase at the top level of export (e.g. `EXPORTED_OBJECT.key`) and maintain that all nested properties do not change. back to top Accessors - 24.1 Accessor functions for properties are not required. - 24.2 Do not use JavaScript getters/setters as they cause unexpected side effects and are harder to test, maintain, and reason about. Instead, if you do make accessor functions, use getVal() and setVal('hello'). - 24.3 If the property/method is a boolean, use isVal() or hasVal(). - 24.4 Its okay to create get() and set() functions, but be consistent. back to top Events - 25.1 When attaching data payloads to events (whether DOM events or something more proprietary like Backbone events), pass an object literal (also known as a ""hash"") instead of a raw value. This allows a subsequent contributor to add more data to the event payload without finding and updating every handler for the event. For example, instead of: prefer: back to top jQuery - 26.1 Prefix jQuery object variables with a $. - 26.2 Cache jQuery lookups. - 26.3 For DOM queries use Cascading $('.sidebar ul') or parent > child $('.sidebar > ul'). jsPerf - 26.4 Use find with scoped jQuery object queries. back to top ECMAScript 5 Compatibility - 27.1 Refer to Kangaxs ES5 compatibility table. back to top ECMAScript 6+ (ES 2015+) Styles - 28.1 This is a collection of links to the various ES6+ features. Arrow Functions Classes Object Shorthand Object Concise Object Computed Properties Template Strings Destructuring Default Parameters Rest Array Spreads Let and Const Exponentiation Operator Iterators and Generators Modules - 28.2 Do not use TC39 proposals that have not reached stage 3. > Why? [They are not finalized](https://tc39.github.io/process-document/), and they are subject to change or to be withdrawn entirely. We want to use JavaScript, and proposals are not JavaScript yet. back to top Standard Library The Standard Library contains utilities that are functionally broken but remain for legacy reasons. - 29.1 Use Number.isNaN instead of global isNaN. eslint: no-restricted-globals > Why? The global `isNaN` coerces non-numbers to numbers, returning true for anything that coerces to NaN. > If this behavior is desired, make it explicit. - 29.2 Use Number.isFinite instead of global isFinite. eslint: no-restricted-globals > Why? The global `isFinite` coerces non-numbers to numbers, returning true for anything that coerces to a finite number. > If this behavior is desired, make it explicit. back to top Testing - 30.1 Yup. - 30.2 No, but seriously: - Whichever testing framework you use, you should be writing tests! - Strive to write many small pure functions, and minimize where mutations occur. - Be cautious about stubs and mocks - they can make your tests more brittle. - We primarily use mocha and jest at Airbnb. tape is also used occasionally for small, separate modules. - 100% test coverage is a good goal to strive for, even if its not always practical to reach it. - Whenever you fix a bug, write a regression test. A bug fixed without a regression test is almost certainly going to break again in the future. back to top Performance On Layout & Web Performance String vs Array Concat Try/Catch Cost In a Loop Bang Function jQuery Find vs Context, Selector innerHTML vs textContent for script text Long String Concatenation Are JavaScript functions like map(), reduce(), and filter() optimized for traversing arrays? Loading... back to top Resources Learning ES6+ Latest ECMA spec ExploringJS ES6 Compatibility Table Comprehensive Overview of ES6 Features Read This Standard ECMA-262 Tools Code Style Linters ESlint - Airbnb Style .eslintrc JSHint - Airbnb Style .jshintrc Neutrino Preset - @neutrinojs/airbnb Other Style Guides Google JavaScript Style Guide Google JavaScript Style Guide (Old) jQuery Core Style Guidelines Principles of Writing Consistent, Idiomatic JavaScript StandardJS Other Styles Naming this in nested functions - Christian Johansen Conditional Callbacks - Ross Allen Popular JavaScript Coding Conventions on GitHub - JeongHoon Byun Multiple var statements in JavaScript, not superfluous - Ben Alman Further Reading Understanding JavaScript Closures - Angus Croll Basic JavaScript for the impatient programmer - Dr. Axel Rauschmayer You Might Not Need jQuery - Zack Bloom & Adam Schwartz ES6 Features - Luke Hoban Frontend Guidelines - Benjamin De Cock Books JavaScript: The Good Parts - Douglas Crockford JavaScript Patterns - Stoyan Stefanov Pro JavaScript Design Patterns - Ross Harmes and Dustin Diaz High Performance Web Sites: Essential Knowledge for Front-End Engineers - Steve Souders Maintainable JavaScript - Nicholas C. Zakas JavaScript Web Applications - Alex MacCaw Pro JavaScript Techniques - John Resig Smashing Node.js: JavaScript Everywhere - Guillermo Rauch Secrets of the JavaScript Ninja - John Resig and Bear Bibeault Human JavaScript - Henrik Joreteg Superhero.js - Kim Joar Bekkelund, Mads Mobk, & Olav Bjorkoy JSBooks - Julien Bouquillon Third Party JavaScript - Ben Vinegar and Anton Kovalyov Effective JavaScript: 68 Specific Ways to Harness the Power of JavaScript - David Herman Eloquent JavaScript - Marijn Haverbeke You Dont Know JS: ES6 & Beyond - Kyle Simpson Blogs JavaScript Weekly JavaScript, JavaScript... Bocoup Weblog Adequately Good NCZOnline Perfection Kills Ben Alman Dmitry Baranovskiy nettuts Podcasts JavaScript Air JavaScript Jabber back to top In the Wild This is a list of organizations that are using this style guide. Send us a pull request and we'll add you to the list. 123erfasst: 123erfasst/javascript 4Catalyzer: 4Catalyzer/javascript Aan Zee: AanZee/javascript Airbnb: airbnb/javascript AloPeyk: AloPeyk AltSchool: AltSchool/javascript Apartmint: apartmint/javascript Ascribe: ascribe/javascript Avant: avantcredit/javascript Axept: axept/javascript Billabong: billabong/javascript Bisk: bisk Bonhomme: bonhommeparis/javascript Brainshark: brainshark/javascript CaseNine: CaseNine/javascript Cerner: Cerner Chartboost: ChartBoost/javascript-style-guide Coeur d'Alene Tribe: www.cdatribe-nsn.gov ComparaOnline: comparaonline/javascript Compass Learning: compasslearning/javascript-style-guide DailyMotion: dailymotion/javascript DoSomething: DoSomething/eslint-config Digitpaint digitpaint/javascript Drupal: www.drupal.org Ecosia: ecosia/javascript Evernote: evernote/javascript-style-guide Evolution Gaming: evolution-gaming/javascript EvozonJs: evozonjs/javascript ExactTarget: ExactTarget/javascript Flexberry: Flexberry/javascript-style-guide Gawker Media: gawkermedia General Electric: GeneralElectric/javascript Generation Tux: GenerationTux/javascript GoodData: gooddata/gdc-js-style GreenChef: greenchef/javascript Grooveshark: grooveshark/javascript Grupo-Abraxas: Grupo-Abraxas/javascript Happeo: happeo/javascript Honey: honeyscience/javascript How About We: howaboutwe/javascript HubSpot: HubSpot/javascript Hyper: hyperoslo/javascript-playbook InterCity Group: intercitygroup/javascript-style-guide Jam3: Jam3/Javascript-Code-Conventions JSSolutions: JSSolutions/javascript Kaplan Komputing: kaplankomputing/javascript KickorStick: kickorstick Kinetica Solutions: kinetica/javascript LEINWAND: LEINWAND/javascript Lonely Planet: lonelyplanet/javascript M2GEN: M2GEN/javascript Mighty Spring: mightyspring/javascript MinnPost: MinnPost/javascript MitocGroup: MitocGroup/javascript Muber: muber National Geographic: natgeo NullDev: NullDevCo/JavaScript-Styleguide Nulogy: nulogy/javascript Orange Hill Development: orangehill/javascript Orion Health: orionhealth/javascript OutBoxSoft: OutBoxSoft/javascript Peerby: Peerby/javascript Pier 1: Pier1/javascript Qotto: Qotto/javascript-style-guide React: facebook.github.io/react/contributing/how-to-contribute.html#style-guide REI: reidev/js-style-guide Ripple: ripple/javascript-style-guide Sainsburys Supermarkets: jsainsburyplc Shutterfly: shutterfly/javascript Sourcetoad: sourcetoad/javascript Springload: springload StratoDem Analytics: stratodem/javascript SteelKiwi Development: steelkiwi/javascript StudentSphere: studentsphere/javascript SwoopApp: swoopapp/javascript SysGarage: sysgarage/javascript-style-guide Syzygy Warsaw: syzygypl/javascript Target: target/javascript Terra: terra TheLadders: TheLadders/javascript The Nerdery: thenerdery/javascript-standards Tomify: tomprats Traitify: traitify/eslint-config-traitify T4R Technology: T4R-Technology/javascript UrbanSim: urbansim VoxFeed: VoxFeed/javascript-style-guide WeBox Studio: weboxstudio/javascript Weggo: Weggo/javascript Zillow: zillow/javascript ZocDoc: ZocDoc/javascript back to top Translation This style guide is also available in other languages: Brazilian Portuguese: armoucar/javascript-style-guide Bulgarian: borislavvv/javascript Catalan: fpmweb/javascript-style-guide Chinese (Simplified): lin-123/javascript Chinese (Traditional): jigsawye/javascript French: nmussy/javascript-style-guide German: timofurrer/javascript-style-guide Italian: sinkswim/javascript-style-guide Japanese: mitsuruog/javascript-style-guide Korean: ParkSB/javascript-style-guide Russian: leonidlebedev/javascript-airbnb Spanish: paolocarrasco/javascript-style-guide Thai: lvarayut/javascript-style-guide Turkish: eraycetinay/javascript Ukrainian: ivanzusko/javascript Vietnam: dangkyokhoang/javascript-style-guide The JavaScript Style Guide Guide Reference Chat With Us About JavaScript Find us on gitter. Contributors View Contributors License (The MIT License) Copyright (c) 2012 Airbnb Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the 'Software'), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED 'AS IS', WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. back to top Amendments We encourage you to fork this guide and change the rules to fit your teams style guide. Below, you may list some amendments to the style guide. This allows you to periodically update your style guide without having to deal with merge conflicts. };"
4609,"A PHP string manipulation library with multibyte supportA PHP string manipulation library with multibyte support. Compatible with PHP 5.4+, PHP 7+, and HHVM. Refer to the 1.x branch or 2.x branch for older documentation. Why? Installation OO and Chaining Implemented Interfaces PHP 5.6 Creation StaticStringy Class methods create Instance methods append at between camelize chars collapseWhitespace contains containsAll containsAny countSubstr dasherize delimit endsWith endsWithAny ensureLeft ensureRight first getEncoding hasLowerCase hasUpperCase htmlDecode htmlEncode humanize indexOf indexOfLast insert isAlpha isAlphanumeric isBase64 isBlank isHexadecimal isJson isLowerCase isSerialized isUpperCase last length lines longestCommonPrefix longestCommonSuffix longestCommonSubstring lowerCaseFirst pad padBoth padLeft padRight prepend regexReplace removeLeft removeRight repeat replace reverse safeTruncate shuffle slugify slice split startsWith startsWithAny stripWhitespace substr surround swapCase tidy titleize toAscii toBoolean toLowerCase toSpaces toTabs toTitleCase toUpperCase trim trimLeft trimRight truncate underscored upperCamelize upperCaseFirst Extensions Tests License Why? In part due to a lack of multibyte support (including UTF-8) across many of PHP's standard string functions. But also to offer an OO wrapper around the mbstring module's multibyte-compatible functions. Stringy handles some quirks, provides additional functionality, and hopefully makes strings a little easier to work with! Installation If you're using Composer to manage dependencies, you can include the following in your composer.json file: Then, after running composer update or php composer.phar update, you can load the class using Composer's autoloading: Otherwise, you can simply require the file directly: And in either case, I'd suggest using an alias. Please note that Stringy relies on the mbstring module for its underlying multibyte support. If the module is not found, Stringy will use symfony/polyfill-mbstring. ex-mbstring is a non-default, but very common module. For example, with debian and ubuntu, it's included in libapache2-mod-php5, php5-cli, and php5-fpm. For OSX users, it's a default for any version of PHP installed with homebrew. If compiling PHP from scratch, it can be included with the --enable-mbstring flag. OO and Chaining The library offers OO method chaining, as seen below: Stringy\Stringy has a __toString() method, which returns the current string when the object is used in a string context, ie: (string) S::create('foo') // 'foo' Implemented Interfaces Stringy\Stringy implements the IteratorAggregate interface, meaning that foreach can be used with an instance of the class: It implements the Countable interface, enabling the use of count() to retrieve the number of characters in the string: Furthermore, the ArrayAccess interface has been implemented. As a result, isset() can be used to check if a character at a specific index exists. And since Stringy\Stringy is immutable, any call to offsetSet or offsetUnset will throw an exception. offsetGet has been implemented, however, and accepts both positive and negative indexes. Invalid indexes result in an OutOfBoundsException. PHP 5.6 Creation As of PHP 5.6, use function is available for importing functions. Stringy exposes a namespaced function, Stringy\create, which emits the same behaviour as Stringy\Stringy::create(). If running PHP 5.6, or another runtime that supports the use function syntax, you can take advantage of an even simpler API as seen below: StaticStringy All methods listed under ""Instance methods"" are available as part of a static wrapper. For StaticStringy methods, the optional encoding is expected to be the last argument. The return value is not cast, and may thus be of type Stringy, integer, boolean, etc. Class methods create(mixed $str [, $encoding ]) Creates a Stringy object and assigns both str and encoding properties the supplied values. $str is cast to a string prior to assignment, and if $encoding is not specified, it defaults to mb_internal_encoding(). It then returns the initialized object. Throws an InvalidArgumentException if the first argument is an array or object without a __toString method. Instance Methods Stringy objects are immutable. All examples below make use of PHP 5.6 function importing, and PHP 5.4 short array syntax. They also assume the encoding returned by mb_internal_encoding() is UTF-8. For further details, see the documentation for the create method above, as well as the notes on PHP 5.6 creation. append(string $string) Returns a new string with $string appended. at(int $index) Returns the character at $index, with indexes starting at 0. between(string $start, string $end [, int $offset]) Returns the substring between $start and $end, if found, or an empty string. An optional offset may be supplied from which to begin the search for the start string. camelize() Returns a camelCase version of the string. Trims surrounding spaces, capitalizes letters following digits, spaces, dashes and underscores, and removes spaces, dashes, as well as underscores. chars() Returns an array consisting of the characters in the string. collapseWhitespace() Trims the string and replaces consecutive whitespace characters with a single space. This includes tabs and newline characters, as well as multibyte whitespace such as the thin space and ideographic space. contains(string $needle [, boolean $caseSensitive = true ]) Returns true if the string contains $needle, false otherwise. By default, the comparison is case-sensitive, but can be made insensitive by setting $caseSensitive to false. containsAll(array $needles [, boolean $caseSensitive = true ]) Returns true if the string contains all $needles, false otherwise. By default the comparison is case-sensitive, but can be made insensitive by setting $caseSensitive to false. containsAny(array $needles [, boolean $caseSensitive = true ]) Returns true if the string contains any $needles, false otherwise. By default the comparison is case-sensitive, but can be made insensitive by setting $caseSensitive to false. countSubstr(string $substring [, boolean $caseSensitive = true ]) Returns the number of occurrences of $substring in the given string. By default, the comparison is case-sensitive, but can be made insensitive by setting $caseSensitive to false. dasherize() Returns a lowercase and trimmed string separated by dashes. Dashes are inserted before uppercase characters (with the exception of the first character of the string), and in place of spaces as well as underscores. delimit(int $delimiter) Returns a lowercase and trimmed string separated by the given delimiter. Delimiters are inserted before uppercase characters (with the exception of the first character of the string), and in place of spaces, dashes, and underscores. Alpha delimiters are not converted to lowercase. endsWith(string $substring [, boolean $caseSensitive = true ]) Returns true if the string ends with $substring, false otherwise. By default, the comparison is case-sensitive, but can be made insensitive by setting $caseSensitive to false. endsWithAny(string $substrings [, boolean $caseSensitive = true ]) Returns true if the string ends with any of $substrings, false otherwise. By default, the comparison is case-sensitive, but can be made insensitive by setting $caseSensitive to false. ensureLeft(string $substring) Ensures that the string begins with $substring. If it doesn't, it's prepended. ensureRight(string $substring) Ensures that the string ends with $substring. If it doesn't, it's appended. first(int $n) Returns the first $n characters of the string. getEncoding() Returns the encoding used by the Stringy object. hasLowerCase() Returns true if the string contains a lower case char, false otherwise. hasUpperCase() Returns true if the string contains an upper case char, false otherwise. htmlDecode() Convert all HTML entities to their applicable characters. An alias of html_entity_decode. For a list of flags, refer to http://php.net/manual/en/function.html-entity-decode.php htmlEncode() Convert all applicable characters to HTML entities. An alias of htmlentities. Refer to http://php.net/manual/en/function.htmlentities.php for a list of flags. humanize() Capitalizes the first word of the string, replaces underscores with spaces, and strips '_id'. indexOf(string $needle [, $offset = 0 ]); Returns the index of the first occurrence of $needle in the string, and false if not found. Accepts an optional offset from which to begin the search. A negative index searches from the end indexOfLast(string $needle [, $offset = 0 ]); Returns the index of the last occurrence of $needle in the string, and false if not found. Accepts an optional offset from which to begin the search. Offsets may be negative to count from the last character in the string. insert(int $index, string $substring) Inserts $substring into the string at the $index provided. isAlpha() Returns true if the string contains only alphabetic chars, false otherwise. isAlphanumeric() Returns true if the string contains only alphabetic and numeric chars, false otherwise. isBase64() Returns true if the string is base64 encoded, false otherwise. isBlank() Returns true if the string contains only whitespace chars, false otherwise. isHexadecimal() Returns true if the string contains only hexadecimal chars, false otherwise. isJson() Returns true if the string is JSON, false otherwise. Unlike json_decode in PHP 5.x, this method is consistent with PHP 7 and other JSON parsers, in that an empty string is not considered valid JSON. isLowerCase() Returns true if the string contains only lower case chars, false otherwise. isSerialized() Returns true if the string is serialized, false otherwise. isUpperCase() Returns true if the string contains only upper case chars, false otherwise. last(int $n) Returns the last $n characters of the string. length() Returns the length of the string. An alias for PHP's mb_strlen() function. lines() Splits on newlines and carriage returns, returning an array of Stringy objects corresponding to the lines in the string. longestCommonPrefix(string $otherStr) Returns the longest common prefix between the string and $otherStr. longestCommonSuffix(string $otherStr) Returns the longest common suffix between the string and $otherStr. longestCommonSubstring(string $otherStr) Returns the longest common substring between the string and $otherStr. In the case of ties, it returns that which occurs first. lowerCaseFirst() Converts the first character of the supplied string to lower case. pad(int $length [, string $padStr = ' ' [, string $padType = 'right' ]]) Pads the string to a given length with $padStr. If length is less than or equal to the length of the string, no padding takes places. The default string used for padding is a space, and the default type (one of 'left', 'right', 'both') is 'right'. Throws an InvalidArgumentException if $padType isn't one of those 3 values. padBoth(int $length [, string $padStr = ' ' ]) Returns a new string of a given length such that both sides of the string string are padded. Alias for pad() with a $padType of 'both'. padLeft(int $length [, string $padStr = ' ' ]) Returns a new string of a given length such that the beginning of the string is padded. Alias for pad() with a $padType of 'left'. padRight(int $length [, string $padStr = ' ' ]) Returns a new string of a given length such that the end of the string is padded. Alias for pad() with a $padType of 'right'. prepend(string $string) Returns a new string starting with $string. regexReplace(string $pattern, string $replacement [, string $options = 'msr']) Replaces all occurrences of $pattern in $str by $replacement. An alias for mb_ereg_replace(). Note that the 'i' option with multibyte patterns in mb_ereg_replace() requires PHP 5.6+ for correct results. This is due to a lack of support in the bundled version of Oniguruma in PHP < 5.6, and current versions of HHVM (3.8 and below). removeLeft(string $substring) Returns a new string with the prefix $substring removed, if present. removeRight(string $substring) Returns a new string with the suffix $substring removed, if present. repeat(int $multiplier) Returns a repeated string given a multiplier. An alias for str_repeat. replace(string $search, string $replacement) Replaces all occurrences of $search in $str by $replacement. reverse() Returns a reversed string. A multibyte version of strrev(). safeTruncate(int $length [, string $substring = '' ]) Truncates the string to a given length, while ensuring that it does not split words. If $substring is provided, and truncating occurs, the string is further truncated so that the substring may be appended without exceeding the desired length. shuffle() A multibyte str_shuffle() function. It returns a string with its characters in random order. slugify([, string $replacement = '-' [, string $language = 'en']]) Converts the string into an URL slug. This includes replacing non-ASCII characters with their closest ASCII equivalents, removing remaining non-ASCII and non-alphanumeric characters, and replacing whitespace with $replacement. The replacement defaults to a single dash, and the string is also converted to lowercase. The language of the source string can also be supplied for language-specific transliteration. slice(int $start [, int $end ]) Returns the substring beginning at $start, and up to, but not including the index specified by $end. If $end is omitted, the function extracts the remaining string. If $end is negative, it is computed from the end of the string. split(string $pattern [, int $limit ]) Splits the string with the provided regular expression, returning an array of Stringy objects. An optional integer $limit will truncate the results. startsWith(string $substring [, boolean $caseSensitive = true ]) Returns true if the string begins with $substring, false otherwise. By default, the comparison is case-sensitive, but can be made insensitive by setting $caseSensitive to false. startsWithAny(string $substrings [, boolean $caseSensitive = true ]) Returns true if the string begins with any of $substrings, false otherwise. By default the comparison is case-sensitive, but can be made insensitive by setting $caseSensitive to false. stripWhitespace() Strip all whitespace characters. This includes tabs and newline characters, as well as multibyte whitespace such as the thin space and ideographic space. substr(int $start [, int $length ]) Returns the substring beginning at $start with the specified $length. It differs from the mb_substr() function in that providing a $length of null will return the rest of the string, rather than an empty string. surround(string $substring) Surrounds a string with the given substring. swapCase() Returns a case swapped version of the string. tidy() Returns a string with smart quotes, ellipsis characters, and dashes from Windows-1252 (commonly used in Word documents) replaced by their ASCII equivalents. titleize([, array $ignore]) Returns a trimmed string with the first letter of each word capitalized. Also accepts an array, $ignore, allowing you to list words not to be capitalized. toAscii([, string $language = 'en' [, bool $removeUnsupported = true ]]) Returns an ASCII version of the string. A set of non-ASCII characters are replaced with their closest ASCII counterparts, and the rest are removed by default. The language or locale of the source string can be supplied for language-specific transliteration in any of the following formats: en, en_GB, or en-GB. For example, passing ""de"" results in """" mapping to ""aeoeue"" rather than ""aou"" as in other languages. toBoolean() Returns a boolean representation of the given logical string value. For example, 'true', '1', 'on' and 'yes' will return true. 'false', '0', 'off', and 'no' will return false. In all instances, case is ignored. For other numeric strings, their sign will determine the return value. In addition, blank strings consisting of only whitespace will return false. For all other strings, the return value is a result of a boolean cast. toLowerCase() Converts all characters in the string to lowercase. An alias for PHP's mb_strtolower(). toSpaces([, tabLength = 4 ]) Converts each tab in the string to some number of spaces, as defined by $tabLength. By default, each tab is converted to 4 consecutive spaces. toTabs([, tabLength = 4 ]) Converts each occurrence of some consecutive number of spaces, as defined by $tabLength, to a tab. By default, each 4 consecutive spaces are converted to a tab. toTitleCase() Converts the first character of each word in the string to uppercase. toUpperCase() Converts all characters in the string to uppercase. An alias for PHP's mb_strtoupper(). trim([, string $chars]) Returns a string with whitespace removed from the start and end of the string. Supports the removal of unicode whitespace. Accepts an optional string of characters to strip instead of the defaults. trimLeft([, string $chars]) Returns a string with whitespace removed from the start of the string. Supports the removal of unicode whitespace. Accepts an optional string of characters to strip instead of the defaults. trimRight([, string $chars]) Returns a string with whitespace removed from the end of the string. Supports the removal of unicode whitespace. Accepts an optional string of characters to strip instead of the defaults. truncate(int $length [, string $substring = '' ]) Truncates the string to a given length. If $substring is provided, and truncating occurs, the string is further truncated so that the substring may be appended without exceeding the desired length. underscored() Returns a lowercase and trimmed string separated by underscores. Underscores are inserted before uppercase characters (with the exception of the first character of the string), and in place of spaces as well as dashes. upperCamelize() Returns an UpperCamelCase version of the supplied string. It trims surrounding spaces, capitalizes letters following digits, spaces, dashes and underscores, and removes spaces, dashes, underscores. upperCaseFirst() Converts the first character of the supplied string to upper case. Extensions The following is a list of libraries that extend Stringy: SliceableStringy: Python-like string slices in PHP SubStringy: Advanced substring methods Tests From the project directory, tests can be ran using phpunit License Released under the MIT License - see LICENSE.txt for details."
3998,"JumpServer 4A JumpServer ENGLISH || |------------------| |JumpServerhttps://jinshuju.net/f/E0qAl8| JumpServer GNU GPL v2.0 4A JumpServer Python / Django Web 2.0 Web Terminal JumpServer : : : Web Terminal : : : : WindowsKubernetes Authentication LDAP/AD RADIUS OpenID CAS MFA MFA Google Authenticator RADIUS :small_orange_diamond: Account :small_orange_diamond: :small_orange_diamond: :small_orange_diamond: :small_orange_diamond: :small_orange_diamond: Authorization MySQL RemoteApp :small_orange_diamond: SFTP / Web SFTP :small_orange_diamond: :small_orange_diamond: Audit LinuxWindows RemoteApp:small_orange_diamond:MySQL Database Web UI :small_orange_diamond: MySQL Oracle :small_orange_diamond: MariaDB :small_orange_diamond: PostgreSQL :small_orange_diamond: SQL SQL DB, TABLE : :small_orange_diamond: X-PACK Lina JumpServer Web UI Luna JumpServer Web Terminal KoKo JumpServer Connector Python Coco Guacamole JumpServer Connector Apache Guacamole Bug, Pull Request JumpServer Apache Guacamole Web RDP, SSH, VNCJumpServer OmniDB WebJumpServer Web JumpServer JumpServer JumpServer IT JumpServer JumpServer JumpServer JumpServer JumpServer JumpServer JumpServer . ibuler@fit2cloud.com support@fit2cloud.com 400-052-0755 License & Copyright Copyright (c) 2014-2020 FIT2CLOUD, All rights reserved. Licensed under The GNU General Public License version 2 (GPLv2) (the ""License""); you may not use this file except in compliance with the License. You may obtain a copy of the License at https://www.gnu.org/licenses/gpl-2.0.html Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
3411,"A modern formatting library{fmt} .. image:: https://github.com/fmtlib/fmt/workflows/linux/badge.svg :target: https://github.com/fmtlib/fmt/actions?query=workflow%3Alinux .. image:: https://github.com/fmtlib/fmt/workflows/macos/badge.svg :target: https://github.com/fmtlib/fmt/actions?query=workflow%3Amacos .. image:: https://github.com/fmtlib/fmt/workflows/windows/badge.svg :target: https://github.com/fmtlib/fmt/actions?query=workflow%3Awindows .. image:: https://ci.appveyor.com/api/projects/status/ehjkiefde6gucy1v :target: https://ci.appveyor.com/project/vitaut/fmt .. image:: https://oss-fuzz-build-logs.storage.googleapis.com/badges/fmt.svg :alt: fmt is continuously fuzzed at oss-fuzz :target: https://bugs.chromium.org/p/oss-fuzz/issues/list?\ colspec=ID%20Type%20Component%20Status%20Proj%20Reported%20Owner%20\ Summary&q=proj%3Dfmt&can=1 .. image:: https://img.shields.io/badge/stackoverflow-fmt-blue.svg :alt: Ask questions at StackOverflow with the tag fmt :target: https://stackoverflow.com/questions/tagged/fmt {fmt} is an open-source formatting library providing a fast and safe alternative to C stdio and C++ iostreams. If you like this project, please consider donating to BY_Help, an initiative to help victims of political repressions in Belarus: https://www.facebook.com/donate/199475051809330/. Documentation <https://fmt.dev>__ Q&A: ask questions on StackOverflow with the tag fmt <https://stackoverflow.com/questions/tagged/fmt>_. Try {fmt} in Compiler Explorer <https://godbolt.org/z/Eq5763>_. Features Simple format API <https://fmt.dev/latest/api.html>_ with positional arguments for localization Implementation of C++20 std::format <https://en.cppreference.com/w/cpp/utility/format>__ Format string syntax <https://fmt.dev/latest/syntax.html> similar to Python's format <https://docs.python.org/3/library/stdtypes.html#str.format> Fast IEEE 754 floating-point formatter with correct rounding, shortness and round-trip guarantees Safe printf implementation <https://fmt.dev/latest/api.html#printf-formatting>_ including the POSIX extension for positional arguments Extensibility: support for user-defined types <https://fmt.dev/latest/api.html#formatting-user-defined-types>_ High performance: faster than common standard library implementations of (s)printf, iostreams, to_string and to_chars, see Speed tests and Converting a hundred million integers to strings per second <http://www.zverovich.net/2020/06/13/fast-int-to-string-revisited.html> Small code size both in terms of source code with the minimum configuration consisting of just three files, core.h, format.h and format-inl.h, and compiled code; see Compile time and code bloat_ Reliability: the library has an extensive set of tests <https://github.com/fmtlib/fmt/tree/master/test> and is continuously fuzzed <https://bugs.chromium.org/p/oss-fuzz/issues/list?colspec=ID%20Type%20 Component%20Status%20Proj%20Reported%20Owner%20Summary&q=proj%3Dfmt&can=1> Safety: the library is fully type safe, errors in format strings can be reported at compile time, automatic memory management prevents buffer overflow errors Ease of use: small self-contained code base, no external dependencies, permissive MIT license <https://github.com/fmtlib/fmt/blob/master/LICENSE.rst>_ Portability <https://fmt.dev/latest/index.html#portability>_ with consistent output across platforms and support for older compilers Clean warning-free codebase even on high warning levels such as -Wall -Wextra -pedantic Locale-independence by default Optional header-only configuration enabled with the FMT_HEADER_ONLY macro See the documentation <https://fmt.dev>_ for more details. Examples Print to stdout (run <https://godbolt.org/z/Tevcjh>_) .. code:: c++ #include <fmt/core.h> int main() { fmt::print(""Hello, world!\n""); } Format a string (run <https://godbolt.org/z/oK8h33>_) .. code:: c++ std::string s = fmt::format(""The answer is {}."", 42); // s == ""The answer is 42."" Format a string using positional arguments (run <https://godbolt.org/z/Yn7Txe>_) .. code:: c++ std::string s = fmt::format(""I'd rather be {1} than {0}."", ""right"", ""happy""); // s == ""I'd rather be happy than right."" Print chrono durations (run <https://godbolt.org/z/K8s4Mc>_) .. code:: c++ #include <fmt/chrono.h> int main() { using namespace std::literals::chrono_literals; fmt::print(""Default format: {} {}\n"", 42s, 100ms); fmt::print(""strftime-like format: {:%H:%M:%S}\n"", 3h + 15min + 30s); } Output:: Default format: 42s 100ms strftime-like format: 03:15:30 Print a container (run <https://godbolt.org/z/MjsY7c>_) .. code:: c++ #include <vector> #include <fmt/ranges.h> int main() { std::vector<int> v = {1, 2, 3}; fmt::print(""{}\n"", v); } Output:: [1, 2, 3] Check a format string at compile time .. code:: c++ std::string s = fmt::format(FMT_STRING(""{:d}""), ""I am not a number""); This gives a compile-time error because d is an invalid format specifier for a string. Write a file from a single thread .. code:: c++ #include <fmt/os.h> int main() { auto out = fmt::output_file(""guide.txt""); out.print(""Don't {}"", ""Panic""); } This can be 5 to 9 times faster than fprintf <http://www.zverovich.net/2020/08/04/optimal-file-buffer-size.html>_. Print with colors and text styles .. code:: c++ #include <fmt/color.h> int main() { fmt::print(fg(fmt::color::crimson) | fmt::emphasis::bold, ""Hello, {}!\n"", ""world""); fmt::print(fg(fmt::color::floral_white) | bg(fmt::color::slate_gray) | fmt::emphasis::underline, ""Hello, {}!\n"", """"); fmt::print(fg(fmt::color::steel_blue) | fmt::emphasis::italic, ""Hello, {}!\n"", """"); } Output on a modern terminal: .. image:: https://user-images.githubusercontent.com/ 576385/88485597-d312f600-cf2b-11ea-9cbe-61f535a86e28.png Benchmarks Speed tests ~~~~~~~~~~~ ================= ============= =========== Library Method Run Time, s ================= ============= =========== libc printf 1.04 libc++ std::ostream 3.05 {fmt} 6.1.1 fmt::print 0.75 Boost Format 1.67 boost::format 7.24 Folly Format folly::format 2.23 ================= ============= =========== {fmt} is the fastest of the benchmarked methods, ~35% faster than printf. The above results were generated by building tinyformat_test.cpp on macOS 10.14.6 with clang++ -O3 -DNDEBUG -DSPEED_TEST -DHAVE_FORMAT, and taking the best of three runs. In the test, the format string ""%0.10f:%04d:%+g:%s:%p:%c:%%\n"" or equivalent is filled 2,000,000 times with output sent to /dev/null; for further details refer to the source <https://github.com/fmtlib/format-benchmark/blob/master/tinyformat_test.cpp>_. {fmt} is up to 20-30x faster than std::ostringstream and sprintf on floating-point formatting (dtoa-benchmark <https://github.com/fmtlib/dtoa-benchmark>) and faster than double-conversion <https://github.com/google/double-conversion> and ryu <https://github.com/ulfjack/ryu>_: .. image:: https://user-images.githubusercontent.com/576385/ 95684665-11719600-0ba8-11eb-8e5b-972ff4e49428.png :target: https://fmt.dev/unknown_mac64_clang12.0.html Compile time and code bloat ~~~~~~~~~~~~~~~~~~~~~~~~~~~ The script bloat-test.py <https://github.com/fmtlib/format-benchmark/blob/master/bloat-test.py> from format-benchmark <https://github.com/fmtlib/format-benchmark> tests compile time and code bloat for nontrivial projects. It generates 100 translation units and uses printf() or its alternative five times in each to simulate a medium sized project. The resulting executable size and compile time (Apple LLVM version 8.1.0 (clang-802.0.42), macOS Sierra, best of three) is shown in the following tables. Optimized build (-O3) ============= =============== ==================== ================== Method Compile Time, s Executable size, KiB Stripped size, KiB ============= =============== ==================== ================== printf 2.6 29 26 printf+string 16.4 29 26 iostreams 31.1 59 55 {fmt} 19.0 37 34 Boost Format 91.9 226 203 Folly Format 115.7 101 88 ============= =============== ==================== ================== As you can see, {fmt} has 60% less overhead in terms of resulting binary code size compared to iostreams and comes pretty close to printf. Boost Format and Folly Format have the largest overheads. printf+string is the same as printf but with extra <string> include to measure the overhead of the latter. Non-optimized build ============= =============== ==================== ================== Method Compile Time, s Executable size, KiB Stripped size, KiB ============= =============== ==================== ================== printf 2.2 33 30 printf+string 16.0 33 30 iostreams 28.3 56 52 {fmt} 18.2 59 50 Boost Format 54.1 365 303 Folly Format 79.9 445 430 ============= =============== ==================== ================== libc, lib(std)c++ and libfmt are all linked as shared libraries to compare formatting function overhead only. Boost Format is a header-only library so it doesn't provide any linkage options. Running the tests ~~~~~~~~~~~~~~~~~ Please refer to Building the library__ for the instructions on how to build the library and run the unit tests. __ https://fmt.dev/latest/usage.html#building-the-library Benchmarks reside in a separate repository, format-benchmarks <https://github.com/fmtlib/format-benchmark>_, so to run the benchmarks you first need to clone this repository and generate Makefiles with CMake:: $ git clone --recursive https://github.com/fmtlib/format-benchmark.git $ cd format-benchmark $ cmake . Then you can run the speed test:: $ make speed-test or the bloat test:: $ make bloat-test Migrating code clang-tidy-fmt <https://github.com/mikecrowe/clang-tidy-fmt>_ provides clang tidy checks for converting occurrences of printf and fprintf to fmt::print. Projects using this library 0 A.D. <https://play0ad.com/>_: a free, open-source, cross-platform real-time strategy game 2GIS <https://2gis.ru/>_: free business listings with a city map AMPL/MP <https://github.com/ampl/mp>_: an open-source library for mathematical programming Aseprite <https://github.com/aseprite/aseprite>_: animated sprite editor & pixel art tool AvioBook <https://www.aviobook.aero/en>_: a comprehensive aircraft operations suite Blizzard Battle.net <https://battle.net/>_: an online gaming platform Celestia <https://celestia.space/>_: real-time 3D visualization of space Ceph <https://ceph.com/>_: a scalable distributed storage system ccache <https://ccache.dev/>_: a compiler cache ClickHouse <https://github.com/ClickHouse/ClickHouse>_: analytical database management system CUAUV <https://cuauv.org/>_: Cornell University's autonomous underwater vehicle Drake <https://drake.mit.edu/>_: a planning, control, and analysis toolbox for nonlinear dynamical systems (MIT) Envoy <https://lyft.github.io/envoy/>_: C++ L7 proxy and communication bus (Lyft) FiveM <https://fivem.net/>_: a modification framework for GTA V fmtlog <https://github.com/MengRao/fmtlog>_: a performant fmtlib-style logging library with latency in nanoseconds Folly <https://github.com/facebook/folly>_: Facebook open-source library HarpyWar/pvpgn <https://github.com/pvpgn/pvpgn-server>_: Player vs Player Gaming Network with tweaks KBEngine <https://github.com/kbengine/kbengine>_: an open-source MMOG server engine Keypirinha <https://keypirinha.com/>_: a semantic launcher for Windows Kodi <https://kodi.tv/>_ (formerly xbmc): home theater software Knuth <https://kth.cash/>_: high-performance Bitcoin full-node Microsoft Verona <https://github.com/microsoft/verona>_: research programming language for concurrent ownership MongoDB <https://mongodb.com/>_: distributed document database MongoDB Smasher <https://github.com/duckie/mongo_smasher>_: a small tool to generate randomized datasets OpenSpace <https://openspaceproject.com/>_: an open-source astrovisualization framework PenUltima Online (POL) <https://www.polserver.com/>_: an MMO server, compatible with most Ultima Online clients PyTorch <https://github.com/pytorch/pytorch>_: an open-source machine learning library quasardb <https://www.quasardb.net/>_: a distributed, high-performance, associative database Quill <https://github.com/odygrd/quill>_: asynchronous low-latency logging library QKW <https://github.com/ravijanjam/qkw>_: generalizing aliasing to simplify navigation, and executing complex multi-line terminal command sequences redis-cerberus <https://github.com/HunanTV/redis-cerberus>_: a Redis cluster proxy redpanda <https://vectorized.io/redpanda>_: a 10x faster Kafka replacement for mission critical systems written in C++ rpclib <http://rpclib.net/>_: a modern C++ msgpack-RPC server and client library Salesforce Analytics Cloud <https://www.salesforce.com/analytics-cloud/overview/>_: business intelligence software Scylla <https://www.scylladb.com/>_: a Cassandra-compatible NoSQL data store that can handle 1 million transactions per second on a single server Seastar <http://www.seastar-project.org/>_: an advanced, open-source C++ framework for high-performance server applications on modern hardware spdlog <https://github.com/gabime/spdlog>_: super fast C++ logging library Stellar <https://www.stellar.org/>_: financial platform Touch Surgery <https://www.touchsurgery.com/>_: surgery simulator TrinityCore <https://github.com/TrinityCore/TrinityCore>_: open-source MMORPG framework Windows Terminal <https://github.com/microsoft/terminal>_: the new Windows terminal More... <https://github.com/search?q=fmtlib&type=Code>_ If you are aware of other projects using this library, please let me know by email <mailto:victor.zverovich@gmail.com> or by submitting an issue <https://github.com/fmtlib/fmt/issues>. Motivation So why yet another formatting library? There are plenty of methods for doing this task, from standard ones like the printf family of function and iostreams to Boost Format and FastFormat libraries. The reason for creating a new library is that every existing solution that I found either had serious issues or didn't provide all the features I needed. printf ~~~~~~ The good thing about printf is that it is pretty fast and readily available being a part of the C standard library. The main drawback is that it doesn't support user-defined types. printf also has safety issues although they are somewhat mitigated with __attribute__ ((format (printf, ...)) <https://gcc.gnu.org/onlinedocs/gcc/Function-Attributes.html> in GCC. There is a POSIX extension that adds positional arguments required for i18n <https://en.wikipedia.org/wiki/Internationalization_and_localization> to printf but it is not a part of C99 and may not be available on some platforms. iostreams ~~~~~~~~~ The main issue with iostreams is best illustrated with an example: .. code:: c++ std::cout << std::setprecision(2) << std::fixed << 1.23456 << ""\n""; which is a lot of typing compared to printf: .. code:: c++ printf(""%.2f\n"", 1.23456); Matthew Wilson, the author of FastFormat, called this ""chevron hell"". iostreams don't support positional arguments by design. The good part is that iostreams support user-defined types and are safe although error handling is awkward. Boost Format ~~~~~~~~~~~~ This is a very powerful library which supports both printf-like format strings and positional arguments. Its main drawback is performance. According to various, benchmarks it is much slower than other methods considered here. Boost Format also has excessive build times and severe code bloat issues (see Benchmarks_). FastFormat ~~~~~~~~~~ This is an interesting library which is fast, safe and has positional arguments. However, it has significant limitations, citing its author: Three features that have no hope of being accommodated within the current design are: * Leading zeros (or any other non-space padding) * Octal/hexadecimal encoding * Runtime width/alignment specification It is also quite big and has a heavy dependency, STLSoft, which might be too restrictive for using it in some projects. Boost Spirit.Karma ~~~~~~~~~~~~~~~~~~ This is not really a formatting library but I decided to include it here for completeness. As iostreams, it suffers from the problem of mixing verbatim text with arguments. The library is pretty fast, but slower on integer formatting than fmt::format_to with format string compilation on Karma's own benchmark, see Converting a hundred million integers to strings per second <http://www.zverovich.net/2020/06/13/fast-int-to-string-revisited.html>_. License {fmt} is distributed under the MIT license <https://github.com/fmtlib/fmt/blob/master/LICENSE.rst>_. Documentation License The Format String Syntax <https://fmt.dev/latest/syntax.html> section in the documentation is based on the one from Python string module documentation <https://docs.python.org/3/library/string.html#module-string>. For this reason the documentation is distributed under the Python Software Foundation license available in doc/python-license.txt <https://raw.github.com/fmtlib/fmt/master/doc/python-license.txt>_. It only applies if you distribute the documentation of {fmt}. Maintainers The {fmt} library is maintained by Victor Zverovich (vitaut <https://github.com/vitaut>) and Jonathan Mller (foonathan <https://github.com/foonathan>) with contributions from many other people. See Contributors <https://github.com/fmtlib/fmt/graphs/contributors> and Releases <https://github.com/fmtlib/fmt/releases> for some of the names. Let us know if your contribution is not listed or mentioned incorrectly and we'll make it right."
3941,"Flat Surface Shader for rendering illuminated trianglesFlat Surface Shader [FSS] Simple, lightweight Flat Surface Shader written in JavaScript for rendering lit Triangles to a number of contexts. Currently there is support for WebGL, Canvas 2D and SVG. Check out this demo to see it in action. Understanding Lighting Simply put, FSS uses the Lambertian Reflectance model to calculate the color of a Triangle based on an array of Light sources within a Scene. Light A Light is composed of a 3D position Vector and 2 Color objects defining its ambient & diffuse emissions. These color channels interact with the Material of a Mesh to calculate the color of a Triangle. Triangle A Triangle is constructed from 3 Vertices which each define the x, y and z coordinates of a corner. Based on these 3 Vertices, a forth 3D Vector is automatically derived at the center of the Triangle this is known as its Centroid. Alongside the Centroid, a fifth unit Vector is automatically calculated which defines the surface Normal. The Normal describes the direction that the Triangle is facing. Geometry Geometry is simply a collection of triangles nothing more. Material A Material is composed of 2 Color objects which define the ambient & diffuse properties of a surface. Mesh A Mesh is constructed from a Geometry object and a Material object. All the Triangles within the Geometry are rendered using the properties of the Material. Scene A Scene sits at the very top of the stack. It simply manages arrays of Mesh & Light objects. Renderer The Renderer takes all the information in a Scene and renders it to a context. Currently FSS supports WebGL, Canvas 2D and SVG. Calculation For every Triangle in a Scene the following calculation is performed: A Vector between the Triangle's Centroid and the Light's Position is calculated and normalised. This can be considered as a single Ray travelling from the Light to the center of the Triangle. The angle beween this Ray and the Normal of the Triangle is then calculated using the dot product. This angle is simply a number ranging from -1 to 1. When the Ray and the Normal are coincident, this value is 0, and when they are perpendicular to one another, this value is 1. This value goes into the negative range when the Light is behind the Triangle. Firstly, the diffuse color of the Light is multiplied by the diffuse color of the Material associated with the Triangle. This color is then multiplied by the coincidence angle described above. For example, if the diffuse color of the Light is #FFFFFF { R:1, G:1, B:1 } and the diffuse color of the Material is #FF0000 { R:1, G:0, B:0 }, the combined color would be #FF0000 { R:1*1=1, G:1*0=0, B:1*0=0 }. If the coincidence angle was 0.5, the final color of the Triangle would be #800000 { R:1*0.5=0.5, G:0*0.5=0, B:0*0.5=0 }. In much the same way as above, the ambient color of the Light is multipled by the ambient color of the Material. Since ambient light is a uniform dissipation of scattered light, it is not modified any further. The final color of the Triangle is simply calculated by adding the diffuse & ambient colors together. Simples. Example NOTE: All objects exist within the FSS namespace. Building Install Dependancies: npm install uglify-js@2.2.5 Build: node build.js Inspiration Please also checkout the case study on Behance created by my dear friend Tobias van Schneider @schneidertobias. Acknowledgments The architecture of this project was heavily influenced by three.js and the implementation of the Vector calculations was taken from glMatrix. Author Matthew Wagerfield: @mwagerfield License Licensed under MIT. Enjoy."
1221,"A visualization grammar.Vega: A Visualization Grammar Vega is a visualization grammar, a declarative format for creating, saving, and sharing interactive visualization designs. With Vega you can describe data visualizations in a JSON format, and generate interactive views using either HTML5 Canvas or SVG. For documentation, tutorials, and examples, see the Vega website. For a description of changes between Vega 2 and later versions, please refer to the Vega Porting Guide. Build Instructions For a basic setup allowing you to build Vega and run examples: Clone https://github.com/vega/vega. Run yarn to install dependencies for all packages. If you don't have yarn installed, see https://yarnpkg.com/en/docs/install. We use Yarn workspaces to manage multiple packages within this monorepo. Once installation is complete, run yarn test to run test cases, or run yarn build to build output files for all packages. After running either yarn test or yarn build, run yarn serve to launch a local web server your default browser will open and you can browse to the ""test"" folder to view test specifications. This repository includes the Vega website and documentation in the docs folder. To launch the website locally, first run bundle install in the docs folder to install the necessary Jekyll libraries. Afterwards, use yarn docs to build the documentation and launch a local webserver. After launching, you can open http://127.0.0.1:4000/vega/ to see the website. ES5 Support For backwards compatibility, Vega includes a babel-ified ES5-compatible version of the code in packages/vega/build-es5 directory. Older browser would also require several polyfill libraries: Contributions, Development, and Support Interested in contributing to Vega? Please see our contribution and development guidelines, subject to our code of conduct. Looking for support, or interested in sharing examples and tips? Post to the Vega discussion forum or join the Vega slack organization! We also have examples available as Observable notebooks. If you're curious about system performance, see some in-browser benchmarks. Read about future plans in our roadmap."
501,":fire: Android developers should collect the following utils(updating).README of Chinese About AndroidUtilCode :fire: is a powerful & easy to use library for Android. This library encapsulates the functions that commonly used in Android development which have complete demo and unit test. By using it's encapsulated APIs, you can greatly improve the development efficiency. The program mainly consists of two modules which is utilcode, which is commonly used in development, and subutil which is rarely used in development, but the utils can be beneficial to simplify the main module. :fire: Documentation utilcode README of English README of Chinese subutil README of English README of Chinese Donations If this project helps you a lot and you want to support the project's development and maintenance of this project, feel free to scan the following QR code for donation. Your donation is highly appreciated. Thank you! Contact Change Log "
2607,"The best Swiper component for React Native. The best Swiper component for React Native. react-native-swiper Roadmap see: ROADMAP.md Changelogs [1.6.0-rc] Dependency Remove ViewPagerAndroid, use ScrollView #1009 Test Integration Setup e2e test TypeScript correct the wrong types #1000 Add missing scrollBy TypeScript definition #931 New Feature add scrollTo #831 Added prop to disable the PrevButton #749 Optionally render page #1004 Bug Fix ES6 and CommonJS compatibility #717 Solves the issue of state messing up when parent component calls setState #939 replay when autoplay is setted to true #1002 fix broken examples and migrate to react-native 0.60.x fix bad jumping on ios when loadMinimal set true fix fliker when loop and loadMinimal are enabled #1062 [1.5.6] Fix #16, #36, #371, #410, #411, #422, #468 Fix landscape orientation auto resize! (thanks @ahmed3mar, @timmywil) Add containerStyle prop to customize the view container. [1.5.5] Update: using PropTypes from prop-types and Change View.propTypes to ViewPropTypes [1.5.4] Added easily accessible pagination point manipulation: use dotColor / activeDotColor and dotStyle / activeDotStyle (thanks @denizs) Added scrollEnabled prop to documentation (thanks @ibandominguez) [1.5.3] Add loadMinimalLoader prop to customize <ActivityIndicator /> (thanks @Exilz) Disable autoplay timer when prop changes to false (thanks @dizlexik) Special thanks to @hypatiah for fixed some grammatical errors in README [1.5.2] Add yarn lock Fix jitter when quickly swiping back and forth between pages (iOS) (thanks @nemophrost) The first webview always reloaded when injecting the rest of the children (thanks @eosterberg) see more: CHANGELOG.md Show Cases Try these cases by yourself very easy, Just open examples/ios/swiper.xcodeproj in Xcode, then press Cmd + R; you may edit examples/index.ios.js for switch cases. examples/components/Basic examples/components/Swiper examples/components/SwiperNumber examples/components/Phone examples/components/LoadMinimal Getting Started Installation Basic Usage Properties Basic Custom basic style & content Pagination Autoplay Control buttons Props of Children Basic props of <ScrollView /> Supported ScrollResponder Examples Development Installation v1.5.14 v1.6.0-rc Basic Usage Install react-native first Initialization of a react-native project Then, edit myproject/index.ios.js, like this: Properties Basic | Prop | Default | Type | Description | | :------------- | :-------------: | :------: | :---------------------------------------------------------------------------------------------------------- | | horizontal | true | bool | If true, the scroll view's children are arranged horizontally in a row instead of vertically in a column. | | loop | true | bool | Set to false to disable continuous loop mode. | | index | 0 | number | Index number of initial slide. | | showsButtons | false | bool | Set to true make control buttons visible. | | autoplay | false | bool | Set to true enable auto play mode. | | onIndexChanged | (index) => null | func | Called with the new index when the user swiped | Custom basic style & content | Prop | Default | Type | Description | | :---------------- | :---------------------: | :-------: | :------------------------------------------------------------------------- | | width | - | number | If no specify default enable fullscreen mode by flex: 1. | | height | - | number | If no specify default fullscreen mode by flex: 1. | | style | {...} | style | See default style in source. | | containerStyle | {...} | style | See default container style in source. | | loadMinimal | false | bool | Only load current index slide , loadMinimalSize slides before and after. | | loadMinimalSize | 1 | number | see loadMinimal | | loadMinimalLoader | <ActivityIndicator /> | element | Custom loader to display when slides aren't loaded | Pagination | Prop | Default | Type | Description | | :--------------- | :-------------------------------------------------------------------------------------------------------------------------------------------------------: | :--------: | :-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | | showsPagination | true | bool | Set to true make pagination visible. | | paginationStyle | {...} | style | Custom styles will merge with the default styles. | | renderPagination | - | function | Complete control how to render pagination with three params (index, total, context) ref to this.state.index / this.state.total / this, For example: show numbers instead of dots. | | dot | <View style={{backgroundColor:'rgba(0,0,0,.2)', width: 8, height: 8,borderRadius: 4, marginLeft: 3, marginRight: 3, marginTop: 3, marginBottom: 3,}} /> | element | Allow custom the dot element. | | activeDot | <View style={{backgroundColor: '#007aff', width: 8, height: 8, borderRadius: 4, marginLeft: 3, marginRight: 3, marginTop: 3, marginBottom: 3,}} /> | element | Allow custom the active-dot element. | | dotStyle | - | object | Allow custom the dot element. | | dotColor | - | string | Allow custom the dot element. | | activeDotColor | - | string | Allow custom the active-dot element. | | activeDotStyle | - | object | Allow custom the active-dot element. | Autoplay | Prop | Default | Type | Description | | :---------------- | :-----: | :------: | :----------------------------------------------- | | autoplay | true | bool | Set to true enable auto play mode. | | autoplayTimeout | 2.5 | number | Delay between auto play transitions (in second). | | autoplayDirection | true | bool | Cycle direction control. | Control buttons | Prop | Default | Type | Description | | :----------------- | :---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------: | :-------: | :------------------------------------------ | | showsButtons | true | bool | Set to true make control buttons visible. | | buttonWrapperStyle | {backgroundColor: 'transparent', flexDirection: 'row', position: 'absolute', top: 0, left: 0, flex: 1, paddingHorizontal: 10, paddingVertical: 10, justifyContent: 'space-between', alignItems: 'center'} | style | Custom styles. | | nextButton | <Text style={styles.buttonText}></Text> | element | Allow custom the next button. | | prevButton | <Text style={styles.buttonText}></Text> | element | Allow custom the prev button. | Props of Children | Prop | Default | Type | Description | | :---- | :----------------------------------: | :-------: | :------------------------------------------------------------- | | style | {...} | style | Custom styles will merge with the default styles. | | title | {...} | element | If this parameter is not specified, will not render the title. | Basic props of <ScrollView /> | Prop | Default | Type | Description | | :------------------------------- | :-----: | :----: | :---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | | horizontal | true | bool | If true, the scroll view's children are arranged horizontally in a row instead of vertically in a column. | | pagingEnabled | true | bool | If true, the scroll view stops on multiples of the scroll view's size when scrolling. This can be used for horizontal pagination. | | showsHorizontalScrollIndicator | false | bool | Set to true if you want to show horizontal scroll bar. | | showsVerticalScrollIndicator | false | bool | Set to true if you want to show vertical scroll bar. | | bounces | false | bool | If true, the scroll view bounces when it reaches the end of the content if the content is larger then the scroll view along the axis of the scroll direction. If false, it disables all bouncing even if the alwaysBounce* props are true. | | scrollsToTop | false | bool | If true, the scroll view scrolls to top when the status bar is tapped. | | removeClippedSubviews | true | bool | If true, offscreen child views (whose overflow value is hidden) are removed from their native backing superview when offscreen. This canimprove scrolling performance on long lists. | | automaticallyAdjustContentInsets | false | bool | Set to true if you need adjust content insets automation. | | scrollEnabled | true | bool | Enables/Disables swiping | @see: http://facebook.github.io/react-native/docs/scrollview.html Supported ScrollResponder | Prop | Params | Type | Description | | :------------------ | :-----------------------: | :--------: | :---------------------------------------------------------- | | onScrollBeginDrag | e / state / context | function | When animation begins after letting up | | onMomentumScrollEnd | e / state / context | function | Makes no sense why this occurs first during bounce | | onTouchStartCapture | e / state / context | function | Immediately after onMomentumScrollEnd | | onTouchStart | e / state / context | function | Same, but bubble phase | | onTouchEnd | e / state / context | function | You could hold the touch start for a long time | | onResponderRelease | e / state / context | function | When lifting up - you could pause forever before * lifting | Note: each ScrollResponder be injected with two params: state and context, you can get state and context(ref to swiper's this) from params, for example: More ScrollResponder info, see: https://github.com/facebook/react-native/blob/master/Libraries/Components/ScrollResponder.js Methods scrollBy(index, animated) Scroll by relative index. Parameters: | Name | Type | default | Description | | :------- | :------: | :---------: | :----------- | | index | number | undefined | offset index | | animated | bool | true | offset index | Examples Quick start with examples. Development Then launch simulator to preview. Note that you just need to edit the source file src/index.js, the change will auto sync to examples. After development, you should add test for your modification and make all tests passed to prevent other contributors break the feature in the future accidentally. We use detox + jest for e2e test now, you can read Detox for more detail. Contribution @leecade The main author. @rajkissu The secondary contributor. Questions Feel free to contact me or create an issue Inspired by nolimits4web/Swiper & Design material from Dribbble & made with ."
731,"Let's learn a new technology every week. A new technology blog every Sunday in 2016.52 technologies in 2016 I have taken a challenge to learn a new technology every week in 2016. The goal is to learn a new technology, build a simple application using it, and blog about it. I have decided to discontinue this series after writing 42 blogs. No more blogs will be published in this series. Thanks for your support. Contributing to the 52 technologies in 2016 series Please contribute if you see an error or something that could be better! Raise an issue or send me a pull request to improve. Contributions of all kinds, including corrections, additions, improvements, and translations, are welcome! Open for external blogs If you would like to write a guest post for 52-technologies-in-2016 series then send a PR with a blog post. Technologies covered in 52 technologies in 2016 series Below is the list of technologies covered in this series: Week 1: January 03, 2016 Finatra - Build Beautiful REST API The Twitter Way. In this tutorial, we will learn how to write Scala REST APIs using Twitter's open source framework Finatra. We will build an application from scratch covering all the steps required to build the application. Week 2: January 10, 2016 SBT: The Missing Tutorial. In this tutorial, we will learn sbt build tool. sbt is a general purpose build tool written in Scala. It is best suited for Scala application development. Week 3: January 17, 2016 Sentiment Analysis in Scala with Stanford CoreNLP. In this tutorial, we will learn how to use Stanford CoreNLP library for performing sentiment analysis of unstructured text in Scala. Week 4: January 24, 2016 Slick: Functional Relational Mapping for Mere Mortals Part 1. In this tutorial, we will learn how to get started with Slick so that we can interact with relational databases in our Scala applications. Slick is a powerful Scala library to work with relational databases. Week 5: January 31, 2016 Slick: Functional Relational Mapping for Mere Mortals Part 2: Querying Data. In this tutorial, we will learn how to perform select queries with Slick. Slick allows you to work with database tables in the same way as you work with Scala collections. This means that you can use methods like map, filter, sort, etc. to process data in your table. Week 6: February 07, 2016 Building A Lightweight REST API Client with Scala and OkHttp. In this tutorial, we will learn how to build REST API client for Medium's REST API using Scala and OkHttp. OkHttp is an open source Java HTTP client library focussed on efficiency. Week 7: February 14, 2016 Hugo: A Modern WebSite Engine That Just Works. In this tutorial, we will learn how to build a static website using Hugo. Hugo is a static site generator written in Go programming language. Week 8: February 21, 2016 CoreOS for Application Developers. The goal of this tutorial is to help application developers understand why they should care about CoreOS and show them how to work with CoreOS cluster running on top of Amazon EC2. CoreOS is an Open source Linux distribution built to run and manage highly scalable and fault tolerant systems. Week 9: February 28, 2016 Realtime People Counter with Google's Cloud Vision API and RxJava. Google recently released Cloud Vision API that enables developers to incorporate image recognition in their applications. Image Recognition allow developers to build applications that can understand content of images. In this tutorial, we will learn how to build a realtime people counter. Week 10: March 06, 2016 Gatling: The Ultimate Load Testing Tools for Programmers. Gatling is a high performance open source load testing tool built on top of Scala, Netty, and Akka. It is a next generation, modern load testing tools very different from existing tools like Apache JMeter. In this tutorial, you will learn how to write load tests using Gatling. Week 11: March 13, 2016 Tweet Deduplication: This week I decided to write a tweet deduplication library. The library will give you a stream of deduplicated tweets. Week 11: March 13, 2016 TextBlob. TextBlob is an open source text processing library written in Python. It can be used to perform various natural language processing tasks such as part-of-speech tagging, noun-phrase extraction, sentiment analysis, text translation, and many more. Week 12: March 20, 2016 Play Framework. Play framework is a MVC style web application framework for JVM. It provides API for both Java and Scala programming languages. I am maintaining this tutorial in a separate GitHub repository. Week 13: March 27, 2016 ArangoDB: Polyglot Persistence Without Cost. ArangoDB is an open source NoSQL database that provides flexible data model. You can use ArangoDB to model data using combination of document, graph, and key value data modeling styles. Week 14: April 03, 2016 Apache Kafka. I have not yet written this article. Week 15: April 10, 2016 Airline Bot Platform with Huginn. This week I decided to build a bot platform using Huginn that can perform a lot of tasks for which we normally use mobile apps. Our goal was to show them that they should think beyond mobile apps and look into the world of bots as bots can be less intrusive, more secure, and does not require installation. Apps are dead, long live bots. Week 16: April 17, 2016 Building Your ""Read It Later"" App using Python and Newspaper Library.In this tutorial, you will learn how we can use a Python library newspaper to perform article extraction and build a simple ""Read It Later"" application. Week 17: April 24, 2016 Let's Learn TypeScript. This week I decided to learn TypeScript so I will discuss how you can get started with TypeScript. TypeScript is a typed superset of JavaScript, which means that it supports all the JavaScript features plus it adds static typing to the language. Week 18: May 01, 2016 Getting Started with Apache Mesos. This week we will learn about Apache Mesos -- an open source cluster manager and scheduler for your datacenter. Week 19: May 08, 2016 Load testing with bees. This week I discovered a Python utility called beeswithmachineguns that can load test a web application by launching many micro EC2 instances. Week 20: May 15, 2016 5 open source projects that will make working with JSON awesome and fun. This week I will share my 5 favorite open source projects that makes working with JSON easy and fun. I use them on regular basis and find them very useful whenever I am working with JSON. Week 21: May 22, 2016 Java 8 String Manipulation Library. This week I wrote and released a Java 8 library to work with String. Week 22: May 29, 2016 Making Sense of Regular Expressions. In this tutorial, I will walk you through a series of examples that will help you learn about regular expressions. I will end this tutorial by covering a library VerbalExpressions that you can use to programmatically build regular expressions. Week 23: June 5, 2016 Building An Android Application Part 1. In this tutorial, we will develop an Android app that will be used to report and track missing kids. Today, we will only cover photo capturing capability of the application. Like any camera application, this application will enable users to capture photos, save them to an album, and finally upload them to the backend servers. Week 24: June 12, 2016 Moving back to WordPress from Jekyll. In this blog, I will share my experience of running a Jekyll blog and then migrating it back to WordPress. Week 25: June 19, 2016 Trello Clone with Angular Dragula. In this blog, I will cover how you can build Trello like drag and drop list interface with Angular Dragula. Week 26: June 26, 2016 Building An Android Application Part 2. In this blog, we will extend the Android application we built in week 23. We will use an Android library Glide to handle the image preview. We will also add sharing functionality using Android's inbuilt sharing support using ShareActionProvider. Week 27: July 03, 2016 Learn GoLang For Great Good -- Part 1. In this blog, we will learn Go programming language by writing a number of small programs. Go is an object oriented programming language with memory management builtin. Week 28: July 10, 2016 Build mobile apps using Ionic Framework. In this blog, we will build a hybrid mobile app using Ionic and Cordova. The complete application will have a server side which will send JSON data, consumed by the application. The mobile app is written in ECMAScript. Week 29: July 15, 2016 Go Language - GitHub System Status API & Slack Notifications. In this blog, we are going to investigate a few more features of the language and combine that into a real life application where we can monitor the status of the GitHub System via its Status API and report its current status directly into a Slack Team page. Week 29: July 17, 2016 Learn GoLang For Great Good Part 2: Unit Testing in Go. This week we will take our Go knowledge to the next level by learning how to perform unit testing in Go. Unit testing has become an essential skill set for every programmer. Week 30: July 24, 2016 Dropwizard: Your Java Library For Building Microservices This blog covers how to build Java REST backend using Dropwizard library. Week 31: July 31, 2016 50 Gradle Tips. Over last year or so I have started using Gradle as my primary build tool for JVM based projects. In this document, I will list down tips that I have learnt over last year or so. Week 32: August 7, 2016 Groovy AST Transformations By Example. This week I learnt about Groovy AST transformations. AST transformations allows you to hook into the Groovy compilation process so that you can customize it to meet your needs. In this blog, you will learn how to write an AST transformation that will add a toHash method to a class. toHash method will generate a hash for your object. You will be able to provide hash algorithm of your choice. We will use Java's java.security.MessageDigest to generate the hash code. Week 34: August 21, 2016 Automating Your Static Website Social Notifications with AWS Lambda. AWS Lambda is an event-driven, serverless computing platform that executes your code in response to events. It manages the underlying infrastructure scaling it up or down to meet the event rate. You are only charged for the time your code is executed. AWS Lambda currently supports Java, Python, and Node.js language runtimes. Week 36: September 04, 2016 Webpack: The Missing Tutorial. webpack takes modules with dependencies and generates static assets representing those modules. Week 37: September 11, 2016 Building ""Bootiful"" Scala Web Applications with Spring Boot. In this post, I will quickly show you how to use Spring Boot with Scala by converting Spring Boot's official Building a RESTful Web Service guide to Scala. Week 38: September 18, 2016 Actor System Termination on JVM Shutdown. In this short post, I will discuss how to cleanly shutdown Akka ActorSystem on JVM exit. Week 39: October 07, 2016 Docker for Java Developers Part 1. This week I had to give a talk on Docker ecosystem so I spent a lot of my after office hours preparing for the talk. Docker is a container technology that allows us to package an application and its dependencies together in a filesystem so that they can be deployed together on any server. This helps us achieve package once deploy anywhere. So, in the next few posts of this series, we will learn how Java developers can get started with Docker. Week 40: October 19, 2016 Using Docker Containers As Cron Jobs: This week I was working on a problem that required cron jobs. The use case was that after user registers with the application, we will create a cron job that will track his/her social activities. We will have one container per user. I wanted to keep cron jobs to work in a different process from the main application so that different concerns of the application don't intermingle. In my view, containers provide the right abstraction to solve this use case. Week 41: December 04, 2016 Understanding Akka Dispatcher: Akkais a toolkit and runtime for building highly concurrent, distributed and resilient message driven systems. This post assumes you already know Akka. Actor needs a dispatcher to perform its task. A dispatcher relies on executor to provide thread. There are two types of executors a dispatcher can have: 1)fork-join-executor2)thread-pool-executor. In this post, we will understand how you can configurefork-join-executorandthread-pool-executorto meet your needs. Week 42: December 08, 2016 Using Docker Compose with wait-for-it: Today, we will learn about Docker Compose, a tool for defining and running multi-container Docker applications. This post will also cover how to use Docker Compose with wait-for-it. wait-for-it is a simple bash utility to test and wait for the availability of TCP host and port. Week 43: December 26, 2016 GraphQL - building a pokedex in React with GraphQL: GraphQL, a query language that is starting to get more and more attention. Facebook, who internally used GraphQL since 2012 and released a first specification and reference implementation of GraphQL in 2015 announced GraphQL to be [production ready] in September 2016. What followed is a trend of more and more companies starting to use GraphQL, such as GitHub, Coursera and Shopify. You can follow me on twitter at https://twitter.com/shekhargulati or email me at shekhargulati84@gmail.com. Also, you can read my blogs at http://shekhargulati.com/"
4049,"Nifty Modal Dialog EffectsNiftyDialogEffects NiftyDialogEffects is deprecated Nifty Modal Dialog Effects look like this(Nifty Modal Window Effects) ScreenShot . . . Gradle using JitPack: Usage Configuration Effects Fadein, Slideleft, Slidetop, SlideBottom, Slideright, Fall, Newspager, Fliph, Flipv, RotateBottom, RotateLeft, Slit, Shake, Sidefill (See The Effect) Developed By -Li Tao - onresume@live.com License Copyright 2014 litao. Licensed under the Apache License, Version 2.0 (the ""License""); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License. by cncounter"
1786,"A machine learning package built for humans.aerosolve Machine learning for humans. What is it? A machine learning library designed from the ground up to be human friendly. It is different from other machine learning libraries in the following ways: A thrift based feature representation that enables pairwise ranking loss and single context multiple item representation. A feature transform language gives the user a lot of control over the features Human friendly debuggable models Separate lightweight Java inference code Scala code for training Simple image content analysis code suitable for ordering or ranking images This library is meant to be used with sparse, interpretable features such as those that commonly occur in search (search keywords, filters) or pricing (number of rooms, location, price). It is not as interpretable with problems with very dense non-human interpretable features such as raw pixels or audio samples. There are a few reasons to focus on interpretability: Your corpus is new and not fully defined and you want more insight into your corpus Having interpretable models lets you iterate quickly. Figure out where the model disagrees most and have insight into what kind of new features are needed. Debugging noisy features. By plotting the feature weights you can discover buggy features or fit them to splines and discover features that are unexpectedly complex (which usually indicates overfitting). You can discover relationships between different variables and your target prediction. e.g. For the Airbnb demand model, plotting graphs of reviews and 3-star reviews is more interpretable than many nested if then else rules. How to get started? The artifacts for aerosolve are hosted on bintray. If you use Maven, SBT or Gradle you can just point to bintray as a repository and automatically fetch the artifacts. Check out the image impression demo where you can learn how to teach the algorithm to paint in the pointillism style of painting. Image Impressionism Demo. There is also an income prediction demo based on a popular machine learning benchmark. Income Prediction Demo. Feature Representation This section dives into the thrift based feature representation. Features are grouped into logical groups called families of features. The reason for this is so we can express transformations on an entire feature family at once or interact two different families of features together to create a new feature family. There are three kinds of features per FeatureVector: stringFeatures - this is a map of feature family to binary feature strings. For example ""GEO"" -> { ""San Francisco"", ""CA"", ""USA"" } floatFeatures - this is a map of feature family to feature name and value. For example ""LOC"" -> { ""Latitude"" : 37.75, ""Longitude"" : -122.43 } denseFeatures - this is a map of feature family to a dense array of floats. Not really used except for the image content analysis code. Example Representation Examples are the basic unit of creating training data and scoring. A single example is composed of: context - this is a FeatureVector that occurs once in the example. It could be the features representing a search session for example. e.g. ""Keyword"" -> ""Free parking"" example(0..N) - this is a repeated list of FeatureVectors that represent the items being scored. These can correspond to documents in a search session. e.g. ""LISTING CITY"" -> ""San Francisco"" The reasons for having this structure are: having one context for hundreds of items saves a lot of space during RPCs or even on disk you can compute the transforms for the context once, then apply the transformed context repeatedly in conjunction with each item having a list of items allows the use of list based loss functions such as pairwise ranking loss, domination loss etc where we evaluate multiple items at once Feature Transform language This section dives into the feature transform language. Feature transforms are applied with a separate transformer module that is decoupled from the model. This allows the user to break apart transforms or transform data ahead of time of scoring for example. e.g. in an application the items in a corpus may be transformed ahead of time and stored, while the context is not known until runtime. Then at runtime, one can transform the context and combined them with each transformed item to get the final feature vector that is then fed to the models. Feature transforms allow us to modify FeatureVectors on the fly. This allows engineers to rapidly iterate on feature engineering quickly and in a controlled way. Here are some examples of feature transforms that are commonly used: List transform. A meta transform that specifies other transforms to be applied Cross transform. Operates only on stringFeatures. Allows interactions between two different string feature families. e.g. ""Keyword"" cross ""LISTING CITY"" creates the new feature family ""Keyword_x_city"" -> ""Free parking^San Francisco"" Multiscale grid transform Constructs multiple nested grids for 2D coordinates. Useful for modelling geography. Please see the corresponding unit tests as to what these transforms do, what kind of features they operate on and what kind of config they expect. Models This section covers debuggable models. Although there are several models in the model directory only two are the main debuggable models. The rest are experimental or sub-models that create transforms for the interpretable models. Linear model. Supports hinge, logistic, epsilon insensitive regression, ranking loss functions. Only operates on stringFeatures. The label for the task is stored in a special feature family and specified by rank_key in the config. See the linear model unit tests on how to set up the models. Note that in conjunction with quantization and crosses you can get incredible amounts of complexity from the ""linear"" model, so it is not actually your regular linear model but something more complex and can be thought of as a bushy, very wide decision tree with millions of branches. Spline model. A general additive linear piecewise spline model. The training is done at a higher resolution specified by num_buckets between the min and max of a feature's range. At the end of each iteration we attempt to project the linear piecewise spline into a lower dimensional function such as a polynomial spline with Dirac delta endpoints. If the RMSE of the projection is above threshold, we leave the spline alone in the high resolution piecewise linear mode. This allows us to debug the spline model for features that are buggy or unexpectedly complex (e.g. jumping up and down when we expect some kind of smoothness) Boosted stumps model - small compact model. Not very interpretable but at small sizes useful for feature selection. Decision tree model - in memory only. Mostly used to generate transforms for the linear or spline model. Maxout neural network model. Experimental and mostly used as a comparison baseline. IDE If you use intellij, try build first, so that thrift classes is available and to fix the spark compiling error inside intellij, type command+; and click dependency and change related files from test to compile, such as org.apache.spark and org.apache.hadoop:hadoop-common. We keep gradle config as testCompile so that to reduce jar file size. Support Hackpad Dev group User group In the wild Organizations and projects using aerosolve can list themselves here."
1694,"Progressive pie, donut, bar and line chartsPeity Peity (sounds like deity) is a jQuery plugin that converts an element's content into a mini <svg> pie, donut, line or bar chart. Basic Usage HTML JavaScript (jQuery) Docs More detailed usage can be found at benpickles.github.io/peity. Development Run the automated visual regression tests with: make test Run a filtered set of tests with: ARGS=""--grep bar"" make test To manually view all test cases run: make server And hit http://localhost:8080/. Release Update the version string in jquery.peity.js, run make release, and follow the instructions. Copyright Copyright 2009-2020 Ben Pickles. See LICENCE for details."
23,"Semantic is a UI component framework based around useful principles from natural language.Semantic UI Semantic is a UI framework designed for theming. Key Features * 50+ UI elements * 3000 + CSS variables * 3 Levels of variable inheritance (similar to SublimeText) * Built with EM values for responsive design * Flexbox friendly Semantic allows developers to build beautiful websites fast, with concise HTML, intuitive javascript, and simplified debugging, helping make front-end development a delightful experience. Semantic is responsively designed allowing your website to scale on multiple devices. Semantic is production ready and partnered with frameworks such as React, Angular, Meteor, and Ember, which means you can integrate it with any of these frameworks to organize your UI layer alongside your application logic. 2.4.0 Release (Sep 17th, 2018) Semantic UI 2.4 is now available. Read up on what's new in the docs. Migration info from 1.x can be found in the 2.0 release notes User Support Please help us keep the issue tracker organized. For technical questions that do not include a specific JSFiddle test case (bug reports), or feature request please use StackOverflow to find a solution. Visit our contributing guide for more on what should be posted to GitHub Issues. Install Recommended Install Semantic UI includes an interactive installer to help setup your project. For more details on setup visit our getting started guide. To learn more about theming please read our theming guide Additional Versions Environment | Install Script | Repo --- | --- | --- | CSS Only | npm install semantic-ui-css | CSS Repo LESS Only | npm install semantic-ui-less | LESS Repo LESS plugin | npm install less-plugin-semantic-ui | LESS Plugin Repo EmberJS | ember install:addon semantic-ui-ember | Ember Repo |Meteor - LESS | meteor add semantic:ui | Meteor Repo | |Meteor - CSS | meteor add semantic:ui-css | CSS Repo | Bower | bower install semantic-ui | Check out our integration wiki for more options. Browser Support Last 2 Versions FF, Chrome, Safari Mac IE 11+ Android 4.4+, Chrome for Android 44+ iOS Safari 7+ Microsoft Edge 12+ Although some components will work in IE9, grids and other flexbox components are not supported by IE9 and may not appear correctly. Community Getting Help Please do not post usage questions to GitHub Issues. For these types of questions use our [Gitter chatroom] or StackOverflow. Submitting Bugs and Enhancements GitHub Issues is for suggesting enhancements and reporting bugs. Before submiting a bug make sure you do the following: * Check out our contributing guide for info on our release cycle. * Fork this boilerplate JSFiddle to create a test case for your bug. If a bug is apparent in the docs, that's ok as a test case, just make it clear exactly how to reproduce the issue. Only bugs that include a test case can be triaged. Pull Requests When adding pull requests, be sure to merge into the next branch. If you need to demonstrate a fix in next release, you can use this JSFiddle International Chinese A Chinese mirror site is available at http://www.semantic-ui.cn. Right-to-Left (RTL) An RTL version can be created using our build tools by selecting rtl from the install script. Translation To help translate see the Wiki Guide for translations. Resources Resource | Description --- | --- | Bugs & Feature Requests | All bug submission require a link to a test case, and a set of steps to reproduce the issue. You can make a test case by forking this JSFiddle, then submit your bug report on GitHub Issues Live Chat | Join our Gitter.im Room Newsletter Updates | Sign up for updates at semantic-ui.com Additional Resources | Submit a question on StackOverflow or ask our Google Group Places to Help Project | How To Help | Next Step --- | --- | --- | Localization | Help us translate Semantic UI into your language | Join our Translation Community SCSS | SASS needs PR to support variables inside @import | Add Pull Request for #739 Angular | Help develop angular bindings | Reach Out on GitHub Issues Guides & Tutorials | Help write guides and tutorials | Join the discussion Reaching Out If you'd like to start a conversation about Semantic feel free to e-mail me at jack@semantic-ui.com "
3328,"localStorage and sessionStorage done right for AngularJS.ngStorage An AngularJS module that makes Web Storage working in the Angular Way. Contains two services: $localStorage and $sessionStorage. Differences with Other Implementations No Getter 'n' Setter Bullshit - Right from AngularJS homepage: ""Unlike other frameworks, there is no need to [...] wrap the model in accessors methods. Just plain old JavaScript here."" Now you can enjoy the same benefit while achieving data persistence with Web Storage. sessionStorage - We got this often-overlooked buddy covered. Cleanly-Authored Code - Written in the Angular Way, well-structured with testability in mind. No Cookie Fallback - With Web Storage being readily available in all the browsers AngularJS officially supports, such fallback is largely redundant. Install Bower NOTE: We are ngstorage and NOT ngStorage. The casing is important! NPM NOTE: We are ngstorage and NOT ngStorage. The casing is important! nuget Or search for Angular ngStorage in the nuget package manager. https://www.nuget.org/packages/gsklee.ngStorage CDN cdnjs cdnjs now hosts ngStorage at https://cdnjs.com/libraries/ngStorage To use it jsDelivr jsDelivr hosts ngStorage at http://www.jsdelivr.com/#!ngstorage To use is Usage Require ngStorage and Inject the Services Read and Write | Demo Pass $localStorage (or $sessionStorage) by reference to a hook under $scope in plain ol' JavaScript: And use it like you-already-know: Optionally, specify default values using the $default() method: With this setup, changes will be automatically sync'd between $scope.$storage, $localStorage, and localStorage - even across different browser tabs! Read and Write Alternative (Not Recommended) | Demo If you're not fond of the presence of $scope.$storage, you can always use watchers: This, however, is not the way ngStorage is designed to be used with. As can be easily seen by comparing the demos, this approach is way more verbose, and may have potential performance implications as the values being watched quickly grow. Delete | Demo Plain ol' JavaScript again, what else could you better expect? This will delete the corresponding entry inside the Web Storage. Delete Everything | Demo If you wish to clear the Storage in one go, use the $reset() method: ` Optionally, pass in an object you'd like the Storage to reset to: Permitted Values | Demo You can store anything except those not supported by JSON: Infinity, NaN - Will be replaced with null. undefined, Function - Will be removed. Usage from config phase To read and set values during the Angular config phase use the .get/.set functions provided by the provider. Prefix To change the prefix used by ngStorage use the provider function setKeyPrefix during the config phase. Custom serialization To change how ngStorage serializes and deserializes values (uses JSON by default) you can use your own functions. Minification Just run $ npm install to install dependencies. Then run $ grunt for minification. Hints Watch the watch ngStorage internally uses an Angular watch to monitor changes to the $storage/$localStorage objects. That means that a digest cycle is required to persist your new values into the browser local storage. Normally this is not a problem, but, for example, if you launch a new window after saving a value... the new values will not reliably be saved into the browser local storage. Allow a digest cycle to occur by using a zero-value $timeout as: or better using $scope.$evalAsync as: And your new values will be persisted correctly. Todos ngdoc Documentation Namespace Support Unit Tests Grunt Tasks Any contribution will be appreciated."
3500,"list of interesting conference talks and videos on PHP -PHP must watch Basics General Architecture and Design Performance and Scalability Security Testing Frameworks Others Advanced A list of interesting conference talks and great videos on PHP. Inspired by js-must-watch Suggestions and contributions are welcome, please read the contributing guidelines. Basics Composer, Autoloading, Namespacing, and PHPUnit - Tuts+ Code [23:53] Clean Code I: Arguments - Uncle Bob, not PHP-specific [53:33] Clean Code II: Functions - Uncle Bob, not PHP-specific [51:30] Back to top General PHPCraft SouthAfrica Keynote 2014 - Rasmus Lerdorf [1:00:43] It Was Like That When I Got Here: Steps Toward Modernizing a Legacy Codebase - Paul M. Jones at Nashville PHP [47:44] My Take on PHP - Fabien Potencier at dotScale 2014 [18:19] The Modern Developer Toolbox - Pablo Godel at PHPNW14 [49:55] PHP-FIG:History and Future - Phil Sturgeon at PHP CRAFT SouthAfrica 2014 [1:05:01] PHP 5.NEXT: The New Bits - Davey Shafik at PHP UK Conference 2014 [42:40] Your (coding) standards matter - Volker Dusch at PHPNW13 [45:00] HHVM in 2014 - Elizabeth Smith at php[tek] 2014 [58:58] In Depth Composer - Jordi Boggiano at Laracon EU 2013 [46:49] HTTP and Your Angry Dog - Ross Tuck at Laracon 2013 [52:14] Introduction to NoSQL - Martin Fowler at GOTO Conference 2013 [54:51] Vagrant Provisioners In A Nutshell - Erika Heidi at PHP UK Conference 2014 [47:01] Debugging: Past, Present and Future - Derick Rethans at PHPNW14 [45:09] 0x0F Ways to be a Better Developer - Lorna Mitchell & Ivo Jansch at PHPNW13 [40:02] Your code sucks, let's fix it - Rafael Dohms at Kings of Code Festival 2012 [47:24] Ansible Orchestrate your Infrastructure - Jeremy Coates at PHP Day 2014 [52:37] Back to top Architecture and Design Elastic scaling in a (micro)service oriented architecture - Bastian Hofmann at PHP UK Conference 2016 [1:02:24] Inheritance, Polymorphism, & Testing - Misko Hevery, Clean Code Talks 2008 [38:24] Global State & Singletons - Misko Hevery, Clean Code Talks 2008 [54:08] Don't be STUPID, Grasp SOLID - Anthony Ferrara at PHPNW13 [32:30] Keynote: Architecture the Lost Years - Uncle Bob, Ruby Midwest 2011 [1:06:38] Hexagonal Architecture - Chris Fidao at Laracon 2014 [38:43] Unbreakable Domain Models - Mathias Verraes at PHP UK Conference 2014 [1:03:25] Practical Event Sourcing - Mathias Verraes at phpDay 2014 [43:38] Decoupling the Model from the Framework - Mathias Verraes at Laracon 2014 [53:35] API Design: It's Not Rocket Surgery - Dave Ingram at PHP UK 2013 [36:40] The Template Is Not The View: A Brief Introduction to Action-Domain-Responder - Paul M. Jones at Nomad PHP [12:56] Action-Domain-Responder - Paul M. Jones [52:33] Designing HTTP Interfaces And RESTful Web Services - David Zuelke at SymfonyLive Paris 2012 [1:00:54] Web Frontend, API Backend - Lorna Mitchell at PHPNW14 [45:42] RESTing with Symfony 2 - Lukas Kahwe Smith at Symfony Camp [56:52] PHP Annotations: They Exist! - Rafael Dohms at Laracon 2014 [49:48] Aphorisms of API Design - Larry Garfield at Forum PHP 2013 [43:54] Asynchronous PHP - Christopher Pitt at PHP CRAFT SouthAfrica 2014 [47:39] GOTO Conference Keynote - Microservices - Martin Fowler [26:25] Practical Refactoring - Stefan Koopmanschap at PHPNW14 [52:27] Introducing Dependency Injection - Rob Allen at PHPNW13 [39:40] Dont screw it up, how to build durable web APIs - Alessandro Cinelli and Alessandro Nadalin at PHP Day 2014 [45:39] Beyond Design Patterns - Anthony Ferrara at PHPNW14 [49:23] Principles of Agile Design - Uncle Bob, not-PHP specifc [29:35] Beyond Frameworks - Stewart Stuart Herbert at PHP UK Conferences [49:52] Back to top Performance and Scalability High Performance PHP - Anthony Ferrara at PHPNW14 [44:38] Caching Best Practices - Eli White at PHP UK 2014 [1:03:29] Scaling PHP in the Real World - Dustin Whittle at PHP CRAFT SouthAfrica 2014 [33:35] Scaling e-commerce with PHP - Simonas erlinskas at High Load Strategy 2015 [30:14] Processing events at scale - Mariusz Gil at High Load Strategy 2015 [29:17] Profiling PHP Applications - Bastian Hofmann at PHP UK 2014 [1:03:44] Bottleneck Analysis - Ilia Alshanetsky at PHP UK Conference 2013 [50:28] Scaling a High Traffic Web Application: Our Journey from Java to PHP - Dr. Aris Zakinthinos, 2012 [1:18:37] Back to top Security Web Security And You - Eli White at PHP UK Conference 2014 [1:04:23] Security Is Not a Feature, It's a State of Mind - Elizabeth Smith at php[tek] 2014 [1:06:50] Understanding the OWASP - Gary Hockin at PHPNW14 [44:09] Password Storage (And Hacking) in PHP - Anthony Ferrara at PHP Benelux Conference 2013 [39:30] Application Logic Security - Ilia Alshanetsky at PHPBenelux 2013 [54:09] Back to top Testing PHPUnit Best Practices - Sebastian Bergmann at Atlanta PHP UG [1:01:55] Emergent Design with PhpSpec - Marcello Duarte at phpDay 2014 [49:34] Using PhpSpec to build quality into a Symfony app - Jakub Zalas at SymfonyLive London 2013 [40:53] Design How Your Objects Talk Through Mocking - Konstantin Kudryashov at Laracon EU 2014 [1:00:40] Codeception, because tests can have frameworks too! - Luka Muini at phpDay 2014 [25:15] Behat v3! Behavioral-Driven-Development, Functional Tests and Selenium- Ryan Weaver at GrPhpDev 2014 [1:04:23] Test, Transform, Refactor - Marcello Duarte at PHP UK Conference 2014 [52:28] Unit Testing - Misko Hevery, Clean Code Talks [32:07] Don't Look For Things - Misko Hevery, Clean Code Talks 2008 [37:56] Test Driven Laravel form scratch - Adam Wathan, ZendCon 2016 [26:39] Back to top Frameworks Silex Anatomy - Igor Wiedler at PHP Benelux 2013 [46:31] Standardization, the Symfony Way - Fabien Potencier at Laracon 2013 [1:00:05] The State of Laravel - Taylor Otwell at Laracon 2014 [1:00:17] The Tao of Laravel - Taylor Otwell at Laracon EU 2015[32:53] Things Laravel Made Me Believe - Jeffrey Way at Laracon EU 2015 [53:59] Back to top Others Intl Me This, Intl me That - Andrei Zmievski at PHP UK Conference 2014 [51:56] Lisp - Igor Wiedler at Laracon EU 2014 [56:00] Be Awesome in PHPStorm - Jeffrey Way ~[2:00:00] (series) Symfony must watch - must watch videos about Symfony Back to top Advanced Include Hack - HHVM - PHP++ - Paul Tarjan, Sara Golemon at OSCON 2014 [42:06] PHP Under The Hood - Davey Shafik at PHP UK 2014 [36:19] Abstract Machines - Igor Wiedler at Laracon 2014 [1:00:43] Back to top"
4436,"Project moved to: https://github.com/llvm/llvm-projectThe LLVM Compiler Infrastructure This directory and its subdirectories contain source code for LLVM, a toolkit for the construction of highly optimized compilers, optimizers, and runtime environments. LLVM is open source software. You may freely distribute it under the terms of the license agreement found in LICENSE.txt. Please see the documentation provided in docs/ for further assistance with LLVM, and in particular docs/GettingStarted.rst for getting started with LLVM and docs/README.txt for an overview of LLVM's documentation setup. If you are writing a package for LLVM, see docs/Packaging.rst for our suggestions."
2907,"Go configuration with fangsViper v2 feedback Viper is heading towards v2 and we would love to hear what you would like to see in it. Share your thoughts here: https://forms.gle/R6faU74qPRPAzchZ9 Thank you! Go configuration with fangs! Many Go projects are built using Viper including: Hugo EMC RexRay Imgurs Incus Nanobox/Nanopack Docker Notary BloomApi doctl Clairctl Mercure Install Note: Viper uses Go Modules to manage dependencies. What is Viper? Viper is a complete configuration solution for Go applications including 12-Factor apps. It is designed to work within an application, and can handle all types of configuration needs and formats. It supports: setting defaults reading from JSON, TOML, YAML, HCL, envfile and Java properties config files live watching and re-reading of config files (optional) reading from environment variables reading from remote config systems (etcd or Consul), and watching changes reading from command line flags reading from buffer setting explicit values Viper can be thought of as a registry for all of your applications configuration needs. Why Viper? When building a modern application, you dont want to worry about configuration file formats; you want to focus on building awesome software. Viper is here to help with that. Viper does the following for you: Find, load, and unmarshal a configuration file in JSON, TOML, YAML, HCL, INI, envfile or Java properties formats. Provide a mechanism to set default values for your different configuration options. Provide a mechanism to set override values for options specified through command line flags. Provide an alias system to easily rename parameters without breaking existing code. Make it easy to tell the difference between when a user has provided a command line or config file which is the same as the default. Viper uses the following precedence order. Each item takes precedence over the item below it: explicit call to Set flag env config key/value store default Important: Viper configuration keys are case insensitive. There are ongoing discussions about making that optional. Putting Values into Viper Establishing Defaults A good configuration system will support default values. A default value is not required for a key, but its useful in the event that a key hasn't been set via config file, environment variable, remote configuration or flag. Examples: Reading Config Files Viper requires minimal configuration so it knows where to look for config files. Viper supports JSON, TOML, YAML, HCL, INI, envfile and Java Properties files. Viper can search multiple paths, but currently a single Viper instance only supports a single configuration file. Viper does not default to any configuration search paths leaving defaults decision to an application. Here is an example of how to use Viper to search for and read a configuration file. None of the specific paths are required, but at least one path should be provided where a configuration file is expected. You can handle the specific case where no config file is found like this: NOTE [since 1.6]: You can also have a file without an extension and specify the format programmaticaly. For those configuration files that lie in the home of the user without any extension like .bashrc Writing Config Files Reading from config files is useful, but at times you want to store all modifications made at run time. For that, a bunch of commands are available, each with its own purpose: WriteConfig - writes the current viper configuration to the predefined path, if exists. Errors if no predefined path. Will overwrite the current config file, if it exists. SafeWriteConfig - writes the current viper configuration to the predefined path. Errors if no predefined path. Will not overwrite the current config file, if it exists. WriteConfigAs - writes the current viper configuration to the given filepath. Will overwrite the given file, if it exists. SafeWriteConfigAs - writes the current viper configuration to the given filepath. Will not overwrite the given file, if it exists. As a rule of the thumb, everything marked with safe won't overwrite any file, but just create if not existent, whilst the default behavior is to create or truncate. A small examples section: Watching and re-reading config files Viper supports the ability to have your application live read a config file while running. Gone are the days of needing to restart a server to have a config take effect, viper powered applications can read an update to a config file while running and not miss a beat. Simply tell the viper instance to watchConfig. Optionally you can provide a function for Viper to run each time a change occurs. Make sure you add all of the configPaths prior to calling WatchConfig() Reading Config from io.Reader Viper predefines many configuration sources such as files, environment variables, flags, and remote K/V store, but you are not bound to them. You can also implement your own required configuration source and feed it to viper. Setting Overrides These could be from a command line flag, or from your own application logic. Registering and Using Aliases Aliases permit a single value to be referenced by multiple keys Working with Environment Variables Viper has full support for environment variables. This enables 12 factor applications out of the box. There are five methods that exist to aid working with ENV: AutomaticEnv() BindEnv(string...) : error SetEnvPrefix(string) SetEnvKeyReplacer(string...) *strings.Replacer AllowEmptyEnv(bool) When working with ENV variables, its important to recognize that Viper treats ENV variables as case sensitive. Viper provides a mechanism to try to ensure that ENV variables are unique. By using SetEnvPrefix, you can tell Viper to use a prefix while reading from the environment variables. Both BindEnv and AutomaticEnv will use this prefix. BindEnv takes one or more parameters. The first parameter is the key name, the rest are the name of the environment variables to bind to this key. If more than one are provided, they will take precedence in the specified order. The name of the environment variable is case sensitive. If the ENV variable name is not provided, then Viper will automatically assume that the ENV variable matches the following format: prefix + ""_"" + the key name in ALL CAPS. When you explicitly provide the ENV variable name (the second parameter), it does not automatically add the prefix. For example if the second parameter is ""id"", Viper will look for the ENV variable ""ID"". One important thing to recognize when working with ENV variables is that the value will be read each time it is accessed. Viper does not fix the value when the BindEnv is called. AutomaticEnv is a powerful helper especially when combined with SetEnvPrefix. When called, Viper will check for an environment variable any time a viper.Get request is made. It will apply the following rules. It will check for an environment variable with a name matching the key uppercased and prefixed with the EnvPrefix if set. SetEnvKeyReplacer allows you to use a strings.Replacer object to rewrite Env keys to an extent. This is useful if you want to use - or something in your Get() calls, but want your environmental variables to use _ delimiters. An example of using it can be found in viper_test.go. Alternatively, you can use EnvKeyReplacer with NewWithOptions factory function. Unlike SetEnvKeyReplacer, it accepts a StringReplacer interface allowing you to write custom string replacing logic. By default empty environment variables are considered unset and will fall back to the next configuration source. To treat empty environment variables as set, use the AllowEmptyEnv method. Env example Working with Flags Viper has the ability to bind to flags. Specifically, Viper supports Pflags as used in the Cobra library. Like BindEnv, the value is not set when the binding method is called, but when it is accessed. This means you can bind as early as you want, even in an init() function. For individual flags, the BindPFlag() method provides this functionality. Example: You can also bind an existing set of pflags (pflag.FlagSet): Example: The use of pflag in Viper does not preclude the use of other packages that use the flag package from the standard library. The pflag package can handle the flags defined for the flag package by importing these flags. This is accomplished by a calling a convenience function provided by the pflag package called AddGoFlagSet(). Example: Flag interfaces Viper provides two Go interfaces to bind other flag systems if you dont use Pflags. FlagValue represents a single flag. This is a very simple example on how to implement this interface: Once your flag implements this interface, you can simply tell Viper to bind it: FlagValueSet represents a group of flags. This is a very simple example on how to implement this interface: Once your flag set implements this interface, you can simply tell Viper to bind it: Remote Key/Value Store Support To enable remote support in Viper, do a blank import of the viper/remote package: import _ ""github.com/spf13/viper/remote"" Viper will read a config string (as JSON, TOML, YAML, HCL or envfile) retrieved from a path in a Key/Value store such as etcd or Consul. These values take precedence over default values, but are overridden by configuration values retrieved from disk, flags, or environment variables. Viper uses crypt to retrieve configuration from the K/V store, which means that you can store your configuration values encrypted and have them automatically decrypted if you have the correct gpg keyring. Encryption is optional. You can use remote configuration in conjunction with local configuration, or independently of it. crypt has a command-line helper that you can use to put configurations in your K/V store. crypt defaults to etcd on http://127.0.0.1:4001. Confirm that your value was set: See the crypt documentation for examples of how to set encrypted values, or how to use Consul. Remote Key/Value Store Example - Unencrypted etcd Consul You need to set a key to Consul key/value storage with JSON value containing your desired config. For example, create a Consul key/value store key MY_CONSUL_KEY with value: Firestore Of course, you're allowed to use SecureRemoteProvider also Remote Key/Value Store Example - Encrypted Watching Changes in etcd - Unencrypted Getting Values From Viper In Viper, there are a few ways to get a value depending on the values type. The following functions and methods exist: Get(key string) : interface{} GetBool(key string) : bool GetFloat64(key string) : float64 GetInt(key string) : int GetIntSlice(key string) : []int GetString(key string) : string GetStringMap(key string) : map[string]interface{} GetStringMapString(key string) : map[string]string GetStringSlice(key string) : []string GetTime(key string) : time.Time GetDuration(key string) : time.Duration IsSet(key string) : bool AllSettings() : map[string]interface{} One important thing to recognize is that each Get function will return a zero value if its not found. To check if a given key exists, the IsSet() method has been provided. Example: Accessing nested keys The accessor methods also accept formatted paths to deeply nested keys. For example, if the following JSON file is loaded: Viper can access a nested field by passing a . delimited path of keys: This obeys the precedence rules established above; the search for the path will cascade through the remaining configuration registries until found. For example, given this configuration file, both datastore.metric.host and datastore.metric.port are already defined (and may be overridden). If in addition datastore.metric.protocol was defined in the defaults, Viper would also find it. However, if datastore.metric was overridden (by a flag, an environment variable, the Set() method, ) with an immediate value, then all sub-keys of datastore.metric become undefined, they are shadowed by the higher-priority configuration level. Viper can access array indices by using numbers in the path. For example: Lastly, if there exists a key that matches the delimited key path, its value will be returned instead. E.g. Extracting a sub-tree When developing reusable modules, it's often useful to extract a subset of the configuration and pass it to a module. This way the module can be instantiated more than once, with different configurations. For example, an application might use multiple different cache stores for different purposes: We could pass the cache name to a module (eg. NewCache(""cache1"")), but it would require weird concatenation for accessing config keys and would be less separated from the global config. So instead of doing that let's pass a Viper instance to the constructor that represents a subset of the configuration: Note: Always check the return value of Sub. It returns nil if a key cannot be found. Internally, the NewCache function can address max-items and item-size keys directly: The resulting code is easy to test, since it's decoupled from the main config structure, and easier to reuse (for the same reason). Unmarshaling You also have the option of Unmarshaling all or a specific value to a struct, map, etc. There are two methods to do this: Unmarshal(rawVal interface{}) : error UnmarshalKey(key string, rawVal interface{}) : error Example: If you want to unmarshal configuration where the keys themselves contain dot (the default key delimiter), you have to change the delimiter: Viper also supports unmarshaling into embedded structs: Viper uses github.com/mitchellh/mapstructure under the hood for unmarshaling values which uses mapstructure tags by default. Marshalling to string You may need to marshal all the settings held in viper into a string rather than write them to a file. You can use your favorite format's marshaller with the config returned by AllSettings(). Viper or Vipers? Viper comes ready to use out of the box. There is no configuration or initialization needed to begin using Viper. Since most applications will want to use a single central repository for their configuration, the viper package provides this. It is similar to a singleton. In all of the examples above, they demonstrate using viper in its singleton style approach. Working with multiple vipers You can also create many different vipers for use in your application. Each will have its own unique set of configurations and values. Each can read from a different config file, key value store, etc. All of the functions that viper package supports are mirrored as methods on a viper. Example: When working with multiple vipers, it is up to the user to keep track of the different vipers. Q & A Why is it called Viper? A: Viper is designed to be a companion to Cobra. While both can operate completely independently, together they make a powerful pair to handle much of your application foundation needs. Why is it called Cobra? Is there a better name for a commander? Does Viper support case sensitive keys? tl;dr: No. Viper merges configuration from various sources, many of which are either case insensitive or uses different casing than the rest of the sources (eg. env vars). In order to provide the best experience when using multiple sources, the decision has been made to make all keys case insensitive. There has been several attempts to implement case sensitivity, but unfortunately it's not that trivial. We might take a stab at implementing it in Viper v2, but despite the initial noise, it does not seem to be requested that much. You can vote for case sensitivity by filling out this feedback form: https://forms.gle/R6faU74qPRPAzchZ9 Is it safe to concurrently read and write to a viper? No, you will need to synchronize access to the viper yourself (for example by using the sync package). Concurrent reads and writes can cause a panic. Troubleshooting See TROUBLESHOOTING.md."
199,"The de-facto solution to flexible routing with nested views in AngularJSAngularUI Router Note: this is the Angular 1.x source for UI-Router version 1.x. If you are looking for the source for UI-Router version 0.x, it can be found here The de-facto solution to flexible routing in angular Tutorials | API Docs | Download stable (or Minified) | Guide | Sample App | FAQ | Report an Issue | Contribute | Help! | Angular UI-Router is a client-side Single Page Application routing framework for AngularJS. Routing frameworks for SPAs update the browser's URL as the user navigates through the app. Conversely, this allows changes to the browser's URL to drive navigation through the app, thus allowing the user to create a bookmark to a location deep within the SPA. UI-Router applications are modeled as a hierarchical tree of states. UI-Router provides a state machine to manage the transitions between those application states in a transaction-like manner. Get Started UI-Router for Angular 1 UI-Router for Angular 2 UI-Router for React Resources In-Depth Guide Slides comparing ngRoute to ui-router UI-Router Extras / Addons for legacy (0.x) (@christopherthielen) Videos Introduction Video (egghead.io) Tim Kindberg on Angular UI-Router Activating States (egghead.io) Learn Angular.js using UI-Router (LearnCode.academy) Reporting issues and Contributing Please read our Contributor guidelines before reporting an issue or creating a pull request."
1675,"An Android library that help you to build app with swipe back gesture.SwipeBackLayout An Android library that help you to build app with swipe back gesture. Demo Apk GooglePlay Requirement The latest android-support-v4.jar should be referenced by your project. Usage Add SwipeBackLayout as a dependency to your existing project. To enable SwipeBackLayout, you can simply make your Activity extend SwipeBackActivity: In onCreate method, setContentView() should be called as usual. You will have access to the getSwipeBackLayout() method so you can customize the SwipeBackLayout. Make window translucent by adding <item name=""android:windowIsTranslucent"">true</item> to your theme. Simple Example Download Download via Jcenter: Support Pull Requests I will gladly accept pull requests for fixes and feature enhancements but please do them in the develop branch. License Copyright 2013 Isaac Wang Licensed under the Apache License, Version 2.0 (the ""License""); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
3464,"Marlin is an optimized firmware for RepRap 3D printers based on the Arduino platform. | Many commercial 3D printers come with Marlin installed. Check with your vendor if you need source code for your specific machine.Marlin 3D Printer Firmware Additional documentation can be found at the Marlin Home Page. Please test this firmware and let us know if it misbehaves in any way. Volunteers are standing by! Marlin 2.0 Marlin 2.0 takes this popular RepRap firmware to the next level by adding support for much faster 32-bit and ARM-based boards while improving support for 8-bit AVR boards. Read about Marlin's decision to use a ""Hardware Abstraction Layer"" below. Download earlier versions of Marlin on the Releases page. Building Marlin 2.0 To build Marlin 2.0 you'll need Arduino IDE 1.8.8 or newer or PlatformIO. Detailed build and install instructions are posted at: Installing Marlin (Arduino) Installing Marlin (VSCode). Supported Platforms Platform|MCU|Example Boards --------|---|------- Arduino AVR|ATmega|RAMPS, Melzi, RAMBo Teensy++ 2.0|AT90USB1286|Printrboard Arduino Due|SAM3X8E|RAMPS-FD, RADDS, RAMPS4DUE LPC1768|ARM Cortex-M3|MKS SBASE, Re-ARM, Selena Compact LPC1769|ARM Cortex-M3|Smoothieboard, Azteeg X5 mini, TH3D EZBoard STM32F103|ARM Cortex-M3|Malyan M200, GTM32 Pro, MKS Robin, BTT SKR Mini STM32F401|ARM Cortex-M4|ARMED, Rumba32, SKR Pro, Lerdge, FYSETC S6 STM32F7x6|ARM Cortex-M7|The Borg, RemRam V1 SAMD51P20A|ARM Cortex-M4|Adafruit Grand Central M4 Teensy 3.5|ARM Cortex-M4| Teensy 3.6|ARM Cortex-M4| Teensy 4.0|ARM Cortex-M7| Teensy 4.1|ARM Cortex-M7| Submitting Changes Submit Bug Fixes as Pull Requests to the (bugfix-2.0.x) branch. Follow the Coding Standards to gain points with the maintainers. Please submit your questions and concerns to the Issue Queue. Marlin Support For best results getting help with configuration and troubleshooting, please use the following resources: Marlin Documentation - Official Marlin documentation Marlin Discord - Discuss issues with Marlin users and developers Facebook Group ""Marlin Firmware"" RepRap.org Marlin Forum Tom's 3D Forums Facebook Group ""Marlin Firmware for 3D Printers"" Marlin Configuration on YouTube Credits The current Marlin dev team consists of: Scott Lahteine [@thinkyhead] - USA Donate Roxanne Neufeld [@Roxy-3D] - USA Chris Pepper [@p3p] - UK Bob Kuhn [@Bob-the-Kuhn] - USA Erik van der Zalm [@ErikZalm] - Netherlands License Marlin is published under the GPL license because we believe in open development. The GPL comes with both rights and obligations. Whether you use Marlin firmware as the driver for your open or closed-source product, you must keep Marlin open, and you must provide your compatible Marlin source code to end users upon request. The most straightforward way to comply with the Marlin license is to make a fork of Marlin on Github, perform your modifications, and direct users to your modified fork. While we can't prevent the use of this code in products (3D printers, CNC, etc.) that are closed source or crippled by a patent, we would prefer that you choose another firmware or, better yet, make your own."
3753,"Privacy enhanced BitTorrent client with P2P content discoveryTribler |jenkins_build| |docs| |contributors| |pr_closed| |issues_closed| |downloads_7_0| |downloads_7_1| |downloads_7_2| |downloads_7_3| |downloads_7_4| |downloads_7_5| |doi| |openhub| Towards making Bittorrent anonymous and impossible to shut down. We use our own dedicated Tor-like network for anonymous torrent downloading. We implemented and enhanced the Tor protocol specifications plus merged them with Bittorrent streaming. More info: https://github.com/Tribler/tribler/wiki Tribler includes our own Tor-like onion routing network with hidden services based seeding and end-to-end encryption, detailed specs: https://github.com/Tribler/tribler/wiki/Anonymous-Downloading-and-Streaming-specifications The aim of Tribler is giving anonymous access to online (streaming) videos. We are trying to make privacy, strong cryptography and authentication the Internet norm. Tribler currently offers a Youtube-style service. For instance, Bittorrent-compatible streaming, fast search, thumbnail previews and comments. For the past 11 years we have been building a very robust Peer-to-Peer system. Today Tribler is robust: ""the only way to take Tribler down is to take The Internet down"" (but a single software bug could end everything). We make use of submodules, so remember using the --recursive argument when cloning this repo. Obtaining the latest release Just click here <https://github.com/Tribler/tribler/releases/latest>__ and download the latest package for your OS. Obtaining support If you found a bug or have a feature request, please make sure you read our contributing page <http://tribler.readthedocs.io/en/latest/contributing.html> and then open an issue <https://github.com/Tribler/tribler/issues/new>. We will have a look at it ASAP. Contributing Contributions are very welcome! If you are interested in contributing code or otherwise, please have a look at our contributing page <http://tribler.readthedocs.io/en/latest/contributing.html>. Have a look at the issue tracker <https://github.com/Tribler/tribler/issues> if you are looking for inspiration :). Running Tribler from the repository First clone the repository: .. code-block:: bash git clone --recursive https://github.com/Tribler/tribler.git Second, install the dependencies <doc/development/development_on_linux.rst>_. Setting up your development environment We support development on Linux, macOS and Windows. We have written documentation that guides you through installing the required packages when setting up a Tribler development environment. Linux <http://tribler.readthedocs.io/en/latest/development/development_on_linux.html>_ Windows <http://tribler.readthedocs.io/en/latest/development/development_on_windows.html>_ macOS <http://tribler.readthedocs.io/en/latest/development/development_on_osx.html>_ Running Now you can run tribler by executing the tribler.sh script on the root of the repository: .. code-block:: bash ./src/tribler.sh On Windows, you can use the following command to run Tribler: .. code-block:: bash python run_tribler.py Packaging Tribler We have written guides on how to package Tribler for distribution on various systems. Please take a look here <http://tribler.readthedocs.io/en/latest/building/building.html>_. Submodule notes As updated submodules are in detached head state, remember to check out a branch before committing changes on them. If you forgot to check out a branch before doing a commit, you should get a warning telling you about it. To get the commit to a branch just check out the branch and do a git cherry-pick of the commit. Take care of not accidentally committing a submodule revision change with git commit -a. Do not commit a submodule update without running all the tests first and making sure the new code is not breaking Tribler. .. |jenkins_build| image:: http://jenkins-ci.tribler.org/job/Test_tribler_main/badge/icon :target: http://jenkins-ci.tribler.org/job/Test_tribler_main/ :alt: Build status on Jenkins .. |pr_closed| image:: https://img.shields.io/github/issues-pr-closed/tribler/tribler.svg?style=flat :target: https://github.com/Tribler/tribler/pulls :alt: Pull Requests .. |issues_closed| image:: https://img.shields.io/github/issues-closed/tribler/tribler.svg?style=flat :target: https://github.com/Tribler/tribler/issues :alt: Issues .. |openhub| image:: https://www.openhub.net/p/tribler/widgets/project_thin_badge.gif?style=flat :target: https://www.openhub.net/p/tribler .. |downloads_7_0| image:: https://img.shields.io/github/downloads/tribler/tribler/v7.0.2/total.svg?style=flat :target: https://github.com/Tribler/tribler/releases :alt: Downloads(7.0.2) .. |downloads_7_1| image:: https://img.shields.io/github/downloads/tribler/tribler/v7.1.3/total.svg?style=flat :target: https://github.com/Tribler/tribler/releases :alt: Downloads(7.1.3) .. |downloads_7_2| image:: https://img.shields.io/github/downloads/tribler/tribler/v7.2.2/total.svg?style=flat :target: https://github.com/Tribler/tribler/releases :alt: Downloads(7.2.2) .. |downloads_7_3| image:: https://img.shields.io/github/downloads/tribler/tribler/v7.3.2/total.svg?style=flat :target: https://github.com/Tribler/tribler/releases :alt: Downloads(7.3.2) .. |downloads_7_4| image:: https://img.shields.io/github/downloads/tribler/tribler/v7.4.1/total.svg?style=flat :target: https://github.com/Tribler/tribler/releases :alt: Downloads(7.4.1) .. |downloads_7_5| image:: https://img.shields.io/github/downloads/tribler/tribler/v7.5.1/total.svg?style=flat :target: https://github.com/Tribler/tribler/releases :alt: Downloads(7.5.1) .. |contributors| image:: https://img.shields.io/github/contributors/tribler/tribler.svg?style=flat :target: https://github.com/Tribler/tribler/graphs/contributors :alt: Contributors .. |doi| image:: https://zenodo.org/badge/8411137.svg :target: https://zenodo.org/badge/latestdoi/8411137 :alt: DOI number .. |docs| image:: https://readthedocs.org/projects/tribler/badge/?version=main :target: https://tribler.readthedocs.io/en/latest/?badge=main :alt: Documentation Status"
1647,"Text-mode interface for gitTig: text-mode interface for Git :docext: adoc image:https://github.com/jonas/tig/workflows/Linux/badge.svg[Linux CI,link=https://github.com/jonas/tig/actions?query=workflow%3ALinux] image:https://github.com/jonas/tig/workflows/macOS/badge.svg[macOS CI,link=https://github.com/jonas/tig/actions?query=workflow%3AmacOS] image:https://ci.appveyor.com/api/projects/status/jxt1uf52o7r0a8r7/branch/master?svg=true[AppVeyor Build,link=https://ci.appveyor.com/project/fonseca/tig] image:https://badges.gitter.im/Join%20Chat.svg[Join Chat,link=""https://gitter.im/jonas/tig?utm_source=badge&utm_medium=badge&utm_campaign=pr-badge&utm_content=badge""] What is Tig? Tig is an ncurses-based text-mode interface for git. It functions mainly as a Git repository browser, but can also assist in staging changes for commit at chunk level and act as a pager for output from various Git commands. Resources Homepage: https://jonas.github.io/tig/[] Manual: https://jonas.github.io/tig/doc/manual.html[] Tarballs: https://github.com/jonas/tig/releases[] Git URL: git://github.com/jonas/tig.git Gitter: https://gitter.im/jonas/tig[] Q&A: https://stackoverflow.com/questions/tagged/tig[] Bugs and Feature Requests Bugs and feature requests can be reported using the https://github.com/jonas/tig/issuesissue tracker or by mail to either the Git mailing list or directly to the maintainer. Ensure that the word ""tig"" is in the subject. For other Tig related questions please use Stack Overflow: https://stackoverflow.com/questions/tagged/tig[]. Installation and News Information on how to build and install Tig are found in link:INSTALL.{docext}[the installation instructions]. News about releases and latest features and bug fixes are found in link:NEWS.{docext}[the release notes]."
642,"A JavaScript library dedicated to graph drawingsigma.js - v1.2.1 Sigma is a JavaScript library dedicated to graph drawing, mainly developed by @jacomyal and @Yomguithereal. Resources The website provides a global overview of the project, and the documentation is available in the GitHub Wiki. Also, the plugins and examples directories contain various use-cases that might help you understand how to use sigma. How to use it To use it, clone the repository: To build the code: Install Node.js. Install gjslint. Use npm install to install sigma development dependencies. Use npm run build to minify the code with Uglify. The minified file sigma.min.js will then be accessible in the build/ folder. Also, you can customize the build by adding or removing files from the coreJsFiles array in Gruntfile.js before applying the grunt task. Contributing You can contribute by submitting issues tickets and proposing pull requests. Make sure that tests and linting pass before submitting any pull request by running the command grunt. The whole source code is validated by the Google Closure Linter and JSHint, and the comments are written in JSDoc (tags description is available here)."
4040,":fries: The definitive front-end performance guideHow to lose weight (in the browser) The definitive front-end performance guide. Contributing If you want to add new tips or edit the existing ones, just go to the src/documents folder. There you can find all of them in Markdown (.md) format. Remember to add references on each tip that you write at References wiki. Instructions How can I locally run the project? Install Git and NodeJS, if you don't have them already. Open your terminal and download DocPad through this command: Now clone it: Then go to the project's folder: Install all dependencies: And finally run: Now you can see the website running at localhost:9778 :D How can I run another language version? Simply go to the docpad.coffee file and change the value of the currentLang variable. Then you just need to run docpad run again. Browser Support We do care about it. | | | | --- | --- | --- | --- | --- | IE 9+ | Latest | Latest | Latest | Latest | Structure This project uses DocPad, a static generator in NodeJS, and here's the basic structure: . |-- out/ |-- src/ | |-- documents | |-- layouts | |-- partials `-- package.json out/ This is where the generated files are stored, once DocPad has been run. However, this directory is unnecessary for versioning, so it is ignored (.gitignore). src/documents Contains all tips in Markdown (.md) format, in addition to images, fonts, CSS and JS files. src/layouts Contains the default template. src/partials Contains reusable blocks of code. package.json Lists all NodeJS dependencies. Team BrowserDiet was made with love by these people and a bunch of awesome contributors. Creator | --- | Zeno RochaLiferay, Inc. | Design | --- | Briza BuenoAmericanas | Authors | | --- | --- | --- Davidson FellipeGlobo.com | Giovanni KeppelenPlanedia | Jaydson GomesTerra Reviewers | | --- | --- | --- Marcel DuranTwitter | Renato ManginiGoogle | Srgio LopesCaelum Translations | | | | | | --- | --- | --- | --- | --- | --- | --- Mike TaylorEnglish | Emilio lvarezSpanish | Lukasz JakubPolish | FordleeChinese | Nicolas CarloFrench | Tomas DvorakCzech | Makoto TatenoJapanese Credits DocPad by Benjamin Lupton Highlight.js by Ivan Sagalaev Fonts Pacifico by Vernon Adams Open Sans by Steve Matteson Horseshoes by Lauren Ashpole Illustrations The 56 Geeks Project by Scott Johnson Flag Icon Set by GoSquared License Code is under MIT license and content is under Creative Commons BY-SA 3.0"
4023,"A full stack for bitcoin and blockchain-based applicationsBitcore Infrastructure to build Bitcoin and blockchain-based applications for the next generation of financial technology. Getting Started Requirements Trusted P2P Peer MongoDB Server >= v3.4 make g++ gcc Checkout the repo Setup Guide 1. Setup Bitcore config Example bitcore.config.json 2. Setup Bitcoin Node Example Bitcoin Mainnet Config 3. Run Bitcoin node Example Starting a Bitcoin Node 4. Start Bitcore Applications Bitcore Node - A full node with extended capabilities using Bitcoin Core Bitcore Wallet - A command-line based wallet client Bitcore Wallet Client - A client for the wallet service Bitcore Wallet Service - A multisig HD service for wallets Bitpay Wallet - An easy-to-use, multiplatform, multisignature, secure bitcoin wallet Insight - A blockchain explorer web user interface Libraries Bitcore Channel - Micropayment channels for rapidly adjusting bitcoin transactions Bitcore ECIES - Uses ECIES symmetric key negotiation from public keys to encrypt arbitrarily long data streams Bitcore Lib - A pure and powerful JavaScript Bitcoin library Bitcore Lib Cash - A pure and powerful JavaScript Bitcoin Cash library Bitcore Message - Bitcoin message verification and signing Bitcore Mnemonic - Implements mnemonic code for generating deterministic keys Bitcore P2P - The peer-to-peer networking protocol for BTC Bitcore P2P Cash - The peer-to-peer networking protocol for BCH Crypto Wallet Core - A coin-agnostic wallet library for creating transactions, signing, and address derivation Extras Bitcore Build - A helper to add tasks to gulp Bitcore Client - A helper to create a wallet using the bitcore-v8 infrastructure Contributing See CONTRIBUTING.md on the main bitcore repo for information about how to contribute. License Code released under the MIT license. Copyright 2013-2019 BitPay, Inc. Bitcore is a trademark maintained by BitPay, Inc."
3505,"JavaScript hyper-lapse utility for Google Street View.Hyperlapse.js JavaScript hyper-lapse utility for Google Street View. This library was written to create dynamic hyper-lapse (time-lapse with movement) sequences using Google Street View. See it action. Read about this project. Video of what's possible. Example Simple example Dependencies Three.js (r57) a modified version of GSVPano.js Google Maps API v3.12 API Docs API Documentation License The MIT License Copyright (c) 2013 Teehan+Lax Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the ""Software""), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
227,"Generation of diagram and flowchart from text in a similar manner as markdownmermaid :trophy: Mermaid was nominated and won the JS Open Source Awards (2019) in the category ""The most exciting use of technology""!!! Thanks to all involved, people committing pull requests, people answering questions and special thanks to Tyler Long who is helping me maintain the project About Mermaid is a Javascript based diagramming and charting tool that uses Markdown-inspired text definitions and a renderer to create and modify complex diagrams. The main purpose of Mermaid is to help documentation catch up with development. Doc-Rot is a Catch-22 that Mermaid helps to solve. Diagramming and documentation costs precious developer time and gets outdated quickly. But not having diagrams or docs ruins productivity and hurts organizational learning. Mermaid addresses this problem by cutting the time, effort and tooling that is required to create modifiable diagrams and charts, for smarter and more reusable content. The text definitions for Mermaid diagrams allows for it to be updated easily, it can also be made part of production scripts (and other pieces of code). So less time needs to be spent on documenting, as a separate and laborious task. Even non-programmers can create diagrams through the Mermaid Live Editor. Tutorials has video tutorials. Use Mermaid with your favorite applications, check out the list of Integrations and Usages of Mermaid. For a more detailed introduction to Mermaid and some of its more basic uses, look to the Beginner's Guide and Usage. CDN | Documentation | Contribution | Changelog Examples The following are some examples of the diagrams, charts and graphs that can be made using Mermaid and the Markdown-inspired text specific to it. Click here jump into the text syntax. Flow [docs - live editor] graph TD A[Hard] -->|Text| B(Round) B --> C{Decision} C -->|One| D[Result 1] C -->|Two| E[Result 2] Sequence [docs - live editor] sequenceDiagram Alice->>John: Hello John, how are you? loop Healthcheck John->>John: Fight against hypochondria end Note right of John: Rational thoughts! John-->>Alice: Great! John->>Bob: How about you? Bob-->>John: Jolly good! Gantt [docs - live editor] gantt section Section Completed :done, des1, 2014-01-06,2014-01-08 Active :active, des2, 2014-01-07, 3d Parallel 1 : des3, after des1, 1d Parallel 2 : des4, after des1, 1d Parallel 3 : des5, after des3, 1d Parallel 4 : des6, after des4, 1d Class [docs - live editor] classDiagram Class01 <|-- AveryLongClass : Cool <<interface>> Class01 Class09 --> C2 : Where am i? Class09 --* C3 Class09 --|> Class07 Class07 : equals() Class07 : Object[] elementData Class01 : size() Class01 : int chimp Class01 : int gorilla class Class10 { <<service>> int id size() } State [docs - live editor] stateDiagram-v2 [*] --> Still Still --> [*] Still --> Moving Moving --> Still Moving --> Crash Crash --> [*] Pie [docs - live editor] pie ""Dogs"" : 386 ""Cats"" : 85 ""Rats"" : 15 Git [experimental - live editor] Coming soon! User Journey [docs - live editor] journey title My working day section Go to work Make tea: 5: Me Go upstairs: 3: Me Do work: 1: Me, Cat section Go home Go downstairs: 5: Me Sit down: 3: Me Related projects Command Line Interface Live Editor HTTP Server Contributors Mermaid is a growing community and is always accepting new contributors. There's a lot of different ways to help out and we're always looking for extra hands! Look at this issue if you want to know where to start helping out. Detailed information about how to contribute can be found in the contribution guide Appreciation A quick note from Knut Sveidqvist: Many thanks to the d3 and dagre-d3 projects for providing the graphical layout and drawing libraries! Thanks also to the js-sequence-diagram project for usage of the grammar for the sequence diagrams. Thanks to Jessica Peter for inspiration and starting point for gantt rendering. Thank you to Tyler Long who has been a collaborator since April 2017. Thank you to the ever-growing list of contributors that brought the project this far! Mermaid was created by Knut Sveidqvist for easier documentation."
4224,"The missing Javascript smart persistent layerBasil.js The missing Javascript smart persistence layer. Unified localstorage, cookie and session storage JavaScript API. Philosophy Basil aims to ease the frontend storage management for developers. It strives to be bulletproof and handle disabled cookies, full localStorage and other unwanted native storage exceptions.. When you try to store something, basil will automatically look through all the available storage mechanisms and find the best suited one to store your value. It also handles storage of complex javascript objects using json. Basic Usage Advanced Usage Storages Native storages Namespaces Configuration Here is the whole options object that you could give to Basil: Compatibility Firefox 3.5+ Internet Explorer 7 (requires json2.js) Internet Explorer 8+ Chrome 4+ Safari 4+ Plugins List plugin This plugin mimics Redis Lists methods and behaviors. Here are the (yet) supported methods. Set plugin This plugin mimics Redis Sets methods and behaviors. Except sscan all the methods are implemented. Build To generate the production files, make sure you have already installed the dependencies using ` and then just use: ` Tests To launch the test suite, make sure you have already installed the dependencies using `. Tests are launching in all your installed browsers. They're also launched on Travis CI, in PhantomJS. ` License MIT. See LICENSE.md"
3360,"Custom transition between viewcontrollers holding tableviews Custom transition between viewcontrollers holding tableviews. Each cell is animated to simulate a 'wave effect'. Read more about transitions here and UIKit Dynamics here Screenshot Getting Started Install with CocoaPods Add to your Podfile Run Run Install with Carthage Setup as superclass Subclass and override or follow these steps: Setup manually Implement and this delegate method: Remember to set your instance as the navigation delegate: Implement th protocol by returning your tableview's visible cells: Interactive gesture To implement the interactive gesture create a new property in your view controller: initialize it in your viewDidLoad: Attach the gesture recognizer in your viewDidAppear: and detach it in the viewDidDisappear:: If the view controller you are transitioning to has no table view, don't implement visibleCells, the library will handle the transition correctly. As you can see in the sample project, the best results are obtained by setting the view and the cells' background to , and setting a background color or a background image to the navigation controller. Author Andrea Mazzini. I'm available for freelance work, feel free to contact me. Want to support the development of these free libraries? Buy me a coffee via Paypal. Contributors Thanks to everyone kind enough to submit a pull request. MIT License The MIT License (MIT) Copyright (c) 2017 Andrea Mazzini Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the ""Software""), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
1293,"Language Savant. If your repository's language is being reported incorrectly, send us a pull request!Linguist This library is used on GitHub.com to detect blob languages, ignore binary or vendored files, suppress generated files in diffs, and generate language breakdown graphs. Documentation How Linguist works Change Linguist's behaviour with overrides Troubleshooting Contributing guidelines Installation Install the gem: Dependencies Linguist is a Ruby library so you will need a recent version of Ruby installed. There are known problems with the macOS/XCode supplied version of Ruby that causes problems installing some of the dependencies. Accordingly, we highly recommend you install a version of Ruby using Homebrew, rbenv, rvm, ruby-build, asdf or other packaging system, before attempting to install Linguist and the dependencies. Linguist uses charlock_holmes for character encoding and rugged for libgit2 bindings for Ruby. These components have their own dependencies. 1. charlock_holmes * cmake * pkg-config * ICU * zlib 2. rugged * libcurl * OpenSSL You may need to install missing dependencies before you can install Linguist. For example, on macOS with Homebrew: On Ubuntu: Usage Application usage Linguist can be used in your application as follows: Command line usage Git Repository A repository's languages stats can also be assessed from the command line using the github-linguist executable. Without any options, github-linguist will output the breakdown that correlates to what is shown in the language stats bar. The --breakdown flag will additionally show the breakdown of files by language. You can try running github-linguist on the root directory in this repository itself: Single file Alternatively you can find stats for a single file using the github-linguist executable. You can try running github-linguist on files in this repository itself: Docker If you have Docker installed you can build an image and run Linguist within a container: Contributing Please check out our contributing guidelines. License The language grammars included in this gem are covered by their repositories' respective licenses. vendor/README.md lists the repository for each grammar. All other files are covered by the MIT license, see LICENSE."
1634,"Physics-based animations for iOS, tvOS, and macOS.Advance An animation library for iOS, tvOS, and macOS that uses physics-based animations (including springs) to power interactions that move and respond realistically. Installation There are several ways to integrate Advance into your project. Manually: add Advance.xcodeproj to your project, then add Advance-{iOS|macOS|tvOS}.framework as an ""Embedded Binary"" to your application target (under General in target settings). From there, add import Advance to your code and you're good to go. Carthage: add github ""timdonnelly/Advance"" to your Cartfile. CocoaPods: add pod 'Advance' to your Podfile. Swift Package Manager: add a dependency to your Project.swift: .package(url: ""http://github.com/timdonnelly/Advance"", from: ""3.0.0"") Requirements iOS 10+, tvOS 10+, or macOS 10.12+ Swift 5.0 (Xcode 10.2 or higher) Usage API documentation is available here. Advance animations are applied on every frame (using CADisplayLink on iOS/tvOS, and CVDisplayLink on macOS), allowing for fine-grained control at any time. Spring Spring instances animate changes to a value over time, using spring physics. Configuring a spring Animator Animator allows for more flexibility in the types of animation that can be performed, but gives up some convenience in order to do so. Specifically, animators allow for any type of animation or simulation to be performed for a single value. Animators support two fundamentally different types of animations: timed and simulated. Timed animations Timed animations are, well, timed: they have a fixed duration, and they animate to a final value in a predictable manner. TimingFunction described the pacing of a timed animation. TimingFunction comes with a standard set of functions: Custom timing functions can be expressed as unit beziers (described here). Simulated animations Simulated animations use a simulation function to power a physics-based transition. Simulation functions are types conforming to the SimulationFunction protocol. Simulated animations may be started using two different methods: Animating Custom Types Values conforming to the VectorConvertible protocol can be animated by Advance. Conforming types can be converted to and from a Vector implementation. The library adds conformance for many common types through extensions. Contributing If you encounter any issues or surprises, please open an issue. For suggestions or new features, please consider opening a PR with a functional implementation. Issues may be used if you aren't sure how to implement the change, but working code is typically easier to evaluate. License This project is released under the BSD 2-clause license."
3271,"ArduPlane, ArduCopter, ArduRover sourceArduPilot Project Ardupilot is the most advanced, full-featured and reliable open source autopilot software available. It has been under development since 2010 by a diverse team of professional engineers, computer scientists and community contributors. Our autopilot software is capable of controlling almost any vehicle system imaginable, from conventional airplanes, quadplanes, multirotors, and helicopters, to rovers, boats, balancebots and even submarines. It is continually being expanded to provide support for new emerging vehicle types. The ArduPilot project is made up of: ArduCopter: code, wiki ArduPlane: code, wiki Rover: code, wiki ArduSub : code, wiki Antenna Tracker : code, wiki User Support & Discussion Forums Support Forum: https://discuss.ardupilot.org/ Community Site: https://ardupilot.org Developer Information Github repository: https://github.com/ArduPilot/ardupilot Main developer wiki: https://ardupilot.org/dev/ Developer discussion: https://discuss.ardupilot.org Developer chat: https://discord.com/channels/ardupilot Top Contributors Flight code contributors Wiki contributors Most active support forum users Partners who contribute financially How To Get Involved The ArduPilot project is open source and we encourage participation and code contributions: guidelines for contributors to the ardupilot codebase We have an active group of Beta Testers to help us improve our code: release procedures Desired Enhancements and Bugs can be posted to the issues list. Help other users with log analysis in the support forums Improve the wiki and chat with other wiki editors on Gitter Contact the developers on one of the communication channels License The ArduPilot project is licensed under the GNU General Public License, version 3. Overview of license Full Text Maintainers ArduPilot is comprised of several parts, vehicles and boards. The list below contains the people that regularly contribute to the project and are responsible for reviewing patches on their specific area. Andrew Tridgell: Vehicle: Plane, AntennaTracker Board: Pixhawk, Pixhawk2, PixRacer Francisco Ferreira: Bug Master Grant Morphett: Vehicle: Rover Jacob Walser: Vehicle: Sub Lucas De Marchi: Subsystem: Linux Michael du Breuil: Subsystem: Batteries Subsystem: GPS Subsystem: Scripting Peter Barker: Subsystem: DataFlash, Tools Randy Mackay: Vehicle: Copter, Rover, AntennaTracker Tom Pittenger: Vehicle: Plane Bill Geyer: Vehicle: TradHeli Chris Olson: Vehicle: TradHeli Emile Castelnuovo: Board: VRBrain Eugene Shamaev: Subsystem: CAN bus Subsystem: UAVCAN Georgii Staroselskii: Board: NavIO Gustavo Jos de Sousa: Subsystem: Build system Julien Beraud: Board: Bebop & Bebop 2 Leonard Hall: Subsystem: Copter attitude control and navigation Matt Lawrence: Vehicle: 3DR Solo & Solo based vehicles Matthias Badaire: Subsystem: FRSky Mirko Denecke: Board: BBBmini, BeagleBone Blue, PocketPilot Paul Riseborough: Subsystem: AP_NavEKF2 Subsystem: AP_NavEKF3 Pierre Kancir: Subsystem: Copter SITL, Rover SITL Vctor Mayoral Vilches: Board: PXF, Erle-Brain 2, PXFmini Amilcar Lucas: Subsystem: Marvelmind Samuel Tabor: Subsystem: Soaring/Gliding"
3185,"Epoxy is an Android library for building complex screens in a RecyclerViewEpoxy Epoxy is an Android library for building complex screens in a RecyclerView. Models are automatically generated from custom views or databinding layouts via annotation processing. These models are then used in an EpoxyController to declare what items to show in the RecyclerView. This abstracts the boilerplate of view holders, diffing items and binding payload changes, item types, item ids, span counts, and more, in order to simplify building screens with multiple view types. Additionally, Epoxy adds support for saving view state and automatic diffing of item changes. We developed Epoxy at Airbnb to simplify the process of working with RecyclerViews, and to add the missing functionality we needed. We now use Epoxy for most of the main screens in our app and it has improved our developer experience greatly. Installation Basic Usage Documentation Min SDK Contributing Sample App Installation Gradle is the only supported build configuration, so just add the dependency to your project build.gradle file: Replace the variable $epoxyVersion with the latest version : See the releases page for up to date release versions and details Kotlin If you are using Kotlin you should also add so that AutoModel annotations work properly. More information here Also, make sure to use kapt instead of annotationProcessor in your dependencies in the build.gradle file. Library Projects If you are using layout resources in Epoxy annotations then for library projects add Butterknife's gradle plugin to your buildscript. and then apply it in your module: Now make sure you use R2 instead of R inside all Epoxy annotations. This is not necessary if you don't use resources as annotation parameters, such as with custom view models. Basic Usage There are two main components of Epoxy: The EpoxyModels that describe how your views should be displayed in the RecyclerView. The EpoxyController where the models are used to describe what items to show and with what data. Creating Models Epoxy generates models for you based on your view or layout. Generated model classes are suffixed with an underscore (_) are used directly in your EpoxyController classes. From Custom Views Add the @ModelView annotation on a view class. Then, add a ""prop"" annotation on each setter method to mark it as a property for the model. A HeaderViewModel_ is then generated in the same package. More Details From DataBinding If you use Android DataBinding you can simply set up your xml layouts like normal: Then, create an interface or class in any package and add an EpoxyDataBindingLayouts annotation to declare your databinding layouts. From this layout name Epoxy generates a HeaderViewBindingModel_. More Details From ViewHolders If you use xml layouts without databinding you can create a model class to do the binding. A HeaderModel_ class is generated that subclasses HeaderModel and implements the model details. More Details Using your models in a controller A controller defines what items should be shown in the RecyclerView, by adding the corresponding models in the desired order. The controller's buildModels method declares which items to show. You are responsible for calling requestModelBuild whenever your data changes, which triggers buildModels to run again. Epoxy tracks changes in the models and automatically binds and updates views. As an example, our PhotoController shows a header, a list of photos, and a loader (if more photos are being loaded). The controller's setData(photos, loadingMore) method is called whenever photos are loaded, which triggers a call to buildModels so models representing the state of the new data can be built. Or with Kotlin An extension function is generated for each model so we can write this: Integrating with RecyclerView Get the backing adapter off the EpoxyController to set up your RecyclerView: If you are using the EpoxyRecyclerView integration is easier. Kotlin Or use Kotlin Extensions to simplify further and remove the need for a controller class. More Reading And that's it! The controller's declarative style makes it very easy to visualize what the RecyclerView will look like, even when many different view types or items are used. Epoxy handles everything else. If a view only partially changes, such as the description, only that new value is set on the view, so the system is very efficient Epoxy handles much more than these basics, and is highly configurable. See the wiki for in depth documentation. Documentation See examples and browse complete documentation at the Epoxy Wiki If you still have questions, feel free to create a new issue. Min SDK We support a minimum SDK of 14. However, Epoxy is based on the v7 support libraries so it should work with lower versions if you care to override the min sdk level in the manifest. Contributing Pull requests are welcome! We'd love help improving this library. Feel free to browse through open issues to look for things that need work. If you have a feature request or bug, please open a new issue so we can track it. License"
553,"An easy way to add a simple, shimmering effect to any view in an iOS app.Shimmer Shimmer is an easy way to add a shimmering effect to any view in your app. It's useful as an unobtrusive loading indicator. Shimmer was originally developed to show loading status in Paper. Usage To use Shimmer, create a FBShimmeringView or FBShimmeringLayer and add your content. To start shimmering, set the shimmering property to YES. An example of making a label shimmer: There's also an example project. In the example, you can swipe horizontally and vertically to try various shimmering parameters, or tap to start or stop shimmering. (To build the example locally, you'll need to open FBShimmering.xcworkpace rather than the .xcodeproj.) Installation There are two options: Shimmer is available as Shimmer in Cocoapods. Manually add the files into your Xcode project. Slightly simpler, but updates are also manual. Shimmer requires iOS 6 or later. How it works Shimmer uses the -[CALayer mask] property to enable shimmering, similar to what's described in John Harper's 2009 WWDC talk (unfortunately no longer online). Shimmer uses CoreAnimation's timing features to smoothly transition ""on-beat"" when starting and stopping the shimmer. Other Platforms We have a version of Shimmer for Android, too! It's also available on GitHub. Contributing See the CONTRIBUTING file for how to help out. License Shimmer is BSD-licensed."
2518,"Android library implementing a fading effect for the action bar, similar to the one found in the Play Music appFadingActionBar FadingActionBar is a library which implements the cool fading action bar effect that can be seen in the new Play Music app. This library uses the techniques outlined by Cyril Mottier in a popular blog post. The three most commonly used action bar implementations are supported: stock (API 11+), ActionBarCompat and ActionBarSherlock. Try out the sample application: Or browse the source code of the sample application for a complete example of use. Including in your project The library is pushed to Maven Central as a AAR, so you just need to add the following dependency to your build.gradle. dependencies { compile 'com.github.manuelpeinado.fadingactionbar:fadingactionbar:3.1.2' } If your project doesn't use the stock action bar, but one of the compatibility implementations, you would use the following: dependencies { // Use the following if your project uses ActionBarCompat compile 'com.github.manuelpeinado.fadingactionbar:fadingactionbar-abc:3.1.2' // Or the following if your project uses ActionBarSherlock compile 'com.github.manuelpeinado.fadingactionbar:fadingactionbar-abs:3.1.2' } Usage Using the library is really simple, just look at the source code of the provided samples: If your content should be in a ScrollView. If your content should be in a ListView. If your content is a WebView. You can even use the library from a fragment, which is useful when implementing a dual phone/tablet layout. See the demos included in the sample application for a complete overview of the features supported by the library. Known Issues There is an important issue with the library and ListViews. More specifically, things don't work quite right when the activity is re-created due to a configuration change. So, unless you handle configuration changes yourself (or your activity is portrait/landscape only), I strongly suggest you stick to having your content in a ScrollView until a solution to this issue is found. Acknowledgements Thanks to Cyril Mottier for sharing the techniques that make this library possible. Thanks to Antonio Leiva for writing the Navigation Drawer sample. Thanks to Micha Motyczko for coming up with a fix for an important bug. Who's using it #withme. This app attempts to organise information from various social network streams into a single source. Pearl Jam Lyrics. Unofficial app for Pearl Jam fans that want to have all the lyrics of their favorite band in the palm of their hands. Weatherize. A weather app that is designed to look great and tell you the weather like a human does, not a machine. Last.fm for Android. Do you think the official Last.fm app feels a little bit outdated? Check out this one! It has a scrobbler, and a non-ugly holo interface. Watch South Park Episodes. Watch full-length South Park episodes directly from your phone! Browse through your favorite season or search for your favorite episode! Gas Monitor. An application designed around individuals who keep track of their fill history on their vehicles: from price, gallons, date purchased, and miles traveled. RSS Reader. Get all your news in a simple and fluid application. Night of the museums. A unique and easy way to be closer to the art and history of the region of Yekaterinburg, Nevyansk, Irbit and Nizhny Tagil (Russia). Lffl Feed Reader. Lffl feed reader is a free app that allows you to stay up to date on the latest news of your favorite linux blogs using a modern and minimal interface. Club Douala Ravensburg. This app gives you access to the program of the Club Douala Ravensburg (Germany). Does your app use FadingActionBar? If you want to be featured on this list drop me a line. Developed By Manuel Peinado Gallego - manuel.peinado@gmail.com License Copyright 2013,2014 Manuel Peinado Licensed under the Apache License, Version 2.0 (the ""License""); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
2964,"DEPRECATED The TypeScript Definition ManagerThe TypeScript Definition Manager. Deprecation Notice: Regarding TypeScript@2.0 For users doing typings install dt~<package> --global and receiving errors. Starting from TypeScript 2.0, users can install typings using npm install @types/<package>. These typings are coming from DefinitelyTyped. In the future, we hope redirects will be enabled to support existing maintainers to contribute effectively to NPM's @types as they did to typings/registry. Typings on DefinitelyTyped have also moved to the external module format supported by TypeScript. This finally solved the real problem that Typings was trying to solve! It also means it will cause errors such as: To resolve this, we recommend moving to TypeScript 2.0's official aquisition method (npm install @types/angular). You can also drop the --global flag from typings, though some definitions on DefinitelyTyped may not work with the Typings approach because of new TypeScript features (namely UMD namespaces). This project will remain operational for the foreseeable future, but is effectively deprecated. New projects should use @types from NPM. Quick Start Usage Typings is the simple way to manage and install TypeScript definitions. It uses typings.json, which can resolve to the Typings Registry, GitHub, NPM, Bower, HTTP and local files. Packages can use type definitions from various sources and different versions, knowing they will never conflict for users. The public registry is maintained by the community, and is used to resolve official type definitions for JavaScript packages. Read More Commands Coming from TSD? Example typings Why external modules? About the registry FAQ Known Issues Sources npm - dependencies from NPM github - dependencies directly from GitHub (E.g. Duo, JSPM) bitbucket - dependencies directly from Bitbucket jspm: - dependencies from installed JSPM packages with typings distributed. Requires jspm@0.17+. bower - dependencies from Bower common - ""standard"" libraries without a known ""source"" shared - shared library functionality lib - shared environment functionality (mirror of shared) (--global) env - environments (E.g. atom, electron) (--global) global - global (window.<var>) libraries (--global) dt - typings from DefinitelyTyped (usually --global) Contributing Change Log License MIT"
4308,"Malicious traffic detection systemContent Introduction Architecture Demo pages Requirements Quick start Administrator's guide Sensor Server User's guide Reporting interface Real-life cases Mass scans Anonymous attackers Service attackers Malware Suspicious domain lookups Suspicious ipinfo requests Suspicious direct file downloads Suspicious HTTP requests Port scanning DNS resource exhaustion Data leakage False positives Best practice(s) License Sponsors Developers Presentations Blacklist Thank you Third-party integrations Introduction Maltrail is a malicious traffic detection system, utilizing publicly available (black)lists containing malicious and/or generally suspicious trails, along with static trails compiled from various AV reports and custom user defined lists, where trail can be anything from domain name (e.g. zvpprsensinaix.com for Banjori malware), URL (e.g. hXXp://109.162.38.120/harsh02.exe for known malicious executable), IP address (e.g. 185.130.5.231 for known attacker) or HTTP User-Agent header value (e.g. sqlmap for automatic SQL injection and database takeover tool). Also, it uses (optional) advanced heuristic mechanisms that can help in discovery of unknown threats (e.g. new malware). The following (black)lists (i.e. feeds) are being utilized: As of static entries, the trails for the following malicious entities (e.g. malware C&Cs or sinkholes) have been manually included (from various AV reports and personal research): Architecture Maltrail is based on the Traffic -> Sensor <-> Server <-> Client architecture. Sensor(s) is a standalone component running on the monitoring node (e.g. Linux platform connected passively to the SPAN/mirroring port or transparently inline on a Linux bridge) or at the standalone machine (e.g. Honeypot) where it ""monitors"" the passing Traffic for blacklisted items/trails (i.e. domain names, URLs and/or IPs). In case of a positive match, it sends the event details to the (central) Server where they are being stored inside the appropriate logging directory (i.e. LOG_DIR described in the Configuration section). If Sensor is being run on the same machine as Server (default configuration), logs are stored directly into the local logging directory. Otherwise, they are being sent via UDP messages to the remote server (i.e. LOG_SERVER described in the Configuration section). Server's primary role is to store the event details and provide back-end support for the reporting web application. In default configuration, server and sensor will run on the same machine. So, to prevent potential disruptions in sensor activities, the front-end reporting part is based on the ""Fat client"" architecture (i.e. all data post-processing is being done inside the client's web browser instance). Events (i.e. log entries) for the chosen (24h) period are transferred to the Client, where the reporting web application is solely responsible for the presentation part. Data is sent toward the client in compressed chunks, where they are processed sequentially. The final report is created in a highly condensed form, practically allowing presentation of virtually unlimited number of events. Note: Server component can be skipped altogether, and just use the standalone Sensor. In such case, all events would be stored in the local logging directory, while the log entries could be examined either manually or by some CSV reading application. Demo pages Fully functional demo pages with collected real-life threats can be found here. Requirements To properly run the Maltrail, Python 2.6, 2.7 or 3.x is required on *nix/BSD system, together with installed package pcapy (e.g. sudo apt-get install python-pcapy). Sensor component requires at least 1GB of RAM to run in single-process mode or more if run in multiprocessing mode, depending on the value used for option CAPTURE_BUFFER. Additionally, Sensor component (in general case) requires administrative/root privileges. Server component does not have any special requirements. Quick start The following set of commands should get your Maltrail Sensor up and running (out of the box with default settings and monitoring interface ""any""): For Ubuntu/Debian For SUSE/openSUSE For Docker environment instructions can be found here. To start the (optional) Server on same machine, open a new terminal and execute the following: To test that everything is up and running execute the following: Also, to test the capturing of DNS traffic you can try the following: To stop Sensor and Server instances (if running in background) execute the following: Access the reporting interface (i.e. Client) by visiting the http://127.0.0.1:8338 (default credentials: admin:changeme!) from your web browser: Administrator's guide Sensor Sensor's configuration can be found inside the maltrail.conf file's section [Sensor]: If option USE_MULTIPROCESSING is set to true then all CPU cores will be used. One core will be used only for packet capture (with appropriate affinity, IO priority and nice level settings), while other cores will be used for packet processing. Otherwise, everything will be run on a single core. Option USE_FEED_UPDATES can be used to turn off the trail updates from feeds altogether (and just use the provided static ones). Option UPDATE_PERIOD contains the number of seconds between each automatic trails update (Note: default value is set to 86400 (i.e. one day)) by using definitions inside the trails directory (Note: both Sensor and Server take care of the trails update). Option CUSTOM_TRAILS_DIR can be used by user to provide location of directory containing the custom trails (*.txt) files. Option USE_HEURISTICS turns on heuristic mechanisms (e.g. long domain name (suspicious), excessive no such domain name (suspicious), direct .exe download (suspicious), etc.), potentially introducing false positives. Option CAPTURE_BUFFER presents a total memory (in bytes of percentage of total physical memory) to be used in case of multiprocessing mode for storing packet capture in a ring buffer for further processing by non-capturing processes. Option MONITOR_INTERFACE should contain the name of the capturing interface. Use value any to capture from all interfaces (if OS supports this). Option CAPTURE_FILTER should contain the network capture (tcpdump) filter to skip the uninteresting packets and ease the capturing process. Option SENSOR_NAME contains the name that should be appearing inside the events sensor_name value, so the event from one sensor could be distinguished from the other. If option LOG_SERVER is set, then all events are being sent remotely to the Server, otherwise they are stored directly into the logging directory set with option LOG_DIR, which can be found inside the maltrail.conf file's section [All]. In case that the option UPDATE_SERVER is set, then all the trails are being pulled from the given location, otherwise they are being updated from trails definitions located inside the installation itself. Options SYSLOG_SERVER and/or LOGSTASH_SERVER can be used to send sensor events (i.e. log data) to non-Maltrail servers. In case of SYSLOG_SERVER, event data will be sent in CEF (Common Event Format) format to UDP (e.g. Syslog) service listening at the given address (e.g. 192.168.2.107:514), while in case of LOGSTASH_SERVER event data will be sent in JSON format to UDP (e.g. Logstash) service listening at the given address (e.g. 192.168.2.107:5000). Example of event data being sent over UDP is as follows: For option SYSLOG_SERVER (Note: LogSeverity values are 0 (for low), 1 (for medium) and 2 (for high)): For option LOGSTASH_SERVER: When running the sensor (e.g. sudo python sensor.py) for the first time and/or after a longer period of non-running, it will automatically update the trails from trail definitions (Note: stored inside the trails directory). After the initialization, it will start monitoring the configured interface (option MONITOR_INTERFACE inside the maltrail.conf) and write the events to either the configured log directory (option LOG_DIR inside the maltrail.conf file's section [All]) or send them remotely to the logging/reporting Server (option LOG_SERVER). Detected events are stored inside the Server's logging directory (i.e. option LOG_DIR inside the maltrail.conf file's section [All]) in easy-to-read CSV format (Note: whitespace ' ' is used as a delimiter) as single line entries consisting of: time sensor src_ip src_port dst_ip dst_port proto trail_type trail trail_info reference (e.g. ""2015-10-19 15:48:41.152513"" beast 192.168.5.33 32985 8.8.8.8 53 UDP DNS 0000mps.webpreview.dsl.net malicious siteinspector.comodo.com): Server Server's configuration can be found inside the maltrail.conf section [Server]: Option HTTP_ADDRESS contains the web server's listening address (Note: use 0.0.0.0 to listen on all interfaces). Option HTTP_PORT contains the web server's listening port. Default listening port is set to 8338. If option USE_SSL is set to true then SSL/TLS will be used for accessing the web server (e.g. https://192.168.6.10:8338/). In that case, option SSL_PEM should be pointing to the server's private/cert PEM file. Subsection USERS contains user's configuration settings. Each user entry consists of the username:sha256(password):UID:filter_netmask(s). Value UID represents the unique user identifier, where it is recommended to use values lower than 1000 for administrative accounts, while higher value for non-administrative accounts. The part filter_netmask(s) represents the comma-delimited hard filter(s) that can be used to filter the shown events depending on the user account(s). Default entry is as follows: Option UDP_ADDRESS contains the server's log collecting listening address (Note: use 0.0.0.0 to listen on all interfaces), while option UDP_PORT contains listening port value. If turned on, when used in combination with option LOG_SERVER, it can be used for distinct (multiple) Sensor <-> Server architecture. Option FAIL2BAN_REGEX contains the regular expression (e.g. attacker|reputation|potential[^""]*(web scan|directory traversal|injection|remote code)|spammer|mass scanner) to be used in /fail2ban web calls for extraction of today's attacker source IPs. This allows the usage of IP blocking mechanisms (e.g. fail2ban, iptables or ipset) by periodic pulling of blacklisted IP addresses from remote location. Example usage would be the following script (e.g. run as a root cronjob on a minute basis): Same as for Sensor, when running the Server (e.g. python server.py) for the first time and/or after a longer period of non-running, if option USE_SERVER_UPDATE_TRAILS is set to true, it will automatically update the trails from trail definitions (Note: stored inside the trails directory). Its basic function is to store the log entries inside the logging directory (i.e. option LOG_DIR inside the maltrail.conf file's section [All]) and provide the web reporting interface for presenting those same entries to the end-user (Note: there is no need install the 3rd party web server packages like Apache): User's guide Reporting interface When entering the Server's reporting interface (i.e. via the address defined by options HTTP_ADDRESS and HTTP_PORT), user will be presented with the following authentication dialog. User has to enter the proper credentials that have been set by the server's administrator inside the configuration file maltrail.conf (Note: default credentials are admin:changeme!): Once inside, user will be presented with the following reporting interface: The top part holds a sliding timeline (Note: activated after clicking the current date label and/or the calendar icon ) where user can select logs for past events (Note: mouse over event will trigger display of tooltip with approximate number of events for current date). Dates are grouped by months, where 4 month period of data are displayed inside the widget itself. However, by using the provided slider (i.e. ) user can easily access events from previous months. Once clicking the date, all events for that particular date should be loaded and represented by the client's web browser. Depending on number of events and the network connection speed, loading and display of logged events could take from couple of seconds, up to several minutes (e.g. 100,000 events takes around 5 seconds in total). For the whole processing time, animated loader will be displayed across the disabled user interface: Middle part holds a summary of displayed events. Events box represents total number of events in a selected 24-hour period, where red line represents IP-based events, blue line represents DNS-based events and yellow line represents URL-based events. Sources box represents number of events per top sources in form of a stacked column chart, with total number of sources on top. Threats box represents percentage of top threats in form of a pie chart (Note: gray area holds all threats having each <1% in total events), with total number of threats on top. Trails box represents percentage of top trails in form of a pie chart (Note: gray area holds all trails having each <1% in total events), with total number of trails on top. Each of those boxes are active, hence the click on one of those will result with a more detailed graph. Bottom part holds a condensed representation of logged events in form of a paginated table. Each entry holds details for a single threat (Note: uniquely identified by a pair (src_ip, trail) or (dst_ip, trail) if the src_ip is the same as the trail as in case of attacks coming from the outside): Column threat holds threat's unique ID (e.g. 85fdb08d) and color (Note: extruded from the threat's ID), sensor holds sensor name(s) where the event has been triggered (e.g. blitvenica), events holds total number of events for a current threat, severity holds evaluated severity of threat (Note: calculated based on values in info and reference columns, prioritizing malware generated traffic), first_seen holds time of first event in a selected (24h) period (e.g. 06th 08:21:54), last_seen holds time of last event in a selected (24h) period (e.g. 06th 15:21:23), sparkline holds a small sparkline graph representing threat's activity in selected period, src_ip holds source IP(s) of a threat (e.g. 99.102.41.102), src_port holds source port(s) (e.g. 44556, 44589, 44601), dst_ip holds destination IP(s) (e.g. 213.202.100.28), dst_port holds destination port(s) (e.g. 80 (HTTP)), proto holds protocol(s), (e.g. TCP), trail holds a blacklisted (or heuristic) entry that triggered the event(s), info holds more information about the threat/trail (e.g. known attacker for known attacker's IP addresses or ipinfo for known IP information service commonly used by malware during a startup), reference holds a source of the blacklisted entry (e.g. (static) for static trails or myip.ms for a dynamic feed retrieved from that same source) and tags holds user defined tags for a given trail (e.g. APT28). When moving mouse over src_ip and dst_ip table entries, information tooltip is being displayed with detailed reverse DNS and WHOIS information (Note: RIPE is the information provider): Event details (e.g. src_port, dst_port, proto, etc.) that differ inside same threat entry are condensed in form of a bubble icon (i.e. ). This is performed to get an usable reporting interface with as less rows as possible. Moving mouse over such icon will result in a display of an information tooltip with all items held (e.g. all port numbers being scanned by attacker): Clicking on one such icon will open a new dialog containing all stored items (Note: in their uncondensed form) ready to be Copy-Paste(d) for further analysis: When hovering mouse pointer over the threat's trail for couple of seconds it will result in a frame consisted of results using the trail as a search term performed against Search Encrypt search engine. In lots of cases, this provides basic information about the threat itself, eliminating the need for user to do the manual search for it. In upper right corner of the opened frame window there are two extra buttons. By clicking the first one (i.e. ), the resulting frame will be opened inside the new browser's tab (or window), while by clicking the second one (i.e. ) will immediately close the frame (Note: the same action is achieved by moving the mouse pointer outside the frame borders): For each threat there is a column tag that can be filled with arbitrary ""tags"" to closely describe all threats sharing the same trail. Also, it is a great way to describe threats individually, so all threats sharing the same tag (e.g. yahoo) could be grouped out later: Real-life cases In the following section some of the ""usual suspects"" scenarios will be described through the real-life cases. Mass scans Mass scans is a fairly common phenomenon where individuals and/or organizations give themselves a right to scan the whole 0.0.0.0/0 IP range (i.e. whole Internet) on a daily basis, with disclaimer where they say that if you don't like it then you should contact them privately to be skipped from future scans. To make stuff worse, organizations as Shodan and ZoomEye give all results freely available (to other potential attackers) through their search engine. In the following screenshots you'll see details of Shodan scans in one single day. Here is a reverse DNS and WHOIS lookup of the ""attacker""'s address: When hovering mouse pointer over the trail column's content (IP address), you'll be presented with the search results from Search Encrypt where you'll be able to find more information about the ""attacker"": In the dst_ip column, if you have a large organization, you'll be presented with large list of scanned IP addresses: In the dst_port column you'll be able to see all ports that have been scanned by such mass scans: In other similar situations you'll see the same behaviour, coming from blacklisted individual attacker(s) (in this case by cinsscore.com): One more common behaviour is scanning of the whole 0.0.0.0/0 IP range (i.e. Internet) in search for one particular port (e.g. TCP port 443 when Heartbleed has been found). In the following screenshot you'll find one such case for previously blacklisted attacker(s) (in this case by alienvault.com and two other blacklists) targeting the UDP port 5060 (i.e. SIP) in search for misconfigured VoIP devices: Anonymous attackers To spot the potential attackers hidden behind the Tor anonymity network, Maltrail utilizes publicly available lists of Tor exit nodes. In the following screenshot you'll see a case where potential attacker has been utilizing the Tor network to access the web target (over HTTP) in our organization's range in suspicious way (total 171 connection requests in 10 minutes): Service attackers Fairly similar case to the previous one is when previously blacklisted attacker tries to access particular (e.g. non-HTTP(s)) service in our organization's range in rather suspicious way (i.e. total 1513 connection attempts in less than 15 minutes): If we enter the ssh attacker to the Filter field, we'll be able to see all similar occurrences for that day, but in this case for port 22 (i.e. SSH): Malware In case of connection attempts coming from infected computers inside our organization toward already known C&C servers, you'll be able to find threats similar to the following (in this case Beebone): In case of DNS requests containing known DGA domain names, threat will be shown like (in this case Necurs): In the following case file downloads from blacklisted (in this case by malwarepatrol.net) URL(s) have occurred: If we enter the particular malware name (in this case Ramnit) into the Filter field, only threats that are known to be linked to this malware will be filtered in (showing you all affected internal computers): More generally, if we enter the malware into the Filter field, all threats that have been found by malware(-related) trails (e.g. IP addresses) will be filtered in: Suspicious domain lookups Maltrail uses the static list of TLD domains that are known to be commonly involved in suspicious activities. Most such TLD domains are coming from free domain registrars (e.g. Freenom), hence they should be under greater scrutiny. In the following screenshot we can find a case where one such TLD domain .cm has been used by unknown malware using the DGA algorithm to contact its C&C server(s): There are also cases when perfectly valid TLD domains (e.g. .ru) are used for suspicious activities, such in this case (e.g. long domain name (suspicious)) where the domains are obviously DGA generated by unknown malware: Maltrail uses static list of so-called ""dynamic domains"" that are often used in suspicious activities (e.g. for malware C&C servers that often change the destination's IP addresses): Also, Maltrail uses static list of ""onion""-related domains that are also often used in suspicious activities (e.g. malware contacting C&C servers by using Tor2Web service(s)): In case of old and/or obsolete malware that sits undetected on organization's infected internal computers, there is often a ""phenomenon"" where malware continuously tries to contact the long dead C&C server's domain without any DNS resolution. Hence, those kind of (potential) threats will be marked as excessive no such domain (suspicious): In case that one trail is responsible for too many threats (e.g. in case of fake source IPs like in DNS amplification attacks), all similar threats will be grouped under a single flood threat (Note: threat's ID will be marked with suffix F0), like in the following example: Suspicious ipinfo requests Lots of malware uses some kind of ipinfo service (e.g. ipinfo.io) to find out the victim's Internet IP address. In case of regular and especially in out-of-office hours, those kind of requests should be closely monitored, like in the following example: By using filter ipinfo all potentially infected computers in our organization's range can be listed that share this kind of suspicious behaviour: Suspicious direct file downloads Maltrail tracks all suspicious direct file download attempts (e.g. .apk, .bin, .class, .chm, .dll, .egg, .exe, .hta, .hwp, .ps1, .scr, .sct and .xpi file extensions). This can trigger lots of false positives, but eventually could help in reconstruction of the chain of infection (Note: legitimate service providers, like Google, usually use encrypted HTTPS to perform this kind of downloads): Suspicious HTTP requests In case of suspicious requests coming from outer web application security scanners (e.g. searching for SQLi, XSS, LFI, etc. vulnerabilities) and/or the internal user malicious attempts toward unknown web sites, threats like the following could be found (real case of attackers trying to exploit Joomla! CMS CVE-2015-7297, CVE-2015-7857, and CVE-2015-7858 vulnerabilities): In following example, web application vulnerability scan has been marked as ""suspicious"": If we click on the bubble icon (i.e. ) for details and copy paste the whole content to a textual file, we'll be able to see all suspicious HTTP requests: In the following screenshot, a run of popular SQLi vulnerability tool sqlmap can be found inside our logs: Port scanning In case of too many connection attempts toward considerable amount of different TCP ports, Maltrail will warn about the potential port scanning, as a result of its heuristic mechanism detection. It the following screenshot such warning(s) can be found for a run of popular port scanning tool nmap: DNS resource exhaustion One popular DDoS attack against the web server(s) infrastructure is the resource exhaustion of its (main) DNS server by making valid DNS recursion queries for (pseudo)random subdomain names (e.g. abpdrsguvjkyz.www.dedeni.com): Data leakage Miscellaneous programs (especially mobile-based) present malware(-like) behaviour where they send potentially sensitive data to the remote beacon posts. Maltrail will try to capture such behaviour like in the following example: False positives Like in all other security solutions, Maltrail is prone to ""false positives"". In those kind of cases, Maltrail will (especially in case of suspicious threats) record a regular user's behaviour and mark it as malicious and/or suspicious. In the following example it can be seen that a blacklist feed provider blocklist.de marked regular Google server as attacker(s), resulting with the following threat: By hovering mouse over the trail, frame with results from Search Encrypt search show that this is (most probably) a regular Google's server: As another example, access to regular .work domains (popular TLD for malicious purposes) resulted with the following threat: Nevertheless, administrator(s) should invest some extra time and check (with other means) whether the ""suspicious"" means malicious or not, as in the following example: Best practice(s) Install Maltrail: On Ubuntu/Debian On SUSE/openSUSE Set working environment: Set running environment: crontab -e # autostart server & periodic update sudo crontab -e # autostart sensor & periodic restart License This software is provided under a MIT License. See the accompanying LICENSE file for more information. Sponsors Sansec Developers Miroslav Stampar (@stamparm) Mikhail Kasimov (@MikhailKasimov) Presentations 47th TF-CSIRT Meeting, Prague (Czech Republic), 2016 (slides) Blacklist Maltrail's daily updated blacklist of malware-related domains can be found here. It is based on trails found at trails/static/malware and can be safely used for DNS traffic blocking purposes. Thank you Thomas Kristner Eduardo Arcusa Les James Lay Ladislav Baco (@laciKE) John Kristoff (@jtkdpu) Michael Mnz (@mimugmail) David Brush @Godwottery Third-party integrations FreeBSD Port OPNSense Gateway Plugin D4 Project BlackArch Linux GScan 1 MalwareWorld 1 oisd | domain blocklist 1 NextDNS 1 NoTracking 1 1 Using (only) trails"
4072,"A Node.js tool to automate end-to-end web testing. A Node.js tool to automate end-to-end web testing.Write tests in JS or TypeScript, run them and view results. Homepage Documentation FAQ Support Works on all popular environments: TestCafe runs on Windows, MacOS, and Linux. It supports desktop, mobile, remote and cloud browsers (UI or headless). 1 minute to set up: You do not need WebDriver or any other testing software. Install TestCafe with one command, and you are ready to test: npm install -g testcafe Free and open source: TestCafe is free to use under the MIT license. Plugins provide custom reports, integration with other tools, launching tests from IDE, etc. You can use the plugins made by the GitHub community or make your own. Running a sample test in Safari Table of contents Features TestCafe Studio: IDE for End-to-End Web Testing Getting Started Documentation Get Help Issue Tracker Stay in Touch Contributing Plugins Different Versions of TestCafe Badge License Creators Features Stable tests and no manual timeouts TestCafe automatically waits for page loads and XHRs before the test starts and after each action. It also features smart test actions and assertions that wait for page elements to appear. You can change the maximum wait time. If elements load faster, tests skip the timeout and continue. Rapid test development tool Changes in test code immediately restart the test, and you see the results instantly. See how it works in the TestCafe Live repository. Latest JS and TypeScript support TestCafe supports the latest JavaScript features, including ES2017 (for example, async/await). You can also use TypeScript if you prefer a strongly typed language. Detects JS errors in your code TestCafe reports JS errors that it finds on the webpage. Tests automatically fail because of that. However, you can disable this. Concurrent test launch TestCafe can open multiple instances of the same browser to run parallel tests which decreases test execution time. PageObject pattern support The TestCafe's Test API includes a high-level selector library, assertions, etc. You can combine them to implement readable tests with the PageObject pattern. Easy to include in a continuous integration system You can run TestCafe from a console, and its reports can be viewed in a CI system's interface (TeamCity, Jenkins, Travis & etc.) TestCafe Studio: IDE for End-to-End Web Testing TestCafe works great for JavaScript developers, but at some point you will need to delegate testing tasks to your Q&A department. If that's the case and you are looking for a codeless way to record and maintain tests compatible with your existing infrastructure, check out TestCafe Studio - a testing IDE built on top of the open-source TestCafe. Read the following article to learn how TestCafe Studio could fit into your workflow: What's Better than TestCafe? TestCafe Studio. Record and Run a Test in TestCafe Studio Getting Started Installation Ensure that Node.js (Current or Active LTS is recommended, version 12 at minimum) and npm are installed on your computer before running it: Creating the Test As an example, we are going to test the https://devexpress.github.io/testcafe/example page. Create a .js or .ts file on your computer. Note that it needs to have a specific structure: tests must be organized into fixtures. You can paste the following code to see the test in action: Running the Test Call the following command in a command shell. Specify the target browser and file path. TestCafe opens the browser and starts executing the test. Important! Make sure the browser tab that runs tests stays active. Do not minimize the browser window. Inactive tabs and minimized browser windows switch to a lower resource consumption mode where tests are not guaranteed to execute correctly. Viewing the Results TestCafe outputs the results into a command shell by default. See Reporters for more information. You can also use plugins to customize the reports. Read the Getting Started page for a more detailed guide. Documentation Go to our website for full documentation on TestCafe. Get Help Join the TestCafe community on Stack Overflow to get help. Ask and answer questions with the TestCafe tag. Issue Tracker Use our GitHub issues page to report bugs and suggest improvements. Stay in Touch Follow us on Twitter. We post TestCafe news and updates, several times a week. Contributing Read our Contributing Guide to learn how to contribute to the project. To create your own plugin for TestCafe, you can use these plugin generators: Build a browser provider to set up tests on your on-premises server farm, to use a cloud testing platform, or to start your local browsers in a special way. Use this Yeoman generator to write only a few lines of code. To build a custom reporter with your formatting and style, check out this generator. If you want your plugin to be listed below, send us a note in a Github issue. Thank you to all the people who already contributed to TestCafe! | | | | | | :---: |:---: |:---: |:---: |:---: |:---: | aha-oretama |ai |aleks-pro |AlexanderMoiseev |AlexanderMoskovkin |alexey-lin | | | | | | | :---: |:---: |:---: |:---: |:---: |:---: | AlexKamaev |AlexSkorkin |alexwybraniec |andrewbranch |AndreyBelym |AndyWendt | | | | | | | :---: |:---: |:---: |:---: |:---: |:---: | anthophobiac |arubtsov |augustomezencio-hotmart |bdwain |benmonro |beyondcompute | | | | | | | :---: |:---: |:---: |:---: |:---: |:---: | bill-looby-i |bsmithb2 |caseyWebb |cdrini |cgfarmer4 |Chris-Greaves | | | | | | | :---: |:---: |:---: |:---: |:---: |:---: | churkin |dej611 |DIRECTcut |Dmitry-Ostashev |ericyd |Farfurix | | | | | | | :---: |:---: |:---: |:---: |:---: |:---: | GeoffreyBooth |helen-dikareva |honsq90 |infctr |inikulin |Ivan-Katovich | | | | | | | :---: |:---: |:---: |:---: |:---: |:---: | jamesgeorge007 |jaypea |kanhaiya15 |kirovboris |kubejm |LavrovArtem | | | | | | | :---: |:---: |:---: |:---: |:---: |:---: | link89 |lzxb |macdonaldr93 |MargaritaLoseva |Marketionist |MatthewNielsen27 | | | | | | | :---: |:---: |:---: |:---: |:---: |:---: | mattmanske |mcjim |miherlosev |morfey13 |mostlyfabulous |murajun1978 | | | | | | | :---: |:---: |:---: |:---: |:---: |:---: | NiavlysB |NickCis |Nuarat |Ogurecher |pietrovich |radarhere | | | | | | | :---: |:---: |:---: |:---: |:---: |:---: | raspo |rbardini |renancouto |rueyaa332266 |sgrillon14 |smockle | | | | | | | :---: |:---: |:---: |:---: |:---: |:---: | stefanschenk |superroma |theghostbel |titerman |tobiasbueschel |varunkumar | | | | | | | :---: |:---: |:---: |:---: |:---: |:---: | VasilyStrelyaev |vitalics |Vla8islav |wentwrong |intermike |DevSide | | | | :---: |:---: |:---: | b12031106 |tomashanacek |danielroe | Plugins TestCafe developers and community members made these plugins: Browser Providers Use TestCafe with cloud browser providers and emulators. SauceLabs provider (by @AndreyBelym) BrowserStack provider (by @AndreyBelym) CrossBrowserTesting provider (by @sijosyn) LambdaTest provider (by @kanhaiya15) Nightmare headless provider (by @ryx) Testingbot provider (by @testingbot) fbsimctl iOS emulator (by @ents24) Electron (by @AndreyBelym) Puppeteer (by @jdobosz) Puppeteer Chromium (by @stefanschenk) Framework-Specific Selectors Work with page elements in a way that is native to your framework. React (by @kirovboris) Angular (by @miherlosev) Vue (by @miherlosev) Aurelia (by @miherlosev) Plugins for Task Runners Integrate TestCafe into your project's workflow. Grunt (by @crudo) Gulp (by @inikulin) Custom Reporters View test results in different formats. TeamCity (by @nirsky) Slack (by @Shafied) NUnit (by @AndreyBelym) TimeCafe (by @jimthedev) GitHub Action Run TestCafe tests in GitHub Actions workflows. Run TestCafe Test Accessibility Find accessibility issues in your web app. axe-testcafe (by @helen-dikareva) IDE Plugins Run tests and view results from your favorite IDE. TestCafe Test Runner for Visual Studio Code (by @romanresh) TestLatte for Visual Studio Code (by @Selminha) TestCafe runner for Webstorm (by @lilbaek) Code snippets for TestCafe (by @hdorgeval) SublimeText (by @churkin) ESLint Use ESLint when writing and editing TestCafe tests. ESLint plugin (by @miherlosev) Cucumber Support Create and run tests that use the Cucumber syntax. gherkin-testcafe (by @kiwigrid) - run your Cucumber tests with TestCafe as a backend. Requires CucumberJS. testcafe-cucumber-steps (by @Marketionist) - provides predefined Cucumber steps for gherkin-testcafe. Different Versions of TestCafe | | TestCafe | TestCafe Studio | | ------ |:-------------------------------------------------:|:-----------------------------------------------------------------------:| | No need for WebDriver, browser plugins or other tools | | | | Cross-platform and cross-browser out of the box | | | | Write tests in the latest JavaScript or TypeScript | | | | Clear and flexible API supports ES6 and PageModel pattern | | | | Stable tests due to the Smart Assertion Query Mechanism | | | | Tests run fast due to intelligent Automatic Waiting Mechanism and Concurrent Test Execution | | | | Custom reporter plugins | | | | Use third-party Node.js modules in test scripts | | | | Integration with popular CI systems | | * | | Free and open-source | | | | Visual Test Recorder | | | | Interactive Test Editor | | | | Automatic Selector Generation | | | | Run Configuration Manager | | | | IDE-like GUI | | | * You can use open-source TestCafe to run TestCafe Studio tests in CI systems. Badge Show everyone you are using TestCafe: To display this badge, add the following code to your repository readme: Thanks to BrowserStack We are grateful to BrowserStack for providing the infrastructure that we use to test code in this repository. License Code released under the MIT license. Creators Developer Express Inc. (https://devexpress.com)"
3375,"Metis - Free Bootstrap Admin Dashboard Templatebootstrap-admin-template Metis is a simple yet powerful free Bootstrap admin dashboard template that you can feel free to use for any app, service, software or anything else. Feel free to share and fork it. This template currently is slighly outdated but withing few weeks we are going to make a major overhaul making ot the best free admin template you have seen on Github or elsewhere on the web. TOC Download Building Demo Release History Credits Author License Download Bootstrap 2.3.2 v1.2 ready for use Bootstrap 3.3.7 v2.3.2 ready public folder your use 2.3.2 Version required node.js & bower & gulp 2.3.2 RTL Version required node.js & bower & gulp 1.2 Version Demo Demo v2.3.2 RTL v2.3.2 Credits node.js bower gulp Assemble jQuery Bootstrap LESS Moment.js SubtlePatterns FullCalendar Chosen CKEditor Colorpicker for Bootstrap Data Tables Datepicker for Bootstrap elFinder Input Limiter Jasny Bootstrap jQuery Validation jQuery Sparklines Animate Autosize Countdown Date range picker Flot jQuery Form Form Wizard Gritter Mouse Wheel PageDown-Bootstrap Plupload Bootstrap Switch tablesorter tagsinput Bootstrap Timepicker Touch Punch Uniform Validation Engine jquery.validVal bootstrap3-wysihtml5-bower screenfull.js metisMenu About Authors Colorlib - Colorlib is the most popular source for free WordPress themes and HTML templates. Aigars Silkalns - Aigars maintains this project and is also the idea author behind Colorlib and everything you will find on that website. Other resources Free Admin Dashboards - Most popular free admin dashboards that can be used as templates for your upcoming projects. Free HTML Admin Templates Free Admin Templates Free Dashboard Templates Free Website Templates - Most popular free HTML website templates. Admin Templates (premium) License Copyright (c) 2016 Aigars Silkalns & Colorlib Released under the MIT license. This free Bootstrap admin template is distributed as as it with no support. You can feel free to use it, share it, tweak it, work in it, sell it or do whatever you want as long as you keep the original license in place. This file was generated by verb, v0.9.0, on July 31, 2017."
3466,"Solarized Colorscheme for IntelliJ IDEASolarized Colorscheme for IntelliJ IDEA Original Solarized color scheme developed by Ethan Schoonover es@ethanschoonover.com Adapted for IntelliJ IDEA by: Adam Vandenberg flangy@gmail.com Johan Kaving johan@kaving.se Visit the Solarized homepage See the Solarized homepage for screenshots, details and color scheme versions for Vim, Mutt, popular terminal emulators and other applications. These versions can also be found in the main Solarized repository on GitHub. Unfortunately the IntelliJ subtree in the main repository has not been updated and is out-of-sync with this repository. For IntelliJ this IntelliJ-only repository is therefore recommended over the main repository. Status These color scheme files are primarily tested with the latest version of IntelliJ IDEA Community Edition. They might work with other versions of IntelliJ IDEA as well as other JetBrains tools (e.g. PhpStorm and PyCharm). This table lists the languages (and other sections under Preferences | Editor | Colors & Fonts) for which the syntax highlighting has been adapted to the Solarized color scheme: Language/Section Supported Note ActionScript Yes Android Logcat Yes Apache Config Yes BEMHTML Yes Bash Yes (BashSupport 1.1beta14 or later) Buildout config Yes C No C++ No CMD Yes CSS Yes Clojure Templates Yes CoffeeScript Yes Custom Templates Yes Dart Yes Debugger Yes Diff Yes Django/Jinja2 Template Yes ERB Yes Erlang Yes File Status Yes General Yes Gherkin (Cucumber) Yes Google Go Yes GQL Yes Groovy Yes HAML Yes HTML Yes Haskell Yes JFlex Yes Jade Yes Java Yes JavaScript Yes JSP Yes Jodd props file Yes Kotlin Yes LESS Yes Localization file Yes Lua Yes Mako Template Yes Markdown Yes Objective-C Yes PHP Yes Properties Yes Python Yes ReST file Yes RegExp Yes Ruby Yes Rust Yes SASS Yes SQL Yes Scala Yes Tea Yes Twig Yes XML Yes XPath Yes YAML Yes Installation Option 1: Install using ""Import Settings..."" Clone this repository Go to File | Import Settings... and specify the intellij-colors-solarized directory or the settings.jar file. Click OK in the dialog that appears. Restart IntelliJ IDEA macOS Go to Preferences | Editor | Colors Scheme and select one of the new color themes. Windows / Linux * Go to File | Settings... | Editor | Color Scheme and select one of the new color themes. Option 2: Manual installation Clone this repository Copy Solarized Dark.icls and Solarized Light.icls to your IntelliJ IDEA preferences color directory. The directory varies, depending on which JetBrains IDE you are using. The colors directory may need to be created. It is typically in: macOS * ~/Library/Preferences/IntelliJIdeaXX/colors (IntelliJ IDEA Ultimate Edition), * ~/Library/Preferences/IdeaICXX/colors (IntelliJ IDEA Community Edition), * ~/Library/Preferences/WebIDE70/colors (PHPStorm 7.0), * ~/Library/Preferences/WebIDE80/colors (PHPStorm 8.0), * ~/Library/Preferences/WebStorm8/colors (WebStorm 8.0). Linux * ~/.<PRODUCT><VERSION>/colors Generic path, * ~/.IdeaICXX/config/colors (IntelliJ IDEA), * ~/.PyCharmXX/colors (PyCharm). Windows * %USERPROFILE%\.IdeaICXX\config\colors (IntelliJ IDEA Community Edition), * %USERPROFILE%\.PyCharm40\config\colors (PyCharm 4.5 Community Edition). Restart IntelliJ IDEA macOS Go to Preferences | Editor | Colors Scheme and select one of the new color themes. Windows / Linux * Go to File | Settings... | Editor | Color Scheme and select one of the new color themes. Darcula Depending on the Look and Feel that you use the background color for editor tabs will be different. The default L&F has a light gray background, while the Darcula L&F has a dark background. It is hard to find colors that work equally well on both light and dark backgrounds, and therefore the settings.jar file contains Darcula versions of the color schemes. The only difference from the regular versions is that these color schemes inherit their default colors from the Darcula theme rather than from Default. Note About Fonts Unfortunately, font settings are included in the color settings files. You should probably modify these in Preferences | Editor | Colors & Fonts | Font after adding the color schemes to your IntelliJ IDEA installation. Note About Committing Changes If you want to commit updates to the ICLS color scheme files, make sure to run the buildjar.sh script before committing to generate an updated settings.jar file as well. The script has been tested on OS X, on other operating systems you're on your own."
4231,Edit in place for AngularJSAngular-xeditable Edit in place for AngularJS Overview Angular-xeditable is a bundle of AngularJS directives that allows you to create editable elements in your projects. Such technique is also known as click-to-edit or edit-in-place. It is based on ideas of x-editable but was written from scratch to use power of angular and support complex forms / editable grids. Demo and docs https://vitalets.github.io/angular-xeditable Installation Bower ` NPM ` Manual Download latest version from project homepage. Insert dependency ` Usage with a Asset/Module Bundler Dependencies Basically it does not depend on any libraries except AngularJS itself. For themes you may need to include Twitter Bootstrap CSS. For some extra controls (e.g. datepicker) you may need to include angular-ui bootstrap for Bootstrap 2/3. Include ui-bootstrap4 for Bootstrap 4. To use ui-select you will need to include angular-ui ui-select. To use ngTagsInput you will need to include mbenford ngTagsInput. To use ui-date you will need to include angular-ui ui-date. Reporting issues and Contributing Please read our Contributor guidelines before reporting an issue or creating a pull request. License MIT
3135,":baby: The easiest way to use Bluetooth (BLE )in ios/os ,even bady can use . ,iososThe easiest way to use Bluetooth (BLE )in ios,even bady can use. CoreBluetoothiosmac osx. 1CoreBluetoothCoreBluetooth API 2CoreBluetoothBabyBluetoothblock 3: 4:channel 5: 6: 7:githubstarBluetooth 8:demoios 9:central model and peripheral model 0.7.0 wiki The full documentation of the project is available on its wiki. english readme link,please click it! Table Of Contents QuickExample QuickExample central model appBLE4.0 wiki :BabyBluetoothAppDemo peripheral model appBLE4.0 2service6characteristic ` wiki :BluetoothStubOnIOS 1 step1:Classes/objc step2:.h ` 2 cocoapods step1:add the following line to your Podfile: ` step2:.h ` wiki BabyBluetoothExamples/BabyBluetoothAppDemo :lightblueBabyBluetooth - 1 - 2servicescharacteristic - 3characteristiccharacteristicvaluedescriptorsDescriptorsvalue - 40x01characteristic - 5/ characteristicnotify BabyBluetoothExamples/BluetoothStubOnIOS : iOS2characteristic Babybluetooth BabyBluetoothExamples/BabyBluetoothOSDemo :mac ososiosBabyBluetoothios/ososmaciosos - 1characteristiccharacteristicvaluedescriptorsDescriptorsvaluenslog BabyBluetoothExamples/BluetoothStubOnOSX :mac osperipheral modelswift - 1 - 21service3characteristic 4.0bleios6iPhone4s osios osBabyBluetoothOSDemo ios 8.36.0 Carthage Install swift,swift wiki babybluetooth,~ ios iosios iosapp iosBabyBluetooth -iosBabyBluetooth ... CoreBuetooth Bluetooth Accessory Design Guidelines for Apple Products live qq6: 284341984( qq5: 426082944( qq4: 313084771( qq3530142592( qq2168756967( qq1426603940() -iotp6 p7 ,android,iOS, coolnameismy@gmail.com starfollow~ BUGIssues appBabybluetoothcoolnameismy@hotmail.comreadme BabyBluetoothBabyBluetoothPull Requests"
1371,perfect-scrollbar[ARCHIVED] - Use https://github.com/mdbootstrap/perfect-scrollbar Bower Package of perfect-scrollbar This is the Bower package of perfect-scrollbar. For details and usage please read more on https://github.com/noraesae/perfect-scrollbar.
2688,"Using the jedi autocompletion library for VIM... image:: https://github.com/davidhalter/jedi-vim/blob/master/doc/logotype-a.svg jedi-vim - awesome Python autocompletion with VIM .. image:: https://travis-ci.org/davidhalter/jedi-vim.svg?branch=master :target: https://travis-ci.org/davidhalter/jedi-vim :alt: Travis-CI build status jedi-vim is a VIM binding to the autocompletion library Jedi <http://github.com/davidhalter/jedi>_. Here are some pictures: .. image:: https://github.com/davidhalter/jedi/raw/master/docs/_screenshots/screenshot_complete.png Completion for almost anything (Ctrl+Space). .. image:: https://github.com/davidhalter/jedi/raw/master/docs/_screenshots/screenshot_function.png Display of function/class bodies, docstrings. .. image:: https://github.com/davidhalter/jedi/raw/master/docs/_screenshots/screenshot_pydoc.png Documentation (Pydoc) support (with highlighting, Shift+k). There is also support for goto and renaming. Get the latest from github <http://github.com/davidhalter/jedi-vim>_. Documentation Documentation is available in your vim: :help jedi-vim. You can also look it up on github <http://github.com/davidhalter/jedi-vim/blob/master/doc/jedi-vim.txt>_. You can read the Jedi library documentation here <http://jedi.readthedocs.io/en/latest/>_. If you want to report issues, just use the github issue tracker. In case of questions about the software, please use stackoverflow <https://stackoverflow.com/questions/tagged/jedi-vim>_ and tag your question with jedi-vim. Contributing We love Pull Requests! Read the instructions in CONTRIBUTING.md. Features The Jedi library understands most of Python's core features. From decorators to generators, there is broad support. Apart from that, jedi-vim supports the following commands Completion <C-Space> Goto assignment <leader>g (typical goto function) Goto definition <leader>d (follow identifier as far as possible, includes imports and statements) Goto (typing) stub <leader>s Show Documentation/Pydoc K (shows a popup with assignments) Renaming <leader>r Usages <leader>n (shows all the usages of a name) Open module, e.g. :Pyimport os (opens the os module) Installation Requirements You need a VIM version that was compiled with Python 2.7 or later (+python or +python3). You can check this from within VIM using :python3 import sys; print(sys.version) (use :python for Python 2). Manual installation You might want to use pathogen <https://github.com/tpope/vim-pathogen> or Vundle <https://github.com/gmarik/vundle> to install jedi-vim. The first thing you need after that is an up-to-date version of Jedi. Install git submodule update --init --recursive in your jedi-vim repository. Example installation command using Pathogen: .. code-block:: sh git clone --recursive https://github.com/davidhalter/jedi-vim.git ~/.vim/bundle/jedi-vim Example installation using Vundle: Add the following line in your ~/.vimrc .. code-block:: vim Plugin 'davidhalter/jedi-vim' For installing Jedi, pip install jedi will also work, but you might run into issues when working in virtual environments. Please use git submodules. Installation with your distribution On Arch Linux, you can also install jedi-vim from official repositories as vim-jedi <https://www.archlinux.org/packages/community/any/vim-jedi/>. It is also available on Debian (8) <https://packages.debian.org/vim-python-jedi> and Ubuntu (14.04) <http://packages.ubuntu.com/vim-python-jedi> as vim-python-jedi. On Fedora Linux, it is available as vim-jedi <https://apps.fedoraproject.org/packages/vim-jedi>. Please note that this version might be quite old compared to using jedi-vim from Git. Caveats Note that the python-mode <https://github.com/klen/python-mode>_ VIM plugin seems to conflict with jedi-vim, therefore you should disable it before enabling jedi-vim. To enjoy the full features of jedi-vim, you should have VIM >= 7.3, compiled with +conceal (which is not the case on some platforms, including OS X). If your VIM does not meet these requirements, the parameter recommendation list may not appear when you type an open bracket after a function name. Please read the documentation <http://github.com/davidhalter/jedi-vim/blob/master/doc/jedi-vim.txt>_ for details. Settings Jedi is by default automatically initialized. If you don't want that I suggest you disable the auto-initialization in your .vimrc: .. code-block:: vim let g:jedi#auto_initialization = 0 There are also some VIM options (like completeopt and key defaults) which are automatically initialized, but you can skip this: .. code-block:: vim let g:jedi#auto_vim_configuration = 0 You can make jedi-vim use tabs when going to a definition etc: .. code-block:: vim let g:jedi#use_tabs_not_buffers = 1 If you are a person who likes to use VIM-splits, you might want to put this in your .vimrc: .. code-block:: vim let g:jedi#use_splits_not_buffers = ""left"" This options could be ""left"", ""right"", ""top"", ""bottom"" or ""winwidth"". It will decide the direction where the split open. Jedi automatically starts the completion, if you type a dot, e.g. str., if you don't want this: .. code-block:: vim let g:jedi#popup_on_dot = 0 Jedi selects the first line of the completion menu: for a better typing-flow and usually saves one keypress. .. code-block:: vim let g:jedi#popup_select_first = 0 Jedi displays function call signatures in insert mode in real-time, highlighting the current argument. The call signatures can be displayed as a pop-up in the buffer (set to 1 by default (with the conceal feature), 2 otherwise), which has the advantage of being easier to refer to (but is a hack with many drawbacks since it changes the buffer's contents), or in Vim's command line aligned with the function call (set to 2), which can improve the integrity of Vim's undo history. .. code-block:: vim let g:jedi#show_call_signatures = ""1"" Here are a few more defaults for actions, read the docs (:help jedi-vim) to get more information. If you set them to """", they are not assigned. .. code-block:: vim NOTE: subject to change! let g:jedi#goto_command = ""<leader>d"" let g:jedi#goto_assignments_command = ""<leader>g"" let g:jedi#goto_stubs_command = ""<leader>s"" let g:jedi#goto_definitions_command = """" let g:jedi#documentation_command = ""K"" let g:jedi#usages_command = ""<leader>n"" let g:jedi#completions_command = ""<C-Space>"" let g:jedi#rename_command = ""<leader>r"" An example for setting up your project: .. code-block:: vim let g:jedi#environment_path = ""/usr/bin/python3.9"" jedi-vim tries its best to guess your virtual env. If you want to work with a specific virtual environment however, you can point jedi-vim towards it: .. code-block:: vim let g:jedi#environment_path = ""venv"" Finally, if you don't want completion, but all the other features, use: .. code-block:: vim let g:jedi#completions_enabled = 0 FAQ I don't want the docstring window to popup during completion This depends on the completeopt option. Jedi initializes it in its ftplugin. Add the following line to your .vimrc to disable it: .. code-block:: vim autocmd FileType python setlocal completeopt-=preview I want to do autocompletion Don't even think about changing the Jedi command to <Tab>, use supertab <https://github.com/ervandew/supertab>_! The completion is too slow! Completion of complex libraries (like Numpy) should only be slow the first time you complete them. After that the results should be cached and very fast. If it is still slow after the initial completion and you have installed the python-mode Vim plugin, try disabling its rope mode: .. code-block:: vim let g:pymode_rope = 0 See issue #163 <https://github.com/davidhalter/jedi-vim/issues/163>__. You can also use deoplete-jedi <https://github.com/zchee/deoplete-jedi>__ for completions, which uses Jedi, but does completions asynchronously (requires Neovim). It makes sense to use both jedi-vim and deoplete-jedi, but you should disable jedi-vim's completions then: .. code-block:: vim let g:jedi#completions_enabled = 0 Testing jedi-vim is being tested with a combination of vspec <https://github.com/kana/vim-vspec> and py.test <http://pytest.org/>. The tests are in the test subdirectory, you can run them calling:: py.test The tests are automatically run with travis <https://travis-ci.org/davidhalter/jedi-vim>_."
4769,"Docker container orchestration platformHelios Status: Bug-fix only This project was created when there were no open source container orchestration frameworks. Since the advent of Kubernetes and other tools, we've stopped adding new features to helios and are now switching to other tools like Kubernetes. This project will no longer have new features or accept PRs for new features. We will continue to accept bug fixes, however. Helios is a Docker orchestration platform for deploying and managing containers across an entire fleet of servers. Helios provides a HTTP API as well as a command-line client to interact with servers running your containers. It also keeps a history of events in your cluster including information such as deploys, restarts and version changes. Usage Example Getting Started If you're looking for how to use Helios, see the docs directory. Most probably the User Manual is what you're looking for. If you're looking for how to download, build, install and run Helios, keep reading. Prerequisites The binary release of Helios is built for Ubuntu 14.04.1 LTS, but Helios should be buildable on any platform with at least Java 8 and a recent Maven 3 available. Other components that are required for a helios installation are: Docker 1.0 or newer Zookeeper 3.4.0 or newer Install & Run Quick start for local usage Use helios-solo to launch a local environment with a Helios master and agent. First, ensure you have Docker installed locally. Test this by making sure docker info works. Then install helios-solo: Once you've got it installed, bring up the helios-solo cluster: You can now use helios-solo as your local Helios cluster. If you have issues, see the detailed helios-solo documentation. Production on Debian, Ubuntu, etc. Prebuilt Debian packages are available for production use. To install: Note that the Helios master and agent services both try to connect to ZooKeeper at localhost:2181 by default. We recommend reading the Helios configuration & deployment guide before starting a production cluster. Manual approach The launcher scripts are in bin/. After you've built Helios following the instructions below, you should be able to start the agent and master: $ bin/helios-master & $ bin/helios-agent & If you see any issues, make sure you have the prerequisites (Docker and Zookeeper) installed. Build & Test First, make sure you have Docker installed locally. If you're using OS X, we recommend using docker-machine. Actually building Helios and running its tests should be a simple matter of running: $ mvn clean package For more info on setting up a development environment and an introduction to the source code, see the Developer Guide. How it all fits together The helios command line tool connects to your helios master via HTTP. The Helios master is connected to a Zookeeper cluster that is used both as persistent storage and as a communications channel to the agents. The helios agent is a java process that typically lives on the same host as the Docker daemon, connecting to it via a Unix socket or optionally TCP socket. Helios is designed for high availability, with execution state being confined to a potentially highly available Zookeeper cluster. This means that several helios-master services can respond to HTTP requests concurrently, removing any single point of failure in the helios setup using straight forward HTTP load balancing strategies. Production Readiness We at Spotify are running Helios in production (as of October 2015) with dozens of critical backend services, so we trust it. Whether you should trust it to not cause smoking holes in your infrastructure is up to you. Why Helios? There are a number of Docker orchestration systems, why should you choose Helios? Helios is pragmatic. We're not trying to solve everything today, but what we have, we try hard to ensure is rock-solid. So we don't have things like resource limits or dynamic scheduling yet. Today, for us, it has been more important to get the CI/CD use cases, and surrounding tooling solid first. That said, we eventually want to do dynamic scheduling, composite jobs, etc. (see below for more). But what we provide, we use (i.e. we eat our own dogfood), so you can have reasonable assurances that anything that's been in the codebase for more than a week or two is pretty solid as we release frequently (usually, at least weekly) into production here at Spotify. Helios should be able to fit in the way you already do ops. Of the popular Docker orchestration frameworks, Helios is the only one we're aware of that doesn't have anything much in the way of system dependencies. That is, we don't require that you run in AWS or GCE, etc. We don't require a specific network topology. We don't require you run a specific operating system. We don't require that you're using Mesos. Our only requirement is that you have a ZooKeeper cluster somewhere and a JVM on the machines which Helios runs on. So if you're using Puppet, Chef, etc., to manage the rest of the OS install and configuration, you can still continue to do so with whatever Linux OS you're using. Don't have to drink all the Kool-Aid. Generally, we try to make it so you only have to take the features you want to use, and should be able to ignore the rest. For example, Helios doesn't prescribe a discovery service: we happen to provide a plugin for SkyDNS, and we hear that someone else is working on one for another service, but if you don't want to even use a discovery service, you don't have to. Scalability. We're already at hundreds of machines in production, but we're nowhere near the limit before the existing architecture would need to be revisited. Helios can also scale down well in that you can run a single machine instance if you want to run it all locally. Other Software You Might Want To Consider Here are a few other things you probably want to consider using alongside Helios: * docker-gc Garbage collects dead containers and removes unused images. * helios-skydns Makes it so you can auto register services in SkyDNS. If you use leading underscores in your SRV record names, let us know, we have a patch for etcd which disables the ""hidden"" node feature which makes this use case break. * skygc When using SkyDNS, especially if you're using the Helios Testing Framework, can leave garbage in the skydns tree within etcd. This will clean out dead stuff. * docker-maven-plugin Simplifies the building of Docker containers if you're using Maven (and most likely Java). Findbugs To run findbugs on the helios codebase, do mvn clean compile site. This will build helios and then run an analysis, emitting reports in helios-*/target/site/findbugs.html. To silence an irrelevant warning, add a filter match along with a justification in findbugs-exclude.xml. The Nickel Tour The sources for the Helios master and agent are under helios-services. The CLI source is under helios-tools. The Helios Java client is under helios-client. The main meat of the Helios agent is in Supervisor.java, which revolves around the lifecycle of managing individual running Docker containers. For the master, the HTTP response handlers are in src/main/java/com/spotify/helios/master/resources. Interactions with ZooKeeper for the agent and master are mainly in ZookeeperAgentModel.java and ZooKeeperMasterModel.java, respectively. The Helios services use Dropwizard which is a bundle of Jetty, Jersey, Jackson, Yammer Metrics, Guava, Logback and other Java libraries. Community Ideas These are things we want, but haven't gotten to. If you feel inspired, we'd love to talk to you about these (in no particular order): Host groups ACLs - on jobs, hosts, and deployments Composite jobs -- be able to deploy related containers as a unit on a machine Run once jobs -- for batch jobs Resource specification and enforcement -- That is: restrict my container to X MB of RAM, X CPUs, and X MB disk and perhaps other things like IOPs, network bandwidth, etc. Dynamic scheduling of jobs -- either within Helios itself or as a layer on top Packaging/Config for other Linux distributions such as RedHat, CoreOS, etc."
3169,"MapDB provides concurrent Maps, Sets and Queues backed by disk storage or off-heap-memory. It is a fast and easy to use embedded Java database engine. MapDB: database engine MapDB combines embedded database engine and Java collections. It is free under Apache 2 license. MapDB is flexible and can be used in many roles: Drop-in replacement for Maps, Lists, Queues and other collections. Off-heap collections not affected by Garbage Collector Multilevel cache with expiration and disk overflow. RDBMs replacement with transactions, MVCC, incremental backups etc Local data processing and filtering. MapDB has utilities to process huge quantities of data in reasonable time. Hello world Maven snippet, VERSION is Hello world: You can continue with quick start or refer to the documentation. Support More details. Development MapDB is written in Kotlin, you will need IntelliJ Idea. You can use Gradle to build MapDB. MapDB is extensively unit-tested. By default, only tiny fraction of all tests are executed, so build finishes under 10 minutes. Full test suite has over million test cases and runs for several hours/days. To run full test suite, set -Dmdbtest=1 VM option. Longer unit tests might require more memory. Use this to increase heap memory assigned to unit tests: -DtestArgLine=""-Xmx3G"" By default unit tests are executed in 3 threads. Thread count is controlled by -DtestThreadCount=3 property On machine with limited memory you can change fork mode so unit test consume less RAM, but run longer: -DtestReuseForks=false"
4431,"For resolve the layout conflict when keybord & panel are switching (Android )The handler for the keyboard and panel layout conflict in Android This solution was built When I was working in WeChat, what is used for resolving the layout conflict when you switch between the keyboard and the emoji-panel/function-panel. There is a post to declaration the core rules of this solution: Switching between the panel and the keyboard in Wechat Welcome PR Comments as much as possible. Commit message format follow: AngularJS's commit message convention . The change of each commit as small as possible. INSTALLATION JKeyboardPanelSwitch is installed by adding the following dependency to your build.gradle file: If you want to import snapshot version, We have already publish the snapshot version to the sonatype so you can import snapshot version after declare the following repository: USAGE Recommend clone the demo project and run it, I has already cover cases as much as possible in the demo project. The integration tutorial of The non-fullscreen theme Or The status bar is translucent with fitsSystemWindows=true The integration tutorial of The fullscreen theme Or The status bar is translucent with fitsSystemWindows=false PRINCIPLE The calculation about the height of keyboard and whether the keyboard is showingRef: KeyboardUtil.KeyboardStatusListener#calculateKeyboardHeightKeyboardUtil.KeyboardStatusListener#calculateKeyboardShowing Handle the problem about the layout conflictRef: KPSwitchRootLayoutHandlerBesides the panel layout used in the case of the non-fullscreen theme: KPSwitchPanelLayoutHandlerThe panel layout used in case of the fullscreen theme: KPSwitchFSPanelLayoutHandler License"
4864,"The HTML5 ebook framework to publish interactive books & magazines on iPad & iPhone using simply open web standardsProject Baker This is the original Baker Framework repository by Davide Casali, Marco Colombo and Alessandro Morandi. Note that this repo is not maintained anymore. The new official fork can be found at https://github.com/bakerframework/baker/."
2142,"Simple & lightweight responsive slider plugin (in 1kb)ResponsiveSlides.js v1.55 Simple & lightweight responsive slider plugin (in 1kb) ResponsiveSlides.js is a tiny jQuery plugin that creates a responsive slider using elements inside a container. It has been used on sites like Microsoft's Build 2012 and Gridset App. ResponsiveSlides.js works with wide range of browsers including all IE versions from IE6 and up. It also adds CSS max-width support for IE6 and other browsers that don't natively support it. Only dependency is jQuery (1.6 and up supported, tested up to 1.8.3) and that all the images are the same size. Biggest difference to other responsive slider plugins is the file size (1.4kb minified and gzipped) + that this one doesn't try to do everything. ResponsiveSlides.js has basically only two different modes: Either it just automatically fades the images, or operates as a responsive image container with pagination and/or navigation to fade between slides. Features: Fully responsive 1kb minified and gzipped CSS3 transitions with JavaScript fallback Simple markup using unordered list Settings for transition and timeout durations Multiple slideshows supported Automatic and manual fade Works in all major desktop and mobile browsers Captions and other html-elements supported inside slides Separate pagination and next/prev controls Possibility to choose where the controls append to Possibility to randomize the order of the slides Possibility to use custom markup for pagination Can be paused while hovering slideshow and/or controls Images can be wrapped inside links Optional 'before' and 'after' callbacks Usage Instructions and demo For instructions and demo go to http://responsiveslides.com/, or download this repository as a zip file and and open ""index.html"" from the ""example"" folder. View additional usage examples online. View a demo with captions. Currently jQuery 1.6 and up is supported. License Licensed under the MIT license. Copyright (c) 2011-2012 Viljami Salminen, http://viljamis.com/ Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the ""Software""), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. Changelog v1.55 (2016-08-05) - Adds jQuery 3.0 compatibility (thanks to @Requios!). v1.54 (2013-04-26) - Fixes few bugs with the before and after callbacks. v1.53 (2013-01-14) - Minor speed optimization (thanks @bazineta!). v1.52 (2013-01-07) - Adds option called ""manualControls"" which allows to write custom markup for pager navigation (thanks to @andyadams). ""controls"" option is renamed to ""navContainer"". Default speed of the transition is now to 500ms. Adds also webkit-backface-visibility: hidden; style for the slides to prevent some HD acceleration issues on mobile WebKit browsers. v1.51 (2012-12-15) - Fixes a bug where pictures would not display if next button was clicked too quickly 10 times. v1.5 (2012-12-14) - Adds CSS3 transition support with automatic jQuery fallback. v1.32 (2012-05-09) - Fixes a bug which caused the slideshow to break in Chrome when changing between active and inactive browser tabs. v1.31 (2012-05-02) - Easier to use callbacks (+ optional ""active"" class for the next/prev buttons when animating slides. If you need this functionality, open the unminified version and search for ""Adds active class during slide animation"" and remove comments around it). v1.3 (2012-04-26) - Three new options: ""random"", ""pause"", ""pauseControls"" + small bug fixes. v1.25 (2012-04-19) - No more flashing of unstyled slideshow before JS has loaded. Adds also better support for cases when JavaScript isn't available. v1.24 (2012-04-12) - Changes the way slideshow works if there's only one slide. Now all classes and max-width for the container are added, but we don't show the next and prev buttons anymore as they don't make much sense in that case. This version also fixes a bug which made the 'previous' button always go to the next slide. v1.23 (2012-03-31) - Adds new option called ""controls"", which allows to choose where the controls should be appended to. Includes also code optimization, bug fixes, better option names and better jQuery support (jQuery 1.4 and up is now supported). v1.22 (2012-03-27) - Adds callback events which are similar as in @Wilto's Dynamic Carousel. The possibility to change the 'namespace' is also back + next/prev buttons have now classes which make more sense. v1.21 (2012-03-23) - Added two new options: 'nextText' and 'prevText'. v1.20 (2012-03-21) - New option called 'nav', which enables next and previous buttons. Can be used with 'pagination' and 'auto' options. Adds also new themes folder with three different ways to use the new next and previous buttons. v1.10 (2012-03-12) - Refactoring, New markup style, CSS is now separated from the plugin, you can have links around images and other elements inside slides (not just images, but also captions etc.) + New option called ""pagination"", which enables to choose both ""pagination"" and ""auto"" at the same time. Shout outs for the help to @bgutschke v1.05 (2012-03-05) - No more need to change the namespace if you have more than one slideshow on the same page. v1.04 (2011-12-19) - Fixes problems when ResponsiveSlides.js is used with other plugins v1.03 (2011-12-12) - Code refactoring, smaller size, better performance v1.01 (2011-12-11) - Better usage of styles and the namespace v1.00 (2011-12-04) - Release Want to do a pull request? Great! New ideas are more than welcome, but please check the Pull Request Guidelines first before doing so."
2407,"Autosize is a small, stand-alone script to automatically adjust textarea height to fit text.Summary Autosize is a small, stand-alone script to automatically adjust textarea height to fit text. Demo Full documentation and a demo can be found at jacklmoore.com/autosize Install via NPM Browser compatibility Chrome | Firefox | IE | Safari | iOS Safari | Android | Opera Mini | Windows Phone IE ------ | --------|----|--------|------------|---------|------------|------------------ yes | yes | 9 | yes | yes | 4 | ? | 8.1 Usage The autosize function accepts a single textarea element, or an array or array-like object (such as a NodeList or jQuery collection) of textarea elements. Released under the MIT License"
100,"fullPage plugin by Alvaro Trigo. Create full screen pages fast and simplefullPage.js English | Espaol | Franais | P | | Available for Vue, React and Angular. | 7Kb gziped | Created by @imac2 Demo online | Codepen Wordpress plugin for Gutenberg and WordPress plugin for Elementor Wordpress theme fullpage.js Extensions Frequently Answered Questions A simple and easy to use library that creates fullscreen scrolling websites (also known as single page websites or onepage sites) and adds landscape sliders inside the sections of the site. Introduction Compatibility License Usage Creating links to sections or slides Creating smaller or bigger sections State classes added by fullpage.js Lazy loading Auto play/pause embedded media Use extensions Options Methods Callbacks Reporting issues Contributing to fullpage.js Changelog Build tasks Resources Who is using fullpage.js Donations Sponsors Introduction Suggestion are more than welcome, not only for feature requests but also for coding style improvements. Let's make this a great library to make people's lives easier! Compatibility fullPage.js is fully functional on all modern browsers, as well as some old ones such as Internet Explorer 9, Opera 12, etc. It works with browsers with CSS3 support and with the ones which don't have it, making it ideal for old browsers compatibility. It also provides touch support for mobile phones, tablets and touch screen computers. Special thanks to Browserstack for supporting fullpage.js. License Commercial license If you want to use fullPage to develop non open sourced sites, themes, projects, and applications, the Commercial license is the appropriate license. With this option, your source code is kept proprietary. Which means, you won't have to change your whole application source code to an open source license. [Purchase a Fullpage Commercial License] Open source license If you are creating an open source application under a license compatible with the GNU GPL license v3, you may use fullPage under the terms of the GPLv3. The credit comments in the JavaScript and CSS files should be kept intact (even after combination or minification) Read more about fullPage's license. Usage As you can see in the example files, you will need to include: - The JavaScript file fullpage.js (or its minified version fullpage.min.js) - The css file fullpage.css Optionally, when using css3:false, you can add the easings file in case you want to use other easing effects apart from the one included in the library (easeInOutCubic). Install using bower or npm Optionally, you can install fullPage.js with bower or npm if you prefer: Terminal: Including files: Using Webpack, Browserify or Require.js? Check how to use fullPage.js with module loaders. Optional use of CDN If you prefer to use a CDN to load the needed files, fullPage.js is in CDNJS: https://cdnjs.com/libraries/fullPage.js Required HTML structure Start your HTML document with the compulsory HTML DOCTYPE declaration on the 1st line of your HTML code. You might have troubles with sections heights otherwise. The examples provided use HTML 5 doctype <!DOCTYPE html>. Each section will be defined with an element containing the section class. The active section by default will be the first section, which is taken as the home page. Sections should be placed inside a wrapper (<div id=""fullpage""> in this case). The wrapper can not be the body element. If you want to define a different starting point rather than the first section or the first slide of a section, just add the class active to the section and slide you want to load first. In order to create a landscape slider within a section, each slide will be defined by default with an element containing the slide class: You can see a fully working example of the HTML structure in the [simple.html` file](https://github.com/alvarotrigo/fullPage.js/blob/master/examples/simple.html). Initialization Initialization with Vanilla Javascript All you need to do is call fullPage.js before the closing </body> tag. Initialization with jQuery You can use fullpage.js as a jQuery plugin if you want to! Functions and methods can still be called in the jQuery way, as in fullPage.js v2.X. Vanilla JS example with all options A more complex initialization with all options set could look like this: Creating links to sections or slides If you are using fullPage.js with anchor links for the sections (using the anchors option or the attribute data-anchor in each section), then you will be able to use anchor links also to navigate directly to a certain slide inside a section. This would be an example of a link with an anchor: http://alvarotrigo.com/fullPage/#secondPage/2 (which is the URL you will see once you access to that section/slide manually) Notice the last part of the URL ends in #secondPage/2. Having the following initialization: The anchor at the end of the URL #secondPage/2 defines the section and slide of destination respectively. In the previous URL, the section of destination will be the one defined with the anchor secondPage and the slide will be the 2nd slide, as we are using the index 2 for it. (the fist slide of a section has index 0, as technically it is a section). We could have used a custom anchor for the slide instead of its index if we would have used the attribute data-anchor on the HTML markup like so: In this last case, the URL we would use would be #secondPage/slide3, which is the equivalent to our previous #secondPage/2. Note that section anchors can also be defined in the same way, by using the data-anchor attribute, if no anchors array is provided. Be careful! data-anchor tags can not have the same value as any ID element on the site (or NAME element for IE). Creating smaller or bigger sections Demo fullPage.js provides a way to remove the full height restriction from its sections and slides. It is possible to create sections which height is smaller or bigger than the viewport. This is ideal for footers. It is important to realise that it doesn't make sense to have all of your sections using this feature. If there is more than one section in the initial load of the site, fullPage.js won't scroll at all to see the next one as it will be already in the viewport. To create smaller sections just use the class fp-auto-height in the section you want to apply it. It will then take the height defined by your section/slide content. Responsive auto height sections Demo A responsive auto height can be applied by using the class fp-auto-height-responsive. This way sections will be fullscreen until the responsive mode gets fired. Then they'll take the size required by their content, which could be bigger or smaller than the viewport. State classes added by fullpage.js Fullpage.js adds multiple classes in different elements to keep a record of the status of the site: active is added the current visible section and slide. active is added to the current menu element (if using the menu option). A class of the form fp-viewing-SECTION-SLIDE is added to the body element of the site. (eg: fp-viewing-secondPage-0) The SECTION and SLIDE parts will be the anchors (or indexes if no anchor is provided) of the current section and slide. fp-responsive is added to the body element when the entering in the responsive mode fp-enabled is added to the html element when fullpage.js is enabled. (and removed when destroyed). fp-destroyed is added to the fullpage.js container when fullPage.js is destroyed. Lazy Loading Demo fullPage.js provides a way to lazy load images, videos and audio elements so they won't slow down the loading of your site or unnecessarily waste data transfer. When using lazy loading, all these elements will only get loaded when entering in the viewport. To enable lazy loading all you need to do is change your src attribute to data-src as shown below: If you already use another lazy load solution which uses data-src as well, you can disable the fullPage.js lazy loading by setting the option lazyLoading: false. Auto play/pause embedded media Demo Note: the autoplay feature might not work on some mobile devices depending on the OS and browser (i.e. Safari on iOS version < 10.0). Play on section/slide load: Using the attribute autoplay for videos or audio, or the param autoplay=1 for youtube iframes will result in the media element playing on page load. In order to play it on section/slide load use instead the attribute data-autoplay. For example: Pause on leave Embedded HTML5 <video> / <audio> and Youtube iframes are automatically paused when you navigate away from a section or slide. This can be disabled by using the attribute data-keepplaying. For example: Use extensions fullpage.js provides a set of extensions you can use to enhance its default features. All of them are listed as fullpage.js options. Extensions requires you to use the minified file fullpage.extensions.min.js that is inside the dist folder instead of the usual fullPage.js file (fullpage.js or fullpage.min.js). Once you acquire the extension file, you will need to add it before fullPage. For example, if I want to use the Continuous Horizontal extension, I would have include the extension file and then the extensions version of the fullPage file. An activation key and a license key will be required for each extension. See more details about it here. Then you will be able to use and configure them as explained in options. Options licenseKey: (default null). This option is compulsory. If you use fullPage in a non open source project, then you should use the license key provided on the purchase of the fullPage Commercial License. If your project is open source and it is compatible with the GPLv3 license you can request a license key. Please read more about licenses here and on the website. For example: v2compatible: (default false). Determines whether to make it 100% compatible with any code written for version 2, ignoring new features or api changes of version 3. State classes, callbacks signature etc. will work exactly in the same way as it did on verion 2. Note that this option will be removed at some point in the future.. controlArrows: (default true) Determines whether to use control arrows for the slides to move right or left. verticalCentered: (default true) Vertically centering of the content within sections. When set to true, your content will be wrapped by the library. Consider using delegation or load your other scripts in the afterRender callback. scrollingSpeed: (default 700) Speed in milliseconds for the scrolling transitions. sectionsColor: (default none) Define the CSS background-color property for each section. Example: anchors: (default []) Defines the anchor links (#example) to be shown on the URL for each section. Anchors value should be unique. The position of the anchors in the array will define to which sections the anchor is applied. (second position for second section and so on). Using anchors forward and backward navigation will also be possible through the browser. This option also allows users to bookmark a specific section or slide. Be careful! anchors can not have the same value as any ID element on the site (or NAME element for IE). Now anchors can be defined directly in the HTML structure by using the attribute data-anchor as explained here. lockAnchors: (default false) Determines whether anchors in the URL will have any effect at all in the library. You can still using anchors internally for your own functions and callbacks, but they won't have any effect in the scrolling of the site. Useful if you want to combine fullPage.js with other plugins using anchor in the URL. Important It is helpful to understand that the values in the anchors option array correlate directly to the element with the class of .section by it's position in the markup. easing: (default easeInOutCubic) Defines the transition effect to use for the vertical and horizontal scrolling. It requires the file vendors/easings.min.js or jQuery UI for using some of its transitions. Other libraries could be used instead. easingcss3: (default ease) Defines the transition effect to use in case of using css3:true. You can use the pre-defined ones (such as linear, ease-out...) or create your own ones using the cubic-bezier function. You might want to use Matthew Lein CSS Easing Animation Tool for it. loopTop: (default false) Defines whether scrolling up in the first section should scroll to the last one or not. loopBottom: (default false) Defines whether scrolling down in the last section should scroll to the first one or not. loopHorizontal: (default true) Defines whether horizontal sliders will loop after reaching the last or previous slide or not. css3: (default true). Defines whether to use JavaScript or CSS3 transforms to scroll within sections and slides. Useful to speed up the movement in tablet and mobile devices with browsers supporting CSS3. If this option is set to true and the browser doesn't support CSS3, a fallback will be used instead. autoScrolling: (default true) Defines whether to use the ""automatic"" scrolling or the ""normal"" one. It also has affects the way the sections fit in the browser/device window in tablets and mobile phones. fitToSection: (default true) Determines whether or not to fit sections to the viewport or not. When set to true the current active section will always fill the whole viewport. Otherwise the user will be free to stop in the middle of a section. fitToSectionDelay: (default 1000). If fitToSection is set to true, this delays the fitting by the configured milliseconds. scrollBar: (default false) Determines whether to use scroll bar for the vertical sections on site or not. In case of using scroll bar, the autoScrolling functionality will still work as expected. The user will also be free to scroll the site with the scroll bar and fullPage.js will fit the section in the screen when scrolling finishes. paddingTop: (default 0) Defines the top padding for each section with a numerical value and its measure (paddingTop: '10px', paddingTop: '10em'...) Useful in case of using a fixed header. paddingBottom: (default 0) Defines the bottom padding for each section with a numerical value and its measure (paddingBottom: '10px', paddingBottom: '10em'...). Useful in case of using a fixed footer. fixedElements: (default null) Defines which elements will be taken off the scrolling structure of the plugin which is necessary when using the css3 option to keep them fixed. It requires a string with the Javascript selectors for those elements. (For example: fixedElements: '#element1, .element2') normalScrollElements: (default null) Demo If you want to avoid the auto scroll when scrolling over some elements, this is the option you need to use. (useful for maps, scrolling divs etc.) It requires a string with the Javascript selectors for those elements. (For example: normalScrollElements: '#element1, .element2'). This option should not be applied to any section/slide element itself. bigSectionsDestination: (default null) Demo Defines how to scroll to a section which height is bigger than the viewport and when not using scrollOverflow:true. (Read how to create smaller or bigger sections). By default fullPage.js scrolls to the top if you come from a section above the destination one and to the bottom if you come from a section below the destination one. Possible values are top, bottom, null. keyboardScrolling: (default true) Defines if the content can be navigated using the keyboard. touchSensitivity: (default 5) Defines a percentage of the browsers window width/height, and how far a swipe must measure for navigating to the next section / slide continuousVertical: (default false) Defines whether scrolling down in the last section should scroll down to the first one and if scrolling up in the first section should scroll up to the last one. Not compatible with loopTop, loopBottom or any scroll bar present in the site (scrollBar:true or autoScrolling:false). continuousHorizontal: (default false) Extension of fullpage.js. Defines whether sliding right in the last slide should slide right to the first one or not, and if scrolling left in the first slide should slide left to the last one or not. Not compatible with loopHorizontal. Requires fullpage.js >= 3.0.1. scrollHorizontally: (default false) Extension of fullpage.js. Defines whether to slide horizontally within sliders by using the mouse wheel or trackpad. It can only be used when using: autoScrolling:true. Ideal for story telling. Requires fullpage.js >= 3.0.1. interlockedSlides: (default false) Extension of fullpage.js. Determines whether moving one horizontal slider will force the sliding of sliders in other section in the same direction. Possible values are true, false or an array with the interlocked sections. For example [1,3,5] starting by 1. Requires fullpage.js >= 3.0.1. dragAndMove: (default false) Extension of fullpage.js. Enables or disables the dragging and flicking of sections and slides by using mouse or fingers. Requires fullpage.js >= 3.0.1. Possible values are: true: enables the feature. false: disables the feature. vertical: enables the feature only vertically. horizontal: enables the feature only horizontally. fingersonly: enables the feature for touch devices only. mouseonly: enables the feature for desktop devices only (mouse and trackpad). offsetSections: (default false)Extension of fullpage.js. Provides a way to use non full screen sections based on percentage. Ideal to show visitors there's more content in the site by showing part of the next or previous section. Requires fullPage.js >= 3.0.1. To define the percentage of each section the attribute data-percentage must be used. The centering of the section in the viewport can be determined by using a boolean value in the attribute data-centered (default to true if not specified). For example: resetSliders: (default false). Extension of fullpage.js. Defines whether or not to reset every slider after leaving its section. Requires fullpage.js >= 3.0.1. fadingEffect: (default false). Extension of fullpage.js. Defines whether to use a fading effect or not instead of the default scrolling one. Possible values are true, false, sections, slides. It can therefore be applied just vertically or horizontally, or to both at the time. It can only be used when using: autoScrolling:true. Requires fullpage.js >= 3.0.1. animateAnchor: (default true) Defines whether the load of the site when given an anchor (#) will scroll with animation to its destination or will directly load on the given section. recordHistory: (default true) Defines whether to push the state of the site to the browser's history. When set to true each section/slide of the site will act as a new page and the back and forward buttons of the browser will scroll the sections/slides to reach the previous or next state of the site. When set to false, the URL will keep changing but will have no effect on the browser's history. This option is automatically turned off when using autoScrolling:false. menu: (default false) A selector can be used to specify the menu to link with the sections. This way the scrolling of the sections will activate the corresponding element in the menu using the class active. This won't generate a menu but will just add the active class to the element in the given menu with the corresponding anchor links. In order to link the elements of the menu with the sections, an HTML 5 data-tag (data-menuanchor) will be needed to use with the same anchor links as used within the sections. Example: Note: the menu element should be placed outside the fullpage wrapper in order to avoid problem when using css3:true. Otherwise it will be appended to the body by the plugin itself. navigation: (default false) If set to true, it will show a navigation bar made up of small circles. navigationPosition: (default none) It can be set to left or right and defines which position the navigation bar will be shown (if using one). navigationTooltips: (default []) Defines the tooltips to show for the navigation circles in case they are being used. Example: navigationTooltips: ['firstSlide', 'secondSlide']. You can also define them by using the attribute data-tooltip in each section if you prefer. showActiveTooltip: (default false) Shows a persistent tooltip for the actively viewed section in the vertical navigation. slidesNavigation: (default false) If set to true it will show a navigation bar made up of small circles for each landscape slider on the site. slidesNavPosition: (default bottom) Defines the position for the landscape navigation bar for sliders. Admits top and bottom as values. You may want to modify the CSS styles to determine the distance from the top or bottom as well as any other style such as color. scrollOverflow: (default false) defines whether or not to create a scroll for the section/slide in case its content is bigger than the height of it. When set to true, your content will be wrapped by the plugin. Consider using delegation or load your other scripts in the afterRender callback. In case of setting it to true, it requires the vendor library scrolloverflow.min.js. This file has to be loaded before the fullPage.js plugin, but after jQuery ( in case of using it). For example: In order to prevent fullpage.js from creating the scrollbar in certain sections or slides use the class fp-noscroll. For example: <div class=""section fp-noscroll""> You can also prevent scrolloverflow from getting applied on responsive mode when using fp-auto-height-responsive in the section element. scrollOverflowReset: (default false) Extension of fullpage.js. When set to true it scrolls up the content of the section/slide with scroll bar when leaving to another vertical section. This way the section/slide will always show the start of its content even when scrolling from a section under it. scrollOverflowOptions: when using scrollOverflow:true fullpage.js will make use of a forked and modified version of iScroll.js library. You can customize the scrolling behaviour by providing fullpage.js with the iScroll.js options you want to use. Check its documentation for more info. sectionSelector: (default .section) Defines the Javascript selector used for the plugin sections. It might need to be changed sometimes to avoid problem with other plugins using the same selectors as fullpage.js. slideSelector: (default .slide) Defines the Javascript selector used for the plugin slides. It might need to be changed sometimes to avoid problem with other plugins using the same selectors as fullpage.js. responsiveWidth: (default 0) A normal scroll (autoScrolling:false) will be used under the defined width in pixels. A class fp-responsive is added to the body tag in case the user wants to use it for their own responsive CSS. For example, if set to 900, whenever the browser's width is less than 900 the plugin will scroll like a normal site. responsiveHeight: (default 0) A normal scroll (autoScrolling:false) will be used under the defined height in pixels. A class fp-responsive is added to the body tag in case the user wants to use it for their own responsive CSS. For example, if set to 900, whenever the browser's height is less than 900 the plugin will scroll like a normal site. responsiveSlides: (default false) Extension of fullpage.js. When set to true slides will be turned into vertical sections when responsive mode is fired. (by using the responsiveWidth or responsiveHeight options detailed above). Requires fullpage.js >= 3.0.1. parallax: (default false) Extension of fullpage.js. Defines whether or not to use the parallax backgrounds effects on sections / slides. Read more about how to apply the parallax option. parallaxOptions: (default: { type: 'reveal', percentage: 62, property: 'translate'}). Allows to configure the parameters for the parallax backgrounds effect when using the option parallax:true. Read more about how to apply the parallax option. dropEffect (default false) Extension of fullpage.js. Defines whether or not to use the drop effect on sections / slides. Read more about how to apply the the drop effect option. dropEffectOptions: (default: { speed: 2300, color: '#F82F4D', zIndex: 9999}). Allows to configure the parameters for the drop effect when using the option dropEffect:true.Read more about how to apply the the drop effect option. cards: (default false) Extension of fullpage.js. Defines whether or not to use the cards effect on sections/slides. Read more about how to apply the cards option. cardsOptions: (default: { perspective: 100, fadeContent: true, fadeBackground: true}). Allows you to configure the parameters for the cards effect when using the option cards:true. Read more about how to apply the cards option. lazyLoading: (default true) Lazy loading is active by default which means it will lazy load any media element containing the attribute data-src as detailed in the Lazy Loading docs . If you want to use any other lazy loading library you can disable this fullpage.js feature. Methods You can see them in action here getActiveSection() Demo Gets an Object (type Section) containing the active section and its properties. getActiveSlide() Demo Gets an Object (type Slide) containing the active slide and its properties. moveSectionUp() Demo Scrolls one section up: moveSectionDown() Demo Scrolls one section down: moveTo(section, slide) Demo Scrolls the page to the given section and slide. The first section will have the index 1 whilst the first slide, the visible one by default, will have index 0. silentMoveTo(section, slide) Demo Exactly the same as moveTo but in this case it performs the scroll without animation. A direct jump to the destination. moveSlideRight() Demo Scrolls the horizontal slider of the current section to the next slide: moveSlideLeft() Demo Scrolls the horizontal slider of the current section to the previous slide: setAutoScrolling(boolean) Demo Sets the scrolling configuration in real time. Defines the way the page scrolling behaves. If it is set to true, it will use the ""automatic"" scrolling, otherwise, it will use the ""manual"" or ""normal"" scrolling of the site. setFitToSection(boolean) Demo Sets the value for the option fitToSection determining whether to fit the section in the screen or not. fitToSection() Demo Scrolls to the nearest active section fitting it in the viewport. setLockAnchors(boolean) Demo Sets the value for the option lockAnchors determining whether anchors will have any effect in the URL or not. setAllowScrolling(boolean, [directions]) Demo Adds or remove the possibility of scrolling through sections/slides by using the mouse wheel/trackpad or touch gestures (which is active by default). Note this won't disable the keyboard scrolling. You would need to use setKeyboardScrolling for it. directions: (optional parameter) Admitted values: all, up, down, left, right or a combination of them separated by commas like down, right. It defines the direction for which the scrolling will be enabled or disabled. setKeyboardScrolling(boolean, [directions]) Demo Adds or remove the possibility of scrolling through sections by using the keyboard (which is active by default). directions: (optional parameter) Admitted values: all, up, down, left, right or a combination of them separated by commas like down, right. It defines the direction for which the scrolling will be enabled or disabled. setRecordHistory(boolean) Demo Defines whether to record the history for each hash change in the URL. setScrollingSpeed(milliseconds) Demo Defines the scrolling speed in milliseconds. destroy(type) Demo Destroys the plugin events and optionally its HTML markup and styles. Ideal to use when using AJAX to load content. type: (optional parameter) can be empty or all. If all is passed, the HTML markup and styles used by fullpage.js will be removed. This way the original HTML markup, the one used before any plugin modification is made, will be maintained. reBuild() Updates the DOM structure to fit the new window size or its contents. Ideal to use in combination with AJAX calls or external changes in the DOM structure of the site, specially when using scrollOverflow:true. setResponsive(boolean) Demo Sets the responsive mode of the page. When set to true the autoScrolling will be turned off and the result will be exactly the same one as when the responsiveWidth or responsiveHeight options get fired. responsiveSlides.toSections() Extension of fullpage.js. Requires fullpage.js >= 3.0.1. Turns horizontal slides into vertical sections. responsiveSlides.toSlides() Extension of fullpage.js. Requires fullpage.js >= 3.0.1. Turns back the original slides (now converted into vertical sections) into horizontal slides again. Callbacks Demo You can see them in action here. Some callbacks, such as onLeave will contain Object type of parameters containing the following properties: anchor: (String) item's anchor. index: (Number) item's index. item: (DOM element) item element. isFirst: (Boolean) determines if the item is the first child. isLast: (Boolean) determines if the item is the last child. afterLoad (origin, destination, direction) Callback fired once the sections have been loaded, after the scrolling has ended. Parameters: origin: (Object) section of origin. destination: (Object) destination section. direction: (String) it will take the values up or down depending on the scrolling direction. Example: onLeave (origin, destination, direction) This callback is fired once the user leaves a section, in the transition to the new section. Returning false will cancel the move before it takes place. Parameters: origin: (Object) section of origin. destination: (Object) destination section. direction: (String) it will take the values up or down depending on the scrolling direction. Example: Cancelling the scroll before it takes place You can cancel the scroll by returning false on the onLeave callback: afterRender() This callback is fired just after the structure of the page is generated. This is the callback you want to use to initialize other plugins or fire any code which requires the document to be ready (as this plugin modifies the DOM to create the resulting structure). See FAQs for more info. Example: afterResize(width, height) This callback is fired after resizing the browser's window. Just after the sections are resized. Parameters: width: (Number) window's width. height: (Number) window's height. Example: afterReBuild() This callback is fired after manually re-building fullpage.js by calling fullpage_api.reBuild(). Example: afterResponsive(isResponsive) This callback is fired after fullpage.js changes from normal to responsive mode or from responsive mode to normal mode. Parameters: isResponsive: (Boolean) determines if it enters into responsive mode (true) or goes back to normal mode (false). Example: afterSlideLoad (section, origin, destination, direction) Callback fired once the slide of a section have been loaded, after the scrolling has ended. Parameters: section: (Object) active vertical section. origin: (Object) horizontal slide of origin. destination: (Object) destination horizontal slide. direction: (String) right or left depending on the scrolling direction. Example: onSlideLeave (section, origin, destination, direction) This callback is fired once the user leaves an slide to go to another, in the transition to the new slide. Returning false will cancel the move before it takes place. Parameters: section: (Object) active vertical section. origin: (Object) horizontal slide of origin. destination: (Object) destination horizontal slide. direction: (String) right or left depending on the scrolling direction. Example: Cancelling a move before it takes place You can cancel a move by returning false on the onSlideLeave callback. Same as when canceling a movement with onLeave. Reporting issues Please, look for your issue before asking using the github issues search. Make sure you use the latest fullpage.js version. No support is provided for older versions. Use the the Github Issues forum to create issues. An isolated reproduction of the issue will be required. Make use of jsfiddle or codepen for it if possible. Contributing to fullpage.js Please see Contributing to fullpage.js Changelog To see the list of recent changes, see Releases section. Build tasks Want to build fullpage.js distribution files? Please see Build Tasks Resources Wordpress Plugin for Gutenberg and for Elementor. Wordpress theme Official Vue.js wrapper component Official React.js wrapper component Official Angular wrapper component CSS Easing Animation Tool - Matthew Lein (useful to define the easingcss3 value) fullPage.js jsDelivr CDN fullPage.js plugin for October CMS fullPage.js Angular2 directive fullPage.js angular directive fullPage.js ember-cli addon fullPage.js Rails Ruby Gem Angular fullPage.js - Adaptation for Angular.js v1.x Integrating fullPage.js with Wordpress (Tutorial) Wordpress Plugin for Divi Wordpress Plugin for Elementor Who is using fullPage.js If you want your page to be listed here, please contact me with the URL. https://www.coca-colacompany.com/annual-review/2017/index.html http://www.bbc.co.uk/news/resources/idt-d88680d1-26f2-4863-be95-83298fd01e02 http://www.newjumoconcept.com/ http://www.shootinggalleryasia.com/ http://medoff.ua/en/ http://promo.prestigio.com/grace1/ http://torchbrowser.com/ http://thekorner.fr/ http://charlotteaimes.com/ http://www.boxreload.com/ http://educationaboveall.org/ http://usescribe.com/ http://boxx.hk/ http://www.sanyang.com.tw/service/Conception/ http://trasmissione-energia.terna.it/ http://www.villareginateodolinda.it http://www.kesstrio.com http://ded-morozz.kiev.ua/ http://dancingroad.com http://www.camanihome.com/ You can find another list here. Donations Donations would be more than welcome :) Sponsors Become a sponsor and get your logo on our README on Github with a link to your site. [Become a sponsor] | [Become a patreon] People "
2651,Simpsons characters in CSSSimpsons in CSS Simpsons characters in pure CSS View the project page Disclaimer All images are copyright to their respective owners.
765,"Normalizes nested JSON according to a schemanormalizr Install Install from the NPM repository using yarn or npm: Motivation Many APIs, public or not, return JSON data that has deeply nested objects. Using data in this kind of structure is often very difficult for JavaScript applications, especially those using Flux or Redux. Solution Normalizr is a small, but powerful utility for taking JSON with a schema definition and returning nested entities with their IDs, gathered in dictionaries. Documentation Introduction Build Files Quick Start API normalize denormalize schema Using with JSONAPI Examples Normalizing GitHub Issues Relational Data Interactive Redux Quick Start Consider a typical blog post. The API response for a single post might look something like this: We have two nested entity types within our article: users and comments. Using various schema, we can normalize all three entity types down: Now, normalizedData will be: Dependencies None. Credits Normalizr was originally created by Dan Abramov and inspired by a conversation with Jing Chen. Since v3, it was completely rewritten and maintained by Paul Armstrong. It has also received much help, enthusiasm, and contributions from community members."
1538,"The world's #1 JavaScript library for rich text editing. Available for React, Vue and AngularTinyMCE TinyMCE is the world's most advanced open source core rich text editor. Trusted by millions of developers, and used by some of the world's largest companies and fastest-growing start-ups, TinyMCE is the WYSIWYG editor that is built to scale, designed to innovate, and is built to thrive with edge-cases. You can access a full featured demo of TinyMCE in the docs on the Tiny website. Get started with TinyMCE TinyMCE Cloud Deployment Quick Start Guide TinyMCE Self-hosted Deployment Guide TinyMCE provides a range of configuration options that allow you to integrate it into your application. Start customizing with a basic setup. Configure it for one of three modes of editing: TinyMCE classic editing mode. TinyMCE inline editing mode. TinyMCE distraction-free editing mode. Features Integration TinyMCE is easily integrated into your projects with the help of components such as: tinymce-react tinymce-vue tinymce-angular See the Tiny docs for a full list of integration components. Customization It is easy to configure the UI to match the design of your site, product or application. Due to its flexibility, you can configure the editor with as much or as little functionality as you like, depending on your requirements. With 50+ powerful plugins available, adding additional functionality is as simple as including a single line of code. Realizing the full power of most plugins requires only a few lines more. Extensibility Sometimes your business requirements can be quite unique, and you need the freedom and flexibility to innovate. View the source code and develop your own extensions for custom functionality to meet your own requirements. The API is exposed to make it easier for you to write custom functionality that fits within the existing framework of TinyMCE UI components. Extended Features and Support For the professional software teams that require more in-depth efficiency, compliance or collaborative features built to enterprise-grade standards, please get in touch with our team. Tiny also offers dedicated SLAs and support for professional development teams. Compiling and contributing In 2019 the decision was made to transition our codebase to a monorepo. For information on compiling and contributing, see: contribution guidelines. As an open source product, we encourage and support the active development of our software. Want more information? Visit the TinyMCE website and check out the TinyMCE documentation."
926,"music library manager and MusicBrainz tagger.. image:: https://img.shields.io/pypi/v/beets.svg :target: https://pypi.python.org/pypi/beets .. image:: https://img.shields.io/codecov/c/github/beetbox/beets.svg :target: https://codecov.io/github/beetbox/beets .. image:: https://github.com/beetbox/beets/workflows/ci/badge.svg?branch=master :target: https://github.com/beetbox/beets/actions .. image:: https://repology.org/badge/tiny-repos/beets.svg :target: https://repology.org/project/beets/versions beets Beets is the media library management system for obsessive music geeks. The purpose of beets is to get your music collection right once and for all. It catalogs your collection, automatically improving its metadata as it goes. It then provides a bouquet of tools for manipulating and accessing your music. Here's an example of beets' brainy tag corrector doing its thing:: $ beet import ~/music/ladytron Tagging: Ladytron - Witching Hour (Similarity: 98.4%) * Last One Standing -> The Last One Standing * Beauty -> Beauty*2 * White Light Generation -> Whitelightgenerator * All the Way -> All the Way... Because beets is designed as a library, it can do almost anything you can imagine for your music collection. Via plugins_, beets becomes a panacea: Fetch or calculate all the metadata you could possibly need: album art, lyrics, genres, tempos, ReplayGain levels, or acoustic fingerprints. Get metadata from MusicBrainz, Discogs, and Beatport_. Or guess metadata using songs' filenames or their acoustic fingerprints. Transcode audio_ to any format you like. Check your library for duplicate tracks and albums or for albums that are missing tracks. Clean up crufty tags left behind by other, less-awesome tools. Embed and extract album art from files' metadata. Browse your music library graphically through a Web browser and play it in any browser that supports HTML5 Audio_. Analyze music files' metadata from the command line. Listen to your library with a music player that speaks the MPD_ protocol and works with a staggering variety of interfaces. If beets doesn't do what you want yet, writing your own plugin_ is shockingly simple if you know a little Python. .. _plugins: https://beets.readthedocs.org/page/plugins/ .. _MPD: https://www.musicpd.org/ .. _MusicBrainz music collection: https://musicbrainz.org/doc/Collections/ .. _writing your own plugin: https://beets.readthedocs.org/page/dev/plugins.html .. _HTML5 Audio: http://www.w3.org/TR/html-markup/audio.html .. _albums that are missing tracks: https://beets.readthedocs.org/page/plugins/missing.html .. _duplicate tracks and albums: https://beets.readthedocs.org/page/plugins/duplicates.html .. _Transcode audio: https://beets.readthedocs.org/page/plugins/convert.html .. _Discogs: https://www.discogs.com/ .. _acoustic fingerprints: https://beets.readthedocs.org/page/plugins/chroma.html .. _ReplayGain: https://beets.readthedocs.org/page/plugins/replaygain.html .. _tempos: https://beets.readthedocs.org/page/plugins/acousticbrainz.html .. _genres: https://beets.readthedocs.org/page/plugins/lastgenre.html .. _album art: https://beets.readthedocs.org/page/plugins/fetchart.html .. _lyrics: https://beets.readthedocs.org/page/plugins/lyrics.html .. _MusicBrainz: https://musicbrainz.org/ .. _Beatport: https://www.beatport.com Install You can install beets by typing pip install beets. Beets has also been packaged in the software repositories of several distributions. Check out the Getting Started guide for more information. .. _Getting Started: https://beets.readthedocs.org/page/guides/main.html .. _software repositories: https://repology.org/project/beets/versions Contribute Thank you for considering contributing to beets! Whether you're a programmer or not, you should be able to find all the info you need at CONTRIBUTING.rst_. .. _CONTRIBUTING.rst: https://github.com/beetbox/beets/blob/master/CONTRIBUTING.rst Read More Learn more about beets at its Web site. Follow @b33ts on Twitter for news and updates. .. its Web site: https://beets.io/ .. @b33ts: https://twitter.com/b33ts/ Contact Encountered a bug you'd like to report? Check out our issue tracker_! If your issue hasn't already been reported, please open a new ticket_ and we'll be in touch with you shortly. If you'd like to vote on a feature/bug, simply give a :+1: on issues you'd like to see prioritized over others. Need help/support, would like to start a discussion, have an idea for a new feature, or would just like to introduce yourself to the team? Check out GitHub Discussions or Discourse! .. _GitHub Discussions: https://github.com/beetbox/beets/discussions .. _issue tracker: https://github.com/beetbox/beets/issues .. _open a new ticket: https://github.com/beetbox/beets/issues/new/choose .. _Discourse: https://discourse.beets.io/ Authors Beets is by Adrian Sampson_ with a supporting cast of thousands. .. _Adrian Sampson: https://www.cs.cornell.edu/~asampson/"
144,"Powerful and flexible library for loading, caching and displaying images on Android.Universal Image Loader The great ancestor of modern image-loading libraries :) UIL aims to provide a powerful, flexible and highly customizable instrument for image loading, caching and displaying. It provides a lot of configuration options and good control over the image loading and caching process. Project News Really have no time for development... so I stop project maintaining since Nov 27 :( UIL [27.11.2011 - 27.11.2015] Thanks to all developers for your support :) Features Multi-thread image loading (async or sync) Wide customization of ImageLoader's configuration (thread executors, downloader, decoder, memory and disk cache, display image options, etc.) Many customization options for every display image call (stub images, caching switch, decoding options, Bitmap processing and displaying, etc.) Image caching in memory and/or on disk (device's file system or SD card) Listening loading process (including downloading progress) Android 4.1+ support Downloads universal-image-loader-1.9.5.jar Documentation Quick Setup Configuration Display Options Useful Info - Read it before asking a question User Support - Read it before creating new issue Sample project - Learn it to understand the right way of library usage ChangeLog - Info about API changes is here Usage Dependency Acceptable URIs examples NOTE: Use drawable:// only if you really need it! Always consider the native way to load drawables - ImageView.setImageResource(...) instead of using of ImageLoader. Simple Complete Load & Display Task Flow Applications using Universal Image Loader MediaHouse, UPnP/DLNA Browser | Prezzi Benzina (AndroidFuel) | ROM Toolbox Lite, Pro | Stadium Astro | Chef Astro | Sporee - Live Soccer Scores | EyeEm - Photo Filter Camera | Topface - meeting is easy | reddit is fun | Diaro - personal diary | Meetup | Vingle - Magazines by Fans | Anime Music Radio | WidgetLocker Theme Viewer | ShortBlogger for Tumblr | SnapDish Food Camera | Twitch | TVShow Time, TV show guide | Planning Center Services | Lapse It | My Cloud Player for SoundCloud | SoundTracking | LoopLR Social Video | Hr24 | Immobilien Scout24 | Lieferheld - Pizza Pasta Sushi | Loocator: free sex datings | - ,,,,, | Streambels AirPlay/DLNA Player | Ship Mate - All Cruise Lines | Disk & Storage Analyzer | | Balance BY | Anti Theft Alarm - Security | XiiaLive - Internet Radio | Bandsintown Concerts | Save As Web Archive | MCPE STORE -Download MCPE file | All-In-One Toolbox (29 Tools) | Zaim | Calculator Plus Free | Truedialer by Truecaller | DoggCatcher Podcast Player | PingTools Network Utilities | The Traveler | minube: travel photo album | Wear Store for Wear Apps | Cast Store for Chromecast Apps | WebMoney Keeper Donation You can support the project and thank the author for his hard work :) PayPal - nostra.uil[at]gmail[dot]com Alternative libraries Fresco Glide Picasso Volley : ImageLoader License Copyright 2011-2015 Sergey Tarasevich Licensed under the Apache License, Version 2.0 (the ""License""); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
3822,"A PaaS built on top of Amazon EC2 Container Service (ECS)Empire Empire is a control layer on top of Amazon EC2 Container Service (ECS) that provides a Heroku like workflow. It conforms to a subset of the Heroku Platform API, which means you can use the same tools and processes that you use with Heroku, but with all the power of EC2 and Docker. Empire is targeted at small to medium sized startups that are running a large number of microservices and need more flexibility than what Heroku provides. You can read the original blog post about why we built empire on the Remind engineering blog. Quickstart To use Empire, you'll need to have an ECS cluster running. See the quickstart guide for more information. Architecture Empire aims to make it trivially easy to deploy a container based microservices architecture, without all of the complexities of managing systems like Mesos or Kubernetes. ECS takes care of much of that work, but Empire attempts to enhance the interface to ECS for deploying and maintaining applications, allowing you to deploy Docker images as easily as: Heroku API compatibility Empire supports a subset of the Heroku Platform API, which means any tool that uses the Heroku API can probably be used with Empire, if the endpoint is supported. As an example, you can use the hk CLI with Empire like this: However, the best user experience will be by using the emp command, which is a fork of hk with Empire specific features. Routing Empire's routing layer is backed by internal ELBs. Any application that specifies a web process will get an internal ELB attached to its associated ECS Service. When a new version of the app is deployed, ECS manages spinning up the new versions of the process, waiting for old connections to drain, then killing the old release. When a new internal ELB is created, an associated CNAME record will be created in Route53 under the internal TLD, which means you can use DNS for service discovery. If we deploy an app named feed then it will be available at http://feed within the ECS cluster. Apps default to only being exposed internally, unless you add a custom domain to them. Adding a custom domain will create a new external ELB for the ECS service. Deploying Any tagged Docker image can be deployed to Empire as an app. Empire doesn't enforce how you tag your Docker images, but we recommend tagging the image with the git sha that it was built from (any any immutable identifier), and deploying that. When you deploy a Docker image to Empire, it will extract a Procfile from the WORKDIR. Like Heroku, you can specify different process types that compose your service (e.g. web and worker), and scale them individually. Each process type in the Procfile maps directly to an ECS Service. Contributing Pull requests are more than welcome! For help with setting up a development environment, see CONTRIBUTING.md Community We have a google group, empire-dev, where you can ask questions and engage with the Empire community. You can also join our Slack team for discussions and support. Auth Flow The current authentication model used by emp login relies on a deprecated GitHub endpoint that is scheduled to be deactivated in November 2020. Therefore both the client and the server need to be updated to support the web authentication flow The web flow works like this The user runs a command like emp web-login The client starts up a HTTP listener on a free local port The client opens a browser window on the local machine to $EMPIRE_API_URL/oauth/start?port=????? The port parameter specifies where the client is listening The browser executes a GET against the URL The Empire server sees the request and constructs an OAuth request URL that will hit the GitHub OAuth endpoint and returns it as a redirect The browser makes the request to the GitHub auth endpoint, which shows the UI a request to authorize the application If they've previously authorized it will just immediately grant the request GitHub redirects the browser back to the redirect URL specified in the configuration, meaning back to the Empire server The Empire server receives the browser request and can now perform the code exchange to turn the provided code into an actual authentication token This is just like it would have received from the old endpoint. However, it's not usable yet because it still isn't in the possession of the client, only the browser The Empire server now redirects the browser back to localhost on the original port provided by the client The client receives the token, but can't use it directly. The Empire server expects it to be wrapped in a JSON Web Token that only the server can create. The client can now make a request directly to the Empire server (its first in this sequence) providing the token and requesting a JSON Web Token in response The client stores the received token just as it would have with the response to an emp login command The client is authenticated In theory the Empire server could construct the JWT directly after the code exchange and push that directly to the client, but the abstraction doesn't really seem to easily support that flow"
3648,"UI form validation library for AndroidAndroid Saripaar v2 - sari-paar (Tamil for ""to check"", ""verify"" or ""validate"") Android Saripaar is a simple, feature-rich and powerful rule-based UI form validation library for Android. It is the SIMPLEST UI validation library available for Android. Why Android Saripaar? Built on top of Apache Commons Validator, a validation framework with proven track record on the web, desktop and mobile platforms. Declarative style validation using Annotations. Extensible, now allows Custom Annotations. Synchronous and Asynchronous validations, you don't have to worry about threading. Supports both BURST and IMMEDIATE modes. Works with Stock Android Widgets, no custom view dependencies. Isolates validation logic using rules. Compatible with other annotation-based libraries and frameworks such as ButterKnife, AndroidAnnotations, RoboGuice, etc., Quick Start Step 1 - Annotate your widgets using Saripaar Annotations The annotations are self-explanatory. The @Order annotation is required ONLY when performing ordered validations using Validator.validateTill(View) and Validator.validateBefore(View) or in IMMEDIATE mode. Step 2 - Instantiate a new Validator You will need a Validator and a ValidationListener for receiving callbacks on validation events. Step 3 - Implement a ValidationListener onValidationSucceeded() - Called when all your views pass all validations. onValidationFailed(List<ValidationError> errors) - Called when there are validation error(s). Step 4 - Validate The Validator.validate() call runs the validations and returns the result via appropriate callbacks on the ValidationListener. You can run validations on a background AsyncTask by calling the Validator.validate(true) method. Saripaar X If you are looking for country-specific annotations, checkout the Saripaar X project. The extensions project is in its early stages and needs contributors. Feel free to contribute. Maven <dependency> <groupId>com.mobsandgeeks</groupId> <artifactId>android-saripaar</artifactId> <version>(latest version)</version> </dependency> Gradle dependencies { compile 'com.mobsandgeeks:android-saripaar:(latest version)' } Snapshots In your {project_base}/build.gradle file, include the following. allprojects { repositories { jcenter() maven { url ""https://oss.sonatype.org/content/repositories/snapshots/"" } } } ProGuard Exclude Saripaar classes from obfuscation and minification. Add the following rules to your proguard-rules.pro file. -keep class com.mobsandgeeks.saripaar.** {*;} -keep @com.mobsandgeeks.saripaar.annotation.ValidateUsing class * {*;} Evolution For those interested in finding out how v2 evolved from v1, watch this (~20 second) video. Using Saripaar? Tweet me with your Google Play URL and I'll add your app to the list :) Icon | App | Icon | App | Icon | App ------------ | ------------- | ------------ | ------------- | ------------ | ------------- | Wikipedia | | Wikipedia Beta | | Mizuno Baton | Fetch | | HealtheMinder | | MomMe | Feelknit | | StreetBarz | | Roast Me | Pipe | | Snagajob | | Tatva Moksh Lakshya Wiki Please visit the wiki for a complete guide on Android Saripaar. License Copyright 2012 - 2015 Mobs & Geeks Licensed under the Apache License, Version 2.0 (the ""License""); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License. Saripaar Logo 2013 - 2015, Mobs & Geeks."
4648,"JSONESJsonFormat-Xcode JSON>Weibo-EnjoySR JSONkeyvalueNullNSString RootClassRootClass MJExtension objectClassInArray() Xcode 8http://www.cocoachina.com/ios/20161207/18313.html 1-Xcode-Command+B-Xcode 2Alcatraz ESJsonFormat 3-pluginzip~/Library/Application Support/Developer/Shared/Xcode/Plug-ins-Xcode Window-ESJsonFormat-Json-Enter OR (Control+Shift+J)-JSON-Enter Xcode-Window-ESJsonFormat-Setting 1) MJExtension objectClassInArray() 2)(Xcode 7 ) 3)( RootClass) 4)keyid() JSON Accelerator @synthesize-> MJExtension -0.1 JSON .m -0.2 Swift JSONvalueNull BOOL -0.3 MJExtensionobjectClassInArray Bug -0.4 (Xcode 7) -0.5 Xcode 9 Alcatraz Alcatraz ESJsonFormat JSON ~~~ { ""name"": """", ""gender"": ""man"", ""age"": 15, ""height"": ""140cm"" } ~~~ ~~~ { ""name"": """", ""gender"": ""man"", ""age"": 15, ""height"": ""140cm"", ""addr"": { ""province"": ""fujian"", ""city"": ""quanzhou"", ""code"": ""300000"" }, ""hobby"": [ { ""name"": ""billiards"", ""code"": ""1"" }, { ""name"": ""computerGame"", ""code"": ""2"" } ] } ~~~ Issues Issues Issues ThanksGsonFormatVVDocumenter-XcodeMJExtension"
33,"A curated list of awesome Python frameworks, libraries, software and resourcesAwesome Python A curated list of awesome Python frameworks, libraries, software and resources. Inspired by awesome-php. Awesome Python Admin Panels Algorithms and Design Patterns ASGI Servers Asynchronous Programming Audio Authentication Build Tools Built-in Classes Enhancement Caching ChatOps Tools CMS Code Analysis Command-line Interface Development Command-line Tools Compatibility Computer Vision Concurrency and Parallelism Configuration Cryptography Data Analysis Data Validation Data Visualization Database Drivers Database Date and Time Debugging Tools Deep Learning DevOps Tools Distributed Computing Distribution Documentation Downloader E-commerce Editor Plugins and IDEs Email Enterprise Application Integrations Environment Management Files Foreign Function Interface Forms Functional Programming Game Development Geolocation GUI Development Hardware HTML Manipulation HTTP Clients Image Processing Implementations Interactive Interpreter Internationalization Job Scheduler Logging Machine Learning Miscellaneous Natural Language Processing Network Virtualization News Feed ORM Package Management Package Repositories Penetration testing Permissions Processes Recommender Systems Refactoring RESTful API Robotics RPC Servers Science Search Serialization Serverless Frameworks Shell Specific Formats Processing Static Site Generator Tagging Task Queues Template Engine Testing Text Processing Third-party APIs URL Manipulation Video Web Asset Management Web Content Extracting Web Crawling Web Frameworks WebSocket WSGI Servers Resources Books Newsletters Podcasts Websites Contributing Admin Panels Libraries for administrative interfaces. ajenti - The admin panel your servers deserve. django-grappelli - A jazzy skin for the Django Admin-Interface. django-jet - Modern responsive template for the Django admin interface with improved functionality. django-suit - Alternative Django Admin-Interface (free only for Non-commercial use). django-xadmin - Drop-in replacement of Django admin comes with lots of goodies. flask-admin - Simple and extensible administrative interface framework for Flask. flower - Real-time monitor and web admin for Celery. jet-bridge - Admin panel framework for any application with nice UI (ex Jet Django) wooey - A Django app which creates automatic web UIs for Python scripts. Algorithms and Design Patterns Python implementation of data structures, algorithms and design patterns. Also see awesome-algorithms. Algorithms algorithms - Minimal examples of data structures and algorithms. python-ds - A collection of data structure and algorithms for coding interviews. sortedcontainers - Fast and pure-Python implementation of sorted collections. TheAlgorithms - All Algorithms implemented in Python. Design Patterns PyPattyrn - A simple yet effective library for implementing common design patterns. python-patterns - A collection of design patterns in Python. transitions - A lightweight, object-oriented finite state machine implementation. ASGI Servers ASGI-compatible web servers. daphne - A HTTP, HTTP2 and WebSocket protocol server for ASGI and ASGI-HTTP. uvicorn - A lightning-fast ASGI server implementation, using uvloop and httptools. Asynchronous Programming asyncio - (Python standard library) Asynchronous I/O, event loop, coroutines and tasks. awesome-asyncio trio - A friendly library for async concurrency and I/O. Twisted - An event-driven networking engine. uvloop - Ultra fast asyncio event loop. Audio Libraries for manipulating audio and its metadata. Audio audioread - Cross-library (GStreamer + Core Audio + MAD + FFmpeg) audio decoding. dejavu - Audio fingerprinting and recognition. kapre - Keras Audio Preprocessors librosa - Python library for audio and music analysis matchering - A library for automated reference audio mastering. mingus - An advanced music theory and notation package with MIDI file and playback support. pyAudioAnalysis - Audio feature extraction, classification, segmentation and applications. pydub - Manipulate audio with a simple and easy high level interface. TimeSide - Open web audio processing framework. Metadata beets - A music library manager and MusicBrainz tagger. eyeD3 - A tool for working with audio files, specifically MP3 files containing ID3 metadata. mutagen - A Python module to handle audio metadata. tinytag - A library for reading music meta data of MP3, OGG, FLAC and Wave files. Authentication Libraries for implementing authentications schemes. OAuth authlib - JavaScript Object Signing and Encryption draft implementation. django-allauth - Authentication app for Django that ""just works."" django-oauth-toolkit - OAuth 2 goodies for Django. oauthlib - A generic and thorough implementation of the OAuth request-signing logic. python-oauth2 - A fully tested, abstract interface to creating OAuth clients and servers. python-social-auth - An easy-to-setup social authentication mechanism. JWT pyjwt - JSON Web Token implementation in Python. python-jose - A JOSE implementation in Python. python-jwt - A module for generating and verifying JSON Web Tokens. Build Tools Compile software from source code. BitBake - A make-like build tool for embedded Linux. buildout - A build system for creating, assembling and deploying applications from multiple parts. PlatformIO - A console tool to build code with different development platforms. pybuilder - A continuous build tool written in pure Python. SCons - A software construction tool. Built-in Classes Enhancement Libraries for enhancing Python built-in classes. attrs - Replacement for __init__, __eq__, __repr__, etc. boilerplate in class definitions. bidict - Efficient, Pythonic bidirectional map data structures and related functionality.. Box - Python dictionaries with advanced dot notation access. dataclasses - (Python standard library) Data classes. DottedDict - A library that provides a method of accessing lists and dicts with a dotted path notation. CMS Content Management Systems. django-cms - An Open source enterprise CMS based on the Django. feincms - One of the most advanced Content Management Systems built on Django. indico - A feature-rich event management system, made @ CERN. Kotti - A high-level, Pythonic web application framework built on Pyramid. mezzanine - A powerful, consistent, and flexible content management platform. plone - A CMS built on top of the open source application server Zope. quokka - Flexible, extensible, small CMS powered by Flask and MongoDB. wagtail - A Django content management system. Caching Libraries for caching data. beaker - A WSGI middleware for sessions and caching. django-cache-machine - Automatic caching and invalidation for Django models. django-cacheops - A slick ORM cache with automatic granular event-driven invalidation. dogpile.cache - dogpile.cache is next generation replacement for Beaker made by same authors. HermesCache - Python caching library with tag-based invalidation and dogpile effect prevention. pylibmc - A Python wrapper around the libmemcached interface. python-diskcache - SQLite and file backed cache backend with faster lookups than memcached and redis. ChatOps Tools Libraries for chatbot development. errbot - The easiest and most popular chatbot to implement ChatOps. Code Analysis Tools of static analysis, linters and code quality checkers. Also see awesome-static-analysis. Code Analysis coala - Language independent and easily extendable code analysis application. code2flow - Turn your Python and JavaScript code into DOT flowcharts. prospector - A tool to analyse Python code. pycallgraph - A library that visualises the flow (call graph) of your Python application. vulture - A tool for finding and analysing dead Python code. Code Linters flake8 - A wrapper around pycodestyle, pyflakes and McCabe. awesome-flake8-extensions pylama - A code audit tool for Python and JavaScript. pylint - A fully customizable source code analyzer. wemake-python-styleguide - The strictest and most opinionated python linter ever. Code Formatters black - The uncompromising Python code formatter. isort - A Python utility / library to sort imports. yapf - Yet another Python code formatter from Google. Static Type Checkers, also see awesome-python-typing mypy - Check variable types during compile time. pyre-check - Performant type checking. typeshed - Collection of library stubs for Python, with static types. Static Type Annotations Generators MonkeyType - A system for Python that generates static type annotations by collecting runtime types. pyannotate - Auto-generate PEP-484 annotations. pytype - Pytype checks and infers types for Python code - without requiring type annotations. Command-line Interface Development Libraries for building command-line applications. Command-line Application Development cement - CLI Application Framework for Python. click - A package for creating beautiful command line interfaces in a composable way. cliff - A framework for creating command-line programs with multi-level commands. docopt - Pythonic command line arguments parser. python-fire - A library for creating command line interfaces from absolutely any Python object. python-prompt-toolkit - A library for building powerful interactive command lines. Terminal Rendering alive-progress - A new kind of Progress Bar, with real-time throughput, eta and very cool animations. asciimatics - A package to create full-screen text UIs (from interactive forms to ASCII animations). bashplotlib - Making basic plots in the terminal. colorama - Cross-platform colored terminal text. rich - Python library for rich text and beautiful formatting in the terminal. Also provides a great RichHandler log handler. tqdm - Fast, extensible progress bar for loops and CLI. Command-line Tools Useful CLI-based tools for productivity. Productivity Tools copier - A library and command-line utility for rendering projects templates. cookiecutter - A command-line utility that creates projects from cookiecutters (project templates). doitlive - A tool for live presentations in the terminal. howdoi - Instant coding answers via the command line. Invoke - A tool for managing shell-oriented subprocesses and organizing executable Python code into CLI-invokable tasks. PathPicker - Select files out of bash output. percol - Adds flavor of interactive selection to the traditional pipe concept on UNIX. thefuck - Correcting your previous console command. tmuxp - A tmux session manager. try - A dead simple CLI to try out python packages - it's never been easier. CLI Enhancements httpie - A command line HTTP client, a user-friendly cURL replacement. iredis - Redis CLI with autocompletion and syntax highlighting. kube-shell - An integrated shell for working with the Kubernetes CLI. litecli - SQLite CLI with autocompletion and syntax highlighting. mycli - MySQL CLI with autocompletion and syntax highlighting. pgcli - PostgreSQL CLI with autocompletion and syntax highlighting. saws - A Supercharged aws-cli. Compatibility Libraries for migrating from Python 2 to 3. python-future - The missing compatibility layer between Python 2 and Python 3. modernize - Modernizes Python code for eventual Python 3 migration. six - Python 2 and 3 compatibility utilities. Computer Vision Libraries for Computer Vision. EasyOCR - Ready-to-use OCR with 40+ languages supported. Face Recognition - Simple facial recognition library. Kornia - Open Source Differentiable Computer Vision Library for PyTorch. OpenCV - Open Source Computer Vision Library. pytesseract - A wrapper for Google Tesseract OCR. SimpleCV - An open source framework for building computer vision applications. tesserocr - Another simple, Pillow-friendly, wrapper around the tesseract-ocr API for OCR. Concurrency and Parallelism Libraries for concurrent and parallel execution. Also see awesome-asyncio. concurrent.futures - (Python standard library) A high-level interface for asynchronously executing callables. eventlet - Asynchronous framework with WSGI support. gevent - A coroutine-based Python networking library that uses greenlet. multiprocessing - (Python standard library) Process-based parallelism. scoop - Scalable Concurrent Operations in Python. uvloop - Ultra fast implementation of asyncio event loop on top of libuv. Configuration Libraries for storing and parsing configuration options. configobj - INI file parser with validation. configparser - (Python standard library) INI file parser. hydra - Hydra is a framework for elegantly configuring complex applications. profig - Config from multiple formats with value conversion. python-decouple - Strict separation of settings from code. Cryptography cryptography - A package designed to expose cryptographic primitives and recipes to Python developers. paramiko - The leading native Python SSHv2 protocol library. passlib - Secure password storage/hashing library, very high level. pynacl - Python binding to the Networking and Cryptography (NaCl) library. Data Analysis Libraries for data analyzing. AWS Data Wrangler - Pandas on AWS. Blaze - NumPy and Pandas interface to Big Data. Open Mining - Business Intelligence (BI) in Pandas interface. Optimus - Agile Data Science Workflows made easy with PySpark. Orange - Data mining, data visualization, analysis and machine learning through visual programming or scripts. Pandas - A library providing high-performance, easy-to-use data structures and data analysis tools. Data Validation Libraries for validating data. Used for forms in many cases. Cerberus - A lightweight and extensible data validation library. colander - Validating and deserializing data obtained via XML, JSON, an HTML form post. jsonschema - An implementation of JSON Schema for Python. schema - A library for validating Python data structures. Schematics - Data Structure Validation. valideer - Lightweight extensible data validation and adaptation library. voluptuous - A Python data validation library. Data Visualization Libraries for visualizing data. Also see awesome-javascript. Altair - Declarative statistical visualization library for Python. Bokeh - Interactive Web Plotting for Python. bqplot - Interactive Plotting Library for the Jupyter Notebook Cartopy - A cartographic python library with matplotlib support Dash - Built on top of Flask, React and Plotly aimed at analytical web applications. awesome-dash diagrams - Diagram as Code. Matplotlib - A Python 2D plotting library. plotnine - A grammar of graphics for Python based on ggplot2. Pygal - A Python SVG Charts Creator. PyGraphviz - Python interface to Graphviz. PyQtGraph - Interactive and realtime 2D/3D/Image plotting and science/engineering widgets. Seaborn - Statistical data visualization using Matplotlib. VisPy - High-performance scientific visualization based on OpenGL. Database Databases implemented in Python. pickleDB - A simple and lightweight key-value store for Python. tinydb - A tiny, document-oriented database. ZODB - A native object database for Python. A key-value and object graph database. Database Drivers Libraries for connecting and operating databases. MySQL - awesome-mysql mysqlclient - MySQL connector with Python 3 support (mysql-python fork). PyMySQL - A pure Python MySQL driver compatible to mysql-python. PostgreSQL - awesome-postgres psycopg2 - The most popular PostgreSQL adapter for Python. queries - A wrapper of the psycopg2 library for interacting with PostgreSQL. SQlite - awesome-sqlite sqlite3 - (Python standard library) SQlite interface compliant with DB-API 2.0 SuperSQLite - A supercharged SQLite library built on top of apsw. Other Relational Databases pymssql - A simple database interface to Microsoft SQL Server. clickhouse-driver - Python driver with native interface for ClickHouse. NoSQL Databases cassandra-driver - The Python Driver for Apache Cassandra. happybase - A developer-friendly library for Apache HBase. kafka-python - The Python client for Apache Kafka. py2neo - A client library and toolkit for working with Neo4j. pymongo - The official Python client for MongoDB. redis-py - The Python client for Redis. Asynchronous Clients motor - The async Python driver for MongoDB. Date and Time Libraries for working with dates and times. Arrow - A Python library that offers a sensible and human-friendly approach to creating, manipulating, formatting and converting dates, times and timestamps. Chronyk - A Python 3 library for parsing human-written times and dates. dateutil - Extensions to the standard Python datetime module. delorean - A library for clearing up the inconvenient truths that arise dealing with datetimes. maya - Datetimes for Humans. moment - A Python library for dealing with dates/times. Inspired by Moment.js. Pendulum - Python datetimes made easy. PyTime - An easy-to-use Python module which aims to operate date/time/datetime by string. pytz - World timezone definitions, modern and historical. Brings the tz database into Python. when.py - Providing user-friendly functions to help perform common date and time actions. Debugging Tools Libraries for debugging code. pdb-like Debugger ipdb - IPython-enabled pdb. pdb++ - Another drop-in replacement for pdb. pudb - A full-screen, console-based Python debugger. wdb - An improbable web debugger through WebSockets. Tracing lptrace - strace for Python programs. manhole - Debugging UNIX socket connections and present the stacktraces for all threads and an interactive prompt. pyringe - Debugger capable of attaching to and injecting code into Python processes. python-hunter - A flexible code tracing toolkit. Profiler line_profiler - Line-by-line profiling. memory_profiler - Monitor Memory usage of Python code. py-spy - A sampling profiler for Python programs. Written in Rust. pyflame - A ptracing profiler For Python. vprof - Visual Python profiler. Others django-debug-toolbar - Display various debug information for Django. django-devserver - A drop-in replacement for Django's runserver. flask-debugtoolbar - A port of the django-debug-toolbar to flask. icecream - Inspect variables, expressions, and program execution with a single, simple function call. pyelftools - Parsing and analyzing ELF files and DWARF debugging information. Deep Learning Frameworks for Neural Networks and Deep Learning. Also see awesome-deep-learning. caffe - A fast open framework for deep learning.. keras - A high-level neural networks library and capable of running on top of either TensorFlow or Theano. mxnet - A deep learning framework designed for both efficiency and flexibility. pytorch - Tensors and Dynamic neural networks in Python with strong GPU acceleration. SerpentAI - Game agent framework. Use any video game as a deep learning sandbox. tensorflow - The most popular Deep Learning framework created by Google. Theano - A library for fast numerical computation. DevOps Tools Software and libraries for DevOps. Configuration Management ansible - A radically simple IT automation platform. cloudinit - A multi-distribution package that handles early initialization of a cloud instance. OpenStack - Open source software for building private and public clouds. pyinfra - A versatile CLI tools and python libraries to automate infrastructure. saltstack - Infrastructure automation and management system. SSH-style Deployment cuisine - Chef-like functionality for Fabric. fabric - A simple, Pythonic tool for remote execution and deployment. fabtools - Tools for writing awesome Fabric files. Process Management honcho - A Python clone of Foreman, for managing Procfile-based applications. supervisor - Supervisor process control system for UNIX. Monitoring psutil - A cross-platform process and system utilities module. Backup BorgBackup - A deduplicating archiver with compression and encryption. Others docker-compose - Fast, isolated development environments using Docker. Distributed Computing Frameworks and libraries for Distributed Computing. Batch Processing dask - A flexible parallel computing library for analytic computing. luigi - A module that helps you build complex pipelines of batch jobs. mrjob - Run MapReduce jobs on Hadoop or Amazon Web Services. PySpark - Apache Spark Python API. Ray - A system for parallel and distributed Python that unifies the machine learning ecosystem. Stream Processing faust - A stream processing library, porting the ideas from Kafka Streams to Python. streamparse - Run Python code against real-time streams of data via Apache Storm. Distribution Libraries to create packaged executables for release distribution. dh-virtualenv - Build and distribute a virtualenv as a Debian package. Nuitka - Compile scripts, modules, packages to an executable or extension module. py2app - Freezes Python scripts (Mac OS X). py2exe - Freezes Python scripts (Windows). pyarmor - A tool used to obfuscate python scripts, bind obfuscated scripts to fixed machine or expire obfuscated scripts. PyInstaller - Converts Python programs into stand-alone executables (cross-platform). pynsist - A tool to build Windows installers, installers bundle Python itself. shiv - A command line utility for building fully self-contained zipapps (PEP 441), but with all their dependencies included. Documentation Libraries for generating project documentation. sphinx - Python Documentation generator. awesome-sphinxdoc pdoc - Epydoc replacement to auto generate API documentation for Python libraries. pycco - The literate-programming-style documentation generator. Downloader Libraries for downloading. akshare - A financial data interface library, built for human beings! s3cmd - A command line tool for managing Amazon S3 and CloudFront. s4cmd - Super S3 command line tool, good for higher performance. you-get - A YouTube/Youku/Niconico video downloader written in Python 3. youtube-dl - A small command-line program to download videos from YouTube. E-commerce Frameworks and libraries for e-commerce and payments. alipay - Unofficial Alipay API for Python. Cartridge - A shopping cart app built using the Mezzanine. django-oscar - An open-source e-commerce framework for Django. django-shop - A Django based shop system. forex-python - Foreign exchange rates, Bitcoin price index and currency conversion. merchant - A Django app to accept payments from various payment processors. money - Money class with optional CLDR-backed locale-aware formatting and an extensible currency exchange. python-currencies - Display money format and its filthy currencies. saleor - An e-commerce storefront for Django. shoop - An open source E-Commerce platform based on Django. Editor Plugins and IDEs Emacs elpy - Emacs Python Development Environment. Sublime Text anaconda - Anaconda turns your Sublime Text 3 in a full featured Python development IDE. SublimeJEDI - A Sublime Text plugin to the awesome auto-complete library Jedi. Vim jedi-vim - Vim bindings for the Jedi auto-completion library for Python. python-mode - An all in one plugin for turning Vim into a Python IDE. YouCompleteMe - Includes Jedi-based completion engine for Python. Visual Studio PTVS - Python Tools for Visual Studio. Visual Studio Code Python - The official VSCode extension with rich support for Python. IDE PyCharm - Commercial Python IDE by JetBrains. Has free community edition available. spyder - Open Source Python IDE. Email Libraries for sending and parsing email. Mail Servers modoboa - A mail hosting and management platform including a modern Web UI. salmon - A Python Mail Server. Clients imbox - Python IMAP for Humans. yagmail - Yet another Gmail/SMTP client. Others flanker - An email address and Mime parsing library. mailer - High-performance extensible mail delivery framework. Enterprise Application Integrations Platforms and tools for systems integrations in enterprise environments Zato - ESB, SOA, REST, APIs and Cloud Integrations in Python. Environment Management Libraries for Python version and virtual environment management. pyenv - Simple Python version management. virtualenv - A tool to create isolated Python environments. Files Libraries for file manipulation and MIME type detection. mimetypes - (Python standard library) Map filenames to MIME types. path.py - A module wrapper for os.path. pathlib - (Python standard library) An cross-platform, object-oriented path library. PyFilesystem2 - Python's filesystem abstraction layer. python-magic - A Python interface to the libmagic file type identification library. Unipath - An object-oriented approach to file/directory operations. watchdog - API and shell utilities to monitor file system events. Foreign Function Interface Libraries for providing foreign function interface. cffi - Foreign Function Interface for Python calling C code. ctypes - (Python standard library) Foreign Function Interface for Python calling C code. PyCUDA - A Python wrapper for Nvidia's CUDA API. SWIG - Simplified Wrapper and Interface Generator. Forms Libraries for working with forms. Deform - Python HTML form generation library influenced by the formish form generation library. django-bootstrap3 - Bootstrap 3 integration with Django. django-bootstrap4 - Bootstrap 4 integration with Django. django-crispy-forms - A Django app which lets you create beautiful forms in a very elegant and DRY way. django-remote-forms - A platform independent Django form serializer. WTForms - A flexible forms validation and rendering library. Functional Programming Functional Programming with Python. Coconut - A variant of Python built for simple, elegant, Pythonic functional programming. CyToolz - Cython implementation of Toolz: High performance functional utilities. fn.py - Functional programming in Python: implementation of missing features to enjoy FP. funcy - A fancy and practical functional tools. more-itertools - More routines for operating on iterables, beyond itertools. returns - A set of type-safe monads, transformers, and composition utilities. Toolz - A collection of functional utilities for iterators, functions, and dictionaries. GUI Development Libraries for working with graphical user interface applications. curses - Built-in wrapper for ncurses used to create terminal GUI applications. Eel - A library for making simple Electron-like offline HTML/JS GUI apps. enaml - Creating beautiful user-interfaces with Declarative Syntax like QML. Flexx - Flexx is a pure Python toolkit for creating GUI's, that uses web technology for its rendering. Gooey - Turn command line programs into a full GUI application with one line. kivy - A library for creating NUI applications, running on Windows, Linux, Mac OS X, Android and iOS. pyglet - A cross-platform windowing and multimedia library for Python. PyGObject - Python Bindings for GLib/GObject/GIO/GTK+ (GTK+3). PyQt - Python bindings for the Qt cross-platform application and UI framework. PySimpleGUI - Wrapper for tkinter, Qt, WxPython and Remi. pywebview - A lightweight cross-platform native wrapper around a webview component. Tkinter - Tkinter is Python's de-facto standard GUI package. Toga - A Python native, OS native GUI toolkit. urwid - A library for creating terminal GUI applications with strong support for widgets, events, rich colors, etc. wxPython - A blending of the wxWidgets C++ class library with the Python. DearPyGui - A Simple GPU accelerated Python GUI framework GraphQL Libraries for working with GraphQL. graphene - GraphQL framework for Python. tartiflette-aiohttp - An aiohttp-based wrapper for Tartiflette to expose GraphQL APIs over HTTP. tartiflette-asgi - ASGI support for the Tartiflette GraphQL engine. tartiflette - SDL-first GraphQL engine implementation for Python 3.6+ and asyncio. Game Development Awesome game development libraries. Arcade - Arcade is a modern Python framework for crafting games with compelling graphics and sound. Cocos2d - cocos2d is a framework for building 2D games, demos, and other graphical/interactive applications. Harfang3D - Python framework for 3D, VR and game development. Panda3D - 3D game engine developed by Disney. Pygame - Pygame is a set of Python modules designed for writing games. PyOgre - Python bindings for the Ogre 3D render engine, can be used for games, simulations, anything 3D. PyOpenGL - Python ctypes bindings for OpenGL and it's related APIs. PySDL2 - A ctypes based wrapper for the SDL2 library. RenPy - A Visual Novel engine. Geolocation Libraries for geocoding addresses and working with latitudes and longitudes. django-countries - A Django app that provides a country field for models and forms. GeoDjango - A world-class geographic web framework. GeoIP - Python API for MaxMind GeoIP Legacy Database. geojson - Python bindings and utilities for GeoJSON. geopy - Python Geocoding Toolbox. HTML Manipulation Libraries for working with HTML and XML. BeautifulSoup - Providing Pythonic idioms for iterating, searching, and modifying HTML or XML. bleach - A whitelist-based HTML sanitization and text linkification library. cssutils - A CSS library for Python. html5lib - A standards-compliant library for parsing and serializing HTML documents and fragments. lxml - A very fast, easy-to-use and versatile library for handling HTML and XML. MarkupSafe - Implements a XML/HTML/XHTML Markup safe string for Python. pyquery - A jQuery-like library for parsing HTML. untangle - Converts XML documents to Python objects for easy access. WeasyPrint - A visual rendering engine for HTML and CSS that can export to PDF. xmldataset - Simple XML Parsing. xmltodict - Working with XML feel like you are working with JSON. HTTP Clients Libraries for working with HTTP. grequests - requests + gevent for asynchronous HTTP requests. httplib2 - Comprehensive HTTP client library. httpx - A next generation HTTP client for Python. requests - HTTP Requests for Humans. treq - Python requests like API built on top of Twisted's HTTP client. urllib3 - A HTTP library with thread-safe connection pooling, file post support, sanity friendly. Hardware Libraries for programming with hardware. ino - Command line toolkit for working with Arduino. keyboard - Hook and simulate global keyboard events on Windows and Linux. mouse - Hook and simulate global mouse events on Windows and Linux. Pingo - Pingo provides a uniform API to program devices like the Raspberry Pi, pcDuino, Intel Galileo, etc. PyUserInput - A module for cross-platform control of the mouse and keyboard. scapy - A brilliant packet manipulation library. wifi - A Python library and command line tool for working with WiFi on Linux. Image Processing Libraries for manipulating images. hmap - Image histogram remapping. imgSeek - A project for searching a collection of images using visual similarity. nude.py - Nudity detection. pagan - Retro identicon (Avatar) generation based on input string and hash. pillow - Pillow is the friendly PIL fork. python-barcode - Create barcodes in Python with no extra dependencies. pygram - Instagram-like image filters. PyMatting - A library for alpha matting. python-qrcode - A pure Python QR Code generator. pywal - A tool that generates color schemes from images. pyvips - A fast image processing library with low memory needs. Quads - Computer art based on quadtrees. scikit-image - A Python library for (scientific) image processing. thumbor - A smart imaging service. It enables on-demand crop, re-sizing and flipping of images. wand - Python bindings for MagickWand, C API for ImageMagick. Implementations Implementations of Python. CLPython - Implementation of the Python programming language written in Common Lisp. CPython - Default, most widely used implementation of the Python programming language written in C. Cython - Optimizing Static Compiler for Python. Grumpy - More compiler than interpreter as more powerful CPython2.7 replacement (alpha). IronPython - Implementation of the Python programming language written in C#. Jython - Implementation of Python programming language written in Java for the JVM. MicroPython - A lean and efficient Python programming language implementation. Numba - Python JIT compiler to LLVM aimed at scientific Python. PeachPy - x86-64 assembler embedded in Python. Pyjion - A JIT for Python based upon CoreCLR. PyPy - A very fast and compliant implementation of the Python language. Pyston - A Python implementation using JIT techniques. Stackless Python - An enhanced version of the Python programming language. Interactive Interpreter Interactive Python interpreters (REPL). bpython - A fancy interface to the Python interpreter. Jupyter Notebook (IPython) - A rich toolkit to help you make the most out of using Python interactively. awesome-jupyter ptpython - Advanced Python REPL built on top of the python-prompt-toolkit. Internationalization Libraries for working with i18n. Babel - An internationalization library for Python. PyICU - A wrapper of International Components for Unicode C++ library (ICU). Job Scheduler Libraries for scheduling jobs. Airflow - Airflow is a platform to programmatically author, schedule and monitor workflows. APScheduler - A light but powerful in-process task scheduler that lets you schedule functions. django-schedule - A calendaring app for Django. doit - A task runner and build tool. gunnery - Multipurpose task execution tool for distributed systems with web-based interface. Joblib - A set of tools to provide lightweight pipelining in Python. Plan - Writing crontab file in Python like a charm. Prefect - A modern workflow orchestration framework that makes it easy to build, schedule and monitor robust data pipelines. schedule - Python job scheduling for humans. Spiff - A powerful workflow engine implemented in pure Python. TaskFlow - A Python library that helps to make task execution easy, consistent and reliable. Logging Libraries for generating and working with logs. logbook - Logging replacement for Python. logging - (Python standard library) Logging facility for Python. loguru - Library which aims to bring enjoyable logging in Python. sentry-python - Sentry SDK for Python. structlog - Structured logging made easy. Machine Learning Libraries for Machine Learning. Also see awesome-machine-learning. gym - A toolkit for developing and comparing reinforcement learning algorithms. H2O - Open Source Fast Scalable Machine Learning Platform. Metrics - Machine learning evaluation metrics. NuPIC - Numenta Platform for Intelligent Computing. scikit-learn - The most popular Python library for Machine Learning. Spark ML - Apache Spark's scalable Machine Learning library. vowpal_porpoise - A lightweight Python wrapper for Vowpal Wabbit. xgboost - A scalable, portable, and distributed gradient boosting library. MindsDB - MindsDB is an open source AI layer for existing databases that allows you to effortlessly develop, train and deploy state-of-the-art machine learning models using standard queries. Microsoft Windows Python programming on Microsoft Windows. Python(x,y) - Scientific-applications-oriented Python Distribution based on Qt and Spyder. pythonlibs - Unofficial Windows binaries for Python extension packages. PythonNet - Python Integration with the .NET Common Language Runtime (CLR). PyWin32 - Python Extensions for Windows. WinPython - Portable development environment for Windows 7/8. Miscellaneous Useful libraries or tools that don't fit in the categories above. blinker - A fast Python in-process signal/event dispatching system. boltons - A set of pure-Python utilities. itsdangerous - Various helpers to pass trusted data to untrusted environments. magenta - A tool to generate music and art using artificial intelligence. pluginbase - A simple but flexible plugin system for Python. tryton - A general purpose business framework. Natural Language Processing Libraries for working with human languages. General gensim - Topic Modeling for Humans. langid.py - Stand-alone language identification system. nltk - A leading platform for building Python programs to work with human language data. pattern - A web mining module. polyglot - Natural language pipeline supporting hundreds of languages. pytext - A natural language modeling framework based on PyTorch. PyTorch-NLP - A toolkit enabling rapid deep learning NLP prototyping for research. spacy - A library for industrial-strength natural language processing in Python and Cython. Stanza - The Stanford NLP Group's official Python library, supporting 60+ languages. Chinese funNLP - A collection of tools and datasets for Chinese NLP. jieba - The most popular Chinese text segmentation library. pkuseg-python - A toolkit for Chinese word segmentation in various domains. snownlp - A library for processing Chinese text. Network Virtualization Tools and libraries for Virtual Networking and SDN (Software Defined Networking). mininet - A popular network emulator and API written in Python. napalm - Cross-vendor API to manipulate network devices. pox - A Python-based SDN control applications, such as OpenFlow SDN controllers. News Feed Libraries for building user's activities. django-activity-stream - Generating generic activity streams from the actions on your site. Stream Framework - Building news feed and notification systems using Cassandra and Redis. ORM Libraries that implement Object-Relational Mapping or data mapping techniques. Relational Databases Django Models - The Django ORM. SQLAlchemy - The Python SQL Toolkit and Object Relational Mapper. awesome-sqlalchemy dataset - Store Python dicts in a database - works with SQLite, MySQL, and PostgreSQL. orator - The Orator ORM provides a simple yet beautiful ActiveRecord implementation. orm - An async ORM. peewee - A small, expressive ORM. pony - ORM that provides a generator-oriented interface to SQL. pydal - A pure Python Database Abstraction Layer. NoSQL Databases hot-redis - Rich Python data types for Redis. mongoengine - A Python Object-Document-Mapper for working with MongoDB. PynamoDB - A Pythonic interface for Amazon DynamoDB. redisco - A Python Library for Simple Models and Containers Persisted in Redis. Package Management Libraries for package and dependency management. pip - The package installer for Python. pip-tools - A set of tools to keep your pinned Python dependencies fresh. PyPI conda - Cross-platform, Python-agnostic binary package manager. poetry - Python dependency management and packaging made easy. Package Repositories Local PyPI repository server and proxies. bandersnatch - PyPI mirroring tool provided by Python Packaging Authority (PyPA). devpi - PyPI server and packaging/testing/release tool. localshop - Local PyPI server (custom packages and auto-mirroring of pypi). warehouse - Next generation Python Package Repository (PyPI). Penetration Testing Frameworks and tools for penetration testing. fsociety - A Penetration testing framework. setoolkit - A toolkit for social engineering. sqlmap - Automatic SQL injection and database takeover tool. Permissions Libraries that allow or deny users access to data or functionality. django-guardian - Implementation of per object permissions for Django 1.2+ django-rules - A tiny but powerful app providing object-level permissions to Django, without requiring a database. Processes Libraries for starting and communicating with OS processes. delegator.py - Subprocesses for Humans 2.0. sarge - Yet another wrapper for subprocess. sh - A full-fledged subprocess replacement for Python. Recommender Systems Libraries for building recommender systems. annoy - Approximate Nearest Neighbors in C++/Python optimized for memory usage. fastFM - A library for Factorization Machines. implicit - A fast Python implementation of collaborative filtering for implicit datasets. libffm - A library for Field-aware Factorization Machine (FFM). lightfm - A Python implementation of a number of popular recommendation algorithms. spotlight - Deep recommender models using PyTorch. Surprise - A scikit for building and analyzing recommender systems. tensorrec - A Recommendation Engine Framework in TensorFlow. Refactoring Refactoring tools and libraries for Python Bicycle Repair Man - Bicycle Repair Man, a refactoring tool for Python. Bowler - Safe code refactoring for modern Python. Rope - Rope is a python refactoring library. RESTful API Libraries for building RESTful APIs. Django django-rest-framework - A powerful and flexible toolkit to build web APIs. django-tastypie - Creating delicious APIs for Django apps. Flask eve - REST API framework powered by Flask, MongoDB and good intentions. flask-api - Browsable Web APIs for Flask. flask-restful - Quickly building REST APIs for Flask. Pyramid cornice - A RESTful framework for Pyramid. Framework agnostic apistar - A smart Web API framework, designed for Python 3. falcon - A high-performance framework for building cloud APIs and web app backends. fastapi - A modern, fast, web framework for building APIs with Python 3.6+ based on standard Python type hints. hug - A Python 3 framework for cleanly exposing APIs. sandman2 - Automated REST APIs for existing database-driven systems. sanic - A Python 3.6+ web server and web framework that's written to go fast. vibora - Fast, efficient and asynchronous Web framework inspired by Flask. Robotics Libraries for robotics. PythonRobotics - This is a compilation of various robotics algorithms with visualizations. rospy - This is a library for ROS (Robot Operating System). RPC Servers RPC-compatible servers. RPyC (Remote Python Call) - A transparent and symmetric RPC library for Python zeroRPC - zerorpc is a flexible RPC implementation based on ZeroMQ and MessagePack. Science Libraries for scientific computing. Also see Python-for-Scientists. astropy - A community Python library for Astronomy. bcbio-nextgen - Providing best-practice pipelines for fully automated high throughput sequencing analysis. bccb - Collection of useful code related to biological analysis. Biopython - Biopython is a set of freely available tools for biological computation. cclib - A library for parsing and interpreting the results of computational chemistry packages. Colour - Implementing a comprehensive number of colour theory transformations and algorithms. Karate Club - Unsupervised machine learning toolbox for graph structured data. NetworkX - A high-productivity software for complex networks. NIPY - A collection of neuroimaging toolkits. NumPy - A fundamental package for scientific computing with Python. ObsPy - A Python toolbox for seismology. Open Babel - A chemical toolbox designed to speak the many languages of chemical data. PyDy - Short for Python Dynamics, used to assist with workflow in the modeling of dynamic motion. PyMC - Markov Chain Monte Carlo sampling toolkit. QuTiP - Quantum Toolbox in Python. RDKit - Cheminformatics and Machine Learning Software. SciPy - A Python-based ecosystem of open-source software for mathematics, science, and engineering. SimPy - A process-based discrete-event simulation framework. statsmodels - Statistical modeling and econometrics in Python. SymPy - A Python library for symbolic mathematics. Zipline - A Pythonic algorithmic trading library. Search Libraries and software for indexing and performing search queries on data. django-haystack - Modular search for Django. elasticsearch-dsl-py - The official high-level Python client for Elasticsearch. elasticsearch-py - The official low-level Python client for Elasticsearch. pysolr - A lightweight Python wrapper for Apache Solr. whoosh - A fast, pure Python search engine library. Serialization Libraries for serializing complex data types marshmallow - A lightweight library for converting complex objects to and from simple Python datatypes. pysimdjson - A Python bindings for simdjson. python-rapidjson - A Python wrapper around RapidJSON. ultrajson - A fast JSON decoder and encoder written in C with Python bindings. Serverless Frameworks Frameworks for developing serverless Python code. python-lambda - A toolkit for developing and deploying Python code in AWS Lambda. Zappa - A tool for deploying WSGI applications on AWS Lambda and API Gateway. Shell Shells based on Python. xonsh - A Python-powered, cross-platform, Unix-gazing shell language and command prompt. Specific Formats Processing Libraries for parsing and manipulating specific text formats. General tablib - A module for Tabular Datasets in XLS, CSV, JSON, YAML. Office docxtpl - Editing a docx document by jinja2 template openpyxl - A library for reading and writing Excel 2010 xlsx/xlsm/xltx/xltm files. pyexcel - Providing one API for reading, manipulating and writing csv, ods, xls, xlsx and xlsm files. python-docx - Reads, queries and modifies Microsoft Word 2007/2008 docx files. python-pptx - Python library for creating and updating PowerPoint (.pptx) files. unoconv - Convert between any document format supported by LibreOffice/OpenOffice. XlsxWriter - A Python module for creating Excel .xlsx files. xlwings - A BSD-licensed library that makes it easy to call Python from Excel and vice versa. xlwt / xlrd - Writing and reading data and formatting information from Excel files. PDF PDFMiner - A tool for extracting information from PDF documents. PyPDF2 - A library capable of splitting, merging and transforming PDF pages. ReportLab - Allowing Rapid creation of rich PDF documents. Markdown Mistune - Fastest and full featured pure Python parsers of Markdown. Python-Markdown - A Python implementation of John Grubers Markdown. YAML PyYAML - YAML implementations for Python. CSV csvkit - Utilities for converting to and working with CSV. Archive unp - A command line tool that can unpack archives easily. Static Site Generator Static site generator is a software that takes some text + templates as input and produces HTML files on the output. lektor - An easy to use static CMS and blog engine. mkdocs - Markdown friendly documentation generator. makesite - Simple, lightweight, and magic-free static site/blog generator (< 130 lines). nikola - A static website and blog generator. pelican - Static site generator that supports Markdown and reST syntax. Tagging Libraries for tagging items. django-taggit - Simple tagging for Django. Task Queues Libraries for working with task queues. celery - An asynchronous task queue/job queue based on distributed message passing. dramatiq - A fast and reliable background task processing library for Python 3. huey - Little multi-threaded task queue. mrq - A distributed worker task queue in Python using Redis & gevent. rq - Simple job queues for Python. Template Engine Libraries and tools for templating and lexing. Genshi - Python templating toolkit for generation of web-aware output. Jinja2 - A modern and designer friendly templating language. Mako - Hyperfast and lightweight templating for the Python platform. Testing Libraries for testing codebases and generating test data. Testing Frameworks hypothesis - Hypothesis is an advanced Quickcheck style property based testing library. nose2 - The successor to nose, based on `unittest2. pytest - A mature full-featured Python testing tool. Robot Framework - A generic test automation framework. unittest - (Python standard library) Unit testing framework. Test Runners green - A clean, colorful test runner. mamba - The definitive testing tool for Python. Born under the banner of BDD. tox - Auto builds and tests distributions in multiple Python versions GUI / Web Testing locust - Scalable user load testing tool written in Python. PyAutoGUI - PyAutoGUI is a cross-platform GUI automation Python module for human beings. Schemathesis - A tool for automatic property-based testing of web applications built with Open API / Swagger specifications. Selenium - Python bindings for Selenium WebDriver. sixpack - A language-agnostic A/B Testing framework. splinter - Open source tool for testing web applications. Mock doublex - Powerful test doubles framework for Python. freezegun - Travel through time by mocking the datetime module. httmock - A mocking library for requests for Python 2.6+ and 3.2+. httpretty - HTTP request mock tool for Python. mock - (Python standard library) A mocking and patching library. mocket - A socket mock framework with gevent/asyncio/SSL support. responses - A utility library for mocking out the requests Python library. VCR.py - Record and replay HTTP interactions on your tests. Object Factories factory_boy - A test fixtures replacement for Python. mixer - Another fixtures replacement. Supports Django, Flask, SQLAlchemy, Peewee and etc. model_mommy - Creating random fixtures for testing in Django. Code Coverage coverage - Code coverage measurement. Fake Data fake2db - Fake database generator. faker - A Python package that generates fake data. mimesis - is a Python library that help you generate fake data. radar - Generate random datetime / time. Text Processing Libraries for parsing and manipulating plain texts. General chardet - Python 2/3 compatible character encoding detector. difflib - (Python standard library) Helpers for computing deltas. ftfy - Makes Unicode text less broken and more consistent automagically. fuzzywuzzy - Fuzzy String Matching. Levenshtein - Fast computation of Levenshtein distance and string similarity. pangu.py - Paranoid text spacing. pyfiglet - An implementation of figlet written in Python. pypinyin - Convert Chinese hanzi () to pinyin (). textdistance - Compute distance between sequences with 30+ algorithms. unidecode - ASCII transliterations of Unicode text. Slugify awesome-slugify - A Python slugify library that can preserve unicode. python-slugify - A Python slugify library that translates unicode to ASCII. unicode-slugify - A slugifier that generates unicode slugs with Django as a dependency. Unique identifiers hashids - Implementation of hashids in Python. shortuuid - A generator library for concise, unambiguous and URL-safe UUIDs. Parser ply - Implementation of lex and yacc parsing tools for Python. pygments - A generic syntax highlighter. pyparsing - A general purpose framework for generating parsers. python-nameparser - Parsing human names into their individual components. python-phonenumbers - Parsing, formatting, storing and validating international phone numbers. python-user-agents - Browser user agent parser. sqlparse - A non-validating SQL parser. Third-party APIs Libraries for accessing third party services APIs. Also see List of Python API Wrappers and Libraries. apache-libcloud - One Python library for all clouds. boto3 - Python interface to Amazon Web Services. django-wordpress - WordPress models and views for Django. facebook-sdk - Facebook Platform Python SDK. google-api-python-client - Google APIs Client Library for Python. gspread - Google Spreadsheets Python API. twython - A Python wrapper for the Twitter API. URL Manipulation Libraries for parsing URLs. furl - A small Python library that makes parsing and manipulating URLs easy. purl - A simple, immutable URL class with a clean API for interrogation and manipulation. pyshorteners - A pure Python URL shortening lib. webargs - A friendly library for parsing HTTP request arguments with built-in support for popular web frameworks. Video Libraries for manipulating video and GIFs. moviepy - A module for script-based movie editing with many formats, including animated GIFs. scikit-video - Video processing routines for SciPy. vidgear - Most Powerful multi-threaded Video Processing framework. Web Asset Management Tools for managing, compressing and minifying website assets. django-compressor - Compresses linked and inline JavaScript or CSS into a single cached file. django-pipeline - An asset packaging library for Django. django-storages - A collection of custom storage back ends for Django. fanstatic - Packages, optimizes, and serves static file dependencies as Python packages. fileconveyor - A daemon to detect and sync files to CDNs, S3 and FTP. flask-assets - Helps you integrate webassets into your Flask app. webassets - Bundles, optimizes, and manages unique cache-busting URLs for static resources. Web Content Extracting Libraries for extracting web contents. html2text - Convert HTML to Markdown-formatted text. lassie - Web Content Retrieval for Humans. micawber - A small library for extracting rich content from URLs. newspaper - News extraction, article extraction and content curation in Python. python-readability - Fast Python port of arc90's readability tool. requests-html - Pythonic HTML Parsing for Humans. sumy - A module for automatic summarization of text documents and HTML pages. textract - Extract text from any document, Word, PowerPoint, PDFs, etc. toapi - Every web site provides APIs. Web Crawling Libraries to automate web scraping. cola - A distributed crawling framework. feedparser - Universal feed parser. grab - Site scraping framework. MechanicalSoup - A Python library for automating interaction with websites. portia - Visual scraping for Scrapy. pyspider - A powerful spider system. robobrowser - A simple, Pythonic library for browsing the web without a standalone web browser. scrapy - A fast high-level screen scraping and web crawling framework. Web Frameworks Traditional full stack web frameworks. Also see RESTful API. Synchronous Django - The most popular web framework in Python. awesome-django awesome-django Flask - A microframework for Python. awesome-flask Pyramid - A small, fast, down-to-earth, open source Python web framework. awesome-pyramid Masonite - The modern and developer centric Python web framework. Asynchronous Tornado - A web framework and asynchronous networking library. WebSocket Libraries for working with WebSocket. autobahn-python - WebSocket & WAMP for Python on Twisted and asyncio. channels - Developer-friendly asynchrony for Django. websockets - A library for building WebSocket servers and clients with a focus on correctness and simplicity. WSGI Servers WSGI-compatible web servers. bjoern - Asynchronous, very fast and written in C. gunicorn - Pre-forked, ported from Ruby's Unicorn project. uWSGI - A project aims at developing a full stack for building hosting services, written in C. waitress - Multi-threaded, powers Pyramid. werkzeug - A WSGI utility library for Python that powers Flask and can easily be embedded into your own projects. Resources Where to discover learning resources or new Python libraries. Books Fluent Python Think Python Websites Tutorials Full Stack Python Python Cheatsheet Real Python The Hitchhikers Guide to Python Ultimate Python study guide Libraries Awesome Python @LibHunt Others Python ZEEF Pythonic News What the f*ck Python! Newsletters Awesome Python Newsletter Pycoder's Weekly Python Tricks Python Weekly Podcasts Django Chat Podcast.__init__ Python Bytes Running in Production Talk Python To Me Test and Code The Real Python Podcast Contributing Your contributions are always welcome! Please take a look at the contribution guidelines first. I will keep some pull requests open if I'm not sure whether those libraries are awesome, you could vote for them by adding :+1: to them. Pull requests will be merged when their votes reach 20. If you have any question about this opinionated list, do not hesitate to contact me @VintaChen on Twitter or open an issue on GitHub."
2673,"Container data volume manager for your Dockerized applicationFlocker Flocker is an open-source Container Data Volume Manager for your Dockerized applications. By providing tools for data migrations, Flocker gives ops teams the tools they need to run containerized stateful services like databases in production. Unlike a Docker data volume which is tied to a single server, a Flocker data volume, called a dataset, is portable and can be used with any container, no matter where that container is running. Flocker manages Docker containers and data volumes together. When you use Flocker to manage your stateful microservice, your volumes will follow your containers when they move between different hosts in your cluster. You can also use Flocker to manage only your volumes, while continuing to manage your containers however you choose. About Us Flocker is being developed by ClusterHQ. We are a small team of engineers with experience running distributed systems and many of us are core contributors to the Twisted project. This project is under active development; version 1.0 was released on June 17th, 2015. Contributions are welcome. If you have any issues or feedback, you can talk to us_. We're looking forward to working on this project with you. Documentation You can read more about installing Flocker, follow a tutorial and learn about the features of Flocker and its architecture in the Flocker docs_. Feature Requests If you have any feature requests or suggestions, we would love to hear about them. Please send us your ideas by filing a GitHub issue_. Tests Flocker's test suite is based on unittest and Twisted Trial. The preferred way to run the test suite is using the command trial flocker. Flocker also includes a tox configuration to run the test suite in multiple environments and to run additional checks (such as flake8) and build the documentation with Sphinx. You can run all of the tox environments using the command tox. Flocker is also tested using continuous integration_. .. _ClusterHQ: https://clusterhq.com/ .. _Twisted: https://twistedmatrix.com/trac/ .. _Flocker docs: https://flocker.readthedocs.io/ .. _unittest: https://docs.python.org/2/library/unittest.html .. _Twisted Trial: https://twistedmatrix.com/trac/wiki/TwistedTrial .. _tox: https://tox.readthedocs.org/ .. _continuous integration: http://build.clusterhq.com/ .. _talk to us: http://flocker-docs.clusterhq.com/en/latest/gettinginvolved/contributing.html#talk-to-us .. _flake8: https://pypi.python.org/pypi/flake8 .. _GitHub issue: https://github.com/clusterhq/flocker/issues"
3664,"Generate regular expressions that match a set of stringsregexgen Generates regular expressions that match a set of strings. Installation regexgen can be installed using npm: Example The simplest use is to simply pass an array of strings to regexgen: You can also use the Trie class directly: CLI regexgen also has a simple CLI to generate regexes using inputs from the command line. The optional first parameter is the flags to add to the regex (e.g. -i for a case insensitive match). ES2015 and Unicode By default regexgen will output a standard JavaScript regular expression, with Unicode codepoints converted into UCS-2 surrogate pairs. If desired, you can request an ES2015-compatible Unicode regular expression by supplying the -u flag, which results in those codepoints being retained. Such regular expressions are compatible with current versions of Node, as well as the latest browsers, and may be more transferrable to other languages. How does it work? Generate a Trie containing all of the input strings. This is a tree structure where each edge represents a single character. This removes redundancies at the start of the strings, but common branches further down are not merged. A trie can be seen as a tree-shaped deterministic finite automaton (DFA), so DFA algorithms can be applied. In this case, we apply Hopcroft's DFA minimization algorithm to merge the nondistinguishable states. Convert the resulting minimized DFA to a regular expression. This is done using Brzozowski's algebraic method, which is quite elegant. It expresses the DFA as a system of equations which can be solved for a resulting regex. Along the way, some additional optimizations are made, such as hoisting common substrings out of an alternation, and using character class ranges. This produces an an Abstract Syntax Tree (AST) for the regex, which is then converted to a string and compiled to a JavaScript RegExp object. License MIT"
3438,Snapshot view unit tests for iOSFBSnapshotTestCase This project has a new name and home! You can now find iOSSnapshotTestCase here.
2021,"Augmented Traffic Control: A tool to simulate network conditionsAugmented Traffic Control Full documentation for the project is available at http://facebook.github.io/augmented-traffic-control/. Overview Augmented Traffic Control (ATC) is a tool to simulate network conditions. It allows controlling the connection that a device has to the internet. Developers can use ATC to test their application across varying network conditions, easily emulating high speed, mobile, and even severely impaired networks. Aspects of the connection that can be controlled include: bandwidth latency packet loss corrupted packets packets ordering In order to be able to shape the network traffic, ATC must be running on a device that routes the traffic and sees the real IP address of the device, like your network gateway for instance. This also allows any devices that route through ATC to be able to shape their traffic. Traffic can be shaped/unshaped using a web interface allowing any devices with a web browser to use ATC without the need for a client application. ATC is made of multiple components that interact together: * atcd: The ATC daemon which is responsible for setting/unsetting traffic shaping. atcd exposes a Thrift interface to interact with it. * django-atc-api: A Django app based on Django Rest Framework that provides a RESTful interface to atcd. * django-atc-demo-ui: A Django app that provides a simple Web UI to use atc from a mobile phone. * django-atc-profile-storage: A Django app that can be used to save shaping profiles, making it easier to re-use them later without manually re-entering those settings. By splitting ATC in sub-components, it make it easier to hack on it or build on top of it. While django-atc-demo-ui is shipped as part of ATC's main repository to allow people to be able to use ATC out of the box, by providing a REST API to atcd, it makes it relatively easy to interact with atcd via the command line and opens the path for the community to be able to build creative command line tools, web UI or mobile apps that interact with ATC. Requirements Most requirements are handled automatically by pip, the packaging system used by ATC, and each ATC package may have different requirements and the README.md files of the respective packages should be checked for more details. Anyhow, some requirements apply to the overall codebase: Python 2.7: Currently, ATC is only supported on python version 2.7. Django 1.10: Currently, ATC is only supported using django version 1.10. Installing ATC The fact that ATC is splitted in multiple packages allows for multiple deployment scenarii. However, deploying all the packages on the same host is the simplest and most likely fitting most use cases. To get more details on how to install/configure each packages, please refer to the packages' respective READMEs. Packages The easiest way to install ATC is by using pip. Django Now that we have all the packages installed, we need to create a new Django project in which we will use our Django app. Now that we have our django project, we need to configure it to use our apps and we need to tell it how to route to our apps. Open atcui/settings.py and enable the ATC apps by adding to INSTALLED_APPS: Now, open atcui/urls.py and enable routing to the ATC apps by adding the routes to urlpatterns: Finally, let's update the Django DB: Running ATC All require packages should now be installed and configured. We now need to run the daemon and the UI interface. While we will run ATC straight from the command line in this example, you can refer to example sysvinit and upstart scripts. atcd atcd modifies network related settings and as such needs to run in privileged mode: Supposing eth0 is your interface to connect to the internet and eth1, your interface to connect to your lan, this should just work. If your setting is slightly different, use the command line arguments --atcd-wan and --atcd-lan to adapt to your configuration. ATC UI The UI on the other hand is a standard Django Web app and can be run as a normal user. Make sure you are in the directory that was created when you ran django-admin startproject atcui and run: You should now be able to access the web UI at http://localhost:8000 ATC Code Structure ATC source code is available under the atc directory, it is currently composed of: atc_thrift the thrift interface's library atcd the ATC daemon that runs on the router doing the traffic shaping django-atc-api A django app that provides a RESTful interface to atcd django-atc-demo-ui A django app that provides a simple demo UI leveraging the RESTful API django-atc-profile-storage A django app that allows saving shaping profiles to DB allowing users to select their favorite profile from a list instead of re-entering all the profile details every time. The chef directory contains 2 chef cookbooks: atc A cookbook to deploy ATC. It also allows to deploy ATC in a Virtual Box VM in order to develop on ATC. atclient Set up a Linux Desktop VM that can be used to test shaping end to end. atcd atcd is the daemon that runs on the router that does the shaping. Interaction with the daemon is done using thrift. The interface definition can be found in atc_thrift.thrift. atc_thrift atc_thrift defines the thrift interface to communicate with the atcd daemon. django-atc-api django-atc-api is a django app that provide a REST API to the atcd daemon. Web applications, command line tools can use the API in order to shape/unshape traffic. django-atc-demo-ui django-atc-demo-ui is a simple Web UI to enable/disable traffic shaping. The UI is mostly written in React django-atc-profile-storage django-atc-profile-storage allows saving profiles to DB. A typical use case will be to save a list of predefined/often used shaping settings that you want to be able to accessing in just a few clicks/taps. Developing on ATC To make ATC development easier, we use Virtual Box and Vagrant to provision and run a VM that will run the ATC daemon and the ATC UI from your git checkout. Interacting with ATC will only shape the traffic within the VM and not on the host. Setting up the environment Note: vagrant is an easy way to set up a test environment, but virtualization will produce different results than a setup on bare-metal. We recommend using vagrant only for testing/development and using bare-metal for setups which require realistic shaping settings. You will need to install VirtualBox, Vagrant and a couple of plugins: VirtualBox Vagrant Chef DK Install some vagrant plugins: vagrant plugin install vagrant-berkshelf --plugin-version '>= 2.0.1' vagrant plugin install vagrant-omnibus Clone this repo: git clone git@github.com:facebook/augmented-traffic-control.git atc Running ATC Once in the repo, go to the chef/atc directory and run: This will take some time before it completes, once the VM is provision, SSH into it: You should now be able to access ATC at: http://localhost:8080/ Using the Sample Profiles Once you've got ATC up and running, you can run the script utils/restore-profiles.sh to setup the set of default profiles. The script needs to be passed a hostname:port with the location of your ATC instance: utils/restore-profiles.sh localhost:8080 After doing this, you should see the 10 sample profiles listed below in your ATC instance: 2G - Developing Rural 2G - Developing Urban 3G - Average 3G - Good Cable DSL Edge - Average Edge - Good Edge - Lossy No Connectivity Naturally, you cannot improve your natural network speed by selecting a faster profile than your service. For example, selecting the Cable profile will not make your network faster if your natural connection speed resembles DSL more closely. Hacking on the code Hacking on ATC is done from the host and tested in the VM. In order to reflect the changes, you will need to start the services manually. Both atcd and atcui have their python libraries installed in a python virtualenv so you will need to activate the environment in order to be able to run the services. The virtualenv is installed in /usr/local/atc/venv/bin/activate . Running the daemon The atcd daemon is running under the root user privileges, all operations below needs to be done as root. To run the daemon manually, first make sure it is not running in the background: And run the daemon: Once you are happy with your changes and you want to test them, you will need to kill the daemon and restart it in order to apply the changes. Running the API/UI This is a django project and, when running the django built-in HTTP server, will detect code changes and reload automatically. To run the HTTP REST API and UI:"
742,"A window management application (replacement for Divvy/SizeUp/ShiftIt)About Slate Slate is a window management application similar to Divvy and SizeUp (except better and free!). Originally written to replace them due to some limitations in how each work, it attempts to overcome them by simply being extremely configurable. As a result, it may be a bit daunting to get configured, but once it is done, the benefit is huge. Slate currently works on Mac OS X 10.6 and above Summary of Features Highly customizable Bind keystrokes to: move and/or resize windows directionally focus windows activate preset layouts create, delete, and activate snapshots of the current state of windows Set default layouts for different monitor configurations which will activate when that configuration is detected. Window Hints: an intuitive way to change window focus [Beta] A better, more customizable, application switcher. Credits Big thanks to philc for the Window Hints idea (and initial implementation) as well as plenty of other suggestions and improvement ideas. Using Slate Installing Slate NEW Installation Instructions Note: You must turn on the Accessibility API by checking System Preferences > Universal Access > Enable access for assistive devices Direct Download .dmg .tar.gz Terminal Just run this in your terminal: cd /Applications && curl http://www.ninjamonkeysoftware.com/slate/versions/slate-latest.tar.gz | tar -xz Configuring Slate NEW: You may now use a "".slate.js"" file to configure slate using JavaScript. This allows for much more complex and dynamic configurations than the normal slate configuration style below. You can check out the documentation for this here. Slate is configured using a "".slate"" file in the current user's home directory. Configuration is loaded upon running Slate. You can also re-load the config using the ""Load Config"" menu option on the status menu (use this at your own risk. It is better to simply restart Slate). Note: If no "".slate"" file exists in the current user's home directory, the default config file will be used. Configuration is split into the following directives: config (for global configurations) alias (to create alias variables) layout (to configure layouts) default (to default certain screen configurations to layouts) bind (for key bindings) source (to load configs from another file) Note: # is the comment character. Anything after a # will be ignored. Expressions Some directives allow parameters that can be expressions. The following strings will be replaced with the appropriate values when using expressions: screenOriginX = target screen's top left x coordinate (should not be used in Window Hints configs) screenOriginY = target screen's top left y coordinate (should not be used in Window Hints configs) screenSizeX = target screen's width screenSizeY = target screen's height windowTopLeftX = window's current top left x coordinate (should not be used in Window Hints configs) windowTopLeftY = window's current top left y coordinate (should not be used in Window Hints configs) windowSizeX = window's width windowSizeY = window's height newWindowSizeX = window's new width (after resize, only usable in topLeftX and topLeftY, should not be used in configs) newWindowSizeY = window's new height (after resize, only usable in topLeftX and topLeftY, should not be used in configs) windowHintsWidth = the value of the windowHintsWidth config (only usable in windowHintsTopLeftX and windowHintsTopLeftY) windowHintsHeight = the value of the windowHintsHeight config (only usable in windowHintsTopLeftX and windowHintsTopLeftY) In addition to the variables above, expressions can be used with the following functions and operators: + e.g. 1+1 = 2 - e.g. 1-1 = 0 * e.g. 2*2 = 4 / e.g. 4/2 = 2 ** e.g. 3**2 = 9 sum e.g. sum({1,2,3}) = 6 count e.g. count({4,5,6}) = 3 min e.g. min({1,3,5}) = 1 max e.g. max({1,3,5}) = 5 average e.g. average({1,2,3,4}) = 2.5 median e.g. median({1,2,3,10,15}) = 3 stddev e.g. stddev({1,2,3,4,5}) = 1.4142135623730951 sqrt e.g. sqrt(9) = 3.0 log e.g. log(100) = 2.0 ln e.g. ln(8) = 2.0794415416798357 exp e.g. exp(2) = 7.3890560989306504 (this is ""e**parameter"") floor e.g. floor(1.9) = 1.0 ceiling e.g. ceiling(1.1) = 2.0 abs e.g. abs(-1) = 1 trunc e.g. trunc(1.1123123123) = 1.0 random e.g. random() = 0.20607629744336009 (random float between 0 and 1) randomn e.g. randomn(10) = 4 (random integer between 0 and parameter-1) Note: When using expressions spaces are not allowed! The config Directive The config directive follows the following format: config name value List of allowed configs Example: config defaultToCurrentScreen true Note: the .slate file is read top-down directives that come before config directives may not have the config applied. As such, it is best to put config directives at the top of your .slate file. The alias Directive The alias directive follows the following format: alias name value When you set an alias, you can refer to it in any directive (sequentially after that alias directive) by referencing like ${name}. Example: alias bot-right-2nd-mon move screenOriginX+2*screenSizeX/3;screenOriginY+screenSizeY/2 screenSizeX/3;screenSizeY/2 1 Will allow you to use ${bot-right-2nd-mon} as a reference to move screenOriginX+2*screenSizeX/3;screenOriginY+screenSizeY/2 screenSizeX/3;screenSizeY/2 1 in any directive following the alias (including other alias directives) The layout Directive The layout directive follows the following format: layout name 'app name':OPTIONS operations Where: name = the name you want to use to reference the layout 'app name' = single-quoted name of the application to add to the layout **or** BEFORE or AFTER OPTIONS = a comma separated list of options for this application (cannot be used with BEFORE or AFTER) operations = a pipe separated list of operations (move, resize, push, nudge, throw, or corner) Possible Options: | Name | Function | |:-----|:---------| | IGNORE_FAIL | This will let slate move to the next operation if the current operation fails to resize/move on the current window | | REPEAT | This will repeat the list of operations if the number of windows is larger than the number of operations | | REPEAT_LAST | This will repeat the last operation in the list if the number of windows is larger than the number of operations | | MAIN_FIRST | This will cause the main window to always use the first operation | | MAIN_LAST | This will cause the main window to always use the last operation (mutally exclusive with MAIN_FIRST) | | SORT_TITLE | This will cause the window operations to be triggered on the windows in sorted order by the window title (can be used with MAIN_FIRST or MAIN_LAST) | | TITLE_ORDER=order | This will cause the operations to be triggered on the windows starting with order which is a semi-colon separated list of window titles | | TITLE_ORDER_REGEX=order | This will cause the operations to be triggered on the windows starting with the order which is a semi-colon separated list of window title regexes to match. Note that once a match is seen, the next regex will be used to match. This means if you have two windows that match the same regex, only the first one seen will be matched. The second will not. | You can have multiple layout directives that point to the same name in order to link any number of applications to the same layout. Example: layout myLayout 'iTerm' push up bar-resize:screenSizeY/2 | push down bar-resize:screenSizeY/2 layout myLayout 'Google Chrome' push left bar-resize:screenSizeX/2 | push right bar-resize:screenSizeX/2 layout myLayout BEFORE shell path:~/ '/opt/local/bin/mvim before' layout myLayout AFTER shell path:~/ '/opt/local/bin/mvim after' Will create a layout called myLayout with two operations for iTerm and two operations for Google Chrome. When activated, the first window of iTerm will be moved using the first operation in the first list and the second window of iTerm will be moved using the second operation in the first list. In addition, the first window of Google Chrome will be moved using the first operation in the second list and the second window of Google Chrome will be moved using the second operation in the second list. Finally, the operation shell path:~/ '/opt/local/bin/mvim before' will be run before any Applications are moved and the operation shell path:~/ '/opt/local/bin/mvim after' will be run after any Applications are moved. BEFORE and AFTER may also be used if the layout doesn't have any applications tied to it. Also, you may specify multiple BEFORE or AFTER lines (they will be run in the order that they appear). More information on how to actually use these layouts can be found under the layout operation in the bind directive section. The default Directive The default directive follows the following format (tokens may be separated by any number of spaces): default layout-or-snapshot-name screen-configuration Where: layout-or-snapshot-name = the name of the layout or snapshot you want to default to screen-configuration = either ""count:NUMBER_OF_SCREENS"" or ""resolutions:SEMICOLON_SEPARATED_LIST_OF_RESOLUTIONS"" This directive will cause any screen configuration change (add monitor, remove monitor, screen resolution change) to trigger a search for a default layout or snapshot. If the screen configuration matches one of the defaults set, the layout or snapshot matching layout-or-snapshot-name will be triggered. For example: default myLayout count:2 Will trigger myLayout anytime the screen configuration changes to have 2 monitors. Also: default myLayout2 resolutions:1440x900;1024x768;1680x1050 Will trigger myLayout2 anytime the screen configuration changes to have exactly 3 monitors with resolutions 1440x900, 1024x768, and 1680x1050. The bind Directive The bind directive follows one of the following formats (tokens may be separated by any number of spaces): bind key:modifiers operation parameter+ bind key:modal-key operation parameter+ Key key is a reference to a key on the keyboard. See Allowed Keys for a complete list. For example: the s key would simply be s while the 1 key on the number pad would be pad1. Modifiers modifiers is a comma or semicolon separated list of standard modifier keys. Allowed modifiers are: Control: ctrl Option/Alt: alt Command: cmd Shift: shift Note: If you bind any binding to cmd-tab or cmd-shift-tab, Slate will completely disable the default Mac OS X Application switcher! Note: Bindings that are used by Mac OS X spaces, expose, and mission control will override Slate bindings. Be sure to turn these bindings off if you want to use them in Slate. Modal Key modal-key is any one of the Allowed Keys. If using a modal-key, pressing that key will cause the Slate menu bar icon to change indicating modal mode is activated. then clicking key will activate the binding. Modal mode will remain active until key has been pressed or modal-key is pressed again. You may specify multiple bindings with the same modal-key as long as key is different. Also, modal-key can accompany a comma or semicolon separated list of modifier keys listed above. This will cause that entire keystroke to be considered the modal activation binding. For example: bind 1:f4,ctrl,alt will result in the modal keystroke being ctrl+alt+f4. After pressing that keystroke, modal mode will be activated and pressing 1 after that will activate the binding. Modal Toggle Behavior If you add :toggle to the end of a modal binding it will cause that binding to not end the modal mode. For example with the binding 1:ctrl,f4, you press ctrl+f4 and then press 1 to activate the binding. Once that binding is activated, modal mode will end and you have to press ctrl+f4 again to activate it. However, with the binding 1:ctrl,f4:toggle pressing ctrl+f4 will toggle modal mode. pressing 1 will activate the binding but not end modal mode. To end modal mode, press ctrl+f4 again or use the config modalEscapeKey. Operation Operations define what to actually do to the focused window. Screens Some operations allow you to specify a screen. Here are the list of possible values for screen: Integer representing the screen ID (indexed at 0). Screens are ordered from left to right (by X coordinate of the origin which is the top-left point). If orderScreensLeftToRight is set to false, the screen ID is the Mac OS internal ID (indexed at 0). If orderScreensLeftToRight is set to false but you still want to reference screens in the default ordered mode, prefix the screen ID with ordered:. Screen resolution in the format WIDTHxHEIGHT (e.g. 1440x900) Screen direction relative to the current screen (left|right|up|above|down|below) next or previous (represents the currentID+1 or currentID-1 screen) Allowed operations are: move Move/Resize the window any which way: move topLeftX;topLeftY sizeX;sizeY screen topLeftX = top left x coordinate of the window's desired position (can be an expression) topLeftY = top left y coordinate of the window's desired position (can be an expression) sizeX = width of the window's desired position (can be an expression) sizeY = height of the window's desired position (can be an expression) screen = (optional) the reference to the screen of the window's desired position. If this is not specified, it will default to the screen the window is currently on. See the table at the beginning of the Operation section for more information. Example: bind pad1:ctrl move 0;0 100;100 1 Will bind the keystroke ctrl-numpad1 to moving the window to the screen at index `1` with top-left coordinate `0,0` and size `100,100` **Note:** Remember to offset with `screenOriginX` in your `topLeftX` and `screenOriginY` in your `topLeftY` when using the `screen` option (or when using multiple screens in general) or your move operation will offset from the default origin `(0,0)` which is the origin of screen `0`. resize Resize the window (keeping top-left the same): resize x y anchor x = amount to resize width either as a percent or a hard value (+10% or -100) y = amount to resize height either as a percent or a hard value (+10% or -100) anchor = (optional) which corner to anchor on top-left|top-right|bottom-left|bottom-right (default is top-left) Example: bind right:ctrl resize +10% +0 Will bind the keystroke ctrl-rightarrow to increase the width the current window by `10%`. **Note:** ctrl-rightarrow is used by default in Mac OS X by spaces. Be sure to turn these bindings off if you want to use them in Slate. push Push the window to the edge of the screen: push direction style direction = top|up|bottom|down|left|right style = (optional) none|center|bar|bar-resize:expression (default is none) screen = (optional) the reference to the screen of the window's desired position. If this is not specified, it will default to the screen the window is currently on. See the table at the beginning of the Operation section for more information. Example: bind up:alt,ctrl push up Will bind the keystroke alt-ctrl-uparrow to push the window so that it is aligned with the top of the screen nudge Nudge the window in any direction: nudge x y x = amount to nudge x either as a percent or a hard value (+10% or -100) y = amount to nudge y either as a percent or a hard value (+10% or -100) Example: bind left:ctrl,shift nudge -100 +0 Will bind the keystroke ctrl-shift-leftarrow to nudge the window `100` pixels to the left throw Throw the window to any screen's origin: throw screen style screen = the screen you want to throw the window to (0 indexed) style = (optional) resize|resize:x-expression;y-expression (default will not resize) Example: bind pad1:alt,ctrl throw 1 resize Will bind the keystroke alt-ctrl-numpad1 to throw the window to the 2nd screen and resize it to fit that screen corner Move/Resize the window into a corner: corner direction style direction = top-left|top-right|bottom-left|bottom-right style = (optional) resize:x-expression;y-expression (default will not resize) screen = (optional) the reference to the screen of the window's desired position. If this is not specified, it will default to the screen the window is currently on. See the table at the beginning of the Operation section for more information. Example: bind 1:ctrl corner top-left resize:screenSizeX/2;screenSizeY/2 Will bind the keystroke ctrl-1 to move the window to the top-left corner and resize it to 1/4 of the screen shell Execute a shell command: shell options 'command' command = (required) the command to run. note that it is a quoted string. options = (optional) a space separated list of: wait - block slate until the shell command exits. Useful when using shell commands in a sequence binding path: - the inital working directory to use when starting the command. For example path:~/code would set the inital working directory to ~/code Example: bind 1:ctrl wait path:~/code '/opt/local/bin/mvim' Will bind the keystroke ctrl-1 to run the command `/opt/local/bin/mvim` with the current working directory of `~/code`. Slate will also block until the command is done. Note that you may **not** use the tilda home directory shortcut within the command itself, it is only allowed within the path. hide Hide one or more applications: hide applications applications = a comma separated list of application names. Individual application names must be surrounded by quotes. You can also specify `current`, `all`, or `all-but:` for the Application name (no quotes). `current` will apply to the currently focused application, `all` will apply to all open applications and `all-but:'APP_NAME'` will apply to all open applications except `APP_NAME`. Note that when trying to hide `all` it will not work as intended because OS X will not allow every visible app to be hidden. Hiding `all` will hide all apps but OS X will auto-show one of the apps that were hidden. Example: bind 1:ctrl hide 'iTerm','Google Chrome' Will bind the keystroke ctrl-1 to hide iTerm and Google Chrome. show Show one or more applications: show applications applications = a comma separated list of application names. Individual application names must be surrounded by quotes. You can also specify `current`, `all`, or `all-but:` for the Application name (no quotes). `current` will apply to the currently focused application, `all` will apply to all open applications and `all-but:'APP_NAME'` will apply to all open applications except `APP_NAME`. Example: bind 1:ctrl show 'iTerm','Google Chrome' Will bind the keystroke ctrl-1 to show (unhide) iTerm and Google Chrome. toggle Toggle one or more applications: toggle applications applications = a comma separated list of application names. Individual application names must be surrounded by quotes. You can also specify `current`, `all`, or `all-but:` for the Application name (no quotes). `current` will apply to the currently focused application, `all` will apply to all open applications and `all-but:'APP_NAME'` will apply to all open applications except `APP_NAME`. Note that when trying to toggle `all` it will may not work as intended because OS X will not allow every visible app to be hidden. If at any point during the toggling all apps become hidden, OS X will auto-show one of the apps that were hidden. Example: bind 1:ctrl toggle 'iTerm','Google Chrome' Will bind the keystroke ctrl-1 to toggle iTerm and Google Chrome. Toggle meaning if the individual application is currently hidden it will be shown and if it is currently shown it will be hidden. **Note:** If you specify current in this toggle operation it will not toggle properly because after the current application is hidden, it is no longer the current application anymore. chain Chain multiple operations to one binding: chain opAndParams1 | opAndParams2 ... opAndParamsX = any operation string (except sequence, hint and grid) Example: bind 1:ctrl chain push up | push right | push down | push left Will bind the keystroke ctrl-1 to push up on the first press, then push right on the second press, then push down on the third press, the push left on the fourth press and rotate back to pushing up on the fifth press (etc). sequence Activate a sequence of operations in one binding: sequence opAndParams1 separator opAndParams 2 ... opAndParamsX = any of the above operation strings (except chain and grid. hint must be last if present) separator = | or >. | will cause the next operation to be performed on the window focused at the time of execution of that operation, > will cause the next operation to be performed on the window focused at the start of the > chain. Example: bind 1:ctrl sequence focus right > push left | push right Will bind the keystroke ctrl-1 to first focus the window to the right, then push the previously focused window to the left, then push the newly focused window to the right. Obviously Hint will ignore `>` and `|` and just display because it doesn't care which window was focused. layout Activate a layout: layout name name = the name of the layout to activate (set using the layout directive) Example: bind 1:ctrl layout myLayout Will bind the keystroke ctrl-l to activate the layout called `myLayout`. Note that the layout **must** be created before you bind it. focus Focus a window in a direction or from an application: focus direction|app direction = right|left|up|above|down|below|behind app = an app name surrounded by quotes Example: bind 1:ctrl focus above Will bind the keystroke ctrl-1 to focus the window Slate finds to be above the currently focused window (from any application). Minimized and hidden windows are ignored. A couple global configuration options set using the `config` directive exist to tweak this. Also, up and above are the same. Down and below are also the same. bind 1:ctrl focus 'iTerm' Will bind the keystroke ctrl-1 to focus the main window of the application iTerm. The main window is the last focused window of that application. snapshot Create a snapshot of your current window locations: snapshot name options name = the name of the snapshot to create (used in delete-snapshot and activate-snapshot) options = (optional) a semicolon separated list of any of the following options: save-to-disk -> saves the snapshot to disk so Slate will load it when it starts up next stack -> treats this snapshot as stack so you can use this binding multiple times to push snapshots on the stack Example: bind 1:ctrl snapshot theName save-to-disk;stack Will bind the keystroke ctrl-1 to create a snapshot called `theName`, save that snapshot to disk, and treat it as a stack so you can hit the keystroke multiple times to push snapshots onto the stack. **Note:** There is a menu option to take a snapshot of the current screen configuration. delete-snapshot Delete a snapshot: delete-snapshot name options name = the name of the snapshot to delete options = (optional) a semicolon separated list of any of the following options: all -> if the snapshot is a stack (if it isn't, this option is useless), this will delete all snapshots in the stack (if this option is not specified, the default is to only delete the top snapshot of the stack). Example: bind 1:ctrl delete-snapshot theName all Will bind the keystroke ctrl-1 to delete the snapshot called `theName` if it exists. This will delete all instances of theName meaning if you have pushed multiple snapshots on the stack, it will completely clear them all. activate-snapshot Activate a snapshot: activate-snapshot name options name = the name of the snapshot to activate options = (optional) a semicolon separated list of any of the following options: delete -> this will delete the snapshot after activating it (if the snapshot is a stack, it will pop the top snapshot off and keep the rest) Example: bind 1:ctrl activate-snapshot theName delete Will bind the keystroke ctrl-1 to activate the snapshot called `theName` if it exists. This will also delete the snapshot (or pop it off the stack if the snapshot is a stack). **Note:** There is a menu option to activate the snapshot that you may have created using the menu option. hint Show Window Hints (similar to Link Hints in Vimium except for Windows): hint characters characters = (optional) a simple string of characters to be used for the hints. each hint consists of one character. if there are more windows than characters then some windows will not get hints. this string can contain any of the single character Allowed Keys. Letters may be upper case or lower case, but both will be bound to the lowercase letter for the hint. Using upper or lower case only changes how they are displayed. The default string of characters is ""ABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789"" Example: bind 1:ctrl hint QWERTYUIOP Will bind the keystroke ctrl-1 to show Window Hints using the letters `Q`, `W`, `E`, `R`, `T`, `Y`, `U`, `I`, `O`, and `P`. This will show an overlay in the top-left corner of every window on screen containing one of those letters. While the overlays are showing, if one of those letters is pressed, the corresponding window will be focused. If there are more than 10 windows, some windows will not get hints. Pressing ESC will dismiss the hints. **Note:** There are *tons* of config options to tweak this. grid Show a Grid to one-off resize and move windows: grid options options is a whitespace separated list of: padding:<integer> = the padding between cells screenRef:width,height = width and height are integers specifying the width and height of the grid (number of cells, not absolute size). screenRef is either the screenID or screen resolution (widthxheight) Example: bind 1:ctrl grid padding:5 1680x1050:16,9 1050x1680:9,16 Will bind the keystroke ctrl-1 to show Grids on each screen. The default width and height are 12. This will set the padding between the cells to be 5. Also, this will change the width and height of the grid on the monitor with the resolution 1680x1050 to 16 and 9 respectively. For the monitor with the resolution 1050x1680, it will set the width to 9 and height to 16. If you have multiple monitors, the Grid that is on the same screen as your mouse pointer will be focused. If you want to use a grid on a different monitor you **must** click it first and then click+drag. **Note:** There are a bunch of config options to tweak how this looks. relaunch Relaunch Slate: relaunch Example: bind 1:ctrl relaunch Will bind the keystroke ctrl-1 to relaunch Slate. This will also reload the `.slate` file from scratch. undo Undo an Operation: undo Example bind 1:ctrl undo Will bind the keystroke ctrl-1 to undo the last binding that was triggered. By default you can undo up to the last 10 commands. This can be changed using the `undoMaxStackSize` config. Also, you can only undo movement-based operations. Focus-related operations will not undo. switch [Beta] A Better Application Switcher: switch If you bind any binding to cmd-tab or cmd-shift-tab, Slate will completely disable the default Mac OS X Application switcher! Example: bind tab:cmd switch Will disable the default Mac OS X Application switcher and bind the keystroke cmd-tab to a better application switcher. **Note:** There are *tons* of config options to tweak this. The source Directive The source directive follows the following format (tokens may be separated by any number of spaces): source filename optional:if_exists Where filename is the name of a file containing any of the directives above (including source). If no absolute path is specified, the user's home directory will be prepended to filename. If the user specifies the option if_exists as the second argument, Slate will not complain if it cannot find the file. For Example: source ~/.slate.test if_exists Will append all of the configurations from the file ~/.slate.test to the current configuration if the file ~/.slate.test exists. Note: You may use any aliases, layouts, etc that you specify before the source directive in the file you source. Any aliases, layouts, etc specified after cannot be used. Additionally, any aliases, layouts, etc that you specify in the file you source can be used after the source directive. Example Config You can check out my own config here. Useful Stuff kvs has created a Sublime Text 2 preference for .slate files here. trishume has done a really nice writeup on getting started with Slate here Contact Please send all questions, bug reports, suggestions, or general commentary to Jigish Patel or create an issue on github. Allowed Keys Note: If you bind any binding to cmd-tab or cmd-shift-tab, Slate will completely disable the default Mac OS X Application switcher! ' , - . / 0 1 2 3 4 5 6 7 8 9 ; = ` a b backslash c caps d delete down e end esc f f1 f10 f11 f12 f13 f14 f15 f16 f17 f18 f19 f2 f20 f3 f4 f5 f6 f7 f8 f9 g h help home i j k l left m mute n o p pad* pad+ pad- pad. pad/ pad0 pad1 pad2 pad3 pad4 pad5 pad6 pad7 pad8 pad9 pad= padClear padEnter pageDown pageUp q r return right s space t tab u up v w x y z [ ]"
4280,"A feed parsing libraryFeedjira Feedjira is a Ruby library designed to parse feeds. Installation Add this line to your application's Gemfile: Parsing An example of parsing a feed with Feedjira: Specifying parser If you have the XML and just want to provide a parser class for one parse, you can specify that using parse with the parser option: Adding attributes to all feeds types / all entries types Adding attributes to only one class If you want to add attributes for only one class you simply have to declare them in the class Configuration Parsers Adding a custom parser You can insert your own parser at the front of the available parser list by: Now when you call Feedjira.parse, MyAwesomeParser will be the first one to get a chance to parse the feed. Explicitly set all available parsers Feedjira can be configured to use a specific set of parsers and in a specific order: Stripping whitespace from XML Feedjira can be configured to strip all whitespace but defaults to lstrip only: Contributing Bug reports and pull requests are welcome on GitHub at https://github.com/feedjira/feedjira. This project is intended to be a safe, welcoming space for collaboration, and contributors are expected to adhere to the Contributor Covenant code of conduct. Projects that use Feedjira Feedjira is used in some awesome projects around the web - from RSS readers to add-ons and everything in between. Here are some of them: Feedbin: Feedbin bills itself as a fast, simple RSS reader that delivers a great reading experience. It's a paid RSS reader that integrates with mobile apps and it even has a fully featured API! Stringer: Stringer is a self-hosted, anti-social RSS reader. It's an open-source project that's easy to deploy to any host, there's even a one-click button to deploy on Heroku. BlogFeeder: BlogFeeder is a paid Shopify App that makes it easy for you to import any external blog into your Shopify store. It helps improve your store's SEO and keeps your blogs in sync, plus a lot more. Feedbunch: Feedbunch is an open source feed reader built to fill the hole left by Google Reader. It aims to support all features of Google Reader and actually improve on others. The Old Reader: The Old Reader advertises as the ultimate social RSS reader. It's free to start and also has a paid premium version. There's an API and it integrates with many different mobile apps. Solve for All: Solve for All combines search engine and feed parsing while protecting your privacy. It's even extendable by the community! Feedi API: Feedi simplifies how you handle RSS, Atom, or JSON feeds. You can add and keep track of your favourite feed data with a simple and clean REST API. All entries are enriched by Machine Learning and Semantic engines. Breaker: The social podcast app Huginn: Huginn is a system for building agents that perform automated tasks for you online. Note: to get your project on this list, simply send an email with your project's details."
2633,"Simple, lightweight, persistent two-way databindingway.js Simple, lightweight, persistent, framework-agnostic two-way databinding Javascript library. With no to little JS code to write. And no dependencies. Demo Codepen jsFiddle Buy us coffee: Gittip Follow us on Twitter: @way_js The following documentation is also available in Chinese (credits: @wuyunjiang). Quick start Declare an HTML element with some tags. Boom. Now every change in the form will be stored in-memory. The bound span's html will be changed on the fly. And the bound data will be persistent, meaning your HTML will be populated with your data on page reloads. Enough talk, see it in action. Installation [Step 1] Include the library to your page. 1.a. via NPM then 1.b. or [Step 2] There is no step 2. You are good to go. Options Options can be passed via data attributes or JavaScript. For data attributes, append the option name to way-, as in way-data="""". Set these options to the elements that have to be bound. Name | Type | Default | Description ----|------|---- | ---- data | string | null | Allows to define the dot separated path where the data will be stored. Can include arrays. When used on a form, a json variable made of all the included inputs with a name attribute will be created and stored in the specified storage. Pass the ""__all__"" path to access all way.js' data. default | string | null | A link to a default data to set on an element, in case there is no bound value. persistent | boolean | true | Allows to store the data to localStorage everytime the bound data changes. readonly | boolean | false | Prevents the element changes from resetting the bound value. writeonly | Boolean | false | Prevents the element from getting changed when the bound value changes. json | boolean | false | Returns pretty-printed json data to its DOM element. html | boolean | false | Declares whether the data attributed to an element should be parsed as HTML or not. pick | array | null | A comma separated list of values to pick (in forms only) to sync with the storage. By default, all form inputs are synced. omit | array | null | A comma separated list of values (in forms only) to not sync with the storage. By default, no form input is omitted. Some examples: Scopes You can set scopes to your DOM elements' data. [way-scope] attribute Passing this attribute to an element will point all its children's ""way-data"" attributes to this scope. Scopes can be nested. [way-scope-break] attribute Breaks a scope chain. All the child elements of this one will have no scope set. scope() method Returns the scope of a given DOM element Repeats Duplicates a DOM element for each of the values it can loop through in a way.js' passed data. Notes: - Repeat blocks automatically set the appropriate scope to their child elements. - On each loop, ""$$key"" corresponds to the key of the current element looped. Having this: Will render that: Transforms Transforms the displayed data bound to your DOM elements. [way-transform] attribute Pass transform functions by name. Add multiple transforms by separating them with the ""|"" symbol. In case of conflicts between transforms, the last mentionned transform wins. Some pre-build transforms [PR welcome for more!] Name | Description | Example ----|------|---- uppercase | Sets a string to uppercase | ""hello"" becomes ""HELLO"" lowercase | Sets a string to lowercase | ""HELLO"" becomes ""hello"" reverse | Reverses a string | ""hello"" becomes ""olleh"" registerTransform(name, transform) method Adds a new transform. Helper elements Allows to perform simple tasks on your way.js' data with a click. Attribute | Description ---- | ------ way-action-remove | Removes a way data way-action-push | if provided with an array, pushes an null value to it Example: Helper classes For images only way.js adds classes to your DOM elements to easily detect load / error / success statuses with the data they get passed. Class | Description ---- | ------ way-loading | When an image is getting downloaded to a DOM element way-error | When no image is returned from the URL provided way-success | When... Well, you got it. Methods Everything should be done for you from the HTML tags. But if necessary, you can also use helper functions to interact with your stored data and DOM elements. Notes: - [element] refers to the CSS selector of a DOM element. - options is optional. By default, options are read from the HTML tags of the elements. But you can overwrite them, by passing this parameter. DOM methods way.dom(element).toStorage(options) Stores the element's value to the in-store memory. way.dom(element).fromStorage(options) Sets the element's value from the stored one. way.dom(element).toJSON(options) Returns a JSON with the parsed data of the input (particularly handy for forms). way.dom(element).fromJSON(data, options) Sets the element's value from any data (in json). way.dom(element).getValue() Returns a structured JSON containing the value of the DOM element. way.dom(element).setValue(value, options) Sets the element's value from any data (in json). way.dom(element).setDefault(force) Sets the default value of an element. By default, only the DOM element gets its value set to the default value. Its bound value in the datastore in unchanged. Pass a [force] parameter if you need to force setting in-memory value of this data to the element's default value. way.setDefaults(force) Sets all the default values of bound DOM elements. way.dom(element).getOptions() Returns the list of the [""way-""] options attributed to a DOM element. Data methods way.get(selector) Returns the value of the data stored under a given pathname. way.set(selector, value, options) Saves the data in memory under the specified pathname. way.remove(selector, options) Removes the data stored under a given pathname. way.clear(options) Clears all the data localStorage methods way.backup() Stores the data saved in way.js' datastore to localStorage. way.restore() Restores the data saved in localStorage. Called on $(document).ready by default (can be changed with global options). Binding methods way.registerBindings() Triggers a scan of the DOM to find and save the elements with the [way-data] attribute, that will be bound with some data. way.updateBindings(selector) Sets the value of all the DOM elements binded to a data selector with their values in way.js' datastore. If omitted, all (excluding write-only's and omitted) DOM elements with a ""way-data="" attribute will be refreshed. Repeat methods way.registerRepeats() Triggers a scan of the DOM to find and save the elements with the [way-repeat] attribute, that will be bound with some data. way.updateRepeats(selector) Triggers a refresh of the repeat elements with their respective data. Watcher methods way.watch(selector, callback[value]) Watches changes of a given value. way.watchAll(callback[selector, value]) Watches all changes in way.js' datastore. Global options way.options.persistent (Boolean) Sets whether or not data will be restored from localStorage on document.ready (true by default). way.options.timeoutInput (Number) Number of milliseconds of the timeout between keypresses on bound elements to store their values to the datastore (50 by default). way.options.timeoutDOM (Number) Number of milliseconds of the timeout between scans of the DOM to list bound elements on each DOM change (500 by default). To do document a bit more the code test enjoy Integrations Meteor To be coming Contribute Fork & pull request. If you planning add some feature please create issue before. Otherwise changes will be rejected. Licence The MIT License Copyright (c) 2014 Gwendall Esnault gwendall.esnault@gmail.com Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the ""Software""), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
1962,"A statuspage generator that lets you host your statuspage for free on Github.We are currently alpha-testing a fully automated statuspage GitHub app. Check out corestatus.io if you like to test it out. Statuspage A statuspage generator that lets you host your statuspage for free on GitHub. Uses issues to display incidents and labels for severity. Demo See a real status page generated by this here demo site Quickstart Install statuspage with pip: pip install statuspage There are also binaries for macOS and Linux available, see installation for more. Now, create an GitHub API token: Go to your Personal Access tokens page. Click on Generate new token. Make sure to check the public_repo and write:repo_hook scope. Copy the token somewhere safe, you won't be able to see it again once you leave the page. To create a new status page, run: statuspage create --token=<yourtoken> You'll be prompted for a repo name and the systems you want to show a status for. Name: mystatuspage Systems, eg (Website,API): Website, CDN, API Please note: This will generate a new repo under that name. Make sure it doesn't exist already. The command takes a couple of seconds to run. Once ready, it will output links to the issue tracker and your new status page. Create new issues at https://github.com/<login>/mystatuspage/issues Visit your new status page at https://<login>.github.com/mystatuspage/ The generator will then print the statuspage update command filled with all the details you need to update your page. Create an issue To create a new issue, go to your newly created repo and click on New Issue. Click on the cog icon next to labels on the right. Choose the affected systems (black labels) Choose a severity label (major outage, degraded performance, investigating) Fill in the title, leave a comment and click on Submit new issue. Now, update your status page. Go back to your commandline and type: statuspage update --token=<yourtoken> Name: mystatuspage If you change the issue (eg. when you add a new label, create a comment or close the issue), you'll need to run statuspage update again. Adding and removing systems In order to add or remove a system, run: statuspage add_system --token=<token> --name=<repo> --system=<system to add> statuspage remove_system --token=<token> --name=<repo> --system=<system to remove> Upgrading from previous versions First, install the latest version with pip, or grab the latest binary: pip install statuspage --upgrade Updating your page to the latest version is now as simple as running: statuspage upgrade --token=<token> --name=<repo> followed by an update: statuspage update --token=<token> --name=<repo> Translations The generated status page is translated via JavaScript on the client side using webL10n. It detects the visitors preferred language and translates all strings automatically. Translations are available for the following languages: en de nl pt es ru fr pl Want to add a translation? Open translations.ini and add it. Pull requests welcome! Customizing Want to change styles, the logo, or the footer? Check out customizing. Options Want to create a status page for an organisation, or a private one? See options."
4162,"This is not an official Facebook product, and is not affiliated with, or sponsored or endorsed by, Facebook.Messenger for Desktop 2 UNMAINTAINED -- Caprine is a nice alternative A simple & beautiful desktop client for Facebook Messenger. Chat without distractions on OS X, Windows and Linux. Not affiliated with Facebook. This is NOT an official product. @devs: If you're willing to help improve, fix or maintain the app, I can make you a collaborator to help me. Join me on Gitter and let's chat! Sponsors Thanks! Features :star: Themes & Mini Mode Native Notifications (with reply on OS X) Spell Checker & Auto Correct Support for Facebook for Work Keyboard Shortcuts Launch on OS startup Automatic Updates How to install Note: If you download from the releases page, be careful what version you pick. Releases that end with -beta are beta releases, the ones that end with -dev are development releases, and the rest are stable. If you're unsure which to pick, opt for stable. Once you download the app, you'll be able to switch to another channel from the menu. dev: these releases get the newest and hottest features, but they are less tested and might break things beta: these releases are the right balance between getting new features early while staying away from nasty bugs stable: these releases are more thoroughly tested; they receive new features later, but there's a lower chance that things will go wrong If you want to help me make Messenger for Desktop better, I recommend dev or beta. Let's go! OS X DMG or zip: Download messengerfordesktop-x.x.x-osx.dmg or messengerfordesktop-x.x.x-osx.zip Open or unzip the file and drag the app into the Applications folder Done! The app will update automatically Using brew: Run brew cask install messenger-for-desktop in your terminal The app will be installed in your Applications Done! The app will update automatically (you can also use brew) Windows Installer (recommended): Download messengerfordesktop-x.x.x-win32-nsis.exe Run the installer, wait until it finishes Done! The app will update automatically Portable: Download messengerfordesktop-x.x.x-win32-portable.zip Extract the zip wherever you want (e.g. a flash drive) and run the app from there Done! The app will NOT update automatically, but you can still check for updates Linux Ubuntu, Debian 8+ (deb package): Download messengerfordesktop-x.x.x-linux-arch.deb Double click and install, or run dpkg -i messengerfordesktop-x.x.x-linux-arch.deb in the terminal Start the app with your app launcher or by running messengerfordesktop in a terminal Done! The app will NOT update automatically, but you can still check for updates You can also use apt-get (recommended): Fedora, CentOS, Red Hat (RPM package): Download messengerfordesktop-x.x.x-linux-arch.rpm Double click and install, or run rpm -ivh messengerfordesktop-x.x.x-linux-arch.rpm in the terminal Start the app with your app launcher or by running messengerfordesktop in a terminal Done! The app will NOT update automatically, but you can still check for updates You can also use yum (recommended): Arch Linux (AUR): Simply run yaourt -S messengerfordesktop Start the app with your app launcher or by running messengerfordesktop in a terminal Done! The app will NOT update automatically, but you can still check for updates Repository URL: https://aur.archlinux.org/packages/messengerfordesktop/ For Developers Contributions are welcome! Please help me make Messenger for Desktop the best app for Facebook Messenger. For feature requests and bug reports please submit an issue or get in touch with me on Gitter or Twitter @aluxian. Build Note: for some tasks, a GitHub access token might be required (if you get errors, make sure you have this token). After you generate it (see here if you need help; repo permissions are enough), set it as an env var: - Unix: export GITHUB_TOKEN=123 - Windows: set GITHUB_TOKEN=123 Install pre-requisites If you want to build deb and rpm packages for Linux, you also need fpm. To install it on OS X: Install dependencies Global dependencies: Local dependencies: Native modules The app uses native modules. Make sure you rebuild the modules before building the app: Build and watch During development you can use the watch tasks, which have live reload. As you edit files in ./src, they will be re-compiled and moved into the build folder: If you want to build it just one time, use build: For production builds, set NODE_ENV=production or use the --prod flag. Production builds don't include dev modules. To see detailed logs, run every gulp task with the --verbose flag. If you don't specify a platform when running a task, the task will run for the current platform. App debug logs To see debug messages while running the app, set the DEBUG env var. This will print logs from the main process. To open the webview dev tools, type this in the main dev tools console: If you want to automatically open the webview dev tools, use: Pack OS X You'll need to set these env vars: Pack the app in a neat .dmg: This uses node-appdmg which works only on OS X machines. Windows You'll need to set these env vars: Create an installer. This will also sign every executable inside the app, and the setup exe itself: Or, if you prefer, create a portable zip. This will also sign the executable: These tasks only work on Windows machines due to their dependencies: Squirrel.Windows and Microsoft's SignTool. Linux Create deb/rpm packages: Make sure you've installed fpm. Release flow develop -> staging -> deploy -> master All work is done on branch develop. Every push to develop will make the CIs run code linting and other checks. In order to build, push to staging. Every push to staging will make the CIs build the app and upload it to Bintray at aluxian/artifacts, available for testing. After a version is tested and is ready for release, push it to deploy. This will rebuild the app and upload it to GitHub, Bintray and other repositories. Now, the code is ready to be merged into master."
893,"Elegant transition library for iOS & tvOS Hero is a library for building iOS view controller transitions. It provides a declarative layer on top of the UIKit's cumbersome transition APIsmaking custom transitions an easy task for developers. Hero is similar to Keynote's Magic Move. It checks the heroID property on all source and destination views. Every matched view pair is then automatically transitioned from its old state to its new state. Hero can also construct animations for unmatched views. It is easy to define these animations via the heroModifiers property. Hero will run these animations alongside the Magic Move animations. All of these animations can be interactively controlled by user gestures. At view controller level, Hero provides several template transitions that you can set through heroModalAnimationType, heroNavigationAnimationType, and heroTabBarAnimationType. These can be used as the foundation of your custom transitions. Combine with heroID & heroModifiers to make your own unique transitions. By default, Hero provides dynamic duration based on the Material Design Motion Guide. Duration is automatically determined by changes to distance and sizesaving you the hassle, while providing consistent and delightful animations. Hero doesn't make any assumptions about how the view is built or structured. It won't modify any of your views' states other than hiding them during the animation. This makes it work with Auto Layout, programmatic layout, UICollectionView (without modifying its layout object), UITableView, UINavigationController, UITabBarController, etc... Usage Example 1 View Controller 1 View Controller 2 Usage Example 2 View Controller 1 View Controller 2 You can do these in the storyboard too! Installation CocoaPods Add the following entry to your Podfile: Then run pod install. Don't forget to import Hero in every file you'd like to use Hero. Carthage Add the following entry to your Cartfile: Then run carthage update. If this is your first time using Carthage in the project, you'll need to go through some additional steps as explained over at Carthage. Accio Add the following to your Package.swift: Next, add Hero to your App targets dependencies like so: Then run accio update. Swift Package Manager To integrate using Apple's Swift package manager, add the following as a dependency to your Package.swift: and then specify ""Hero"" as a dependency of the Target in which you wish to use Hero. Here's an example PackageDescription: Manually Drag the Sources folder anywhere in your project. Documentations Checkout the WIKI PAGES (Usage Guide) for documentations. For more up-to-date ones, please see the header-doc. (use alt+click in Xcode) Interactive Transition Tutorials Interactive transitions with Hero (Part 1) FAQ Not able to use Hero transition even when self.hero.isEnabled is set to true Make sure that you have also enabled self.hero.isEnabled on the navigation controller if you are doing a push/pop inside the navigation controller. Views being covered by another matched view during the transition Matched views use global coordinate space while unmatched views use local coordinate space by default. Local coordinate spaced views might be covered by other global coordinate spaced views. To solve this, use the useGlobalCoordinateSpace modifier on the views being covered. Checkout Coordinate Space Wiki page for details. Push animation is shown along side my custom animation This is the default animation for navigation controller provided by Hero. To disable the push animation, set self.hero.navigationAnimationType to .fade or .none on the navigation controller. How do I use a different default animation when dismissing You can use the animation type .selectBy(presenting:dismissing) to specify a different default animation for dismiss. For example: Contribute We welcome any contributions. Please read the Contribution Guide."
2603,"A quick introduction to DockerDocker Jumpstart, by Andrew Odewahn This is the source for the Docker Jumpstart, a short guide by Andrew Odewahn from O'Reilly Media to help you get up and running with Docker. Its table of contents is: Introduction. A basic intro about what Docker is and isn't. boot2docker. How to get Docker running on Mac or Windows. Images: Layered filesystems. A brief explanation of images and layers. Containers: Running instances of an Image. Using docker run to turn a static image into a running container. Creating your own Docker Image. Putting everything together to make your own images. Building images with Dockerfiles. Dockerfiles, a lightweight IA tool to describe an image's contents. Sharing images on Docker Hub. Finding and sharing images with the world. Additional Resources. Where to learn more once you've mastered the basics of Docker. Topics I'd love to cover in more depth are in the wishlist directory. Most of this stuff is just a place to keep links and research will (OK, might) someday lead to a more in-depth coverage. Contributing This book is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License. I encourage you to fork my work and make your own improvements under the terms of the license. If you have any changes you want to send back our way, please make a regular pull request via Github. If the authors like your changes, they may integrate them into the official repo and give you a credit. If you just have an issue to report, please use the regular Github issue system. Running the site locally The site uses harpjs to build a site and Atlas to build the PDF, mobi, and epub. To build the site: Install harp. Clone the repo Run harp server --port 4567 When you want to build the site, clone the repo down again into another directory, create a gh-pages branch, and then run harp compile . _new directory_"
471,"Next-generation ES module bundlerRollup Overview Rollup is a module bundler for JavaScript which compiles small pieces of code into something larger and more complex, such as a library or application. It uses the standardized ES module format for code, instead of previous idiosyncratic solutions such as CommonJS and AMD. ES modules let you freely and seamlessly combine the most useful individual functions from your favorite libraries. Rollup can optimize ES modules for faster native loading in modern browsers, or output a legacy module format allowing ES module workflows today. Quick Start Guide Install with npm install --global rollup. Rollup can be used either through a command line interface with an optional configuration file, or else through its JavaScript API. Run rollup --help to see the available options and parameters. The starter project templates, rollup-starter-lib and rollup-starter-app, demonstrate common configuration options, and more detailed instructions are available throughout the user guide. Commands These commands assume the entry point to your application is named main.js, and that you'd like all imports compiled into a single file named bundle.js. For browsers: For Node.js: For both browsers and Node.js: Why Developing software is usually easier if you break your project into smaller separate pieces, since that often removes unexpected interactions and dramatically reduces the complexity of the problems you'll need to solve, and simply writing smaller projects in the first place isn't necessarily the answer. Unfortunately, JavaScript has not historically included this capability as a core feature in the language. This finally changed with ES modules support in JavaScript, which provides a syntax for importing and exporting functions and data so they can be shared between separate scripts. Most browsers and Node.js support ES modules. However, Node.js releases before 12.17 support ES modules only behind the --experimental-modules flag, and older browsers like Internet Explorer do not support ES modules at all. Rollup allows you to write your code using ES modules, and run your application even in environments that do not support ES modules natively. For environments that support them, Rollup can output optimized ES modules; for environments that don't, Rollup can compile your code to other formats such as CommonJS modules, AMD modules, and IIFE-style scripts. This means that you get to write future-proof code, and you also get the tremendous benefits of... Tree Shaking In addition to enabling the use of ES modules, Rollup also statically analyzes and optimizes the code you are importing, and will exclude anything that isn't actually used. This allows you to build on top of existing tools and modules without adding extra dependencies or bloating the size of your project. For example, with CommonJS, the entire tool or library must be imported. But with ES modules, instead of importing the whole utils object, we can just import the one ajax function we need: Because Rollup includes the bare minimum, it results in lighter, faster, and less complicated libraries and applications. Since this approach is based on explicit import and export statements, it is vastly more effective than simply running an automated minifier to detect unused variables in the compiled output code. Compatibility Importing CommonJS Rollup can import existing CommonJS modules through a plugin. Publishing ES Modules To make sure your ES modules are immediately usable by tools that work with CommonJS such as Node.js and webpack, you can use Rollup to compile to UMD or CommonJS format, and then point to that compiled version with the main property in your package.json file. If your package.json file also has a module field, ES-module-aware tools like Rollup and webpack will import the ES module version directly. Contributors This project exists thanks to all the people who contribute. [Contribute]. Backers Thank you to all our backers! [Become a backer] Sponsors Support this project by becoming a sponsor. Your logo will show up here with a link to your website. [Become a sponsor] License MIT"
468,"Open Source multi-language/multi-currency/multi-store E-commerce platform for Ruby on Rails with a modern UX, PWA frontend, REST API, GraphQL, several official extensions, and 3rd party integrations. Spree Commerce Success Stories Documentation Integrations Spree is a complete open source e-commerce solution built with Ruby on Rails. It was started by Sean Schofield and is now developed by Spark Solutions. We're open to contributions. Key Features Headless Commerce - build mobile apps or custom storefronts in any technology PWA - offline shopping experiences like native mobile apps Mobile-first Storefront - modern, ultra fast and responsive storefront designed for great UX as well as SEO Global Commerce - multi currency and multi language support out of the box, different shipping methods / costs for different regions, advanced tax calculation Multi-Store - host multiple brands / stores on one Spree instance with different branding, configuration, payment methods, shipping options, product catalogs etc Responsive Admin Panel - manage and curate products, users, orders, returns, shipments & more Orders - robust system for orders, shipments, returns and refunds Carts - comprehensive and advanced discounts system Payments - over 30 payment provider integration out of the box plus API to integrate any other gateway Run everywhere - cloud, VPS, Docker, Kubernetes Battle Tested - used by thousands of merchants around the globe in all categories since 2007! Fully customizable - pick and choose parts you want to use and customize everything else (storefront, order processing, API, etc) to create unique solutions that your business requires More features available via extensions - dozens of extensions built by community, ready for use for free! Demo See Spree in action: demo.spreecommerce.org Or fire up your own demo on Heroku: Admin panel credentials for your own Heroku demo: login: spree@example.com password: spree123 Installation Option A - use Spree Starter with Docker Install Docker Download Spree Starter Unzip it Run bin/setup in spree_starter-main directory Option B - add Spree to an existing Ruby on Rails application Please follow Add Spree to an existing Ruby on Rails application tutorial Documentation Go to Spree Guides Extensions Extensions provide additional features and integrations for your Spree store Go to Extensions Directory Contributing Spree is an open source project and we love contributions in any form - pull requests, issues, feature ideas! Please review the Contributing Guide License Spree is released under the New BSD License. About Spark Solutions Spark Solutions is a software development agency specialized in Ruby on Rails, Spree Commerce and Javascript development. Weve been leading Spree open-source efforts since 2016 as its core team. We also do client work. Our project teams consist of UX and UI designers, Software Engineers, Testers and Project Managers practicing agile project delivery. Well integrate our team with yours to jointly architect, deliver, maintain and scale the software products you need. You drive the project with requirements and acceptance testing and we help you deliver faster using industry-standard project management and comms best practices. We are passionate about open source software. We are available for hire."
859," The missing package manager for macOS (or Linux)Homebrew Features, usage and installation instructions are summarised on the homepage. Terminology (e.g. the difference between a Cellar, Tap, Cask and so forth) is explained here. What Packages Are Available? Type brew formulae for a list. Or visit formulae.brew.sh to browse packages online. Or use brew search --desc <keyword> to browse packages from the command line. More Documentation brew help, man brew or check our documentation. Troubleshooting First, please run brew update and brew doctor. Second, read the Troubleshooting Checklist. If you don't read these it will take us far longer to help you with your problem. Contributing We'd love you to contribute to Homebrew. First, please read our Contribution Guide and Code of Conduct. We explicitly welcome contributions from people who have never contributed to open-source before: we were all beginners once! We can help build on a partially working pull request with the aim of getting it merged. We are also actively seeking to diversify our contributors and especially welcome contributions from women from all backgrounds and people of colour. A good starting point for contributing is running brew audit --strict with some of the packages you use (e.g. brew audit --strict wget if you use wget) and then read through the warnings, try to fix them until brew audit --strict shows no results and submit a pull request. If no formulae you use have warnings you can run brew audit --strict without arguments to have it run on all packages and pick one. Alternatively, for something more substantial, check out one of the issues labeled help wanted in Homebrew/brew or Homebrew/homebrew-core. Good luck! Donations Homebrew is a non-profit project run entirely by unpaid volunteers. We need your funds to pay for software, hardware and hosting around continuous integration and future improvements to the project. Every donation will be spent on making Homebrew better for our users. Please consider a regular donation through GitHub Sponsors or Patreon. Alternatively, if you'd rather make a one-off payment: Donate with PayPal Donate by USA $ check from a USA bank: Make check payable to ""Software Freedom Conservancy, Inc."" and place ""Directed donation: Homebrew"" in the memo field. Checks should then be mailed to: Software Freedom Conservancy, Inc. 137 Montague ST STE 380 BROOKLYN, NY 11201 USA Donate by wire transfer: contact accounting@sfconservancy.org for wire transfer details. Homebrew is a member of the Software Freedom Conservancy which provides us with an ability to receive tax-deductible, Homebrew earmarked donations (and many other services). Software Freedom Conservancy, Inc. is a 501(c)(3) organization incorporated in New York, and donations made to it are fully tax-deductible to the extent permitted by law. Security Please report security issues to our HackerOne. Who We Are Homebrew's Project Leader is Mike McQuaid. Homebrew's Project Leadership Committee is Issy Long, Jonathan Chang, Markus Reiter, Misty De Meo and Sean Molenaar. Homebrew's Technical Steering Committee is Bo Anderson, FX Coudert, Michka Popoff, Mike McQuaid and Rylan Polster. Homebrew's Linux maintainers are Daniel Nachun, Dawid Dziurla, Issy Long, Jonathan Chang, Michka Popoff and Shaun Jackman. Homebrew's other current maintainers are Alexander Bayandin, Caleb Xu, Carlo Cabrera, Claudia Pellegrino, Dustin Rodrigues, Eric Knibbe, Maxim Belkin, Miccal Matthews, Nanda H Krishna, Randall, Sam Ford, Steve Peters, Thierry Moisan, Tom Schoonjans, Vtor Galvo and rui. Former maintainers with significant contributions include Jan Viljanen, JCount, commitay, Dominyk Tiller, Tim Smith, Baptiste Fontaine, Xu Cheng, Martin Afanasjew, Brett Koonce, Charlie Sharpsteen, Jack Nagel, Adam Vandenberg, Andrew Janke, Alex Dunn, neutric, Tomasz Pajor, Uladzislau Shablinski, Alyssa Ross, ilovezfs, Chongyu Zhu and Homebrew's creator: Max Howell. Community Homebrew/discussions (forum) @MacHomebrew (Twitter) License Code is under the BSD 2-clause ""Simplified"" License. Documentation is under the Creative Commons Attribution license. Sponsors Our macOS continuous integration infrastructure is hosted by MacStadium's Orka. Secure password storage and syncing is provided by 1Password for Teams. Homebrew is a member of the Software Freedom Conservancy. Homebrew is generously supported by Substack, GitHub, Randy Reddig, embark-studios, Realist.ai and many other users and organisations via GitHub Sponsors."
2948," create a single executable out of your node.js apps npm i nexe -g Nexe is a command-line utility that compiles your Node.js application into a single executable file. Motivation and Features Self contained applications Ability to run multiple applications with different node.js runtimes. Distribute binaries without needing node / npm. Idempotent builds Start and deploy faster. Lockdown specific application versions, and easily rollback. Flexible build pipeline Cross platform builds Usage Application entrypoint: nexe my-app.js stdin interface rollup -c | nexe --resource ""./public/**/*"" -o my-app.exe For more CLI options see: nexe --help Examples nexe server.js -r ""public/**/*.html"" nexe --build nexe -t x86-8.0.0 Resources Additional files or resources can be added to the binary by passing -r ""glob/pattern/**/*"". These included files can be read in the application by using fs.readFile or fs.readFileSync. Compiling Node By default nexe will attempt to download a pre-built executable. These are listed on the Nexe V3 releases page. The exact version you want may be unavailable or you may want to customize what is built. See nexe --help for a list of options available when passing the --build option. You will also need to ensure your environment is setup to build node. Note: the python binary in your path should be an acceptable version of python 2. eg. Systems that have python2 will need to create a symlink. Node.js API Example NexeOptions options: object input: string Input bundle file path default: stdin or the current directory's main file (package.json) output: string Output executable file path default: same as name with an OS specific extension. target: string | object An object or string describing platform-arch-version. e.g. 'windows-ia32-10.13.0' each segment is optional, and will be merged with the current environment Examples: (full list) 'win32-x86-10.13.0 { platform: 'alpine' } darwin-10.13.0 linux-x64 macos-10.13.0 See test/target.spec.ts - If the build flag is set, the platform portion of the target is ignored. - default: process - #### bundle: string | boolean - If a string is provided it must be a valid relative module path and should provide an export with the following signature: default: true name: string Module friendly name of the application default: basename of the input file, or nexe_${Date.now()} cwd: string Directory nexe will operate on as though it is the cwd default: process.cwd() mangle: boolean If set to false, nexe will not include the virtual filesystem (your application and resources) on the output. This will cause the output to error as an ""Invalid Binary"" unless a userland patch alters the contents of lib/_third_party_main.js in the nodejs source. default: true build: boolean Build node from source, passing this flag tells nexe to download and build from source. Subsequently using this flag will cause nexe to use the previously built binary. To rebuild, first add --clean remote: string Provide a custom remote location for fetching pre-built nexe binaries from. This can either be an HTTP or HTTPS URL or a file path. default: null python: string On Linux this is the path pointing to your python2 executable On Windows this is the directory where python can be accessed default: null flags: string[] Array of node runtime flags to build node with. Example: ['--expose-gc'] default: [] configure: string[] Array of arguments for the node build configure step Example: ['--with-dtrace', '--dest-cpu=x64'] default: [] make: string[] Array of arguments for the node build make step default: [] vcBuild: string[] Options for windows build default: ['nosign', 'release'] snapshot: string path to a file to be used as the warmup snapshot for the build default: null resources: string[] Array of globs with files to include in the build Example: ['./public/**/*'] default: [] temp: string Path to use for storing nexe's build files Override in the env with NEXE_TEMP default: ~/.nexe ico: string Path to a user provided icon to be used (Windows only). Requires --build to be set. rc: object Settings for patching the node.rc configuration file (Windows only). Example (keys may vary depending on the version. Reference the file linked above): default: {} clean: boolean If included, nexe will remove temporary files for the accompanying configuration and exit enableNodeCli: boolean Enable the original Node CLI (will prevent application cli from working). Node CLI arguments passed via the NODE_OPTIONS environment variable will still be processed. NODE_OPTIONS support can be disabled with the --without-node-options configure flag. default: false fakeArgv: boolean fake the entry point file name (process.argv[1]). If nexe was used with stdin this will be '[stdin]'. ghToken: string Provide a Github Token for accessing nexe releases This is usually needed in CI environments default: process.env.GITHUB_TOKEN sourceUrl: string Provide an alternate url for the node source code Note: temporary files will still be created for this under the specified version loglevel: string Set the loglevel, info, silent, or verbose default: 'info' patches: NexePatch[] Userland patches for patching or modifying node source default: [] plugins: NexePatch[] Userland plugins for modifying nexe executable behavior default: [] NexePatch: (compiler: NexeCompiler, next: () => Promise<void>) => Promise<void> Patches and Plugins are just a middleware functions that take two arguments, the compiler, and next. The compiler is described below, and next ensures that the pipeline continues. Its invocation should always be awaited or returned to ensure correct behavior. Patches also require that --build be set, while plugins do not. For examples, see the built in patches: src/patches. NexeCompiler setFileContentsAsync(filename: string, contents: string): Promise<void> Quickly set a file's contents within the downloaded Node.js source. replaceInFileAsync(filename: string, ...replaceArgs): Promise<void> Quickly perform a replace in a file within the downloaded Node.js source. The rest arguments are passed along to String.prototype.replace readFileAsync(filename: string): Promise<NexeFile> Access (or create) a file within the downloaded Node.js source. addResource(filename: string, contents: Buffer): Promise<void> Add a resource to the nexe bundle files: NexeFile[] The cache of the currently read, modified, or created files within the downloaded Node.js source. NexeFile contents: string absPath: string filename: string Any modifications made to NexeFile#contents will be maintained in the cache without the need to explicitly write them back out, e.g. using NexeCompiler#setFileContentsAsync. Native Modules In order to use native modules, the native binaries must be shipped alongside the binary generated by nexe. Contributing Building Testing"
3265,"High performance server-side application frameworkSeastar Introduction SeaStar is an event-driven framework allowing you to write non-blocking, asynchronous code in a relatively straightforward manner (once understood). It is based on futures. Building Seastar For more details and alternative work-flows, read HACKING.md. Assuming that you would like to use system packages (RPMs or DEBs) for Seastar's dependencies, first install them: then configure (in ""release"" mode): then compile: If you're missing a dependency of Seastar, then it is possible to have the configuration process fetch a version of the dependency locally for development. For example, to fetch fmt locally, configure Seastar like this: --cook can be repeated many times for selecting multiple dependencies. Build modes The configure.py script is a wrapper around cmake. The --mode argument maps to CMAKE_BUILD_TYPE, and supports the following modes | | CMake mode | Debug info | Optimizations | Sanitizers | Allocator | Checks | Use for | | -------- | ------------------- | ---------- | ------------------ |------------- | --------- | -------- | -------------------------------------- | | debug | Debug | Yes | -O0 | ASAN, UBSAN | System | All | gdb | | release | RelWithDebInfo | Yes | -O3 | None | Seastar | Asserts | production | | dev | Dev (Custom) | No | -O1 | None | Seastar | Asserts | build and test cycle | | sanitize | Sanitize (Custom) | Yes | -Os | ASAN, UBSAN | System | All | second level of tests, track down bugs | Note that seastar is more sensitive to allocators and optimizations than usual. A quick rule of the thumb of the relative performances is that release is 2 times faster than dev, 150 times faster than sanitize and 300 times faster than debug. Using Seastar from its build directory (without installation) It's possible to consume Seastar directly from its build directory with CMake or pkg-config. We'll assume that the Seastar repository is located in a directory at $seastar_dir. Via pkg-config: and with CMake using the Seastar package: CMakeLists.txt for my_app: The CMAKE_PREFIX_PATH values ensure that CMake can locate Seastar and its compiled submodules. The CMAKE_MODULE_PATH value ensures that CMake can uses Seastar's CMake scripts for locating its dependencies. Using an installed Seastar You can also consume Seastar after it has been installed to the file-system. Important: Seastar works with a customized version of DPDK, so by default builds and installs the DPDK submodule to $build_dir/_cooking/installed First, configure the installation path: then run the install target: then consume it from pkg-config: or consume it with the same CMakeLists.txt as before but with a simpler CMake invocation: (If Seastar has not been installed to a ""standard"" location like /usr or /usr/local, then you can invoke CMake with -DCMAKE_PREFIX_PATH=$my_install_root.) There are also instructions for building on any host that supports Docker. Use of the DPDK is optional. Seastar's C++ dialect: C++17 or C++20 Seastar supports both C++17, and C++20. It can be selected with the --c++-dialect=gnu++17 configure option or, if using CMake directly, by setting on the Seastar_CXX_DIALECT CMake variable. See the compatibity statement for more information. Getting started There is a mini tutorial and a more comprehensive one. The documentation is available on the web. Resources Ask questions and post patches on the development mailing list. Subscription information and archives are available here, or just send an email to seastar-dev@googlegroups.com. Information can be found on the main project website. File bug reports on the project issue tracker. The Native TCP/IP Stack Seastar comes with its own userspace TCP/IP stack for better performance. Recommended hardware configuration for SeaStar CPUs - As much as you need. SeaStar is highly friendly for multi-core and NUMA NICs - As fast as possible, we recommend 10G or 40G cards. It's possible to use 1G too but you may be limited by their capacity. In addition, the more hardware queue per cpu the better for SeaStar. Otherwise we have to emulate that in software. Disks - Fast SSDs with high number of IOPS. Client machines - Usually a single client machine can't load our servers. Both memaslap (memcached) and WRK (httpd) cannot over load their matching server counter parts. We recommend running the client on different machine than the servers and use several of them. Projects using Seastar cpv-cql-driver: C++ driver for Cassandra/Scylla based on seastar framework cpv-framework: A web framework written in c++ based on seastar framework redpanda: A Kafka replacement for mission critical systems Scylla: A fast and reliable NoSQL data store compatible with Cassandra and DynamoDB smf: The fastest RPC in the West"
373,"Groom your apps Ruby environmentGroom your apps Ruby environment with rbenv. Use rbenv to pick a Ruby version for your application and guarantee that your development environment matches production. Put rbenv to work with Bundler for painless Ruby upgrades and bulletproof deployments. Powerful in development. Specify your app's Ruby version once, in a single file. Keep all your teammates on the same page. No headaches running apps on different versions of Ruby. Just Works from the command line and with app servers like Pow. Override the Ruby version anytime: just set an environment variable. Rock-solid in production. Your application's executables are its interface with ops. With rbenv and Bundler binstubs you'll never again need to cd in a cron job or Chef recipe to ensure you've selected the right runtime. The Ruby version dependency lives in one placeyour appso upgrades and rollbacks are atomic, even when you switch versions. One thing well. rbenv is concerned solely with switching Ruby versions. It's simple and predictable. A rich plugin ecosystem lets you tailor it to suit your needs. Compile your own Ruby versions, or use the ruby-build plugin to automate the process. Specify per-application environment variables with rbenv-vars. See more plugins on the wiki. Why choose rbenv over RVM? Table of Contents How It Works Understanding PATH Understanding Shims Choosing the Ruby Version Locating the Ruby Installation Installation Using Package Managers Basic GitHub Checkout Upgrading with Git Updating the list of available Ruby versions How rbenv hooks into your shell Installing Ruby versions Installing Ruby gems Uninstalling Ruby versions Uninstalling rbenv Command Reference rbenv local rbenv global rbenv shell rbenv versions rbenv version rbenv rehash rbenv which rbenv whence Environment variables Development How It Works At a high level, rbenv intercepts Ruby commands using shim executables injected into your PATH, determines which Ruby version has been specified by your application, and passes your commands along to the correct Ruby installation. Understanding PATH When you run a command like ruby or rake, your operating system searches through a list of directories to find an executable file with that name. This list of directories lives in an environment variable called PATH, with each directory in the list separated by a colon: /usr/local/bin:/usr/bin:/bin Directories in PATH are searched from left to right, so a matching executable in a directory at the beginning of the list takes precedence over another one at the end. In this example, the /usr/local/bin directory will be searched first, then /usr/bin, then /bin. Understanding Shims rbenv works by inserting a directory of shims at the front of your PATH: ~/.rbenv/shims:/usr/local/bin:/usr/bin:/bin Through a process called rehashing, rbenv maintains shims in that directory to match every Ruby command across every installed version of Rubyirb, gem, rake, rails, ruby, and so on. Shims are lightweight executables that simply pass your command along to rbenv. So with rbenv installed, when you run, say, rake, your operating system will do the following: Search your PATH for an executable file named rake Find the rbenv shim named rake at the beginning of your PATH Run the shim named rake, which in turn passes the command along to rbenv Choosing the Ruby Version When you execute a shim, rbenv determines which Ruby version to use by reading it from the following sources, in this order: The RBENV_VERSION environment variable, if specified. You can use the rbenv shell command to set this environment variable in your current shell session. The first .ruby-version file found by searching the directory of the script you are executing and each of its parent directories until reaching the root of your filesystem. The first .ruby-version file found by searching the current working directory and each of its parent directories until reaching the root of your filesystem. You can modify the .ruby-version file in the current working directory with the rbenv local command. The global ~/.rbenv/version file. You can modify this file using the rbenv global command. If the global version file is not present, rbenv assumes you want to use the ""system"" Rubyi.e. whatever version would be run if rbenv weren't in your path. Locating the Ruby Installation Once rbenv has determined which version of Ruby your application has specified, it passes the command along to the corresponding Ruby installation. Each Ruby version is installed into its own directory under ~/.rbenv/versions. For example, you might have these versions installed: ~/.rbenv/versions/1.8.7-p371/ ~/.rbenv/versions/1.9.3-p327/ ~/.rbenv/versions/jruby-1.7.1/ Version names to rbenv are simply the names of the directories in ~/.rbenv/versions. Installation Compatibility note: rbenv is incompatible with RVM. Please make sure to fully uninstall RVM and remove any references to it from your shell initialization files before installing rbenv. Using Package Managers Install rbenv. macOS If you're on macOS, we recommend installing rbenv with Homebrew. ~~~ sh $ brew install rbenv ~~~ Note that this also installs ruby-build, so you'll be ready to install other Ruby versions out of the box. Upgrading with Homebrew To upgrade to the latest rbenv and update ruby-build with newly released Ruby versions, upgrade the Homebrew packages: ~~~ sh $ brew upgrade rbenv ruby-build ~~~ - Debian, Ubuntu and their derivatives ~~~ sh $ sudo apt install rbenv ~~~ - Arch Linux and it's derivatives Archlinux has an AUR Package for rbenv and you can install it from the AUR using the instructions from this wiki page. Set up rbenv in your shell. ~~~ sh $ rbenv init ~~~ Follow the printed instructions to set up rbenv shell integration. Close your Terminal window and open a new one so your changes take effect. Verify that rbenv is properly set up using this rbenv-doctor script: ~~~ sh $ curl -fsSL https://github.com/rbenv/rbenv-installer/raw/main/bin/rbenv-doctor | bash Checking for rbenv' in PATH: /usr/local/bin/rbenv Checking for rbenv shims in PATH: OK Checkingrbenv install' support: /usr/local/bin/rbenv-install (ruby-build 20170523) Counting installed Ruby versions: none There aren't any Ruby versions installed under `~/.rbenv/versions'. You can install Ruby versions like so: rbenv install 2.2.4 Checking RubyGems settings: OK Auditing installed plugins: OK ~~~ That's it! Installing rbenv includes ruby-build, so now you're ready to install some other Ruby versions using rbenv install. Basic GitHub Checkout For a more automated install, you can use rbenv-installer. If you prefer a manual approach, follow the steps below. This will get you going with the latest version of rbenv without needing a systemwide install. Clone rbenv into ~/.rbenv. ~~~ sh $ git clone https://github.com/rbenv/rbenv.git ~/.rbenv ~~~ Optionally, try to compile dynamic bash extension to speed up rbenv. Don't worry if it fails; rbenv will still work normally: ~~~ $ cd ~/.rbenv && src/configure && make -C src ~~~ Add ~/.rbenv/bin to your $PATH for access to the rbenv command-line utility. For bash: ~~~ bash $ echo 'export PATH=""$HOME/.rbenv/bin:$PATH""' >> ~/.bash_profile ~~~ For Ubuntu Desktop: In Ubuntu ~/.bash_profile is only sourced by bash when started in interactive login mode. That is typically only when you login at the console (Ctrl+Alt+F1..F6), or connecting via ssh. This issue is explained in detail here. ~~~ bash $ echo 'export PATH=""$HOME/.rbenv/bin:$PATH""' >> ~/.profile ~~~ For Zsh: ~~~ zsh $ echo 'export PATH=""$HOME/.rbenv/bin:$PATH""' >> ~/.zshrc ~~~ For Fish shell: ~~~ fish $ set -Ux fish_user_paths $HOME/.rbenv/bin $fish_user_paths ~~~ Set up rbenv in your shell. ~~~ sh $ ~/.rbenv/bin/rbenv init ~~~ Follow the printed instructions to set up rbenv shell integration. Restart your shell so that PATH changes take effect. (Opening a new terminal tab will usually do it.) Verify that rbenv is properly set up using this rbenv-doctor script: ~~~ sh $ curl -fsSL https://github.com/rbenv/rbenv-installer/raw/main/bin/rbenv-doctor | bash Checking for rbenv' in PATH: /usr/local/bin/rbenv Checking for rbenv shims in PATH: OK Checkingrbenv install' support: /usr/local/bin/rbenv-install (ruby-build 20170523) Counting installed Ruby versions: none There aren't any Ruby versions installed under `~/.rbenv/versions'. You can install Ruby versions like so: rbenv install 2.2.4 Checking RubyGems settings: OK Auditing installed plugins: OK ~~~ (Optional) Install ruby-build, which provides the rbenv install command that simplifies the process of installing new Ruby versions. Upgrading with Git If you've installed rbenv manually using Git, you can upgrade to the latest version by pulling from GitHub: ~~~ sh $ cd ~/.rbenv $ git pull ~~~ Updating the list of available Ruby versions If you're using the rbenv install command, then the list of available Ruby versions is not automatically updated when pulling from the rbenv repo. To do this manually: How rbenv hooks into your shell Skip this section unless you must know what every line in your shell profile is doing. rbenv init is the only command that crosses the line of loading extra commands into your shell. Coming from RVM, some of you might be opposed to this idea. Here's what rbenv init actually does: Sets up your shims path. This is the only requirement for rbenv to function properly. You can do this by hand by prepending ~/.rbenv/shims to your $PATH. Installs autocompletion. This is entirely optional but pretty useful. Sourcing ~/.rbenv/completions/rbenv.bash will set that up. There is also a ~/.rbenv/completions/rbenv.zsh for Zsh users. Rehashes shims. From time to time you'll need to rebuild your shim files. Doing this automatically makes sure everything is up to date. You can always run rbenv rehash manually. Installs the sh dispatcher. This bit is also optional, but allows rbenv and plugins to change variables in your current shell, making commands like rbenv shell possible. The sh dispatcher doesn't do anything invasive like override cd or hack your shell prompt, but if for some reason you need rbenv to be a real script rather than a shell function, you can safely skip it. Run rbenv init - for yourself to see exactly what happens under the hood. Installing Ruby versions The rbenv install command doesn't ship with rbenv out of the box, but is provided by the ruby-build project. If you installed it either as part of GitHub checkout process outlined above or via Homebrew, you should be able to: ~~~ sh list latest stable versions: $ rbenv install -l list all local versions: $ rbenv install -L install a Ruby version: $ rbenv install 2.0.0-p247 ~~~ Set a Ruby version to finish installation and start using commands rbenv global 2.0.0-p247 or rbenv local 2.0.0-p247 Alternatively to the install command, you can download and compile Ruby manually as a subdirectory of ~/.rbenv/versions/. An entry in that directory can also be a symlink to a Ruby version installed elsewhere on the filesystem. rbenv doesn't care; it will simply treat any entry in the versions/ directory as a separate Ruby version. Installing Ruby gems Once you've installed some Ruby versions, you'll want to install gems. First, ensure that the target version for your project is the one you want by checking rbenv version (see Command Reference). Select another version using rbenv local 2.0.0-p247, for example. Then, proceed to install gems as you normally would: You don't need sudo to install gems. Typically, the Ruby versions will be installed and writeable by your user. No extra privileges are required to install gems. Check the location where gems are being installed with gem env: Uninstalling Ruby versions As time goes on, Ruby versions you install will accumulate in your ~/.rbenv/versions directory. To remove old Ruby versions, simply rm -rf the directory of the version you want to remove. You can find the directory of a particular Ruby version with the rbenv prefix command, e.g. rbenv prefix 1.8.7-p357. The ruby-build plugin provides an rbenv uninstall command to automate the removal process. Uninstalling rbenv The simplicity of rbenv makes it easy to temporarily disable it, or uninstall from the system. To disable rbenv managing your Ruby versions, simply remove the rbenv init line from your shell startup configuration. This will remove rbenv shims directory from PATH, and future invocations like ruby will execute the system Ruby version, as before rbenv. rbenv will still be accessible on the command line, but your Ruby apps won't be affected by version switching. To completely uninstall rbenv, perform step (1) and then remove its root directory. This will delete all Ruby versions that were installed under `rbenv root`/versions/ directory:rm -rf `rbenv root` If you've installed rbenv using a package manager, as a final step perform the rbenv package removal. - Homebrew: `brew uninstall rbenv` Debian, Ubuntu and their derivatives: `sudo apt purge rbenv` Archlinux and it's derivatives: `sudo pacman -R rbenv` Command Reference Like git, the rbenv command delegates to subcommands based on its first argument. The most common subcommands are: rbenv local Sets a local application-specific Ruby version by writing the version name to a .ruby-version file in the current directory. This version overrides the global version, and can be overridden itself by setting the RBENV_VERSION environment variable or with the rbenv shell command. $ rbenv local 1.9.3-p327 When run without a version number, rbenv local reports the currently configured local version. You can also unset the local version: $ rbenv local --unset rbenv global Sets the global version of Ruby to be used in all shells by writing the version name to the ~/.rbenv/version file. This version can be overridden by an application-specific .ruby-version file, or by setting the RBENV_VERSION environment variable. $ rbenv global 1.8.7-p352 The special version name system tells rbenv to use the system Ruby (detected by searching your $PATH). When run without a version number, rbenv global reports the currently configured global version. rbenv shell Sets a shell-specific Ruby version by setting the RBENV_VERSION environment variable in your shell. This version overrides application-specific versions and the global version. $ rbenv shell jruby-1.7.1 When run without a version number, rbenv shell reports the current value of RBENV_VERSION. You can also unset the shell version: $ rbenv shell --unset Note that you'll need rbenv's shell integration enabled (step 3 of the installation instructions) in order to use this command. If you prefer not to use shell integration, you may simply set the RBENV_VERSION variable yourself: $ export RBENV_VERSION=jruby-1.7.1 rbenv versions Lists all Ruby versions known to rbenv, and shows an asterisk next to the currently active version. $ rbenv versions 1.8.7-p352 1.9.2-p290 * 1.9.3-p327 (set by /Users/sam/.rbenv/version) jruby-1.7.1 rbx-1.2.4 ree-1.8.7-2011.03 rbenv version Displays the currently active Ruby version, along with information on how it was set. $ rbenv version 1.9.3-p327 (set by /Users/sam/.rbenv/version) rbenv rehash Installs shims for all Ruby executables known to rbenv (i.e., ~/.rbenv/versions/*/bin/*). Run this command after you install a new version of Ruby, or install a gem that provides commands. $ rbenv rehash rbenv which Displays the full path to the executable that rbenv will invoke when you run the given command. $ rbenv which irb /Users/sam/.rbenv/versions/1.9.3-p327/bin/irb rbenv whence Lists all Ruby versions with the given command installed. $ rbenv whence rackup 1.9.3-p327 jruby-1.7.1 ree-1.8.7-2011.03 Environment variables You can affect how rbenv operates with the following settings: name | default | description -----|---------|------------ RBENV_VERSION | | Specifies the Ruby version to be used.Also see rbenv shell RBENV_ROOT | ~/.rbenv | Defines the directory under which Ruby versions and shims reside.Also see rbenv root RBENV_DEBUG | | Outputs debug information.Also as: rbenv --debug <subcommand> RBENV_HOOK_PATH | see wiki | Colon-separated list of paths searched for rbenv hooks. RBENV_DIR | $PWD | Directory to start searching for .ruby-version files. Development The rbenv source code is hosted on GitHub. It's clean, modular, and easy to understand, even if you're not a shell hacker. Tests are executed using Bats: $ bats test $ bats test/<file>.bats Please feel free to submit pull requests and file bugs on the issue tracker."
3868,":atom_symbol: React primitive UI components built with styled-system. Rebass React primitive UI components built with Styled System. https://rebassjs.org Getting Started Features Start your design system without boiling the ocean Build consistent UI with design constraints and user-defined scales Best-in-class developer ergonomics with Styled System props First-class support for theming & fully compatible with Theme UI Quick, mobile-first responsive styles with array-based syntax Flexbox layout with the Box and Flex components Flexibility built in for high design & development velocity Minimal footprint at about 4KB ""One of the best React component libs out there"" Max Stoiber ""Rebass is the Bootstrap of React."" Jori Lallo ""A whopper component library built on styled-components. Responsive, systematic, scalable...the business!"" Colm Tuite Principles Rebass is intended to be: Minimal Useful Unopinionated Flexible Consistent Extensible Themeable Do one thing, and do it well Unix philosophy See Patterns for Style Composition in React for more on some of the thought behind Rebass. Documentation Docs Getting Started Props Extending Theming Reflexbox Text Heading Button Link Image Card CodeSandbox Try it out: https://codesandbox.io/s/github/rebassjs/rebass/tree/master/examples/sandbox Related Styled System Theme UI Emotion Styled Components Upgrading from v3 See the Migration Guide. Previous Versions v3.2.2 v3 Docs v2.3.2 Docs for Rebass v2 v1.0.7 Contributing | MIT License"
3477,"Enables easy Google map + overlays creation in Ruby apps== Google Maps for Rails {}[https://pledgie.com/campaigns/23367] {}[https://www.codementor.io/apneadiving?utm_campaign=profile&utm_source=button-apneadiving&utm_medium=dark] {}[http://travis-ci.org/apneadiving/Google-Maps-for-Rails] {}[https://codeclimate.com/github/apneadiving/Google-Maps-for-Rails] {}[http://badge.fury.io/rb/gmaps4rails] {}[http://coderwall.com/apneadiving] Gmaps4rails is developed to simply create a Google Map with overlays (markers, infowindows...). Yet it's backed on a very flexible codebase which could be prone to accept other map providers. Use it with any Ruby app (I guess you could simply take the js anywhere if you like). Here is a {quick tutorial on youtube}[http://www.youtube.com/watch?v=R0l-7en3dUw&feature=youtu.be], and my {presentation on speaker deck}[https://speakerdeck.com/apneadiving/gmaps4rails]. For live examples, {see here}[http://apneadiving.github.io/]. == A note for < 2.x users Google-Maps-for-Rails-2.0 is an important rewrite to keep the minimum code and features. If you're migrating from previous versions, you may want to read the {rationale about it}[https://github.com/apneadiving/Google-Maps-for-Rails/wiki/Why-but-why%3F]. == Requirements 1) Gemfile gem 'gmaps4rails' 2) HTML Add a div to bear your map, example: <div style='width: 800px;'> <div id=""map"" style='width: 800px; height: 400px;'></div> </div> 3) Javascript Dependencies: Insert google scripts in your dom: <script src=""//maps.google.com/maps/api/js?key=[your API key]""></script> <script src=""//cdn.rawgit.com/mahnunchik/markerclustererplus/master/dist/markerclusterer.min.js""></script> <script src='//cdn.rawgit.com/printercu/google-maps-utility-library-v3-read-only/master/infobox/src/infobox_packed.js' type='text/javascript'></script> <!-- only if you need custom infoboxes --> You'll require underscore.js too, see here: {http://underscorejs.org/}[http://underscorejs.org/] (lo-dash is compatible too, your choice!). 4) Javascript source code If you have the asset pipeline, add this: //= require underscore //= require gmaps/google If you don't have asset pipeline, you'll need to import the js OR coffee files: rails g gmaps4rails:copy_js rails g gmaps4rails:copy_coffee 5) Javascript code: Create your map: handler = Gmaps.build('Google'); handler.buildMap({ provider: {}, internal: {id: 'map'}}, function(){ markers = handler.addMarkers([ { ""lat"": 0, ""lng"": 0, ""picture"": { ""url"": ""http://people.mozilla.com/~faaborg/files/shiretoko/firefoxIcon/firefox-32.png"", ""width"": 32, ""height"": 32 }, ""infowindow"": ""hello!"" } ]); handler.bounds.extendWith(markers); handler.fitMapToBounds(); }); 6) Add options: You're likely going to want to customize your maps by passing an options object. Using the example above, let's say you'd like to disable the map controls. This and any other options you can find in the {Google Maps API reference}[https://developers.google.com/maps/documentation/javascript/reference] can be passed into the provider options hash like so: handler = Gmaps.build('Google'); handler.buildMap({ provider: { disableDefaultUI: true // pass in other Google Maps API options here }, internal: { id: 'map' } }, function(){ markers = handler.addMarkers([ { ""lat"": 0, ""lng"": 0, ""picture"": { ""url"": ""http://people.mozilla.com/~faaborg/files/shiretoko/firefoxIcon/firefox-32.png"", ""width"": 32, ""height"": 32 }, ""infowindow"": ""hello!"" } ]); handler.bounds.extendWith(markers); handler.fitMapToBounds(); } ); You can see other examples of adding provider options in the {live examples}[http://apneadiving.github.io/]. Also, check the {wiki}[https://github.com/apneadiving/Google-Maps-for-Rails/wiki/Js-Methods] for further documentation on the possible JavaScript methods. == Generating JSON In your controller: @users = User.all @hash = Gmaps4rails.build_markers(@users) do |user, marker| marker.lat user.latitude marker.lng user.longitude end In your view: <script> markers = handler.addMarkers(<%=raw @hash.to_json %>); </script> == Easily customizable You can change almost everything with a few lines of code. {See details here}[https://github.com/apneadiving/Google-Maps-for-Rails/wiki/Change-handler-behavior]. == Options Markers with Info window, Custom Picture, RichMarkers (make your own markers with custom html) Circles, Polylines, Polygons, Kml Refresh your map on the fly with Javascript (and Ajax) {More details in the Wiki}[https://github.com/apneadiving/Google-Maps-for-Rails/wiki] == Todo? Feel free to contact us, you have your say. == Copyright MIT license. Author: Benjamin Roth {Contributors}[https://github.com/apneadiving/Google-Maps-for-Rails/graphs/contributors]"
1740,"DEPRECATED jQuery Responsive Carousel.YEAH SO THIS IS PRETTY MUCH DEAD, DO YOURSELF A FAVOR AND SWITCH TO tiny-slider Owl Carousel 2 Touch enabled jQuery plugin that lets you create a beautiful, responsive carousel slider. To get started, check out https://owlcarousel2.github.io/OwlCarousel2/. Notice: The old Owl Carousel site (owlgraphic [dot] com) is no longer in use. Please delete all references to this in bookmarks and your own products' documentation as it's being used for malicious purposes. Quick start Install This package can be installed with: npm: npm install --save owl.carousel or yarn add owl.carousel jquery bower: bower install --save owl.carousel Or download the latest release. Load Webpack Add jQuery via the ""webpack.ProvidePlugin"" to your webpack configuration: const webpack = require('webpack'); //... plugins: [ new webpack.ProvidePlugin({ $: 'jquery', jQuery: 'jquery', 'window.jQuery': 'jquery' }), ], //... Load the required stylesheet and JS: Static HTML Put the required stylesheet at the top of your markup: NOTE: If you want to use the default navigation styles, you will also need to include owl.theme.default.css. Put the script at the bottom of your markup right after jQuery: Usage Wrap your items (div, a, img, span, li etc.) with a container element (div, ul etc.). Only the class owl-carousel is mandatory to apply proper styles: NOTE: The owl-theme class is optional, but without it, you will need to style navigation features on your own. Call the plugin function and your carousel is ready. Documentation The documentation, included in this repo in the root directory, is built with Assemble and publicly available at https://owlcarousel2.github.io/OwlCarousel2/. The documentation may also be run locally. Building This package comes with Grunt and Bower. The following tasks are available: default compiles the CSS and JS into /dist and builds the doc. dist compiles the CSS and JS into /dist only. watch watches source files and builds them automatically whenever you save. test runs JSHint and QUnit tests headlessly in PhantomJS. To define which plugins are build into the distribution just edit /_config.json to fit your needs. Contributing Please read CONTRIBUTING.md. Roadmap Please make sure to check out our Roadmap Discussion. License The code and the documentation are released under the MIT License."
828,"A cross-platform, linkable library implementation of Git that you can use in your application.libgit2 - the Git linkable library | Build Status | | | ------------ | - | | main branch CI builds | | | v1.1 branch CI builds | | | v1.0 branch CI builds | | | Nightly builds | | libgit2 is a portable, pure C implementation of the Git core methods provided as a linkable library with a solid API, allowing to build Git functionality into your application. Language bindings like Rugged (Ruby), LibGit2Sharp (.NET), pygit2 (Python) and NodeGit (Node) allow you to build Git tooling in your favorite language. libgit2 is used to power Git GUI clients like GitKraken and gmaster and on Git hosting providers like GitHub, GitLab and Azure DevOps. We perform the merge every time you click ""merge pull request"". libgit2 is licensed under a very permissive license (GPLv2 with a special Linking Exception). This basically means that you can link it (unmodified) with any kind of software without having to release its source code. Additionally, the example code has been released to the public domain (see the separate license for more information). Table of Contents Using libgit2 Quick Start Getting Help What It Can Do Optional dependencies Initialization Threading Conventions Building libgit2 - Using CMake Building Installation Advanced Usage Compiler and linker options MacOS X Android MinGW Language Bindings How Can I Contribute? License Using libgit2 Most of these instructions assume that you're writing an application in C and want to use libgit2 directly. If you're not using C, and you're writing in a different language or platform like .NET, Node.js, or Ruby, then there is probably a ""language binding"" that you can use to take care of the messy tasks of calling into native code. But if you do want to use libgit2 directly - because you're building an application in C - then you may be able use an existing binary. There are packages for the vcpkg and conan package managers. And libgit2 is available in Homebrew and most Linux distributions. However, these versions may be outdated and we recommend using the latest version if possible. Thankfully libgit2 is not hard to compile. Quick Start Prerequisites for building libgit2: CMake, and is recommended to be installed into your PATH. Python is used by our test framework, and should be installed into your PATH. C compiler: libgit2 is C90 and should compile on most compilers. Windows: Visual Studio is recommended Mac: Xcode is recommended Unix: gcc or clang is recommended. Build Create a build directory beneath the libgit2 source directory, and change into it: mkdir build && cd build Create the cmake build environment: cmake .. Build libgit2: cmake --build . Trouble with these steps? Read our troubleshooting guide. More detailed build guidance is available below. Getting Help Chat with us via IRC: join #libgit2 on Freenode via Slack: visit slack.libgit2.org to sign up, then join us in #libgit2 Getting Help If you have questions about the library, please be sure to check out the API documentation. If you still have questions, reach out to us on Slack or post a question on StackOverflow (with the libgit2 tag). Reporting Bugs Please open a GitHub Issue and include as much information as possible. If possible, provide sample code that illustrates the problem you're seeing. If you're seeing a bug only on a specific repository, please provide a link to it if possible. We ask that you not open a GitHub Issue for help, only for bug reports. Reporting Security Issues Please have a look at SECURITY.md. What It Can Do libgit2 provides you with the ability to manage Git repositories in the programming language of your choice. It's used in production to power many applications including GitHub.com, Plastic SCM and Azure DevOps. It does not aim to replace the git tool or its user-facing commands. Some APIs resemble the plumbing commands as those align closely with the concepts of the Git system, but most commands a user would type are out of scope for this library to implement directly. The library provides: SHA conversions, formatting and shortening abstracted ODB backend system commit, tag, tree and blob parsing, editing, and write-back tree traversal revision walking index file (staging area) manipulation reference management (including packed references) config file management high level repository management thread safety and reentrancy descriptive and detailed error messages ...and more (over 175 different API calls) As libgit2 is purely a consumer of the Git system, we have to adjust to changes made upstream. This has two major consequences: Some changes may require us to change provided interfaces. While we try to implement functions in a generic way so that no future changes are required, we cannot promise a completely stable API. As we have to keep up with changes in behavior made upstream, we may lag behind in some areas. We usually to document these incompatibilities in our issue tracker with the label ""git change"". Optional dependencies While the library provides git functionality without the need for dependencies, it can make use of a few libraries to add to it: pthreads (non-Windows) to enable threadsafe access as well as multi-threaded pack generation OpenSSL (non-Windows) to talk over HTTPS and provide the SHA-1 functions LibSSH2 to enable the SSH transport iconv (OSX) to handle the HFS+ path encoding peculiarities Initialization The library needs to keep track of some global state. Call git_libgit2_init(); before calling any other libgit2 functions. You can call this function many times. A matching number of calls to git_libgit2_shutdown(); will free the resources. Note that if you have worker threads, you should call git_libgit2_shutdown after those threads have exited. If you require assistance coordinating this, simply have the worker threads call git_libgit2_init at startup and git_libgit2_shutdown at shutdown. Threading See threading for information Conventions See conventions for an overview of the external and internal API/coding conventions we use. Building libgit2 - Using CMake Building libgit2 builds cleanly on most platforms without any external dependencies. Under Unix-like systems, like Linux, *BSD and Mac OS X, libgit2 expects pthreads to be available; they should be installed by default on all systems. Under Windows, libgit2 uses the native Windows API for threading. The libgit2 library is built using CMake (version 2.8 or newer) on all platforms. On most systems you can build the library using the following commands $ mkdir build && cd build $ cmake .. $ cmake --build . Alternatively you can point the CMake GUI tool to the CMakeLists.txt file and generate platform specific build project or IDE workspace. Running Tests Once built, you can run the tests from the build directory with the command $ ctest -V Alternatively you can run the test suite directly using, $ ./libgit2_clar Invoking the test suite directly is useful because it allows you to execute individual tests, or groups of tests using the -s flag. For example, to run the index tests: $ ./libgit2_clar -sindex To run a single test named index::racy::diff, which corresponds to the test function test_index_racy__diff: $ ./libgit2_clar -sindex::racy::diff The test suite will print a . for every passing test, and an F for any failing test. An S indicates that a test was skipped because it is not applicable to your platform or is particularly expensive. Note: There should be no failing tests when you build an unmodified source tree from a release, or from the main branch. Please contact us or open an issue if you see test failures. Installation To install the library you can specify the install prefix by setting: $ cmake .. -DCMAKE_INSTALL_PREFIX=/install/prefix $ cmake --build . --target install Advanced Usage For more advanced use or questions about CMake please read https://cmake.org/Wiki/CMake_FAQ. The following CMake variables are declared: CMAKE_INSTALL_BINDIR: Where to install binaries to. CMAKE_INSTALL_LIBDIR: Where to install libraries to. CMAKE_INSTALL_INCLUDEDIR: Where to install headers to. BUILD_SHARED_LIBS: Build libgit2 as a Shared Library (defaults to ON) BUILD_CLAR: Build Clar-based test suite (defaults to ON) THREADSAFE: Build libgit2 with threading support (defaults to ON) To list all build options and their current value, you can do the following: # Create and set up a build directory $ mkdir build $ cmake .. # List all build options and their values $ cmake -L Compiler and linker options CMake lets you specify a few variables to control the behavior of the compiler and linker. These flags are rarely used but can be useful for 64-bit to 32-bit cross-compilation. CMAKE_C_FLAGS: Set your own compiler flags CMAKE_FIND_ROOT_PATH: Override the search path for libraries ZLIB_LIBRARY, OPENSSL_SSL_LIBRARY AND OPENSSL_CRYPTO_LIBRARY: Tell CMake where to find those specific libraries MacOS X If you want to build a universal binary for Mac OS X, CMake sets it all up for you if you use -DCMAKE_OSX_ARCHITECTURES=""i386;x86_64"" when configuring. Android Extract toolchain from NDK using, make-standalone-toolchain.sh script. Optionally, crosscompile and install OpenSSL inside of it. Then create CMake toolchain file that configures paths to your crosscompiler (substitute {PATH} with full path to the toolchain): SET(CMAKE_SYSTEM_NAME Linux) SET(CMAKE_SYSTEM_VERSION Android) SET(CMAKE_C_COMPILER {PATH}/bin/arm-linux-androideabi-gcc) SET(CMAKE_CXX_COMPILER {PATH}/bin/arm-linux-androideabi-g++) SET(CMAKE_FIND_ROOT_PATH {PATH}/sysroot/) SET(CMAKE_FIND_ROOT_PATH_MODE_PROGRAM NEVER) SET(CMAKE_FIND_ROOT_PATH_MODE_LIBRARY ONLY) SET(CMAKE_FIND_ROOT_PATH_MODE_INCLUDE ONLY) Add -DCMAKE_TOOLCHAIN_FILE={pathToToolchainFile} to cmake command when configuring. MinGW If you want to build the library in MinGW environment with SSH support enabled, you may need to pass -DCMAKE_LIBRARY_PATH=""${MINGW_PREFIX}/${MINGW_CHOST}/lib/"" flag to CMake when configuring. This is because CMake cannot find the Win32 libraries in MinGW folders by default and you might see an error message stating that CMake could not resolve ws2_32 library during configuration. Another option would be to install msys2-w32api-runtime package before configuring. This package installs the Win32 libraries into /usr/lib folder which is by default recognized as the library path by CMake. Please note though that this package is meant for MSYS subsystem which is different from MinGW. Language Bindings Here are the bindings to libgit2 that are currently available: C++ libqgit2, Qt bindings https://projects.kde.org/projects/playground/libs/libqgit2/repository/ Chicken Scheme chicken-git https://wiki.call-cc.org/egg/git D dlibgit https://github.com/s-ludwig/dlibgit Delphi GitForDelphi https://github.com/libgit2/GitForDelphi Erlang Geef https://github.com/carlosmn/geef Go git2go https://github.com/libgit2/git2go GObject libgit2-glib https://wiki.gnome.org/Projects/Libgit2-glib Guile Guile-Git https://gitlab.com/guile-git/guile-git Haskell hgit2 https://github.com/jwiegley/gitlib Java Jagged https://github.com/ethomson/jagged Javascript / WebAssembly ( browser and nodejs ) WASM-git https://github.com/petersalomonsen/wasm-git Julia LibGit2.jl https://github.com/JuliaLang/julia/tree/master/stdlib/LibGit2 Lua luagit2 https://github.com/libgit2/luagit2 .NET libgit2sharp https://github.com/libgit2/libgit2sharp Node.js nodegit https://github.com/nodegit/nodegit Objective-C objective-git https://github.com/libgit2/objective-git OCaml ocaml-libgit2 https://github.com/fxfactorial/ocaml-libgit2 Parrot Virtual Machine parrot-libgit2 https://github.com/letolabs/parrot-libgit2 Perl Git-Raw https://github.com/jacquesg/p5-Git-Raw PHP php-git https://github.com/libgit2/php-git PowerShell PSGit https://github.com/PoshCode/PSGit Python pygit2 https://github.com/libgit2/pygit2 R gert https://docs.ropensci.org/gert git2r https://github.com/ropensci/git2r Ruby Rugged https://github.com/libgit2/rugged Rust git2-rs https://github.com/rust-lang/git2-rs Swift SwiftGit2 https://github.com/SwiftGit2/SwiftGit2 Vala libgit2.vapi https://github.com/apmasell/vapis/blob/master/libgit2.vapi If you start another language binding to libgit2, please let us know so we can add it to the list. How Can I Contribute? We welcome new contributors! We have a number of issues marked as ""up for grabs"" and ""easy fix"" that are good places to jump in and get started. There's much more detailed information in our list of outstanding projects. Please be sure to check the contribution guidelines to understand our workflow, and the libgit2 coding conventions. License libgit2 is under GPL2 with linking exception. This means you can link to and use the library from any program, proprietary or open source; paid or gratis. However, if you modify libgit2 itself, you must distribute the source to your modified version of libgit2. See the COPYING file for the full license text."
561,"A rich text editor for everyday writingTrix A Rich Text Editor for Everyday Writing Compose beautifully formatted text in your web application. Trix is a WYSIWYG editor for writing messages, comments, articles, and liststhe simple documents most web apps are made of. It features a sophisticated document model, support for embedded attachments, and outputs terse and consistent HTML. Trix is an open-source project from Basecamp, the creators of Ruby on Rails. Millions of people trust their text to Basecamp, and we built Trix to give them the best possible editing experience. See Trix in action in the all-new Basecamp 3. Different By Design Most WYSIWYG editors are wrappers around HTMLs contenteditable and execCommand APIs, designed by Microsoft to support live editing of web pages in Internet Explorer 5.5, and eventually reverse-engineered and copied by other browsers. Because these APIs were never fully specified or documented, and because WYSIWYG HTML editors are enormous in scope, each browsers implementation has its own set of bugs and quirks, and JavaScript developers are left to resolve the inconsistencies. Trix sidesteps these inconsistencies by treating contenteditable as an I/O device: when input makes its way to the editor, Trix converts that input into an editing operation on its internal document model, then re-renders that document back into the editor. This gives Trix complete control over what happens after every keystroke, and avoids the need to use execCommand at all. Built for the Modern Web Trix supports all evergreen, self-updating desktop and mobile browsers. Trix is built with emerging web standards, notably Custom Elements, Mutation Observer, and Promises. Eventually we expect all browsers to implement these standards. In the meantime, Trix includes polyfills for missing functionality. Getting Started Include the bundled trix.css and trix.js files in the <head> of your page. trix.css includes default styles for the Trix toolbar, editor, and attachments. Skip this file if you prefer to define these styles yourself. To use your own polyfills, or to target only browsers that support all of the required standards, include trix-core.js instead. Creating an Editor Place an empty <trix-editor></trix-editor> tag on the page. Trix will automatically insert a separate <trix-toolbar> before the editor. Like an HTML <textarea>, <trix-editor> accepts autofocus and placeholder attributes. Unlike a <textarea>, <trix-editor> automatically expands vertically to fit its contents. Integrating With Forms To submit the contents of a <trix-editor> with a form, first define a hidden input field in the form and assign it an id. Then reference that id in the editors input attribute. Trix will automatically update the value of the hidden input field with each change to the editor. Populating With Stored Content To populate a <trix-editor> with stored content, include that content in the associated input elements value attribute. Always use an associated input element to safely populate an editor. Trix wont load any HTML content inside a <trix-editor></trix-editor> tag. Styling Formatted Content To ensure what you see when you edit is what you see when you save, use a CSS class name to scope styles for Trix formatted content. Apply this class name to your <trix-editor> element, and to a containing element when you render stored Trix content for display in your application. The default trix.css file includes styles for basic formatted contentincluding bulleted and numbered lists, code blocks, and block quotesunder the class name trix-content. We encourage you to use these styles as a starting point by copying them into your applications CSS with a different class name. Storing Attached Files Trix automatically accepts files dragged or pasted into an editor and inserts them as attachments in the document. Each attachment is considered pending until you store it remotely and provide Trix with a permanent URL. To store attachments, listen for the trix-attachment-add event. Upload the attached files with XMLHttpRequest yourself and set the attachments URL attribute upon completion. See the attachment example for detailed information. If you dont want to accept dropped or pasted files, call preventDefault() on the trix-file-accept event, which Trix dispatches just before the trix-attachment-add event. Editing Text Programmatically You can manipulate a Trix editor programmatically through the Trix.Editor interface, available on each <trix-editor> element through its editor property. Understanding the Document Model The formatted content of a Trix editor is known as a document, and is represented as an instance of the Trix.Document class. To get the editors current document, use the editor.getDocument method. You can convert a document to an unformatted JavaScript string with the document.toString method. Immutability and Equality Documents are immutable values. Each change you make in an editor replaces the previous document with a new document. Capturing a snapshot of the editors content is as simple as keeping a reference to its document, since that document will never change over time. (This is how Trix implements undo.) To compare two documents for equality, use the document.isEqualTo method. Getting and Setting the Selection Trix documents are structured as sequences of individually addressable characters. The index of one character in a document is called a position, and a start and end position together make up a range. To get the editors current selection, use the editor.getSelectedRange method, which returns a two-element array containing the start and end positions. You can set the editors current selection by passing a range array to the editor.setSelectedRange method. Collapsed Selections When the start and end positions of a range are equal, the range is said to be collapsed. In the editor, a collapsed selection appears as a blinking cursor rather than a highlighted span of text. For convenience, the following calls to setSelectedRange are equivalent when working with collapsed selections: Directional Movement To programmatically move the cursor or selection through the document, call the editor.moveCursorInDirection or editor.expandSelectionInDirection methods with a direction argument. The direction can be either ""forward"" or ""backward"". Converting Positions to Pixel Offsets Sometimes you need to know the x and y coordinates of a character at a given position in the editor. For example, you might want to absolutely position a pop-up menu element below the editors cursor. Call the editor.getClientRectAtPosition method with a position argument to get a DOMRect instance representing the left and top offsets, width, and height of the character at the given position. Inserting and Deleting Text The editor interface provides methods for inserting, replacing, and deleting text at the current selection. To insert or replace text, begin by setting the selected range, then call one of the insertion methods below. Trix will first remove any selected text, then insert the new text at the start position of the selected range. Inserting Plain Text To insert unformatted text into the document, call the editor.insertString method. Inserting HTML To insert HTML into the document, call the editor.insertHTML method. Trix will first convert the HTML into its internal document model. During this conversion, any formatting that cannot be represented in a Trix document will be lost. Inserting a File To insert a DOM File object into the document, call the editor.insertFile method. Trix will insert a pending attachment for the file as if you had dragged and dropped it onto the editor. Inserting a Content Attachment Content attachments are self-contained units of HTML that behave like files in the editor. They can be moved or removed, but not edited directly, and are represented by a single character position in the document model. To insert HTML as an attachment, create a Trix.Attachment with a content attribute and call the editor.insertAttachment method. The HTML inside a content attachment is not subject to Trixs document conversion rules and will be rendered as-is. Inserting a Line Break To insert a line break, call the editor.insertLineBreak method, which is functionally equivalent to pressing the return key. Deleting Text If the current selection is collapsed, you can simulate deleting text before or after the cursor with the editor.deleteInDirection method. To delete a range of text, first set the selected range, then call editor.deleteInDirection with either direction as the argument. Working With Attributes and Nesting Trix represents formatting as sets of attributes applied across ranges of a document. By default, Trix supports the inline attributes bold, italic, href, and strike, and the block-level attributes heading1, quote, code, bullet, and number. Applying Formatting To apply formatting to the current selection, use the editor.activateAttribute method. To set the href attribute, pass a URL as the second argument to editor.activateAttribute. Removing Formatting Use the editor.deactivateAttribute method to remove formatting from a selection. Formatting With a Collapsed Selection If you activate or deactivate attributes when the selection is collapsed, your formatting changes will apply to the text inserted by any subsequent calls to editor.insertString. Adjusting the Nesting Level To adjust the nesting level of quotes, bulleted lists, or numbered lists, call the editor.increaseNestingLevel and editor.decreaseNestingLevel methods. Using Undo and Redo Trix editors support unlimited undo and redo. Successive typing and formatting changes are consolidated together at five-second intervals; all other input changes are recorded individually in undo history. Call the editor.undo and editor.redo methods to perform an undo or redo operation. Changes you make through the editor interface will not automatically record undo entries. You can save your own undo entries by calling the editor.recordUndoEntry method with a description argument. Loading and Saving Editor State Serialize an editors state with JSON.stringify and restore saved state with the editor.loadJSON method. The serialized state includes the document and current selection, but does not include undo history. Observing Editor Changes The <trix-editor> element emits several events which you can use to observe and respond to changes in editor state. trix-before-initialize fires when the <trix-editor> element is attached to the DOM just before Trix installs its editor object. trix-initialize fires when the <trix-editor> element is attached to the DOM and its editor object is ready for use. trix-change fires whenever the editors contents have changed. trix-selection-change fires any time the selected range changes in the editor. trix-focus and trix-blur fire when the editor gains or loses focus, respectively. trix-file-accept fires when a file is dropped or inserted into the editor. You can access the DOM File object through the file property on the event. Call preventDefault on the event to prevent attaching the file to the document. trix-attachment-add fires after an attachment is added to the document. You can access the Trix attachment object through the attachment property on the event. If the attachment object has a file property, you should store this file remotely and set the attachments URL attribute. See the attachment example for detailed information. trix-attachment-remove fires when an attachment is removed from the document. You can access the Trix attachment object through the attachment property on the event. You may wish to use this event to clean up remotely stored files. Contributing to Trix Trix is open-source software, freely distributable under the terms of an MIT-style license. The source code is hosted on GitHub. We welcome contributions in the form of bug reports, pull requests, or thoughtful discussions in the GitHub issue tracker. Please see the Code of Conduct for our pledge to contributors. Trix was created by Javan Makhmali and Sam Stephenson, with development sponsored by Basecamp. Building From Source Trix is written in CoffeeScript and compiled to JavaScript with Blade. From inside a checkout of the Trix Git repository, issue the following commands to build the distributable files in dist/: Developing In-Browser You can spawn a development web server to work on Trix in a more convenient fashion. Instead of manually rebuilding the source each time, just reload a page in your browser to see your changes. To develop in-browser, run bin/setup and follow the displayed instructions. Running Tests Make sure youre set up to build from source using the instructions above. Then run bin/blade runner and visit the displayed URL to run the Trix test suite. Pull Requests Only commit changes to Trixs source (everything except the compiled files in /dist) and leave the VERSION unchanged. We update both when publishing new releases. :heart: 2020 Basecamp, LLC."
3563,"A pure PHP library for reading and writing word processing documentsMaster: Develop: PHPWord is a library written in pure PHP that provides a set of classes to write to and read from different document file formats. The current version of PHPWord supports Microsoft Office Open XML (OOXML or OpenXML), OASIS Open Document Format for Office Applications (OpenDocument or ODF), Rich Text Format (RTF), HTML, and PDF. PHPWord is an open source project licensed under the terms of LGPL version 3. PHPWord is aimed to be a high quality software product by incorporating continuous integration and unit testing. You can learn more about PHPWord by reading the Developers' Documentation. If you have any questions, please ask on StackOverFlow Read more about PHPWord: Features Requirements Installation Getting started Contributing Developers' Documentation Features With PHPWord, you can create OOXML, ODF, or RTF documents dynamically using your PHP 5.3.3+ scripts. Below are some of the things that you can do with PHPWord library: Set document properties, e.g. title, subject, and creator. Create document sections with different settings, e.g. portrait/landscape, page size, and page numbering Create header and footer for each sections Set default font type, font size, and paragraph style Use UTF-8 and East Asia fonts/characters Define custom font styles (e.g. bold, italic, color) and paragraph styles (e.g. centered, multicolumns, spacing) either as named style or inline in text Insert paragraphs, either as a simple text or complex one (a text run) that contains other elements Insert titles (headers) and table of contents Insert text breaks and page breaks Insert and format images, either local, remote, or as page watermarks Insert binary OLE Objects such as Excel or Visio Insert and format table with customized properties for each rows (e.g. repeat as header row) and cells (e.g. background color, rowspan, colspan) Insert list items as bulleted, numbered, or multilevel Insert hyperlinks Insert footnotes and endnotes Insert drawing shapes (arc, curve, line, polyline, rect, oval) Insert charts (pie, doughnut, bar, line, area, scatter, radar) Insert form fields (textinput, checkbox, and dropdown) Create document from templates Use XSL 1.0 style sheets to transform headers, main document part, and footers of an OOXML template ... and many more features on progress Requirements PHPWord requires the following: PHP 5.3.3+ XML Parser extension Laminas Escaper component Zip extension (optional, used to write OOXML and ODF) GD extension (optional, used to add images) XMLWriter extension (optional, used to write OOXML and ODF) XSL extension (optional, used to apply XSL style sheet to template ) dompdf library (optional, used to write PDF) Installation PHPWord is installed via Composer. To add a dependency to PHPWord in your project, either Run the following to use the latest stable version or if you want the latest master version You can of course also manually edit your composer.json file Getting started The following is a basic usage example of the PHPWord library. More examples are provided in the samples folder. For an easy access to those samples launch php -S localhost:8000 in the samples directory then browse to http://localhost:8000 to view the samples. You can also read the Developers' Documentation for more detail. Contributing We welcome everyone to contribute to PHPWord. Below are some of the things that you can do to contribute. Read our contributing guide. Fork us and request a pull to the develop branch. Submit bug reports or feature requests to GitHub. Follow @PHPWord and @PHPOffice on Twitter."
3455,"An extension for VS Code which provides support for the Go language. We have moved to https://github.com/golang/vscode-goGo for Visual Studio Code An extension for VS Code which provides support for the Go language. We have moved! As of June 2020, our new home is https://github.com/golang/vscode-go. For more on this, please see the below blog posts - The next phase of Go experience in VS Code - VS Code Go extension joins the Go project Contributing This project welcomes contributions and suggestions. Please go through the Contributing Guide in the new repository. Code of Conduct This project has adopted the Microsoft Open Source Code of Conduct. For more information see the Code of Conduct FAQ or contact opencode@microsoft.com with any additional questions or comments. License MIT"
3550,"Open-Source Iconfont.Elusive-Iconfont The Elusive Iconfont is an icons webfont, optimized for use with twitter's bootstrap. For examples & usage see http://shoestrap.org/downloads/elusive-icons-webfont/ Licence: SIL"
2236, Standard Tooling for Vue.js DevelopmentVue CLI Vue CLI is the Standard Tooling for Vue.js Development. Documentation Docs are available at https://cli.vuejs.org/ - we are still working on refining it and contributions are welcome! Contributing Please see contributing guide. License MIT
833,"JavaScript toolkit for creating interactive real-time graphsRickshaw Rickshaw is a JavaScript toolkit for creating interactive time series graphs, developed at Shutterstock Table of Contents Getting Started Install Dependencies Rickshaw.Graph element series renderer width height min max padding interpolation stack Methods render() configure() onUpdate(f) Extensions Rickshaw.Color.Palette Color Schemes Interpolation Rickshaw and Cross-Browser Support Minification Development Contributing Authors License Getting Started Getting started with a simple graph is straightforward. Here's the gist: See the overview, tutorial, and examples for more. Install In the browser, manually add rickshaw.min.js and rickshaw.min.css in the document head. Alternatively, you can install Rickshaw using Bower or npm. Dependencies Rickshaw relies on the fantastic D3 visualization library to do lots of the heavy lifting for stacking and rendering to SVG. Some extensions require jQuery and jQuery UI, but for drawing some basic graphs you'll be okay without. Rickshaw uses jsdom to run unit tests in Node to be able to do SVG manipulation. As of the jsdom 7.0.0 release, jsdom requires Node.js 4 or newer jsdom changelog. If you want to run the tests on your machine, and you don't have access to a version of node >= 4.0, you can npm install jsdom@3 so that you can run the tests using the 3.x branch of jsdom. Rickshaw.Graph A Rickshaw graph. Send an element reference, series data, and optionally other properties to the constructor before calling render() to point the graph. A listing of properties follows. Send these as arguments to the constructor, and optionally set them later on already-instantiated graphs with a call to configure() element A reference to an HTML element that should hold the graph. series Array of objects containing series data to plot. Each object should contain data at a minimum, a sorted array of objects each with x and y properties. Optionally send a name and color as well. Some renderers and extensions may also support additional keys. renderer A string containing the name of the renderer to be used. Options include area, stack, bar, line, and scatterplot. Defaults to line. Also see the multi meta renderer in order to support different renderers per series. width Width of the graph in pixels. Falls back to the width of the element, or defaults to 400 if the element has no width. height Height of the graph in pixels. Falls back to the height of the element, or defaults to 250 if the element has no height. min Lower value on the Y-axis, or auto for the lowest value in the series. Defaults to 0. max Highest value on the Y-axis. Defaults to the highest value in the series. padding An object containing any of top, right, bottom, and left properties specifying a padding percentage around the extrema of the data in the graph. Defaults to 0.01 on top for 1% padding, and 0 on other sides. Padding on the bottom only applies when the yMin is either negative or auto. interpolation Line smoothing / interpolation method (see D3 docs); notable options: linear: straight lines between points step-after: square steps from point to point cardinal: smooth curves via cardinal splines (default) basis: smooth curves via B-splines stack Allows you to specify whether series should be stacked while in the context of stacking renderers (area, bar, etc). Defaults to stack: 'true'. To unstack, unstack: 'true'. Methods Once you have instantiated a graph, call methods below to get pixels on the screen, change configuration, and set callbacks. render() Draw or redraw the graph. configure() Set properties on an instantiated graph. Specify any properties the constructor accepts, including width and height and renderer. Call render() to redraw the graph and reflect newly-configured properties. onUpdate(f) Add a callback to run when the graph is rendered Extensions Once you have a basic graph, extensions let you add functionality. See the overview and examples listing for more. Rickshaw.Graph.Legend - add a basic legend Rickshaw.Graph.HoverDetail - show details on hover Rickshaw.Graph.JSONP - get data via a JSONP request Rickshaw.Graph.Annotate - add x-axis annotations Rickshaw.Graph.RangeSlider - dynamically zoom on the x-axis with a slider Rickshaw.Graph.RangeSlider.Preview - pan and zoom via graphical preview of entire data set Rickshaw.Graph.Axis.Time - add an x-axis and grid lines with time labels Rickshaw.Graph.Axis.X - add an x-axis and grid lines with arbitrary labels Rickshaw.Graph.Axis.Y - add a y-axis and grid lines Rickshaw.Graph.Axis.Y.Scaled - add a y-axis with an alternate scale Rickshaw.Graph.Behavior.Series.Highlight - highlight series on legend hover Rickshaw.Graph.Behavior.Series.Order - reorder series in the stack with drag-and-drop Rickshaw.Graph.Behavior.Series.Toggle - toggle series on and off through the legend Rickshaw.Color.Palette Rickshaw comes with a few color schemes. Instantiate a palette and specify a scheme name, and then call color() on the palette to get each next color. Optionally, to palette.color() can take a numeric argument to specify which color from the palette should be used (zero-indexed). This can be helpful when assigning a color to series of a plot with particular meaning: Color Schemes classic9 colorwheel cool munin spectrum14 spectrum2000 spectrum2001 Interpolation For graphs with more series than palettes have colors, specify an interpolatedStopCount to the palette constructor. Rickshaw and Cross-Browser Support This library works in modern browsers and Internet Explorer 9+. Rickshaw relies on the HTMLElement#classList API, which isn't natively supported in Internet Explorer 9. Rickshaw adds support by including a shim which implements the classList API by extending the HTMLElement prototype. You can disable this behavior if you like, by setting RICKSHAW_NO_COMPAT to a true value before including the library. Minification If your project uses minification, you will need to give a hint to the minifier to leave variables named $super named $super. For example, with uglify on the command line: Or a sample configuration with grunt-contrib-uglify: Development For building, we use Node and npm. Running npm run build or make should get you going with any luck. After doing a build you can run the tests with the command: npm test For more availible options see the package.json scripts section. Contributing Pull requests are always welcome! Please follow a few guidelines: Please don't include updated versions of rickshaw.js and rickshaw.min.js. Just changes to the source files will suffice. Add a unit test or two to cover the proposed changes Do as the Romans do and stick with existing whitespace and formatting conventions (i.e., tabs instead of spaces, etc) Consider adding a simple example under examples/ that demonstrates any new functionality Please note that all interactions with Shutterstock follow the Contributor Covenant Code of Conduct. Authors This library was developed by David Chester, Douglas Hunter, and Silas Sewell at Shutterstock License Copyright (C) 2011-2020 by Shutterstock Images, LLC Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the ""Software""), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
1691,"A Ruby interface to the Twitter API.The Twitter Ruby Gem A Ruby interface to the Twitter API. Installation gem install twitter CLI Looking for the Twitter command-line interface? It was removed from this gem in version 0.5.0 and now exists as a separate project. Documentation http://rdoc.info/gems/twitter Examples https://github.com/sferik/twitter/tree/master/examples Announcements You should follow @gem on Twitter for announcements and updates about this library. Mailing List Please direct questions about this library to the mailing list. Apps Wiki Does your project or organization use this gem? Add it to the apps wiki! Configuration Twitter API v1.1 requires you to authenticate via OAuth, so you'll need to register your application with Twitter. Once you've registered an application, make sure to set the correct access level, otherwise you may see the error: Read-only application cannot POST Your new application will be assigned a consumer key/secret pair and you will be assigned an OAuth access token/secret pair for that application. You'll need to configure these values before you make a request or else you'll get the error: Bad Authentication data You can pass configuration options as a block to Twitter::REST::Client.new. Usage Examples After configuring a client, you can do the following things. Tweet (as the authenticated user) Follow a user (by screen name or user ID) Fetch a user (by screen name or user ID) Fetch a cursored list of followers with profile details (by screen name or user ID, or by implicit authenticated user) Fetch a cursored list of friends with profile details (by screen name or user ID, or by implicit authenticated user) Fetch the timeline of Tweets by a user Fetch the timeline of Tweets from the authenticated user's home page Fetch the timeline of Tweets mentioning the authenticated user Fetch a particular Tweet by ID Collect the three most recent marriage proposals to @justinbieber Find a Japanese-language Tweet tagged #ruby (excluding retweets) For more usage examples, please see the full documentation. Streaming Site Streams are restricted to whitelisted accounts. To apply for access, follow the steps in the Site Streams documentation. User Streams do not require prior approval. Configuration works just like Twitter::REST::Client Stream a random sample of all tweets Stream mentions of coffee or tea Stream tweets, events, and direct messages for the authenticated user An object may be one of the following: * Twitter::Tweet * Twitter::DirectMessage * Twitter::Streaming::DeletedTweet * Twitter::Streaming::Event * Twitter::Streaming::FriendList * Twitter::Streaming::StallWarning Ads We recommend using the Twitter Ads SDK for Ruby to interact with the Twitter Ads API. Object Graph This entity-relationship diagram is generated programatically. If you add or remove any Twitter objects, please regenerate the ERD with the following command: bundle exec rake erd Supported Ruby Versions This library aims to support and is tested against the following Ruby versions: Ruby 2.4 Ruby 2.5 Ruby 2.6 Ruby 2.7 If something doesn't work on one of these versions, it's a bug. This library may inadvertently work (or seem to work) on other Ruby versions, however support will only be provided for the versions listed above. If you would like this library to support another Ruby version or implementation, you may volunteer to be a maintainer. Being a maintainer entails making sure all tests run and pass on that implementation. When something breaks on your implementation, you will be responsible for providing patches in a timely fashion. If critical issues for a particular implementation exist at the time of a major release, support for that Ruby version may be dropped. Versioning This library aims to adhere to Semantic Versioning 2.0.0. Violations of this scheme should be reported as bugs. Specifically, if a minor or patch version is released that breaks backward compatibility, that version should be immediately yanked and/or a new version should be immediately released that restores compatibility. Breaking changes to the public API will only be introduced with new major versions. As a result of this policy, you can (and should) specify a dependency on this gem using the Pessimistic Version Constraint with two digits of precision. For example: spec.add_dependency 'twitter', '~> 6.0' Copyright Copyright (c) 2006-2016 Erik Berlin, John Nunemaker, Wynn Netherland, Steve Richert, Steve Agalloco. See LICENSE for details."
2908,"Verbatim mirror of the git.drupal.org repository for Drupal core. Please see the https://github.com/drupal/drupal#contributing. PRs are not accepted on GitHub. Drupal is an open source content management platform supporting a variety of websites ranging from personal weblogs to large community-driven websites. For more information, visit the Drupal website, Drupal.org, and join the Drupal community. Contributing Drupal is developed on Drupal.org, the home of the international Drupal community since 2001! Drupal.org hosts Drupal's GitLab repository, its issue queue, and its documentation. Before you start working on code, be sure to search the issue queue and create an issue if your aren't able to find an existing issue. Every issue on Drupal.org automatically creates a new community-accessible fork that you can contribute to. Learn more about the code contribution process on the Issue forks & merge requests page. Usage For a brief introduction, see USAGE.txt. You can also find guides, API references, and more by visiting Drupal's documentation page. You can quickly extend Drupal's core feature set by installing any of its thousands of free and open source modules. With Drupal and its module ecosystem, you can often build most or all of what your project needs before writing a single line of code. Changelog Drupal keeps detailed change records. You can search Drupal's changes for a record of every notable breaking change and new feature since 2011. Security For a list of security announcements, see the Security advisories page (available as an RSS feed). This page also describes how to subscribe to these announcements via email. For information about the Drupal security process, or to find out how to report a potential security issue to the Drupal security team, see the Security team page. Need a helping hand? Visit the Support page or browse over a thousand Drupal providers offering design, strategy, development, and hosting services. Legal matters Know your rights when using Drupal by reading Drupal core's license. Learn about the Drupal trademark and logo policy here."
764,gridster.js is a jQuery plugin that makes building intuitive draggable layouts from elements spanning multiple columnsGridster.js Gridster is a jQuery plugin that makes building intuitive draggable layouts from elements spanning multiple columns. You can even dynamically add and remove elements from the grid. More at http://gridster.net/. Releases CHANGELOG Gridster is maintained by Ducksboard occasionally but not actively. @dustmoo and @pushmatrix have also write permissions as Gridster maintainers they are. Thank you guys! Forks Mr @dustmoo (maintainer of Gridster) has his own fork of gridster.js with some new interesting features like widget-swapping and static widgets. Can be found here: dustmoo/gridster.js @dustmoo is working in his spare time to merge all these changes into ducksboard/gridster.js If anyone would like to help @dustmoo improve his fork and reconcile it with the main library he would be happy for the help. Contributing to this project Anyone and everyone is welcome to contribute. Please take a moment to review the guidelines for contributing. Bug reports Feature requests Pull requests License Distributed under the MIT license. Whodunit Gridster is built by Ducksboard with the help of all these wonderful people.
544,"The perfect library for adding search, sort, filters and flexibility to tables, lists and various HTML elements. Built to be invisible and work on existing HTML.List.js Perfect library for adding search, sort, filters and flexibility to tables, lists and various HTML elements. Built to be invisible and work on existing HTML. Really simple and easy to use! Core idea Simple and invisible Easy to apply to existing HTML No dependencies Fast Small Handle thousands of items Features Works both lists, tables and almost anything else. E.g. <div>,<ul>,<table>, etc. Search Read more Sort Read more Filter Read more Simple templating system that adds possibility to add, edit, remove items Read more Support for Chrome, Safari, Firefox, IE9+ Download / Install Via NPM Via Bower Via CDNJS Via Direct Download Compressed list.js Uncompressed list.js Questions / How to? https://stackoverflow.com/questions/tagged/list.js Demo / Examples Existing list Existing list + add New list Add, get, remove Fuzzy search Pagination Search in specific column Filter in range Show message filter/search results in 0 items Only show list after search/filter Documentation Getting started Options List API Item API Changelog Thanks to all lovely contributors! Want to join them? Read more at listjs.com/overview/contribute Creator | | Jonny Strmberg @javve | | ---------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ | | | I hope you like the lib. Ive put a lot of hours into it! Feel free to follow me on Twitter for news and donate a coffee for good karma ;) | License (MIT) Copyright (c) 2011-2020 Jonny Strmberg javve.com"
1744,"Sketch app plugin for generating dummy data such as avatars, names, photos, geo data etcContent Generator for Sketch Content generator allows you quickly create dummy data such as avatars, names, geo location data etc. Demo Generating pictures Generating names Generating dummy text Generating strings You can create a custom string by combining any of these options: - plain text (example: banana) - random number from range (example: [0-20] ) - random item from an array (example: [banana\~apple\~grapes] ) An example of a combined string: $[0-999],[10-99] [new\~used\~old] Which would result in ""$321,34 old"" or ""$12,75 new"" Generating custom images In Sketch app use Plugins\Content Generator\Images\Custom plugin to specify path to your own folder with images Installation Manual Download Zip and Extract it to a folder In Sketch app Plugins > Manage Plugins... In the Preferences window, click on the cog-wheel icon, and select Show Plugins Folder from the dropdown. Place the extracted folder directly to the Plugins folder (nesting might not work atm) Sketch plugin manager Installation via Sketch Plugin Manager: In the 'Catalog' tab of the Sketch Plugin Manager window search for 'Content Generator' Upcoming features More types of data Fetch content directly from different online sources Easier extensibility Feature requests & feedback Ping me on twitter or follow for updates. Bug reports Open Console app Applications/Utilities/Console Type Sketch In filter box like so Run broken plugin Submit output of the Console app via Github issues or twitter toghether with the version of your Sketch app Contributors Author Timur Carpeev Number plugins Liu Liu And others Credits Photo collection Unsplash User pics Uifaces User names Uinames Random data Mockaroo Custom photos Ian Silber Vintage user pics Rad faces Flickr keywords https://github.com/nickstamas"
3921,"Template rendering, notifier, and supervisor for @HashiCorp Consul and Vault data.Consul Template This project provides a convenient way to populate values from Consul into the file system using the consul-template daemon. The daemon consul-template queries a Consul or Vault cluster and updates any number of specified templates on the file system. As an added bonus, it can optionally run arbitrary commands when the update process completes. Please see the examples folder for some scenarios where this functionality might prove useful. The documentation in this README corresponds to the master branch of Consul Template. It may contain unreleased features or different APIs than the most recently released version. Please see the Git tag that corresponds to your version of Consul Template for the proper documentation. Table of Contents Community Support Installation Quick Example Learn Guides Configuration Command Line Flags Configuration File Reload Configuration and Templates Templating Language API Functions Scratch Helper Functions Math Functions Observability Logging Modes Once Mode De-Duplication Mode Exec Mode Plugins Caveats Docker Image Use Dots in Service Names Termination on Error Commands Environment Multiple Commands Multi-phase Execution Running and Process Lifecycle Debugging FAQ Contributing Community Support If you have questions about how consul-template works, its capabilities or anything other than a bug or feature request (use github's issue tracker for those), please see our community support resources. Community portal: https://discuss.hashicorp.com/c/consul Other resources: https://www.consul.io/community.html Additionally, for issues and pull requests, we'll be using the :+1: reactions as a rough voting system to help gauge community priorities. So please add :+1: to any issue or pull request you'd like to see worked on. Thanks. Installation Download a pre-compiled, released version from the Consul Template releases page. Extract the binary using unzip or tar. Move the binary into $PATH. To compile from source, please see the instructions in the contributing section. Quick Example This short example assumes Consul is installed locally. Start a Consul cluster in dev mode: Author a template in.tpl to query the kv store: Start Consul Template: Write data to the key in Consul: Observe Consul Template has written the file out.txt: For more examples and use cases, please see the examples folder in this repository. Learn Guides In addition to these examples, HashiCorp has published guides and official documentation to help walk through a few common use cases for Consul Template. * Consul KV * Consul Catalog * Vault Agent Templates * Vault Secrets Configuration Configuration documentation has been moved to docs/configuration.md. Reload Configuration and Templates While there are multiple ways to run Consul Template, the most common pattern is to run Consul Template as a system service. When Consul Template first starts, it reads any configuration files and templates from disk and loads them into memory. From that point forward, changes to the files on disk do not propagate to running process without a reload. The reason for this behavior is simple and aligns with other tools like haproxy. A user may want to perform pre-flight validation checks on the configuration or templates before loading them into the process. Additionally, a user may want to update configuration and templates simultaneously. Having Consul Template automatically watch and reload those files on changes is both operationally dangerous and against some of the paradigms of modern infrastructure. Instead, Consul Template listens for the SIGHUP syscall to trigger a configuration reload. If you update configuration or templates, simply send HUP to the running Consul Template process and Consul Template will reload all the configurations and templates from disk. Templating Language Templating Language documentation has been moved to docs/templating-language.md. Caveats Docker Image Use The Alpine Docker image is configured to support an external volume to render shared templates to. If mounted you will need to make sure that the consul-template user in the docker image has write permissions to the directory. Also if you build your own image using these you need to be sure you have the permissions correct. The consul-template user in docker has a UID of 100 and a GID of 1000. This effects the in image directories /consul-template/config, used to add configuration when using this as a parent image, and /consul-template/data, exported as a VOLUME as a location to render shared results. Previously the image initially ran as root in order to ensure the permissions allowed it. But this ran against docker best practices and security policies. If you build your own image based on ours you can override these values with --build-arg parameters. Dots in Service Names Using dots . in service names will conflict with the use of dots for TAG delineation in the template. Dots already interfere with using DNS for service names, so we recommend avoiding dots wherever possible. Termination on Error By default Consul Template is highly fault-tolerant. If Consul is unreachable or a template changes, Consul Template will happily continue running. The only exception to this rule is if the optional command exits non-zero. In this case, Consul Template will also exit non-zero. The reason for this decision is so the user can easily configure something like Upstart or God to manage Consul Template as a service. If you want Consul Template to continue watching for changes, even if the optional command argument fails, you can append || true to your command. Note that || is a ""shell-ism"", not a built-in function. You will also need to run your command under a shell: In this example, even if the Nginx restart command returns non-zero, the overall function will still return an OK exit code; Consul Template will continue to run as a service. Additionally, if you have complex logic for restarting your service, you can intelligently choose when you want Consul Template to exit and when you want it to continue to watch for changes. For these types of complex scripts, we recommend using a custom sh or bash script instead of putting the logic directly in the consul-template command or configuration file. Commands Environment The current processes environment is used when executing commands with the following additional environment variables: CONSUL_HTTP_ADDR CONSUL_HTTP_TOKEN CONSUL_HTTP_AUTH CONSUL_HTTP_SSL CONSUL_HTTP_SSL_VERIFY These environment variables are exported with their current values when the command executes. Other Consul tooling reads these environment variables, providing smooth integration with other Consul tools (like consul maint or consul lock). Additionally, exposing these environment variables gives power users the ability to further customize their command script. Multiple Commands The command configured for running on template rendering must be a single command. That is you cannot join multiple commands with &&, ;, |, etc. This is a restriction of how they are executed. However you are able to do this by combining the multiple commands in an explicit shell command using sh -c. This is probably best explained by example. Say you have a couple scripts you need to run when a template is rendered, /opt/foo and /opt/bar, and you only want /opt/bar to run if /opt/foo is successful. You can do that with the command... command = ""sh -c '/opt/foo && /opt/bar'"" As this is a full shell command you can even use conditionals. So accomplishes the same thing. command = ""sh -c 'if /opt/foo; then /opt/bar ; fi'"" Using this method you can run as many shell commands as you need with whatever logic you need. Though it is suggested that if it gets too long you might want to wrap it in a shell script, deploy and run that. Multi-phase Execution Consul Template does an n-pass evaluation of templates, accumulating dependencies on each pass. This is required due to nested dependencies, such as: During the first pass, Consul Template does not know any of the services in Consul, so it has to perform a query. When those results are returned, the inner-loop is then evaluated with that result, potentially creating more queries and watches. Because of this implementation, template functions need a default value that is an acceptable parameter to a range function (or similar), but does not actually execute the inner loop (which would cause a panic). This is important to mention because complex templates must account for the ""empty"" case. For example, the following will not work: This will raise an error like: That is because, during the first evaluation of the template, the service key is returning an empty slice. You can account for this in your template like so: This will still add the dependency to the list of watches, but will not evaluate the inner-if, avoiding the out-of-index error. FAQ Q: How is this different than confd? A: The answer is simple: Service Discovery as a first class citizen. You are also encouraged to read this Pull Request on the project for more background information. We think confd is a great project, but Consul Template fills a missing gap. Additionally, Consul Template has first class integration with Vault, making it easy to incorporate secret material like database credentials or API tokens into configuration files. Q: How is this different than Puppet/Chef/Ansible/Salt? A: Configuration management tools are designed to be used in unison with Consul Template. Instead of rendering a stale configuration file, use your configuration management software to render a dynamic template that will be populated by Consul. Contributing To build and install Consul-Template locally, you will need to install Go. Clone the repository: To compile the consul-template binary for your local machine: This will compile the consul-template binary into bin/consul-template as well as your $GOPATH and run the test suite. If you want to compile a specific binary, set XC_OS and XC_ARCH or run the following to generate all binaries: If you want to run the tests, first install consul and vault locally, then: Or to run a specific test in the suite:"
486,"Knockout makes it easier to create rich, responsive UIs with JavaScriptKnockout Knockout is a JavaScript MVVM (a modern variant of MVC) library that makes it easier to create rich, desktop-like user interfaces with JavaScript and HTML. It uses observers to make your UI automatically stay in sync with an underlying data model, along with a powerful and extensible set of declarative bindings to enable productive development. Getting started Totally new to Knockout? The most fun place to start is the online interactive tutorials. For more details, see Documentation on the project's website Online examples at http://knockoutjs.com/examples/ Downloading Knockout You can download released versions of Knockout from the project's website. For Node.js developers, Knockout is also available from npm - just run npm install knockout. Building Knockout from sources If you prefer to build the library yourself: Clone the repo from GitHub Acquire build dependencies. Make sure you have Node.js and Java installed on your workstation. These are only needed to build Knockout from sources. Knockout itself has no dependency on Node.js or Java once it is built (it works with any server technology or none). Now run: Run the build tool Now you'll find the built files in build/output/. To run a single task, use -- Running the tests If you have phantomjs installed, then the grunt script will automatically run the specification suite and report its results. Or, if you want to run the specs in a browser (e.g., for debugging), simply open spec/runner.html in your browser. License MIT license - http://www.opensource.org/licenses/mit-license.php"
2588,"Tabbed navigation that you can swipe between, each tab can have its own ScrollView and maintain its own scroll position between swipes. Pleasantly animated. Customizable tab barreact-native-scrollable-tab-view This is probably my favorite navigation pattern on Android, I wish it were more common on iOS! This is a very simple JavaScript-only implementation of it for React Native. For more information about how the animations behind this work, check out the Rebound section of the React Native Animation Guide Add it to your project Run npm install react-native-scrollable-tab-view --save var ScrollableTabView = require('react-native-scrollable-tab-view'); Demo Run this example Basic usage Injecting a custom tab bar Suppose we had a custom tab bar called CustomTabBar, we would inject it into our ScrollableTabView like this: To start you can just copy DefaultTabBar. Examples SimpleExample. ScrollableTabsExample. OverlayExample. FacebookExample. Props renderTabBar (Function:ReactComponent) - accept 1 argument props and should return a component to use as the tab bar. The component has goToPage, tabs, activeTab and ref added to the props, and should implement setAnimationValue to be able to animate itself along with the tab content. You can manually pass the props to the TabBar component. tabBarPosition (String) Defaults to ""top"". ""bottom"" to position the tab bar below content. ""overlayTop"" or ""overlayBottom"" for a semitransparent tab bar that overlays content. Custom tab bars must consume a style prop on their outer element to support this feature: style={this.props.style}. onChangeTab (Function) - function to call when tab changes, should accept 1 argument which is an Object containing two keys: i: the index of the tab that is selected, ref: the ref of the tab that is selected onScroll (Function) - function to call when the pages are sliding, should accept 1 argument which is an Float number representing the page position in the slide frame. locked (Bool) - disables horizontal dragging to scroll between tabs, default is false. initialPage (Integer) - the index of the initially selected tab, defaults to 0 === first tab. page (Integer) - set selected tab(can be buggy see #126 children (ReactComponents) - each top-level child component should have a tabLabel prop that can be used by the tab bar component to render out the labels. The default tab bar expects it to be a string, but you can use anything you want if you make a custom tab bar. tabBarUnderlineStyle (View.propTypes.style) - style of the default tab bar's underline. tabBarBackgroundColor (String) - color of the default tab bar's background, defaults to white tabBarActiveTextColor (String) - color of the default tab bar's text when active, defaults to navy tabBarInactiveTextColor (String) - color of the default tab bar's text when inactive, defaults to black tabBarTextStyle (Object) - Additional styles to the tab bar's text. Example: {fontFamily: 'Roboto', fontSize: 15} style (View.propTypes.style) contentProps (Object) - props that are applied to root ScrollView/ViewPagerAndroid. Note that overriding defaults set by the library may break functionality; see the source for details. scrollWithoutAnimation (Bool) - on tab press change tab without animation. prerenderingSiblingsNumber (Integer) - pre-render nearby # sibling, Infinity === render all the siblings, default to 0 === render current page. Contribution Issues are welcome. Please add a screenshot of bug and code snippet. Quickest way to solve issue is to reproduce it on one of the examples. Pull requests are welcome. If you want to change API or making something big better to create issue and discuss it first. Before submiting PR please run Also all eslint fixes are welcome. Please attach video or gif to PR's and issues it is super helpful. How to make video How to make gif from video MIT Licensed"
1469,:wrench: Cross-platform GUI management tool for RedisRDM Install & Run | Quick Start | Native Formatters | Development Guide | Known issues | Telegram Chat Open source cross-platform Desktop Manager for Redis based on Qt 5 Officially Supported platforms: Supported Redis versions: 2.8+ (for old redis-servers use RedisDesktopManager 0.8.8)
3773,"A web interface for MySQL and MariaDBphpMyAdmin A web interface for MySQL and MariaDB. https://www.phpmyadmin.net/ Code status .. image:: https://github.com/phpmyadmin/phpmyadmin/workflows/Run%20tests/badge.svg?branch=master :alt: Testsuite :target: https://github.com/phpmyadmin/phpmyadmin/actions .. image:: https://github.com/phpmyadmin/phpmyadmin/workflows/Run%20selenium%20tests/badge.svg?branch=master :alt: Selenium tests :target: https://github.com/phpmyadmin/phpmyadmin/actions .. image:: https://readthedocs.org/projects/phpmyadmin/badge/?version=latest :target: https://docs.phpmyadmin.net/en/latest/ :alt: Documentation build status .. image:: https://hosted.weblate.org/widgets/phpmyadmin/-/master/svg-badge.svg :alt: Translation status :target: https://hosted.weblate.org/engage/phpmyadmin/?utm_source=widget .. image:: https://codecov.io/gh/phpmyadmin/phpmyadmin/branch/master/graph/badge.svg :alt: Coverage percentage :target: https://codecov.io/gh/phpmyadmin/phpmyadmin .. image:: https://scrutinizer-ci.com/g/phpmyadmin/phpmyadmin/badges/quality-score.png :alt: Code quality score :target: https://scrutinizer-ci.com/g/phpmyadmin/phpmyadmin/ .. image:: https://bestpractices.coreinfrastructure.org/projects/213/badge :alt: CII Best Practices :target: https://bestpractices.coreinfrastructure.org/projects/213 Download You can get the newest release at https://www.phpmyadmin.net/. If you prefer to follow the Git repository, the following branch and tag names may be of interest: STABLE is the current stable release. master is the development branch. Releases are tagged, for example version 5.0.1 was tagged as RELEASE_5_0_1. Note that phpMyAdmin uses Composer <https://getcomposer.org/> to manage library dependencies, when using Git development versions, you must manually run Composer. Please see the documentation <https://docs.phpmyadmin.net/en/latest/setup.html#installing-from-git> for details. More Information Please see https://docs.phpmyadmin.net/, or browse the documentation in the doc folder. For support <https://www.phpmyadmin.net/support/> or security issues <https://www.phpmyadmin.net/security/> you can visit https://www.phpmyadmin.net/ Translations are welcome, you can translate phpMyAdmin to your language <https://hosted.weblate.org/projects/phpmyadmin/>_. If you would like to contribute to the phpMyAdmin's codebase, you can read the code contribution file <CONTRIBUTING.md> or browse our website's contributing page <https://www.phpmyadmin.net/contribute/>."
228,"Official Sass port of Bootstrap 2 and 3.Bootstrap 3 for Sass bootstrap-sass is a Sass-powered version of Bootstrap 3, ready to drop right into your Sass powered applications. This is Bootstrap 3. For Bootstrap 4 use the Bootstrap rubygem if you use Ruby, and the main repo otherwise. Installation Please see the appropriate guide for your environment of choice: Ruby on Rails. Bower. npm / Node.js. a. Ruby on Rails bootstrap-sass is easy to drop into Rails with the asset pipeline. In your Gemfile you need to add the bootstrap-sass gem, and ensure that the sass-rails gem is present - it is added to new Rails applications by default. bundle install and restart your server to make the files available through the pipeline. Import Bootstrap styles in app/assets/stylesheets/application.scss: bootstrap-sprockets must be imported before bootstrap for the icon fonts to work. Make sure the file has .scss extension (or .sass for Sass syntax). If you have just generated a new Rails app, it may come with a .css file instead. If this file exists, it will be served instead of Sass, so rename it: Then, remove all the *= require_self and *= require_tree . statements from the sass file. Instead, use @import to import Sass files. Do not use *= require in Sass or your other stylesheets will not be able to access the Bootstrap mixins or variables. Bootstrap JavaScript depends on jQuery. If you're using Rails 5.1+, add the jquery-rails gem to your Gemfile: Require Bootstrap Javascripts in app/assets/javascripts/application.js: bootstrap-sprockets and bootstrap should not both be included in application.js. bootstrap-sprockets provides individual Bootstrap Javascript files (alert.js or dropdown.js, for example), while bootstrap provides a concatenated file containing all Bootstrap Javascripts. Bower with Rails When using bootstrap-sass Bower package instead of the gem in Rails, configure assets in config/application.rb: Replace Bootstrap @import statements in application.scss with: Replace Bootstrap require directive in application.js with: Rails 4.x Please make sure sprockets-rails is at least v2.1.4. Rails 3.2.x bootstrap-sass is no longer compatible with Rails 3. The latest version of bootstrap-sass compatible with Rails 3.2 is v3.1.1.0. b. Bower bootstrap-sass Bower package is compatible with node-sass 3.2.0+. You can install it with: Sass, JS, and all other assets are located at assets. By default, bower.json main field list only the main _bootstrap.scss and all the static assets (fonts and JS). This is compatible by default with asset managers such as wiredep. Node.js Mincer If you use mincer with node-sass, import Bootstrap like so: In application.css.ejs.scss (NB .css.ejs.scss): In application.js: See also this example manifest.js for mincer. c. npm / Node.js Configuration Sass By default all of Bootstrap is imported. You can also import components explicitly. To start with a full list of modules copy _bootstrap.scss file into your assets as _bootstrap-custom.scss. Then comment out components you do not want from _bootstrap-custom. In the application Sass file, replace @import 'bootstrap' with: Sass: Number Precision bootstrap-sass requires minimum Sass number precision of 8 (default is 5). Precision is set for Ruby automatically when using the sassc-rails gem. When using the npm or Bower version with Ruby, you can set it with: Sass: Autoprefixer Bootstrap requires the use of Autoprefixer. Autoprefixer adds vendor prefixes to CSS rules using values from Can I Use. To match upstream Bootstrap's level of browser compatibility, set Autoprefixer's browsers option to: JavaScript assets/javascripts/bootstrap.js contains all of Bootstrap's JavaScript, concatenated in the correct order. JavaScript with Sprockets or Mincer If you use Sprockets or Mincer, you can require bootstrap-sprockets instead to load the individual modules: You can also load individual modules, provided you also require any dependencies. You can check dependencies in the Bootstrap JS documentation. Fonts The fonts are referenced as: $icon-font-path defaults to bootstrap/ if asset path helpers are used, and ../fonts/bootstrap/ otherwise. When using bootstrap-sass with Compass, Sprockets, or Mincer, you must import the relevant path helpers before Bootstrap itself, for example: Usage Sass Import Bootstrap into a Sass file (for example, application.scss) to get all of Bootstrap's styles, mixins and variables! You can also include optional Bootstrap theme: The full list of Bootstrap variables can be found here. You can override these by simply redefining the variable before the @import directive, e.g.: Eyeglass Bootstrap is available as an Eyeglass module. After installing Bootstrap via NPM you can import the Bootstrap library via: or import only the parts of Bootstrap you need: Version Bootstrap for Sass version may differ from the upstream version in the last number, known as PATCH. The patch version may be ahead of the corresponding upstream minor. This happens when we need to release Sass-specific changes. Before v3.3.2, Bootstrap for Sass version used to reflect the upstream version, with an additional number for Sass-specific changes. This was changed due to Bower and npm compatibility issues. The upstream versions vs the Bootstrap for Sass versions are: | Upstream | Sass | |---------:|--------:| | 3.3.4+ | same | | 3.3.2 | 3.3.3 | | <= 3.3.1 | 3.3.1.x | Always refer to CHANGELOG.md when upgrading. Development and Contributing If you'd like to help with the development of bootstrap-sass itself, read this section. Upstream Converter Keeping bootstrap-sass in sync with upstream changes from Bootstrap used to be an error prone and time consuming manual process. With Bootstrap 3 we have introduced a converter that automates this. Note: if you're just looking to use Bootstrap 3, see the installation section above. Upstream changes to the Bootstrap project can now be pulled in using the convert rake task. Here's an example run that would pull down the master branch from the main twbs/bootstrap repo: rake convert This will convert the latest LESS to Sass and update to the latest JS. To convert a specific branch or version, pass the branch name or the commit hash as the first task argument: rake convert[e8a1df5f060bf7e6631554648e0abde150aedbe4] The latest converter script is located here and does the following: Converts upstream Bootstrap LESS files to its matching SCSS file. Copies all upstream JavaScript into assets/javascripts/bootstrap, a Sprockets manifest at assets/javascripts/bootstrap-sprockets.js, and a concatenation at assets/javascripts/bootstrap.js. Copies all upstream font files into assets/fonts/bootstrap. Sets Bootstrap::BOOTSTRAP_SHA in version.rb to the branch sha. This converter fully converts original LESS to SCSS. Conversion is automatic but requires instructions for certain transformations (see converter output). Please submit GitHub issues tagged with conversion. Credits bootstrap-sass has a number of major contributors: Thomas McDonald Tristan Harward Peter Gumeson Gleb Mazovetskiy and a significant number of other contributors. You're in good company bootstrap-sass is used to build some awesome projects all over the web, including Diaspora, rails_admin, Michael Hartl's Rails Tutorial, gitlabhq and kandan."
4316,"Fabulous Image Processing in SwiftToucan is a Swift library that provides a clean, quick API for processing images. It greatly simplifies the production of images, supporting resizing, cropping and stylizing your images. Features Easy and smart resizing Elliptical and rounded rect masking Mask with custom images Chainable image processing stages Requirements Xcode 10.0+ iOS 11.0+ Setup Install using CocoaPods: https://cocoapods.org/pods/Toucan or manually include the Toucan framework by dragging it into your project and import the library in your code using import Toucan Toucan Usage Toucan provides two methods of interaction - either through wrapping an single image within a Toucan instance, or through the static functions, providing an image for each invocation. This allows for some very flexible usage. Create an instance wrapper for easy method chaining: Or, using static methods when you need a single operation: Typically, the instance version is a bit cleaner to use, and the one you want. Resizing Resize the contained image to the specified size. Depending on what fitMode is supplied, the image may be clipped, cropped or scaled. Fit Mode FitMode drives the resizing process to determine what to do with an image to make it fit the given size bounds. Example | Mode ---- | --------- |Clip ModeToucan.Resize.FitMode.ClipResizes the image to fit within the width and height boundaries without cropping or distorting the image.Toucan(image: portraitImage).resize(CGSize(width: 500, height: 500), fitMode: Toucan.Resize.FitMode.Clip).image |Crop ModeToucan.Resize.FitMode.cropResizes the image to fill the width and height boundaries and crops any excess image data.Toucan(image: portraitImage).resize(CGSize(width: 500, height: 500), fitMode: Toucan.Resize.FitMode.Crop).image |Scale ModeToucan.Resize.FitMode.scaleScales the image to fit the constraining dimensions exactly.Toucan(image: portraitImage).resize(CGSize(width: 500, height: 500), fitMode: Toucan.Resize.FitMode.Scale).image Masking Alter the original image with a mask; supports ellipse, rounded rect and image masks. Ellipse Mask Example | Function ---- | --------- |Mask the given image with an ellipse. Allows specifying an additional border to draw on the clipped image. For a circle, ensure the image width and height are equal!Toucan(image: myImage).maskWithEllipse().image |When specifying a border width, it is draw on the clipped image.Toucan(image: myImage).maskWithEllipse(borderWidth: 10, borderColor: UIColor.yellowColor()).image Path Mask Example | Function ---- | --------- |Mask the given image with a path. The path will be scaled to fit the image correctly!path.moveToPoint(CGPointMake(0, 50))path.addLineToPoint(CGPointMake(50, 0))path.addLineToPoint(CGPointMake(100, 50))path.addLineToPoint(CGPointMake(50, 100))path.closePath()Toucan(image: myImage).maskWithPath(path: path).image |Mask the given image with a path provided via a closure. This allows you to construct your path relative to the bounds of the image!Toucan(image: myImage).maskWithPathClosure(path: (rect: CGRect) -> (UIBezierPath)).image Rounded Rect Mask Example | Function ---- | --------- |Mask the given image with a rounded rectangle border. Allows specifying an additional border to draw on the clipped image.Toucan(image: myImage).maskWithRoundedRect(cornerRadius: 30).image |When specifying a border width, it is draw on the clipped rounded rect.Toucan(image: myImage).maskWithRoundedRect(cornerRadius: 30, borderWidth: 10, borderColor: UIColor.purpleColor()).image Image Mask Example | Function ---- | --------- |Mask the given image with another image mask. Note that the areas in the original image that correspond to the black areas of the mask show through in the resulting image. The areas that correspond to the white areas of the mask arent painted. The areas that correspond to the gray areas in the mask are painted using an intermediate alpha value thats equal to 1 minus the image mask sample value.Toucan(image: myImage).maskWithImage(maskImage: octagonMask).image Example Images Example images used under Creative Commons with thanks to: David Amsler Sheila Sund Contributing Please fork this project Implement new methods or changes in the Toucan.swift file. Write tests in the ToucanTests folder. Write appropriate docs and comments in the README.md Submit a pull request. Contact Raise an Issue or hit me up on Twitter @gavinbunney License Toucan is released under an MIT license. See LICENSE for more information."
4620,"A touchable jQuery lightboxSwipebox A touchable jQuery lightbox. View project page What is Swipebox ? Swipebox is a jQuery ""lightbox"" plugin for desktop, mobile and tablet. Features Swipe gestures for mobile Keyboard Navigation for desktop CSS transitions with jQuery fallback Retina support for UI icons Easy CSS customization Video, Images and Inline content Compatibility Chrome, Safari, Firefox, Opera, IE9+, IOS4+, Android, windows phone. Usage Javascript Include jquery and the swipebox script in your head tags or right before your body closing tag. CSS Include the swipebox CSS style in your head tags. HTML Use a specific class for your links and use the title attribute as caption. Fire the plugin Bind the swipebox behaviour on every link with the ""swipebox"" class. Options Pull Requests I want to keep this plugin as simple as possible. I won't merge pull requests for additional features such as download buttons, social like buttons, IE8 compatibility etc... But feel free to fork the project and customize it to suit to your needs. Most wanted PR are for bug fixes. Also, a future improvement will be to allow zoom on touchable devices. If you want to submit a pull request please be sure to grunt the whole thing (mostly jshintrc validation and minified file) and send me a demo URL. Also, please comment your code. Thanks for your understanding and thank you all for your helpful support!"
724,"Low-Budget Password Strength Estimationzxcvbn is a password strength estimator inspired by password crackers. Through pattern matching and conservative estimation, it recognizes and weighs 30k common passwords, common names and surnames according to US census data, popular English words from Wikipedia and US television and movies, and other common patterns like dates, repeats (aaa), sequences (abcd), keyboard patterns (qwertyuiop), and l33t speak. Consider using zxcvbn as an algorithmic alternative to password composition policy it is more secure, flexible, and usable when sites require a minimal complexity score in place of annoying rules like ""passwords must contain three of {lower, upper, numbers, symbols}"". More secure: policies often fail both ways, allowing weak passwords (P@ssword1) and disallowing strong passwords. More flexible: zxcvbn allows many password styles to flourish so long as it detects sufficient complexity passphrases are rated highly given enough uncommon words, keyboard patterns are ranked based on length and number of turns, and capitalization adds more complexity when it's unpredictaBle. More usable: zxcvbn is designed to power simple, rule-free interfaces that give instant feedback. In addition to strength estimation, zxcvbn includes minimal, targeted verbal feedback that can help guide users towards less guessable passwords. For further detail and motivation, please refer to the USENIX Security '16 paper and presentation. At Dropbox we use zxcvbn (Release notes) on our web, desktop, iOS and Android clients. If JavaScript doesn't work for you, others have graciously ported the library to these languages: zxcvbn-python (Python) zxcvbn-cpp (C/C++/Python/JS) zxcvbn-c (C/C++) zxcvbn-rs (Rust) zxcvbn-go (Go) zxcvbn4j (Java) nbvcxz (Java) zxcvbn-ruby (Ruby) zxcvbn-js (Ruby [via ExecJS]) zxcvbn-ios (Objective-C) zxcvbn-cs (C#/.NET) szxcvbn (Scala) zxcvbn-php (PHP) zxcvbn-api (REST) ocaml-zxcvbn (OCaml bindings for zxcvbn-c) Integrations with other frameworks: * angular-zxcvbn (AngularJS) Installation zxcvbn detects and supports CommonJS (node, browserify) and AMD (RequireJS). In the absence of those, it adds a single function zxcvbn() to the global namespace. Bower Install node and bower if you haven't already. Get zxcvbn: Add this script to your index.html: To make sure it loaded properly, open in a browser and type zxcvbn('Tr0ub4dour&3') into the console. To pull in updates and bug fixes: Node / npm / MeteorJS zxcvbn works identically on the server. RequireJS Add zxcvbn.js to your project (using bower, npm or direct download) and import as usual: Browserify / Webpack If you're using npm and have require('zxcvbn') somewhere in your code, browserify and webpack should just work. But we recommend against bundling zxcvbn via tools like browserify and webpack, for three reasons: Minified and gzipped, zxcvbn is still several hundred kilobytes. (Significantly grows bundle size.) Most sites will only need zxcvbn on a few pages (registration, password reset). Most sites won't need zxcvbn() immediately upon page load; since zxcvbn() is typically called in response to user events like filling in a password, there's ample time to fetch zxcvbn.js after initial html/css/js loads and renders. See the performance section below for tips on loading zxcvbn stand-alone. Tangentially, if you want to build your own standalone, consider tweaking the browserify pipeline used to generate dist/zxcvbn.js: --debug adds an inline source map to the bundle. exorcist pulls it out into dist/zxcvbn.js.map. --standalone zxcvbn exports a global zxcvbn when CommonJS/AMD isn't detected. -t coffeeify --extension='.coffee' compiles .coffee to .js before bundling. This is convenient as it allows .js modules to import from .coffee modules and vice-versa. Instead of this transform, one could also compile everything to .js first (npm run prepublish) and point browserify to lib instead of src. -t uglifyify minifies the bundle through UglifyJS, maintaining proper source mapping. Manual installation Download zxcvbn.js. Add to your .html: Usage try zxcvbn interactively to see these docs in action. zxcvbn() takes one required argument, a password, and returns a result object with several properties: ` The optional user_inputs argument is an array of strings that zxcvbn will treat as an extra dictionary. This can be whatever list of strings you like, but is meant for user inputs from other fields of the form, like name and email. That way a password that includes a user's personal information can be heavily penalized. This list is also good for site-specific vocabulary Acme Brick Co. might want to include ['acme', 'brick', 'acmebrick', etc]. Performance runtime latency zxcvbn operates below human perception of delay for most input: ~5-20ms for ~25 char passwords on modern browsers/CPUs, ~100ms for passwords around 100 characters. To bound runtime latency for really long passwords, consider sending zxcvbn() only the first 100 characters or so of user input. script load latency zxcvbn.js bundled and minified is about 400kB gzipped or 820kB uncompressed, most of which is dictionaries. Consider these tips if you're noticing page load latency on your site. Make sure your server is configured to compress static assets for browsers that support it. (nginx tutorial, Apache/IIS tutorial.) Then try one of these alternatives: Put your <script src=""zxcvbn.js""> tag at the end of your html, just before the closing </body> tag. This ensures your page loads and renders before the browser fetches and loads zxcvbn.js. The downside with this approach is zxcvbn() becomes available later than had it been included in <head> not an issue on most signup pages where users are filling out other fields first. If you're using RequireJS, try loading zxcvbn.js separately from your main bundle. Something to watch out for: if zxcvbn.js is required inside a keyboard handler waiting for user input, the entire script might be loaded only after the user presses their first key, creating nasty latency. Avoid this by calling your handler once upon page load, independent of user input, such that the requirejs() call runs earlier. Use the HTML5 async script attribute. Downside: doesn't work in IE7-9 or Opera Mini. Include an inline <script> in <head> that asynchronously loads zxcvbn.js in the background. Advantage over (3): it works in older browsers. Development Bug reports and pull requests welcome! zxcvbn is built with CoffeeScript, browserify, and uglify-js. CoffeeScript source lives in src, which gets compiled, bundled and minified into dist/zxcvbn.js. For debugging, both build and watch output an external source map dist/zxcvbn.js.map that points back to the original CoffeeScript code. Two source files, adjacency_graphs.coffee and frequency_lists.coffee, are generated by python scripts in data-scripts that read raw data from the data directory. For node developers, in addition to dist, the zxcvbn npm module includes a lib directory (hidden from git) that includes one compiled .js and .js.map file for every .coffee in src. See prepublish in package.json to learn more. Acknowledgments Dropbox for supporting open source! Mark Burnett for releasing his 10M password corpus and for his 2005 book, Perfect Passwords: Selection, Protection, Authentication. Wiktionary contributors for building a frequency list of English words as used in television and movies. Researchers at Concordia University for studying password estimation rigorously and recommending zxcvbn. And xkcd for the inspiration :+1::horse::battery::heart:"
4122,"UltimateAndroid is a rapid development framework for developing your appsUltimateAndroid Version:0.10.2 UltimateAndroid is a rapid development framework for developing apps Master branch: Dev branch: V0.7.0 Ui Demo screenshot UltimateAndroid is a rapid development framework for developing apps. UltimateAndroid framework contains many features like View Injection,ORM,Asynchronous Networking and Image Loader,over 100 Ui effects etc.And there are also many useful features like WebViewUtils,DaoUtils,Https Utils,CryptographyUtils,FileUploadUtils etc.The framework will be added more feature in the future. The framework is like flask(a web development framework) which contains some other opensource project like Butter Knife,RxJava, retrofit and many other which I said at the end of Readme or in the updatelog. Welcome to fork and pull request. If you have some good idea about the framework,you can email to us or put your idea on the issue.My Email is cymcsg # gmail.com Manual Quick Setup (Basic Usage) Using Gradle: or grab via Maven The UltimateAndroid use many opensource programs and I am very grateful to the them. The opensource program which I use: Butter Knife for View Injection retrofit RxJava RxAndroid RxBinding DiskLruCache glide google-gson glide-transformations If there's anything I forgot to mention,I would be very appreciated for helping me notice it. Screenshot: Screen Shot: License"
1732,HumHub - Open Source Social NetworkHumHub - Social Network Kit HumHub is a feature rich and highly flexible OpenSource Social Network Kit written in PHP. It's perfect for individual: - Social Intranets - Enterprise Social Networks - Private Social Networks More information: - Homepage & Demo - Documentation & Class Reference - Community - Licence
4803,"A highly customized dark theme for ChromeZeroDarkMatrix Theme for Chrome A highly customized dark theme for Google Chrome. Stable and Canary channels are officially supported. Beta and Dev channels will work, but I'm not testing on them. Please follow development for this theme at zero base themes. Installation Add Zero Dark Matrix from the Chrome Web Store. Open chrome://flags/#enable-devtools-experiments Enable Developer Tools experiments and click ""Relaunch Now"" at the bottom. Open the Developer Tools panel -> Click on the 3 dots on upper right hand side -> settings -> on left hand side drowdown set theme to 'Dark' In the same panel on the left hand side select the Experiments tab. Check 'Allow custom UI themes` Preview Elements Resources Timeline Network Sources CSS Highlighting JS Highlighting Console Features Majority of inspector chrome re-styled Customized Scrollbars Animations for finding elements setting elements inactive ** elements/sources/network panels Subtle pulsating element selection Re-styled Popovers (PSD files included) Child element styling in elements panel Credits Thanks to Simon Owen for the base styles. I used his So-Dark-Monokai-v3 as a starting point. CSS Tricks for the tutorial on customized scrollbars. Animate.css for some of the animations. Simon's version also used samples from other templates so I will thank them as well! * IR_Dark_Monokai - Designed and developed by Andres Pagella (@mapagella) * Todd Werth's IR_Black * toolbar code from Harris Novick * Inspired by Darcy Clarke's blog post * Automatic rake file Rodolfo Puig"
297,"A high-level browser automation library.Nightmare Nightmare is a high-level browser automation library from Segment. The goal is to expose a few simple methods that mimic user actions (like goto, type and click), with an API that feels synchronous for each block of scripting, rather than deeply nested callbacks. It was originally designed for automating tasks across sites that don't have APIs, but is most often used for UI testing and crawling. Under the covers it uses Electron, which is similar to PhantomJS but roughly twice as fast and more modern. Security Warning: We've implemented many of the security recommendations outlined by Electron to try and keep you safe, but undiscovered vulnerabilities may exist in Electron that could allow a malicious website to execute code on your computer. Avoid visiting untrusted websites. Migrating to 3.x: You'll want to check out this issue before upgrading. We've worked hard to make improvements to nightmare while limiting the breaking changes and there's a good chance you won't need to do anything. Niffy is a perceptual diffing tool built on Nightmare. It helps you detect UI changes and bugs across releases of your web app. Daydream is a complementary chrome extension built by @stevenmiller888 that generates Nightmare scripts for you while you browse. Many thanks to @matthewmueller and @rosshinkley for their help on Nightmare. Examples UI Testing Quick Start Perceptual Diffing with Niffy & Nightmare API Set up an instance Interact with the page Extract from the page Cookies Proxies Promises Extending Nightmare Usage Debugging Additional Resources Examples Let's search on DuckDuckGo: You can run this with: Or, let's run some mocha tests: You can see examples of every function in the tests here. To get started with UI Testing, check out this quick start guide. To install dependencies To run the mocha tests Node versions Nightmare is intended to be run on NodeJS 4.x or higher. API Nightmare(options) Creates a new instance that can navigate around the web. The available options are documented here, along with the following nightmare-specific options. waitTimeout (default: 30s) Throws an exception if the .wait() didn't return true within the set timeframe. gotoTimeout (default: 30s) Throws an exception if the .goto() didn't finish loading within the set timeframe. Note that, even though goto normally waits for all the resources on a page to load, a timeout exception is only raised if the DOM itself has not yet loaded. loadTimeout (default: infinite) Forces Nightmare to move on if a page transition caused by an action (eg, .click()) didn't finish within the set timeframe. If loadTimeout is shorter than gotoTimeout, the exceptions thrown by gotoTimeout will be suppressed. executionTimeout (default: 30s) The maximum amount of time to wait for an .evaluate() statement to complete. paths The default system paths that Electron knows about. Here's a list of available paths: https://github.com/atom/electron/blob/master/docs/api/app.md#appgetpathname You can overwrite them in Nightmare by doing the following: switches The command line switches used by the Chrome browser that are also supported by Electron. Here's a list of supported Chrome command line switches: https://github.com/atom/electron/blob/master/docs/api/chrome-command-line-switches.md electronPath The path to the prebuilt Electron binary. This is useful for testing on different versions of Electron. Note that Nightmare only supports the version on which this package depends. Use this option at your own risk. dock (OS X) A boolean to optionally show the Electron icon in the dock (defaults to false). This is useful for testing purposes. openDevTools Optionally shows the DevTools in the Electron window using true, or use an object hash containing mode: 'detach' to show in a separate window. The hash gets passed to contents.openDevTools() to be handled. This is also useful for testing purposes. Note that this option is honored only if show is set to true. typeInterval (default: 100ms) How long to wait between keystrokes when using .type(). pollInterval (default: 250ms) How long to wait between checks for the .wait() condition to be successful. maxAuthRetries (default: 3) Defines the number of times to retry an authentication when set up with .authenticate(). certificateSubjectName A string to determine the client certificate selected by electron. If this options is set, the select-client-certificate event will be set to loop through the certificateList and find the first certificate that matches subjectName on the electron Certificate Object. .engineVersions() Gets the versions for Electron and Chromium. .useragent(useragent) Sets the useragent used by electron. .authentication(user, password) Sets the user and password for accessing a web page using basic authentication. Be sure to set it before calling .goto(url). .end() Completes any queue operations, disconnect and close the electron process. Note that if you're using promises, .then() must be called after .end() to run the .end() task. Also note that if using an .end() callback, the .end() call is equivalent to calling .end() followed by .then(fn). Consider: .halt(error, done) Clears all queued operations, kills the electron process, and passes error message or 'Nightmare Halted' to an unresolved promise. Done will be called after the process has exited. Interact with the Page .goto(url[, headers]) Loads the page at url. Optionally, a headers hash can be supplied to set headers on the goto request. When a page load is successful, goto returns an object with metadata about the page load, including: url: The URL that was loaded code: The HTTP status code (e.g. 200, 404, 500) method: The HTTP method used (e.g. ""GET"", ""POST"") referrer: The page that the window was displaying prior to this load or an empty string if this is the first page load. headers: An object representing the response headers for the request as in {header1-name: header1-value, header2-name: header2-value} If the page load fails, the error will be an object with the following properties: message: A string describing the type of error code: The underlying error code describing what went wrong. Note this is NOT the HTTP status code. For possible values, see https://code.google.com/p/chromium/codesearch#chromium/src/net/base/net_error_list.h details: A string with additional details about the error. This may be null or an empty string. url: The URL that failed to load Note that any valid response from a server is considered successful. That means things like 404 not found errors are successful results for goto. Only things that would cause no page to appear in the browser window, such as no server responding at the given address, the server hanging up in the middle of a response, or invalid URLs, are errors. You can also adjust how long goto will wait before timing out by setting the gotoTimeout option on the Nightmare constructor. .back() Goes back to the previous page. .forward() Goes forward to the next page. .refresh() Refreshes the current page. .click(selector) Clicks the selector element once. .mousedown(selector) Mousedowns the selector element once. .mouseup(selector) Mouseups the selector element once. .mouseover(selector) Mouseovers the selector element once. .mouseout(selector) Mouseout the selector element once. .type(selector[, text]) Enters the text provided into the selector element. Empty or falsey values provided for text will clear the selector's value. .type() mimics a user typing in a textbox and will emit the proper keyboard events. Key presses can also be fired using Unicode values with .type(). For example, if you wanted to fire an enter key press, you would write .type('body', '\u000d'). If you don't need the keyboard events, consider using .insert() instead as it will be faster and more robust. .insert(selector[, text]) Similar to .type(), .insert() enters the text provided into the selector element. Empty or falsey values provided for text will clear the selector's value. .insert() is faster than .type() but does not trigger the keyboard events. .check(selector) Checks the selector checkbox element. .uncheck(selector) Unchecks the selector checkbox element. .select(selector, option) Changes the selector dropdown element to the option with attribute [value=option] .scrollTo(top, left) Scrolls the page to desired position. top and left are always relative to the top left corner of the document. .viewport(width, height) Sets the viewport size. .inject(type, file) Injects a local file onto the current page. The file type must be either js or css. .evaluate(fn[, arg1, arg2,...]) Invokes fn on the page with arg1, arg2,.... All the args are optional. On completion it returns the return value of fn. Useful for extracting information from the page. Here's an example: Error-first callbacks are supported as a part of evaluate(). If the arguments passed are one fewer than the arguments expected for the evaluated function, the evaluation will be passed a callback as the last parameter to the function. For example: Note that callbacks support only one value argument (eg function(err, value)). Ultimately, the callback will get wrapped in a native Promise and only be able to resolve a single value. Promises are also supported as a part of evaluate(). If the return value of the function has a then member, .evaluate() assumes it is waiting for a promise. For example: .wait(ms) Waits for ms milliseconds e.g. .wait(5000). .wait(selector) Waits until the element selector is present e.g. .wait('#pay-button'). .wait(fn[, arg1, arg2,...]) Waits until the fn evaluated on the page with arg1, arg2,... returns true. All the args are optional. See .evaluate() for usage. .header(header, value) Adds a header override for all HTTP requests. If header is undefined, the header overrides will be reset. Extract from the Page .exists(selector) Returns whether the selector exists or not on the page. .visible(selector) Returns whether the selector is visible or not. .on(event, callback) Captures page events with the callback. You have to call .on() before calling .goto(). Supported events are documented here. Additional ""page"" events .on('page', function(type=""error"", message, stack)) This event is triggered if any javascript exception is thrown on the page. But this event is not triggered if the injected javascript code (e.g. via .evaluate()) is throwing an exception. ""page"" events Listens for window.addEventListener('error'), alert(...), prompt(...) & confirm(...). .on('page', function(type=""error"", message, stack)) Listens for top-level page errors. This will get triggered when an error is thrown on the page. .on('page', function(type=""alert"", message)) Nightmare disables window.alert from popping up by default, but you can still listen for the contents of the alert dialog. .on('page', function(type=""prompt"", message, response)) Nightmare disables window.prompt from popping up by default, but you can still listen for the message to come up. If you need to handle the confirmation differently, you'll need to use your own preload script. .on('page', function(type=""confirm"", message, response)) Nightmare disables window.confirm from popping up by default, but you can still listen for the message to come up. If you need to handle the confirmation differently, you'll need to use your own preload script. .on('console', function(type [, arguments, ...])) type will be either log, warn or error and arguments are what gets passed from the console. This event is not triggered if the injected javascript code (e.g. via .evaluate()) is using console.log. .once(event, callback) Similar to .on(), but captures page events with the callback one time. .removeListener(event, callback) Removes a given listener callback for an event. .screenshot([path][, clip]) Takes a screenshot of the current page. Useful for debugging. The output is always a png. Both arguments are optional. If path is provided, it saves the image to the disk. Otherwise it returns a Buffer of the image data. If clip is provided (as documented here), the image will be clipped to the rectangle. .html(path, saveType) Saves the current page as html as files to disk at the given path. Save type options are here. .pdf(path, options) Saves a PDF to the specified path. Options are here. .title() Returns the title of the current page. .url() Returns the url of the current page. .path() Returns the path name of the current page. Cookies .cookies.get(name) Gets a cookie by it's name. The url will be the current url. .cookies.get(query) Queries multiple cookies with the query object. If a query.name is set, it will return the first cookie it finds with that name, otherwise it will query for an array of cookies. If no query.url is set, it will use the current url. Here's an example: Available properties are documented here: https://github.com/atom/electron/blob/master/docs/api/session.md#sescookiesgetdetails-callback .cookies.get() Gets all the cookies for the current url. If you'd like get all cookies for all urls, use: .get({ url: null }). .cookies.set(name, value) Sets a cookie's name and value. This is the most basic form, and the url will be the current url. .cookies.set(cookie) Sets a cookie. If cookie.url is not set, it will set the cookie on the current url. Here's an example: Available properties are documented here: https://github.com/atom/electron/blob/master/docs/api/session.md#sescookiessetdetails-callback .cookies.set(cookies) Sets multiple cookies at once. cookies is an array of cookie objects. Take a look at the .cookies.set(cookie) documentation above for a better idea of what cookie should look like. .cookies.clear([name]) Clears a cookie for the current domain. If name is not specified, all cookies for the current domain will be cleared. .cookies.clearAll() Clears all cookies for all domains. Proxies Proxies are supported in Nightmare through switches. If your proxy requires authentication you also need the authentication call. The following example not only demonstrates how to use proxies, but you can run it to test if your proxy connection is working: Promises By default, Nightmare uses default native ES6 promises. You can plug in your favorite ES6-style promises library like bluebird or q for convenience! Here's an example: You can also specify a custom Promise library per-instance with the Promise constructor option like so: Extending Nightmare Nightmare.action(name, [electronAction|electronNamespace], action|namespace) You can add your own custom actions to the Nightmare prototype. Here's an example: Remember, this is attached to the static class Nightmare, not the instance. You'll notice we used an internal function evaluate_now. This function is different than nightmare.evaluate because it runs it immediately, whereas nightmare.evaluate is queued. An easy way to remember: when in doubt, use evaluate. If you're creating custom actions, use evaluate_now. The technical reason is that since our action has already been queued and we're running it now, we shouldn't re-queue the evaluate function. We can also create custom namespaces. We do this internally for nightmare.cookies.get and nightmare.cookies.set. These are useful if you have a bundle of actions you want to expose, but it will clutter up the main nightmare object. Here's an example of that: You can also add custom Electron actions. The additional Electron action or namespace actions take name, options, parent, win, renderer, and done. Note the Electron action comes first, mirroring how .evaluate() works. For example: ...would clear the browsers cache before navigating to example.org. See this document for more details on creating custom actions. .use(plugin) nightmare.use is useful for reusing a set of tasks on an instance. Check out nightmare-swiftly for some examples. Custom preload script If you need to do something custom when you first load the window environment, you can specify a custom preload script. Here's how you do that: The only requirement for that script is that you'll need the following prelude: To benefit of all of nightmare's feedback from the browser, you can instead copy the contents of nightmare's preload script. Storage Persistence between nightmare instances By default nightmare will create an in-memory partition for each instance. This means that any localStorage or cookies or any other form of persistent state will be destroyed when nightmare is ended. If you would like to persist state between instances you can use the webPreferences.partition api in electron. If you specify a null paritition then it will use the electron default behavior (persistent) or any string that starts with 'persist:' will persist under that partition name, any other string will result in in-memory only storage. Usage Installation Nightmare is a Node.js module, so you'll need to have Node.js installed. Then you just need to npm install the module: Execution Nightmare is a node module that can be used in a Node.js script or module. Here's a simple script to open a web page: If you save this as cnn.js, you can run it on the command line like this: Common Execution Problems Nightmare heavily relies on Electron for heavy lifting. And Electron in turn relies on several UI-focused dependencies (eg. libgtk+) which are often missing from server distros. For help running nightmare on your server distro check out How to run nightmare on Amazon Linux and CentOS guide. Debugging There are three good ways to get more information about what's happening inside the headless browser: Use the DEBUG=* flag described below. Pass { show: true } to the nightmare constructor to have it create a visible, rendered window where you can watch what is happening. Listen for specific events. To run the same file with debugging output, run it like this DEBUG=nightmare node cnn.js (on Windows use set DEBUG=nightmare & node cnn.js). This will print out some additional information about what's going on: Debug Flags All nightmare messages DEBUG=nightmare* Only actions DEBUG=nightmare:actions* Only logs DEBUG=nightmare:log* Additional Resources Ross Hinkley's Nightmare Examples is a great resource for setting up nightmare, learning about custom actions, and avoiding common pitfalls. Nightmare Issues has a bunch of standalone runnable examples. The script numbers correspond to nightmare issue numbers. Nightmarishly good scraping is a great tutorial by ndrew Rininsland on getting up & running with Nightmare using real-life data. Tests Automated tests for nightmare itself are run using Mocha and Chai, both of which will be installed via npm install. To run nightmare's tests, just run make test. When the tests are done, you'll see something like this: Note that if you are using xvfb, make test will automatically run the tests under an xvfb-run wrapper. If you are planning to run the tests headlessly without running xvfb first, set the HEADLESS environment variable to 0. License (MIT) Copyright (c) 2015 Segment.io, Inc. friends@segment.com Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the 'Software'), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED 'AS IS', WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
3377,"Kalman Filter book using Jupyter Notebook. Focuses on building intuition and experience, not formal proofs. Includes Kalman filters,extended Kalman filters, unscented Kalman filters, particle filters, and more. All exercises include solutions.Kalman and Bayesian Filters in Python Introductory text for Kalman and Bayesian filters. All code is written in Python, and the book itself is written using Juptyer Notebook so that you can run and modify the code in your browser. What better way to learn? ""Kalman and Bayesian Filters in Python"" looks amazing! ... your book is just what I needed - Allen Downey, Professor and O'Reilly author. Thanks for all your work on publishing your introductory text on Kalman Filtering, as well as the Python Kalman Filtering libraries. Weve been using it internally to teach some key state estimation concepts to folks and its been a huge help. - Sam Rodkey, SpaceX Start reading online now by clicking the binder or Azure badge below: What are Kalman and Bayesian Filters? Sensors are noisy. The world is full of data and events that we want to measure and track, but we cannot rely on sensors to give us perfect information. The GPS in my car reports altitude. Each time I pass the same point in the road it reports a slightly different altitude. My kitchen scale gives me different readings if I weigh the same object twice. In simple cases the solution is obvious. If my scale gives slightly different readings I can just take a few readings and average them. Or I can replace it with a more accurate scale. But what do we do when the sensor is very noisy, or the environment makes data collection difficult? We may be trying to track the movement of a low flying aircraft. We may want to create an autopilot for a drone, or ensure that our farm tractor seeded the entire field. I work on computer vision, and I need to track moving objects in images, and the computer vision algorithms create very noisy and unreliable results. This book teaches you how to solve these sorts of filtering problems. I use many different algorithms, but they are all based on Bayesian probability. In simple terms Bayesian probability determines what is likely to be true based on past information. If I asked you the heading of my car at this moment you would have no idea. You'd proffer a number between 1 and 360 degrees, and have a 1 in 360 chance of being right. Now suppose I told you that 2 seconds ago its heading was 243. In 2 seconds my car could not turn very far, so you could make a far more accurate prediction. You are using past information to more accurately infer information about the present or future. The world is also noisy. That prediction helps you make a better estimate, but it also subject to noise. I may have just braked for a dog or swerved around a pothole. Strong winds and ice on the road are external influences on the path of my car. In control literature we call this noise though you may not think of it that way. There is more to Bayesian probability, but you have the main idea. Knowledge is uncertain, and we alter our beliefs based on the strength of the evidence. Kalman and Bayesian filters blend our noisy and limited knowledge of how a system behaves with the noisy and limited sensor readings to produce the best possible estimate of the state of the system. Our principle is to never discard information. Say we are tracking an object and a sensor reports that it suddenly changed direction. Did it really turn, or is the data noisy? It depends. If this is a jet fighter we'd be very inclined to believe the report of a sudden maneuver. If it is a freight train on a straight track we would discount it. We'd further modify our belief depending on how accurate the sensor is. Our beliefs depend on the past and on our knowledge of the system we are tracking and on the characteristics of the sensors. The Kalman filter was invented by Rudolf Emil Klmn to solve this sort of problem in a mathematically optimal way. Its first use was on the Apollo missions to the moon, and since then it has been used in an enormous variety of domains. There are Kalman filters in aircraft, on submarines, and on cruise missiles. Wall street uses them to track the market. They are used in robots, in IoT (Internet of Things) sensors, and in laboratory instruments. Chemical plants use them to control and monitor reactions. They are used to perform medical imaging and to remove noise from cardiac signals. If it involves a sensor and/or time-series data, a Kalman filter or a close relative to the Kalman filter is usually involved. Motivation The motivation for this book came out of my desire for a gentle introduction to Kalman filtering. I'm a software engineer that spent almost two decades in the avionics field, and so I have always been 'bumping elbows' with the Kalman filter, but never implemented one myself. As I moved into solving tracking problems with computer vision the need became urgent. There are classic textbooks in the field, such as Grewal and Andrew's excellent Kalman Filtering. But sitting down and trying to read many of these books is a dismal experience if you do not have the required background. Typically the first few chapters fly through several years of undergraduate math, blithely referring you to textbooks on topics such as It calculus, and present an entire semester's worth of statistics in a few brief paragraphs. They are good texts for an upper undergraduate course, and an invaluable reference to researchers and professionals, but the going is truly difficult for the more casual reader. Symbology is introduced without explanation, different texts use different terms and variables for the same concept, and the books are almost devoid of examples or worked problems. I often found myself able to parse the words and comprehend the mathematics of a definition, but had no idea as to what real world phenomena they describe. ""But what does that mean?"" was my repeated thought. However, as I began to finally understand the Kalman filter I realized the underlying concepts are quite straightforward. A few simple probability rules, some intuition about how we integrate disparate knowledge to explain events in our everyday life and the core concepts of the Kalman filter are accessible. Kalman filters have a reputation for difficulty, but shorn of much of the formal terminology the beauty of the subject and of their math became clear to me, and I fell in love with the topic. As I began to understand the math and theory more difficulties present themselves. A book or paper's author makes some statement of fact and presents a graph as proof. Unfortunately, why the statement is true is not clear to me, nor is the method for making that plot obvious. Or maybe I wonder ""is this true if R=0?"" Or the author provides pseudocode at such a high level that the implementation is not obvious. Some books offer Matlab code, but I do not have a license to that expensive package. Finally, many books end each chapter with many useful exercises. Exercises which you need to understand if you want to implement Kalman filters for yourself, but exercises with no answers. If you are using the book in a classroom, perhaps this is okay, but it is terrible for the independent reader. I loathe that an author withholds information from me, presumably to avoid 'cheating' by the student in the classroom. From my point of view none of this is necessary. Certainly if you are designing a Kalman filter for an aircraft or missile you must thoroughly master all of the mathematics and topics in a typical Kalman filter textbook. I just want to track an image on a screen, or write some code for an Arduino project. I want to know how the plots in the book are made, and chose different parameters than the author chose. I want to run simulations. I want to inject more noise in the signal and see how a filter performs. There are thousands of opportunities for using Kalman filters in everyday code, and yet this fairly straightforward topic is the provenance of rocket scientists and academics. I wrote this book to address all of those needs. This is not the book for you if you program navigation computers for Boeing or design radars for Raytheon. Go get an advanced degree at Georgia Tech, UW, or the like, because you'll need it. This book is for the hobbyist, the curious, and the working engineer that needs to filter or smooth data. This book is interactive. While you can read it online as static content, I urge you to use it as intended. It is written using Jupyter Notebook, which allows me to combine text, math, Python, and Python output in one place. Every plot, every piece of data in this book is generated from Python that is available to you right inside the notebook. Want to double the value of a parameter? Click on the Python cell, change the parameter's value, and click 'Run'. A new plot or printed output will appear in the book. This book has exercises, but it also has the answers. I trust you. If you just need an answer, go ahead and read the answer. If you want to internalize this knowledge, try to implement the exercise before you read the answer. This book has supporting libraries for computing statistics, plotting various things related to filters, and for the various filters that we cover. This does require a strong caveat; most of the code is written for didactic purposes. It is rare that I chose the most efficient solution (which often obscures the intent of the code), and in the first parts of the book I did not concern myself with numerical stability. This is important to understand - Kalman filters in aircraft are carefully designed and implemented to be numerically stable; the naive implementation is not stable in many cases. If you are serious about Kalman filters this book will not be the last book you need. My intention is to introduce you to the concepts and mathematics, and to get you to the point where the textbooks are approachable. Finally, this book is free. The cost for the books required to learn Kalman filtering is somewhat prohibitive even for a Silicon Valley engineer like myself; I cannot believe they are within the reach of someone in a depressed economy, or a financially struggling student. I have gained so much from free software like Python, and free books like those from Allen B. Downey here. It's time to repay that. So, the book is free, it is hosted on free servers, and it uses only free and open software such as IPython and MathJax to create the book. Reading Online The book is written as a collection of Jupyter Notebooks, an interactive, browser based system that allows you to combine text, Python, and math into your browser. There are multiple ways to read these online, listed below. binder binder serves interactive notebooks online, so you can run the code and change the code within your browser without downloading the book or installing Jupyter. nbviewer The website http://nbviewer.org provides a Jupyter Notebook server that renders notebooks stored at github (or elsewhere). The rendering is done in real time when you load the book. You may use this nbviewer link to access my book via nbviewer. If you read my book today, and then I make a change tomorrow, when you go back tomorrow you will see that change. Notebooks are rendered statically - you can read them, but not modify or run the code. nbviewer seems to lag the checked in version by a few days, so you might not be reading the most recent content. GitHub GitHub is able to render the notebooks directly. The quickest way to view a notebook is to just click on them above. However, it renders the math incorrectly, and I cannot recommend using it if you are doing more than just dipping into the book. PDF Version A PDF version of the book is available here The PDF will usually lag behind what is in github as I don't update it for every minor check in. Downloading and Running the Book However, this book is intended to be interactive and I recommend using it in that form. It's a little more effort to set up, but worth it. If you install IPython and some supporting libraries on your computer and then clone this book you will be able to run all of the code in the book yourself. You can perform experiments, see how filters react to different data, see how different filters react to the same data, and so on. I find this sort of immediate feedback both vital and invigorating. You do not have to wonder ""what happens if"". Try it and see! The book and supporting software can be downloaded from GitHub by running this command on the command line: git clone --depth=1 https://github.com/rlabbe/Kalman-and-Bayesian-Filters-in-Python.git pip install filterpy Instructions for installation of the IPython ecosystem can be found in the Installation appendix, found here. Once the software is installed you can navigate to the installation directory and run Juptyer notebook with the command line instruction jupyter notebook This will open a browser window showing the contents of the base directory. The book is organized into chapters, each contained within one IPython Notebook (these notebook files have a .ipynb file extension). For example, to read Chapter 2, click on the file 02-Discrete-Bayes.ipynb. Sometimes there are supporting notebooks for doing things like generating animations that are displayed in the chapter. These are not intended to be read by the end user, but of course if you are curious as to how an animation is made go ahead and take a look. You can find these notebooks in the folder named Supporting_Notebooks. This is admittedly a somewhat cumbersome interface to a book; I am following in the footsteps of several other projects that are somewhat repurposing Jupyter Notebook to generate entire books. I feel the slight annoyances have a huge payoff - instead of having to download a separate code base and run it in an IDE while you try to read a book, all of the code and text is in one place. If you want to alter the code, you may do so and immediately see the effects of your change. If you find a bug, you can make a fix, and push it back to my repository so that everyone in the world benefits. And, of course, you will never encounter a problem I face all the time with traditional books - the book and the code are out of sync with each other, and you are left scratching your head as to which source to trust. Companion Software I wrote an open source Bayesian filtering Python library called FilterPy. I have made the project available on PyPi, the Python Package Index. To install from PyPi, at the command line issue the command pip install filterpy If you do not have pip, you may follow the instructions here: https://pip.pypa.io/en/latest/installing.html. All of the filters used in this book as well as others not in this book are implemented in my Python library FilterPy, available here. You do not need to download or install this to read the book, but you will likely want to use this library to write your own filters. It includes Kalman filters, Fading Memory filters, H infinity filters, Extended and Unscented filters, least square filters, and many more. It also includes helper routines that simplify the designing the matrices used by some of the filters, and other code such as Kalman based smoothers. FilterPy is hosted on github at (https://github.com/rlabbe/filterpy). If you want the bleeding edge release you will want to grab a copy from github, and follow your Python installation's instructions for adding it to the Python search path. This might expose you to some instability since you might not get a tested release, but as a benefit you will also get all of the test scripts used to test the library. You can examine these scripts to see many examples of writing and running filters while not in the Jupyter Notebook environment. Alternative Way of Running the Book in Conda environment If you have conda or miniconda installed, you can create an environment by conda env update -f environment.yml and use conda activate kf_bf and conda deactivate kf_bf to activate and deactivate the environment. Issues or Questions If you have comments, you can write an issue at GitHub so that everyone can read it along with my response. Please don't view it as a way to report bugs only. Alternatively I've created a gitter room for more informal discussion. License Kalman and Bayesian Filters in Python by Roger R. Labbe is licensed under a Creative Commons Attribution 4.0 International License. All software in this book, software that supports this book (such as in the the code directory) or used in the generation of the book (in the pdf directory) that is contained in this repository is licensed under the following MIT license: The MIT License (MIT) Copyright (c) 2015 Roger R. Labbe Jr Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the ""Software""), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.TION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. Contact rlabbejr at gmail.com"
65,"Elegant HTTP Networking in SwiftAlamofire is an HTTP networking library written in Swift. Features Component Libraries Requirements Migration Guides Communication Installation Usage Introduction - Making Requests, Response Handling, Response Validation, Response Caching HTTP - HTTP Methods, Parameters and Parameter Encoder, HTTP Headers, Authentication Large Data - Downloading Data to a File, Uploading Data to a Server Tools - Statistical Metrics, cURL Command Output Advanced Usage URL Session - Session Manager, Session Delegate, Request Routing - Routing Requests, Adapting and Retrying Requests Model Objects - Custom Response Handlers Connection - Security, Network Reachability Open Radars FAQ Credits Donations License Features [x] Chainable Request / Response Methods [x] Combine Support [x] URL / JSON Parameter Encoding [x] Upload File / Data / Stream / MultipartFormData [x] Download File using Request or Resume Data [x] Authentication with URLCredential [x] HTTP Response Validation [x] Upload and Download Progress Closures with Progress [x] cURL Command Output [x] Dynamically Adapt and Retry Requests [x] TLS Certificate and Public Key Pinning [x] Network Reachability [x] Comprehensive Unit and Integration Test Coverage [x] Complete Documentation Component Libraries In order to keep Alamofire focused specifically on core networking implementations, additional component libraries have been created by the Alamofire Software Foundation to bring additional functionality to the Alamofire ecosystem. AlamofireImage - An image library including image response serializers, UIImage and UIImageView extensions, custom image filters, an auto-purging in-memory cache, and a priority-based image downloading system. AlamofireNetworkActivityIndicator - Controls the visibility of the network activity indicator on iOS using Alamofire. It contains configurable delay timers to help mitigate flicker and can support URLSession instances not managed by Alamofire. Requirements iOS 10.0+ / macOS 10.12+ / tvOS 10.0+ / watchOS 3.0+ Xcode 11+ Swift 5.1+ Migration Guides Alamofire 5.0 Migration Guide Alamofire 4.0 Migration Guide Alamofire 3.0 Migration Guide Alamofire 2.0 Migration Guide Communication If you need help with making network requests using Alamofire, use Stack Overflow and tag alamofire. If you need to find or understand an API, check our documentation or Apple's documentation for URLSession, on top of which Alamofire is built. If you need help with an Alamofire feature, use our forum on swift.org. If you'd like to discuss Alamofire best practices, use our forum on swift.org. If you'd like to discuss a feature request, use our forum on swift.org. If you found a bug, open an issue here on GitHub and follow the guide. The more detail the better! If you want to contribute, submit a pull request! Installation CocoaPods CocoaPods is a dependency manager for Cocoa projects. For usage and installation instructions, visit their website. To integrate Alamofire into your Xcode project using CocoaPods, specify it in your Podfile: Carthage Carthage is a decentralized dependency manager that builds your dependencies and provides you with binary frameworks. To integrate Alamofire into your Xcode project using Carthage, specify it in your Cartfile: Swift Package Manager The Swift Package Manager is a tool for automating the distribution of Swift code and is integrated into the swift compiler. It is in early development, but Alamofire does support its use on supported platforms. Once you have your Swift package set up, adding Alamofire as a dependency is as easy as adding it to the dependencies value of your Package.swift. Manually If you prefer not to use any of the aforementioned dependency managers, you can integrate Alamofire into your project manually. Embedded Framework Open up Terminal, cd into your top-level project directory, and run the following command ""if"" your project is not initialized as a git repository: Add Alamofire as a git submodule by running the following command: Open the new Alamofire folder, and drag the Alamofire.xcodeproj into the Project Navigator of your application's Xcode project. It should appear nested underneath your application's blue project icon. Whether it is above or below all the other Xcode groups does not matter. Select the Alamofire.xcodeproj in the Project Navigator and verify the deployment target matches that of your application target. Next, select your application project in the Project Navigator (blue project icon) to navigate to the target configuration window and select the application target under the ""Targets"" heading in the sidebar. In the tab bar at the top of that window, open the ""General"" panel. Click on the + button under the ""Embedded Binaries"" section. You will see two different Alamofire.xcodeproj folders each with two different versions of the Alamofire.framework nested inside a Products folder. It does not matter which Products folder you choose from, but it does matter whether you choose the top or bottom Alamofire.framework. Select the top Alamofire.framework for iOS and the bottom one for macOS. You can verify which one you selected by inspecting the build log for your project. The build target for Alamofire will be listed as Alamofire iOS, Alamofire macOS, Alamofire tvOS, or Alamofire watchOS. And that's it! The Alamofire.framework is automagically added as a target dependency, linked framework and embedded framework in a copy files build phase which is all you need to build on the simulator and a device. Open Radars The following radars have some effect on the current implementation of Alamofire. rdar://21349340 - Compiler throwing warning due to toll-free bridging issue in the test case rdar://26870455 - Background URL Session Configurations do not work in the simulator rdar://26849668 - Some URLProtocol APIs do not properly handle URLRequest FB7624529 - urlSession(_:task:didFinishCollecting:) never called on watchOS Resolved Radars The following radars have been resolved over time after being filed against the Alamofire project. rdar://26761490 - Swift string interpolation causing memory leak with common usage. (Resolved): 9/1/17 in Xcode 9 beta 6. rdar://36082113 - URLSessionTaskMetrics failing to link on watchOS 3.0+ (Resolved): Just add CFNetwork to your linked frameworks. Workarounds Collection of URLSessionTaskMetrics is currently disabled on watchOS due to FB7624529. FAQ What's the origin of the name Alamofire? Alamofire is named after the Alamo Fire flower, a hybrid variant of the Bluebonnet, the official state flower of Texas. Credits Alamofire is owned and maintained by the Alamofire Software Foundation. You can follow them on Twitter at @AlamofireSF for project updates and releases. Security Disclosure If you believe you have identified a security vulnerability with Alamofire, you should report it as soon as possible via email to security@alamofire.org. Please do not post it to a public issue tracker. Donations The ASF is looking to raise money to officially stay registered as a federal non-profit organization. Registering will allow Foundation members to gain some legal protections and also allow us to put donations to use, tax-free. Donating to the ASF will enable us to: Pay our yearly legal fees to keep the non-profit in good status Pay for our mail servers to help us stay on top of all questions and security issues Potentially fund test servers to make it easier for us to test the edge cases Potentially fund developers to work on one of our projects full-time The community adoption of the ASF libraries has been amazing. We are greatly humbled by your enthusiasm around the projects and want to continue to do everything we can to move the needle forward. With your continued support, the ASF will be able to improve its reach and also provide better legal safety for the core members. If you use any of our libraries for work, see if your employers would be interested in donating. Any amount you can donate today to help us reach our goal would be greatly appreciated. Supporters MacStadium provides Alamofire with a free, hosted Mac mini. License Alamofire is released under the MIT license. See LICENSE for details."
12,"Linux kernel source treeLinux kernel There are several guides for kernel developers and users. These guides can be rendered in a number of formats, like HTML and PDF. Please read Documentation/admin-guide/README.rst first. In order to build the documentation, use make htmldocs or make pdfdocs. The formatted documentation can also be read online at: https://www.kernel.org/doc/html/latest/ There are various text files in the Documentation/ subdirectory, several of them using the Restructured Text markup notation. Please read the Documentation/process/changes.rst file, as it contains the requirements for building and running the kernel, and information about the problems which may result by upgrading your kernel."
485,"GitHub on steroidsAbout Browser extension that enhances GitHub code review and exploration. You can download Octotree for your browser from our website. Octotree supports Chrome, Firefox, Edge, Opera and Safari. Support Please check out the troubleshooting guide to see if it solves the problem. If it doesn't, please either create a forum ticket or send an email to support@octotree.io. Learn more Demo User guide Authentication Browser permissions Copyright Octotree is a proprietary software. This repository contains the old source code of a very limited version of Octotree. The Octotree team owns the complete copyright over this code."
4556,"dat.gui is a lightweight controller library for JavaScript.dat.GUI A lightweight graphical user interface for changing variables in JavaScript. Get started with dat.GUI by reading the API documentation. Packaged Builds The easiest way to use dat.GUI in your code is by using the built source at build/dat.gui.min.js. These built JavaScript files bundle all the necessary dependencies to run dat.GUI. In your head tag, include the following code: Installing from npm Directory Contents Building your own dat.GUI In the terminal, enter the following: npm scripts npm run build - Build development and production version of scripts. npm run dev - Build development version of script and watch for changes. Working with Content Security Policy If you're using a server with a Content Security Policy in place that blocks 'unsafe-inline', you will have problems when dat.gui.js tries to inject style information. To get around this, load 'build/dat.gui.css' as an external style sheet. Changes View the Change Log Thanks The following libraries / open-source projects were used in the development of dat.GUI: * Rollup * Sass * Node.js * QUnit / jquery"
472,"An open-source C++ library developed and used at Facebook.Folly: Facebook Open-source Library What is folly? Folly (acronymed loosely after Facebook Open Source Library) is a library of C++14 components designed with practicality and efficiency in mind. Folly contains a variety of core library components used extensively at Facebook. In particular, it's often a dependency of Facebook's other open source C++ efforts and place where those projects can share code. It complements (as opposed to competing against) offerings such as Boost and of course std. In fact, we embark on defining our own component only when something we need is either not available, or does not meet the needed performance profile. We endeavor to remove things from folly if or when std or Boost obsoletes them. Performance concerns permeate much of Folly, sometimes leading to designs that are more idiosyncratic than they would otherwise be (see e.g. PackedSyncPtr.h, SmallLocks.h). Good performance at large scale is a unifying theme in all of Folly. Logical Design Folly is a collection of relatively independent components, some as simple as a few symbols. There is no restriction on internal dependencies, meaning that a given folly module may use any other folly components. All symbols are defined in the top-level namespace folly, except of course macros. Macro names are ALL_UPPERCASE and should be prefixed with FOLLY_. Namespace folly defines other internal namespaces such as internal or detail. User code should not depend on symbols in those namespaces. Folly has an experimental directory as well. This designation connotes primarily that we feel the API may change heavily over time. This code, typically, is still in heavy use and is well tested. Physical Design At the top level Folly uses the classic ""stuttering"" scheme folly/folly used by Boost and others. The first directory serves as an installation root of the library (with possible versioning a la folly-1.0/), and the second is to distinguish the library when including files, e.g. #include <folly/FBString.h>. The directory structure is flat (mimicking the namespace structure), i.e. we don't have an elaborate directory hierarchy (it is possible this will change in future versions). The subdirectory experimental contains files that are used inside folly and possibly at Facebook but not considered stable enough for client use. Your code should not use files in folly/experimental lest it may break when you update Folly. The folly/folly/test subdirectory includes the unittests for all components, usually named ComponentXyzTest.cpp for each ComponentXyz.*. The folly/folly/docs directory contains documentation. What's in it? Because of folly's fairly flat structure, the best way to see what's in it is to look at the headers in top level folly/ directory. You can also check the docs folder for documentation, starting with the overview. Folly is published on GitHub at https://github.com/facebook/folly Build Notes Because folly does not provide any ABI compatibility guarantees from commit to commit, we generally recommend building folly as a static library. build.sh The simplest way to build folly is using the build.sh script in the top-level of the repository. build.sh can be used on Linux and MacOS, on Windows use the build.bat script instead. This script will download and build all of the necessary dependencies first, and will then build folly. This will help ensure that you build with recent versions of all of the dependent libraries, regardless of what versions are installed locally on your system. By default this script will build and install folly and its dependencies in a scratch directory. You can also specify a --scratch-path argument to control the location of the scratch directory used for the build. There are also --install-dir and --install-prefix arguments to provide some more fine-grained control of the installation directories. However, given that folly provides no compatibility guarantees between commits we generally recommend building and installing the libraries to a temporary location, and then pointing your project's build at this temporary location, rather than installing folly in the traditional system installation directories. e.g., if you are building with CMake you can use the CMAKE_PREFIX_PATH variable to allow CMake to find folly in this temporary installation directory when building your project. Dependencies folly supports gcc (5.1+), clang, or MSVC. It should run on Linux (x86-32, x86-64, and ARM), iOS, macOS, and Windows (x86-64). The CMake build is only tested on some of these platforms; at a minimum, we aim to support macOS and Linux (on the latest Ubuntu LTS release or newer.) folly requires a version of boost compiled with C++14 support. googletest is required to build and run folly's tests. You can download it from https://github.com/google/googletest/archive/release-1.8.0.tar.gz The following commands can be used to download and install it: Finding dependencies in non-default locations If you have boost, gtest, or other dependencies installed in a non-default location, you can use the CMAKE_INCLUDE_PATH and CMAKE_LIBRARY_PATH variables to make CMAKE look also look for header files and libraries in non-standard locations. For example, to also search the directories /alt/include/path1 and /alt/include/path2 for header files and the directories /alt/lib/path1 and /alt/lib/path2 for libraries, you can invoke cmake as follows: Building tests By default, building the tests is disabled as part of the CMake all target. To build the tests, specify -DBUILD_TESTS=ON to CMake at configure time. Ubuntu 16.04 LTS The following packages are required (feel free to cut and paste the apt-get command below): Folly relies on fmt which needs to be installed from source. The following commands will download, compile, and install fmt. If advanced debugging functionality is required, use: In the folly directory (e.g. the checkout root or the archive unpack root), run: OS X (Homebrew) folly is available as a Formula and releases may be built via brew install folly. You may also use folly/build/bootstrap-osx-homebrew.sh to build against master: This will create a build directory _build in the top-level. OS X (MacPorts) Install the required packages from MacPorts: Download and install double-conversion: Download and install folly with the parameters listed below: Windows (Vcpkg) folly is available in Vcpkg and releases may be built via vcpkg install folly:x64-windows. You may also use vcpkg install folly:x64-windows --head to build against master. Other Linux distributions double-conversion (https://github.com/google/double-conversion) Download and build double-conversion. You may need to tell cmake where to find it. [double-conversion/] ln -s src double-conversion [folly/] mkdir build && cd build [folly/build/] cmake ""-DCMAKE_INCLUDE_PATH=$DOUBLE_CONVERSION_HOME/include"" ""-DCMAKE_LIBRARY_PATH=$DOUBLE_CONVERSION_HOME/lib"" .. [folly/build/] make additional platform specific dependencies: Fedora >= 21 64-bit (last tested on Fedora 28 64-bit) - gcc - gcc-c++ - cmake - automake - boost-devel - libtool - lz4-devel - lzma-devel - snappy-devel - zlib-devel - glog-devel - gflags-devel - scons - double-conversion-devel - openssl-devel - libevent-devel - fmt-devel - libsodium-devel Optional - libdwarf-devel - elfutils-libelf-devel - libunwind-devel"
3544,"Graph drawing library for JavaScriptVivaGraph VivaGraphJS is designed to be extensible and to support different rendering engines and layout algorithms. Underlying algorithms have been broken out into ngraph. The larger family of modules can be found by querying npm for ""ngraph"". Enough talking. Show me the demo! Some examples of library usage in the real projects: Amazon Visualization Shows related products on Amazon.com, uses SVG as graph output Graph Viewer visualization of sparse matrices collection of the University of Florida. WebGL based. Vkontakte Visualization friendship visualization of the largest social network in Russia vk.com. WebGL based. To start using the library include vivagraph.js script from the dist folder. The following code is the minimum required to render a graph with two nodes and one edge: This will instantiate a graph inside document.body: If you want to render graph in your own DOM element: The code above adds a link to the graph between nodes 1 and 2. Since nodes are not yet in the graph they will be created. It's equivalent to Customization VivaGraphJS is all about customization. You can easily change the appearance of nodes and links. You can also change the layouting algorithm and medium that displays elements of the graph. For example: The following code allows you to use WebGL-based rendering, instead of the default SVG. graphics class is responsible for rendering nodes and links on the page. And renderer orchestrates the process. To change nodes appearance tell graphics how to represent them. Here is an example of graph with six people who I follow at github: The result is: Tuning layout algorithm Graphs vary by their nature. Some graphs have hundreds of nodes and few edges (or links), some might connect every node with every other. Tuning the physics often helps get the best layout. Consider the following example: Graph generators are part of the library, which can produce classic graphs. grid generator creates a grid with given number of columns and rows. But with default parameters the rendering is pretty ugly: Let's tweak the original code: Now the result is much better: You can tune values during simulation with layout.simulator.springLength(newValue), layout.simulator.springCoeff(newValue), etc. See all the values that you can tune in this source file. Tuning layout algorithm is definitely one of the hardest part of using this library. It has to be improved in future to simplify usage. Each of the force directed algorithm parameters are described in the source code. Design philosophy/roadmap Until version 0.7.x VivaGraph was a single monolithic code base. Starting from 0.7.x the library is bundled from small npm modules into Viva namespace. All these modules are part of a larger ngraph family. ngraph modules support rendering graphs into images, 3D rendering, integration with gephi, pagerank calculation and many more. Version 0.7 is a compromise between maximum backward compatibility and ngraph flexibility. Eventually I hope to further simplify API and provide interface for custom builds. Upgrade guide Please refer the upgrade guide to see how to update older versions of the library to the latest one. Local Build Run the following script: The combined/minified code should be stored in folder. Looking for alternatives? I'm trying to put up a list of all known graph drawing libraries. Please find it here I need your feedback Disclaimer: I wrote this library to learn JavaScript. By no means I pretend to be an expert in the language and chosen approach to design may not be the optimal. I would love to hear your feedback and suggestions. Though I implemented this library from scratch, I went through many existing libraries to pick the best (at my view) out of them. If you are evaluating libraries for your project make sure to check them out as well. My goal is to create highly performant javascript library, which serves in the field of graph drawing. To certain extent I achieved it. But I have no doubt there is much more to improve here."
3611,"A jQuery Masonry alternative with CSS-driven configuration.Salvattore Salvattore is a library agnostic JS script that will help you organize your HTML elements according to the number of columns you specify, like jQuery Masonry. Features No requirements: Salvattore is a standalone script, it will work right away after being referenced in your HTML page. Extremely lightweight: about 2.7KB (minified and gzipped.) CSS-driven configuration: the number of columns is defined in CSS and the styling is left to the user. Media queries ready: the same parameters can be used inside media queries for better results on different devices. Wide browser support: modern browsers and IE9+ Upcoming Balanced columns: to keep all columns about the same height. To find out more and see it in action, please visit our website. You can also follow us on Twitter. Methods Methods can be called on the globally exposed salvattore object for advanced usage. Method | Argument | Description ------ | -------- | ----------- appendElements | grid : DOM object, elements: Array of DOM objects | Adds elements to the end of a grid. prependElements | grid : DOM object, elements: Array of DOM objects | Adds elements to a beginning of a grid. Adds multiple elements one by one before each other, so note the order. registerGrid | grid : DOM object | Adds a new grid to salvattore. Which is initialized automatically then. recreateColumns | grid : DOM object | Removes all the columns from the grid, and adds them again. rescanMediaQueries | | Checks stylesheets and selectors for media queries again. Recreates the columns for all grids afterwards. How to contribute We use Gulp to add polyfills and minify the script in the dist/ folder. To make changes to the script itself, please edit src/salvattore.js and send us a pull request. Share feedback & ideas You can even contribute by using Salvattore and sharing bugs, ideas or solutions on the Issues page. Protip: if you're posting a bug please share all the relevant data and ideally a live URL so that we can debug (yeah we do that!)"
315,"The official jQuery user interface library.jQuery UI - Interactions and Widgets for the web jQuery UI is a curated set of user interface interactions, effects, widgets, and themes built on top of jQuery. Whether you're building highly interactive web applications, or you just need to add a date picker to a form control, jQuery UI is the perfect choice. If you want to use jQuery UI, go to jqueryui.com to get started, jqueryui.com/demos/ for demos, api.jqueryui.com for API documentation, or the Using jQuery UI Forum for discussions and questions. If you want to report a bug/issue, please visit bugs.jqueryui.com. If you are interested in helping develop jQuery UI, you are in the right place. To discuss development with team members and the community, visit the Developing jQuery UI Forum or #jqueryui-dev on irc.freenode.net. For Contributors If you want to help and provide a patch for a bugfix or new feature, please take a few minutes and look at our Getting Involved guide. In particular check out the Coding standards and Commit Message Style Guide. In general, fork the project, create a branch for a specific change and send a pull request for that branch. Don't mix unrelated changes. You can use the commit message as the description for the pull request. For more information, see the contributing page. Running the Unit Tests Run the unit tests manually with appropriate browsers and any local web server. See our environment setup and information on running tests. You can also run the unit tests inside phantomjs by setting up your environment."
1543,"A data-driven UICollectionView framework for building fast and flexible lists. A data-driven UICollectionView framework for building fast and flexible lists. | | Main Features | ----------|----------------- | Never call performBatchUpdates(_:, completion:) or reloadData() again | Better architecture with reusable cells and components | Create collections with multiple data types | Decoupled diffing algorithm | Fully unit tested | Customize your diffing behavior for your models | Simply UICollectionView at its core | Extendable API | Written in Objective-C with full Swift interop support IGListKit is built and maintained with by Instagram engineering. We use the open source version master branch in the Instagram app. Multilingual translation Chinese README Requirements Xcode 9.0+ iOS 9.0+ tvOS 9.0+ macOS 10.11+ (diffing algorithm components only) Interoperability with Swift 3.0+ Installation CocoaPods The preferred installation method is with CocoaPods. Add the following to your Podfile: Carthage For Carthage, add the following to your Cartfile: For advanced usage, see our Installation Guide. Getting Started Our Getting Started guide Ray Wenderlich's IGListKit Tutorial: Better UICollectionViews Our example projects Ryan Nystrom's talk at try! Swift NYC(Note: this talk was for an earlier version. Some APIs have changed.) Migrating an UITableView to IGListCollectionView, by Rodrigo Cavalcante Keeping data fresh in Buffer for iOS with AsyncDisplayKit, IGListKit & Pusher, Andy Yates, Buffer Documentation You can find the docs here. Documentation is generated with jazzy and hosted on GitHub-Pages. To regenerate docs, run ./scripts/build_docs.sh from the root directory in the repo. Vision For the long-term goals and ""vision"" of IGListKit, please read our Vision doc. Contributing Please see the CONTRIBUTING file for how to help. At Instagram, we sync the open source version of IGListKit daily, so we're always testing the latest changes. But that requires all changes be thoroughly tested and follow our style guide. We have a set of starter tasks that are great for beginners to jump in on and start contributing. License IGListKit is MIT-licensed. The files in the /Examples/ directory are licensed under a separate license as specified in each file. Documentation is licensed CC-BY-4.0."
1902,"The most used, flexible, fast and streaming parser for multipart form data. Supports uploading to serverless environments, AWS S3, Azure, GCP or the filesystem. Used in production. formidable A Node.js module for parsing form data, especially file uploads. If you have any how-to kind of questions, please read the Contributing Guide and Code of Conduct documents. For bugs reports and feature requests, please create an issue or ping @tunnckoCore at Twitter. This project is semantically versioned and available as part of the Tidelift Subscription for professional grade assurances, enhanced support and security. Learn more. The maintainers of formidable and thousands of other packages are working with Tidelift to deliver commercial support and maintenance for the Open Source dependencies you use to build your applications. Save time, reduce risk, and improve code health, while paying the maintainers of the exact dependencies you use. Status: Maintained This module was initially developed by @felixge for Transloadit, a service focused on uploading and encoding images and videos. It has been battle-tested against hundreds of GBs of file uploads from a large variety of clients and is considered production-ready and is used in production for years. Currently, we are few maintainers trying to deal with it. :) More contributors are always welcome! :heart: Jump on issue #412 which is closed, but if you are interested we can discuss it and add you after strict rules, like enabling Two-Factor Auth in your npm and GitHub accounts. Note: The github master branch is a ""canary"" branch - try it with npm i formidable@canary. Do not expect (for now) things from it to be inside thelatest ""dist-tag"" in the Npm. Theformidable@latestis thev1.2.1 version and probably it will be the lastv1 release! Note: v2 is coming soon! Highlights Fast (~900-2500 mb/sec) & streaming multipart parser Automatically writing file uploads to disk (optional, see options.fileWriteStreamHandler) Plugins API - allowing custom parsers and plugins Low memory footprint Graceful error handling Very high test coverage Install This project requires Node.js >= 10.13. Install it using yarn or npm. We highly recommend to use Yarn when you think to contribute to this project. or with Yarn v1/v2 This is a low-level package, and if you're using a high-level framework it may already be included. Check the examples below and the examples/ folder. Examples For more examples look at the examples/ directory. with Node.js http module Parse an incoming file upload, with the Node.js's built-in http module. with Express.js There are multiple variants to do this, but Formidable just need Node.js Request stream, so something like the following example should work just fine, without any third-party Express.js middleware. Or try the examples/with-express.js with Koa and Formidable Of course, with Koa v1, v2 or future v3 the things are very similar. You can use formidable manually as shown below or through the koa-better-body package which is using formidable under the hood and support more features and different request bodies, check its documentation for more info. Note: this example is assuming Koa v2. Be aware that you should pass ctx.req which is Node.js's Request, and NOT the ctx.request which is Koa's Request object - there is a difference. Benchmarks The benchmark is quite old, from the old codebase. But maybe quite true though. Previously the numbers was around ~500 mb/sec. Currently with moving to the new Node.js Streams API it's faster. You can clearly see the differences between the Node versions. Note: a lot better benchmarking could and should be done in future. Benchmarked on 8GB RAM, Xeon X3440 (2.53 GHz, 4 cores, 8 threads) API Formidable / IncomingForm All shown are equivalent. Please pass options to the function/constructor, not by assigning them to the instance form Options See it's defaults in src/Formidable.js DEFAULT_OPTIONS (the DEFAULT_OPTIONS constant). options.encoding {string} - default 'utf-8'; sets encoding for incoming form fields, options.uploadDir {string} - default os.tmpdir(); the directory for placing file uploads in. You can move them later by using fs.rename(). options.keepExtensions {boolean} - default false; to include the extensions of the original files or not options.allowEmptyFiles {boolean} - default true; allow upload empty files options.minFileSize {number} - default 1 (1byte); the minium size of uploaded file. options.maxFileSize {number} - default 200 * 1024 * 1024 (200mb); limit the size of uploaded file. options.maxFields {number} - default 1000; limit the number of fields, set 0 for unlimited options.maxFieldsSize {number} - default 20 * 1024 * 1024 (20mb); limit the amount of memory all fields together (except files) can allocate in bytes. options.hashAlgorithm {string | false} - default false; include checksums calculated for incoming files, set this to some hash algorithm, see crypto.createHash for available algorithms options.fileWriteStreamHandler {function} - default null, which by default writes to host machine file system every file parsed; The function should return an instance of a Writable stream that will receive the uploaded file data. With this option, you can have any custom behavior regarding where the uploaded file data will be streamed for. If you are looking to write the file uploaded in other types of cloud storages (AWS S3, Azure blob storage, Google cloud storage) or private file storage, this is the option you're looking for. When this option is defined the default behavior of writing the file in the host machine file system is lost. options.multiples {boolean} - default false; when you call the .parse method, the files argument (of the callback) will contain arrays of files for inputs which submit multiple files using the HTML5 multiple attribute. Also, the fields argument will contain arrays of values for fields that have names ending with '[]'. options.filename {function} - default undefined Use it to control newFilename. Must return a string. Will be joined with options.uploadDir. options.filter {function} - default function that always returns true. Use it to filter files before they are uploaded. Must return a boolean. options.filename {function} function (name, ext, part, form) -> string Note: If this size of combined fields, or size of some file is exceeded, an 'error' event is fired. options.filter {function} function ({name, originalFilename, mimetype}) -> boolean Note: use an outside variable to cancel all uploads upon the first error .parse(request, callback) Parses an incoming Node.js request containing form data. If callback is provided, all fields and files are collected and passed to the callback. You may overwrite this method if you are interested in directly accessing the multipart stream. Doing so will disable any 'field' / 'file' events processing which would occur otherwise, making you fully responsible for handling the processing. About uploadDir, given the following directory structure __dirname would be the same directory as the source file itself (src) to put files in uploads. Omitting __dirname would make the path relative to the current working directory. This would be the same if server.js is launched from src but not project-name. null will use default which is os.tmpdir() Note: If the directory does not exist, the uploaded files are silently discarded. To make sure it exists: In the example below, we listen on couple of events and direct them to the data listener, so you can do whatever you choose there, based on whether its before the file been emitted, the header value, the header name, on field, on file and etc. Or the other way could be to just override the form.onPart as it's shown a bit later. .use(plugin: Plugin) A method that allows you to extend the Formidable library. By default we include 4 plugins, which esentially are adapters to plug the different built-in parsers. The plugins added by this method are always enabled. See src/plugins/ for more detailed look on default plugins. The plugin param has such signature: The architecture is simple. The plugin is a function that is passed with the Formidable instance (the form across the README examples) and the options. Note: the plugin function's this context is also the same instance. Important to note, is that inside plugin this.options, self.options and options MAY or MAY NOT be the same. General best practice is to always use the this, so you can later test your plugin independently and more easily. If you want to disable some parsing capabilities of Formidable, you can disable the plugin which corresponds to the parser. For example, if you want to disable multipart parsing (so the src/parsers/Multipart.js which is used in src/plugins/multipart.js), then you can remove it from the options.enabledPlugins, like so Be aware that the order MAY be important too. The names corresponds 1:1 to files in src/plugins/ folder. Pull requests for new built-in plugins MAY be accepted - for example, more advanced querystring parser. Add your plugin as a new file in src/plugins/ folder (lowercased) and follow how the other plugins are made. form.onPart If you want to use Formidable to only handle certain parts for you, you can do something similar. Or see #387 for inspiration, you can for example validate the mime-type. For example, force Formidable to be used only on non-file ""parts"" (i.e., html fields) File file.toJSON() This method returns a JSON-representation of the file, allowing you to JSON.stringify() the file which is useful for logging and responding to requests. Events 'progress' Emitted after each incoming chunk of data that has been parsed. Can be used to roll your own progress bar. 'field' Emitted whenever a field / value pair has been received. 'fileBegin' Emitted whenever a new file is detected in the upload stream. Use this event if you want to stream the file to somewhere else while buffering the upload on the file system. 'file' Emitted whenever a field / file pair has been received. file is an instance of File. 'error' Emitted when there is an error processing the incoming form. A request that experiences an error is automatically paused, you will have to manually call request.resume() if you want the request to continue firing 'data' events. May have error.httpCode and error.code attached. 'aborted' Emitted when the request was aborted by the user. Right now this can be due to a 'timeout' or 'close' event on the socket. After this event is emitted, an error event will follow. In the future there will be a separate 'timeout' event (needs a change in the node core). 'end' Emitted when the entire request has been received, and all contained files have finished flushing to disk. This is a great place for you to send your response. Ports & Credits multipart-parser: a C++ parser based on formidable Ryan Dahl for his work on http-parser which heavily inspired the initial multipart_parser.js. Contributing If the documentation is unclear or has a typo, please click on the page's Edit button (pencil icon) and suggest a correction. If you would like to help us fix a bug or add a new feature, please check our Contributing Guide. Pull requests are welcome! Thanks goes to these wonderful people (emoji key): Felix Geisendrfer Charlike Mike Reagent Kedar Walle Cyril Xargs Amit-A Charmander Dylan Piercey Adam Dobrawy amitrohatgi Jesse Feng Nathanael Demacon MunMunMiao Gabriel Petrovay Philip Woods Dmitry Ivonin Claudio Poli From a Felix blog post: Sven Lito for fixing bugs and merging patches egirshov for contributing many improvements to the node-formidable multipart parser Andrew Kelley for also helping with fixing bugs and making improvements Mike Frey for contributing JSON support License Formidable is licensed under the MIT License. "
4068,"Replicating and improving the lightbox module seen on Medium with fluid transitions.Fluidbox If you're using Fluidbox for production, use the latest stable release and not the edge release (latest commit). Replicating and improving the lightbox module seen on Medium with fluid transitions. View demo here. For users who are looking for a quick setup and/or troubleshooting process, refer to basic usage, but do not forget to read the usage precautions and frequently asked questions. Although not thoroughly tested, Fluidbox should be working in IE 10 and all versions of Chrome, Firefox, Safari, iOS Safari and Android Chrome, with the exception of Opera Mini. However, I suggest disabling Fluidbox on mobile devices or at small screen resolutions. Special thanks to the following stellar folks who has helped majorly in making Fluidbox better: @hybernaut for refactoring the code and reorganizing functions @maxee for implementation of a new feature that enables differential image ratios between thumbnails and linked image @benwhilhelm for suggesting the immedate open option in Fluidbox. Ben has author a PR, but I have found some issues that I cannot resolve. However, I have adopted his idea and simplified the implementation in v1.4.3. @jaechick for creating the LESS file for Fluidbox stylesheet, even though the LESS file is removed from the project as the stylesheet is now being preprocessed by SASS. @_mattbailey for his awesome guide towards integrating Grunt into a project. This has made building Fluidbox a lot easier. @DJDavid98 for enabling proper parsing of backgorund image URLs. Note that the URL provided still has to be RFC3986-compliant. @Gaya for fixing the blurry image issue on OS X / macOS. @Mesoptier for cleaning up messy CSS transition declarations. In addition, a shoutout to: jQuery Boilerplate for their good-to-boot, easy-to-use and standardized jQuery plugin template. Fluidbox is built on the extended version. David Walsh and Jonathan Suh for their insight on listening to transitionend events Introduction Fluidbox was initially a simple personal challenge I set myself, with two simple aimsto replicate the distraction-free, fluid lightbox seen on Medium, and to improve on it such that it will allow linking to a larger-resolution image. The plugin deals with higher resolution, linked images elegantly, such that it only preloads them when users click on the thumbnails, therefore conserving bandwidth usage for your visitors and your server(s). The plugin is relatively lightweight: 8.74kb (2.71kb after gzipped) for the minified JS file, and 2kb (667b after gzipped) for the minimal stylesheet. You can read my article on Medium about how I got inspiration for this little project of mine, and the basic mechanisms behind the plugin. Some serious math is involved (nah, not really). Moreover, you can visit the demo of this plugin on the project page hosted with GitHub. The plugin v1.22 and onwards (uncompressed, minified and its associated CSS file) is hosted with CDNJS. In the wild Fluidbox is part of the vast collection of libraries proudly hosted by CDNJS. You can reference all versions of Fluidbox published hitherto from there. Fluidbox has been implemented on other sites in the wild, toocheck it out: Gemma Busquets by @imgemmabusquets Highlight portfolio theme by 500px Terry Mun by myself To add your site that has implemented Fluidbox, or an article/tutorial you have written on Fluidbox use and/or application, feel free to write to me at @teddyrised. Installation To install Fluidbox, you will have to include the following resources in your page. The JS files should be loaded in the order stipulated below. For the CSS file, you can either incorporate it with your site's stylesheet, or load it externally through the <link> element in <head>. | Type | File Name | Description | |------|----------------------|------------------------------------------------------------------------------------------------------------------------| | JS | jQuery 1.x | External Dependency: The latest verson of jQuery 1.x library is needed for Fluidbox functionality. Minimum version requirement: v1.7 | | JS | jQuery debounce/throttle plugin | External Dependency: Ben Alman's plugin is optional, but highly recommended. | | JS | dist/js/jquery.fluidbox.min.js | Confers the main functionality of Fluidbox. Alternatively, you can load the minified version, jquery.fluidbox.min.js | | CSS | dist/css/fluidbox.min.css | Offers styles that are crucial for the correct display of Fluidbox. The appearance will break if this is not included. Properties in this file include the necessary vendor prefixes. | If you are modifying the source in the src/ directory and wish to rebuild (or make your own build), please refer to the developer notes further down the readme. Dependencies Fluidbox require the following dependencies in order to function properlyyou will have to include them in your page, if you want Fluidbox to work: The latest release of jQuery 1.x (minimum requirement: jQuery 1.7), available from Google's jQuery API at http://ajax.googleapis.com/ajax/libs/jquery/1/jquery.min.js Ben Alman's debounce/throttle plugin, available from CDNJS. This plugin is not compulsory but highly recommended, as it throttles how frequent the window resize event is fired, which triggers recomputing and repositioning of Fluidbox-related elements. Fluidbox will issue a warning, but will still work, if this plugin is not loaded. Usage Basic It is rather straightforward to use Fluidboxsimply chain the .fluidbox() method to a selector of your choice. The plugin will automatically check if the selector is: An anchor element (<a>) Contains one and only one <img /> element (can be nested as an indirect descendant, to support the HTML5 <picture> standard. Is visible upon DOM ready In the event that the element that satisfies the selector criteria but failed any one of the above criteria, the element will be ignored and the plugin moves on to the next available element. Therefore, it is important that your Fluidbox element(s) follow the following format. The title and alt attributes of the <img> element is not used by the plugin, but the alt attribute has to be present for it to be semantically valid. ...or... In your JS file, you can simply chain the .fluidbox() method to your selector on DOM ready: The selector can be anything of your choice. Let's say you want to target the <a> elements specifically in a certain section on your page: Then, you can use, for example: Public functions and custom triggers There are several public functions exposed in the Fluidbox plugin that allows you to manipulate individual Fluidbox instances. There are three ways of calling public functions. Let's say we want to call the close method of Fluidbox: Here is an example: The list of public methods supported by Fluidbox v2.x is as follow: | Method | Version | Description | |---------------------|---------|-------------| | open | 2.0 | Triggers the programmatic opening of Fluidbox. | | close | 2.0 | Triggers the programatic closing of Fluidbox. | | compute | 2.0 | Triggers (re)computing and positioning of Fluidbox instance. Useful when you are altering the size of the thumbnail (such as DOM manipulation). Remember that the window resize event, which might change the thumbnail dimensions, is listened automatically for you. | | destroy | 2.0 | Destroys the Fluidbox instance and reinserts the original DOM node. | | bindEvents | 2.0 | Binds the one and only click event. | | bindListeners | 2.0 | Binds listeners so that Fluidbox listens to public methods called by the .trigger() method. | | unbind | 2.0 | Unbinds the click events and all other listeners associated with Fluidbox function. | | reposition | 2.0 | Repositions the ghost element, useful when Fluidbox is not opened, but the thumbnail dimensions are changed. | | getMetadata | 2.0 | Getter function. It returns all the metadata associated with the Fluidbox instance, and does not return the original jQuery object, and is therefore not suitable for chaining. | Custom events Fluidbox will trigger several distinct namescpaced events depending on the state of the current (and only) instance of Fluidbox. You should use .on() to listen to the event being triggered, and can add your own custom callbacks if necessary, for example: The list of custom events supported by Fluidbox is as follow. Remember that the events are namespaced: | Event | Version | Description | |--------------------|---------|-------------| | openstart.fluidbox | 1.4.1 | Fired when a click event is registered from a Fluidbox instance that triggers its opening. This is called after the linked image has been successfully loaded. | | openend.fluidbox | 1.4.1 | Fired when the transitionend event is fired (with appropriate vendors supported). This happens when Fluidbox has been scaled to its final size (determined by viewportScale, see configuration). The timing between openstart and openend are dictated by the transition-duration settings in fluidbox.css, or any overrides that you have implemented that targets the class .fluidbox-ghost. | | closestart.fluidbox | 1.4.1 | Fired when a click event is registered from a Fluidbox instance that triggers its closing. | | closeend.fluidbox | 1.4.1 | Fired when the transitionend event is fired (with appropriate vendors supported). This happens when Fluidbox has been scaled back to its original thumbnail size on the page. The timing between closestart and closeend are dictated by the transition-duration settings in fluidbox.css, or any overrides that you have implemented that targets the class .fluidbox-ghost. | | computeend.fluidbox or recomputeend.fluidbox | 1.4.2 | Fired when the Fluidbox ghost element, or the active Fluidbox on display, is recomputed due to layout changes not dependent on the $(window).resize() event. This is triggered manually by the custom trigger recompute (see usage instructions). | | imageloaddone.fluidbox | 1.4.3 | Fired when the target/linked image is successfully loaded. Synonymous with delayloaddone if immediateOpen option is set to true. | | imageloadfail.fluidbox | 1.4.3 | Fired when the target/linked image fails to load. | | thumbloaddone.fluidbox | 1.4.3 | Fired when the thumbnail has been loaded. Will only happen once, when .fluidbox() is first applied to the element. | | thumbloadfail.fluidbox | 1.4.3 | Fired when the thumbnail fails to load. Will only happen once, when .fluidbox() is first applied to the element. | There are custom events that were introduced in v1.4.x but are now deprecated because they serve redundant functions: | Event | Version | Description | |--------------------|---------|-------------| | resizeend | 1.4.1 | Removed in v2.x. Fired when the positioning and scale of an opened Fluidbox instance is recalculated and has been transitioned to completion. | | delayedloaddone | 1.4.3 | Removed in v2.x. Fired only when the immediateOpen option is set to true (see configuration). Indicates that the target/linked image has been successfully loaded. | | delayedreposdone | 1.4.3 | Removed in v2.x. Fired only when the immediateOpen option is set to true (see configuration). Indicates that the ghost image has been transformed successfully after retrieving the natural dimensions of the newly loaded image. | Previously hidden elements As of v1.3.4, Fluidbox will only work with elements that are visible, i.e. not display: none, on the page upon DOM ready. This is because dimensions of hidden images (or images in parents who are hidden) are inaccesible to Fluidbox, resulting in an error. You will have to rebind Fluidbox to the newly revealted elements. Given the example below: You will realize that, even after revealing the element, the Fluidbox method is not working for it. That is because non-visible elements, despite satisfying the selector, will not be bound. So, use the following code instead: Dynamically-added elements In order to enable Fluidbox functionality to dynamically-added content, you will have to apply .fluidbox() to the element of interest after appending it to the DOM. For example, let's say clicking a <button> triggers the addition of a new image: You are of course welcome to use other ways to manipulate and/or transverse the DOM, but you will have to adjust the search/filter function (using .find() or other similar jQuery methods) to retrieve the newly inserted content and search for the element of interest where you want Fluidbox to work with. Configuration Fluidbox can be configured according to your needs when calling the .fluidbox() method. Fluidbox follows the following model of setting overridesin increasing order of priority: Default settings in plugin file Custom settings in .fluidbox() method Custom settings in the element's HTML5 data- attribute: Note: In order to ensure that Fluidbox does not clash with commonly-used HTML5 data- attributes, it is tuned to listen in to namespaced attributes. For example, for the immediateOpen property, the corresponding attribute would be data-fluidbox-immediate-open. As per HTML5 specification, you should avoid using camelCase in your HTML5 data attributes because that is parsed into dash-delimited keys by the dataset method (jQuery uses .data() as an alias). For boolean attributes, simply specifying the attribute itself constitutes a =""true"" declaration, as per HTML standards User-defined settings have to be passed as the aforementioned variables/options to the .fluidbox() method, i.e.: You may also pass settings as HTML5 `data- attributes, i.e.: The full list of Fluidbox configurations: | Option | Type | Default | Description | |--------|------|---------|-------------| | immediateOpen | Boolean | false | Determines if Fluidbox should be opened immediately on click. If set to yes, Fluidbox will open the ghost image and wait for the target image to load. If set to no, Fluidbox will wait for the target image to load, then open the ghost image. | | loader | Boolean | false | Determines if a loader will be added to the manipulated DOM. It will have the class of .fluidbox__loader. | | maxWidth | Integer | 0 | Sets the maximum width, in screen pixels, that the ghost image will enlarge to. When set to zero this property is ignored. This property will not override the viewportFill.This option should not be specified (0) in lieu with maxHeight. In the event that both maxWidth and maxHeight are specified (0), maxWidth takes precedence. Fluidbox will throw a warning in the console discouraging this use. | | maxHeight | Integer | 0 | Sets the maximum height, in screen pixels, that the ghost image will enlarge to. When set to zero this property is ignored. This property will not override the viewportFill.This option should not be specified (0) in lieu with maxWidth. In the event that both maxWidth and maxHeight are specified (0), maxWidth takes precedence. Fluidbox will throw a warning in the console discouraging this use. | | resizeThrottle | Integer (milliseconds) | 500 | Determines how much to throttle the viewport resize event that fires recomputing of Fluidbox dimensions and repositioning of the ghost image. | | stackIndex | Integer | 1000 | Determines how high up the z-index will all Fluildbox elements be. Leave this option as default, unless you have other relatively or absolutely positioned elements on the page that is messing with Fluidbox appearance. | | stackIndexDelta | Integer | 10 | Determines how much the z-index will fluctuate from stackIndex in order to allow visually-correct stacking of Fluidbox instances. With the default settings, this means that the effective range of z-indexes Fluidbox operates in will be between 9901010. For elements that should go under the overlay, they should have a z-index of less than 1000. | | viewportFill | Float (fraction) | 0.95 | Dictates how much the longest axis of the image should fill the viewport. The value will be coerced to fall between 0 and 1. | Developer notes Building with Grunt Fluidbox is built using Grunt and NodeJS. If you are new to this, kindly refer to Matt Bailey's excellent guide on setting up Grunt. To build Fluidbox, you will need to run npm install and install the following dependencies: | Grunt dependency | Comment | |------------------|---------| | grunt | Grunt is needed to build from source. | | time-grunt | Keeps track of the time consumed for each time Grunt is run. | | load-grunt-config | Splits up Grunt tasks. | | grunt-concurrent | Allows multiple Grunt tasks to be run at the same time. | | grunt-contrib-clean | Cleans up the dist/ directory. | | grunt-sass | Parses .scss files into .css. PostCSS will take over from here. | | grunt-contrib-uglify | Minifies .js files. | | grunt-contrib-jshint | Needed to perform linting on JS file. | | jshint-stylish | Needed to perform linting on JS file. | | grunt-contrib-watch | Allows you to build on the fly using $ grunt watch by watching for file changes, so that you don't have to run $ grunt at the project root all the time manually. | | grunt-postcss | Uses PostCSS to dynamically add prefixes and handle minification thereafter. | The main tasks are grunt or grunt prod, which minifies everything and makes it ready for produciton, and grunt dev which instead creates a build for testing and development. Configuration The configuration for each Grunt task can be found in their respecitve .js files in the /grunt folder. Known Issues Blurry images in Safari Fluidbox might render the expanded image in a way that appears to be blurry in OS X / macOS Safari. A fix has been implemented as of v2.0.4 (#178, issue #168). Transition of CSS3 transform in Safari For inexplicable reason(s), Safari no longer transition CSS transformations (the scale component especially) after the first time the Fluidbox has been opened. A simple workaround would be enabling the immediateOpen option (i.e. immediateOpen: true) when initializing Fluidbox. Transform of parent nodes lead to incorrect overlay positioning If the CSS transform property is applied to any parent node, this causes the fixed positioned overlay to only expand to the boundaries of the transformed parent. #165. Precautions Overflowing content Fluidbox may not work properly in the event that you have set your parent container, or content wrapping elements, such as <div id=""#content""> and the likes, to hide their overflowing content, i.e. overflow: hidden. This is because the enlarged image is positioned relatively to its hyperlink, and not absolutely or fixed within the viewport. Interaction with other positioned elements on the same page When you want an absolutely/fixed-positioned element on the page to not be obscured by the dynamically-generated wrapping element, you should use a z-index of between 1000 to 1010. 1000 is set as the default stackIndex of Fluidbox, while 10 is set as the default stackIndexDelta, which is toggled on/off depending on the state of the Fluidbox. These settings can be individually tuned, see Configuration below. Binding Fluidbox to previously hidden images As Fluidbox requires access to the final calculation dimensions of the image in question in order to (1) position the ghost element correctly and (2) calculate the correct scale factor and transform values, it will only bind to images that are visible upon DOM ready. If you are relying on dynamic events (e.g. user-triggered, AJAX-loaded and etc.) to trigger a later appearance of an image, rebind Fluidbox to freshly revealed elements. This also applies to dynamically-loaded content, see demo for a working example. Derped ghost element calculations in flexbox layouts In some caseswhich I have also experienced myselfthe ghost element that overlays the thumbnail might have incorrect dimensions being calculated. This is because its dimensions are calculation on DOM ready by retrieving the computed dimensions of the underlying image. When the flexbox layout is active, the browser might change the dimensions of the image when flex-grow and/or flex-shrink are enabled (i.e. set to a non-zero integer). The cause is likely to be that the browser receives information on the image dimensions after DOM ready and then resizes the flex containers, which happens after the computed widths are fed to Fluidbox calculations. In this case, I strongly recommend triggering the recomputer custom trigger (see above) after all images in the flexbox container has loaded. You can do this upon $(window).load(), but you can also use jQuery deferred objects and promises to do so. Let's say we have a flexbox container with the class of .flex: Accidental creation of new stacking contexts There are a few CSS properties, when applied to the wrapping parent of elements meant for the .fluidbox() method, causes a new stacking context to be createdthis leads to an issue where an opened Fluidbox instance will fail to cover its neighbouring elements. They are, in alphabetical order but not exhaustively so: - CSS3 regions1 - filter1, 2 - flex3 - isolation3 - mix-blend-mode3 - opacity1 - position1, 3 - paged media1 - transform1 - will-change3 Sources: What No One Told You About Z-Index by Philip Walton Why does stacking order change on webkit filter hover? on StackOverflow The stacking context on MDN Frequently Asked Questions Fluidbox is not working in my installation. Where should I start? Start by checking your browser's console log. What error messages do you see? Also, make sure that you are using the latest version of jQuery 1.x (minimum requirement: v1.8 or above) and that the dependencies have been loaded successfully. Also, did you remember reading the usage precautions? You might have encountered a scenario where Fluidbox is not designed to handle. Do you plan to implement [insert feature]? Fluidbox is conceived as a means to simplify lightboxes. Therefore, I plan to keep Fluidbox as simple as it is, without additional features, such as captioning (there are other limitations to this, too) and gallery features. However, you can always fork and modify Fluidbox to your personal liking. Manual captioning is possible, refer to the [advanced demo]. The image url isn't being interpretted correctly. Fluidbox fetches the larger image based on the URL specified in the href attribute if the wrapping anchor (<a>) tag. I have a application-specific problem that I need help troubleshooting. Can you help me? Of course! I am more than happy to help, but it really depends if you have a clear problem statement and a minimal, complete and verifiable example (MCVE) that I can play around withI strongly encourage you to host your reduced test case(s) with either JSFiddle, CodePen or the likes. Then, create a new issue. I promise I will get back to you when I have time. Do you provide private support by email / phone call / Skype call / (insert any other forms of communication)? Since Fluidbox is provided as-is and free-of-charge, I am sorry to inform you that it is so far not possible for me to dedicate so much effort. However, you can follow what is described in step #4. Licensing: MIT License This plugin is licensed under the MIT License."
996,"Proxy based Redis cluster solution supporting pipeline and scaling dynamically Codis is a proxy based high performance Redis cluster solution written in Go. It is production-ready and widely used at wandoujia.com and many companies. You can see Codis Releases for latest and most stable realeases. Donation Donate if you want to help us maintaining this project. Thank you! See this issue for details Compared with Twemproxy and Redis Cluster CodisTwemproxyRedis Cluster resharding without restarting clusterYesNoYes pipelineYesYesNo hash tags for multi-key operationsYesYesYes multi-key operations while reshardingYes-No(details) Redis clients supportingAny clientsAny clientsClients have to support cluster protocol ""Resharding"" means migrating the data in one slot from one redis server to another, usually happens while increasing/decreasing the number of redis servers. Other Features GUI website dashboard & admin tools Supports most of Redis commands, Fully compatible with Twemproxy(https://github.com/twitter/twemproxy) Proxies can register on zk/etcd, clients can avoid dead proxies, see ""High Availability"" section. Tutorial English (WIP) FAQ English (WIP) High Availability English (WIP) Architecture Snapshots Proxy Slots Group Sentinel Benchmarks See benchmark results Authors Active authors: * @spinlock9 @ * @yangzhe1991 @__ Emeritus authors: * @goroutine @goroutine * @c4pt0r @Dongxu_Huang Thanks: * @ivanzhaowy * @Apache9 @Apache9 License Codis is licensed under MIT see MIT-LICENSE.txt You are welcome to use Codis in your product, and feel free to let us know~ :)"
1803,"OBSOLETE: Please move to Ionic Native https://github.com/ionic-team/ionic-nativeThis library is obsolete ngCordova is obsolete and is no longer maintained. Please move to our new native plugin library, Ionic Native. See this issue for more information: https://github.com/ionic-team/ng-cordova/issues/1452 ngCordova Cordova with AngularJS Goodness ngCordova gives you simple AngularJS wrappers for a massive amount of Cordova plugins. Check out the list below for all of the available plugins, and create an issue for a new request. Created by the Ionic Framework team and the community. | RESOURCE | LINK | |------------|---------| | Website | ngCordova.com | | Docs | ngCordova.com/docs | | Requirements | AngularJS, Cordova | | Install | bower install ngCordova or download zip file | | Custom build | ngCordova.com/build | Installation Install manually, or from bower: Plugins (67+) Action Sheet AdMob (:warning: share % Ad revenue) App Availability App Rate App Version Background Geolocation Badge Barcode Scanner Battery Status * Beacon Bluetooth Low Energy Bluetooth Serial Brightness Calendar Camera * Clipboard Console * Contacts * Date Picker Device Motion * Device Orientation * Device * Dialogs * Email Composer Facebook Connect Facebook AudienceNetwork Ads (:warning: share % Ad revenue) File * File Transfer * Flashlight Flurry Ads (:warning: share % Ad revenue) Geolocation * Globalization * Google Ads (:warning: share % Ad revenue) Google Analytics Google Plus HealthKit for iOS Httpd (Web Server) Apple iAd (:warning: share % Ad revenue) Image Picker InAppBrowser* Keyboard Keychain Launch Navigator Local Notifications Media Capture Media * MillennialMedia Ads (:warning: share % Ad revenue) MobFox Ads (:warning: share % Ad revenue) MoPub Ads (:warning: share % Ad revenue) Native Audio Network Information * Oauth (available separately) Pin Dialog Preferences Printer Progress Indicator Push Notifications (deprecated - Will be removed in future release) [Push Notifications - V5] (https://github.com/phonegap/phonegap-plugin-push) Screenshots Serial SMS Social Sharing Spinner Dialog Splashscreen * SQLite StatusBar * Toast Touchid Vibration * Video Capture Plus * Zip * official Apache Cordova Plugin Authors Max Lynch https://twitter.com/maxlynch https://github.com/mlynch Paolo Bernasconi https://twitter.com/paolobernasconi https://github.com/pbernasconi Project Maintainer George Stocker https://twitter.com/gortok https://github.com/gortok LICENSE ngCordova is licensed under the MIT Open Source license. For more information, see the LICENSE file in this repository."
1978,"Add an AngularJS admin GUI to any RESTful APIng-admin Plug me to your RESTFul API to get a complete administration interface (datagrid, filters, complex form widgets, multi-model relationships, dashboard) in no time! Beyond simple CRUD, ng-admin lets you build sophisticated GUIs without getting in your way. Online demo (source) Documentation This project is now in maintenance mode. We've rebuilt it from scratch with React.js (the new project is called react-admin), and we're putting all our efforts on the React version. Installation The current ng-admin version (master) depends on Angular.js 1.6. If you need compatibility with Angular 1.3, use ng-admin 0.9. Grab ng-admin from your favorite package manager: With a Module Bundler ng-admin is fully compatible with Webpack, and should also be compatible with all available major module bundlers. If you use one of them, you just have to add this line: Important note: as we include HTML templates using require to prevent the AJAX request implied by templateUrl, you will need to configure your module bundler to deal with HTML. It can be accomplished with Webpack using the HTML loader: If your module bundler also supports SASS or CSS, you can also include stylesheets using: Using a module bundler, you would also be able to generate the source map for all your JavaScript and stylesheets, helping you to hunt even the most obscure bugs. Without a Module Bundler If you don't have a module bundler, don't worry: you can still include ng-admin with a <script> tag: Bootstrapping your Admin Add the ng-admin.min.css and ng-admin.min.js to the HTML, add a <div ui-view=""ng-admin"">, and configure the admin: Getting Started See the Getting Started dedicated chapter for a step-by-step tutorial aimed at beginners. Usage Examples You can find a simple configuration in the blog admin demo, where the entities are posts, comments, and tags. The remote REST API is simulated in the browser, using FakeRest. The Posters Galore demo (source) is a more complete example of an e-commerce administration, with custom authentication, pages, directives and modules, all well organized via WebPack. The remote REST API is also simulated in the browser, using FakeRest. Configuration Reference An administration in ng-admin is made of one application containing several entities. Each entity has up to 5 views, and each view has many fields. See Configuration API Reference dedicated chapter for more details. Tip: You won't find the related classes in the ng-admin project. In fact, the admin configuration API exists as a standalone, framework-agnostic library, called admin-config. Don't hesitate to browse the source of that library to learn more. Relationships Ng-admin supports relationships between entities in read and write views, and provides specialized field types for that: reference, referenced_list, reference_many, and embedded_list. The Relationships Reference chapter describes in more details which field type to use for which case. Also, the Fields section of the Configuration API Reference chapter has a list of all settings for each of these field types. Menu Configuration By default, ng-admin creates a sidebar menu with one entry per entity. If you want to customize this sidebar (labels, icons, order, adding submenus, etc), you have to define menus manually. See Menus Configuration dedicated chapter. Dashboard Configuration The home page of a ng-admin application is called the Dashboard. Use it to show important pieces of information to the end user, such as latest entries, or charts. See Dashboard Configuration dedicated chapter. Customizing the API Mapping All HTTP requests made by ng-admin to your REST API are carried out by Restangular, which is like $resource on steroids. The REST specification doesn't provide enough detail to cover all requirements of an administration GUI. ng-admin makes some assumptions about how your API is designed. All of these assumptions can be overridden by way of Restangular's request and response interceptors. That means you don't need to adapt your API to ng-admin; ng-admin can adapt to any REST API, thanks to the flexibility of Restangular. See the Customizing the API Mapping dedicated chapter. Theming You can override pretty much all the HTML generated by ng-admin, at different levels. See the Theming dedicated chapter. Translation The ng-admin interface uses English as the default language, but supports switching to another language, thanks to angular-translate. See the Translation dedicated chapter. Adding Custom Pages For each entity, ng-admin creates the necessary pages for Creating, Retrieving, Updating, and Deleting (CRUD) this entity. When you need to achieve more specific actions on an entity, you have to add a custom page - for instance a page asking for an email address to send a message to. How can you route to a specific page and display it in the ng-admin layout? See the Adding Custom Pages dedicated chapter. Adding Custom Types When you map a field between a REST API response and ng-admin, you give it a type. This type determines how the data is displayed and edited. It is very easy to customize existing ng-admin types and add new ones. See the Adding Custom Types dedicated chapter. Getting Ready For Production To build the ng-admin source with the dependencies you need, and to get hints about performance boosters, head to the Getting Ready For Production dedicated chapter. News Follow the marmelab blog for news about ng-admin (tutorials, plugins, new releases, etc). You should also watch the ng-admin release page on GitHub for announcements on new releases, and complete changelog. Support Ng-admin is an open-source project, with a community getting larger every day. You will get help by asking politely in any the following channels: StackOverflow Gitter (live chat) Please give as much context as possible, including and admin configuration snippet, and the response from the API you're mapping. Looking For a Material UI / React.js version? marmelab/admin-on-rest, by the same team, uses a different architecture but provides a similar service: an admin GUI for REST APIs, this time with React.js, Redux, react-router, and material UI. Contributing Your feedback about the usage of ng-admin in your specific context is valuable, don't hesitate to open GitHub Issues for any problem or question you may have. All contributions are welcome: please send us a Pull Request for any new feature / bug fix in your fork that you consider worth giving back. Also, if you have some experience with ng-admin, please answer questions from newcomers in any of the support channels (see above). Installing Dependencies Install npm dependencies (for tests) by calling the install target: Running the example app To test your changes, run the example app, which is bundled with a sample REST api, by calling: Then, connect to http://localhost:8000/ to browse the admin app. This task uses webpack-dev-server, which means that the browser will reload the page as soon as one file in the source is updated. This makes the blog app our preferred live testing environment. Testing ng-admin has unit tests (powered by karma) and end to end tests (powered by protractor). Launch the entire tests suite by calling: Tip: If you are working on Karma tests, you can prevent from relaunching the whole process by disabling single-run: Releasing Before releasing a new version, concatenate and minify the JS and CSS sources into minified scripts with: Tip: Don't commit built files in Pull Requests, it forces rebases on other PRs. The core team will take care of regularly updating these built files. License ng-admin is licensed under the MIT Licence, and sponsored by marmelab."
4041,"Local server for Android's HierarchyViewerNOTE: This library is not necessary anymore. Newer versions of Android provide a new tool called Layout Inspector that should be used instead. ViewServer is a simple class you can use in your Android application to use the HierarchyViewer inspection tool. ViewServer requires the Android SDK r12 or higher. http://developer.android.com/sdk/index.html Quick Start Verify that you need this library(newer versions of Android don't) If you do need this library then follow these directions: * Include the ViewServer library(easy directions found here) * Your application must require the INTERNET permission * The recommended way to use this API is to register activities when they are created, and to unregister them when they get destroyed: Please refer to the documentation in ViewServer.java for more info."
4521,"Next generation vim support for atomVim Mode package Provides Vim modal control for Atom, blending the best of Vim and Atom. Current Status - DEPRECATED in favor of vim-mode-plus We're not maintaining this package anymore, because vim-mode-plus has more features and is very well maintained."
230,"An Android library for managing images and the memory they use.Fresco Fresco is a powerful system for displaying images in Android applications. Fresco takes care of image loading and display, so you don't have to. It will load images from the network, local storage, or local resources, and display a placeholder until the image has arrived. It has two levels of cache; one in memory and another in internal storage. In Android 4.x and lower, Fresco puts images in a special region of Android memory. This lets your application run faster - and suffer the dreaded OutOfMemoryError much less often. Fresco also supports: streaming of progressive JPEGs display of animated GIFs and WebPs extensive customization of image loading and display and much more! Find out more at our website. Requirements Fresco can be included in any Android application. Fresco supports Android 2.3 (Gingerbread) and later. Using Fresco in your application If you are building with Gradle, simply add the following line to the dependencies section of your build.gradle file: For full details, visit the documentation on our web site, available in English, Chinese, and Korean: Join the Fresco community Please use our issues page to let us know of any problems. For pull requests, please see the CONTRIBUTING file for information on how to help out. See our documentation for information on how to build from source. License Fresco is MIT-licensed."
4025,"Easily get the device's current location on iOS.INTULocationManager makes it easy to get the device's current location and is currently heading on iOS. It is an Objective-C library that also works great in Swift. INTULocationManager provides a block-based asynchronous API to request the current location, either once or continuously. It internally manages multiple simultaneous locations and heading requests, and each one-time location request can specify its own desired accuracy level and timeout duration. INTULocationManager automatically starts location services when the first request comes in and stops the location services when all requests have been completed, while dynamically managing the power consumed by location services to reduce the impact on battery life. What's wrong with CLLocationManager? CLLocationManager requires you to manually detect and handle things like permissions, stale/inaccurate locations, errors, and more. CLLocationManager uses a more traditional delegate pattern instead of the modern block-based callback pattern. And while it works fine to track changes in the user's location over time (such as, for turn-by-turn navigation), it is extremely cumbersome to correctly request a single location update (such as to determine the user's current city to get a weather forecast, or to autofill an address from the current location). INTULocationManager makes it easy to request both the device's current location, either once or continuously, as well as the device's continuous heading. The API is extremely simple for both one-time location requests and recurring subscriptions to location updates. For one-time location requests, you can specify how accurate of a location you need, and how long you're willing to wait to get it. Significant location change monitoring is also supported. INTULocationManager is power efficient and conserves the device's battery by automatically determining and using the most efficient Core Location accuracy settings, and by automatically powering down location services (e.g. GPS or compass) when they are no longer needed. Installation INTULocationManager requires iOS 9.0 or later. Using CocoaPods Add the pod INTULocationManager to your Podfile. Run pod install from Terminal, then open your app's .xcworkspace file to launch Xcode. Import the INTULocationManager.h header. With use_frameworks! in your Podfile Swift: import INTULocationManager Objective-C: #import <INTULocationManager/INTULocationManager.h> (or with Modules enabled: @import INTULocationManager;) Without use_frameworks! in your Podfile Swift: Add #import ""INTULocationManager.h"" to your bridging header. Objective-C: #import ""INTULocationManager.h"" Using Carthage Add the intuit/LocationManager project to your Cartfile. Run carthage update, then follow the additional steps required to add the iOS and/or Mac frameworks into your project. Import the INTULocationManager framework/module. Swift: import INTULocationManager Objective-C: #import <INTULocationManager/INTULocationManager.h> (or with Modules enabled: @import INTULocationManager;) Manually from GitHub Download all the files in INTULocationManager subdirectory. Add the source files to your Xcode project (drag and drop is easiest). Import the INTULocationManager.h header. Swift: Add #import ""INTULocationManager.h"" to your bridging header. Objective-C: #import ""INTULocationManager.h"" Usage Requesting Permission to Access Location Services INTULocationManager automatically handles obtaining permission to access location services when you issue a location request and the user has not already granted your app the permission to access that location services. iOS 9 and above Starting with iOS 8, you must provide a description for how your app uses location services by setting a string for the key NSLocationWhenInUseUsageDescription or NSLocationAlwaysUsageDescription in your app's Info.plist file. INTULocationManager determines which level of permissions to request based on which description key is present. You should only request the minimum permission level that your app requires, therefore it is recommended that you use the ""When In Use"" level unless you require more access. If you provide values for both description keys, the more permissive ""Always"" level is requested. iOS 11 Starting with iOS 11, you must provide a description for how your app uses location services by setting a string for the key NSLocationAlwaysAndWhenInUseUsageDescription in your app's Info.plist file. iOS 12 Starting with iOS 12, you will have access to set the desiredActivityType as CLActivityTypeAirborne. Getting the Current Location (once) To get the device's current location, use the method requestLocationWithDesiredAccuracy:timeout:block:. The desiredAccuracy parameter specifies how accurate and recent of a location you need. The possible values are: The desiredActivityType parameter indicated the type of activity that is being tracked. The possible values are: The timeout parameter specifies that how long you are willing to wait for a location with the accuracy you requested. The timeout guarantees that your block will execute within this period of time, either with a location of at least the accuracy you requested (INTULocationStatusSuccess), or with whichever location could be determined before the timeout interval was up (INTULocationStatusTimedOut). Pass 0.0 for no timeout (not recommended). By default, the timeout countdown begins as soon as the requestLocationWithDesiredAccuracy:timeout:block: method is called. However, there is another variant of this method that includes a delayUntilAuthorized: parameter, which allows you to pass YES to delay the start of the timeout countdown until the user has responded to the system location services permissions prompt (if the user hasn't allowed or denied the app access yet). Here's an example: Subscribing to Continuous Location Updates To subscribe to continuous location updates, use the method subscribeToLocationUpdatesWithBlock:. This method instructs location services to use the highest accuracy available (which also requires the most power). The block will execute indefinitely (even across errors, until canceled), once for every new updated location regardless of its accuracy. If you do not need the highest possible accuracy level, you should instead use subscribeToLocationUpdatesWithDesiredAccuracy:block:. This method takes the desired accuracy level and uses it to control how much power is used by location services, with lower accuracy levels like Neighborhood and City requiring less power. Note that INTULocationManager will automatically manage the system location services accuracy level, including when there are multiple active location requests/subscriptions with different desired accuracies. If an error occurs, the block will execute with a status other than INTULocationStatusSuccess, and the subscription will be kept alive. Here's an example: Subscribing to Significant Location Changes To subscribe the significant location changes, use the method subscribeToSignificantLocationChangesWithBlock:. This instructs the location services to begin monitoring for significant location changes, which is very power efficient. The block will execute indefinitely (until canceled), once for every new updated location regardless of its accuracy. Note that if there are other simultaneously active location requests or subscriptions, the block will execute for every location update (not just for significant location changes). If you intend to take action only when the location has changed significantly, you should implement custom filtering based on the distance & time received from the last location. If an error occurs, the block will execute with a status other than INTULocationStatusSuccess, and the subscription will be kept alive. Here's an example: If your app has acquired the ""Always"" location services authorization and your app is terminated with at least one active significant location change subscription, your app may be launched in the background when the system detects a significant location change. Note that when the app terminates, all of your active location requests & subscriptions with INTULocationManager are canceled. Therefore, when the app launches due to a significant location change, you should immediately use INTULocationManager to set up a new subscription for significant location changes in order to receive the location information. Here is an example of how to handle being launched in the background due to a significant location change: Managing Active Requests or Subscriptions When issuing a location request, you can optionally store the request ID, which allows you to force complete or cancel the request at any time: Note that subscriptions never timeout; calling forceCompleteLocationRequest: on a subscription will simply cancel it. Subscribing to Continuous Heading Updates To subscribe to continuous heading updates, use the method subscribeToHeadingUpdatesWithBlock:. This method does not set any default heading filter value, but you can do so using the headingFilter property on the manager instance. It also does not filter based on accuracy of the result, but rather leaves it up to you to check the returned CLHeading object's headingAccuracy property to determine whether or not it is acceptable. The block will execute indefinitely (until canceled), once for every new updated heading regardless of its accuracy. Note that if heading requests are removed or canceled, the manager will automatically stop updating the device heading in order to preserve battery life. If an error occurs, the block will execute with a status other than INTUHeadingStatusSuccess, and the subscription will only be automatically canceled if the device doesn't have heading support (i.e. for status INTUHeadingStatusUnavailable). Here's an example: Example Project Open the project included in the repository (requires Xcode 6 and iOS 8.0 or later). It contains a LocationManagerExample scheme that will run a simple demo app. Please note that it can run in the iOS Simulator, but you need to go to the iOS Simulator's Debug > Location menu once running the app to simulate a location (the default is None). Issues & Contributions Please open an issue here on GitHub if you have a problem, suggestion, or other comment. Pull requests are welcome and encouraged! There are no official guidelines, but please try to be consistent with the existing code style. License INTULocationManager is provided under the MIT license. INTU on GitHub Check out more iOS and OS X open source projects from Intuit!"
877,":fork_and_knife: Web applications made easy. Since 2011.Brunch Web applications made easy. Since 2011. Fast front-end web app build tool with simple declarative config and seamless incremental compilation for rapid development. Usage Install Brunch with a simple node.js package manager command: npm install -g brunch Create a new Brunch project: brunch new [--skeleton url] skeleton specifies a skeleton from which your application will be initialized. The default skeleton (dead-simple) doesn't have any opinions about frameworks or libraries. brunch.io/skeletons contains over 50 boilerplate projects, which you can use to init your app from. Develop with Brunch: brunch watch --server tells Brunch to watch your project and incrementally rebuild it when source files are changed. The optional server flag launches a simple web server with push state support. Deploy with Brunch: brunch build --production builds a project for distribution. By default it enables minification. Learn Visit brunch.io Read brunch docs Follow us on Twitter: @brunch Ask questions on Stack Overflow with #brunch tag Contributing See the CONTRIBUTING.md document for more info on how to file issues or get your head into the Brunch's internals. To install edge version (from GitHub master branch): npm install -g brunch/brunch To enable debug mode, simply pass -d flag to any command like that: brunch build -d To create your own plugin, check out our plugin boilerplate as a starting point. License MIT license (c) 2021 Paul Miller paulmillr.com, Elan Shanker, Nik Graf, Thomas Schranz, Allan Berger, Jan Monschke, Martin Schrrer See LICENSE file."
3024,"30-second slideshows for hackersCleaver 30-second Slideshows for Hackers. http://jdan.github.io/cleaver/ Intro Cleaver turns this: title: Basic Example author: name: Jordan Scales twitter: jdan url: http://jordanscales.com output: basic.html controls: true -- # Cleaver 101 ## A first look at quick HTML presentations -- ### A textual example Content can be written in **Markdown!** New lines no longer need two angle brackets. This will be in a separate paragraph -- ### A list of things * Item 1 * Item B * Item gamma No need for multiple templates! Into this: Quick Start Get it on NPM: And run it like so: You can also watch for changes on a file and automatically recompile with: Use the --debug flag to display debug information: More Info Cleaver is a one-stop shop for generating HTML presentations in record time. Using some spiced up markdown, you can produce good-looking, interactive presentations with a just a few lines of text. Slides are written in Markdown, and are separated by two dashes (--). Options title: Basic Example author: name: Jordan Scales twitter: jdan url: http://jordanscales.com style: basic-style.css output: basic.html Cleaver supports several basic options that allow you to further customize the look and feel of your presentation, including author info, stylesheets, and custom templates. See the documentation on options for more information. Be sure to check out the wiki as well. Themes Check out the themes page on our wiki. title: Theme Example output: theme.html theme: jdan/cleaver-retro Cleaver has substantial theme support to give you more fine-grained control over your presentation, similar to options. Instead of manually specifying a stylesheet, template, layout, and others, you can specify a single theme containing each of these assets. More specifically, a theme may contain: style.css - styles for your presentation template.mustache - a template used to render the slides in your presentation layout.mustache - a template used to render the entire document of your presentation script.js - javascript to be included in your slideshow A theme does not need to contain all of these files, only the ones present will be loaded into your slideshow. Examples jdan/cleaver-retro matmuchrapna/cleaver-ribbon Shower implemented in cleaver. sudodoki/reveal-cleaver-theme cleaver meets reveal.js. Specifying Themes Themes may be specified by one of the following options: An absolute or relative path to a directory A URL to a directory A github repository in the form of username/reponame Overriding Themes By default, style.css and script.js will be appended to the default stylesheets and javascripts included in cleaver presentations. If you wish to completely override these defaults, you must include another file in your theme - settings.json - corresponding to the following: Template files will automatically override the default templates. More Info For more information on themes, check out our documentation. Markup Cleaver slides are rendered using the following template: And produce the following markup: #slide-N (for example, #slide-3) allows you to identify a particular full-bleed slide by its position in the slideshow. It extends to the bounds of the page. .slide-content is a smaller window which holds the actual content of the slide. Class List A class list can be placed after each ""slice"" (denoted --) to help you style individual slides without worrying about their index. Slide Types Title slide # Cleaver 101 ## A first look at quick HTML presentations h1 and h2 elements (prefaced with # and ## respectively), will automatically include padding to render a title slide. Other slides ### A list of things * Item 1 * Item B * Item gamma No need for multiple templates! Since slides are written in Markdown, you can include things like lists, images, and arbitrary HTML. h3 tags (prefaced ###) are automatically given a bottom border to represent a slide title. Navigation Cleaver supports keyboard navigation for switching between slides. Alternatively, click the control buttons located below the presentation. To navigate the slideshow: forward: K, L, UP, RIGHT, PgDn, and Space reverse: H, J, LEFT, DOWN, PgUp, and Backspace The toggle fullscreen mode, press the ENTER key. Contributing Fork it Clone it Install dependencies (npm install) Checkout a release branch (git checkout -b feature/cool-wordart) Make changes, commit, and push (npm test and make sure it passes) Open a pull request! With <3,@jdan -- MIT Licensed"
1730,"A modern, flexible logging tool NSLogger NSLogger is a high performance logging utility which displays traces emitted by client applications running on macOS, iOS and Android. It replaces traditional console logging traces (NSLog(), Java Log). The NSLogger Viewer runs on macOS and replaces Xcode, Android Studio or Eclipse consoles. It provides powerful additions like display filtering, defining log domain and level, image and binary logging, message coloring, traces buffering, timing information, link with source code, etc. NSLogger feature summary: View logs using the desktop application Logs can be sent from device or simulator Accept connections from local network clients (using Bonjour) or remote clients connecting directly over the internet Online (application running and connected to NSLogger) and offline (saved logs) log viewing Buffer all traces in memory or in a file, send them over to viewer when a connection is acquired Define a log domain (app, view, model, controller, network) and an importance level (error, warning, debug, noise) Color the log messages using regexp Log images or raw binary data Secure logging (connections use SSL by default) Advanced log filtering options Save viewer logs to share them and/or review them later Export logs to text files Open raw buffered traces files that you brought back from client applications not directly connected to the log viewer Here is what it looks like in action: And with macOS Mojave and later's dark mode: Basic Usage Without any change to your code, all the NSLog() logs from your application are redirected to the NSLogger desktop viewer. The viewer is found automatically on your network, using Bonjour. A rich API lets you log messages, binary data or images with a lot of detail. Simple wrappers are available for your convenience: Swift wrapper API: Objective-C wrapper API: Installation Step 1. Download the NSLogger desktop app on your Mac. Step 2. Add the NSLogger framework to your project. Step 3. There is no step 3 Desktop Viewer Download Download the pre-built, signed version of the NSLogger desktop viewer for macOS. Don't forget to launch the application on your Mac. It won't show a window until a client connects to it and starts logging. Client Framework Install CocoaPods Install If your project is configured to use CocoaPods, just add this line to your Podfile: The above only includes C and Obj-C APIs and is suitable for use in applications without any Swift code. Swift syntactic sugar APIs are added with the Swift subspec. If you're developing code in Swift or a mixed Swift / Obj-C environment, use: Note that you don't strictly need to include the /Swift variant for your Swift applications. You can perfectly develop your own extensions that call into NSLogger's C APIs without using the basic provided ones. Finally if you are using frameworks or libraries that may use NSLogger, then you can use the NoStrip variant which forces the linker to keep all NSLogger functions in the final build, even those that your code doesn't use. Since linked in frameworks may dynamically check for the presence of NSLogger functions, this is required as the linker wouldn't see this use. Carthage Install NSLogger is Carthage-compatible. It builds two frameworks: NSLogger and NSLoggerSwift. You'll need to pick either one (but not both) to use in your application. Both can be used with Swift, the NSLoggerSwift variant adds a simple Swift layer to make NSLogger easier to use from Swift code. You can perfectly develop your own extensions that call into NSLogger's C APIs without using the basic provided ones, and just use the NSLogger framework. Depending on the framework you choose, your code will need to import NSLogger or import NSLoggerSwift. This is a difference with Cocoapods support where you always import NSLogger. Then run: Again, the NSLogger.xcodeproj top-level project offers two targets (NSLogger and NSLoggerSwift). Add the built framework that suits your needs. Advanced Usage Using NSLogger on a Shared Network The first log sent by NSLogger will start the logger, by default on the first Bonjour service encountered. But when multiple NSLogger users share the same network, logger connections can get mixed. To avoid confusion between users, just add this when you app starts (for example, in the applicationDidFinishLaunching method: Then, in the Preferences pane of the NSLogger.app desktop viewer, go to the Network tab. Type your user name (i.e. $USER) in the ""Bonjour service name"" text field. This will allow the traces to be received only by the computer of the user who compiled the app. This only work when NSLogger has been added to your project using CocoaPods. Set up logger options For example if you don't want to disable OS_ACTIVITY_MODE for your scheme because you need that logs. And you wanna have only your logs in NSLogger in Swift call init function: Manual Framework Install When using NSLogger without CocoaPods, add LoggerClient.h, LoggerClient.m and LoggerCommon.h (as well as add the CFNetwork.framework and SystemConfiguration.framework frameworks) to your iOS or Mac OS X application, then replace your NSLog() calls with LogMessageCompat() calls. We recommend using a macro, so you can turn off logs when building the distribution version of your application. How Does the Connection Work? For automatic discovery of the desktop viewer, your application must run on a device that is on the same network as your Mac. When your app starts logging, the NSLogger framework automatically (by default) looks for the desktop viewer using Bonjour. As soon as traces start coming, a new window will open on your Mac. Advanced users can setup a Remote Host / Port to log from a client to a specific host), or specify a Bonjour name in case there are multiple viewers on the network. Advanced Desktop Viewer Features The desktop viewer application provides tools like: Filters (with regular expression matching) that let your perform data mining in your logs Timing information: each message displays the time elapsed since the previous message in the filtered display, so you can get a sense of time between events in your application. Image and binary data display directly in the log window Markers (when a client is connected, place a marker at the end of a log to clearly see what happens afterwards, for example place a marker before pressing a button in your application) Fast navigation in your logs Display and export all your logs as text Optional display of file, line and function for uncluttered display Your logs can be saved to a .nsloggerdata file, and reloaded later. When logging to a file, name your log file with extension .rawnsloggerdata so NSLogger can reopen and process it. You can have clients remotely generating raw logger data files, then send them to you so you can investigate post-mortem. Note that the NSLogger Mac OS X viewer requires Mac OS X 10.6 or later. Advanced Colors Configuration Apply colors to tags and messages using regular expressions. To define the color, you can use: - A standard NSColor name, for example: blue - Hex colors, for example: #DEAD88 - You can add the prefix bold, for example: bold red High Performance, Low Overhead The NSLogger framework runs in its own thread in your application. It tries hard to consume as few CPU and memory as possible. If the desktop viewer has not been found yet, your traces can be buffered in memory until a connection is acquired. This allows for tracing in difficult situations, for example device wakeup times when the network connection is not up and running. Credits NSLogger is Copyright (c) 2010-2018 Florent Pillet, All Rights Reserved, All Wrongs Revenged. Released under the New BSD Licence. The NSLogger icon is Copyright (c) Louis Harboe"
670,"Reduce misspelled email addresses in your web apps.mailcheck.js The Javascript library and jQuery plugin that suggests a right domain when your users misspell it in an email address. mailcheck.js is part of the Mailcheck family, and we're always on the lookout for more ports and adaptions. Get in touch! What does it do? When your user types in ""user@gmil.con"", Mailcheck will suggest ""user@gmail.com"". Mailcheck will offer up suggestions for second and top level domains too. For example, when a user types in ""user@hotmail.cmo"", ""hotmail.com"" will be suggested. Similarly, if only the second level domain is misspelled, it will be corrected independently of the top level domain. See it live in action here. Installation For instant use, download the minified library mailcheck.min.js into your javascripts directory. mailcheck.js is also available unminimised if you want to hack on it, or have your own minimizer. Bower Node/Browserify Usage with jQuery First, include jQuery and Mailcheck into the page. Have a text field. Now, attach Mailcheck to the text field. You can declare an array of domains, second level domains and top level domains you want to check against. Mailcheck takes in two callbacks, suggested and empty. We recommend you supply both. suggested is called when there's a suggestion. Mailcheck passes in the target element and the suggestion. The suggestion is an object with the following members: Mailcheck does not want to get in the way of how you can show suggestions. Use the suggestion object to display suggestions in your preferred manner. empty is called when there's no suggestion. Mailcheck just passes in the target element. It is a good idea to use this callback to clear an existing suggestion. Usage without jQuery Mailcheck is decoupled from jQuery, so its usage without jQuery is almost identical. Using the example from above, you would call Mailcheck.run instead. The rest works similarly. In fact, the Mailcheck jQuery plugin just wraps Mailcheck.run. Usage on Node.js If you're running this on Node.js, you can just require('mailcheck') to get the mailcheck object, and call run on that: Domains Mailcheck has inbuilt defaults if the domains, secondLevelDomains or topLevelDomains options aren't provided. We still recommend supplying your own domains based on the distribution of your users. Adding your own Domains You can replace Mailcheck's default domain/TLD suggestions by supplying replacements to mailcheck.run: Alternatively, you can extend Mailcheck's global set of default domains and TLDs by adding items to Mailcheck.defaultDomains and Mailcheck.defaultTopLevelDomains: Customization The Mailcheck jQuery plugin wraps Mailcheck. The prime candidates for customization are the methods Mailcheck.findClosestDomain and Mailcheck.stringDistance. Mailcheck currently uses the sift3 string similarity algorithm by Siderite. You can modify the inbuilt string distance function, or pass in your own when calling Mailcheck. Since Mailcheck runs client side, keep in mind file size, memory usage and performance. Tests Mailcheck is tested with Jasmine. Run npm test from the command line to run the test suite. Alternatively, you can Load spec/spec_runner.html in your browser. Contributing Let's make Mailcheck awesome. We're on the lookout for maintainers and contributors. And do send in those pull requests! To get them accepted, please: Test your code. Add test cases to spec/mailcheckSpec.js, and run it across browsers (yes, including IE). Minify the plugin by running grunt in the Mailcheck directory (npm install should have installed a git pre-commit hook that takes care of this for you). Upcoming features, bugs and feature requests are managed in Issues. Who uses Mailcheck? Dropbox Hack Design Kicksend Kickstarter Khan Academy Lyft Minecraft SB Nation The Verge Do you use Mailcheck? Tweet me your link. Related Links Official Mailcheck Ports Two ways to reduce bounced welcome emails by Postmark MooTools port by Dimitar Christoff WordPress Plugin by Drew Poland WordPress e-Commerce Plugin Mailcheck for Drupal by Martin Elvar Core Team Derrick Ko, @derrickko. Created Mailcheck. Wei Lu, Hive, @luweidewei. License Released under the MIT License."
3650,"Easy interactive web applications with Rshiny Easily build rich and productive interactive web apps in R no HTML/CSS/JavaScript required. Features An intuitive and extensible reactive programming model which makes it easy to transform existing R code into a ""live app"" where outputs automatically react to new user input. Compared to event-based programming, reactivity allows Shiny to do the minimum amount of work when input(s) change, and allows humans to more easily reason about complex MVC logic. A prebuilt set of highly sophisticated, customizable, and easy-to-use widgets (e.g., plots, tables, sliders, dropdowns, date pickers, and more). An attractive default look based on Bootstrap which can also be easily customized with the bslib package or avoided entirely with more direct R bindings to HTML/CSS/JavaScript. Seamless integration with R Markdown, making it easy to embed numerous applications natively within a larger dynamic document. Tools for improving and monitoring performance, including native support for async programming, caching, load testing, and more. Modules: a framework for reducing code duplication and complexity. An ability to bookmark application state and/or generate code to reproduce output(s). A rich ecosystem of extension packages for more custom widgets, input validation, unit testing, and more. Installation To install the stable version from CRAN: Getting Started Once installed, load the library and run an example: For more examples and inspiration, check out the Shiny User Gallery. For help with learning fundamental Shiny programming concepts, check out the Mastering Shiny book and the Shiny Tutorial. The former is currently more up-to-date with modern Shiny features, whereas the latter takes a deeper, more visual, dive into fundamental concepts. Getting Help To ask a question about Shiny, please use the RStudio Community website. For bug reports, please use the issue tracker and also keep in mind that by writing a good bug report, you're more likely to get help with your problem. Contributing We welcome contributions to the shiny package. Please see our CONTRIBUTING.md file for detailed guidelines of how to contribute. License The shiny package as a whole is licensed under the GPLv3. See the LICENSE file for more details."
577,"The Crystal Programming LanguageCrystal Crystal is a programming language with the following goals: Have a syntax similar to Ruby (but compatibility with it is not a goal) Statically type-checked but without having to specify the type of variables or method arguments. Be able to call C code by writing bindings to it in Crystal. Have compile-time evaluation and generation of code, to avoid boilerplate code. Compile to efficient native code. Why? We love Ruby's efficiency for writing code. We love C's efficiency for running code. We want the best of both worlds. We want the compiler to understand what we mean without having to specify types everywhere. We want full OOP. Oh, and we don't want to write C code to make the code run faster. Project Status Within a major version language features won't be removed or changed in any way that could prevent an existing code to keep compiling and working. And the built in standard library might be enriched but always with backward compatibility in mind. The development is possible thanks to the community's effort and the continued support of 84codes, Nikola Motor Company and every other sponsor. Installing Follow these instructions Try it online play.crystal-lang.org Documentation Language Reference Standard library API Roadmap Community Questions or suggestions? Ask on the Crystal Forum, on our Gitter channel or IRC channel #crystal-lang at chat.freenode.net, or on Stack Overflow under the crystal-lang tag. There is also an archived Google Group. Contributing The Crystal repository is hosted at crystal-lang/crystal on GitHub. Read the general Contributing guide, and then: Fork it (https://github.com/crystal-lang/crystal/fork) Create your feature branch (git checkout -b my-new-feature) Commit your changes (git commit -am 'Add some feature') Push to the branch (git push origin my-new-feature) Create a new Pull Request"
4015,The missing desktop client for Gmail & Google InboxWe've moved! Hi! This repository is no longer being used and has been archived for historical purposes. Find out more at https://wavebox.io
2648,"PHP Database Migrations for EveryonePhinx: Simple PHP Database Migrations Intro Phinx makes it ridiculously easy to manage the database migrations for your PHP app. In less than 5 minutes, you can install Phinx and create your first database migration. Phinx is just about migrations without all the bloat of a database ORM system or framework. Check out book.cakephp.org/phinx (EN, ZH) for the comprehensive documentation. Features Write database migrations using database agnostic PHP code. Migrate up and down. Migrate on deployment. Seed data after database creation. Get going in less than 5 minutes. Stop worrying about the state of your database. Take advantage of SCM features such as branching. Integrate with any app. Supported Adapters Phinx natively supports the following database adapters: MySQL PostgreSQL SQLite Microsoft SQL Server Install & Run See version and branch overview for branch and PHP compatibility. Composer The fastest way to install Phinx is to add it to your project using Composer (https://getcomposer.org/). Install Composer: Require Phinx as a dependency using Composer: Install Phinx: Execute Phinx: As a Phar You can also use the Box application to build Phinx as a Phar archive (https://box-project.github.io/box2/). Clone Phinx from GitHub Install Composer Install the Phinx dependencies Install Box: Create a Phar archive Documentation Check out https://book.cakephp.org/phinx for the comprehensive documentation. Other translations include: Chinese (Maintained by @tsy12321) Contributing Please read the CONTRIBUTING document. News & Updates Follow @CakePHP on Twitter to stay up to date. Limitations PostgreSQL Not able to set a unique constraint on a table (https://github.com/cakephp/phinx/issues/1026). Misc Version History Please read the release notes. License (The MIT license) Copyright (c) 2017 Rob Morgan Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the ""Software""), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
2792,"IPFS implementation in Gogo-ipfs What is IPFS? IPFS is a global, versioned, peer-to-peer filesystem. It combines good ideas from previous systems such as Git, BitTorrent, Kademlia, SFS, and the Web. It is like a single BitTorrent swarm, exchanging git objects. IPFS provides an interface as simple as the HTTP web, but with permanence built-in. You can also mount the world at /ipfs. For more info see: https://docs.ipfs.io/introduction/overview/ Before opening an issue, consider using one of the following locations to ensure you are opening your thread in the right place: - go-ipfs implementation bugs in this repo. - Documentation issues in ipfs/docs issues. - IPFS design in ipfs/specs issues. - Exploration of new ideas in ipfs/notes issues. - Ask questions and meet the rest of the community at the IPFS Forum. Table of Contents Security Issues Install System Requirements Install prebuilt packages From Linux package managers Build from Source Install Go Download and Compile IPFS Troubleshooting Updating go-ipfs Getting Started Some things to try Usage Running IPFS inside Docker Troubleshooting Packages Development CLI, HTTP-API, Architecture Diagram Testing Development Dependencies Contributing License Security Issues The IPFS protocol and its implementations are still in heavy development. This means that there may be problems in our protocols, or there may be mistakes in our implementations. And -- though IPFS is not production-ready yet -- many people are already running nodes in their machines. So we take security vulnerabilities very seriously. If you discover a security issue, please bring it to our attention right away! If you find a vulnerability that may affect live deployments -- for example, by exposing a remote execution exploit -- please send your report privately to security@ipfs.io. Please DO NOT file a public issue. If the issue is a protocol weakness that cannot be immediately exploited or something not yet deployed, just discuss it openly. Install The canonical download instructions for IPFS are over at: https://docs.ipfs.io/guides/guides/install/. It is highly recommended you follow those instructions if you are not interested in working on IPFS development. System Requirements IPFS can run on most Linux, macOS, and Windows systems. We recommend running it on a machine with at least 2 GB of RAM and 2 CPU cores (go-ipfs is highly parallel). On systems with less memory, it may not be completely stable. If your system is resource-constrained, we recommend: Installing OpenSSL and rebuilding go-ipfs manually with make build GOTAGS=openssl. See the download and compile section for more information on compiling go-ipfs. Initializing your daemon with ipfs init --profile=lowpower Install prebuilt packages We host prebuilt binaries over at our distributions page. From there: - Click the blue ""Download go-ipfs"" on the right side of the page. - Open/extract the archive. - Move ipfs to your path (install.sh can do it for you). You can also download go-ipfs from this project's GitHub releases page if you are unable to access ipfs.io. From Linux package managers Arch Linux Nix Solus Snap Arch Linux In Arch Linux go-ipfs is available as go-ipfs package. Development version of go-ipfs is also on AUR under go-ipfs-git. You can install it using your favorite AUR Helper or manually from AUR. Nix For Linux and MacOSX you can use the purely functional package manager Nix: You can also install the Package by using its attribute name, which is also ipfs. Guix GNU's functional package manager, Guix, also provides a go-ipfs package: Solus In solus, go-ipfs is available in the main repository as go-ipfs. You can also install it through the Solus software center. Snap With snap, in any of the supported Linux distributions: From Windows package managers Chocolatey Scoop Chocolatey The package ipfs currently points to go-ipfs and is being maintained. Scoop Scoop provides go-ipfs in its 'extras' bucket. Build from Source go-ipfs's build system requires Go 1.15.2 and some standard POSIX build tools: GNU make Git GCC (or some other go compatible C Compiler) (optional) To build without GCC, build with CGO_ENABLED=0 (e.g., make build CGO_ENABLED=0). Install Go The build process for ipfs requires Go 1.15.2 or higher. If you don't have it: Download Go 1.15+. You'll need to add Go's bin directories to your $PATH environment variable e.g., by adding these lines to your /etc/profile (for a system-wide installation) or $HOME/.profile: (If you run into trouble, see the Go install instructions). Download and Compile IPFS Alternatively, you can run make build to build the go-ipfs binary (storing it in cmd/ipfs/ipfs) without installing it. NOTE: If you get an error along the lines of ""fatal error: stdlib.h: No such file or directory"", you're missing a C compiler. Either re-run make with CGO_ENABLED=0 or install GCC. Cross Compiling Compiling for a different platform is as simple as running: OpenSSL To build go-ipfs with OpenSSL support, append GOTAGS=openssl to your make invocation. Building with OpenSSL should significantly reduce the background CPU usage on nodes that frequently make or receive new connections. Note: OpenSSL requires CGO support and, by default, CGO is disabled when cross-compiling. To cross-compile with OpenSSL support, you must: Install a compiler toolchain for the target platform. Set the CGO_ENABLED=1 environment variable. Troubleshooting Separate instructions are available for building on Windows. git is required in order for go get to fetch all dependencies. Package managers often contain out-of-date golang packages. Ensure that go version reports at least 1.10. See above for how to install go. If you are interested in development, please install the development dependencies as well. WARNING: Older versions of OSX FUSE (for Mac OS X) can cause kernel panics when mounting!- We strongly recommend you use the latest version of OSX FUSE. (See https://github.com/ipfs/go-ipfs/issues/177) For more details on setting up FUSE (so that you can mount the filesystem), see the docs folder. Shell command completion is available in misc/completion/ipfs-completion.bash. Read docs/command-completion.md to learn how to install it. See the misc folder for how to connect IPFS to systemd or whatever init system your distro uses. Updating go-ipfs Using ipfs-update IPFS has an updating tool that can be accessed through ipfs update. The tool is not installed alongside IPFS in order to keep that logic independent of the main codebase. To install ipfs update, download it here. Downloading IPFS builds using IPFS List the available versions of go-ipfs: Then, to view available builds for a version from the previous command ($VERSION): To download a given build of a version: Getting Started See also: https://docs.ipfs.io/introduction/usage/ To start using IPFS, you must first initialize IPFS's config files on your system, this is done with ipfs init. See ipfs init --help for information on the optional arguments it takes. After initialization is complete, you can use ipfs mount, ipfs add and any of the other commands to explore! Some things to try Basic proof of 'ipfs working' locally: echo ""hello world"" > hello ipfs add hello # This should output a hash string that looks something like: # QmT78zSuBmuS4z925WZfrqQ1qHaJ56DQaTfyMUF7F8ff5o ipfs cat <that hash> Usage Running IPFS inside Docker An IPFS docker image is hosted at hub.docker.com/r/ipfs/go-ipfs. To make files visible inside the container you need to mount a host directory with the -v option to docker. Choose a directory that you want to use to import/export files from IPFS. You should also choose a directory to store IPFS files that will persist when you restart the container. export ipfs_staging=</absolute/path/to/somewhere/> export ipfs_data=</absolute/path/to/somewhere_else/> Start a container running ipfs and expose ports 4001, 5001 and 8080: docker run -d --name ipfs_host -v $ipfs_staging:/export -v $ipfs_data:/data/ipfs -p 4001:4001 -p 4001:4001/udp -p 127.0.0.1:8080:8080 -p 127.0.0.1:5001:5001 ipfs/go-ipfs:latest Watch the ipfs log: docker logs -f ipfs_host Wait for ipfs to start. ipfs is running when you see: Gateway (readonly) server listening on /ip4/0.0.0.0/tcp/8080 You can now stop watching the log. Run ipfs commands: docker exec ipfs_host ipfs <args...> For example: connect to peers docker exec ipfs_host ipfs swarm peers Add files: cp -r <something> $ipfs_staging docker exec ipfs_host ipfs add -r /export/<something> Stop the running container: docker stop ipfs_host When starting a container running ipfs for the first time with an empty data directory, it will call ipfs init to initialize configuration files and generate a new keypair. At this time, you can choose which profile to apply using the IPFS_PROFILE environment variable: docker run -d --name ipfs_host -e IPFS_PROFILE=server -v $ipfs_staging:/export -v $ipfs_data:/data/ipfs -p 4001:4001 -p 4001:4001/udp -p 127.0.0.1:8080:8080 -p 127.0.0.1:5001:5001 ipfs/go-ipfs:latest Private swarms inside Docker It is possible to initialize the container with a swarm key file (/data/ipfs/swarm.key) using the variables IPFS_SWARM_KEY and IPFS_SWARM_KEY_FILE. The IPFS_SWARM_KEY creates swarm.key with the contents of the variable itself, whilst IPFS_SWARM_KEY_FILE copies the key from a path stored in the variable. The IPFS_SWARM_KEY_FILE overwrites the key generated by IPFS_SWARM_KEY. docker run -d --name ipfs_host -e IPFS_SWARM_KEY=<your swarm key> -v $ipfs_staging:/export -v $ipfs_data:/data/ipfs -p 4001:4001 -p 4001:4001/udp -p 127.0.0.1:8080:8080 -p 127.0.0.1:5001:5001 ipfs/go-ipfs:latest The swarm key initialization can also be done using docker secrets (requires docker swarm or docker-compose): cat your_swarm.key | docker secret create swarm_key_secret - docker run -d --name ipfs_host --secret swarm_key_secret -e IPFS_SWARM_KEY_FILE=/run/secrets/swarm_key_secret -v $ipfs_staging:/export -v $ipfs_data:/data/ipfs -p 4001:4001 -p 4001:4001/udp -p 127.0.0.1:8080:8080 -p 127.0.0.1:5001:5001 ipfs/go-ipfs:latest Key rotation inside Docker If needed, it is possible to do key rotation in an ephemeral container that is temporarily executing against a volume that is mounted under /data/ipfs: Troubleshooting If you have previously installed IPFS before and you are running into problems getting a newer version to work, try deleting (or backing up somewhere else) your IPFS config directory (~/.ipfs by default) and rerunning ipfs init. This will reinitialize the config file to its defaults and clear out the local datastore of any bad entries. Please direct general questions and help requests to our forum or our IRC channel (freenode #ipfs). If you believe you've found a bug, check the issues list and, if you don't see your problem there, either come talk to us on IRC (freenode #ipfs) or file an issue of your own! Packages This table is generated using the module package-table with package-table --data=package-list.json. Listing of the main packages used in the IPFS ecosystem. There are also three specifications worth linking here: | Name | CI/Travis | Coverage | Description | | ---------|---------|---------|--------- | | Libp2p | | go-libp2p | | | p2p networking library | | go-libp2p-pubsub | | | pubsub built on libp2p | | go-libp2p-kad-dht | | | dht-backed router | | go-libp2p-pubsub-router | | | pubsub-backed router | | Multiformats | | go-cid | | | CID implementation | | go-multiaddr | | | multiaddr implementation | | go-multihash | | | multihash implementation | | go-multibase | | | mulitbase implementation | | Files | | go-unixfs | | | the core 'filesystem' logic | | go-mfs | | | a mutable filesystem editor for unixfs | | go-ipfs-posinfo | | | helper datatypes for the filestore | | go-ipfs-chunker | | | file chunkers | | Exchange | | go-ipfs-exchange-interface | | | exchange service interface | | go-ipfs-exchange-offline | | | (dummy) offline implementation of the exchange service | | go-bitswap | | | bitswap protocol implementation | | go-blockservice | | | service that plugs a blockstore and an exchange together | | Datastores | | go-datastore | | | datastore interfaces, adapters, and basic implementations | | go-ipfs-ds-help | | | datastore utility functions | | go-ds-flatfs | | | a filesystem-based datastore | | go-ds-measure | | | a metric-collecting database adapter | | go-ds-leveldb | | | a leveldb based datastore | | go-ds-badger | | | a badgerdb based datastore | | Namesys | | go-ipns | | | IPNS datastructures and validation logic | | Repo | | go-ipfs-config | | | go-ipfs config file definitions | | go-fs-lock | | | lockfile management functions | | fs-repo-migrations | | | repo migrations | | IPLD | | go-block-format | | | block interfaces and implementations | | go-ipfs-blockstore | | | blockstore interfaces and implementations | | go-ipld-format | | | IPLD interfaces | | go-ipld-cbor | | | IPLD-CBOR implementation | | go-ipld-git | | | IPLD-Git implementation | | go-merkledag | | | IPLD-Merkledag implementation (and then some) | | Commands | | go-ipfs-cmds | | | CLI & HTTP commands library | | go-ipfs-files | | | CLI & HTTP commands library | | go-ipfs-api | | | an old, stable shell for the IPFS HTTP API | | go-ipfs-http-client | | | a new, unstable shell for the IPFS HTTP API | | interface-go-ipfs-core | | | core go-ipfs API interface definitions | | Metrics & Logging | | go-metrics-interface | | | metrics collection interfaces | | go-metrics-prometheus | | | prometheus-backed metrics collector | | go-log | | | logging framework | | Generics/Utils | | go-ipfs-routing | | | routing (content, peer, value) helpers | | go-ipfs-util | | | the kitchen sink | | go-ipfs-addr | | | utility functions for parsing IPFS multiaddrs | For brevity, we've omitted most go-libp2p, go-ipld, and go-multiformats packages. These package tables can be found in their respective project's READMEs: go-libp2p go-ipld Development Some places to get you started on the codebase: Main file: ./cmd/ipfs/main.go CLI Commands: ./core/commands/ Bitswap (the data trading engine): go-bitswap libp2p libp2p: https://github.com/libp2p/go-libp2p DHT: https://github.com/libp2p/go-libp2p-kad-dht PubSub: https://github.com/libp2p/go-libp2p-pubsub IPFS : The Add command demystified Map of go-ipfs Subsystems WIP: This is a high-level architecture diagram of the various sub-systems of go-ipfs. To be updated with how they interact. Anyone who has suggestions is welcome to comment here on how we can improve this! CLI, HTTP-API, Architecture Diagram Origin Description: Dotted means ""likely going away"". The ""Legacy"" parts are thin wrappers around some commands to translate between the new system and the old system. The grayed-out parts on the ""daemon"" diagram are there to show that the code is all the same, it's just that we turn some pieces on and some pieces off depending on whether we're running on the client or the server. Testing Development Dependencies If you make changes to the protocol buffers, you will need to install the protoc compiler. Developer Notes Find more documentation for developers on docs Contributing We all our contributors; this project wouldnt be what it is without you! If you want to help out, please see CONTRIBUTING.md. This repository falls under the IPFS Code of Conduct. You can contact us on the freenode #ipfs-dev channel or attend one of our weekly calls. License The go-ipfs project is dual-licensed under Apache 2.0 and MIT terms: Apache License, Version 2.0, (LICENSE-APACHE or http://www.apache.org/licenses/LICENSE-2.0) MIT license (LICENSE-MIT or http://opensource.org/licenses/MIT)"
931,"Golang terminal dashboardtermui termui is a cross-platform and fully-customizable terminal dashboard and widget library built on top of termbox-go. It is inspired by blessed-contrib and tui-rs and written purely in Go. Features Several premade widgets for common use cases Easily create custom widgets Position widgets either in a relative grid or with absolute coordinates Keyboard, mouse, and terminal resizing events Colors and styling Installation Go modules It is not necessary to go get termui, since Go will automatically manage any imported dependencies for you. Do note that you have to include /v3 in the import statements as shown in the 'Hello World' example below. Dep Add with dep ensure -add github.com/gizak/termui. With Dep, /v3 should not be included in the import statements. Hello World Widgets BarChart Canvas (for drawing braille dots) Gauge Image List Tree Paragraph PieChart Plot (for scatterplots and linecharts) Sparkline StackedBarChart Table Tabs Run an example with go run _examples/{example}.go or run each example consecutively with make run-examples. Documentation wiki Uses dockdash expvarmon go-ethereum/monitorcmd go-jira-ui gotop termeter Related Works blessed-contrib gocui termdash tui-rs tview License MIT"
2628," A simple and extensible shell script for managing your todo.txt file.A simple and extensible shell script for managing your todo.txt file. Read our contributing guide if you're looking to contribute (issues/PRs/etc). Installation Download Download the latest stable release for use on your desktop or server. OS X / macOS Note: The -n flag for cp makes sure you do not overwrite an existing file. Linux From command line NOTE: Makefile defaults to several default paths for installed files. Adjust to your system: INSTALL_DIR: PATH for executables (default /usr/local/bin) CONFIG_DIR: PATH for todo.txt config BASH_COMPLETION: PATH for autocompletion scripts (default to /etc/bash_completion.d) Arch Linux (AUR) https://aur.archlinux.org/packages/todotxt/ Usage For example, to add a todo item, you can do: Read about all the possible commands in the USAGE file. Release History See CHANGELOG.md Support Github Discussions Stack Overflow Twitter Code of Conduct Contributor Code of Conduct. By participating in this project you agree to abide by its terms. Contributing We welcome all contributations. First read our Contributor Code of Conduct and then get started contributing. License GNU General Public License v3.0 todo.txt org"
1483,"A very lightweight jQuery plugin to lazy load imagesunveil.js A very lightweight plugin to lazy load images for jQuery or Zepto.js Most of us are familiar with the Lazy Load plugin by Mika Tuupola. This plugin is very useful and it boosts performance delaying loading of images in long web pages because images outside of viewport (visible part of web page) won't be loaded until the user scrolls to them. Lazy Load has some cool options such as custom effects, container, events or data attribute. If you're not gonna use any of them you can reduce the file size by leaving just the essential code to show the images. That's what I did and this is my lightweight version of Lazy Load with support for serving high-resolution images to devices with retina displays - less than 1k. Visit unveil's project page to read the documentation and see the demo. Browser support Compatible with All Browsers and IE7+. License Unveil is licensed under the MIT license."
3127,"A custom visual calendar for iOS 8+ written in Swift (>= 4.0). Overview Screenshots GIF Demo Installation Usage Architecture Version matrix Advanced API For contributors Screenshots GIF Demo Installation CocoaPods Usage Using CVCalendar isn't difficult at all. There are two actual ways of implementing it in your project: * Storyboard setup * Manual setup So let's get started. Warning! Since 1.1.1 version CVCalendar requires an implementation of two protocols CVCalendarViewDelegate and CVCalendarMenuViewDelegate, please implement both. Also note, they both have a method with the same signature which means you need to impement it only once. Take a look at the Demo project for more info. Storyboard Setup Basic setup. First, you have to integrate CVCalendar with your project through CocoaPods. Now you're about to add 2 UIViews to your Storyboard as it shown in the picture below. Don't forget to add 2 outlets into your code. Two views are representing ultimately a MenuView and a CalendarView so they should have corresponding classes. To change their classes go to Identity Inspector and set custom classes. When it's done, you'll see in the dock panel something similar to the picture below. (Blue UIView -> CVCalendarView, Green UIView -> CVCalendarMenuView) NOTE: Please note that both CalendarView and MenuView are calculating their content's frames depending on their own ones. So in your projects you may be editing the size of initial UIViews in the storyboard to reach an optimal content size. Important note. Before we move to setting up delegates for customization stuff, you should know that CalendarView's initialization is devided by 2 parts: * On Init. * On Layout. As well as most of the developers are using AutoLayout feature UIView's size in the beginning of initialization does not match the one on UIView's appearing. Thus we have either to initialize ContentView with MonthViews and all the appropriate stuff on UIView's appearing or initialize stuff as UIView's being initialized and then simply update frames. The first option doesn't work since there will be a flash effect (the initialization will be finished after your UIView appeared) according to what the CVCalendar has 2 parts of creating. Since CVCalendarView and CVCalendarMenuView will be created automatically all you have to do is this (in the ViewController that contains CVCalendar). ` Delegates Setup (Customization). CVCalendar requires to implement two protocols. They are CVCalendarViewDelegate and CVCalendarMenuViewDelegate. Note that the last one has exactly the same named method as the first one declares which means you have to implement only required methods in CVCalendarViewDelegate and set your controller as a delegate implementing both protocols. These protocols stand for getting the data for building CVCalendarView and CVCalendarMenuView. So do not forget to implement them. API Page A long story in short or customizable properties: * Showing weekdays out * Moving dot markers on highlighting * Showing dot markers on a specific day view * Dot marker's color, offset and size * Space between week views and day views * Day view's label properties (color, background, alpha + different states (normal/highlighted)) Behavior: * Day view selection * Presented date update * Animations on (de)selecting day views Finally we're going to customize properties. To make this possible you have to implement approptiate protocols. (You can see presented protocols and short descriptions in the Architecture Section). Open your Storyboard and do a right-click on CVCalendarView, you'll see the window with outlets and there are a few ones we actually need. Take a look at the picture to make sure you're doing everything properly. Now depending on what you'd like to change you should implement a particular protocol providing methods for customizing that stuff. For delegates' API description take a look at [this page] (https://github.com/CVCalendar/CVCalendar/wiki). Do NOT forget to connect a particular outlet with your ViewController if you're implementing its protocol. NOTE: CVCalendar defines default values for all the customizable properties (i.e. for ones defined in the presented protocols). Thus far if you don't implement protocols yourself the calendar will behave as it was initially designed. Manual Setup If for some reason you'd like to setup CVCalendar manually you have to do the following steps. Initialize CVCalendarView with either init or init:frame methods. I suggest to do it in viewDidLoad method. Do NOT put initialization in viewDidAppear: or viewWillAppear: methods! Then setup delegates if you're going to customize options. Note that CVCalendarAppearanceDelegate should be set before CVCalendarViewDelegate so your changes can be applied. For CVCalendarMenuView you simply initialize it as well as CVCalendarView and it requires to implement CVCalendarMenuViewDelegate protocol. How it should look like. And do not forget to commit updates on viewDidLayoutSubviews method. Here you go. Architecture Version matrix CVCalendar adapts the newest swift language syntax but keeps revisions as stated below: | CVCalendar | Swift | Xcode | Release Notes | | ---------- | -------- | -------------- | ------------ | | 1.6 | 4.x | 8.x, 9.x, 10.x | HEAD | | 1.5 | 3.x | 8.x, 9.x | swift3-branch | | 1.4 | 3.x | 7.x, 8.0 | Unsupported | | 1.3 | 2.x | 7.x | Unsupported | | 1.2 | 1.x | 7.x | Unsupported | Advanced API For contributors If you've any remarks please feel free to open up an issue or submit PRs. Please make sure to adhere to the provided issue template while doing so. Also note that the Demo project is supposed to test the changes on CVCalendar. If you've committed any, do not forget to check if everything compiles and works as intended and update the docs accordingly. Thanks :+1:"
149,"AdminLTE - Free admin dashboard template based on Bootstrap 4AdminLTE - Bootstrap 4 Admin Dashboard AdminLTE is a fully responsive administration template. Based on Bootstrap 4.6 framework and also the JS/jQuery plugin. Highly customizable and easy to use. Fits many screen resolutions from small mobile devices to large desktops. Preview on AdminLTE.io Looking for Premium Templates? AdminLTE.io just opened a new premium templates page. Hand picked to ensure the best quality and the most affordable prices. Visit https://adminlte.io/premium for more information. AdminLTE has been carefully coded with clear comments in all of its JS, SCSS and HTML files. SCSS has been used to increase code customizability. Quick start There are multiple ways to install AdminLTE. Download & Changelog: Always Recommended to download from GitHub latest release AdminLTE 3 for bug free and latest features.\ Visit the releases page to view the changelog.\ Legacy Releases are AdminLTE 2 / AdminLTE 1. Stable release Grab from jsdelivr CDN: Important Note: You needed to add separately cdn links for plugins in your project. Using The Command Line: Important Note: To install it via npm/Yarn, you need at least Node.js 10 or higher. Via npm Via Yarn Via Composer Via Git Unstable release Grab from jsdelivr CDN: Important Note: You needed to add separately cdn links for plugins in your project. Using The Command Line: Important Note: To install it via npm/Yarn, you need at least Node.js 10 or higher. Via npm Via Yarn Via Composer Via Git Documentation Visit the online documentation for the most updated guide. Information will be added on a weekly basis. Browsers support | IE / Edge | Firefox | Chrome | Safari | iOS Safari | Samsung | Opera | Vivaldi | Electron | | --------- | --------- | --------- | --------- | --------- | --------- | --------- | --------- | --------- | | IE10, IE11, Edge| last 2 versions| last 2 versions| last 2 versions| last 2 versions| last 2 versions| last 2 versions| last 2 versions| last 2 versions Compile dist files To compile the dist files you need Node.js/npm, clone/download the repo then: npm install (install npm deps) Optional: npm run dev (developer mode, autocompile with browsersync support for live demo) npm run production (compile css/js files) Contributing Please read through our contributing guidelines. Included are directions for opening issues, coding standards, and notes on development. Editor preferences are available in the editor config for easy use in common text editors. Read more and download plugins at https://editorconfig.org/. License AdminLTE is an open source project by AdminLTE.io that is licensed under MIT. AdminLTE.io reserves the right to change the license of future releases. Image Credits Pixeden Graphicsfuel Pickaface Unsplash Uifaces"
1526,"API Services Made Easy With Node.jsNodal API Services Made Easy with Node.js View the website at nodaljs.com. Nodal is a web server and opinionated framework for building data manipulation-centric (Create Read Update Destroy) API services in Node.js for web, mobile or IoT apps. Why Nodal? Hello, Nodal Building Node.js Servers for Everybody is our first blog post that helps you get acquainted with the reasons behind the creation of the framework. :) Post Parse Prototyping is also a fantastic read explaining the benefits of Nodal for quick and easy mobile / IoT backend development. Overview Nodal is built upon an ideology of a robust, scalable architecture for data storage and retrieval APIs. It is an opinionated, explicit, idiomatic and highly-extensible full-service framework that takes care of all of the hard decisions for you and your team. This allows you to focus on creating an effective product in a short timespan while minimizing technical debt. Nodal servers are not meant to be monoliths. They're stateless and distributed, meant to service your needs of interfacing with your data layer effortlessly. While you can output any data format with Nodal, it's recommended you offload things like static page rendering to other optimized services like CDNs. Check out the first Nodal Screencast here. Stateless Dogma It's important to note that Nodal is meant for stateless API services. This means you should not rely on memory within a specific process to serve multiple requests, and Nodal will use process clustering (even in development) to actively discourage this practice. If you need to work with unstructured data for rapid prototyping, connect Nodal to a PostgreSQL database and use the ""JSON"" field type. You'll find yourself encountering a lot of trouble if you start trying to use in-process memory across different requests. Remember: one input, one output. Side effects dealing with model state should be managed via your Database. Nodal should not be used for streaming (long poll) requests and the HTTP request and response objects are intentionally obfuscated. This also means you can not rely on socket connections. If you need to incorporate realtime functionality in your application, there should be a separate server responsible for this. It can interface with your Nodal API server and even receive events from it, but your API server should never have a stateful (prolonged) connection with any client. Getting Started Getting started with Nodal is easy. Download and install the newest Node 6.x version from nodejs.org Open terminal, and type npm install nodal -g. (If you get an error, run sudo npm install nodal -g or fix permissions permanently by following these directions Using your terminal, visit your projects folder. Perhaps with cd ~. Run nodal new. Follow the on screen instructions, enter your new project directory and type nodal s. That's it! Your Nodal webserver is up and running. Hooking Up Your Database Once Nodal is up and running, it's likely that you'll want to connect your project to a database. Nodal comes packaged with Migrations, a Query Composer and full PostgreSQL integration. First you'll need to install PostgreSQL. OS X users, I recommend using Postgres.app for your development environment. Once you've installed Postgres, make sure to run: To create a default postgres superuser with no password. (Default for Nodal's configuration.) To begin using your database, start with: To create the database and then, To prepare for migrations. From here, nodal db:migrate runs all pending migrations and nodal db:rollback will roll back migrations, one at a time by default. Server Types Nodal works best when you follow its ideology, and that means creating a new service to solve specific Problem Domains of your application and business. The main three suggestions are Branding Server, API Server and Application Server. Nodal's core competency is building API servers. We do, however, also have a project called dotcom for building Branding Servers (search engine optimized server-generated pages). More on this soon. API Server Create an API server using Nodal's Models, PostgreSQL integration, built-in JSON API formatting, and Query Composer (ORM). Bi-directional migrations are packaged with Nodal, meaning you can maintain the integrity of your data. User (including password) and OAuth AccessToken models and controllers are pre-built for you and can be added easily to your project. Packaged with Nodal are workers, scheduling modules, and much more for all of your data needs. We can look at what an API Controller might look like for, say, blog posts: Beginner's Guide You'll be able to learn more about Nodal at nodaljs.com. Documentation Check out the website at nodaljs.com. Roadmap View the roadmap at ROADMAP.md. About Nodal is under active development and maintained by Keith Horwood. Contributors welcome! Follow me on Twitter, @keithwhor Fork me on GitHub, keithwhor Thanks for checking out Nodal!"
3441,"Open-source Javascript Pivot Table (aka Pivot Grid, Pivot Chart, Cross-Tab) implementation with drag'n'drop.PivotTable.js PivotTable.js is a Javascript Pivot Table library with drag'n'drop functionality built on top of jQuery/jQueryUI and originally written in CoffeeScript by Nicolas Kruchten. It is available under an MIT license from CDNJS and NPM and Bower under the name pivottable. And on Packagist.org, it is nicolaskruchten/pivottable. PivotTable.js can be used with Python/Jupyter and R/RStudio and you can try it right now in your browser on a CSV file. Are you using React? Check out the React port: react-pivottable. What does it do? PivotTable.js' basic function is to enable data exploration and analysis by turning a data set into a summary table and then optionally adding a true 2-d drag'n'drop UI to allow a user to manipulate this summary table, turning it into a pivot table, very similar to the one found in older versions of Microsoft Excel with a bunch of extra developer-oriented features and some visualization effects. With optional add-ons, the summary table can be rendered as various kinds of charts, turning the pivot table into a pivot chart. The animation above is based on the Canadian Parliament 2012 dataset example. Where are the demos/examples? There are lots on the examples page but here are some good entry points: a JSFiddle where you can play with the code a simple demo running on the ""Canadian Parliament 2012"" dataset fully-loaded demo running on the 700+ datasets that ship with R fully-loaded demo where you provide your own CSV file for input Why is it good? it's lightweight: the core (without chart support) is a single file with less than 1000 LOC of CoffeeScript, compiles down to 6.3kb of Javascript minified and gzipped, and depends only on jQuery and jQueryUI's 'sortable' it works wherever jQuery and jQueryUI work (tested with jQuery 1.8.3 and jQueryUI 1.9.2) it works acceptably fast in Chrome on commodity hardware up to around a hundred thousand records, depending on the cardinality of the attributes. its UI is localizable its layered architecture allows for summary table generation with or without the pivot table UI around it (if you don't use the UI, then there is no dependency on jQueryUI) it works with common input formats its derived attributes can be created on the fly based on the whole input record by passing in a function its complex aggregation functions can compute values based on the whole input record (e.g. weighted averages) it has built-in support for basic heatmap and bar chart renderers, and optional extra renderers that add charting or TSV export support its extension points allow aggregation functions, table output, UI and visualizations to be tailored to specific applications it works on mobile devices with jQuery UI Touch Punch it has a test suite How do I use the UI? PivotTable.js implements a pivot table drag'n'drop UI similar to that found in popular spreadsheet programs. You can drag attributes into/out of the row/column areas, and specify rendering, aggregation and filtering options. There is a step-by-step tutorial in the wiki. How do I load the code? PivotTable.js implements the Universal Module Definition (UMD) pattern and so should be compatible with most approaches to script loading and dependency management: direct script loading i.e. from CDNJS or with RequireJS, Browserify etc. For the latter options, you can grab it from NPM with npm install pivottable or via Bower with bower install pivottable. If you are loading the scripts directly (as in the examples), you need to: load the dependencies: jQuery in all cases jQueryUI for the interactive pivotUI() function (see below) D3.js, C3.js and/or Google Charts if you use charting plugins load the PivotTable.js files: pivot.min.js any plugins you wish to use The dependencies and PivotTable.js files can be loaded: By copying the files from their official distributions to your project and loading them locally (the dist directory is where you will find the PivotTable.js files) From a Content Distribution Network (CDN) like CDNJS (The examples load dependencies from CDNJS and PivotTable.js locally) How do I use the code? There are two main functions provided by PivotTable.js: pivot() and pivotUI(), both implemented as jQuery plugins, as well as a bunch of helpers and templates. pivot() Once you've loaded jQuery and pivot.js, this code (demo): appends this table to $(""#output"") (the default, overridable behaviour is to populate the table cells with counts): pivotUI() A slight change to the code (calling pivotUI() instead of pivot() ) yields the same table with a drag'n'drop UI around it, so long as you've imported jQueryUI (demo): Note that pivot() and pivotUI() take different parameters in general, even though in the example above we passed the same parameters to both. See the FAQ. See the wiki for full parameter documentation. Where is the documentation? More extensive documentation can be found in the wiki: Frequently Asked Questions Full Parameter Documentation Input Formats Aggregators Renderers Derived Attributes Localization Optional Extra Renderers: Charting and Exporting Used By How can I build the code and run the tests? To install the development dependencies, just run npm install, which will create a node_modules directory with the files required to run the Gulp build system. After modifying any of the .coffee files at the top of the repo, you can compile/minify the files into the dist directory by running node_modules/gulp/bin/gulp.js Once that's done, you can point your browser to tests/index.html to run the Jasmine test suite. You can view the current test results here. The easiest way to modify the code and work with the examples is to leave a node_modules/gulp/bin/gulp.js watch serve command running, which will automatically compile the CoffeeScript files when they are modified and will also run a local web server you can connect to to run the tests and examples. How can I contribute? Pull requests are welcome! Here are some Contribution Guidelines. I have a question, how can I get in touch? Please first check the Frequently Asked Questions and if you can't find what you're looking for there, or in the wiki, then please create a GitHub Issue. When creating an issue, please try to provide a replicable test case so that others can more easily help you. Please do not email the author directly, as you will just be asked to create a Github Issue :) Copyright & Licence (MIT License) PivotTable.js is 2012-2016 Nicolas Kruchten, Datacratic, other contributors Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the ""Software""), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
2351,"Render interfaces using pure functions and virtual DOMDeku Deku is a library for rendering interfaces using pure functions and virtual DOM. Instead of using classes and local state, Deku just uses functions and pushes the responsibility of all state management and side-effects onto tools like Redux. It also aims to support only modern browsers to keep things simple. It can be used in place of libraries like React and works well with Redux and other libraries in the React ecosystem. Deku consists of 5 modules packaged together for convenience: element: Create virtual elements. diff: Compute the difference between two virtual elements. You can use this if you're creating a custom renderer. dom: Create DOM elements from virtual elements and update them using the result of a diff. You'll only use this directly if you're building your own app creator. string: Render a HTML string from virtual elements. createApp: Kickstart an app for the browser. Installation We support the latest two versions of each browser. This means we only support IE10+. Example Documentation You can read the documentation online. License The MIT License (MIT) Copyright (c) 2015 Anthony Short"
2005,"MagicMirror is an open source modular smart mirror platform. With a growing list of installable modules, the MagicMirror allows you to convert your hallway or bathroom mirror into your personal assistant. MagicMirror is an open source modular smart mirror platform. With a growing list of installable modules, the MagicMirror allows you to convert your hallway or bathroom mirror into your personal assistant. MagicMirror is built by the creator of the original MagicMirror with the incredible help of a growing community of contributors. MagicMirror focuses on a modular plugin system and uses Electron as an application wrapper. So no more web server or browser installs necessary! Documentation For the full documentation including installation instructions, please visit our dedicated documentation website: https://docs.magicmirror.builders. Links Website: https://magicmirror.builders Documentation: https://docs.magicmirror.builders Forum: https://forum.magicmirror.builders Discord: https://discord.gg/J5BAtvx Blog: https://michaelteeuw.nl/tagged/magicmirror Donations: https://magicmirror.builders/#donate Contributing Guidelines Contributions of all kinds are welcome, not only in the form of code but also with regards to bug reports documentation translations For the full contribution guidelines, check out: https://docs.magicmirror.builders/getting-started/contributing.html Enjoying MagicMirror? Consider a donation! MagicMirror is opensource and free. That doesn't mean we don't need any money. Please consider a donation to help us cover the ongoing costs like webservers and email services. If we receive enough donations we might even be able to free up some working hours and spend some extra time improving the MagicMirror core. To donate, please follow this link. "
4118,"Github fork of Christian Bach's tablesorter plugin + awesomeness ~tablesorter (FORK) is a jQuery plugin for turning a standard HTML table with THEAD and TBODY tags into a sortable table without page refreshes. tablesorter can successfully parse and sort many types of data including linked data in a cell. This forked version adds lots of new enhancements including: alphanumeric sorting, pager callback functons, multiple widgets providing column styling, ui theme application, sticky headers, column filters and resizer, as well as extended documentation with a lot more demos. Notice! Because of the change to the internal cache, the tablesorter v2.16+ core, filter widget and pager (both plugin & widget) will only work with the same version or newer files. Documentation See the full documentation. All of the original documentation has been included. Information from my blog post on undocumented options and lots of new demos have also been included. Change log moved from included text file into the wiki documentation. Questions? Check the FAQ page. Search the main documentation (click the menu button in the upper left corner). Search the issues to see if the question or problem has been brought up before, and hopefully resolved. If someone is available, ask your question in the #tablesorter IRC channel at freenode.net. Ask your question at Stackoverflow using a tablesorter tag. Please don't open a new issue unless it really is an issue with the plugin, or a feature request. Thanks! Demos Basic alpha-numeric sort Demo. Links to demo pages can be found within the main documentation. More demos & playgrounds - updated in the wiki pages. Features Multi-column alphanumeric sorting and filtering. Multi-tbody sorting - see the options table on the main document page. Supports Bootstrap v2-4. Parsers for sorting text, alphanumeric text, URIs, integers, currency, floats, IP addresses, dates (ISO, long and short formats) & time. Add your own easily. Inline editing - see demo. Support for ROWSPAN and COLSPAN on TH elements. Support secondary ""hidden"" sorting (e.g., maintain alphabetical sort when sorting on other criteria). Extensibility via widget system. Cross-browser: IE 6.0+, FF 2+, Safari 2.0+, Opera 9.0+, Chrome 5.0+. Small code size, starting at 25K minified. Works with jQuery 1.2.6+ (jQuery 1.4.1+ needed with some widgets). Works with jQuery 1.9+ ($.browser.msie was removed; needed in the original version). Licensing Copyright (c) 2007 Christian Bach. The original version can be found at http://tablesorter.com, or on GitHub. Dual licensed under the MIT or GPLv2 licenses (pick one). Download Get all files: zip or tar.gz. Use bower: bower install jquery.tablesorter. Use node.js: npm install tablesorter. CDNJS: https://cdnjs.com/libraries/jquery.tablesorter jsDelivr: http://www.jsdelivr.com/?query=tablesorter Related Projects Plugin for Rails. Maintained by themilkman. UserFrosting (A secure, modern user management system for PHP that uses tablesorter) by @alexweissman. Grav CMS: bin/gpm install tablesorter (ref). tablesorter-pagercontrols programmatically adds pager controls below a table and applies the pager add-on for large HTML tables by isg-software. Contributing If you would like to contribute, please... Fork. Make changes in a branch & add unit tests. Run grunt test (if qunit fails, run it again - it's fickle). Create a pull request. Special Thanks Big shout-out to Nick Craver for getting rid of the eval() function that was previously needed for multi-column sorting. Big thanks to thezoggy for helping with code, themes and providing valuable feedback. Big thanks to ThsSin- for taking over for a while and also providing valuable feedback. Thanks to prijutme4ty for numerous contributions! Also extra thanks to christhomas and Lynesth for help with code. And, of course thanks to everyone else that has contributed, and continues to contribute through pull requests and open issues to this forked project! Recent Changes View the complete change log here. Version 2.31.3 (2020-03-03) Core: Cache parsed value in colspan. Fixes issue #1708. AlignChar: Tweak demo css. See isssue #1713. Pager: Restore first row in cacheIndex. Fixes issues #1714 & #1710. Docs: Update to jQuery 3.4.1 & migrate 3.1.0. Update to Bootstrap 4.4.1. CSS cleanup - code font size was off. Version 2.31.2 (2019-12-01) Column selector: Fix scroller widget compatibility. See issue #1682. Filter: Update select2 regexp. See issue #1497. Fixed in PR #1677; thanks @cwisdo! Prevent search on enter if filters are unchanged. See issue #1631. Fixed in PR #1642; thanks @larsbonczek! Math Add math ignore to cells; it was documented, but not added previously. See issue #1526. Docs: Various fixes. Updated trigger sort page. See issue #1641. Remove invalid widget option. See issue #1581. Version 2.31.1 (2018-11-20) Core: Store sortList on init. Fixes issue #1585. Math: Add math_textAttr. See issue #1601. Readme: Remove bower, gitter & add Slack. Meta: Update dependencies."
691,"Mobile_Detect is a lightweight PHP class for detecting mobile devices (including tablets). It uses the User-Agent string combined with specific HTTP headers to detect the mobile environment.Motto: ""Every business should have a detection script to detect mobile readers."" About Mobile Detect is a lightweight PHP class for detecting mobile devices (including tablets). It uses the User-Agent string combined with specific HTTP headers to detect the mobile environment. Why Your website's content strategy is important! You need a complete toolkit to deliver an experience that is optimized, fast and relevant to your users. Mobile Detect class is a server-side detection tool that can help you with your RWD strategy, it is not a replacement for CSS3 media queries or other forms of client-side feature detection. How We're committed to make Mobile_Detect the best open-source mobile detection resource and this is why before each release we're running unit tests and research and update the detection rules on monthly basis. Who See the history of the project. Announcements JetBrains is sponsoring the project by providing licenses for PHPStorm and DataGrip. Mobile_Detect 2.x.x is only integrating new regexes, User-Agents and tests. We are focusing on new tablets only. The rest of the PRs about TVs, bots or optimizations will be closed and analyzed after 3.0.0-beta is released. Mobile_Detect 3.x.x is experimental and WIP. Install Download and include manually Use this to quickly test the demo. Download latest release Mobile_Detect.php Install as a composer package Use this method to get continuous updates. or include the dependency in the composer.json file: Demo :iphone: Live demo! Code examples Contribute Submit a PR Submit a pull request but before make sure you read how to contribute guide. Donate |Paypal| |------| |Donate :+1:| I'm currently paying for hosting and spend a lot of my family time to maintain the project and planning the future releases. I would highly appreciate any money donations that will keep the research going. Special thanks to the community :+1: for donations, JetBrains team for the continuous support and Dragos Gavrila who contributed with the logo. Modules, plugins, ports Submit new module, plugin, port :point_right: Keep Mobile_Detect.php class in a separate module and do NOT include it in your script core because of the high frequency of updates. :point_right: When including the class into your web application or module always use include_once '../path/to/Mobile_Detect.php to prevent conflicts. JavaScript mobile-detect.js - A JavaScript port of Mobile-Detect class. Made by Heinrich Goebl. Varnish Cache Varnish Mobile Detect - Drop-in varnish solution to mobile user detection based on the Mobile-Detect library. Made by willemk. mobiledetect2vcl - Python script to transform the Mobile Detect JSON database into an UA-based mobile detection VCL subroutine easily integrable in any Varnish Cache configuration. Made by Carlos Abalde. LUA mobile-detect.lua is a port of Mobile-Detect to Lua for NGINX HTTP servers. Follows closely to mobile-detect.js. Supports all methods that server-side mobile-detect.js supports. Fully unit-tested and synced with Travis CI (Build Passing badge included). Made by Mark Walters. PHP WordPress Mobile Detect for WordPress - WordPress has a built-in function (wp_is_mobile()) to detect mobile devices. There is (at least) one catch, though. It considers iPad (iPad pro, and any tablet) as a mobile. So, this 3rd party module changes the way wp_is_mobile() works with the help of Mobile Detect PHP library! Made by Pothi Kalimuthu WordPress Mobile Detect - Gives you the ability to wrap that infographic in a [notdevice][/notdevice] shortcode so at the server level WordPress will decide to show that content only if the user is NOT on a phone or tablet. Made by Jesse Friedman. mobble - provides mobile related conditional functions for your site. e.g. is_iphone(), is_mobile() and is_tablet(). Made by Scott Evans. WordPress Responsage - A small WordPress theme plugin that allows you to make your images responsive. Made by Adrian Ciaschetti. WP247 Body Classes - Add unique classes to the body tag for easy styling based on various attributes (archive, user, post, mobile) and various WordPress ""is"" functions. Mobile attributes include type of device, Operating System, Browser, etc. Examples: .is-mobile, .is-not-mobile, .is-tablet, .is-ios, .is-not-ios, .is-androidos, .is-chromebrowser. Made by wescleveland56. Adaptive Content for WordPress provides the most intuitive set of shortcodes for including/excluding content on mobile devices, tablets desktops and other more specific device parameters. This lightweight plugin lets content writers and theme authors choose when WordPress should or shouldnt show any give content item using shortcodes and quicktags or theme elements using functions. Made by AddFunc. AddFunc Mobile Detect for WordPress redirects mobile traffic to your mobile website and, basically, gives you loads of control over your mobile redirects. Made by AddFunc. Drupal Drupal Mobile Switch - The Mobile Switch Drupal module provides a automatic theme switch functionality for mobile devices, detected by Browscap or Mobile Detect. Made by Siegfried Neumann. Drupal Context Mobile Detect - This is a Drupal context module which integrates Context and PHP Mobile Detect library. Created by Artem Shymko. Drupal Mobile Detect - Lightweight mobile detect module for Drupal created by Matthew Donadio. Joomla yagendoo Joomla! Mobile Detection Plugin - Lightweight PHP plugin for Joomla! that detects a mobile browser using the Mobile Detect class. Made by yagendoo media. User Agent Detector plugin - This system plugin detects the user agent of your website visitor and sets a session variable accordingly. Based on the user agent, the plugin detects if the site is running on a desktop pc, tablet or smartphone. It can also detect if the visitor is a spider bot (search engine). Session variable that is set: ualayout. Possible values: desktop, tablet, mobile, bot. Made by @ReneKreijveld. Magento Magento helper from Optimise Web enables the use of all functions provided by Mobile Detect. Made by Kathir Vel. Magento 2 Mobile Detect Theme Change is an extension for Magento 2 that will change the theme or redirect to a different URL. Also containing a helper to check for the device type. PrestaShop PrestaShop is a free, secure and open source shopping cart platform. Mobile_Detect is included in the default package since 1.5.x. Laravel Agent is a user agent class for Laravel based on Mobile Detect with some additional functionality. Made by Jens Segers. Laravel Mobile Detect is a package that enables you to use device detection right in your Laravel Blade templates. (Utilises the well-known, constantly updated PHP mobile detection library.) Made by Barnabas Kecskes. BrowserDetect is a browser and mobile detection package, collects and wrap together the best user-agent identifiers for Laravel. Created by Varga Zsolt. Zend Framework ZF2 Mobile-Detect is a Zend Framework 2 module that provides Mobile-Detect features (Mobile_Detect class as a service, helper for views and plugin controllers). Made by neilime. ZF2 MobileDetectModule facilitates integration of a PHP MobileDetect class with some ZF2-based application. Has similar idea like the existing ZF2 Mobile-Detect module, but differs in initialization and provision routine of the actual Mobile_Detect class. Appropriate view helper and controller plugin also have different conceptions. Made by Nikola Posa. Symfony Symfony2 Mobile Detect Bundle is a bundle for detecting mobile devices, manage mobile view and redirect to the mobile and tablet version. Made by Nikolay Ivlev. Silex Mobile Detect Service Provider is a service provider to interact with Mobile detect class methods. Made by Lhassan Baazzi. Slim Framework Slim_Mobile_Detect implements Mobile_Detect lib for different responses write on Slim Framework App. ExpressionEngine EE2 Detect Mobile is a lightweight PHP plugin for EE2 that detects a mobile browser using the Mobile Detect class. Made by Gareth Davies. Yii Framework Yii Extension - Mobile detect plugin for Yii framework. Made by Alexey Salnikov. Yii Extension - Mobile detect component for Yii framework 1.x version which supports composer package manager. Made by Candas Minareci. Yii2 Device Detect - Yii2 extension for Mobile-Detect library. Made by Alexander Nestorov. CakePHP CakePHP MobileDetect is a plugin component for CakePHP 2.x. Made by Gregory Gaskill. FuelPHP Special Agent is a FuelPHP package which uses php-mobile-detect to determine whether a device is mobile or not. It overrides the Fuelphp Agent class its methods. Made by Robbie Bardjin. TYPO3 px_mobiledetect is an extension that helps to detect visitor's mobile device class (if thats tablet or mobile device like smartphone). Made by Alexander Tretyak. Other PageCache is a lightweight PHP library for full page cache, with built-in Mobile-Detect support. Made by Muhammed Mamedov. Statamic CMS Mobile Detect is a plugin. Made by Sergei Filippov of Haiku Lab. Kohana Mobile Detect is an example of implementation of Mobile_Detect class with Kohana framework. Written by Luiz Alberto S. Ribeiro. MemHT is a Free PHP CMS and Blog that permit the creation and the management online of websites with few and easy steps. Has the class included in the core. concrete5 is a CMS that is free and open source. The library is included in the core. engine7 is PHP Open Source Framework. The Mobile_Detect class is included in the engine. Zikula is a free and open-source Content Management Framework, which allows you to run impressive websites and build powerful online applications. The core uses Mobile-Detect to switch to a special Mobile theme, using jQueryMobile. UserAgentInfo is a PHP class for parsing user agent strings (HTTP_USER_AGENT). Includes mobile checks, bot checks, browser types/versions and more. Based on browscap, Mobile_Detect and ua-parser. Created for high traffic websites and fast batch processing. Made by quentin389. LJ Mobile Detect is a simple implementation of Mobile Detect for Craft CMS. Made by Lewis Jenkins. Detect Craft is a Craft CMS wrapper for the Mobile_Detect library. Made by Mikkel Rummelhoff. Grav Plugin Mobile Detect is a simple implementation of Mobile Detect for Grav CMS. Made by Dimitri Longo. Mobile_Detect module for UliCMS. Made by derUli. Perl MobileDetect.pm is a Perl module for Mobile Detect. Made by Sebastian Enger. Python pymobiledetect - Mobile detect python package. Made by Bas van Oostveen. Ruby mobile_detect.rb is a Ruby gem using the JSON data exposed by the php project and implementing a basic subset of the API (as much as can be done by the exposed data). Made by Karthik T. Go GoMobileDetect is a Go port of Mobile Detect class. Made by https://github.com/Shaked. LUA ua-lua is a small lib written in LUA providing device type detection. ua-lua is detecting mobile or tablet devices based on user-agent inside nginx daemon. Made by Frdric Robinet. .Net mobile-detect is a .Net partial port written in C#. Made by Valentin Dide. ColdFusion MobileDetect is a CFC port of the Mobile_Detect PHP Library. Made by Giancarlo Gomez. Experiments :bulb: Mobile Detect Fast (See: #474) is a class to increase the performance of Mobile Detect lib. Made by LanaGuani."
3612,"Continuous Unix commit history from 1970 until todayUnix History Repository The history and evolution of the Unix operating system is made available as a revision management repository, covering the period from its inception in 1970 as a 2.5 thousand line kernel and 26 commands, to 2018 as a widely-used 30 million line system. The 1.5GB repository contains about half a million commits and more than two thousand merges. The repository employs Git system for its storage and is hosted on GitHub. It has been created by synthesizing with custom software 24 snapshots of systems developed at Bell Labs, the University of California at Berkeley, and the 386BSD team, two legacy repositories, and the modern repository of the open source FreeBSD system. In total, about one thousand individual contributors are identified, the early ones through primary research. The data set can be used for empirical research in software engineering, information systems, and software archaeology. You can read more details about the contents, creation, and uses of this repository through this link. Two repositories are associated with the project: * unix-history-repo is a repository representing a reconstructed version of the Unix history, based on the currently available data. This repository will be often automatically regenerated from scratch, so this is not a place to make contributions. To ensure replicability its users are encouraged to fork it or archive it. * unix-history-make is a repository containing code and metadata used to build the above repository. Contributions to this repository are welcomed. Project status The project has achieved its major goal with the establishment of a continuous timeline from 1970 until today. The repository contains: snapshots of PDP-7, V1, V2, V3, V4, V5, V6, and V7 Research Edition, Unix/32V, all available BSD releases, the CSRG SCCS history, two releases of 386BSD, the 386BSD patchkit, the FreeBSD 1.0 to 1.1.5 CVS history, an import of the FreeBSD repository starting from its initial imports that led to FreeBSD 2.0, and the current FreeBSD repository. The files appear to be added in the repository in chronological order according to their modification time, and large parts of the source code have been attributed to their actual authors. Commands like git blame and git log produce the expected results. The repository contains a number of two-way merges. 3 BSD is merged from Unix/32V and Research Edition 6 Various BSD releases are merged from the development branch and a time point of BSD-SCCS FreeBSD 1.0 is merged from Net/2 BSD and 386BSD-0.1-patchkit FreeBSD 2.0 is merged from BSD 4.4/Lite1 and FreeBSD 1.1.5 Blame is apportioned appropriately. Tags and Branches The following tags or branch names mark specific releases, listed in rough chronological order. * Epoch * Research-PDP7 * Research-V16 * BSD-1 * BSD-2 * Research-V7 * Bell-32V * BSD-3, 4, 4_1_snap, 4_1c_2, 4_2, 4_3, 4_3_Reno, 4_3_Net_1, 4_3_Tahoe, 4_3_Net_2, 4_4, 4_4_Lite1, 4_4_Lite2 SCCS-END, * 386BSD-0.0, 0.1, patchkit * FreeBSD-release/1.0, 1.1, 1.1.5 * FreeBSD-release/2.0 2.0.5, 2.1.0, 2.1.5, 2.1.6, 2.1.6.1, 2.1.7, 2.2.0, 2.2.1, 2.2.2, 2.2.5, 2.2.6, 2.2.7, 2.2.8 * FreeBSD-release/3.0.0, 3.1.0, 3.2.0, 3.3.0, 3.4.0, 3.5.0 * FreeBSD-release/4.0.0 4.1.0, 4.1.1, 4.2.0, 4.3.0, 4.4.0, 4.5.0, 4.6.0, 4.6.1, 4.6.2, 4.7.0, 4.8.0, 4.9.0, 4.10.0, 4.11.0 * FreeBSD-release/5.0.0 5.1.0, 5.2.0, 5.2.1, 5.3.0, 5.4.0, 5.5.0 * FreeBSD-release/6.0.0, 6.1.0, 6.2.0, 6.3.0, 6.4.0 * FreeBSD-release/7.0.0, 7.1.0, 7.2.0, 7.3.0, 7.4.0 * FreeBSD-release/8.0.0, 8.1.0, 8.2.0, 8.3.0, 8.4.0 * FreeBSD-release/9.0.0, 9.1.0, 9.2.0, 9.3.0 * FreeBSD-release/10.0.0, 10.1.0, 10.2.0, 10.3.0, 10.4.0 * FreeBSD-release/11.0.0, 11.0.1, 11.1.0, 11.2.0, 11.3.0, 11.4.0 * FreeBSD-release/12.0.0, 12.1.0 A detailed description of the major tags is available in the file releases.md. More tags and branches are available. * The -Snapshot-Development branches denote commits that have been synthesized from a time-ordered sequence of a snapshot's files. * The -VCS-Development tags denote the point along an imported version control history branch where a particular release occurred. Cool things you can do The easiest thing you can do is to watch the repository's Gource Visualization. If you have a broadband network connection and about 1.5GB of free disk space, you can download the repository and run Git commands that go back decades. Run to get a local copy of the Unix history repository. View log across releases Running will give you commits such as the following View changes to a specific file Run to see dates on which the C compiler was modified. Annotate lines in a specific file by their version Run to see how the Unix pipe functionality evolved over the years. How you can help You can help if you were there at the time, or if you can locate a source that contains information that is currently missing. * If your current GitHub account is not linked to your past contributions, (you can search them through this page), associate your past email with your current account through your GitHub account settings. (Contact me for instructions on how to add email addresses to which you no longer have access.) * Look for errors and omissions in the files that map file paths to authors. * Look for parts of the system that have not yet been attributed in these files and propose suitable attributions. Keep in mind that attributions for parts that were developed in one place and modified elsewhere (e.g. developed at Bell Labs and modified at Berkeley) should be for the person who did the modification, not the original author. * Look for authors whose identifier starts with in the author id to name map files for Bell Labs, and Berkeley, and provide or confirm their actual login identifier. (The one used is a guess.) * Contribute a path regular expression to contributor map file (see v7.map) for 4.2BSD, 4.3BSD, 4.3BSD-Reno, 4.3BSD-Tahoe, 4.3BSD-Alpha, and Net2. * Import further branches, such as 2BSD, NetBSD, OpenBSD, and Plan 9 from Bell Labs. Re-creating the historical repository from scratch The -make repository is provided to share and document the creation process, rather than as a bullet-proof way to get consistent and repeatable results. For instance, importing the snapshots on a system that is case-insensitive (NTFS, HFS Plus with default settings) will result in a few files getting lost. Prerequisites Git Perl The Perl modules VCS::SCCS and Git::FastExport (Install with sudo cpanm VCS::SCCS Git::FastExport.) If compiling patch under GNU/Linux and library libbsd (e.g. the libbsd-dev package). Sudo (and authorization to use it to mount ISO images) Repository creation The -repo repository can be created with the following commands. Adding a single source If you want to add a new source without running the full import process, you can do the following. Prepare the source's maps and data cd to the repo directory Checkout the repo at the point where the new source will branch out Run a Perl command such as the following. Further reading Documented Unix facilities timeline edX open online course on Unix tools for data, software, and production engineering Scientific publications Diomidis Spinellis. A repository of Unix history and evolution. Empirical Software Engineering, 2017. doi:10.1007/s10664-016-9445-5. HTML, PDF Diomidis Spinellis. A repository with 44 years of Unix evolution. In MSR '15: Proceedings of the 12th Working Conference on Mining Software Repositories, pages 13-16. IEEE, 2015. Best Data Showcase Award. PDF, HTML, poster. Diomidis Spinellis and Paris Avgeriou. Evolution of the Unix system architecture: An exploratory case study. IEEE Transactions on Software Engineering, 2020. http://dx.doi.org/10.1109/TSE.2019.2892149. Warren Toomey, First Edition Unix: Its Creation and Restoration, in IEEE Annals of the History of Computing, vol. 32, no. 3, pp. 74-82, July-Sept. 2010. doi:10.1109/MAHC.2009.55. PDF Warren Toomey, The Restoration of Early UNIX Artifacts, in USENIX ATC '09: 2009 USENIX Annual Technical Conference. 2009. PDF Diomidis Spinellis, Panagiotis Louridas, and Maria Kechagia. An exploratory study on the evolution of C programming in the Unix operating system. In Qing Wang and Guenther Ruhe, editors, ESEM '15: 9th International Symposium on Empirical Software Engineering and Measurement, pages 5457. IEEE, October 2015. HTML, PDF Diomidis Spinellis, Panos Louridas, and Maria Kechagia. The evolution of C programming practices: A study of the Unix operating system 19732015. In Willem Visser and Laurie Williams, editors, ICSE '16: Proceedings of the 38th International Conference on Software Engineering, May 2016. Association for Computing Machinery. doi:10.1145/2884781.2884799. PDF, HTML Diomidis Spinellis. Documented Unix facilities over 48 years. In MSR '18: Proceedings of the 15th Conference on Mining Software Repositories. Association for Computing Machinery, May 2018. doi:10.1145/3196398.3196476 PDF, poster Research Edition Unix Manuals First Edition, November 1971 Second Edition, June 1972 Third Edition, February 1973 Fourth Edition, November 1973 Fifth Edition, June 1974 Sixth Edition, May 1975 Seventh Edition, January 1979, Volume 1 Seventh Edition, January 1979, Volume 2a Seventh Edition, January 1979, Volume 2b Wikipedia: The Free Encyclopedia History of Unix List of Unix systems List of Unix commands List of Unix daemons Research Unix Berkeley Software Distribution Unix philosophy TUHS: The Unix Heritage Society The Unix Tree Historical documents and data PDP-7 Unix restoration project First Edition Unix printout - 1972 Unix 32/V Report - 1978 Berkeley CSRG Archive CD-ROMs Studies M. Douglas McIlroy. A Research UNIX Reader: Annotated Excerpts from the Programmer's Manual, 1971-1986 Michael S. Mahoney. Unix at the Bell Labs - People Acknowledgements The following people helped with Bell Labs login identifiers. Brian W. Kernighan Doug McIlroy Arnold D. Robbins The following people helped with *BSD login identifiers. Clem Cole Era Eriksson Mary Ann Horton Warner Losh Kirk McKusick Jeremy C. Reed Ingo Schwarze Anatole Shaw The BSD SCCS import code is based on work by H. Merijn Brand Jonathan Gray Build identification Data set versioned DOI: Software versioned DOI: * Software URL: https://github.com/dspinellis/unix-history-make * Software SHA: 86383f1340e3735552b58df0a42696dbcb9dac00 * Build timestamp: 2021-01-01 11:40:51 UTC"
1746,"An iOS and macOS audio visualization framework built upon Core Audio useful for anyone doing real-time, low-latency audio processing and visualizations.A simple, intuitive audio framework for iOS and OSX. Deprecated EZAudio has recently been deprecated in favor of AudioKit. However, since some people are still forking and using EZAudio I've decided to restore the README as it was. Check out the note below. Apps Using EZAudio I'd really like to start creating a list of projects made using EZAudio. If you've used EZAudio to make something cool, whether it's an app or open source visualization or whatever, please email me at syedhali07[at]gmail.com and I'll add it to our wall of fame! To start it off: - Detour - Gorgeous location-aware audio walks - Jumpshare - Incredibly fast, real-time file sharing Features Awesome Components I've designed six audio components and two interface components to allow you to immediately get your hands dirty recording, playing, and visualizing audio data. These components simply plug into each other and build on top of the high-performance, low-latency AudioUnits API and give you an easy to use API written in Objective-C instead of pure C. EZAudioDevice A useful class for getting all the current and available inputs/output on any Apple device. The EZMicrophone and EZOutput use this to direct sound in/out from different hardware components. EZMicrophone A microphone class that provides its delegate audio data from the default device microphone with one line of code. EZOutput An output class that will playback any audio it is provided by its datasource. EZAudioFile An audio file class that reads/seeks through audio files and provides useful delegate callbacks. EZAudioPlayer A replacement for AVAudioPlayer that combines an EZAudioFile and a EZOutput to perform robust playback of any file on any piece of hardware. EZRecorder A recorder class that provides a quick and easy way to write audio files from any datasource. EZAudioPlot A Core Graphics-based audio waveform plot capable of visualizing any float array as a buffer or rolling plot. EZAudioPlotGL An OpenGL-based, GPU-accelerated audio waveform plot capable of visualizing any float array as a buffer or rolling plot. Cross Platform EZAudio was designed to work transparently across all iOS and OSX devices. This means one universal API whether you're building for Mac or iOS. For instance, under the hood an EZAudioPlot knows that it will subclass a UIView for iOS or an NSView for OSX and the EZMicrophone knows to build on top of the RemoteIO AudioUnit for iOS, but defaults to the system defaults for input and output for OSX. Examples & Docs Within this repo you'll find the examples for iOS and OSX to get you up to speed using each component and plugging them into each other. With just a few lines of code you'll be recording from the microphone, generating audio waveforms, and playing audio files like a boss. See the full Getting Started guide for an interactive look into each of components. Example Projects EZAudioCoreGraphicsWaveformExample Shows how to use the EZMicrophone and EZAudioPlot to visualize the audio data from the microphone in real-time. The waveform can be displayed as a buffer or a rolling waveform plot (traditional waveform look). EZAudioOpenGLWaveformExample Shows how to use the EZMicrophone and EZAudioPlotGL to visualize the audio data from the microphone in real-time. The drawing is using OpenGL so the performance much better for plots needing a lot of points. EZAudioPlayFileExample Shows how to use the EZAudioPlayer and EZAudioPlotGL to playback, pause, and seek through an audio file while displaying its waveform as a buffer or a rolling waveform plot. EZAudioRecordWaveformExample Shows how to use the EZMicrophone, EZRecorder, and EZAudioPlotGL to record the audio from the microphone input to a file while displaying the audio waveform of the incoming data. You can then playback the newly recorded audio file using AVFoundation and keep adding more audio data to the tail of the file. EZAudioWaveformFromFileExample Shows how to use the EZAudioFile and EZAudioPlot to animate in an audio waveform for an entire audio file. EZAudioPassThroughExample Shows how to use the EZMicrophone, EZOutput, and the EZAudioPlotGL to pass the microphone input to the output for playback while displaying the audio waveform (as a buffer or rolling plot) in real-time. EZAudioFFTExample Shows how to calculate the real-time FFT of the audio data coming from the EZMicrophone and the Accelerate framework. The audio data is plotted using two EZAudioPlots for the time and frequency displays. Documentation The official documentation for EZAudio can be found here: http://cocoadocs.org/docsets/EZAudio/1.1.4/ You can also generate the docset yourself using appledocs by running the appledocs on the EZAudio source folder. Getting Started To begin using EZAudio you must first make sure you have the proper build requirements and frameworks. Below you'll find explanations of each component and code snippets to show how to use each to perform common tasks like getting microphone data, updating audio waveform plots, reading/seeking through audio files, and performing playback. Build Requirements iOS - 6.0+ OSX - 10.8+ Frameworks iOS - Accelerate - AudioToolbox - AVFoundation - GLKit OSX - Accelerate - AudioToolbox - AudioUnit - CoreAudio - QuartzCore - OpenGL - GLKit Adding To Project You can add EZAudio to your project in a few ways: 1.) The easiest way to use EZAudio is via Cocoapods. Simply add EZAudio to your Podfile like so: pod 'EZAudio', '~> 1.1.4' Using EZAudio & The Amazing Audio Engine If you're also using the Amazing Audio Engine then use the EZAudio/Core subspec like so: pod 'EZAudio/Core', '~> 1.1.4' 2.) EZAudio now supports Carthage (thanks Andrew and Tommaso!). You can refer to Carthage's installation for a how-to guide: https://github.com/Carthage/Carthage 3.) Alternatively, you can check out the iOS/Mac examples for how to setup a project using the EZAudio project as an embedded project and utilizing the frameworks. Be sure to set your header search path to the folder containing the EZAudio source. Core Components EZAudio currently offers six audio components that encompass a wide range of functionality. In addition to the functional aspects of these components such as pulling audio data, reading/writing from files, and performing playback they also take special care to hook into the interface components to allow developers to display visual feedback (see the Interface Components below). EZAudioDevice Provides a simple interface for obtaining the current and all available inputs and output for any Apple device. For instance, the iPhone 6 has three microphones available for input, while on OSX you can choose the Built-In Microphone or any available HAL device on your system. Similarly, for iOS you can choose from a pair of headphones connected or speaker, while on OSX you can choose from the Built-In Output, any available HAL device, or Airplay. Getting Input Devices To get all the available input devices use the inputDevices class method: or to just get the currently selected input device use the currentInputDevice method: Getting Output Devices Similarly, to get all the available output devices use the outputDevices class method: or to just get the currently selected output device use the currentInputDevice method: EZMicrophone Provides access to the default device microphone in one line of code and provides delegate callbacks to receive the audio data as an AudioBufferList and float arrays. Relevant Example Projects - EZAudioCoreGraphicsWaveformExample (iOS) - EZAudioCoreGraphicsWaveformExample (OSX) - EZAudioOpenGLWaveformExample (iOS) - EZAudioOpenGLWaveformExample (OSX) - EZAudioRecordExample (iOS) - EZAudioRecordExample (OSX) - EZAudioPassThroughExample (iOS) - EZAudioPassThroughExample (OSX) - EZAudioFFTExample (iOS) - EZAudioFFTExample (OSX) Creating A Microphone Create an EZMicrophone instance by declaring a property and initializing it like so: Alternatively, you could also use the shared EZMicrophone instance and just assign its EZMicrophoneDelegate. Setting The Device The EZMicrophone uses an EZAudioDevice instance to select what specific hardware destination it will use to pull audio data. You'd use this if you wanted to change the input device like in the EZAudioCoreGraphicsWaveformExample for iOS or OSX. At any time you can change which input device is used by setting the device property: Anytime the EZMicrophone changes its device it will trigger the EZMicrophoneDelegate event: Note: For iOS this can happen automatically if the AVAudioSession changes the current device. Getting Microphone Data To tell the microphone to start fetching audio use the startFetchingAudio function. Once the EZMicrophone has started it will send the EZMicrophoneDelegate the audio back in a few ways. An array of float arrays: or the AudioBufferList representation: Pausing/Resuming The Microphone Pause or resume fetching audio at any time like so: Alternatively, you could also toggle the microphoneOn property (safe to use with Cocoa Bindings) EZOutput Provides flexible playback to the default output device by asking the EZOutputDataSource for audio data to play. Doesn't care where the buffers come from (microphone, audio file, streaming audio, etc). As of 1.0.0 the EZOutputDataSource has been simplified to have only one method to provide audio data to your EZOutput instance. Relevant Example Projects - EZAudioPlayFileExample (iOS) - EZAudioPlayFileExample (OSX) - EZAudioPassThroughExample (iOS) - EZAudioPassThroughExample (OSX) Creating An Output Create an EZOutput by declaring a property and initializing it like so: Alternatively, you could also use the shared output instance and just assign it an EZOutputDataSource if you will only have one EZOutput instance for your application. Setting The Device The EZOutput uses an EZAudioDevice instance to select what specific hardware destination it will output audio to. You'd use this if you wanted to change the output device like in the EZAudioPlayFileExample for OSX. At any time you can change which output device is used by setting the device property: Anytime the EZOutput changes its device it will trigger the EZOutputDelegate event: Playing Audio Setting The Input Format When providing audio data the EZOutputDataSource will expect you to fill out the AudioBufferList provided with whatever inputFormat that is set on the EZOutput. By default the input format is a stereo, non-interleaved, float format (see defaultInputFormat for more information). If you're dealing with a different input format (which is typically the case), just set the inputFormat property. For instance: Implementing the EZOutputDataSource An example of implementing the EZOutputDataSource is done internally in the EZAudioPlayer using an EZAudioFile to read audio from an audio file on disk like so: I created a sample project that uses the EZOutput to act as a signal generator to play sine, square, triangle, sawtooth, and noise waveforms. Here's a snippet of code to generate a sine tone: For the full implementation of the square, triangle, sawtooth, and noise functions here: (https://github.com/syedhali/SineExample/blob/master/SineExample/GeneratorViewController.m#L220-L305) Once the EZOutput has started it will send the EZOutputDelegate the audio back as float arrays for visualizing. These are converted inside the EZOutput component from whatever input format you may have provided. For instance, if you provide an interleaved, signed integer AudioStreamBasicDescription for the inputFormat property then that will be automatically converted to a stereo, non-interleaved, float format when sent back in the delegate playedAudio:... method below: An array of float arrays: Pausing/Resuming The Output Pause or resume the output component at any time like so: Chaining Audio Unit Effects Internally the EZOutput is using an AUGraph to chain together a converter, mixer, and output audio units. You can hook into this graph by subclassing EZOutput and implementing the method: This was inspired by the audio processing graph from CocoaLibSpotify (Daniel Kennett of Spotify has an excellent blog post explaining how to add an EQ to the CocoaLibSpotify AUGraph). Here's an example of how to add a delay audio unit (kAudioUnitSubType_Delay): EZAudioFile Provides simple read/seek operations, pulls waveform amplitude data, and provides the EZAudioFileDelegate to notify of any read/seek action occuring on the EZAudioFile. This can be thought of as the NSImage/UIImage equivalent of the audio world. Relevant Example Projects - EZAudioWaveformFromFileExample (iOS) - EZAudioWaveformFromFileExample (OSX) Opening An Audio File To open an audio file create a new instance of the EZAudioFile class. Getting Waveform Data The EZAudioFile allows you to quickly fetch waveform data from an audio file with as much or little detail as you'd like. Reading From An Audio File Reading audio data from a file requires you to create an AudioBufferList to hold the data. The EZAudio utility function, audioBufferList, provides a convenient way to get an allocated AudioBufferList to use. There is also a utility function, freeBufferList:, to use to free (or release) the AudioBufferList when you are done using that audio data. Note: You have to free the AudioBufferList, even in ARC. When a read occurs the EZAudioFileDelegate receives two events. An event notifying the delegate of the read audio data as float arrays: and an event notifying the delegate of the new frame position within the EZAudioFile: Seeking Through An Audio File You can seek very easily through an audio file using the EZAudioFile's seekToFrame: method. The EZAudioFile provides a totalFrames method to provide you the total amount of frames in an audio file so you can calculate a proper offset. When a seek occurs the EZAudioFileDelegate receives the seek event: EZAudioPlayer Provides a class that combines the EZAudioFile and EZOutput for file playback of all Core Audio supported formats to any hardware device. Because the EZAudioPlayer internally hooks into the EZAudioFileDelegate and EZOutputDelegate, you should implement the EZAudioPlayerDelegate to receive the playedAudio:... and updatedPosition: events. The EZAudioPlayFileExample projects for iOS and OSX shows how to use the EZAudioPlayer to play audio files, visualize the samples with an audio plot, adjust the volume, and change the output device using the EZAudioDevice class. The EZAudioPlayer primarily uses NSNotificationCenter to post notifications because often times you have one audio player and multiple UI elements that need to listen for player events to properly update. Creating An Audio Player Playing An Audio File The EZAudioPlayer uses an internal EZAudioFile to provide data to its EZOutput for output via the EZOutputDataSource. You can provide an EZAudioFile by just setting the audioFile property on the EZAudioPlayer will make a copy of the EZAudioFile at that file path url for its own use. As audio is played the EZAudioPlayerDelegate will receive the playedAudio:..., updatedPosition:..., and, if the audio file reaches the end of the file, the reachedEndOfAudioFile: events. A typical implementation of the EZAudioPlayerDelegate would be something like: Seeking You can seek through the audio file in a similar fashion as with the EZAudioFile. That is, using the seekToFrame: or currentTime property. Setting Playback Parameters Because the EZAudioPlayer wraps the EZOutput you can adjust the volume and pan parameters for playback. Getting Audio File Parameters The EZAudioPlayer wraps the EZAudioFile and provides a high level interface for pulling values like current time, duration, the frame index, total frames, etc. In addition, the EZOutput properties are also offered at a high level as well: Notifications The EZAudioPlayer provides the following notifications (as of 1.1.2): EZRecorder Provides a way to record any audio source to an audio file. This hooks into the other components quite nicely to do something like plot the audio waveform while recording to give visual feedback as to what is happening. The EZRecorderDelegate provides methods to listen to write events and a final close event on the EZRecorder (explained below). Relevant Example Projects - EZAudioRecordExample (iOS) - EZAudioRecordExample (OSX) Creating A Recorder To create an EZRecorder you must provide at least 3 things: an NSURL representing the file path of where the audio file should be written to (an existing file will be overwritten), a clientFormat representing the format in which you will be providing the audio data, and either an EZRecorderFileType or an AudioStreamBasicDescription representing the file format of the audio data on disk. Start by declaring an instance of the EZRecorder (you will have one of these per audio file written out) and initialize it using one of the two initializers from above. For instance, using the EZRecorderFileType shortcut initializer you could create an instance like so: or to configure your own custom file format, say to write out a 8000 Hz, iLBC file: Recording Some Audio Once you've initialized your EZRecorder you can append data by passing in an AudioBufferList and its buffer size like so: Responding to an EZRecorder after it has written audio data Once audio data has been successfully written with the EZRecorder it will notify the EZRecorderDelegate of the event so it can respond via: Closing An Audio File When you're recording is done be sure to call the closeAudioFile method to make sure the audio file written to disk is properly closed before you attempt to read it again. This will trigger the EZRecorder's delegate method: Interface Components EZAudio currently offers two drop in audio waveform components that help simplify the process of visualizing audio. EZAudioPlot Provides an audio waveform plot that uses CoreGraphics to perform the drawing. On iOS this is a subclass of UIView while on OSX this is a subclass of NSView. As of the 1.0.0 release, the waveforms are drawn using CALayers where compositing is done on the GPU. As a result, there have been some huge performance gains and CPU usage per real-time (i.e. 60 frames per second redrawing) plot is now about 2-3% CPU as opposed to the 20-30% we were experiencing before. Relevant Example Projects - EZAudioCoreGraphicsWaveformExample (iOS) - EZAudioCoreGraphicsWaveformExample (OSX) - EZAudioRecordExample (iOS) - EZAudioRecordExample (OSX) - EZAudioWaveformFromFileExample (iOS) - EZAudioWaveformFromFileExample (OSX) - EZAudioFFTExample (iOS) - EZAudioFFTExample (OSX) Creating An Audio Plot You can create an audio plot in the interface builder by dragging in a UIView on iOS or an NSView on OSX onto your content area. Then change the custom class of the UIView/NSView to EZAudioPlot. Alternatively, you can could create the audio plot programmatically Customizing The Audio Plot All plots offer the ability to change the background color, waveform color, plot type (buffer or rolling), toggle between filled and stroked, and toggle between mirrored and unmirrored (about the x-axis). For iOS colors are of the type UIColor while on OSX colors are of the type NSColor. IBInspectable Attributes Also, as of iOS 8 you can adjust the background color, color, gain, shouldFill, and shouldMirror parameters directly in the Interface Builder via the IBInspectable attributes: Updating The Audio Plot All plots have only one update function, updateBuffer:withBufferSize:, which expects a float array and its length. EZAudioPlotGL Provides an audio waveform plot that uses OpenGL to perform the drawing. The API this class are exactly the same as those for the EZAudioPlot above. On iOS this is a subclass of the GLKView while on OSX this is a subclass of the NSOpenGLView. In most cases this is the plot you want to use, it's GPU-accelerated, can handle lots of points while displaying 60 frames per second (the EZAudioPlot starts to choke on anything greater than 1024), and performs amazingly on all devices. The only downside is that you can only have one OpenGL plot onscreen at a time. However, you can combine OpenGL plots with Core Graphics plots in the view hierachy (see the EZAudioRecordExample for an example of how to do this). Relevant Example Projects - EZAudioOpenGLWaveformExample (iOS) - EZAudioOpenGLWaveformExample (OSX) - EZAudioPlayFileExample (iOS) - EZAudioPlayFileExample (OSX) - EZAudioRecordExample (iOS) - EZAudioRecordExample (OSX) - EZAudioPassThroughExample (iOS) - EZAudioPassThroughExample (OSX) Creating An OpenGL Audio Plot You can create an audio plot in the interface builder by dragging in a UIView on iOS or an NSView on OSX onto your content area. Then change the custom class of the UIView/NSView to EZAudioPlotGL. Alternatively, you can could create the EZAudioPlotGL programmatically Customizing The OpenGL Audio Plot All plots offer the ability to change the background color, waveform color, plot type (buffer or rolling), toggle between filled and stroked, and toggle between mirrored and unmirrored (about the x-axis). For iOS colors are of the type UIColor while on OSX colors are of the type NSColor. IBInspectable Attributes Also, as of iOS 8 you can adjust the background color, color, gain, shouldFill, and shouldMirror parameters directly in the Interface Builder via the IBInspectable attributes: Updating The OpenGL Audio Plot All plots have only one update function, updateBuffer:withBufferSize:, which expects a float array and its length. License EZAudio is available under the MIT license. See the LICENSE file for more info. Contact & Contributers Syed Haris Ali www.syedharisali.com syedhali07[at]gmail.com Acknowledgements The following people rock: - My brother, Reza Ali, for walking me through all the gritty details of OpenGL and his constant encouragement through this journey to 1.0.0. - Aure Prochazka for his amazing work on AudioKit and his encouragement to bring EZAudio to 1.0.0 - Daniel Kennett for writing this great blog post that inspired the rewrite of the EZOutput in 1.0.0. - Michael Tyson for creating the TPCircularBuffer and all his contributions to the community including the Amazing Audio Engine, Audiobus, and all the tasty pixel blog posts. - Chris Adamson and Kevin Avila for writing the amazing Learning Core Audio book. Deprecated As of today, June 13, 2016, Im officially deprecating EZAudio. Id like to thank everyone for the support over the last few years Ive been hacking on EZAudio and working to make it better. Alternatives The best alternative to EZAudio is now AudioKit. Note that The Amazing Audio Engine and The Amazing Audio Engine 2 have now both been retired as well. Any further contributions I make to iOS/macOS/tvOS audio programming will be to AudioKit. AudioKit Why? EZAudio started as a pet project of mine in 2013 in an attempt to reduce the amount of duplicate code I was writing for my own iOS/Mac audio projects. I originally just wanted to record audio from an iPhones mic and plot a waveform. This over time quickly grew into the collection of classes you may know today (EZMicrophone, EZAudioPlot, etc). I apologize for not being more active in addressing the issues and pull requests, but Im hoping you all understand Im only one person. EZAudio was solely written and maintained by me out of love during weeks of time I wasnt making any money, all while living in one of the most expensive cities in the world. Like many of you, I spend the majority of my time working full-time to sustain myself (I have bills and rent to pay too!). Im transitioning to non-audio ventures and will hopefully be able to share another cool open source project soon enough. Getting the opportunity to work on EZAudio with all of you has been an incredibly insightful experience and Im incredibly grateful to have gotten a chance to share it with all of you. Thank you. Is all of it broken? As Im writing this Im a little hesitant to say its all broken (despite all the issues filed), but Id recommend forking this repo from this point forward and using at your own risk. Ill probably be continuing to use EZAudios EZAudioPlot forrendering waveforms in my future projects, however, please dont expect any updates to this repo. Deprecated means I wont be responding to issues, EZAudio-related emails, or pushing any new changes to this repo."
2630,"Node.js middleware for handling multipart/form-data.Multer Multer is a node.js middleware for handling multipart/form-data, which is primarily used for uploading files. It is written on top of busboy for maximum efficiency. NOTE: Multer will not process any form which is not multipart (multipart/form-data). Translations This README is also available in other languages: (Chinese) (Korean) (Russian) Portugus (Portugus Brazil) Installation Usage Multer adds a body object and a file or files object to the request object. The body object contains the values of the text fields of the form, the file or files object contains the files uploaded via the form. Basic usage example: Don't forget the enctype=""multipart/form-data"" in your form. In case you need to handle a text-only multipart form, you should use the .none() method: Here's an example on how multer is used an HTML form. Take special note of the enctype=""multipart/form-data"" and name=""uploaded_file"" fields: Then in your javascript file you would add these lines to access both the file and the body. It is important that you use the name field value from the form in your upload function. This tells multer which field on the request it should look for the files in. If these fields aren't the same in the HTML form and on your server, your upload will fail: API File information Each file contains the following information: Key | Description | Note --- | --- | --- fieldname | Field name specified in the form | originalname | Name of the file on the user's computer | encoding | Encoding type of the file | mimetype | Mime type of the file | size | Size of the file in bytes | destination | The folder to which the file has been saved | DiskStorage filename | The name of the file within the destination | DiskStorage path | The full path to the uploaded file | DiskStorage buffer | A Buffer of the entire file | MemoryStorage multer(opts) Multer accepts an options object, the most basic of which is the dest property, which tells Multer where to upload the files. In case you omit the options object, the files will be kept in memory and never written to disk. By default, Multer will rename the files so as to avoid naming conflicts. The renaming function can be customized according to your needs. The following are the options that can be passed to Multer. Key | Description --- | --- dest or storage | Where to store the files fileFilter | Function to control which files are accepted limits | Limits of the uploaded data preservePath | Keep the full path of files instead of just the base name In an average web app, only dest might be required, and configured as shown in the following example. If you want more control over your uploads, you'll want to use the storage option instead of dest. Multer ships with storage engines DiskStorage and MemoryStorage; More engines are available from third parties. .single(fieldname) Accept a single file with the name fieldname. The single file will be stored in req.file. .array(fieldname[, maxCount]) Accept an array of files, all with the name fieldname. Optionally error out if more than maxCount files are uploaded. The array of files will be stored in req.files. .fields(fields) Accept a mix of files, specified by fields. An object with arrays of files will be stored in req.files. fields should be an array of objects with name and optionally a maxCount. Example: .none() Accept only text fields. If any file upload is made, error with code ""LIMIT_UNEXPECTED_FILE"" will be issued. .any() Accepts all files that comes over the wire. An array of files will be stored in req.files. WARNING: Make sure that you always handle the files that a user uploads. Never add multer as a global middleware since a malicious user could upload files to a route that you didn't anticipate. Only use this function on routes where you are handling the uploaded files. storage DiskStorage The disk storage engine gives you full control on storing files to disk. There are two options available, destination and filename. They are both functions that determine where the file should be stored. destination is used to determine within which folder the uploaded files should be stored. This can also be given as a string (e.g. '/tmp/uploads'). If no destination is given, the operating system's default directory for temporary files is used. Note: You are responsible for creating the directory when providing destination as a function. When passing a string, multer will make sure that the directory is created for you. filename is used to determine what the file should be named inside the folder. If no filename is given, each file will be given a random name that doesn't include any file extension. Note: Multer will not append any file extension for you, your function should return a filename complete with an file extension. Each function gets passed both the request (req) and some information about the file (file) to aid with the decision. Note that req.body might not have been fully populated yet. It depends on the order that the client transmits fields and files to the server. For understanding the calling convention used in the callback (needing to pass null as the first param), refer to Node.js error handling MemoryStorage The memory storage engine stores the files in memory as Buffer objects. It doesn't have any options. When using memory storage, the file info will contain a field called buffer that contains the entire file. WARNING: Uploading very large files, or relatively small files in large numbers very quickly, can cause your application to run out of memory when memory storage is used. limits An object specifying the size limits of the following optional properties. Multer passes this object into busboy directly, and the details of the properties can be found on busboy's page. The following integer values are available: Key | Description | Default --- | --- | --- fieldNameSize | Max field name size | 100 bytes fieldSize | Max field value size (in bytes) | 1MB fields | Max number of non-file fields | Infinity fileSize | For multipart forms, the max file size (in bytes) | Infinity files | For multipart forms, the max number of file fields | Infinity parts | For multipart forms, the max number of parts (fields + files) | Infinity headerPairs | For multipart forms, the max number of header key=>value pairs to parse | 2000 Specifying the limits can help protect your site against denial of service (DoS) attacks. fileFilter Set this to a function to control which files should be uploaded and which should be skipped. The function should look like this: Error handling When encountering an error, Multer will delegate the error to Express. You can display a nice error page using the standard express way. If you want to catch errors specifically from Multer, you can call the middleware function by yourself. Also, if you want to catch only the Multer errors, you can use the MulterError class that is attached to the multer object itself (e.g. err instanceof multer.MulterError). Custom storage engine For information on how to build your own storage engine, see Multer Storage Engine. License MIT"
2218,"A concise routing library for Ring/ClojureCompojure Compojure is a small routing library for Ring that allows web applications to be composed of small, independent parts. Installation Add the following dependency to your project.clj file: [compojure ""1.6.2""] Documentation Wiki API Docs Community Google Group compojure on Freenode IRC Usage This small Compojure application demonstrates creating a Ring handler from two routes: Also refer to the Getting Started page on the wiki. License Copyright 2020 James Reeves Distributed under the Eclipse Public License, the same as Clojure."
2775,"MySQL/MariaDB database management for macOSSequel Pro Sequel Pro is a fast, easy-to-use Mac database management application for working with MySQL & MariaDB databases. You can find more details on our website: sequelpro.com Build Instructions Install the latest version of Xcode Install GitHub for Mac (or SourceTree, or ) Click ""Clone in Desktop"" on the right sidebar of our GitHub page Open sequel-pro.xcodeproj Click the Run button in the toolbar If the above doesn't work, please file a bug report Contributing The best way to help the project is to use our test builds and report any issues (both bugs and missing features) in the issue tracker. If you want to get more involved, then you can comment on issues written by other people or send us a pull request. Please see our projects page. This lists the issues where we would most like your help. There are simple and difficult tasks there so new contributors should be able to get started. License Copyright (c) 2002-2019 Sequel Pro & CocoaMySQL Teams. All rights reserved. Sequel Pro is free and open source software, licensed under MIT. See LICENSE for full details."
1632,"Experimental, scalable, high performance HTTP serverLwan Web Server Lwan is a high-performance & scalable web server. The project web site contains more details. Build status | OS | Arch | Release | Debug | Static Analysis | Tests | |-------------|--------|---------|-------|-----------------|------------| | Linux | x86_64 | | | Report history | | | Linux | armv7 | | | | | | FreeBSD | x86_64 | | | | | | macOS | x86_64 | | | | | | OpenBSD 6.6 | x86_64 | | | | | Building Before installing Lwan, ensure all dependencies are installed. All of them are common dependencies found in any GNU/Linux distribution; package names will be different, but it shouldn't be difficult to search using whatever package management tool that's used by your distribution. Required dependencies CMake, at least version 2.8 ZLib Optional dependencies The build system will look for these libraries and enable/link if available. Lua 5.1 or LuaJIT 2.0 Valgrind Brotli ZSTD Alternative memory allocators can be used by passing -DUSE_ALTERNATIVE_MALLOC to CMake with the following values: ""mimalloc"" ""jemalloc"" ""tcmalloc"" ""auto"": Autodetect from the list above, falling back to libc malloc if none found To run test suite: Python (2.6+) with Requests Lua 5.1 To run benchmark: Special version of Weighttp Matplotlib To build TechEmpower benchmark suite: Client libraries for either MySQL or MariaDB SQLite 3 On non-x86 systems, libucontext will be downloaded and built alongside Lwan. Common operating system package names Minimum to build ArchLinux: pacman -S cmake zlib FreeBSD: pkg install cmake pkgconf Ubuntu 14+: apt-get update && apt-get install git cmake zlib1g-dev pkg-config macOS: brew install cmake Build all examples ArchLinux: pacman -S cmake zlib sqlite luajit libmariadbclient gperftools valgrind FreeBSD: pkg install cmake pkgconf sqlite3 lua51 Ubuntu 14+: apt-get update && apt-get install git cmake zlib1g-dev pkg-config lua5.1-dev libsqlite3-dev libmysqlclient-dev macOS: brew install cmake mysql-connector-c sqlite lua@5.1 pkg-config Build commands Clone the repository ~$ git clone git://github.com/lpereira/lwan ~$ cd lwan Create the build directory ~/lwan$ mkdir build ~/lwan$ cd build Select build type Selecting a release version (no debugging symbols, messages, enable some optimizations, etc): ~/lwan/build$ cmake .. -DCMAKE_BUILD_TYPE=Release If you'd like to enable optimizations but still use a debugger, use this instead: ~/lwan/build$ cmake .. -DCMAKE_BUILD_TYPE=RelWithDebInfo To disable optimizations and build a more debugging-friendly version: ~/lwan/build$ cmake .. -DCMAKE_BUILD_TYPE=Debug Build Lwan ~/lwan/build$ make This will generate a few binaries: src/bin/lwan/lwan: The main Lwan executable. May be executed with --help for guidance. src/bin/testrunner/testrunner: Contains code to execute the test suite. src/samples/freegeoip/freegeoip: FreeGeoIP sample implementation. Requires SQLite. src/samples/techempower/techempower: Code for the TechEmpower Web Framework benchmark. Requires SQLite and MySQL libraries. src/samples/clock/clock: Clock sample. Generates a GIF file that always shows the local time. src/bin/tools/mimegen: Builds the extension-MIME type table. Used during build process. src/bin/tools/bin2hex: Generates a C file from a binary file, suitable for use with #include. src/bin/tools/configdump: Dumps a configuration file using the configuration reader API. Remarks Passing -DCMAKE_BUILD_TYPE=Release will enable some compiler optimizations (such as LTO) and tune the code for current architecture. Please use this version when benchmarking, as the default is the Debug build, which not only logs all requests to the standard output, but does so while holding a mutex. The default build (i.e. not passing -DCMAKE_BUILD_TYPE=Release) will build a version suitable for debugging purposes. This version can be used under Valgrind (if its headers are present) and includes debugging messages that are stripped in the release version. Debugging messages are printed for each and every request. On debug builds, sanitizers can be enabled. To select which one to build Lwan with, specify one of the following options to the CMake invocation line: -DSANITIZER=ubsan selects the Undefined Behavior Sanitizer. -DSANITIZER=address selects the Address Sanitizer. -DSANITIZER=thread selects the Thread Sanitizer. Alternative memory allocators can be selected as well. Lwan currently supports TCMalloc, mimalloc, and jemalloc out of the box. To use either one of them, pass -DALTERNATIVE_MALLOC=name to the CMake invocation line, using the names provided in the ""Optional dependencies"" section. Tests ~/lwan/build$ make testsuite This will compile the testrunner program and execute regression test suite in src/scripts/testsuite.py. Benchmark ~/lwan/build$ make benchmark This will compile testrunner and execute benchmark script src/scripts/benchmark.py. Coverage Lwan can also be built with the Coverage build type by specifying -DCMAKE_BUILD_TYPE=Coverage. This enables the generate-coverage make target, which will run testrunner to prepare a test coverage report with lcov. Every commit in this repository triggers the generation of this report, and results are publicly available. Running Set up the server by editing the provided lwan.conf; the format is explained in details below. (Lwan will try to find a configuration file based in the executable name in the current directory; testrunner.conf will be used for the testrunner binary, lwan.conf for the lwan binary, and so on.) Configuration files are loaded from the current directory. If no changes are made to this file, running Lwan will serve static files located in the ./wwwroot directory. Lwan will listen on port 8080 on all interfaces. Lwan will detect the number of CPUs, will increase the maximum number of open file descriptors and generally try its best to autodetect reasonable settings for the environment it's running on. Many of these settings can be tweaked in the configuration file, but it's usually a good idea to not mess with them. Optionally, the lwan binary can be used for one-shot static file serving without any configuration file. Run it with --help for help on that. Configuration File Format Lwan uses a familiar key = value configuration file syntax. Comments are supported with the # character (similar to e.g. shell scripts, Python, and Perl). Nested sections can be created with curly brackets. Sections can be empty; in this case, curly brackets are optional. some_key_name is equivalent to some key name in configuration files (as an implementation detail, code reading configuration options will only be given the version with underscores). Values can contain environment variables. Use the syntax ${VARIABLE_NAME}. Default values can be specified with a colon (e.g. ${VARIABLE_NAME:foo}, which evaluates to ${VARIABLE_NAME} if it's set, or foo otherwise). Some examples can be found in lwan.conf and techempower.conf. Value types | Type | Description | |--------|-------------| | str | Any kind of free-form text, usually application specific | | int | Integer number. Range is application specific | | time | Time interval. See table below for units | | bool | Boolean value. See table below for valid values | Time Intervals Time fields can be specified using multipliers. Multiple can be specified, they're just added together; for instance, ""1M 1w"" specifies ""1 month and 1 week"" (37 days). The following table lists all known multipliers: | Multiplier | Description | |------------|-------------| | s | Seconds | | m | Minutes | | h | Hours | | d | Days | | w | 7-day Weeks | | M | 30-day Months | | y | 365-day Years | A number with a multiplier not in this table is ignored; a warning is issued while reading the configuration file. No spaces must exist between the number and its multiplier. Boolean Values | True Values | False Values | |-------------|--------------| | Any integer number different than 0 | 0 | | on | off | | true | false | | yes | no | Global Settings It's generally a good idea to let Lwan decide the best settings for your environment. However, not every environment is the same, and not all uses can be decided automatically, so some configuration options are provided. | Option | Type | Default | Description | |--------|------|---------|-------------| | keep_alive_timeout | time | 15 | Timeout to keep a connection alive | | quiet | bool | false | Set to true to not print any debugging messages. Only effective in release builds. | | expires | time | 1M 1w | Value of the ""Expires"" header. Default is 1 month and 1 week | | threads | int | 0 | Number of I/O threads. Default (0) is the number of online CPUs | | proxy_protocol | bool | false | Enables the PROXY protocol. Versions 1 and 2 are supported. Only enable this setting if using Lwan behind a proxy, and the proxy supports this protocol; otherwise, this allows anybody to spoof origin IP addresses | | max_post_data_size | int | 40960 | Sets the maximum number of data size for POST requests, in bytes | | max_put_data_size | int | 40960 | Sets the maximum number of data size for PUT requests, in bytes | | allow_temp_files | str | """" | Use temporary files; set to post for POST requests, put for PUT requests, or all (equivalent to setting to post put) for both.| Straitjacket Lwan can drop its privileges to a user in the system, and limit its filesystem view with a chroot. While not bulletproof, this provides a first layer of security in the case there's a bug in Lwan. In order to use this feature, declare a straitjacket section, and set some options. This requires Lwan to be executed as root. Although this section can be written anywhere in the file (as long as it is a top level declaration), if any directories are open, due to e.g. instantiating the serve_files module, Lwan will refuse to start. (This check is only performed on Linux as a safeguard for malconfiguration.) | Option | Type | Default | Description | |--------|------|---------|-------------| | user | str | NULL | Drop privileges to this user name | | chroot | str | NULL | Path to chroot() | | drop_capabilities | bool | true | Drop all capabilities with capset(2) (under Linux), or pledge(2) (under OpenBSD). | Headers If there's a need to specify custom headers for each response, one can declare a headers section in the global scope. The order which this section appears isn't important. For example, this declaration: Will both override the Server header (Server: lwan won't be sent), and set Some-Custom-Header with the value obtained from the environment variable $WITH_THIS_ENVIRONMENT_VARIABLE. Some headers can't be overridden, as that would cause issues when sending their actual values while servicing requests. These include but is not limited to: Date Expires WWW-Authenticate Connection Content-Type Transfer-Encoding All Access-Control-Allow- headers Header names are also case-insensitive (and case-preserving). Overriding SeRVeR will override the Server header, but send it the way it was written in the configuration file. Listeners In order to specify which interfaces Lwan should listen on, a listener section must be specified. Only one listener per Lwan process is accepted at the moment. The only parameter to a listener block is the interface address and the port to listen on; anything inside a listener section are instances of modules. The syntax for the listener parameter is ${ADDRESS}:${PORT}, where ${ADDRESS} can either be * (binding to all interfaces), an IPv6 address (if surrounded by square brackets), an IPv4 address, or a hostname. If systemd's socket activation is used, systemd can be specified as a parameter. Routing URLs Using Modules or Handlers In order to route URLs, Lwan matches the largest common prefix from the request URI with a set of prefixes specified in the listener section. How a request to a particular prefix will be handled depends on which handler or module has been declared in the listener section. Handlers and modules are similar internally; handlers are merely functions and hold no state, and modules holds state (named instance). Multiple instances of a module can appear in a listener section. There is no special syntax to attach a prefix to a handler or module; all the configuration parser rules apply here. Use ${NAME} ${PREFIX} to link the ${PREFIX} prefix path to either a handler named ${NAME} (if ${NAME} begins with &, as with C's ""address of"" operator), or a module named ${NAME}. Empty sections can be used here. Each module will have its specific set of options, and they're listed in the next sections. In addition to configuration options, a special authorization section can be present in the declaration of a module instance. Handlers do not take any configuration options, but may include the authorization section. A list of built-in modules can be obtained by executing Lwan with the -m command-line argument. The following is some basic documentation for the modules shipped with Lwan. File Serving The serve_files module will serve static files, and automatically create directory indices or serve pre-compressed files. It'll generally try its best to serve files in the fastest way possible according to some heuristics. | Option | Type | Default | Description | |--------|------|---------|-------------| | path | str | NULL | Path to a directory containing files to be served | | index_path | str | index.html | File name to serve as an index for a directory | | serve_precompressed_path | bool | true | If $FILE.gz exists, is smaller and newer than $FILE, and the client accepts gzip encoding, transfer it | | auto_index | bool | true | Generate a directory list automatically if no index_path file present. Otherwise, yields 404 | | auto_index_readme | bool | true | Includes the contents of README files as part of the automatically generated directory index | | directory_list_template | str | NULL | Path to a Mustache template for the directory list; by default, use an internal template | | read_ahead | int | 131702 | Maximum amount of bytes to read ahead when caching open files. A value of 0 disables readahead. Readahead is performed by a low priority thread to not block the I/O threads while file extents are being read from the filesystem. | | cache_for | time | 5s | Time to keep file metadata (size, compressed contents, open file descriptor, etc.) in cache | Lua The lua module will allow requests to be serviced by scripts written in the Lua programming language. Although the functionality provided by this module is quite spartan, it's able to run frameworks such as Sailor. Scripts can be served from files or embedded in the configuration file, and the results of loading them, the standard Lua modules, and (optionally, if using LuaJIT) optimizing the code will be cached for a while. Each I/O thread in Lwan will create an instance of a Lua VM (i.e. one lua_State struct for every I/O thread), and each Lwan coroutine will spawn a Lua thread (with lua_newthread()) per request. Because of this, Lua scripts can't use global variables, as they may be not only serviced by different threads, but the state will be available only for the amount of time specified in the cache_period configuration option. There's no need to have one instance of the Lua module for each endpoint; a single script, embedded in the configuration file or otherwise, can service many different endpoints. Scripts are supposed to implement functions with the following signature: handle_${METHOD}_${ENDPOINT}(req), where ${METHOD} can be a HTTP method (i.e. get, post, head, etc.), and ${ENDPOINT} is the desired endpoint to be handled by that function. The special ${ENDPOINT} root can be specified to act as a catchall. The req parameter points to a metatable that contains methods to obtain information from the request, or to set the response, as seen below: req:query_param(param) returns the query parameter (from the query string) with the key param, or nil if not found req:post_param(param) returns the post parameter (only for ${POST} handlers) with the key param, or nil if not found req:set_response(str) sets the response to the string str req:say(str) sends a response chunk (using chunked encoding in HTTP) req:send_event(event, str) sends an event (using server-sent events) req:cookie(param) returns the cookie named param, or nil is not found req:set_headers(tbl) sets the response headers from the table tbl; a header may be specified multiple times by using a table, rather than a string, in the table value ({'foo'={'bar', 'baz'}}); must be called before sending any response with say() or send_event() req:header(name) obtains the header from the request with the given name or nil if not found req:sleep(ms) pauses the current handler for the specified amount of milliseconds req:ws_upgrade() returns 1 if the connection could be upgraded to a WebSocket; 0 otherwise req:ws_write(str) sends str through the WebSocket-upgraded connection req:ws_read() returns a string with the contents of the last WebSocket frame, or a number indicating an status (ENOTCONN/107 on Linux if it has been disconnected; EAGAIN/11 on Linux if nothing was available; ENOMSG/42 on Linux otherwise). The return value here might change in the future for something more Lua-like. req:remote_address() returns a string with the remote IP address. req:path() returns a string with the request path. req:query_string() returns a string with the query string (empty string if no query string present). req:body() returns the request body (POST/PUT requests). Handler functions may return either nil (in which case, a 200 OK response is generated), or a number matching an HTTP status code. Attempting to return an invalid HTTP status code or anything other than a number or nil will result in a 500 Internal Server Error response being thrown. | Option | Type | Default | Description | |--------|------|---------|-------------| | default_type | str | text/plain | Default MIME-Type for responses | | script_file | str | NULL | Path to Lua script| | cache_period | time | 15s | Time to keep Lua state loaded in memory | | script | str | NULL | Inline lua script | Rewrite The rewrite module will match patterns in URLs and give the option to either redirect to another URL, or rewrite the request in a way that Lwan will handle the request as if it were made in that way originally. Forked from Lua 5.3.1, the regular expresion engine may not be as feature-packed as most general-purpose engines, but has been chosen specifically because it is a deterministic finite automaton in an attempt to make some kinds of denial of service attacks not possible. The new URL can be specified using a simple text substitution syntax, or use Lua scripts; Lua scripts will contain the same metamethods available in the req metatable provided by the Lua module, so it can be quite powerful. Each instance of the rewrite module will require a pattern and the action to execute when such pattern is matched. Patterns are evaluated in the order they appear in the configuration file, and are specified using nested sections in the configuration file. For instance, consider the following example, where two patterns are specified: This example defines two patterns, one providing a nicer URL that's hidden from the user, and another providing a different way to obtain a direct link to an image hosted on a popular image hosting service (i.e. requesting /some/base/endpoint/imgur/mp4/4kOZNYX will redirect directly to a resource in the Imgur service). The value of rewrite_as or redirect_to can be Lua scripts as well; in which case, the option expand_with_lua must be set to true, and, instead of using the simple text substitution syntax as the example above, a function named handle_rewrite(req, captures) has to be defined instead. The req parameter is documented in the Lua module section; the captures parameter is a table containing all the captures, in order. This function returns the new URL to redirect to. This module has no options by itself. Options are specified in each and every pattern. | Option | Type | Default | Description | |--------|------|---------|-------------| | rewrite_as | str | NULL | Rewrite the URL following this pattern | | redirect_to | str | NULL | Redirect to a new URL following this pattern | | expand_with_lua | bool | false | Use Lua scripts to redirect to or rewrite a request | redirect_to and rewrite_as options are mutually exclusive, and one of them must be specified at least. Redirect The redirect module will, as it says in the tin, generate a 301 Moved permanently (by default; the code can be changed, see below) response, according to the options specified in its configuration. Generally, the rewrite module should be used instead as it packs more features; however, this module serves also as an example of how to write Lwan modules (less than 100 lines of code). If the to option is not specified, it always generates a 500 Internal Server Error response. Specifying an invalid HTTP code, or a code that Lwan doesn't know about (see enum lwan_http_status), will produce a 301 Moved Permanently response. | Option | Type | Default | Description | |--------|------|---------|-------------| | to | str | NULL | The location to redirect to | | code | int | 301 | The HTTP code to perform a redirect | Response The response module will generate an artificial response of any HTTP code. In addition to also serving as an example of how to write a Lwan module, it can be used to carve out voids from other modules (e.g. generating a 405 Not Allowed response for files in /.git, if / is served with the serve_files module). If the supplied code falls outside the response codes known by Lwan, a 404 Not Found error will be sent instead. | Option | Type | Default | Description | |--------|------|---------|-------------| | code | int | 999 | A HTTP response code | Authorization Section Authorization sections can be declared in any module instance or handler, and provides a way to authorize the fulfillment of that request through the standard HTTP authorization mechanism. In order to require authorization to access a certain module instance or handler, declare an authorization section with a basic parameter, and set one of its options. | Option | Type | Default | Description | |--------|------|---------|-------------| | realm | str | Lwan | Realm for authorization. This is usually shown in the user/password UI in browsers | | password_file | str | NULL | Path for a file containing username and passwords (in clear text). The file format is the same as the configuration file format used by Lwan | Hacking Please read this section (and follow it) if you're planning on contributing to Lwan. There's nothing unexpected here; this mostly follows the rules and expectations of many other FOSS projects, but every one expects things a little bit different from one another. Coding Style Lwan tries to follow a consistent coding style throughout the project. If you're considering contributing a patch to the project, please respect this style by trying to match the style of the surrounding code. In general: global_variables_are_named_like_this, even though they tend to be rare and should be marked as static (with rare exceptions) Local variables are usually shorter, e.g. local_var, i, conn Struct names are often as short as they're descriptive. typedef for structs are rarely used in Lwan Header files should use #pragma once instead of the usual include guard hackery Functions that are used between .c files but are not APIs to be exposed to liblwan should have their prototype added to lwan-private.h Functions should be short and sweet. Exceptions may apply Public functions should be prefixed with lwan_ Public types should be prefixed with lwan_ Private functions must be static, and can be named without the lwan_ prefix Code is indented with 4 spaces; don't use tabs There's a suggested line break at column 80, but it's not enforced /* Old C-style comments are preferred */ clang-format can be used to format the source code in an acceptable way; a .clang-format file is provided Tests If modifying well-tested areas of the code (e.g. the event loop, HTTP parser, etc.), please add a new integration test and make sure that, before you send a pull request, all tests (including the new ones you've sent) are working. Tests can be added by modifying src/scripts/testsuite.py, and executed by either invoking that script directly from the source root, or executing the testsuite build target. Some tests will only work on Linux, and won't be executed on other platforms. Fuzz-testing Lwan is automatically fuzz-tested by OSS-Fuzz. To fuzz-test locally, though, one can follow the instructions to test locally. This fuzzes only the request parsing code. There are plans to add fuzzing drivers for other parts of the code, including the rewriting engine, configuration file reader, template parser, and URL routing. Exporting APIs The shared object version of liblwan on ELF targets (e.g. Linux) will use a symbol filter script to hide symbols that are considered private to the library. Please edit src/lib/liblwan.sym to add new symbols that should be exported to liblwan.so. Using Git and Pull Requests Lwan tries to maintain a source history that's as flat as possible, devoid of merge commits. This means that pull requests should be rebased on top of the current master before they can be merged; sometimes this can be done automatically by the GitHub interface, sometimes they need some manual work to fix conflicts. It is appreciated if the contributor fixes these conflicts when asked. It is advisable to push your changes to your fork on a branch-per-pull request, rather than pushing to the master branch; the reason is explained below. Please ensure that Git is configured properly with your name (it doesn't really matter if it is your legal name or a nickname, but it should be enough to credit you) and a valid email address. There's no need to add Signed-off-by lines, even though it's fine to send commits with them. If a change is requested in a pull request, you have two choices: Reply asking for clarification. Maybe the intentions were not clear enough, and whoever asked for changes didn't fully understand what you were trying to achieve Fix the issue. When fixing issues found in pull requests, please use interactive rebases to squash or fixup commits; don't add your fixes on top of your tree. Do not create another pull request just to accomodate the changes. After rewriting the history locally, force-push to your PR branch; the PR will update automatically with your changes. Rewriting the history of development branches is fine, and force-pushing them is normal and expected It is not enforced, but it is recommended to create smaller commits. How commits are split in Lwan is pretty much arbitrary, so please take a look at the commit history to get an idea on how the division should be made. Git offers a plethora of commands to achieve this result: the already mentioned interactive rebase, the -p option to git add, and git commit --amend are good examples. Commit messages should have one line of summary (~72 chars), followed by an empty line, followed by paragraphs of 80-char lines explaining the change. The paragraphs explaining the changes are usually not necessary if the summary is good enough. Try to write good commit messages. Licensing Lwan is licensed under the GNU General Public License, version 2, or (at your option), any later version. Therefore: Code must be either LGPLv2.1, GPLv2, a permissive ""copyfree"" license that is compatible with GPLv2 (e.g. MIT, BSD 3-clause), or public domain code (e.g. CC0) Although the program can be distributed and used as if it were licensed as GPLv3, its code must be compatible with GPLv2 as well; no new code can be licensed under versions of GPL newer than 2 Likewise, code licensed under licenses compatible with GPLv3 but incompatible with GPLv2 (e.g. Apache 2) are not suitable for inclusion in Lwan Even if the license does not specify that credit should be given (e.g. CC0-licensed code), please give credit to the original author for that piece of code Contrary to popular belief, it is possible to use a GPL'd piece of code on a server without having to share the code for your application. It is only when the binary of that server is shared that source must be available to whoever has that binary. Merely accessing a Lwan server through HTTP does not qualify as having access to the binary program that's running on the server When in doubt, don't take legal advice from a README file: please consult a lawyer that understands free software licensing Portability While Lwan was written originally for Linux, it has been ported to BSD systems as well. The build system will detect the supported features and build support library functions as appropriate. For instance, epoll has been implemented on top of kqueue, and Linux-only syscalls and GNU extensions have been implemented for the supported systems. This blog post explains the details and how #include_next is used. Performance It can achieve good performance, yielding about 320000 requests/second on a Core i7 laptop for requests without disk access, and without pipelining. When disk I/O is required, for files up to 16KiB, it yields about 290000 requests/second; for larger files, this drops to 185000 requests/second, which isn't too shabby either. These results, of course, with keep-alive connections, and with weighttp running on the same machine (and thus using resources that could be used for the webserver itself). Without keep-alive, these numbers drop around 6-fold. IRC Channel There is an IRC channel (#lwan) on Freenode. A standard IRC client can be used. A web IRC gateway is also available. Lwan in the wild Here's a non-definitive list of third-party stuff that uses Lwan and have been seen in the wild. Help build this list! This project uses Cython and Lwan to make it possible to write handlers in Python. An experimental version of Node.js using Lwan as its HTTP server is maintained by @raadad. The beginnings of a C++11 web framework based on Lwan written by @vileda. A more complete C++14 web framework by @matt-42 offers Lwan as one of its backends. A word ladder sample program by @sjnam. Demo. A Shodan search listing some brave souls that expose Lwan to the public internet. Some other distribution channels were made available as well: A Dockerfile is maintained by @jaxgeller, and is available from the Docker registry. A buildpack for Heroku is maintained by @bherrera, and is available from its repo. Lwan is also available as a package in Biicode. It's also available in some GNU/Linux distributions: Arch Linux Ubuntu Alpine Linux NixOS It's also available as a package for the Nanos unikernel. Lwan has been also used as a benchmark: Raphael Javaux's master thesis cites Lwan in chapter 5 (""Performance Analysis""). Lwan is used as a benchmark by the PyParallel author. Kong uses Lwan as the backend API in its benchmark. TechEmpower Framework benchmarks feature Lwan since round 10. KrakenD used Lwan for the REST API in all official benchmarks Mentions in academic journals: A dynamic predictive race detector for C/C++ programs uses Lwan as a ""real world example"". Some talks mentioning Lwan: Talk about Lwan at Polyconf16, given by @lpereira. This talk about Iron, a framework for Rust, mentions Lwan as an insane C thing. University seminar presentation about Lwan. This presentation about Sailor web framework mentions Lwan. Performance and Scale @ Istio Service Mesh, at around 7:30min, presented at KubeCon Europe 2018, mentions that Lwan is used on the server side for testing due to its performance and robustness. A multi-core Python HTTP server (much) faster than Go (spoiler: Cython) presented at PyConFR 2018 by J.-P. Smets mentions Nexedi's work on using Lwan as a backend for Python services with Cython. Not really third-party, but alas: The author's blog. The project's webpage. Lwan quotes These are some of the quotes found in the wild about Lwan. They're presented in no particular order. Contributions are appreciated: ""I read lwan's source code. Especially, the part of using coroutine was very impressive and it was more interesting than a good novel. Thank you for that."" -- @patagonia ""For the server side, we're using Lwan, which can handle 100k+ reqs/s. It's supposed to be super robust and it's working well for us."" -- @fawadkhaliq ""Insane C thing"" -- Michael Sproul ""I've never had a chance to thank you for Lwan. It inspired me a lot to develop Zewo"" -- @paulofariarl ""Let me say that lwan is a thing of beauty. I got sucked into reading the source code for pure entertainment, it's so good. high five"" -- @kwilczynski ""Nice work with Lwan! I haven't looked that carefully yet but so far I like what I saw. You definitely have the right ideas."" -- @thinkingfish ""Lwan is a work of art. Every time I read through it, I am almost always awe-struck."" -- @neurodrone ""For Round 10, Lwan has taken the crown"" -- TechEmpower ""Jeez this is amazing. Just end to end, rock solid engineering. (...) But that sells this work short."" kjeetgill ""I am only a spare time C coder myself and was surprised that I can follow the code. Nice!"" cntlzw ""Impressive all and all, even more for being written in (grokkable!) C. Nice work."" tpaschalis"
4590,"a fresh & lightweight javascript game enginemelonJS A fresh & lightweight HTML5 game engine Copyright (C) 2011 - 2021 Olivier Biot melonJS is licensed under the MIT License About melonJS melonJS is the result of our enthusiasm & experiments with Javascript, and currently features : A fresh & lightweight 2D sprite-based engine Standalone library (does not rely on anything else, except a HTML5 capable browser) Compatible with all major browsers (Chrome, Safari, Firefox, Opera, Edge) and mobile devices Fast WebGL renderer for desktop and mobile devices with fallback to Canvas rendering High DPI resolution & Canvas advanced auto scaling Web Audio support with fallback to Multi-channel HTML5 audio Lightweight physics implementation to ensure low cpu requirements Polygon (SAT) based collision algorithm for accurate detection and response Fast Broad-phase collision detection using spatial partitioning 3rd party tools support for physic body definition such as PhysicsEditor Advanced math API for Vector and Matrix Tween Effects, Transition effects Basic set of Object Entities and GUI elements included Pooling support for object recycling Basic Particle System Sprite with Animation management Standard spritesheet, single and multiple Packed Textures support 3rd party tools support for Texture Packing such as TexturePacker, Free Texture Packer, ShoeBox A state manager (to easily manage loading, menu, options, in-game state) Tiled map format version +1.0 integration for easy level design Uncompressed Plain, Base64, CSV and JSON encoded XML tilemap loading Orthogonal, Isometric and Hexagonal maps (both normal and staggered) Multiple layers (multiple background/foreground, collision and Image layers) Multiple Tileset support Tileset Transparency settings Layers Alpha settings Rectangle, Ellipse, Polygon and Polyline objects support Tiled Objects Flipped & rotated Tiles Dynamic Layer and Object/Group ordering Dynamic Entity loading Shape based Tile collision support System & Bitmap fonts Mouse and Touch device support (with mouse emulation) Device motion & accelerometer support Built-in support for 3rd party Application Wrappers such as Cordova Asynchronous publish/subscribe pattern messaging support (minPubSub) A fully customizable preloader As light as ~70kb minified & gzipped Using melonJS Basic Example Simple hello world using melonJS 8.x or higher Documentation : Online API (offline version under the docs directory) Examples For your first time using melonJS, follow these tutorials : Platformer Step by Step Tutorial. Space Invaders Step by Step Tutorial. You may find it useful to skim the overview found at the wiki Details & Usage When starting your own projects, checkout the boilerplate Download melonJS The latest build (plain and minified) with corresponding release note is available for direct download here. Alternatively, the latest version of melonJS can be installed through NPM : $ npm install melonjs If you need to import the ES6 module of melonjs : $ import * as me from ""melonjs-module.js""; Note: when using the es6 module, deprecated methods need to be manually applied, see here Or can simply be added to your html, through a content delivery network (CDN) URL, using for example : and of course the debug panel : Note: ""official"" CDN and NPM install are only available from version 7.0.0 and onwards. Building melonJS For most users, all you probably want is to use melonJS, and all you need then is just to download the latest built release to get started. The only time you should need to build melonJS is if you want to contribute to the project and start developing on it. To build your own version of melonJS you will need to install : The Node.js JavaScript runtime and the NPM package manager Once Node.js and NPM have been installed, you need to install build dependencies, by executing the following in the folder where you cloned the repository : $ [sudo] npm install Then build the melonJS source by running: $ npm run build The generated library will be available under the build directory : - melonjs.js : a plain ES5 UMD bundle - melonjs.min.js : a minified ES5 UMD bundle - melonjs-module.js : a plain ES6 module Building the documentation Similarly, you can build your own copy of the docs locally by running : $ npm run doc The generated documentation will be available in the docs directory Testing To run melonJS tests in node simply run the following: $ npm run test This will run the jasmine spec tests with the output displayed on the shell. Do note that the latest Chrome version is required, as the test unit will run the Browser in a headless mode (in case of failed tests, upgrade your browser). WIP Builds melonJS uses Travis-CI for automated testing and build uploads. The latest build artifacts can be downloaded from the melonjs-builds bucket. Questions, need help ? If you need technical support, you can contact us through the following channels : * melonJS developer forum * gitter web chat * melonJS wikipage * Discord For any other non technical related questions, feel free to also send us an email."
2259,"An Android TabLayout LibFlycoTabLayout An Android TabLayout Lib has 3 kinds of TabLayout at present. SlidingTabLayout: deeply modified from PagerSlidingTabStrip. new added attribute new added kinds of indicators new added unread msg tip new added method for convenience CommonTabLayout:unlike SlidingTabLayout's dependence on ViewPager,it is a tabLayout without dependence on ViewPager and can be used freely with other widgets together. support kinds of indicators and indicator animation support unread msg tip support icon and icon gravity. new added method for convenience SegmentTabLayout Demo Change Log v2.0.0(2016-03-01) - remove the dependence of FlycoRoundView - new added method getIconView and getTitleView v2.0.2(2016-04-23) - remove the dependence of NineOldAnimation(only support 3.0+) Gradle Attributes |name|format|description| |:---:|:---:|:---:| | tl_indicator_color | color |set indicator color | tl_indicator_height | dimension |set indicator height | tl_indicator_width | dimension |set indicator width | tl_indicator_margin_left | dimension |set indicator margin,invalid when indicator width is greater than 0. | tl_indicator_margin_top | dimension |set indicator margin,invalid when indicator width is greater than 0. | tl_indicator_margin_right | dimension |set indicator margin,invalid when indicator width is greater than 0. | tl_indicator_margin_bottom | dimension |set indicator margin,invalid when indicator width is greater than 0. | tl_indicator_corner_radius | dimension |set indicator corner radius | tl_indicator_gravity | enum |set indicator gravity TOP or BOTTOM. | tl_indicator_style | enum |set indicator style NORMAL or TRIANGLE or BLOCK | tl_underline_color | color |set underline color | tl_underline_height | dimension |set underline height | tl_underline_gravity | enum |set underline gravity TOP or BOTTOM | tl_divider_color | color |set divider color | tl_divider_width | dimension |set divider width | tl_divider_padding |dimension| set divider paddingTop and paddingBottom | tl_tab_padding |dimension| set tab paddingLeft and paddingRight | tl_tab_space_equal |boolean| set tab space equal | tl_tab_width |dimension| set tab width | tl_textsize |dimension| set text size | tl_textSelectColor |color| set text select color | tl_textUnselectColor |color| set text unselect color | tl_textBold |boolean| set text is bold | tl_iconWidth |dimension| set icon width(only for CommonTabLayout) | tl_iconHeight |dimension|set icon height(only for CommonTabLayout) | tl_iconVisible |boolean| set icon is visible(only for CommonTabLayout) | tl_iconGravity |enum| set icon gravity LEFT or TOP or RIGHT or BOTTOM(only for CommonTabLayout) | tl_iconMargin |dimension| set icon margin with text(only for CommonTabLayout) | tl_indicator_anim_enable |boolean| set indicator support animation(only for CommonTabLayout) | tl_indicator_anim_duration |integer| set indicator animation duration(only for CommonTabLayout) | tl_indicator_bounce_enable |boolean| set indicator aniamtion with bounce effect(only for CommonTabLayout) | tl_indicator_width_equal_title |boolean| set indicator width same as text(only for SlidingTabLayout) Dependence NineOldAndroids FlycoRoundView Thanks PagerSlidingTabStrip"
1018,"Impressive component library for expressive web development! Build responsive projects on the web with the first front-end component library in Metro Style. And now there are even more opportunities every day! Metro 4 Components Library Sleek, intuitive, and powerful front-end framework for faster and easier web development. Build responsive, mobile-first projects on the web with the first front-end component library in Metro Style. Explore Metro 4 docs Metro 4 is an MIT-licensed open source project. It's an independent project with its ongoing development made possible entirely thanks to the support by these awesome Backers. License and Premium Features This project licensed under the MIT license. In addition, SUPPORT PACK is available for an annual subscription on XS:CODE and for a Patreon Patrons. SUPPORT PACK includes an Extra time for priority support by email and other options. Donation on Patreon Community Contributing All contributions are welcome. Learn more about how you can contribute to this project here. Important! Before you create Pull Request, you must sign CLA! Docs Please click here for Documentation and Demo. Releases Metro 4 releases frequently. I Am create release when there are significant bug fixes, new APIs or components. The usual frequency of release of the new version is one week on Sundays. LTS Long term support of older versions of Metro 4 does not currently exist. If your current version of Metro 4 works for you, you can stay on it for as long as you'd like. If you want to make use of new features as they come in you should upgrade to a newer version. Browser Compatibility | | | | | --- | --- | --- | --- | --- | --- | Latest | Latest | Latest | 11+ | 9.1+ | Latest | Old version Metro UI CSS 3.x you can find in a repo Metro-UI-CSS-3 Metro UI CSS 2.x you can find in a repo Metro-UI-CSS-2 Metro UI CSS 0.x you can find in a repo Metro-UI-CSS-095 Documentation and Demo for V3: metroui.org.ua/v3. Documentation and Demo for V2: metroui.org.ua/v2. Documentation and Demo for V0: metroui.org.ua/v0. Thanks Thanks to all. Special thanks to all those who financially supported the project. Credits You can read about credits here 2012-2020 Copyright by Serhii Pimenov. All Rights Reserved. Created by Serhii Pimenov."
1485,"Cocos2d for iOS and OS X, built using Objective-CCocos2D-ObjC Want pure x-platform Swift? We experience rewrite in this repository. PLEASE READ BEFORE POSTING AN ISSUE! If in doubt, please post questions and comments in the forum The Official Forum This way, more users can learn from your experince. ===== Please note, that the official site has moved. Please update your bookmarks The Official Site The Official Forum Cocos2D-ObjC is a framework for building 2D games, demos, and other graphical/interactive applications for iOS, Mac and tvOS. It is based on the Cocos2D design, but instead of using Python it uses Swift and / or Objective-C. Cocos2D-ObjC is: Fast Free Lightweight Modular Easy to use Community Supported Creating New Projects For creating new projects you should use an official Cocos2D Installer. Documentation You can find the full Cocos2D documentation and user guide at our documentation page. Important: Version 3.5 is introduced. See release notes Features Scene management (workflow) Transitions between scenes Sprites and Sprite Sheets Effects: Lens, Ripple, Waves, Liquid, etc. (Served as extension) Actions (behaviours): Trasformation Actions: Move, Rotate, Scale, Fade, Tint, etc. Composable actions: Sequence, Spawn, Repeat, Reverse Ease Actions: Exp, Sin, Cubic, Elastic, etc. Misc actions: CallFunc, OrbitCamera, Follow, Tween Basic menus and buttons Integrated with Chipmunk physics engine (Served as extension) Particle system (Served as extension) Fonts: Fast font rendering using Fixed and Variable width fonts Support for .ttf fonts Tile Map support: Orthogonal, Isometric and Hexagonal (Served as extension) Parallax scrolling (Served as extension) Motion Streak (Served as extension) Render To Texture (Served as extension) Touch/Accelerometer on iOS Touch/Mouse/Keyboard on Mac Sound Engine support based on OpenAL (Served as extension) Integrated Slow motion/Fast forward Fast textures: PVR compressed and uncompressed textures Point based: RetinaDisplay mode compatible Language: Objective-C / Swift Open Source Commercial Friendly: Compatible with open and closed source projects Image assets support TVOS support App thinning support 3D touch support OpenGL ES 2.0 or Metal (iOS) / OpenGL 2.1 (Mac) based Build Requirements Mac OS X 10.9 (or newer), Xcode 7.0 (or newer) Runtime Requirements iOS 6.0 (7.0 for Swift) or newer for iOS games Snow Leopard (v10.6) or newer for Mac games Running Tests Select the test you want from Xcode Scheme chooser Then click on Xcode Product Run Forum Cocos2D-ObjC Forum Download from Github $ git clone --recursive https://github.com/cocos2d/cocos2d-objc.git $ cd cocos2d-objc"
4852,"Ruby HTML and CSS sanitizer.Sanitize Sanitize is an allowlist-based HTML and CSS sanitizer. It removes all HTML and/or CSS from a string except the elements, attributes, and properties you choose to allow. Using a simple configuration syntax, you can tell Sanitize to allow certain HTML elements, certain attributes within those elements, and even certain URL protocols within attributes that contain URLs. You can also allow specific CSS properties, @ rules, and URL protocols in elements or attributes containing CSS. Any HTML or CSS that you don't explicitly allow will be removed. Sanitize is based on Google's Gumbo HTML5 parser, which parses HTML exactly the same way modern browsers do, and Crass, which parses CSS exactly the same way modern browsers do. As long as your allowlist config only allows safe markup and CSS, even the most malformed or malicious input will be transformed into safe output. Links Home API Docs Issues Release History Online Demo Biased comparison of Ruby HTML sanitization libraries Installation Quick Start Usage Sanitize can sanitize the following types of input: HTML fragments HTML documents CSS stylesheets inside HTML <style> elements CSS properties inside HTML style attributes Standalone CSS stylesheets Standalone CSS properties However, please note that Sanitize cannot fully sanitize the contents of <math> or <svg> elements, since these elements don't follow the same parsing rules as the rest of HTML. If this is something you need, you may want to look for another solution. HTML Fragments A fragment is a snippet of HTML that doesn't contain a root-level <html> element. If you don't specify any configuration options, Sanitize will use its strictest settings by default, which means it will strip all HTML and leave only safe text behind. To keep certain elements, add them to the element allowlist. HTML Documents When sanitizing a document, the <html> element must be allowlisted. You can also set :allow_doctype to true to allow well-formed document type definitions. CSS in HTML To sanitize CSS in an HTML fragment or document, first allowlist the <style> element and/or the style attribute. Then allowlist the CSS properties, @ rules, and URL protocols you wish to allow. You can also choose whether to allow CSS comments or browser compatibility hacks. Standalone CSS Sanitize will happily clean up a standalone CSS stylesheet or property string without needing to invoke the HTML parser. Configuration In addition to the ultra-safe default settings, Sanitize comes with three other built-in configurations that you can use out of the box or adapt to meet your needs. Sanitize::Config::RESTRICTED Allows only very simple inline markup. No links, images, or block elements. Sanitize::Config::BASIC Allows a variety of markup including formatting elements, links, and lists. Images and tables are not allowed, links are limited to FTP, HTTP, HTTPS, and mailto protocols, and a rel=""nofollow"" attribute is added to all links to mitigate SEO spam. Sanitize::Config::RELAXED Allows an even wider variety of markup, including images and tables, as well as safe CSS. Links are still limited to FTP, HTTP, HTTPS, and mailto protocols, while images are limited to HTTP and HTTPS. In this mode, rel=""nofollow"" is not added to links. Custom Configuration If the built-in modes don't meet your needs, you can easily specify a custom configuration: You can also start with one of Sanitize's built-in configurations and then customize it to meet your needs. The built-in configs are deeply frozen to prevent people from modifying them (either accidentally or maliciously). To customize a built-in config, create a new copy using Sanitize::Config.merge(), like so: The example above adds the <div> and <table> elements to a copy of the existing list of elements in Sanitize::Config::BASIC. If you instead want to completely overwrite the elements array with your own, you can omit the + operation: Config Settings :add_attributes (Hash) Attributes to add to specific elements. If the attribute already exists, it will be replaced with the value specified here. Specify all element names and attributes in lowercase. :allow_comments (boolean) Whether or not to allow HTML comments. Allowing comments is strongly discouraged, since IE allows script execution within conditional comments. The default value is false. :allow_doctype (boolean) Whether or not to allow well-formed HTML doctype declarations such as """" when sanitizing a document. This setting is ignored when sanitizing fragments. The default value is false. :attributes (Hash) Attributes to allow on specific elements. Specify all element names and attributes in lowercase. If you'd like to allow certain attributes on all elements, use the symbol :all instead of an element name. To allow arbitrary HTML5 data-* attributes, use the symbol :data in place of an attribute name. :css (Hash) Hash of the following CSS config settings to be used when sanitizing CSS (either standalone or embedded in HTML). :css => :allow_comments (boolean) Whether or not to allow CSS comments. The default value is false. :css => :allow_hacks (boolean) Whether or not to allow browser compatibility hacks such as the IE * and _ hacks. These are generally harmless, but technically result in invalid CSS. The default is false. :css => :at_rules (Array or Set) Names of CSS at-rules to allow that may not have associated blocks, such as import or charset. Names should be specified in lowercase. :css => :at_rules_with_properties (Array or Set) Names of CSS at-rules to allow that may have associated blocks containing CSS properties. At-rules like font-face and page fall into this category. Names should be specified in lowercase. :css => :at_rules_with_styles (Array or Set) Names of CSS at-rules to allow that may have associated blocks containing style rules. At-rules like media and keyframes fall into this category. Names should be specified in lowercase. :css => :import_url_validator This is a Proc (or other callable object) that will be called and passed the URL specified for any @import at-rules. You can use this to limit what can be imported, for example something like the following to limit @import to Google Fonts URLs: :css => :properties (Array or Set) List of CSS property names to allow. Names should be specified in lowercase. :css => :protocols (Array or Set) URL protocols to allow in CSS URLs. Should be specified in lowercase. If you'd like to allow the use of relative URLs which don't have a protocol, include the symbol :relative in the protocol array. :elements (Array or Set) Array of HTML element names to allow. Specify all names in lowercase. Any elements not in this array will be removed. Warning: Sanitize cannot fully sanitize the contents of <math> or <svg> elements, since these elements don't follow the same parsing rules as the rest of HTML. If you add math or svg to the allowlist, you must assume that any content inside them will be allowed, even if that content would otherwise be removed by Sanitize. :parser_options (Hash) Parsing options supplied to nokogumbo. :protocols (Hash) URL protocols to allow in specific attributes. If an attribute is listed here and contains a protocol other than those specified (or if it contains no protocol at all), it will be removed. If you'd like to allow the use of relative URLs which don't have a protocol, include the symbol :relative in the protocol array: :remove_contents (boolean or Array or Set) If this is true, Sanitize will remove the contents of any non-allowlisted elements in addition to the elements themselves. By default, Sanitize leaves the safe parts of an element's contents behind when the element is removed. If this is an Array or Set of element names, then only the contents of the specified elements (when filtered) will be removed, and the contents of all other filtered elements will be left behind. The default value is %w[iframe math noembed noframes noscript plaintext script style svg xmp]. :transformers (Array or callable) Custom HTML transformer or array of custom transformers. See the Transformers section below for details. :whitespace_elements (Hash) Hash of element names which, when removed, should have their contents surrounded by whitespace to preserve readability. Each element name is a key pointing to another Hash, which provides the specific whitespace that should be inserted :before and :after the removed element's position. The :after value will only be inserted if the removed element has children, in which case it will be inserted after those children. The default elements with whitespace added before and after are: Transformers Transformers allow you to filter and modify HTML nodes using your own custom logic, on top of (or instead of) Sanitize's core filter. A transformer is any object that responds to call() (such as a lambda or proc). To use one or more transformers, pass them to the :transformers config setting. You may pass a single transformer or an array of transformers. Input Each transformer's call() method will be called once for each node in the HTML (including elements, text nodes, comments, etc.), and will receive as an argument a Hash that contains the following items: :config - The current Sanitize configuration Hash. :is_allowlisted - true if the current node has been allowlisted by a previous transformer, false otherwise. It's generally bad form to remove a node that a previous transformer has allowlisted. :node - A Nokogiri::XML::Node object representing an HTML node. The node may be an element, a text node, a comment, a CDATA node, or a document fragment. Use Nokogiri's inspection methods (element?, text?, etc.) to selectively ignore node types you aren't interested in. :node_allowlist - Set of Nokogiri::XML::Node objects in the current document that have been allowlisted by previous transformers, if any. It's generally bad form to remove a node that a previous transformer has allowlisted. :node_name - The name of the current HTML node, always lowercase (e.g. ""div"" or ""span""). For non-element nodes, the name will be something like ""text"", ""comment"", ""#cdata-section"", ""#document-fragment"", etc. Output A transformer doesn't have to return anything, but may optionally return a Hash, which may contain the following items: :node_allowlist - Array or Set of specific Nokogiri::XML::Node objects to add to the document's allowlist, bypassing the current Sanitize config. These specific nodes and all their attributes will be allowlisted, but their children will not be. If a transformer returns anything other than a Hash, the return value will be ignored. Processing Each transformer has full access to the Nokogiri::XML::Node that's passed into it and to the rest of the document via the node's document() method. Any changes made to the current node or to the document will be reflected instantly in the document and passed on to subsequently called transformers and to Sanitize itself. A transformer may even call Sanitize internally to perform custom sanitization if needed. Nodes are passed into transformers in the order in which they're traversed. Sanitize performs top-down traversal, meaning that nodes are traversed in the same order you'd read them in the HTML, starting at the top node, then its first child, and so on. Transformers have a tremendous amount of power, including the power to completely bypass Sanitize's built-in filtering. Be careful! Your safety is in your own hands. Example: Transformer to allow image URLs by domain The following example demonstrates how to remove image elements unless they use a relative URL or are hosted on a specific domain. It assumes that the <img> element and its src attribute are already allowlisted. Example: Transformer to allow YouTube video embeds The following example demonstrates how to create a transformer that will safely allow valid YouTube video embeds without having to allow other kinds of embedded content, which would be the case if you tried to do this by just allowing all <iframe> elements: License Copyright (c) 2015 Ryan Grove (ryan@wonko.com) Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the 'Software'), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED 'AS IS', WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
2550,"Paul Fords What Is Code?What Is Code? Businessweek, June 11, 2015 by Paul Ford & contributors Report an issue or suggest changes by submitting a pull request. Issues and pull requests labeled text will be reviewed by an editor, though we make no guarantees about timeliness. Changes merged into master may take a day or so to push live to production, especially on weekends. LICENSE This repository contains a variety of content; some is owned by Bloomberg Finance LP, and some is from third-parties (various Javascript libraries). The third-party content is distributed under the license provided by those parties. The Javascript content owned by Bloomberg Finance LP is distributed under the Apache 2 license; the text of this license can be found in the LICENSE file. The article text, contained in the index.html file, is licensed under the Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International license. For the full text of the license, please see the Creative Commons site."
3034,"A multi-platform library for OpenGL, OpenGL ES, Vulkan, window and inputGLFW Introduction GLFW is an Open Source, multi-platform library for OpenGL, OpenGL ES and Vulkan application development. It provides a simple, platform-independent API for creating windows, contexts and surfaces, reading input, handling events, etc. GLFW natively supports Windows, macOS and Linux and other Unix-like systems. On Linux both X11 and Wayland are supported. GLFW is licensed under the zlib/libpng license. You can download the latest stable release as source or Windows binaries, or fetch the latest branch from GitHub. Each release starting with 3.0 also has a corresponding annotated tag with source and binary archives. The documentation is available online and is included in all source and binary archives. See the release notes for new features, caveats and deprecations in the latest release. For more details see the version history. The master branch is the stable integration branch and should always compile and run on all supported platforms, although details of newly added features may change until they have been included in a release. New features and many bug fixes live in other branches until they are stable enough to merge. If you are new to GLFW, you may find the tutorial for GLFW 3 useful. If you have used GLFW 2 in the past, there is a transition guide for moving to the GLFW 3 API. Compiling GLFW GLFW itself requires only the headers and libraries for your OS and window system. It does not need the headers for any context creation API (WGL, GLX, EGL, NSGL, OSMesa) or rendering API (OpenGL, OpenGL ES, Vulkan) to enable support for them. GLFW supports compilation on Windows with Visual C++ 2010 and later, MinGW and MinGW-w64, on macOS with Clang and on Linux and other Unix-like systems with GCC and Clang. It will likely compile in other environments as well, but this is not regularly tested. There are pre-compiled Windows binaries available for all supported compilers. See the compilation guide for more information about how to compile GLFW yourself. Using GLFW See the documentation for tutorials, guides and the API reference. Contributing to GLFW See the contribution guide for more information. System requirements GLFW supports Windows XP and later and macOS 10.8 and later. Linux and other Unix-like systems running the X Window System are supported even without a desktop environment or modern extensions, although some features require a running window or clipboard manager. The OSMesa backend requires Mesa 6.3. See the compatibility guide in the documentation for more information. Dependencies GLFW itself needs only CMake 3.1 or later and the headers and libraries for your OS and window system. The examples and test programs depend on a number of tiny libraries. These are located in the deps/ directory. getopt_port for examples with command-line options TinyCThread for threaded examples glad2 for loading OpenGL and Vulkan functions linmath.h for linear algebra in examples Nuklear for test and example UI stb_image_write for writing images to disk The documentation is generated with Doxygen if CMake can find that tool. Reporting bugs Bugs are reported to our issue tracker. Please check the contribution guide for information on what to include when reporting a bug. Changelog Added GLFW_RESIZE_NWSE_CURSOR, GLFW_RESIZE_NESW_CURSOR, GLFW_RESIZE_ALL_CURSOR and GLFW_NOT_ALLOWED_CURSOR cursor shapes (#427) Added GLFW_RESIZE_EW_CURSOR alias for GLFW_HRESIZE_CURSOR (#427) Added GLFW_RESIZE_NS_CURSOR alias for GLFW_VRESIZE_CURSOR (#427) Added GLFW_POINTING_HAND_CURSOR alias for GLFW_HAND_CURSOR (#427) Added GLFW_MOUSE_PASSTHROUGH window hint for letting mouse input pass through the window (#1236,#1568) Added GLFW_FEATURE_UNAVAILABLE error for platform limitations (#1692) Added GLFW_FEATURE_UNIMPLEMENTED error for incomplete backends (#1692) Added GLFW_ANGLE_PLATFORM_TYPE init hint and GLFW_ANGLE_PLATFORM_TYPE_* values to select ANGLE backend (#1380) Added GLFW_X11_XCB_VULKAN_SURFACE init hint for selecting X11 Vulkan surface extension (#1793) Made joystick subsystem initialize at first use (#1284,#1646) Updated the minimum required CMake version to 3.1 Disabled tests and examples by default when built as a CMake subdirectory Bugfix: The CMake config-file package used an absolute path and was not relocatable (#1470) Bugfix: Video modes with a duplicate screen area were discarded (#1555,#1556) Bugfix: Compiling with -Wextra-semi caused warnings (#1440) Bugfix: Built-in mappings failed because some OEMs re-used VID/PID (#1583) Bugfix: Some extension loader headers did not prevent default OpenGL header inclusion (#1695) [Win32] Added the GLFW_WIN32_KEYBOARD_MENU window hint for enabling access to the window menu [Win32] Added a version info resource to the GLFW DLL [Win32] Disabled framebuffer transparency on Windows 7 when DWM windows are opaque (#1512) [Win32] Bugfix: GLFW_INCLUDE_VULKAN plus VK_USE_PLATFORM_WIN32_KHR caused symbol redefinition (#1524) [Win32] Bugfix: The cursor position event was emitted before its cursor enter event (#1490) [Win32] Bugfix: The window hint GLFW_MAXIMIZED did not move or resize the window (#1499) [Win32] Bugfix: Disabled cursor mode interfered with some non-client actions [Win32] Bugfix: Super key was not released after Win+V hotkey (#1622) [Win32] Bugfix: glfwGetKeyName could access out of bounds and return an invalid pointer [Win32] Bugfix: Some synthetic key events were reported as GLFW_KEY_UNKNOWN (#1623) [Win32] Bugfix: Non-BMP Unicode codepoint input was reported as UTF-16 [Win32] Bugfix: Monitor functions could return invalid values after configuration change (#1761) [Win32] Bugfix: Initialization would segfault on Windows 8 (not 8.1) (#1775) [Win32] Bugfix: Duplicate size events were not filtered (#1610) [Win32] Bugfix: Full screen windows were incorrectly resized by DPI changes (#1582) [Win32] Bugfix: GLFW_SCALE_TO_MONITOR had no effect on systems older than Windows 10 version 1703 (#1511) [Win32] Bugfix: USE_MSVC_RUNTIME_LIBRARY_DLL had no effect on CMake 3.15 or later (#1783,#1796) [Win32] Bugfix: Compilation with LLVM for Windows failed (#1807,#1824,#1874) [Cocoa] Added support for VK_EXT_metal_surface (#1619) [Cocoa] Added locating the Vulkan loader at runtime in an application bundle [Cocoa] Moved main menu creation to GLFW initialization time (#1649) [Cocoa] Changed EGLNativeWindowType from NSView to CALayer (#1169) [Cocoa] Changed F13 key to report Print Screen for cross-platform consistency (#1786) [Cocoa] Removed dependency on the CoreVideo framework [Cocoa] Bugfix: glfwSetWindowSize used a bottom-left anchor point (#1553) [Cocoa] Bugfix: Window remained on screen after destruction until event poll (#1412) [Cocoa] Bugfix: Event processing before window creation would assert (#1543) [Cocoa] Bugfix: Undecorated windows could not be iconified on recent macOS [Cocoa] Bugfix: Touching event queue from secondary thread before main thread would abort (#1649) [Cocoa] Bugfix: Non-BMP Unicode codepoint input was reported as UTF-16 (#1635) [Cocoa] Bugfix: Failing to retrieve the refresh rate of built-in displays could leak memory [Cocoa] Bugfix: Objective-C files were compiled as C with CMake 3.19 (#1787) [Cocoa] Bugfix: Duplicate video modes were not filtered out (#1830) [Cocoa] Bugfix: Menubar was not clickable on macOS 10.15+ until it lost and regained focus (#1648,#1802) [Cocoa] Bugfix: Monitor name query could segfault on macOS 11 (#1809,#1833) [Cocoa] Bugfix: The install name of the installed dylib was relative (#1504) [X11] Bugfix: The CMake files did not check for the XInput headers (#1480) [X11] Bugfix: Key names were not updated when the keyboard layout changed (#1462,#1528) [X11] Bugfix: Decorations could not be enabled after window creation (#1566) [X11] Bugfix: Content scale fallback value could be inconsistent (#1578) [X11] Bugfix: glfwMaximizeWindow had no effect on hidden windows [X11] Bugfix: Clearing GLFW_FLOATING on a hidden window caused invalid read [X11] Bugfix: Changing GLFW_FLOATING on a hidden window could silently fail [X11] Bugfix: Disabled cursor mode was interrupted by indicator windows [X11] Bugfix: Monitor physical dimensions could be reported as zero mm [X11] Bugfix: Window position events were not emitted during resizing (#1613) [X11] Bugfix: glfwFocusWindow could terminate on older WMs or without a WM [X11] Bugfix: Querying a disconnected monitor could segfault (#1602) [X11] Bugfix: IME input of CJK was broken for ""C"" locale (#1587,#1636) [X11] Bugfix: Termination would segfault if the IM had been destroyed [X11] Bugfix: Any IM started after initialization would not be detected [X11] Bugfix: Xlib errors caused by other parts of the application could be reported as GLFW errors [X11] Bugfix: A handle race condition could cause a BadWindow error (#1633) [X11] Bugfix: XKB path used keysyms instead of physical locations for non-printable keys (#1598) [X11] Bugfix: Function keys were mapped to GLFW_KEY_UNKNOWN for some layout combinaitons (#1598) [X11] Bugfix: Keys pressed simultaneously with others were not always reported (#1112,#1415,#1472,#1616) [X11] Bugfix: Some window attributes were not applied on leaving fullscreen (#1863) [Wayland] Removed support for wl_shell (#1443) [Wayland] Bugfix: The GLFW_HAND_CURSOR shape used the wrong image (#1432) [Wayland] Bugfix: CLOCK_MONOTONIC was not correctly enabled [Wayland] Bugfix: Repeated keys could be reported with NULL window (#1704) [Wayland] Bugfix: Retrieving partial framebuffer size would segfault [Wayland] Bugfix: Scrolling offsets were inverted compared to other platforms (#1463) [Wayland] Bugfix: Client-Side Decorations were destroyed in the wrong worder (#1798) [Wayland] Bugfix: Monitors physical size could report zero (#1784,#1792) [POSIX] Bugfix: CLOCK_MONOTONIC was not correctly tested for or enabled [NSGL] Removed enforcement of forward-compatible flag for core contexts [NSGL] Bugfix: GLFW_COCOA_RETINA_FRAMEBUFFER had no effect on newer macOS versions (#1442) [NSGL] Bugfix: Workaround for swap interval on 10.14 broke on 10.12 (#1483) [EGL] Added platform selection via the EGL_EXT_platform_base extension (#442) [EGL] Added ANGLE backend selection via EGL_ANGLE_platform_angle extension (#1380) Contact On glfw.org you can find the latest version of GLFW, as well as news, documentation and other information about the project. If you have questions related to the use of GLFW, we have a forum, and the #glfw IRC channel on Freenode. If you have a bug to report, a patch to submit or a feature you'd like to request, please file it in the issue tracker on GitHub. Finally, if you're interested in helping out with the development of GLFW or porting it to your favorite platform, join us on the forum, GitHub or IRC. Acknowledgements GLFW exists because people around the world donated their time and lent their skills. Bobyshev Alexander Laurent Aphecetche Matt Arsenault ashishgamedev David Avedissian Keith Bauer John Bartholomew Coku Ba Niklas Behrens Andrew Belt Nevyn Bengtsson Niklas Bergstrm Denis Bernard Doug Binks blanco Kyle Brenneman Rok Breulj Kai Burjack Martin Capitanio Nicolas Caramelli David Carlier Arturo Castro Chi-kwan Chan Ian Clarkson Micha Cicho Lambert Clara Anna Clarke Yaron Cohen-Tal Omar Cornut Andrew Corrigan Bailey Cosier Noel Cower CuriouserThing Jason Daly Jarrod Davis Olivier Delannoy Paul R. Deppe Michael Dickens Mario Dorn Wolfgang Draxinger Jonathan Dummer Ralph Eastwood Fredrik Ehnbom Robin Eklind Siavash Eliasi Felipe Ferreira Michael Fogleman Gerald Franz Mrio Freitas GeO4d Marcus Geelnard Charles Giessen Ryan C. Gordon Stephen Gowen Kovid Goyal Eloi Marn Gratacs Stefan Gustavson Jonathan Hale hdf89shfdfs Sylvain Hellegouarch Matthew Henry heromyth Lucas Hinderberger Paul Holden Warren Hu Charles Huber IntellectualKitty Aaron Jacobs Erik S. V. Jansson Toni Jovanoski Arseny Kapoulkine Cem Karan Osman Keskin Josh Kilmer Byunghoon Kim Cameron King Peter Knut Christoph Kubisch Yuri Kunde Schlesner Rokas Kupstys Konstantin Kfer Eric Larson Francis Lecavalier Jong Won Lee Robin Leffmann Glenn Lewis Shane Liesegang Anders Lindqvist Leon Linhart Marco Lizza Eyal Lotem Aaron Loucks Luflosi lukect Tristam MacDonald Hans Mackowiak Zbigniew Mandziejewicz Adam Marcus Clestin Marot Kyle McDonald David Medlock Bryce Mehring Jonathan Mercier Marcel Metz Liam Middlebrook Ave Milia Jonathan Miller Kenneth Miller Bruce Mitchener Jack Moffitt Jeff Molofee Alexander Monakov Pierre Morel Jon Morton Pierre Moulon Martins Mozeiko Julian Mller ndogxj Kristian Nielsen Kamil Nowakowski onox Denis Ovod Ozzy Andri Plsson Peoro Braden Pellett Christopher Pelloux Arturo J. Prez Vladimir Perminov Anthony Pesch Orson Peters Emmanuel Gil Peyrot Cyril Pichard Keith Pitt Stanislav Podgorskiy Konstantin Podsvirov Nathan Poirier Alexandre Pretyman Pablo Prietz przemekmirek pthom Guillaume Racicot Philip Rideout Eddie Ringle Max Risuhin Jorge Rodriguez Luca Rood Ed Ropple Aleksey Rybalkin Mikko Rytknen Riku Salminen Brandon Schaefer Sebastian Schuberth Christian Sdunek Matt Sealey Steve Sexton Arkady Shapkin Ali Sherief Yoshiki Shibukawa Dmitri Shuralyov Daniel Skorupski Bradley Smith Cliff Smolinsky Patrick Snape Erlend Sogge Heggen Julian Squires Johannes Stein Pontus Stenetorp Michael Stocker Justin Stoecker Elviss Strazdins Paul Sultana Nathan Sweet TTK-Bandit Jared Tiala Sergey Tikhomirov Arthur Tombs Ioannis Tsakpinis Samuli Tuomola Matthew Turner urraka Elias Vanderstuyft Stef Velzel Jari Vetoniemi Ricardo Vieira Nicholas Vitovitch Simon Voordouw Corentin Wallez Torsten Walluhn Patrick Walton Xo Wang Waris Jay Weisskopf Frank Wille Andy Williams Joel Winarske Richard A. Wilkes Tatsuya Yatagawa Ryogo Yoshimura Lukas Zanner Andrey Zholos Aihui Zhu Santi Zupancic Jonas dahl Lasse rni Leonard Knig All the unmentioned and anonymous contributors in the GLFW community, for bug reports, patches, feedback, testing and encouragement"
838,"JavaScript parser / mangler / compressor / beautifier toolkitUglifyJS 3 UglifyJS is a JavaScript parser, minifier, compressor and beautifier toolkit. Note: uglify-js supports JavaScript and most language features in ECMAScript. For more exotic parts of ECMAScript, process your source file with transpilers like Babel before passing onto uglify-js. uglify-js@3 has a simplified API and CLI that is not backwards compatible with uglify-js@2. Install First make sure you have installed the latest version of node.js (You may need to restart your computer after this step). From NPM for use as a command line app: npm install uglify-js -g From NPM for programmatic use: npm install uglify-js Command line usage uglifyjs [input files] [options] UglifyJS can take multiple input files. It's recommended that you pass the input files first, then pass the options. UglifyJS will parse input files in sequence and apply any compression options. The files are parsed in the same global scope, that is, a reference from a file to some variable/function declared in another file will be matched properly. If no input file is specified, UglifyJS will read from STDIN. If you wish to pass your options before the input files, separate the two with a double dash to prevent input files being used as option arguments: uglifyjs --compress --mangle -- input.js Command line options Specify --output (-o) to declare the output file. Otherwise the output goes to STDOUT. CLI source map options UglifyJS can generate a source map file, which is highly useful for debugging your compressed JavaScript. To get a source map, pass --source-map --output output.js (source map will be written out to output.js.map). Additional options: --source-map ""filename='<NAME>'"" to specify the name of the source map. The value of filename is only used to set file attribute (see the spec) in source map file. --source-map ""root='<URL>'"" to pass the URL where the original files can be found. --source-map ""names=false"" to omit symbol names if you want to reduce size of the source map file. --source-map ""url='<URL>'"" to specify the URL where the source map can be found. Otherwise UglifyJS assumes HTTP X-SourceMap is being used and will omit the //# sourceMappingURL= directive. For example: uglifyjs js/file1.js js/file2.js \ -o foo.min.js -c -m \ --source-map ""root='http://foo.com/src',url='foo.min.js.map'"" The above will compress and mangle file1.js and file2.js, will drop the output in foo.min.js and the source map in foo.min.js.map. The source mapping will refer to http://foo.com/src/js/file1.js and http://foo.com/src/js/file2.js (in fact it will list http://foo.com/src as the source map root, and the original files as js/file1.js and js/file2.js). Composed source map When you're compressing JS code that was output by a compiler such as CoffeeScript, mapping to the JS code won't be too helpful. Instead, you'd like to map back to the original code (i.e. CoffeeScript). UglifyJS has an option to take an input source map. Assuming you have a mapping from CoffeeScript compiled JS, UglifyJS can generate a map from CoffeeScript compressed JS by mapping every token in the compiled JS to its original location. To use this feature pass --source-map ""content='/path/to/input/source.map'"" or --source-map ""content=inline"" if the source map is included inline with the sources. CLI compress options You need to pass --compress (-c) to enable the compressor. Optionally you can pass a comma-separated list of compress options. Options are in the form foo=bar, or just foo (the latter implies a boolean option that you want to set true; it's effectively a shortcut for foo=true). Example: uglifyjs file.js -c toplevel,sequences=false CLI mangle options To enable the mangler you need to pass --mangle (-m). The following (comma-separated) options are supported: eval (default: false) mangle names visible in scopes where eval or with are used. reserved (default: []) when mangling is enabled but you want to prevent certain names from being mangled, you can declare those names with --mangle reserved pass a comma-separated list of names. For example: uglifyjs ... -m reserved=['$','require','exports'] to prevent the require, exports and $ names from being changed. CLI mangling property names (--mangle-props) Note: THIS WILL PROBABLY BREAK YOUR CODE. Mangling property names is a separate step, different from variable name mangling. Pass --mangle-props to enable it. It will mangle all properties in the input code with the exception of built in DOM properties and properties in core JavaScript classes. For example: Mangle all properties (except for JavaScript builtins): Mangle all properties except for reserved properties: Mangle all properties matching a regex: Combining mangle properties options: In order for this to be of any use, we avoid mangling standard JS names by default (--mangle-props builtins to override). A default exclusion file is provided in tools/domprops.json which should cover most standard JS and DOM properties defined in various browsers. Pass --mangle-props domprops to disable this feature. A regular expression can be used to define which property names should be mangled. For example, --mangle-props regex=/^_/ will only mangle property names that start with an underscore. When you compress multiple files using this option, in order for them to work together in the end we need to ensure somehow that one property gets mangled to the same name in all of them. For this, pass --name-cache filename.json and UglifyJS will maintain these mappings in a file which can then be reused. It should be initially empty. Example: Now, part1.js and part2.js will be consistent with each other in terms of mangled property names. Using the name cache is not necessary if you compress all your files in a single call to UglifyJS. Mangling unquoted names (--mangle-props keep_quoted) Using quoted property name (o[""foo""]) reserves the property name (foo) so that it is not mangled throughout the entire script even when used in an unquoted style (o.foo). Example: Debugging property name mangling You can also pass --mangle-props debug in order to mangle property names without completely obscuring them. For example the property o.foo would mangle to o._$foo$_ with this option. This allows property mangling of a large codebase while still being able to debug the code and identify where mangling is breaking things. You can also pass a custom suffix using --mangle-props debug=XYZ. This would then mangle o.foo to o._$foo$XYZ_. You can change this each time you compile a script to identify how a property got mangled. One technique is to pass a random number on every compile to simulate mangling changing with different inputs (e.g. as you update the input script with new properties), and to help identify mistakes like writing mangled keys to storage. API Reference Assuming installation via NPM, you can load UglifyJS in your application like this: There is a single high level function, minify(code, options), which will perform all minification phases in a configurable manner. By default minify() will enable the options compress and mangle. Example: You can minify more than one JavaScript file at a time by using an object for the first argument where the keys are file names and the values are source code: The toplevel option: The nameCache option: You may persist the name cache to the file system in the following way: An example of a combination of minify() options: To produce warnings: An error example: Note: unlike uglify-js@2.x, the 3.x API does not throw errors. To achieve a similar effect one could do the following: Minify options annotations pass false to ignore all comment annotations and elide them from output. Useful when, for instance, external tools incorrectly applied /*@__PURE__*/ or /*#__PURE__*/. Pass true to both compress and retain comment annotations in output to allow for further processing downstream. compress (default: {}) pass false to skip compressing entirely. Pass an object to specify custom compress options. ie8 (default: false) set to true to support IE8. keep_fnames (default: false) pass true to prevent discarding or mangling of function names. Useful for code relying on Function.prototype.name. mangle (default: true) pass false to skip mangling names, or pass an object to specify mangle options (see below). mangle.properties (default: false) a subcategory of the mangle option. Pass an object to specify custom mangle property options. nameCache (default: null) pass an empty object {} or a previously used nameCache object if you wish to cache mangled variable and property names across multiple invocations of minify(). Note: this is a read/write property. minify() will read the name cache state of this object and update it during minification so that it may be reused or externally persisted by the user. output (default: null) pass an object if you wish to specify additional output options. The defaults are optimized for best compression. parse (default: {}) pass an object if you wish to specify some additional parse options. sourceMap (default: false) pass an object if you wish to specify source map options. toplevel (default: false) set to true if you wish to enable top level variable and function name mangling and to drop unused variables and functions. v8 (default: false) enable workarounds for Chrome & Node.js bugs. warnings (default: false) pass true to return compressor warnings in result.warnings. Use the value ""verbose"" for more detailed warnings. webkit (default: false) enable workarounds for Safari/WebKit bugs. PhantomJS users should set this option to true. Minify options structure Source map options To generate a source map: Note that the source map is not saved in a file, it's just returned in result.map. The value passed for sourceMap.url is only used to set //# sourceMappingURL=out.js.map in result.code. The value of filename is only used to set file attribute (see the spec) in source map file. You can set option sourceMap.url to be ""inline"" and source map will be appended to code. You can also specify sourceRoot property to be included in source map: If you're compressing compiled JavaScript and have a source map for it, you can use sourceMap.content: If you're using the X-SourceMap header instead, you can just omit sourceMap.url. If you wish to reduce file size of the source map, set option sourceMap.names to be false and all symbol names will be omitted. Parse options bare_returns (default: false) support top level return statements html5_comments (default: true) shebang (default: true) support #!command as the first line Compress options annotations (default: true) Pass false to disable potentially dropping functions marked as ""pure"". A function call is marked as ""pure"" if a comment annotation /*@__PURE__*/ or /*#__PURE__*/ immediately precedes the call. For example: /*@__PURE__*/foo(); arguments (default: true) replace arguments[index] with function parameter name whenever possible. arrows (default: true) apply optimizations to arrow functions assignments (default: true) apply optimizations to assignment expressions awaits (default: true) apply optimizations to await expressions booleans (default: true) various optimizations for boolean context, for example !!a ? b : c a ? b : c collapse_vars (default: true) Collapse single-use non-constant variables, side effects permitting. comparisons (default: true) apply certain optimizations to binary nodes, e.g. !(a <= b) a > b, attempts to negate binary nodes, e.g. a = !b && !c && !d && !e a=!(b||c||d||e) etc. conditionals (default: true) apply optimizations for if-s and conditional expressions dead_code (default: true) remove unreachable code default_values (default: true) drop overshadowed default values directives (default: true) remove redundant or non-standard directives drop_console (default: false) Pass true to discard calls to console.* functions. If you wish to drop a specific function call such as console.info and/or retain side effects from function arguments after dropping the function call then use pure_funcs instead. drop_debugger (default: true) remove debugger; statements evaluate (default: true) Evaluate expression for shorter constant representation. Pass ""eager"" to always replace function calls whenever possible, or a positive integer to specify an upper bound for each individual evaluation in number of characters. expression (default: false) Pass true to preserve completion values from terminal statements without return, e.g. in bookmarklets. functions (default: true) convert declarations from var to function whenever possible. global_defs (default: {}) see conditional compilation hoist_exports (default: true) hoist export statements to facilitate various compress and mangle optimizations. hoist_funs (default: false) hoist function declarations hoist_props (default: true) hoist properties from constant object and array literals into regular variables subject to a set of constraints. For example: var o={p:1, q:2}; f(o.p, o.q); is converted to f(1, 2);. Note: hoist_props works best with toplevel and mangle enabled, alongside with compress option passes set to 2 or higher. hoist_vars (default: false) hoist var declarations (this is false by default because it seems to increase the size of the output in general) if_return (default: true) optimizations for if/return and if/continue imports (default: true) drop unreferenced import symbols when used with unused inline (default: true) inline calls to function with simple/return statement: false same as 0 0 disabled inlining 1 inline simple functions 2 inline functions with arguments 3 inline functions with arguments and variables true same as 3 join_vars (default: true) join consecutive var statements keep_fargs (default: false) discard unused function arguments except when unsafe to do so, e.g. code which relies on Function.prototype.length. Pass true to always retain function arguments. keep_infinity (default: false) Pass true to prevent Infinity from being compressed into 1/0, which may cause performance issues on Chrome. loops (default: true) optimizations for do, while and for loops when we can statically determine the condition. merge_vars (default: true) combine and reuse variables. negate_iife (default: true) negate ""Immediately-Called Function Expressions"" where the return value is discarded, to avoid the parens that the code generator would insert. objects (default: true) compact duplicate keys in object literals. passes (default: 1) The maximum number of times to run compress. In some cases more than one pass leads to further compressed code. Keep in mind more passes will take more time. properties (default: true) rewrite property access using the dot notation, for example foo[""bar""] foo.bar pure_funcs (default: null) You can pass an array of names and UglifyJS will assume that those functions do not produce side effects. DANGER: will not check if the name is redefined in scope. An example case here, for instance var q = Math.floor(a/b). If variable q is not used elsewhere, UglifyJS will drop it, but will still keep the Math.floor(a/b), not knowing what it does. You can pass pure_funcs: [ 'Math.floor' ] to let it know that this function won't produce any side effect, in which case the whole statement would get discarded. The current implementation adds some overhead (compression will be slower). Make sure symbols under pure_funcs are also under mangle.reserved to avoid mangling. pure_getters (default: ""strict"") If you pass true for this, UglifyJS will assume that object property access (e.g. foo.bar or foo[""bar""]) doesn't have any side effects. Specify ""strict"" to treat foo.bar as side-effect-free only when foo is certain to not throw, i.e. not null or undefined. reduce_funcs (default: true) Allows single-use functions to be inlined as function expressions when permissible allowing further optimization. Enabled by default. Option depends on reduce_vars being enabled. Some code runs faster in the Chrome V8 engine if this option is disabled. Does not negatively impact other major browsers. reduce_vars (default: true) Improve optimization on variables assigned with and used as constant values. rests (default: true) apply optimizations to rest parameters sequences (default: true) join consecutive simple statements using the comma operator. May be set to a positive integer to specify the maximum number of consecutive comma sequences that will be generated. If this option is set to true then the default sequences limit is 200. Set option to false or 0 to disable. The smallest sequences length is 2. A sequences value of 1 is grandfathered to be equivalent to true and as such means 200. On rare occasions the default sequences limit leads to very slow compress times in which case a value of 20 or less is recommended. side_effects (default: true) drop extraneous code which does not affect outcome of runtime execution. spreads (default: true) flatten spread expressions. strings (default: true) compact string concatenations. switches (default: true) de-duplicate and remove unreachable switch branches templates (default: true) compact template literals by embedding expressions and/or converting to string literals, e.g. `foo ${42}` ""foo 42"" top_retain (default: null) prevent specific toplevel functions and variables from unused removal (can be array, comma-separated, RegExp or function. Implies toplevel) toplevel (default: false) drop unreferenced functions (""funcs"") and/or variables (""vars"") in the top level scope (false by default, true to drop both unreferenced functions and variables) typeofs (default: true) Transforms typeof foo == ""undefined"" into foo === void 0. Note: recommend to set this value to false for IE10 and earlier versions due to known issues. unsafe (default: false) apply ""unsafe"" transformations (discussion below) unsafe_comps (default: false) compress expressions like a <= b assuming none of the operands can be (coerced to) NaN. unsafe_Function (default: false) compress and mangle Function(args, code) when both args and code are string literals. unsafe_math (default: false) optimize numerical expressions like 2 * x * 3 into 6 * x, which may give imprecise floating point results. unsafe_proto (default: false) optimize expressions like Array.prototype.slice.call(a) into [].slice.call(a) unsafe_regexp (default: false) enable substitutions of variables with RegExp values the same way as if they are constants. unsafe_undefined (default: false) substitute void 0 if there is a variable named undefined in scope (variable name will be mangled, typically reduced to a single character) unused (default: true) drop unreferenced functions and variables (simple direct variable assignments do not count as references unless set to ""keep_assign"") varify (default: true) convert block-scoped declaractions into var whenever safe to do so yields (default: true) apply optimizations to yield expressions Mangle options eval (default: false) Pass true to mangle names visible in scopes where eval or with are used. reserved (default: []) Pass an array of identifiers that should be excluded from mangling. Example: [""foo"", ""bar""]. toplevel (default: false) Pass true to mangle names declared in the top level scope. Examples: Mangle properties options builtins (default: false) Use true to allow the mangling of builtin DOM properties. Not recommended to override this setting. debug (default: false) Mangle names with the original name still present. Pass an empty string """" to enable, or a non-empty string to set the debug suffix. keep_quoted (default: false) Only mangle unquoted property names. regex (default: null) Pass a RegExp literal to only mangle property names matching the regular expression. reserved (default: []) Do not mangle property names listed in the reserved array. Output options The code generator tries to output shortest code possible by default. In case you want beautified output, pass --beautify (-b). Optionally you can pass additional arguments that control the code output: annotations (default: false) pass true to retain comment annotations /*@__PURE__*/ or /*#__PURE__*/, otherwise they will be discarded even if comments is set. ascii_only (default: false) escape Unicode characters in strings and regexps (affects directives with non-ascii characters becoming invalid) beautify (default: true) whether to actually beautify the output. Passing -b will set this to true, but you might need to pass -b even when you want to generate minified code, in order to specify additional arguments, so you can use -b beautify=false to override it. braces (default: false) always insert braces in if, for, do, while or with statements, even if their body is a single statement. comments (default: false) pass true or ""all"" to preserve all comments, ""some"" to preserve multi-line comments that contain @cc_on, @license, or @preserve (case-insensitive), a regular expression string (e.g. /^!/), or a function which returns boolean, e.g. galio (default: false) enable workarounds for ANT Galio bugs indent_level (default: 4) indent_start (default: 0) prefix all lines by that many spaces inline_script (default: true) escape HTML comments and the slash in occurrences of </script> in strings keep_quoted_props (default: false) when turned on, prevents stripping quotes from property names in object literals. max_line_len (default: false) maximum line length (for uglified code) preamble (default: null) when passed it must be a string and it will be prepended to the output literally. The source map will adjust for this text. Can be used to insert a comment containing licensing information, for example. preserve_line (default: false) pass true to retain line numbering on a best effort basis. quote_keys (default: false) pass true to quote all keys in literal objects quote_style (default: 0) preferred quote style for strings (affects quoted property names and directives as well): 0 prefers double quotes, switches to single quotes when there are more double quotes in the string itself. 0 is best for gzip size. 1 always use single quotes 2 always use double quotes 3 always use the original quotes semicolons (default: true) separate statements with semicolons. If you pass false then whenever possible we will use a newline instead of a semicolon, leading to more readable output of uglified code (size before gzip could be smaller; size after gzip insignificantly larger). shebang (default: true) preserve shebang #! in preamble (bash scripts) width (default: 80) only takes effect when beautification is on, this specifies an (orientative) line width that the beautifier will try to obey. It refers to the width of the line text (excluding indentation). It doesn't work very well currently, but it does make the code generated by UglifyJS more readable. wrap_iife (default: false) pass true to wrap immediately invoked function expressions. See #640 for more details. Miscellaneous Keeping copyright notices or other comments You can pass --comments to retain certain comments in the output. By default it will keep JSDoc-style comments that contain ""@preserve"", ""@license"" or ""@cc_on"" (conditional compilation for IE). You can pass --comments all to keep all the comments, or a valid JavaScript regexp to keep only comments that match this regexp. For example --comments /^!/ will keep comments like /*! Copyright Notice */. Note, however, that there might be situations where comments are lost. For example: Even though it has ""@preserve"", the comment will be lost because the inner function g (which is the AST node to which the comment is attached to) is discarded by the compressor as not referenced. The safest comments where to place copyright information (or other info that needs to be kept in the output) are comments attached to toplevel nodes. The unsafe compress option It enables some transformations that might break code logic in certain contrived cases, but should be fine for most code. You might want to try it on your own code, it should reduce the minified size. Here's what happens when this flag is on: new Array(1, 2, 3) or Array(1, 2, 3) [ 1, 2, 3 ] new Object() {} String(exp) or exp.toString() """" + exp new Object/RegExp/Function/Error/Array (...) we discard the new Conditional compilation You can use the --define (-d) switch in order to declare global variables that UglifyJS will assume to be constants (unless defined in scope). For example if you pass --define DEBUG=false then, coupled with dead code removal UglifyJS will discard the following from the output: You can specify nested constants in the form of --define env.DEBUG=false. UglifyJS will warn about the condition being always false and about dropping unreachable code; for now there is no option to turn off only this specific warning, you can pass warnings=false to turn off all warnings. Another way of doing that is to declare your globals as constants in a separate file and include it into the build. For example you can have a build/defines.js file with the following: and build your code like this: uglifyjs build/defines.js js/foo.js js/bar.js... -c UglifyJS will notice the constants and, since they cannot be altered, it will evaluate references to them to the value itself and drop unreachable code as usual. The build will contain the const declarations if you use them. If you are targeting < ES6 environments which does not support const, using var with reduce_vars (enabled by default) should suffice. Conditional compilation API You can also use conditional compilation via the programmatic API. With the difference that the property name is global_defs and is a compressor property: To replace an identifier with an arbitrary non-constant expression it is necessary to prefix the global_defs key with ""@"" to instruct UglifyJS to parse the value as an expression: Otherwise it would be replaced as string literal: Using native Uglify AST with minify() Working with Uglify AST Transversal and transformation of the native AST can be performed through TreeWalker and TreeTransformer respectively. ESTree / SpiderMonkey AST UglifyJS has its own abstract syntax tree format; for practical reasons we can't easily change to using the SpiderMonkey AST internally. However, UglifyJS now has a converter which can import a SpiderMonkey AST. For example Acorn is a super-fast parser that produces a SpiderMonkey AST. It has a small CLI utility that parses one file and dumps the AST in JSON on the standard output. To use UglifyJS to mangle and compress that: acorn file.js | uglifyjs -p spidermonkey -m -c The -p spidermonkey option tells UglifyJS that all input files are not JavaScript, but JS code described in SpiderMonkey AST in JSON. Therefore we don't use our own parser in this case, but just transform that AST into our internal AST. Use Acorn for parsing More for fun, I added the -p acorn option which will use Acorn to do all the parsing. If you pass this option, UglifyJS will require(""acorn""). Acorn is really fast (e.g. 250ms instead of 380ms on some 650K code), but converting the SpiderMonkey tree that Acorn produces takes another 150ms so in total it's a bit more than just using UglifyJS's own parser. Uglify Fast Minify Mode It's not well known, but whitespace removal and symbol mangling accounts for 95% of the size reduction in minified code for most JavaScript - not elaborate code transforms. One can simply disable compress to speed up Uglify builds by 3 to 5 times. | d3.js | minify size | gzip size | minify time (seconds) | | --- | ---: | ---: | ---: | | original | 511,371 | 119,932 | - | | uglify-js@3.13.0 mangle=false, compress=false | 363,988 | 95,695 | 0.56 | | uglify-js@3.13.0 mangle=true, compress=false | 253,305 | 81,281 | 0.99 | | uglify-js@3.13.0 mangle=true, compress=true | 244,436 | 79,854 | 5.30 | To enable fast minify mode from the CLI use: To enable fast minify mode with the API use: Source maps and debugging Various compress transforms that simplify, rearrange, inline and remove code are known to have an adverse effect on debugging with source maps. This is expected as code is optimized and mappings are often simply not possible as some code no longer exists. For highest fidelity in source map debugging disable the Uglify compress option and just use mangle. Compiler assumptions To allow for better optimizations, the compiler makes various assumptions: The code does not rely on preserving its runtime performance characteristics. Typically uglified code will run faster due to less instructions and easier inlining, but may be slower on rare occasions for a specific platform, e.g. see reduce_funcs. .toString() and .valueOf() don't have side effects, and for built-in objects they have not been overridden. undefined, NaN and Infinity have not been externally redefined. arguments.callee, arguments.caller and Function.prototype.caller are not used. The code doesn't expect the contents of Function.prototype.toString() or Error.prototype.stack to be anything in particular. Getting and setting properties on a plain object does not cause other side effects (using .watch() or Proxy). Object properties can be added, removed and modified (not prevented with Object.defineProperty(), Object.defineProperties(), Object.freeze(), Object.preventExtensions() or Object.seal()). Earlier versions of JavaScript will throw SyntaxError with the following: UglifyJS may modify the input which in turn may suppress those errors. - Iteration order of keys over an object which contains spread syntax in later versions of Chrome and Node.js may be altered. - When toplevel is enabled, UglifyJS effectively assumes input code is wrapped within function(){ ... }, thus forbids aliasing of declared global variables: Use of arguments alongside destructuring as function parameters, e.g. function({}, arguments) {} will result in SyntaxError in earlier versions of Chrome and Node.js - UglifyJS may modify the input which in turn may suppress those errors. Earlier versions of Chrome and Node.js will throw ReferenceError with the following: UglifyJS may modify the input which in turn may suppress those errors. - Later versions of JavaScript will throw SyntaxError with the following: UglifyJS may modify the input which in turn may suppress those errors. - Later versions of JavaScript will throw SyntaxError with the following: UglifyJS may modify the input which in turn may suppress those errors. - Some versions of Chrome and Node.js will throw ReferenceError with the following: UglifyJS may modify the input which in turn may suppress those errors. - Some arithmetic operations with BigInt may throw TypeError: UglifyJS may modify the input which in turn may suppress those errors. - Some versions of JavaScript will throw SyntaxError with the following: UglifyJS may modify the input which in turn may suppress those errors. - Some versions of JavaScript will throw SyntaxError with the following: UglifyJS may modify the input which in turn may suppress those errors. - Some versions of Chrome and Node.js will give incorrect results with the following: UglifyJS may modify the input which in turn may suppress those errors. - Later versions of JavaScript will throw SyntaxError with the following: UglifyJS may modify the input which in turn may suppress those errors. - Later versions of JavaScript will throw SyntaxError with the following: UglifyJS may modify the input which in turn may suppress those errors."
3557,"Nomad is an easy-to-use, flexible, and performant workload orchestrator that can deploy a mix of microservice, batch, containerized, and non-containerized applications. Nomad is easy to operate and scale and has native Consul and Vault integrations.Nomad Nomad is a simple and flexible workload orchestrator to deploy and manage containers (docker, podman), non-containerized applications (executable, Java), and virtual machines (qemu) across on-prem and clouds at scale. Nomad is supported on Linux, Windows, and macOS. A commercial version of Nomad, Nomad Enterprise, is also available. Website: https://nomadproject.io Tutorials: HashiCorp Learn Forum: Discuss Mailing List: Google Groups Gitter: hashicorp-nomad Nomad provides several key features: Deploy Containers and Legacy Applications: Nomads flexibility as an orchestrator enables an organization to run containers, legacy, and batch applications together on the same infrastructure. Nomad brings core orchestration benefits to legacy applications without needing to containerize via pluggable task drivers. Simple & Reliable: Nomad runs as a single binary and is entirely self contained - combining resource management and scheduling into a single system. Nomad does not require any external services for storage or coordination. Nomad automatically handles application, node, and driver failures. Nomad is distributed and resilient, using leader election and state replication to provide high availability in the event of failures. Device Plugins & GPU Support: Nomad offers built-in support for GPU workloads such as machine learning (ML) and artificial intelligence (AI). Nomad uses device plugins to automatically detect and utilize resources from hardware devices such as GPU, FPGAs, and TPUs. Federation for Multi-Region, Multi-Cloud: Nomad was designed to support infrastructure at a global scale. Nomad supports federation out-of-the-box and can deploy applications across multiple regions and clouds. Proven Scalability: Nomad is optimistically concurrent, which increases throughput and reduces latency for workloads. Nomad has been proven to scale to clusters of 10K+ nodes in real-world production environments. HashiCorp Ecosystem: Nomad integrates seamlessly with Terraform, Consul, Vault for provisioning, service discovery, and secrets management. Quick Start Testing See Learn: Getting Started for instructions on setting up a local Nomad cluster for non-production use. Optionally, find Terraform manifests for bringing up a development Nomad cluster on a public cloud in the terraform directory. Production See Learn: Nomad Reference Architecture for recommended practices and a reference architecture for production deployments. Documentation Full, comprehensive documentation is available on the Nomad website: https://www.nomadproject.io/docs Guides are available on HashiCorp Learn. Contributing See the contributing directory for more developer documentation."
655,"Terraform enables you to safely and predictably create, change, and improve infrastructure. It is an open source tool that codifies APIs into declarative configuration files that can be shared amongst team members, treated as code, edited, reviewed, and versioned.Terraform Website: https://www.terraform.io Forums: HashiCorp Discuss Documentation: https://www.terraform.io/docs/ Tutorials: HashiCorp's Learn Platform Certification Exam: HashiCorp Certified: Terraform Associate Terraform is a tool for building, changing, and versioning infrastructure safely and efficiently. Terraform can manage existing and popular service providers as well as custom in-house solutions. The key features of Terraform are: Infrastructure as Code: Infrastructure is described using a high-level configuration syntax. This allows a blueprint of your datacenter to be versioned and treated as you would any other code. Additionally, infrastructure can be shared and re-used. Execution Plans: Terraform has a ""planning"" step where it generates an execution plan. The execution plan shows what Terraform will do when you call apply. This lets you avoid any surprises when Terraform manipulates infrastructure. Resource Graph: Terraform builds a graph of all your resources, and parallelizes the creation and modification of any non-dependent resources. Because of this, Terraform builds infrastructure as efficiently as possible, and operators get insight into dependencies in their infrastructure. Change Automation: Complex changesets can be applied to your infrastructure with minimal human interaction. With the previously mentioned execution plan and resource graph, you know exactly what Terraform will change and in what order, avoiding many possible human errors. For more information, see the introduction section of the Terraform website. Getting Started & Documentation Documentation is available on the Terraform website: - Intro - Docs If you're new to Terraform and want to get started creating infrastructure, please check out our Getting Started guides on HashiCorp's learning platform. There are also additional guides to continue your learning. Show off your Terraform knowledge by passing a certification exam. Visit the certification page for information about exams and find study materials on HashiCorp's learning platform. Developing Terraform This repository contains only Terraform core, which includes the command line interface and the main graph engine. Providers are implemented as plugins, and Terraform can automatically download providers that are published on the Terraform Registry. HashiCorp develops some providers, and others are developed by other organizations. For more information, see Extending Terraform. To learn more about compiling Terraform and contributing suggested changes, please refer to the contributing guide. To learn more about how we handle bug reports, please read the bug triage guide. License Mozilla Public License v2.0"
3889,":iphone: React Native Package ManagerDear friends, Last November me (@Kureev) and Mike (@grabbou) started RNPM. We aimed to bring you a better developer experience and bridge the tooling gap we had back then. Now, as you may know, RNPM is merged into React Native core. It means that from now on you don't need to install a third-party software to use your favorite linking functionality (just use a react-native cli). We'd like to say a big ""Thank you!"" to everybody who supported us, filed new issues, composed PRs and helped us to review them. Now, when RNPM is a part of React Native, we're going to seal this repository and keep working on React Native tooling inside the core. That said, I kindly ask you to file all new issues / prs in react-native repo and cc us. This repo (and other rnpm plugins) will be a available for a few more months in a read-only mode. With love, Alexey Kureev and Micha Grabowski React Native Package Manager built to ease your daily React Native development. Inspired by CocoaPods, fastlane and react-native link it acts as your best friend and guides you through the native unknowns. It aims to work with almost all packages available with no extra configuration required. RNPM should always be run in projects that use version control to ensure any changes made can be easily reverted Requirements node >= 4.1 Getting started Installation Running Installing dependency: If you want to install a dependency and link it in one run: Linking dependency: If you already have some installed (but not linked) modules, run: In the case you want to link only one dependency, you can specify its name as an argument: Rationale Why? Tooling is important. We all know this. One of the biggest advantages of native iOS development is Xcode and its great tools. Unfortunately, the process of adding native dependencies to React Native projects is far from perfect and our aim is to make it fun again. React Native Package Manager provides you with (soon) multiple actions to help you with daily development, including automatic app store releases, over-the-air integration with AppHub and react-native-playground shares. But hey, we are tired of tools and 9000+ .rc files So are we. That's why we have spent great amount of work on getting configuration done right. Our packager automatically scans your source directory and dependencies you are working with. This approach allows it to link all the things without supplying any extra configuration. It detects Android package names, import paths, gradle location - and for iOS - it works with any code structure you have ever came up with. And don't worry - in case it fails, you can always add rnpm object to your package.json - our npm in a name is not a mistake! We embrace existing ecosystem and integrate with the present tooling for maximum developer experience. Available commands rnpm link name Automatically updates your project by linking all dependencies for Android (if present) and for iOS (if present). It's a great fit to your postinstall hook to always make sure you are linked. You can supply optional name argument to link only one dependency, e.g. Source: https://github.com/rnpm/rnpm-plugin-link rnpm install name Automatically installs the given package and links it to your project. It's equivalent to running the previous example. It's just instead of running two commands, you can now just: Source: https://github.com/rnpm/rnpm-plugin-install Advanced usage If you're authoring an awesome react-native library with custom assets, you probably need an additional step after linking - copying assets to the application folder. Well, that's not complicated: just add rnpm section in your package.json file: We'll copy your assets carefully with love for Android :heart: For iOS, we will add files to Resources group and update Info.plist so fonts are available for you to use straight away! Plugins As of version 1.1.0, rnpm supports plugin system. It allows you to write your own / use third-party commands to make your rnpm sharpened for specific purposes. Installing plugins In order to install 3rd party plugin simply run below from your project directory: Command exported by installed plugin will be available straight away. Mastering your first plugin First of all, every plugin is just a function which accepts config and args parameters. Every plugin consists of public interface for CLI and implementation intself. We use public interface to make your plugins auto-pluggable and easy to use for end-users. Every public interface consists of name, func & description fields: - name - Name of the plugin. After plugin installation it'll be used as a command name. For instance a plugin with the following interface: can be used like via rnpm like this: func - Plugin itself. This function will be used when you run a command above description - Command description. If user runs $ rnpm --help, this field will be displayed as a command description. options - An array of flags user can specify for your plugin to run. When defined, your exported func will receive an object of options as a 3rd argument. For instance a plugin with the following: will receive the following object: by default. Note: parse and default are optional. You can check commander.js docs for more information on how to define flags value. Also, in the case you want to expose multiple commands from the one plugin, you may use an array syntax: Using third-party plugins All existing plugins follows a naming convention: rnpm-plugin-<plugin name> (e.g. rnpm-plugin-link). To include plugin to your rnpm build, just install it as a npm package, it'll be included to your rnpm tool automatically (wow, magic!). Let's consider following example: we have a rnpm-plugin-something plugin which we doesn't provide you automatically with rnpm tool. To install it manually, you need to run npm install rnpm-plugin-something --save-dev inside your project folder. Then, you can run it by rnpm something or check if command has been successfully installed by running rnpm --help - you should see a new plugin in the list of commands. For further reading you can check our example plugin Commands In the case you need an additional input from the user, you may make a command for this purpose. Commands works similar to the npm scripts. Depdendency's package.json: In this scenario we're using custom prelink and postlink hooks for rnpm-plugin-link to tell rnpm that we want to run prelink script before and postlink after the linking process. Note: commands may be async and require some user input using third-party libraries (inquirer for instance). You don't need to worry about async queues, we do it for you under the rnpm hood. While making your own plugins for rnpm you may use any names for the commands, but we strongly recommend you to use a convention we suggest to avoid collisions: when + plugin name: prelink = pre + link. Params On Android - you can specify a custom packageInstance to be used when linking your project. The reason for that is often that your package constructor simply requires extra user provided config (e.g. API token). rnpm allows you to define an array of additional arguments to get from user during linking process that you can then, reference in your packageInstance. Simply include the following in your package.json: and update your packageInstance with the new variable: Starting from now on - users will be presented an interactive form powered by inquirer each time they run rnpm link. Note: We pass params array directly to inquirer which means you can also let users choose an answer from a list as well as provide a default value! See API docs for more details. Developers The documentation is still in progress, but if you are interested in the concept and good practices, see sample implementation here We're open for community ideas! If you know how to improve rnpm - please, let us know! FAQ How's that different from react-native link react-native link is great, but it only works for Android now. It also does not automatically add packages to your project nor support custom folder configuration. We aim to solve these issues by analyzing folders and getting maximum informations available from them. When running rnpm link you don't have to think about the package exported by developer or the import path to include in your Java project. Does it work with CocoaPods? Yes, in fact - it has nothing to do with it. What it does is just linking static libraries automatically to your xcodeproj in the normal way you have been doing that. There are no more other changes. Can I use rnpm link with npm's postinstall hook? Sure you can! Try doing something like this in your package.json: rnpm link <name> fails with ERRINVALIDPROJ Make sure you have run npm install <name> --save first rnpm link skip react-native module that it should not To be as fast as possible, rnpm link gets list of modules to link from package.json's dependencies. If you have them in devDependencies, they are going to be skipped. Special thanks Special thanks to coreh for giving us the rnpm name in the registry. Versioning This project follows semver. There are several 0.x versions published to npm registry you should not install as they belong to the previous project that was using that name 2 years ago. Contributing We welcome all contributors, simply make an issue or send over a pull request. We really appreciate your help - let's build this tool together! Special thanks to Sonny Lazuardi for the awesome rnpm logo! Sponsors This tool development and maintenance is sponsored by below companies: License The MIT License (MIT) Copyright (c) 2015 Mike Grabowski, 2015 Alexey Kureev Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the ""Software""), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
4060,"Phan is a static analyzer for PHP. Phan prefers to avoid false-positives and attempts to prove incorrectness rather than correctness.Phan is a static analyzer for PHP that prefers to minimize false-positives. Phan attempts to prove incorrectness rather than correctness. Phan looks for common issues and will verify type compatibility on various operations when type information is available or can be deduced. Phan has a good (but not comprehensive) understanding of flow control and can track values in a few use cases (e.g. arrays, integers, and strings). This is the branch for Phan 4. The branch for the older Phan 3 release line is here. Getting Started The easiest way to use Phan is via Composer. With Phan installed, you'll want to create a .phan/config.php file in your project to tell Phan how to analyze your source code. Once configured, you can run it via ./vendor/bin/phan. Phan depends on PHP 7.2+ with the php-ast extension (1.0.10+ is preferred) and supports analyzing PHP version 7.0-8.0 syntax. Installation instructions for php-ast can be found here. (Phan can be used without php-ast by using the CLI option --allow-polyfill-parser, but there are slight differences in the parsing of doc comments) Alternative Installation Methods See Getting Started for alternative methods of using Phan and details on how to configure Phan for your project. Incrementally Strengthening Analysis Take a look at Incrementally Strengthening Analysis for some tips on how to slowly ramp up the strictness of the analysis as your code becomes better equipped to be analyzed. Installing Dependencies Take a look at Installing Phan Dependencies for help getting Phan's dependencies installed on your system. The Wiki has more information about using Phan. Features Phan is able to perform the following kinds of analysis: Check that all methods, functions, classes, traits, interfaces, constants, properties and variables are defined and accessible. Check for type safety and arity issues on method/function/closure calls. Check for PHP7/PHP5 backward compatibility. Check for features that weren't supported in older PHP 7.x minor releases (E.g. object, void, iterable, ?T, [$x] = ...;, negative string offsets, multiple exception catches, etc.) Check for sanity with array accesses. Check for type safety on binary operations. Check for valid and type safe return values on methods, functions, and closures. Check for No-Ops on arrays, closures, constants, properties, variables, unary operators, and binary operators. Check for unused/dead/unreachable code. (Pass in --dead-code-detection) Check for unused variables and parameters. (Pass in --unused-variable-detection) Check for redundant or impossible conditions and pointless casts. (Pass in --redundant-condition-detection) Check for unused use statements. These and a few other issue types can be automatically fixed with --automatic-fix. Check for classes, functions and methods being redefined. Check for sanity with class inheritance (e.g. checks method signature compatibility). Phan also checks for final classes/methods being overridden, that abstract methods are implemented, and that the implemented interface is really an interface (and so on). Supports namespaces, traits and variadics. Supports Union Types. Supports Generic Types (i.e. @template). Supports generic arrays such as int[], UserObject[], array<int,UserObject>, etc.. Supports array shapes such as array{key:string,otherKey:?stdClass}, etc. (internally and in PHPDoc tags) This also supports indicating that fields of an array shape are optional via array{requiredKey:string,optionalKey?:string} (useful for @param) Supports phpdoc type annotations. Supports inheriting phpdoc type annotations. Supports checking that phpdoc type annotations are a narrowed form (E.g. subclasses/subtypes) of the real type signatures Supports inferring types from assert() statements and conditionals in if elements/loops. Supports @deprecated annotation for deprecating classes, methods and functions Supports @internal annotation for elements (such as a constant, function, class, class constant, property or method) as internal to the package in which it's defined. Supports @suppress <ISSUE_TYPE> annotations for suppressing issues. Supports magic @property annotations (@property <union_type> <variable_name>) Supports magic @method annotations (@method <union_type> <method_name>(<union_type> <param1_name>)) Supports class_alias annotations (experimental, off by default) Supports indicating the class to which a closure will be bound, via @phan-closure-scope (example) Supports analysis of closures and return types passed to array_map, array_filter, and other internal array functions. Offers extensive configuration for weakening the analysis to make it useful on large sloppy code bases Can be run on many cores. (requires pcntl) Output is emitted in text, checkstyle, json, pylint, csv, or codeclimate formats. Can run user plugins on source for checks specific to your code. Phan includes various plugins you may wish to enable for your project. See Phan Issue Types for descriptions and examples of all issues that can be detected by Phan. Take a look at the \Phan\Issue to see the definition of each error type. Take a look at the Tutorial for Analyzing a Large Sloppy Code Base to get a sense of what the process of doing ongoing analysis might look like for you. Phan can be used from various editors and IDEs for its error checking, ""go to definition"" support, etc. via the Language Server Protocol. Editors and tools can also request analysis of individual files in a project using the simpler Daemon Mode. See the tests directory for some examples of the various checks. Phan is imperfect and shouldn't be used to prove that your PHP-based rocket guidance system is free of defects. Features provided by plugins Additional analysis features have been provided by plugins. Checking for syntactically unreachable statements (E.g. { throw new Exception(""Message""); return $value; }) Checking *printf() format strings against the provided arguments (as well as checking for common errors) Checking that PCRE regexes passed to preg_*() are valid Checking for @suppress annotations that are no longer needed. Checking for duplicate or missing array keys. Checking coding style conventions Others Example: Phan's plugins for self-analysis. Usage After installing Phan, Phan needs to be configured with details on where to find code to analyze and how to analyze it. The easiest way to tell Phan where to find source code is to create a .phan/config.php file. A simple .phan/config.php file might look something like the following. Take a look at Creating a Config File and Incrementally Strengthening Analysis for more details. Running phan --help will show usage information and command-line options. Annotating Your Source Code Phan reads and understands most PHPDoc type annotations including Union Types (like int|MyClass|string|null) and generic array types (like int[] or string[]|MyClass[] or array<int,MyClass>). Take a look at Annotating Your Source Code and About Union Types for some help getting started with defining types in your code. Phan supports (int|string)[] style annotations, and represents them internally as int[]|string[] (Both annotations are treated like array which may have integers and/or strings). When you have arrays of mixed types, just use array. The following code shows off the various annotations that are supported. Just like in PHP, any type can be nulled in the function declaration which also means a null is allowed to be passed in for that parameter. Phan checks the type of every single element of arrays (Including keys and values). In practical terms, this means that [$int1=>$int2,$int3=>$int4,$int5=>$str6] is seen as array<int,int|string>, which Phan represents as array<int,int>|array<int,string>. [$strKey => new MyClass(), $strKey2 => $unknown] will be represented as array<string,MyClass>|array<string,mixed>. Literals such as [12,'myString'] will be represented internally as array shapes such as array{0:12,1:'myString'} Generating a file list This static analyzer does not track includes or try to figure out autoloader magic. It treats all the files you throw at it as one big application. For code encapsulated in classes this works well. For code running in the global scope it gets a bit tricky because order matters. If you have an index.php including a file that sets a bunch of global variables and you then try to access those after the include(...) in index.php the static analyzer won't know anything about these. In practical terms this simply means that you should put your entry points and any files setting things in the global scope at the top of your file list. If you have a config.php that sets global variables that everything else needs, then you should put that first in the list followed by your various entry points, then all your library files containing your classes. Development Take a look at Developer's Guide to Phan for help getting started hacking on Phan. When you find an issue, please take the time to create a tiny reproducing code snippet that illustrates the bug. And once you have done that, fix it. Then turn your code snippet into a test and add it to tests then ./test and send a PR with your fix and test. Alternatively, you can open an Issue with details. To run Phan's unit tests, just run ./test. To run all of Phan's unit tests and integration tests, run ./tests/run_all_tests.sh Code of Conduct We are committed to fostering a welcoming community. Any participant and contributor is required to adhere to our Code of Conduct. Online Demo This requires an up to date version of Firefox/Chrome and at least 4 GB of free RAM. (this is a 15 MB download) Run Phan entirely in your browser."
387,"Define and run multi-container applications with DockerDocker Compose Docker Compose is a tool for running multi-container applications on Docker defined using the Compose file format. A Compose file is used to define how the one or more containers that make up your application are configured. Once you have a Compose file, you can create and start your application with a single command: docker-compose up. Compose files can be used to deploy applications locally, or to the cloud on Amazon ECS or Microsoft ACI using the Docker CLI. You can read more about how to do this: - Compose for Amazon ECS - Compose for Microsoft ACI Where to get Docker Compose Windows and macOS Docker Compose is included in Docker Desktop for Windows and macOS. Linux You can download Docker Compose binaries from the release page on this repository. Using pip If your platform is not supported, you can download Docker Compose using pip: Note: Docker Compose requires Python 3.6 or later. Quick Start Using Docker Compose is basically a three-step process: 1. Define your app's environment with a Dockerfile so it can be reproduced anywhere. 2. Define the services that make up your app in docker-compose.yml so they can be run together in an isolated environment. 3. Lastly, run docker-compose up and Compose will start and run your entire app. A Compose file looks like this: You can find examples of Compose applications in our Awesome Compose repository. For more information about the Compose format, see the Compose file reference. Contributing Want to help develop Docker Compose? Check out our contributing documentation. If you find an issue, please report it on the issue tracker. Releasing Releases are built by maintainers, following an outline of the release process."
3513,"iOS Slide Menu View based on Google+, iQON, Feedly, Ameba iOS app. It is written in pure swift.SlideMenuControllerSwift iOS Slide View based on iQON, Feedly, Google+, Ameba iPhone app. Installation CocoaPods Carthage if iOS8 or later, Carthage is supported Add github ""dekatotoro/SlideMenuControllerSwift"" to your Cartfile. Run carthage update. for more info, see Carthage Manually Add the SlideMenuController.swift file to your project. Usage Setup Add import SlideMenuControllerSwift in your file In your app delegate: Storyboard Support Inherit SlideMenuController and put UIViewController in a storyboard. Override awakeFromNib, then instantiate any view controllers If you want to use the custom option, please set them before calling the init method, like so: You can access from UIViewController or add navigationBarButton open and close monitor the states of menu, you can use SlideMenuControllerDelegate use this: Requirements Requires Swift4.0 and iOS 9.0 and ARC. If you are developing in the Swift1.1 ~ 3.2, please use branch of swift1.1 ~ 3. If you want to use even iOS8.0, please to import the code directly. If you want to use objective-c even iOS6.0, plesea use SlideMenuControllerOC. Features Highly customizable Complete example Contributing Forks, patches and other feedback are welcome. Creator SlideMenuControllerSwift Yuji Hato Blog SlideMenuControllerOC Pluto Y Blog Sing Weibo License SlideMenuControllerSwift is available under the MIT license. See the LICENSE file for more info."
807,"A set of Ansible playbooks to build and maintain your own private cloud: email, calendar, contacts, file sync, IRC bouncer, VPN, and more.Introduction Sovereign is a set of Ansible playbooks that you can use to build and maintain your own personal cloud based entirely on open source software, so youre in control. If youve never used Ansible before, you might find these playbooks useful to learn from, since they show off a fair bit of what the tool can do. The original author's background and motivations might be of interest. tl;dr: frustrations with Google Apps and concerns about privacy and long-term support. Sovereign offers useful cloud services while being reasonably secure and low-maintenance. Use it to set up your server, SSH in every couple weeks, but mostly forget about it. Services Provided What do you get if you point Sovereign at a server? All kinds of good stuff! IMAP over SSL via Dovecot, complete with full text search provided by Solr. POP3 over SSL, also via Dovecot SMTP over SSL via Postfix, including a nice set of DNSBLs to discard spam before it ever hits your filters. Virtual domains for your email, backed by PostgreSQL. Spam fighting via Rspamd. Mail server verification using DKIM and DMARC so the Internet knows your mailserver is legit. Secure on-disk storage for email and more via EncFS. Webmail via Roundcube. Mobile push notifications via Z-Push. Email client automatic configuration. Jabber/XMPP instant messaging via Prosody. An RSS Reader via Selfoss. CalDAV and CardDAV to keep your calendars and contacts in sync, via ownCloud. Your own private storage cloud via ownCloud. Your own VPN server via OpenVPN. An IRC bouncer via ZNC. Monit to keep everything running smoothly (and alert you when its not). collectd to collect system statistics. Web hosting (ex: for your blog) via Apache. Firewall management via Uncomplicated Firewall (ufw). Intrusion prevention via fail2ban and rootkit detection via rkhunter. SSH configuration preventing root login and insecure password authentication RFC6238 two-factor authentication compatible with Google Authenticator and various hardware tokens Nightly backups to Tarsnap. Git hosting via cgit and gitolite. Read-it-later via Wallabag A bunch of nice-to-have tools like mosh and htop that make life with a server a little easier. Dont want one or more of the above services? Comment out the relevant role in site.yml. Or get more granular and comment out the associated include: directive in one of the playbooks. Usage What Youll Need A VPS (or bare-metal server if you wanna ball hard). My VPS is hosted at Linode. Youll probably want at least 512 MB of RAM between Apache, Solr, and PostgreSQL. Mine has 1024. 64-bit Debian 8.3 or an equivalent Linux distribution. (You can use whatever distro you want, but deviating from Debian will require more tweaks to the playbooks. See Ansibles different packaging modules.) A Tarsnap account with some credit in it. You could comment this out if you want to use a different backup service. Consider paying your hosting provider for backups or using an additional backup service for redundancy. You do not need to acquire an SSL certificate. The SSL certificates you need will be obtained from Let's Encrypt automatically when you deploy your server. Installation On the remote server The following steps are done on the remote server by sshing into it and running these commands. 1. Install required packages e.g aptitude is required on Debian apt-get install sudo python 2. Get a Tarsnap machine key If you havent already, download and install Tarsnap, or use brew install tarsnap if you use Homebrew. Create a new machine key for your server: tarsnap-keygen --keyfile roles/tarsnap/files/decrypted_tarsnap.key --user me@example.com --machine example.com Download a copy of this key and keep it somewhere safe! There's no point having backups if you can't retrieve them when needed. 3. Prep the server For goodness sake, change the root password: passwd Create a user account for Ansible to do its thing through: useradd --create-home deploy passwd deploy Authorize your ssh key if you want passwordless ssh login (optional): mkdir /home/deploy/.ssh chmod 700 /home/deploy/.ssh nano /home/deploy/.ssh/authorized_keys chmod 400 /home/deploy/.ssh/authorized_keys chown deploy:deploy /home/deploy -R echo 'deploy ALL=(ALL) NOPASSWD: ALL' > /etc/sudoers.d/deploy Your new account will be automatically set up for passwordless sudo. Or you can just add your deploy user to the sudo group. adduser deploy sudo On your local machine Ansible (the tool setting up your server) runs locally on your computer and sends commands to the remote server. Download this repository somewhere on your machine, either through Clone or Download > Download ZIP above, wget, or git as below git clone https://github.com/sovereign/sovereign.git 4. Configure your installation Modify the settings in the group_vars/sovereign folder to your liking. If you want to see how theyre used in context, just search for the corresponding string. All of the variables in group_vars/sovereign must be set for sovereign to function. For Git hosting, copy your public key into place: cp ~/.ssh/id_rsa.pub roles/git/files/gitolite.pub Finally, replace the host.example.net in the file hosts. If your SSH daemon listens on a non-standard port, add a colon and the port number after the IP address. In that case you also need to add your custom port to the task Set firewall rules for web traffic and SSH in the file roles/common/tasks/ufw.yml. 5. Set up DNS If youve just bought a new domain name, point it at Linodes DNS Manager or similar. Most VPS services (and even some domain registrars) offer a managed DNS service that you can use for this at no charge. If youre using an existing domain thats already managed elsewhere, you can probably just modify a few records. Create A or CNAME records which point to your server's IP address: example.com mail.example.com www.example.com (for Web hosting) autoconfig.example.com (for email client automatic configuration) read.example.com (for Wallabag) news.example.com (for Selfoss) cloud.example.com (for ownCloud) git.example.com (for cgit) 6. Run the Ansible Playbooks First, make sure youve got Ansible 1.9.3+ installed. To run the whole dang thing: ansible-playbook -i ./hosts --ask-sudo-pass site.yml If you chose to make a passwordless sudo deploy user, you can omit the --ask-sudo-pass argument. To run just one or more piece, use tags. I try to tag all my includes for easy isolated development. For example, to focus in on your firewall setup: ansible-playbook -i ./hosts --tags=ufw site.yml You might find that it fails at one point or another. This is probably because something needs to be done manually, usually because theres no good way of automating it. Fortunately, all the tasks are clearly named so you should be able to find out where it stopped. Ive tried to add comments where manual intervention is necessary. The dependencies tag just installs dependencies, performing no other operations. The tasks associated with the dependencies tag do not rely on the user-provided settings that live in group_vars/sovereign. Running the playbook with the dependencies tag is particularly convenient for working with Docker images. 7. Finish DNS set-up Create an MX record for example.com which assigns mail.example.com as the domains mail server. To ensure your emails pass DKIM checks you need to add a txt record. The name field will be default._domainkey.EXAMPLE.COM. The value field contains the public key used by DKIM. The exact value needed can be found in the file /var/lib/rspamd/dkim/EXAMPLE.COM.default.txt. It will look something like this: v=DKIM1; k=rsa; p=MIGfMA0GCSqGSIb3DQEBAQUAA4GNADCBiQKBgQDKKAQfMwKVx+oJripQI+Ag4uTwYnsXKjgBGtl7Tk6UMTUwhMqnitqbR/ZQEZjcNolTkNDtyKZY2Z6LqvM4KsrITpiMbkV1eX6GKczT8Lws5KXn+6BHCKULGdireTAUr3Id7mtjLrbi/E3248Pq0Zs39hkDxsDcve12WccjafJVwIDAQAB For DMARC you'll also need to add a txt record. The name field should be _dmarc.EXAMPLE.COM and the value should be v=DMARC1; p=none. More info on DMARC can be found here. Set up SPF and reverse DNS as per this post. Make sure to validate that its all working, for example, by sending an email to check-auth@verifier.port25.com and reviewing the report that will be emailed back to you. 8. Miscellaneous Configuration Sign in to the ZNC web interface and set things up to your liking. It isnt exposed through the firewall, so you must first set up an SSH tunnel: ssh deploy@example.com -L 6643:localhost:6643 Then proceed to http://localhost:6643 in your web browser. Similarly, to access the server monitoring page, use another SSH tunnel: ssh deploy@example.com -L 2812:localhost:2812 Again proceeding to http://localhost:2812 in your web browser. Finally, sign into ownCloud with a new administrator account to set it up. You should select PostgreSQL as the configuration backend. Use owncloud as the database user and the database name. For the database password ansible has created a set of random passwords for each service and stores them in your local folder secret, use the one in the file owncloud_db_password. How To Use Your New Personal Cloud Were collecting known-good client setups on our wiki. Troubleshooting If you run into an errors, please check the wiki page. If the problem you encountered, is not listed, please go ahead and create an issue. If you already have a bugfix and/or workaround, just put them in the issue and the wiki page. Reboots You will need to manually enter the password for any encrypted volumes on reboot. This is not Sovereign-specific, but rather a function of how EncFS works. This will necessitate SSHing into your machine after reboot, or accessing it via a console interface if one is available to you. Once you're in, run this: encfs /encrypted /decrypted --public It is possible that some daemons may need to be restarted after you enter your password for the encrypted volume(s). Some services may stall out while looking for resources that will only be available once the /decrypted volume is available and visible to daemon user accounts. IRC Ask questions and provide feedback in #sovereign on Freenode."
4183,"The best javascript plugin for app look-alike on- and off-canvas menus with sliding submenus for your website and webapp.mmenu.js The best javascript plugin for app look-alike on- and off-canvas menus with sliding submenus for your website and webapp. It is very customizable through a wide range of options, extensions and add-ons and it will always fit your needs. Need help? Have a look at the documentation for demos, tutorials, documentation and support. Working on a WordPress site? Check out the mmenu WordPress plugin. Licence The mmenu javascript plugin is licensed under the CC-BY-NC-4.0 license. You can purchase a license if you want to use it in a commercial project. Learn more Tutorial Options Extensions Add-ons API Browser support As of version 8, the mmenu.js plugin only supports ECMAScript 6 compliant browsers. For Internet Explorer 10 and 11, you''ll need some polyfills. Version 7 should work to some degree in Internet Explorer 9, but you'll need a matchMedia polyfill, version 6 should work in Internet Explorer 9 without any shortcomings. Development This project uses Gulp(4) to compile, minify and concatenate the TS/JS and SCSS/CSS files. If you are unfamiliar with Gulp, check this tutorial on how to get started. Run gulp watch in the command-line to put a watch on the files and run all scripts immediately after saving your changes."
3010,"Hard fork of jteeuwen/go-bindata because it disappeared, Please refer to issues#5 for details.Warning this repository is not maintained. Questions or suggestions can be posted here. bindata This package converts any file into managable Go source code. Useful for embedding binary data into a go program. The file data is optionally gzip compressed before being converted to a raw byte slice. It comes with a command line tool in the go-bindata sub directory. This tool offers a set of command line options, used to customize the output being generated. Installation To install the library and command line program, use the following: go get -u github.com/jteeuwen/go-bindata/... Usage Conversion is done on one or more sets of files. They are all embedded in a new Go source file, along with a table of contents and an Asset function, which allows quick access to the asset, based on its name. The simplest invocation generates a bindata.go file in the current working directory. It includes all assets from the data directory. $ go-bindata data/ To include all input sub-directories recursively, use the elipsis postfix as defined for Go import paths. Otherwise it will only consider assets in the input directory itself. $ go-bindata data/... To specify the name of the output file being generated, we use the following: $ go-bindata -o myfile.go data/ Multiple input directories can be specified if necessary. $ go-bindata dir1/... /path/to/dir2/... dir3 The following paragraphs detail some of the command line options which can be supplied to go-bindata. Refer to the testdata/out directory for various output examples from the assets in testdata/in. Each example uses different command line options. To ignore files, pass in regexes using -ignore, for example: $ go-bindata -ignore=\\.gitignore data/... Accessing an asset To access asset data, we use the Asset(string) ([]byte, error) function which is included in the generated output. data, err := Asset(""pub/style/foo.css"") if err != nil { // Asset was not found. } // use asset data Debug vs Release builds When invoking the program with the -debug flag, the generated code does not actually include the asset data. Instead, it generates function stubs which load the data from the original file on disk. The asset API remains identical between debug and release builds, so your code will not have to change. This is useful during development when you expect the assets to change often. The host application using these assets uses the same API in both cases and will not have to care where the actual data comes from. An example is a Go webserver with some embedded, static web content like HTML, JS and CSS files. While developing it, you do not want to rebuild the whole server and restart it every time you make a change to a bit of javascript. You just want to build and launch the server once. Then just press refresh in the browser to see those changes. Embedding the assets with the debug flag allows you to do just that. When you are finished developing and ready for deployment, just re-invoke go-bindata without the -debug flag. It will now embed the latest version of the assets. Lower memory footprint Using the -nomemcopy flag, will alter the way the output file is generated. It will employ a hack that allows us to read the file data directly from the compiled program's .rodata section. This ensures that when we call call our generated function, we omit unnecessary memcopies. The downside of this, is that it requires dependencies on the reflect and unsafe packages. These may be restricted on platforms like AppEngine and thus prevent you from using this mode. Another disadvantage is that the byte slice we create, is strictly read-only. For most use-cases this is not a problem, but if you ever try to alter the returned byte slice, a runtime panic is thrown. Use this mode only on target platforms where memory constraints are an issue. The default behaviour is to use the old code generation method. This prevents the two previously mentioned issues, but will employ at least one extra memcopy and thus increase memory requirements. For instance, consider the following two examples: This would be the default mode, using an extra memcopy but gives a safe implementation without dependencies on reflect and unsafe: Here is the same functionality, but uses the .rodata hack. The byte slice returned from this example can not be written to without generating a runtime error. Optional compression When the -nocompress flag is given, the supplied resource is not GZIP compressed before being turned into Go code. The data should still be accessed through a function call, so nothing changes in the usage of the generated file. This feature is useful if you do not care for compression, or the supplied resource is already compressed. Doing it again would not add any value and may even increase the size of the data. The default behaviour of the program is to use compression. Path prefix stripping The keys used in the _bindata map, are the same as the input file name passed to go-bindata. This includes the path. In most cases, this is not desireable, as it puts potentially sensitive information in your code base. For this purpose, the tool supplies another command line flag -prefix. This accepts a portion of a path name, which should be stripped off from the map keys and function names. For example, running without the -prefix flag, we get: $ go-bindata /path/to/templates/ _bindata[""/path/to/templates/foo.html""] = path_to_templates_foo_html Running with the -prefix flag, we get: $ go-bindata -prefix ""/path/to/"" /path/to/templates/ _bindata[""templates/foo.html""] = templates_foo_html Build tags With the optional -tags flag, you can specify any go build tags that must be fulfilled for the output file to be included in a build. This is useful when including binary data in multiple formats, where the desired format is specified at build time with the appropriate tags. The tags are appended to a // +build line in the beginning of the output file and must follow the build tags syntax specified by the go tool. Related projects go-bindata-assetfs - implements http.FileSystem interface. Allows you to serve assets with net/http."
132,"Web Starter Kit - a workflow for multi-device websitesOverview Web Starter Kit is an opinionated boilerplate for web development. Tools for building a great experience across many devices and performance oriented. Helping you to stay productive following the best practices outlined in Google's Web Fundamentals. A solid starting point for both professionals and newcomers to the industry. Features | Feature | Summary | |----------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------| | Responsive boilerplate | A responsive boilerplate optimized for the multi-screen web. Powered by Material Design Lite. You're free to use either this or a completely clean-slate via basic.html. | | Sass support | Compile Sass into CSS with ease, bringing support for variables, mixins and more. (Run gulp serve or gulp for production) | | Performance optimization | Minify and concatenate JavaScript, CSS, HTML and images to help keep your pages lean. (Run gulp to create an optimised version of your project to /dist) | | Code Linting | JavaScript code linting is done using ESLint - a pluggable linter tool for identifying and reporting on patterns in JavaScript. Web Starter Kit uses ESLint with eslint-config-google, which tries to follow the Google JavaScript style guide. | | ES2015 via Babel 6.0 | Optional ES2015 support using Babel. To enable ES2015 support remove the line ""only"": ""gulpfile.babel.js"", in the .babelrc file. ES2015 source code will be automatically transpiled to ES5 for wide browser support. | | Built-in HTTP Server | A built-in server for previewing your site locally while you develop and iterate | | Live Browser Reloading | Reload the browser in real-time anytime an edit is made without the need for an extension. (Run gulp serve and edit your files) | | Cross-device Synchronization | Synchronize clicks, scrolls, forms and live-reload across multiple devices as you edit your project. Powered by BrowserSync. (Run gulp serve and open up the IP provided on other devices on your network) | | Offline support | Thanks to our baked in Service Worker pre-caching, sites deploying dist to a HTTPS domain will enjoy offline support. This is made possible by sw-precache. | | PageSpeed Insights | Web performance metrics showing how well your site performs on mobile and desktop (Run gulp pagespeed) | Quickstart Download the kit or clone this repository and build on what is included in the app directory. There are two HTML starting points, from which you can choose: index.html - the default starting point, containing Material Design layout. basic.html - no layout, but still includes our minimal mobile best-practices Be sure to look over the installation docs to verify your environment is prepared to run WSK. Once you have verified that your system can run WSK, check out the commands available to get started. Web Performance Web Starter Kit strives to give you a high performance starting point out of the box. Our median Web Page Test scores for the default template have a Speed Index of ~1100 (1000 is ideal) and a repeat-visit Speed Index of ~550 thanks to Service Worker precaching. Browser Support At present, we officially aim to support the last two versions of the following browsers: Chrome Edge Firefox Safari Opera Internet Explorer 9+ This is not to say that Web Starter Kit cannot be used in browsers older than those reflected, but merely that our focus will be on ensuring our layouts work great in the above. Troubleshooting If you find yourself running into issues during installation or running the tools, please check our Troubleshooting guide and then open an issue. We would be happy to discuss how they can be solved. A Boilerplate-only Option If you would prefer not to use any of our tooling, delete the following files from the project: package.json, gulpfile.babel.js and .travis.yml. You can now safely use the boilerplate with an alternative build-system or no build-system at all if you choose. Docs and Recipes File Appendix - What do the different files here do? Using Material Design Lite's Sass - how to get MDL's Sass working with WSK Deployment guides - available for Firebase, Google App Engine and other services. Gulp recipes - the official Gulp recipes directory includes a comprehensive list of guides for different workflows you can add to your project. Inspiration Web Starter Kit is inspired by Mobile HTML5 Boilerplate and Yeoman's generator-gulp-webapp, having taken input from contributors to both projects during development. Our FAQs attempt to answer commonly asked questions about the project. Contributing Contributions, questions and comments are all welcome and encouraged. For code contributions to Web Starter Kit, please see our Contribution guide before submitting a pull request. Website related issues should be filed on the Web Fundamentals issue tracker. License Apache 2.0 Copyright 2015 Google Inc"
2119,"Bash Automated Testing SystemBats: Bash Automated Testing System Bats is a TAP-compliant testing framework for Bash. It provides a simple way to verify that the UNIX programs you write behave as expected. A Bats test file is a Bash script with special syntax for defining test cases. Under the hood, each test case is just a function with a description. Bats is most useful when testing software written in Bash, but you can use it to test any UNIX program. Test cases consist of standard shell commands. Bats makes use of Bash's errexit (set -e) option when running test cases. If every command in the test case exits with a 0 status code (success), the test passes. In this way, each line is an assertion of truth. Running tests To run your tests, invoke the bats interpreter with a path to a test file. The file's test cases are run sequentially and in isolation. If all the test cases pass, bats exits with a 0 status code. If there are any failures, bats exits with a 1 status code. When you run Bats from a terminal, you'll see output as each test is performed, with a check-mark next to the test's name if it passes or an ""X"" if it fails. $ bats addition.bats addition using bc addition using dc 2 tests, 0 failures If Bats is not connected to a terminalin other words, if you run it from a continuous integration system, or redirect its output to a filethe results are displayed in human-readable, machine-parsable TAP format. You can force TAP output from a terminal by invoking Bats with the --tap option. $ bats --tap addition.bats 1..2 ok 1 addition using bc ok 2 addition using dc Test suites You can invoke the bats interpreter with multiple test file arguments, or with a path to a directory containing multiple .bats files. Bats will run each test file individually and aggregate the results. If any test case fails, bats exits with a 1 status code. Writing tests Each Bats test file is evaluated n+1 times, where n is the number of test cases in the file. The first run counts the number of test cases, then iterates over the test cases and executes each one in its own process. For more details about how Bats evaluates test files, see Bats Evaluation Process on the wiki. run: Test other commands Many Bats tests need to run a command and then make assertions about its exit status and output. Bats includes a run helper that invokes its arguments as a command, saves the exit status and output into special global variables, and then returns with a 0 status code so you can continue to make assertions in your test case. For example, let's say you're testing that the foo command, when passed a nonexistent filename, exits with a 1 status code and prints an error message. The $status variable contains the status code of the command, and the $output variable contains the combined contents of the command's standard output and standard error streams. A third special variable, the $lines array, is available for easily accessing individual lines of output. For example, if you want to test that invoking foo without any arguments prints usage information on the first line: load: Share common code You may want to share common code across multiple test files. Bats includes a convenient load command for sourcing a Bash source file relative to the location of the current test file. For example, if you have a Bats test in test/foo.bats, the command will source the script test/test_helper.bash in your test file. This can be useful for sharing functions to set up your environment or load fixtures. skip: Easily skip tests Tests can be skipped by using the skip command at the point in a test you wish to skip. Optionally, you may include a reason for skipping: Or you can skip conditionally: setup and teardown: Pre- and post-test hooks You can define special setup and teardown functions, which run before and after each test case, respectively. Use these to load fixtures, set up your environment, and clean up when you're done. Code outside of test cases You can include code in your test file outside of @test functions. For example, this may be useful if you want to check for dependencies and fail immediately if they're not present. However, any output that you print in code outside of @test, setup or teardown functions must be redirected to stderr (>&2). Otherwise, the output may cause Bats to fail by polluting the TAP stream on stdout. Special variables There are several global variables you can use to introspect on Bats tests: $BATS_TEST_FILENAME is the fully expanded path to the Bats test file. $BATS_TEST_DIRNAME is the directory in which the Bats test file is located. $BATS_TEST_NAMES is an array of function names for each test case. $BATS_TEST_NAME is the name of the function containing the current test case. $BATS_TEST_DESCRIPTION is the description of the current test case. $BATS_TEST_NUMBER is the (1-based) index of the current test case in the test file. $BATS_TMPDIR is the location to a directory that may be used to store temporary files. Installing Bats from source Check out a copy of the Bats repository. Then, either add the Bats bin directory to your $PATH, or run the provided install.sh command with the location to the prefix in which you want to install Bats. For example, to install Bats into /usr/local, $ git clone https://github.com/sstephenson/bats.git $ cd bats $ ./install.sh /usr/local Note that you may need to run install.sh with sudo if you do not have permission to write to the installation prefix. Support The Bats source code repository is hosted on GitHub. There you can file bugs on the issue tracker or submit tested pull requests for review. For real-world examples from open-source projects using Bats, see Projects Using Bats on the wiki. To learn how to set up your editor for Bats syntax highlighting, see Syntax Highlighting on the wiki. Version history 0.4.0 (August 13, 2014) Improved the display of failing test cases. Bats now shows the source code of failing test lines, along with full stack traces including function names, filenames, and line numbers. Improved the display of the pretty-printed test summary line to include the number of skipped tests, if any. Improved the speed of the preprocessor, dramatically shortening test and suite startup times. Added support for absolute pathnames to the load helper. Added support for single-line @test definitions. Added bats(1) and bats(7) manual pages. Modified the bats command to default to TAP output when the $CI variable is set, to better support environments such as Travis CI. 0.3.1 (October 28, 2013) Fixed an incompatibility with the pretty formatter in certain environments such as tmux. Fixed a bug where the pretty formatter would crash if the first line of a test file's output was invalid TAP. 0.3.0 (October 21, 2013) Improved formatting for tests run from a terminal. Failing tests are now colored in red, and the total number of failing tests is displayed at the end of the test run. When Bats is not connected to a terminal (e.g. in CI runs), or when invoked with the --tap flag, output is displayed in standard TAP format. Added the ability to skip tests using the skip command. Added a message to failing test case output indicating the file and line number of the statement that caused the test to fail. Added ""ad-hoc"" test suite support. You can now invoke bats with multiple filename or directory arguments to run all the specified tests in aggregate. Added support for test files with Windows line endings. Fixed regular expression warnings from certain versions of Bash. Fixed a bug running tests containing lines that begin with -e. 0.2.0 (November 16, 2012) Added test suite support. The bats command accepts a directory name containing multiple test files to be run in aggregate. Added the ability to count the number of test cases in a file or suite by passing the -c flag to bats. Preprocessed sources are cached between test case runs in the same file for better performance. 0.1.0 (December 30, 2011) Initial public release. 2014 Sam Stephenson. Bats is released under an MIT-style license; see LICENSE for details."
911," Simple, pretty and powerful logger for android Logger Simple, pretty and powerful logger for android Setup Download Initialize And use Output Options String format arguments are supported Collections are supported (only available for debug logs) Json and Xml support (output will be in debug level) Advanced Loggable Log adapter checks whether the log should be printed or not by checking this function. If you want to disable/hide logs for output, override isLoggable method. true will print the log message, false will ignore it. Save logs to the file //TODO: More information will be added later Add custom tag to Csv format strategy How it works More Use filter for a better result. PRETTY_LOGGER or your custom tag Make sure that wrap option is disabled You can also simplify output by changing settings. Timber Integration License Copyright 2018 Orhan Obut Licensed under the Apache License, Version 2.0 (the ""License""); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License. "
3295,"The Objective-C iOS | macOS | watchOS | tvOS SDK for the Parse Platform Parse SDK for iOS | macOS | watchOS | tvOS A library that gives you access to the powerful Parse Server backend from your iOS or macOS app. For more information about the Parse Platform and its features, see the public documentation. Check out some of the apps using Parse. Getting Started To use parse, head on over to the releases page, and download the latest build. And you're off!. Take a look at the public documentation & API and start building. Notice the API docs aren't totally up to date when it comes to latest Swift signature of the methods and more importantly regarding Push Notifications which are no longer supported by Parse server, keep an eye on its repo Other Installation Options CocoaPods Add the following line to your Podfile: Run pod install, and you should now have the latest parse release. If you wish to use the Facebook or Twitter utils or ParseUI, you can now leverage Cocoapods 'subspecs' Note that in this case, the Parse framework will contain all headers and classes, so you just have to use: Carthage Add the following line to your Cartfile: Run carthage update, and you should now have the latest version of Parse SDK in your Carthage folder. This will also compile the ParseTwitterUtils, ParseFacebookUtilsV4 as well as ParseUI frameworks. Compiling for yourself If you want to manually compile the SDK, clone it locally, and run the following commands in the root directory of the repository: Compiled frameworks will be in multiple archives inside the build/release folder: - Parse-iOS.zip - Parse-macOS.zip - Parse-tvOS.zip - Parse-watchOS.zip - ParseFacebookUtils-iOS.zip - ParseFacebookUtils-tvOS.zip - ParseTwitterUtils-iOS.zip - ParseUI.zip Using Parse as a sub-project You can also include parse as a subproject inside of your application if you'd prefer, although we do not recommend this, as it will increase your indexing time significantly. To do so, just drag and drop the Parse.xcodeproj file into your workspace. Note that unit tests will be unavailable if you use Parse like this, as OCMock will be unable to be found. How Do I Contribute? We want to make contributing to this project as easy and transparent as possible. Please refer to the Contribution Guidelines. Dependencies We use the following libraries as dependencies inside of Parse: Bolts, for task management. OCMock, for unit testing."
3813,"BinNavi is a binary analysis IDE that allows to inspect, navigate, edit and annotate control flow graphs and call graphs of disassembled code.BinNavi Copyright 2011-2020 Google LLC Introduction BinNavi is a binary analysis IDE - an environment that allows users to inspect, navigate, edit, and annotate control-flow-graphs of disassembled code, do the same for the callgraph of the executable, collect and combine execution traces, and generally keep track of analysis results among a group of analysts. Note: The BinNavi project is no longer under active development. Commercial third-party dependency BinNavi uses a commercial third-party graph visualisation library (yFiles) for displaying and laying out graphs. This library is immensely powerful, and not easily replaceable. In order to perform direct development using yFiles, you need a developer license for it. At the same time, we want the community to be able to contribute to BinNavi without needing a commercial yFiles license. In order to do this and conform to the yFiles license, all interfaces to yFiles need to be properly obfuscated. In order to achieve this, we did the following: 1) BinNavi and all the libraries have been split into two: The parts of the project that directly depend on yFiles were split into subpackages called ""yfileswrap"": com.google.security.zynamics.binnavi com.google.security.zynamics.binnavi.yfileswrap com.google.security.zynamics.zylib com.google.security.zynamics.zylib.yfileswrap com.google.security.zynamics.reil com.google.security.zynamics.reil.yfileswrap We are distributing a pre-built JAR file with all the code in the yfileswrap subpackages - pre-linked and obfuscated against yFiles. If you wish to change or add code in BinNavi and do not have a yFiles license, you can freely do pretty much whatever you want in the non-yfileswrap packages - you can simply put the lib/yfileswrap-obfuscated.jar into your classpath to test and see the results. If you wish to make changes to the yfileswrap subdirectories, please be aware that you will need a valid yFiles license - and any contribution that you make to the BinNavi project has to honor their license agreement. This means that you can't simply expose their inner APIs under different names etc. We will enforce this - we're very happy to have found a way to open-source BinNavi with the yFiles dependency, and we will make sure that any code we pull in respects the yFiles license. Note for maintainers/yFiles license holders To rebuild the yFiles wrapper library, first copy y.jar and ysvg.jar to third_party/java/yfiles. Then rebuild with: Building BinNavi from scratch BinNavi uses Maven for its dependency management, but not for the actual build. Java 11 is the minimum supported version. To build from scratch use these commands: Running BinNavi for the first time Please be aware that BinNavi makes use of a central PostgreSQL database for storing disassemblies/comments/traces - so you need to have such an instance running somewhere accessible to you. You can launch BinNavi as follows: Importing the project into Eclipse Loading the code into Eclipse for further development requires a little bit of configuration. Install the dependencies (as described above) and make sure you have a Java SDK with 1.8 language compliance installed. Create a new ""Java Project From Existing Ant Buildfile"" and use the file build.xml Select the ""javac"" task found in target ""build-binnavi-jar"" Open the ""Project Properties"" dialog and choose ""Java build Path"" showing the ""Source"" tab. Remove all but one source folder and edit it to have the following properties: Linked Folder Location: PROJECT_LOC/src/main/java Folder Name: java Click on ""Next"" Add **/yfileswrap/** to the list of directories to exclude. Go to ""Run->Run As"", select ""Java Application"" and then search for CMain. You should be ready to go from here. Exporting disassemblies from IDA As part of this project, we are distributing an IDA Pro plugin that exports disassemblies from IDA into the PostgreSQL database format that BinNavi requires. When running BinNavi, simply configure the right path for IDA, click on the ""install plugin"" button if necessary -- you should now be able to import disassemblies. Using other disassemblers than IDA Right now, we only have the IDA export plugin - but we are hoping very much that someone will help us build export functionality for other disassemblers in the near future. Building BinNavi with Gradle Please note that at current the Maven build is the authoritative build system for BinNavi. Gradle is purely experimental and is likely to change. You can build BinNavi with gradle by running the following: On Linux / OS X: On Windows: This will produce the jar in the project route under build/libs/. Loading the project into Eclipse with Gradle On Linux / OS X: On Windows: As part of the project creation process it will download the dependencies. Once complete do the following to load into Eclipse: Open Eclipse. File > Import... from menu bar. From the window that appears select General > Existing Projects into Workspace. Ensure the ""Select root directory"" radio button is selected. Click Browse... and navigate to the project directory. The projects area should now have ""binnavi"" and a tick next to it. Press Finish. You Eclipse workspace is now setup and complete for BinNavi. Loading the project into IntelliJ with Gradle On Linux / OS X: On Windows: As part of the project creation process it will download the dependencies. Once complete do the following to load into IntelliJ: Open IntelliJ. Select ""Open"" from main window. Navigate to the project folder and should see the IntelliJ icon. This signifies its a project. Press Ok and wait for it to import and load. IntelliJ might not recognise it as a gradle project. Select enable from the popup window and use local gradle. Your IntelliJ environment is now setup and complete for IntelliJ."
677,"The flexible, easy to use, all in one drawer library for your Android project. Now brand new with material 2 design.MaterialDrawer ... the flexible, easy to use, all in one drawer library for your Android project. What's included Setup Migration Guide WIKI / FAQ Used by Sample App What's included the easiest possible integration uses the androidX support libraries compatible down to API Level 16 includes an AccountSwitcher quick and simple api follows the NEW Google Material Design Guidelines use vector (.svg) icons and icon fonts via the Android-Iconics integration Google Material Design Icons, Google Material Community Design Icons, FontAwesome and more comes with various themes which help to get your own themes clean modify the colors on the go comes with multiple default drawer items based on a RecyclerView RTL support Gmail like MiniDrawer expandable items badge support define custom drawer items tested and stable sticky footer or headers absolutely NO limits NavController support by @petretiandrea If you upgrade from < 8.0.0 follow the MIGRATION GUIDE Preview Screenshots Setup Latest releases Kotlin && New | v8.4.0 Kotlin | v7.0.0 | (Builder approach like v6.x) Java && AndroidX | v6.1.2 Java && AppCompat | v6.0.9 1. Provide the gradle dependency You can find dependency versions and all library releases on MVN Repository. 2. Add the Drawer into the XML The MaterialDrawerSliderView has to be provided as child of the DrawerLayout and will as such act as the slider 3. Add the DrawerStyle to your theme Great. Your drawer is now ready to use. Additional Setup Add items and adding some functionality Selecting an item By default, when a drawer item is clicked, it becomes the new selected item. If this isn't the expected behavior, you can disable it for this item using isSelectable = false: Modify items or the drawer Add profiles and an AccountHeader Android-Iconics support The MaterialDrawer provides an extension for the Android-Iconics library. This allows you to create your DrawerItems with an icon from any font. Choose the fonts you need. Available Fonts Advanced Setup For advanced usecases. Please have a look at the provided sample activities. Load images via url The MaterialDrawer supports fetching images from URLs and setting them for the Profile icons. As the MaterialDrawer does not contain an ImageLoading library the dev can choose his own implementation (Picasso, Glide, ...). This has to be done, before the first image should be loaded via URL. (Should be done in the Application, but any other spot before loading the first image is working too) * SAMPLE using PICASSO * SAMPLE using GLIDE An implementation with GLIDE v4 (See tag v6.1.1 for glide v3 sample) can be found in the sample application JVM Target 1.8 Style the drawer Custom style - styles.xml Create your custom style. If you don't need a custom theme see the next section, how you can set the colors just by overwriting the original colors. Adjust BezelImageView style Overwrite the Style of the BezelImageView for the whole MaterialDrawer Used by (feel free to send me new projects) Screener Meldmail Academic Schedule Sprit Club StickyNotes MLManager Fimpl Teacher Gradebook AS Sales Management Sporza Voetbal Atmosphere Fitness Challenge I'm Reading Quran - Kur'an Okuyorum Makota Money Manager Companion for Band Recipedia Right ourse - ruble course Gameru Boost for reddit Calendula MyTimes VoIP By Antisip MBox - One Place for Entertainment D Notes - Smart and Material Note Taking Moviebase MyFuelLog2 MECSol 3D Geeks: Thingiverse Browser for 3D Printing Tusky: Mastodon Client for Android Tibia Live Walkaholic Articles about the MaterialDrawer java-help.ru - MaterialDrawer tutorial MaterialDrawer in multiple activities Credits Mirosaw Stanek - GitHub For his InstaMaterial concept and the idea of inflating the drawerLayout InstaMaterial Concept Lunae Luman - Behance for the Header Image Developed By Mike Penz mikepenz.dev - blog.mikepenz.dev - mikepenz@gmail.com paypal.me/mikepenz Automatic changelog generation action License Copyright 2021 Mike Penz Licensed under the Apache License, Version 2.0 (the ""License""); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
3443,"A simple, declarative, and composable way to fetch data for React componentsReact Refetch A simple, declarative, and composable way to fetch data for React components. Installation Requires React 0.14 or later. This assumes that youre using npm package manager with a module bundler like Webpack or Browserify to consume CommonJS modules. The following ES6 functions are required: Object.assign Promise fetch Array.prototype.find Check the compatibility tables (Object.assign, Promise, fetch, Array.prototype.find) to make sure all browsers and platforms you need to support have these, and include polyfills as necessary. Introduction See Introducing React Refetch on the Heroku Engineering Blog for background and a quick introduction to this project. Motivation This project was inspired by (and forked from) React Redux. Redux/Flux is a wonderful library/pattern for applications that need to maintain complicated client-side state; however, if your application is mostly fetching and rendering read-only data from a server, it can over-complicate the architecture to fetch data in actions, reduce it into the store, only to select it back out again. The other approach of fetching data inside the component and dumping it in local state is also messy and makes components smarter and more mutable than they need to be. This module allows you to wrap a component in a connect() decorator like react-redux, but instead of mapping state to props, this lets you map props to URLs to props. This lets you keep your components completely stateless, describe data sources in a declarative manner, and delegate the complexities of data fetching to this module. Advanced options are also supported to lazy load data, poll for new data, and post data to the server. Example If you have a component called Profile that has a userId prop, you can wrap it in connect() to map userId to one or more requests and assign them to new props called userFetch and likesFetch: When the component mounts, the requests will be calculated, fetched, and the result will be passed into the component as the props specified. The result is represented as a PromiseState, which is a synchronous representation of the fetch Promise. It will either be pending, fulfilled, or rejected. This makes it simple to reason about the fetch state at the point in time the component is rendered: See the composing responses to see how to handle userFetch and likesFetch together. Although not included in this library because of application-specific defaults, see an example PromiseStateContainer and its example usage for a way to abstract and simplify the rendering of PromiseStates. Refetching When new props are received, the requests are re-calculated, and if they changed, the data is refetched and passed into the component as new PromiseStates. Using something like React Router to derive the props from the URL in the browser, the application can control state changes just by changing the URL. When the URL changes, the props change, which recalculates the requests, new data is fetched, and it is reinjected into the components: By default, the requests are compared using their URL, headers, and body; however, if you want to use a custom value for the comparison, set the comparison attribute on the request. This can be helpful when the request should or should not be refetched in response to a prop change that is not in the request itself. A common situation where this occurs is when two different requests should be refetched together even though one of the requests does not actually include the prop. Note, this is using the request object syntax for userStatsFetch instead of just a plain URL string. This syntax allows for more advanced options. See the API documentation for details: In this example, usersFetch is refetched every time props.status or props.page changes because the URL is changed. However, userStatsFetch does not contain these props in its URL, so would not normally be refetched, but because we added comparison: ${props.status}:${props.page}, it will be refetched along with usersFetch. In general, you should only rely on changes to the requests themselves to control when data is refetched, but this technique can be helpful when finer-grained control is needed. If you always want data to be refetched when any new props are received, set the force: true option on the request. This will take precedence over any custom comparison and the default request comparison. For example: Setting force: true should be avoid if at all possible because it could result in extraneous data fetching and rendering of the component. Try to use the default comparison or custom comparison option instead. Automatic Refreshing If the refreshInterval option is provided along with a URL, the data will be refreshed that many milliseconds after the last successful response. If a request was ever rejected, it will not be refreshed or otherwise retried. In this example, likesFetch will be refreshed every minute. Note, this is using the request object syntax for likeFetch instead of just a plain URL string. This syntax allows for more advanced options. See the API documentation for details. When refreshing, the PromiseState will be the same as a the previous fulfilled state, but with the refreshing attribute set. That is, pending will remain unset and the existing value will be left in tact. When the refresh completes, refreshing will be unset and the value will be updated with the latest data. If the refresh is rejected, the PromiseState will move into a rejected and not attempt to refresh again. Fetch Functions Instead of mapping the props directly to a URL string or request object, you can also map the props to a function that returns a URL string or request object. When the component receives props, instead of the data being fetched immediately and injected as a PromiseState, the function is bound to the props and injected into the component as functional prop to be called later (usually in response to a user action). This can be used to either lazy load data, post data to the server, or refresh data. These are best shown with examples: Lazy Loading Here is a simple example of lazy loading the likesFetch with a function: In this example, userFetch is fetched normally when the component receives props, but lazyFetchLikes is a function that returns likesFetch, so nothing is fetched immediately. Instead lazyFetchLikes is injected into the component as a function to be called later inside the component: When this function is called, the request is calculated using both the bound props and any passed in arguments, and the likesFetch result is injected into the component normally as a PromiseState. Posting Data Functions can also be used for post data to the server in response to a user action. For example: The postLike function is injected in as a prop, which can then be tied to a button: When the user clicks the button, someSubject is posted to the URL and the response is injected as a new postLikeResponse prop as a PromiseState to show progress and feedback to the user. Manually Refreshing Data Functions can also be used to manually refresh data by overwriting an existing PromiseState: The userFetch data is first loaded normally when the component receives props, but the refreshUser function is also injected into the component. When this.props.refreshUser() is called, the request is calculated, and compared with the existing userFetch request. If the request changed (or force: true), the data is refetched and the existing userFetch PromiseState is overwritten. This should generally only be used for user-invoked refreshes; see above for automatically refreshing on an interval. Note, the example above sets force: true and refreshing: true on the request returned by the refreshUser() function. These attributes are optional, but commonly used with manual refreshes. force: true avoids the default request comparison (e.g. url, method, headers, body) with the existing userFetch request so that every time this.props.refreshUser() is called, a fetch is performed. Because the request would not have changed from the last prop change in the example above, force: true is required in this case for the fetch to occur when this.props.refreshUser() is called. refreshing: true avoids the existing PromiseState from being cleared while fetch is in progress. Posting + Refreshing Data The two examples above can be combined to post data to the server and refresh an existing PromiseState. This is a common pattern when a responding to a user action to update a resource and reflect that update in the component. For example, if PATCH /users/:user_id responds with the updated user, it can be used to overwrite the existing userFetch when the user updates her name: Composing Responses If a component needs data from more than one URL, the PromiseStates can be combined with PromiseState.all() to be pending until all the PromiseStates have been fulfilled. For example: Similarly, PromiseState.race() can be used to return the first settled PromiseState. Like their asynchronous Promise counterparts, PromiseStates can be chained with then() and catch(); however, the handlers are run immediately to transform the existing state. This can be helpful to handle errors or transform values as part of a composition. For example, to provide a fallback value to likesFetch in the case of failure: Chaining Requests Inside of connect(), requests can be chained using then(), catch(), andThen() and andCatch() to trigger additional requests after a previous request is fulfilled. These are not to be confused with the similar sounding functions on PromiseState, which are on the response side, are synchronous, and are executed for every change of the PromiseState. then() is helpful for cases where multiple requests are required to get the data needed by the component and the subsequent request relies on data from the previous request. For example, if you need to make a request to /foos/${name} to look up foo.id and then make a second request to /bar-for-foos-by-id/${foo.id} and return the whole thing as barFetch (the component will not have access to the intermediate foo): andThen() is similar, but is intended for side effect requests where you still need access to the result of the first request and/or need to fanout to multiple requests: This is also helpful for cases where a fetch function is changing data that is in some other fetch that is a collection. For example, if you have a list of foos and you create a new foo and the list needs to be refreshed: catch and andCatch are similar, but for error cases. Identity Requests: Static Data & Transforming Responses To support static data and response transformations, there is a special kind of request called an ""identity request"" that has a value instead of a url. The value is passed through directly to the PromiseState without actually fetching anything. In its pure form, it looks like this: In this case, the usersFetch PromiseState will be set to the provided list of users. The use case for identity requests by themselves is limited to mostly injecting static data during development and testing; however, they can be quite powerful when used with request chaining. For example, it is possible to fetch data from the server, filter it within a then function, and return an identity request: Note, this form of transformation is similar to what is possible on the PromiseState (i.e. this.props.usersFetch.then(users => users.filter(u => u.verified))); however, this has the advantage of only being called when usersFetch changes and keeps the logic out of the component. Identity requests can also be provided a Promise (or any ""thenable"") or a Function. If value is a Promise, the PromiseState will be pending until the Promise is resolved. This can be helpful for asynchronous, non-fetch operations (e.g. file i/o) that want to use a similar pattern as fetch operations. If value is a Function, it will be evaluated with no arguments and its return value will be used instead, as in cases described above. The Function will be only be called when comparison changes. This can be helpful for cases where you want to provide an identify request, but it is expensive to evaluate. By wrapping it in a function, it is only evaluated when something changes. Accessing Headers & Metadata Both request and response headers and other metadata are accessible. Custom request headers can be set on the request as an object: The raw Request and Response can be accessed via the meta attribute on the PromiseState. For example, to access the a response header: Do not attempt to read bodies directly from meta.request or meta.response. They are provided for metadata purposes only. Setting defaults and hooking into internal processing It is possible to modify the various defaults used by React Refetch, as well as substitute in custom implementations of internal functions. A simple use case would be to avoid repeating the same option for every fetch block: A more advanced use case would be to replace the buildRequest internal function to, for example, modify headers on the fly based on the URL of the request, or using advanced Request options: You can also replace the handleResponse function, which takes a Response, and should return a Promise that resolves to the value of the response, or rejects based on the body, headers, status code, etc. You can use it, for example, to parse CSV instead of JSON: On changing the fetch and Request implementations Through this same API it is possible to change the internal fetch and Request implementations. This could be useful for a number of reasons, such as precise control over requests or customisation that is not possible with either buildRequest or handleResponse. For example, here's a simplistic implementation of a ""caching fetch,"" which will cache the result of successful requests for a minute, regardless of headers: When using this feature, make sure to read the fetch API and interface documentation and all related topics. Notably, you need to keep in mind that the body of a Response can only be consumed once, so if you need to read it in your custom fetch, you also need to recreate a brand new Response (or a .clone() of the original one if you're not modifying the body) so React Refetch can work properly. This is an advanced feature. Use existing declarative functionality wherever possible. Customise buildRequest or handleResponse if these can work instead. Please be aware that changing the fetch (or Request) implementation could conflict with built-in current or future functionality. Unit Testing Connected Components For unit testing components connected, a non-default export of the unconnected component can be exposed to allow unit tests to inject their own PromiseState(s) as props. This allows for unit tests to test both success and error scenarios without having to deal with mocking HTTP, timing of responses, or other details about how the PromiseState(s) is fulfilled -- instead, they can just focus on asserting that the component itself renders the PromiseState(s) correctly in various scenarios. The recommended naming convention for the unconnected component is to prepend an underscore to the component name. For example, if there is a component called Profile, add a non-default export of _Profile before the default export with connect: Now, unit tests can use the static methods on PromiseState to inject their own PromiseState(s) as props. For example, here is a unit test using Enzyme to shallow render the unconnected _Profile and provides a pending PromiseState and asserts that the LoadingAnimation is present: Similarly, the rejected and fulfilled cases can be tested: Complete Example This is a complex example demonstrating various feature at once: TypeScript If you are using React Refetch in a project that is using TypeScript, this library ships with type definitions. Below is example connected component in TypeScript. Note how there is both an OuterProps and InnerProps. The OuterProp are the props the component receives from the outside. In this example, the OuterProps would just be userId: string the caller is expected to pass in (e.g. <UserWidget userId=""user-123""/>). The InnerProps are the PromiseState props that the connect() function injects into the component when fetching data. Since the InnerProps include the OuterProps, they are defined as InnerProps extends OuterProps and then the component itself extends React.Component<InnerProps>. This allows the component to have access to both the userId: string and userFetch: PromiseState<User> internally. However, the connect function returns a component with only the OuterProps (e.g. React.Component<OuterProps>) so callers only need to pass in userId: string. API Documentation connect([mapPropsToRequestsToProps]) connect.defaults([newDefaults]) PromiseState(iterable) Support This software is provided ""as is"", without warranty or support of any kind, express or implied. See license for details. License MIT"
879,"The PHP Unit Testing framework.PHPUnit PHPUnit is a programmer-oriented testing framework for PHP. It is an instance of the xUnit architecture for unit testing frameworks. Installation We distribute a PHP Archive (PHAR) that has all required (as well as some optional) dependencies of PHPUnit 10.0 bundled in a single file: Alternatively, you may use Composer to download and install PHPUnit as well as its dependencies. Please refer to the ""Getting Started"" guide for details on how to install PHPUnit. Contribute Please refer to CONTRIBUTING.md for information on how to contribute to PHPUnit and its related projects. List of Contributors Thanks to everyone who has contributed to PHPUnit! You can find a detailed list of contributors on every PHPUnit related package on GitHub. This list shows only the major components: PHPUnit php-code-coverage A very special thanks to everyone who has contributed to the documentation and helps maintain the translations: English Spanish French Japanese Brazilian Portuguese Simplified Chinese"
3815,"Browse Hacker News like a haxor: A Hacker News command line interface (CLI).haxor-news Coworker who sees me looking at something in a browser: ""Glad you're not busy; I need you to do this, this, this..."" Coworker who sees me staring intently at a command prompt: Backs away, slowly... -Source Check out the haxor-news discussion in this Hacker News post. haxor-news brings Hacker News to the terminal, allowing you to view/filter the following without leaving your command line: Posts Post Comments Post Linked Web Content Monthly Hiring and Freelancers Posts User Info Onions haxor-news helps you filter the large number of comments that popular posts generate. Want to expand only previously unseen comments? -cu/--comments_unseen How about recent comments posted in the past 60 minutes? -cr/--comments_recent Filter comments matching a regex query? -cq/--comments_query [query] Job hunting or just curious what's out there? Filter the monthly who's hiring and freelancers post: $ hn hiring ""(?i)(Node|JavaScript).*(remote)"" > remote_web_jobs.txt Combine haxor-news with pipes, redirects, and other command line utilities. Output to pagers, write to files, automate with cron, etc. haxor-news comes with a handy optional auto-completer with interactive help: Index General Syntax Auto-Completer and Interactive Help Customizable Highlighting Commands Features View Posts View a Post's Linked Web Content View and Filter a Post's Comments View All Comments Filter on Unseen Comments Filter on Recent Comments Filter with Regex Hide Non-Matching Comments View and Filter the Monthly Hiring Post View and Filter the Monthly Freelancer Post Combine With Pipes and Redirects View User Info View Onions View Results in a Browser Windows Support Installation and Tests Installation Pip Installation Virtual Environment Installation Supported Python Versions Supported Platforms Developer Installation Continuous Integration Unit Tests and Code Coverage Documentation Misc Contributing Credits Contact Info License Syntax Usage: $ hn <command> [params] [options] Auto-Completer and Interactive Help Optionally, you can enable fish-style completions and an auto-completion menu with interactive help: $ haxor-news If available, the auto-completer also automatically displays comments through a pager. Within the auto-completer, the same syntax applies: haxor> hn <command> [params] [options] Customizable Highlighting You can control the ansi colors used for highlighting by updating your ~/.haxornewsconfig file. Color options include: For no color, set the value(s) to None. Commands View Posts View the Top, Best, Show, Ask, Jobs, New, and Onion posts. Usage: $ hn [command] [limit] # post limit default: 10 Examples: $ hn top $ hn show 20 View a Post's Linked Web Content After viewing a list of posts, you can view a post's linked web content by referencing the post #. The HTML contents of the post's link are formatted for easy-viewing within your terminal. If available, the formatted output is sent to a pager. See the View in a Browser section to view the contents in a browser instead. Usage: $ hn view [#] Example: $ hn view 1 $ hn view 8 View and Filter a Post's Comments View All Comments After viewing a list of posts, you can view a post's comments by referencing the post #. Examples: $ hn view 8 -c $ hn view 8 --comments > comments.txt Paged Comments If running with the auto-completer, comments are automatically paginated. To get the same pagination without the auto-completer, append | less -r: $ hn view 8 -c | less -r Filter on Unseen Comments Filter comments to expand only those you have not yet seen. Unseen comments are denoted with a [!] and are fully expanded. Seen comments will be truncated with [...] and will be shown to help provide context to unseen comments. Examples: $ hn view 8 -cu $ hn view 8 --comments_unseen | less -r Filter on Recent Comments Filter comments to expand only those posted within the past 60 minutes. Older comments will be truncated with [...] and will be shown to help provide context to recent comments. Examples: $ hn view 8 -cr | less -r $ hn view 8 --comments_recent Filter with Regex Filter comments based on a given regular expression query. Examples: $ hn view 2 -cq ""(?i)programmer"" | less -r $ hn view 2 --comments_regex_query ""(?i)programmer"" > programmer.txt Case insensitive regex: (?i) Hide Non-Matching Comments When filtering comments for unseen, recent, or with regex, non-matching comments are collapsed to provide context. To instead hide non-matching comments, pass the -ch\--comments_hide flag. Hidden comments will be displayed as .. Example: $ hn view 8 -cu -ch | less -r Filter the Monthly Hiring Post Hacker News hosts a monthly hiring post where employers post the latest job openings. Usage: $ hn hiring [regex filter] Examples: $ hn hiring """" $ hn hiring ""(?i)JavaScript|Node"" $ hn hiring ""(?i)(Node|JavaScript).*(remote)"" > remote_jobs.txt Case insensitive regex: (?i) To search a different monthly hiring post other than the latest, use the hiring post id. Usage: $ hn hiring [regex filter] [post id] Filter the Freelancers Post Hacker News hosts a monthly freelancers post where employers and freelancers post availabilities. Usage: $ hn freelance [regex filter] Examples: $ hn freelance """" $ hn freelance ""(?i)JavaScript|Node"" $ hn freelance ""(?i)(Node|JavaScript).*(remote)"" > remote_jobs.txt Case insensitive regex: (?i) To search a different monthly hiring post other than the latest, use the hiring post id. Usage: $ hn freelance [regex filter] [post id] Combine With Pipes and Redirects Output to pagers, write to files, automate with cron, etc. Examples: $ hn view 1 -c | less $ hn freelance ""(?i)(Node|JavaScript).*(remote)"" > remote_jobs.txt View User Info Usage: $ hn user [user id] View Onions Usage: $ hn onion [limit] # post limit default: all View in a Browser View the linked web content or comments in your default browser instead of your terminal. Usage: $ hn <command> [params] [options] -b $ hn <command> [params] [options] --browser Windows Support haxor-news has been tested on Windows 10. Pager Support Pager support on Windows is more limited as discussed in the following ticket. Users can direct output to a pager with the | more command: $ hn view 1 -c | more Config File On Windows, the .haxornewsconfig file can be found in %userprofile%. For example: C:\Users\dmartin\.haxornewsconfig cmder and conemu Although you can use the standard Windows command prompt, you'll probably have a better experience with either cmder or conemu. Installation Pip Installation haxor-news is hosted on PyPI. The following command will install haxor-news: $ pip install haxor-news You can also install the latest haxor-news from GitHub source which can contain changes not yet pushed to PyPI: $ pip install git+https://github.com/donnemartin/haxor-news.git If you are not installing in a virtualenv, run with sudo: $ sudo pip install haxor-news Once installed, run the optional haxor-news auto-completer with interactive help: $ haxor-news Run commands: $ hn <command> [params] [options] Virtual Environment Installation It is recommended that you install Python packages in a virtualenv to avoid potential issues with dependencies or permissions. To view haxor-news virtualenv installation instructions, click here. Mac OS X 10.11 El Capitan Users There is a known issue with Apple and its included python package dependencies (more info at https://github.com/pypa/pip/issues/3165). We are investigating ways to fix this issue but in the meantime, to install haxor-news, you can run: $ sudo pip install haxor-news --upgrade --ignore-installed six Supported Python Versions Python 2.6 Python 2.7 Python 3.3 Python 3.4 Python 3.5 Python 3.6 Python 3.7 Supported Platforms Mac OS X Tested on OS X 10.10 Linux, Unix Tested on Ubuntu 14.04 LTS Windows Tested on Windows 10 Developer Installation If you're interested in contributing to haxor-news, run the following commands: $ git clone https://github.com/donnemartin/haxor-news.git $ pip install -e . $ pip install -r requirements-dev.txt $ haxor-news $ hn <command> [params] [options] Continuous Integration Continuous integration details are available on Travis CI. Unit Tests and Code Coverage Run unit tests in your active Python environment: $ python tests/run_tests.py Run unit tests with tox on multiple Python environments: $ tox Documentation Source code documentation will soon be available on Readthedocs.org. Check out the source docstrings. Run the following to build the docs: $ scripts/update_docs.sh Contributing Contributions are welcome! Review the Contributing Guidelines for details on how to: Submit issues Submit pull requests Credits click by mitsuhiko haxor by avinassh html2text by aaronsw python-prompt-toolkit by jonathanslenders requests by kennethreitz Contact Info Feel free to contact me to discuss any issues, questions, or comments. My contact info can be found on my GitHub page. License I am providing code and resources in this repository to you under an open source license. Because this is my personal repository, the license you receive to my code and resources is from me and not my employer (Facebook). Copyright 2015 Donne Martin Licensed under the Apache License, Version 2.0 (the ""License""); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
151,"A terminal built on web technologies For more details, head to: https://hyper.is Project goals The goal of the project is to create a beautiful and extensible experience for command-line interface users, built on open web standards. In the beginning, our focus will be primarily around speed, stability and the development of the correct API for extension authors. In the future, we anticipate the community will come up with innovative additions to enhance what could be the simplest, most powerful and well-tested interface for productivity. Usage Download the latest release! Linux Arch and derivatives Hyper is available in the AUR. Use an AUR package manager e.g. paru NixOS Hyper is available as Nix package, to install the app run this command: macOS Use Homebrew Cask to download the app by running these commands: Windows Use chocolatey to install the app by running the following command (package information can be found here): Note: The version available on Homebrew Cask, Chocolatey, Snapcraft or the AUR may not be the latest. Please consider downloading it from here if that's the case. Contribute Regardless of the platform you are working on, you will need to have Yarn installed. If you have never installed Yarn before, you can find out how at: https://yarnpkg.com/en/docs/install. Install necessary packages: Windows Be sure to run yarn global add windows-build-tools from an elevated prompt (as an administrator) to install windows-build-tools. macOS Once you have installed Yarn, you can skip this section! Linux (You can see here what your Linux is based on.) RPM-based GraphicsMagick libicns-utils xz (Installed by default on some distributions.) Debian-based graphicsmagick icnsutils xz-utils Fork this repository to your own GitHub account and then clone it to your local device Install the dependencies: yarn Build the code and watch for changes: yarn run dev To run hyper yarn run app from another terminal tab/window/pane If you are using Visual Studio Code, select Launch Hyper in debugger configuration to launch a new Hyper instance with debugger attached. If you interrupt yarn run dev, you'll need to relaunch it each time you want to test something. Webpack will watch changes and will rebuild renderer code when needed (and only what have changed). You'll just have to relaunch electron by using yarn run app or VSCode launch task. To make sure that your code works in the finished application, you can generate the binaries like this: After that, you will see the binary in the ./dist folder! Known issues that can happen during development Error building node-pty If after building during development you get an alert dialog related to node-pty issues, make sure its build process is working correctly by running yarn run rebuild-node-pty. If you are on macOS, this typically is related to Xcode issues (like not having agreed to the Terms of Service by running sudo xcodebuild after a fresh Xcode installation). Error with c++ on macOS when running yarn If you are getting compiler errors when running yarn add the environment variable export CXX=clang++ Error with codesign on macOS when running yarn run dist If you have issues in the codesign step when running yarn run dist on macOS, you can temporarily disable code signing locally by setting export CSC_IDENTITY_AUTO_DISCOVERY=false for the current terminal session. Related Repositories Art Website Sample Extension Sample Theme Awesome Hyper"
3026,"s2n : an implementation of the TLS/SSL protocols s2n-tls is a C99 implementation of the TLS/SSL protocols that is designed to be simple, small, fast, and with security as a priority. It is released and licensed under the Apache License 2.0. Quickstart for Ubuntu Fork s2n-tls on GitHub Run the following commands on Ubuntu. Quickstart for OSX (or other platforms) If you are building on OSX, or simply don't want to execute the entire build script above, you can use build tools like Ninja. OSX An example of building on OSX: Amazonlinux2 Install dependancies with ./codebuild/bin/install_al2_dependencies.sh after cloning. Have a Question? If you have any questions about Submitting PR's, Opening Issues, s2n-tls API usage, or something similar, we have a public chatroom available here to answer your questions: https://gitter.im/awslabs/s2n Otherwise, if you think you might have found a security impacting issue, please instead follow our Security Notification Process. Using s2n-tls The s2n-tls I/O APIs are designed to be intuitive to developers familiar with the widely-used POSIX I/O APIs, and s2n-tls supports blocking, non-blocking, and full-duplex I/O. Additionally there are no locks or mutexes within s2n-tls. For details on building the s2n-tls library and how to use s2n-tls in an application you are developing, see the API Reference. s2n-tls features s2n-tls implements SSLv3, TLS1.0, TLS1.1, and TLS1.2. For encryption, s2n-tls supports 128-bit and 256-bit AES, in the CBC and GCM modes, ChaCha20, 3DES, and RC4. For forward secrecy, s2n-tls supports both DHE and ECDHE. s2n-tls also supports the Server Name Indicator (SNI), Application-Layer Protocol Negotiation (ALPN) and the Online Certificate Status Protocol (OCSP) TLS extensions. SSLv3, RC4, 3DES and DHE are each disabled by default for security reasons. As it can be difficult to keep track of which encryption algorithms and protocols are best to use, s2n-tls features a simple API to use the latest ""default"" set of preferences. If you prefer to remain on a specific version for backwards compatibility, that is also supported. s2n-tls safety mechanisms Internally s2n-tls takes a systematic approach to data protection and includes several mechanisms designed to improve safety. Small and auditable code base Ignoring tests, blank lines and comments, s2n-tls is about 6,000 lines of code. s2n's code is also structured and written with a focus on reviewability. All s2n-tls code is subject to code review, and we plan to complete security evaluations of s2n-tls on an annual basis. To date there have been two external code-level reviews of s2n-tls, including one by a commercial security vendor. s2n-tls has also been shared with some trusted members of the broader cryptography, security, and Open Source communities. Any issues discovered are always recorded in the s2n-tls issue tracker. Static analysis, fuzz-testing and penetration testing In addition to code reviews, s2n-tls is subject to regular static analysis, fuzz-testing, and penetration testing. Several penetration tests have occurred, including two by commercial vendors. Unit tests and end-to-end testing s2n-tls includes positive and negative unit tests and end-to-end test cases. Erase on read s2n-tls encrypts or erases plaintext data as quickly as possible. For example, decrypted data buffers are erased as they are read by the application. Built-in memory protection s2n-tls uses operating system features to protect data from being swapped to disk or appearing in core dumps. Minimalist feature adoption s2n-tls avoids implementing rarely used options and extensions, as well as features with a history of triggering protocol-level vulnerabilities. For example there is no support for session renegotiation or DTLS. Compartmentalized random number generation The security of TLS and its associated encryption algorithms depends upon secure random number generation. s2n-tls provides every thread with two separate random number generators. One for ""public"" randomly generated data that may appear in the clear, and one for ""private"" data that should remain secret. This approach lessens the risk of potential predictability weaknesses in random number generation algorithms from leaking information across contexts. Modularized encryption s2n-tls has been structured so that different encryption libraries may be used. Today s2n-tls supports OpenSSL, LibreSSL, BoringSSL, and the Apple Common Crypto framework to perform the underlying cryptographic operations. Timing blinding s2n-tls includes structured support for blinding time-based side-channels that may leak sensitive data. For example, if s2n-tls fails to parse a TLS record or handshake message, s2n-tls will add a randomized delay of between 10 and 30 seconds, granular to nanoseconds, before responding. This raises the complexity of real-world timing side-channel attacks by a factor of at least tens of trillions. Table based state-machines s2n-tls uses simple tables to drive the TLS/SSL state machines, making it difficult for invalid out-of-order states to arise. C safety s2n-tls is written in C, but makes light use of standard C library functions and wraps all memory handling, string handling, and serialization in systematic boundary-enforcing checks. Security issue notifications If you discover a potential security issue in s2n-tls we ask that you notify AWS Security via our vulnerability reporting page. Please do not create a public github issue. If you package or distribute s2n-tls, or use s2n-tls as part of a large multi-user service, you may be eligible for pre-notification of future s2n-tls releases. Please contact s2n-pre-notification@amazon.com. Contributing to s2n-tls If you are interested in contributing to s2n-tls, please see our development guide. Language Bindings for s2n-tls See our language bindings list for language bindings for s2n-tls that we're aware of."
414,"Bootstrap components built with ReactReact-Bootstrap Bootstrap 4 components built with React. Docs See the documentation with live editable examples and API documentation. To find the documentation for the latest Bootstrap 3 compatible release, go here. Migrating from Bootstrap 3 to Bootstrap 4 If you would like to update React-Bootstrap within an existing project to use Bootstrap 4, please read our docs for migrating to React-Bootstrap V1. Related modules react-router-bootstrap Integration with React Router Awesome React Bootstrap Components - Additional components like off-canvas navbar, switch and sliders. Local setup Yarn is our package manager of choice here. Check out setup instructions here if you don't have it installed already. After that you can run yarn run bootstrap to install all the needed dependencies. From there you can: Run the tests once with yarn test (Or run them in watch mode with yarn run tdd). Start a local copy of the docs site with yarn start Or build a local copy of the library with yarn run build CodeSandbox Examples Click here to explore some React-Bootstrap CodeSandbox examples. Click here to automatically open CodeSandbox with the React-Bootstrap CodeSandbox Examples GitHub Repository as a workspace. Contributions Yes please! See the contributing guidelines for details."
2168,"String manipulation helpers for javascript The stable release documentation can be found here https://epeli.github.io/underscore.string/ Underscore.string Javascript lacks complete string manipulation operations. This is an attempt to fill that gap. List of build-in methods can be found for example from Dive Into JavaScript. Originally started as an Underscore.js extension but is a full standalone library nowadays. Upgrading from 2.x to 3.x? Please read the changelog. Usage For Node.js, Browserify and Webpack Install from npm npm install underscore.string Require individual functions or load the full library to enable chaining but especially when using with Browserify the individual function approach is recommended because using it you only add those functions to your bundle you use. In Meteor From your Meteor project folder and you'll be able to access the library with the s global from both the server and the client. Others The dist/underscore.string.js file is an UMD build. You can load it using an AMD loader such as RequireJS or just stick it to a web page and access the library from the s global. Underscore.js/Lo-Dash integration It is still possible use as Underscore.js/Lo-Dash extension But it's not recommended since include, contains, reverse and join are dropped because they collide with the functions already defined by Underscore.js. Lo-Dash-FP/Ramda integration If you want to use underscore.string with ramdajs or Lo-Dash-FP you can use underscore.string.fp. npm install underscore.string.fp Download Development version Uncompressed with Comments Production version Minified API Individual functions numberFormat(number, [ decimals=0, decimalSeparator='.', orderSeparator=',']) => string Formats the numbers. levenshtein(string1, string2) => number Calculates Levenshtein distance between two strings. capitalize(string, [lowercaseRest=false]) => string Converts first letter of the string to uppercase. If true is passed as second argument the rest of the string will be converted to lower case. decapitalize(string) => string Converts first letter of the string to lowercase. chop(string, step) => array clean(string) => string Trim and replace multiple spaces with a single space. cleanDiacritics(string) => string Replace diacritic characters with closest ASCII equivalents. Check the source for supported characters. Pull requests welcome for missing characters! chars(string) => array swapCase(string) => string Returns a copy of the string in which all the case-based characters have had their case swapped. include(string, substring) => boolean Tests if string contains a substring. count(string, substring) => number Returns number of occurrences of substring in string. escapeHTML(string) => string Converts HTML special characters to their entity equivalents. This function supports cent, yen, euro, pound, lt, gt, copy, reg, quote, amp, apos. unescapeHTML(string) => string Converts entity characters to HTML equivalents. This function supports cent, yen, euro, pound, lt, gt, copy, reg, quote, amp, apos, nbsp. insert(string, index, substring) => string replaceAll(string, find, replace, [ignorecase=false]) => string isBlank(string) => boolean join(separator, ...strings) => string Joins strings together with given separator lines(str) => array Split lines to an array wrap(str, options) => string Splits a line str (default '') into several lines of size options.width (default 75) using a options.seperator (default '\n'). If options.trailingSpaces is true, make each line at least width long using trailing spaces. If options.cut is true, create new lines in the middle of words. If options.preserveSpaces is true, preserve the space that should be there at the end of a line (only works if options.cut is false). dedent(str, pattern) => string Dedent unnecessary indentation or dedent by a pattern. Credits go to @sindresorhus. This implementation is similar to https://github.com/sindresorhus/strip-indent reverse(string) => string Return reversed string: splice(string, index, howmany, substring) => string Like an array splice. startsWith(string, starts, [position]) => boolean This method checks whether the string begins with starts at position (default: 0). endsWith(string, ends, [position]) => boolean This method checks whether the string ends with ends at position (default: string.length). pred(string) => string Returns the predecessor to str. succ(string) => string Returns the successor to str. titleize(string) => string camelize(string, [decapitalize=false]) => string Converts underscored or dasherized string to a camelized one. Begins with a lower case letter unless it starts with an underscore, dash or an upper case letter. classify(string) => string Converts string to camelized class name. First letter is always upper case underscored(string) => string Converts a camelized or dasherized string into an underscored one dasherize(string) => string Converts a underscored or camelized string into an dasherized one humanize(string) => string Converts an underscored, camelized, or dasherized string into a humanized one. Also removes beginning and ending whitespace, and removes the postfix '_id'. trim(string, [characters]) => string Trims defined characters from begining and ending of the string. Defaults to whitespace characters. ltrim(string, [characters]) => string Left trim. Similar to trim, but only for left side. rtrim(string, [characters]) => string Right trim. Similar to trim, but only for right side. truncate(string, length, [truncateString = '...']) => string prune(string, length, pruneString) => string Elegant version of truncate. Makes sure the pruned string does not exceed the original length. Avoid half-chopped words when truncating. words(str, delimiter=/\s+/) => array Split string by delimiter (String or RegExp), /\s+/ by default. sprintf(string format, ...arguments) => string C like string formatting. Makes use of the sprintf-js package. This function will be removed in the next major release, use the sprintf-js package instead. pad(str, length, [padStr, type]) => string pads the str with characters until the total string length is equal to the passed length parameter. By default, pads on the left with the space char ("" ""). padStr is truncated to a single character if necessary. lpad(str, length, [padStr]) => string left-pad a string. Alias for pad(str, length, padStr, ""left"") rpad(str, length, [padStr]) => string right-pad a string. Alias for pad(str, length, padStr, ""right"") lrpad(str, length, [padStr]) => string left/right-pad a string. Alias for pad(str, length, padStr, ""both"") toNumber(string, [decimals]) => number Parse string to number. Returns NaN if string can't be parsed to number. strRight(string, pattern) => string Searches a string from left to right for a pattern and returns a substring consisting of the characters in the string that are to the right of the pattern or all string if no match found. strRightBack(string, pattern) => string Searches a string from right to left for a pattern and returns a substring consisting of the characters in the string that are to the right of the pattern or all string if no match found. strLeft(string, pattern) => string Searches a string from left to right for a pattern and returns a substring consisting of the characters in the string that are to the left of the pattern or all string if no match found. strLeftBack(string, pattern) => string Searches a string from right to left for a pattern and returns a substring consisting of the characters in the string that are to the left of the pattern or all string if no match found. stripTags(string) => string Removes all html tags from string. toSentence(array, [delimiter, lastDelimiter]) => string Join an array into a human readable sentence. toSentenceSerial(array, [delimiter, lastDelimiter]) => string The same as toSentence, but adjusts delimeters to use Serial comma. repeat(string, count, [separator]) => string Repeats a string count times. surround(string, wrap) => string Surround a string with another string. quote(string, quoteChar) or q(string, quoteChar) => string Quotes a string. quoteChar defaults to "". unquote(string, quoteChar) => string Unquotes a string. quoteChar defaults to "". slugify(string) => string Transform text into an ascii slug which can be used in safely in URLs. Replaces whitespaces, accentuated, and special characters with a dash. Limited set of non-ascii characters are transformed to similar versions in the ascii character set such as to a. Caution: this function is charset dependent naturalCmp(string1, string2) => number Naturally sort strings like humans would do. None numbers are compared by their ASCII values. Note: this means ""a"" > ""A"". Use .toLowerCase if this isn't to be desired. Just past it to Array#sort. toBoolean(string) => boolean Turn strings that can be commonly considered as booleas to real booleans. Such as ""true"", ""false"", ""1"" and ""0"". This function is case insensitive. It can be customized by giving arrays of truth and falsy value matcher as parameters. Matchers can be also RegExp objects. map(string, function) => string Creates a new string with the results of calling a provided function on every character of the given string. Library functions If you require the full library you can use chaining and aliases s(string) => chain Start a chain. Returns an immutable chain object with the string functions as methods which return a new chain object instead of the plain string value. The chain object includes also following native Javascript string methods: toUpperCase toLowerCase split replace slice substring substr concat chain.value() Return the string value from the chain When calling a method which does not return a string the resulting value is immediately returned chain.tap(function) => chain Tap into the chain with a custom function Aliases Maintainers This library is maintained by Esa-Matti Suuronen @epeli Christoph Hermann @stoeffel Licence The MIT License Copyright (c) 2011 Esa-Matti Suuronen esa-matti@suuronen.org Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the ""Software""), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
3554,"[Deprecated] A node module to generate service worker code that will precache specific resources so they work offline. sw-precache sw-toolbox and sw-precache are deprecated in favor of Workbox. Please read this migration guide for information on upgrading. About Service Worker Precache is a module for generating a service worker that precaches resources. It integrates with your build process. Once configured, it detects all your static resources (HTML, JavaScript, CSS, images, etc.) and generates a hash of each file's contents. Information about each file's URL and versioned hash are stored in the generated service worker file, along with logic to serve those files cache-first, and automatically keep those files up to date when changes are detected in subsequent builds. Serving your local static resources cache-first means that you can get all the crucial scaffolding for your web appyour App Shellon the screen without having to wait for any network responses. The module can be used in JavaScript-based build scripts, like those written with gulp, and it also provides a command-line interface. You can use the module directly, or if you'd prefer, use one of the wrappers around sw-precache for specific build environments, like webpack. It can be used alongside the sw-toolbox library, which works well when following the App Shell + dynamic content model. The full documentation is in this README, and the getting started guide provides a quicker jumping off point. To learn more about the internals of the generated service worker, you can read this deep-dive by Huang Xuan. Table of Contents Install Usage Overview Example Considerations Command-line interface Runtime Caching API Methods generate(options, callback) write(filePath, options, callback) Options Parameter cacheId [String] clientsClaim [Boolean] directoryIndex [String] dontCacheBustUrlsMatching [Regex] dynamicUrlToDependencies [ObjectString,Buffer,ArrayString] handleFetch [boolean] ignoreUrlParametersMatching [ArrayRegex] importScripts [ArrayString] logger [function] maximumFileSizeToCacheInBytes [Number] navigateFallback [String] navigateFallbackWhitelist [ArrayRegExp] replacePrefix [String] runtimeCaching [ArrayObject] skipWaiting [Boolean] staticFileGlobs [ArrayString] stripPrefix [String] stripPrefixMulti [Object] templateFilePath [String] verbose [boolean] Wrappers and Starter Kits CLIs Starter Kits Recipes for writing a custom wrapper Acknowledgements Support License Install Local build integration: Global command-line interface: Usage Overview Make sure your site is served using HTTPS! Service worker functionality is only available on pages that are accessed via HTTPS. (http://localhost will also work, to facilitate testing.) The rationale for this restriction is outlined in the ""Prefer Secure Origins For Powerful New Features"" document. Incorporate sw-precache into your node-based build script. It should work well with either gulp or Grunt, or other build scripts that run on node. In fact, we've provided examples of both in the demo/ directory. Each build script in demo has a function called writeServiceWorkerFile() that shows how to use the API. Both scripts generate fully-functional JavaScript code that takes care of precaching and fetching all the resources your site needs to function offline. There is also a command-line interface available, for those using alternate build setups. Register the service worker JavaScript. The JavaScript that's generated needs to be registered as the controlling service worker for your pages. This technically only needs to be done from within a top-level ""entry"" page for your site, since the registration includes a scope which will apply to all pages underneath your top-level page. service-worker-registration.js is a sample script that illustrates the best practices for registering the generated service worker and handling the various lifecycle events. Example The project's sample gulpfile.js illustrates the full use of sw-precache in context. (Note that the sample gulpfile.js is the one in the demo folder, not the one in the root of the project.) You can run the sample by cloning this repo, using npm install to pull in the dependencies, changing to the demo/ directory, running `npm bin`/gulp serve-dist, and then visiting http://localhost:3000. There's also a sample Gruntfile.js that shows service worker generation in Grunt. Though, it doesn't run a server on localhost. Here's a simpler gulp example for a basic use case. It assumes your site's resources are located under app and that you'd like to cache all your JavaScript, HTML, CSS, and image files. This task will create app/service-worker.js, which your client pages need to register before it can take control of your site's pages. service-worker-registration.js is a ready-to- use script to handle registration. Considerations Service worker caching should be considered a progressive enhancement. If you follow the model of conditionally registering a service worker only if it's supported (determined by if('serviceWorker' in navigator)), you'll get offline support on browsers with service workers and on browsers that don't support service workers, the offline-specific code will never be called. There's no overhead/breakage for older browsers if you add sw-precache to your build. All resources that are precached will be fetched by a service worker running in a separate thread as soon as the service worker is installed. You should be judicious in what you list in the dynamicUrlToDependencies and staticFileGlobs options, since listing files that are non-essential (large images that are not shown on every page, for instance) will result in browsers downloading more data than is strictly necessary. Precaching doesn't make sense for all types of resources (see the previous point). Other caching strategies, like those outlined in the Offline Cookbook, can be used in conjunction with sw-precache to provide the best experience for your users. If you do implement additional caching logic, put the code in a separate JavaScript file and include it using the importScripts() method. sw-precache uses a cache-first strategy, which results in a copy of any cached content being returned without consulting the network. A useful pattern to adopt with this strategy is to display a toast/alert to your users when there's new content available, and give them an opportunity to reload the page to pick up that new content (which the service worker will have added to the cache, and will be available at the next page load). The sample service-worker-registration.js file illustrates the service worker lifecycle event you can listen for to trigger this message. Command-line interface For those who would prefer not to use sw-precache as part of a gulp or Grunt build, there's a command-line interface which supports the options listed in the API, provided via flags or an external JavaScript configuration file. Hypenated flags are converted to camelCase options. Options starting with --no prefix negate the boolean value. For example, --no-clients-claim sets the value of clientsClaim to false. Warning: When using sw-precache ""by hand"", outside of an automated build process, it's your responsibility to re-run the command each time there's a change to any local resources! If sw-precache is not run again, the previously cached local resources will be reused indefinitely. Sensible defaults are assumed for options that are not provided. For example, if you are inside the top-level directory that contains your site's contents, and you'd like to generate a service-worker.js file that will automatically precache all of the local files, you can simply run Alternatively, if you'd like to only precache .html files that live within dist/, which is a subdirectory of the current directory, you could run Note: Be sure to use quotes around parameter values that have special meanings to your shell (such as the * characters in the sample command line above, for example). Finally, there's support for passing complex configurations using --config <file>. Any of the options from the file can be overridden via a command-line flag. We strongly recommend passing it an external JavaScript file defining config via module.exports. For example, assume there's a path/to/sw-precache-config.js file that contains: That file could be passed to the command-line interface, while also setting the verbose option, via This provides the most flexibility, such as providing a regular expression for the runtimeCaching.urlPattern option. We also support passing in a JSON file for --config, though this provides less flexibility: Runtime Caching It's often desireable, even necessary to use precaching and runtime caching together. You may have seen our sw-toolbox tool, which handles runtime caching, and wondered how to use them together. Fortunately, sw-precache handles this for you. The sw-precache module has the ability to include the sw-toolbox code and configuration alongside its own configuration. Using the runtimeCaching configuration option in sw-precache (see below) is a shortcut that accomplishes what you could do manually by importing sw-toolbox in your service worker and writing your own routing rules. API Methods The sw-precache module exposes two methods: generate and write. generate(options, callback) generate takes in options, generates a service worker from them and passes the result to a callback function, which must have the following interface: callback(error, serviceWorkerString) In the 1.x releases of sw-precache, this was the default and only method exposed by the module. Since 2.2.0, generate() also returns a Promise. write(filePath, options, callback) write takes in options, generates a service worker from them, and writes the service worker to a specified file. This method always invokes callback(error). If no error was found, the error parameter will be null Since 2.2.0, write() also returns a Promise. Options Parameter Both the generate() and write() methods take the same options. cacheId [String] A string used to distinguish the caches created by different web applications that are served off of the same origin and path. While serving completely different sites from the same URL is not likely to be an issue in a production environment, it avoids cache-conflicts when testing various projects all served off of http://localhost. You may want to set it to, e.g., the name property from your package.json. Default: '' clientsClaim [Boolean] Controls whether or not the generated service worker will call clients.claim() inside the activate handler. Calling clients.claim() allows a newly registered service worker to take control of a page immediately, instead of having to wait until the next page navigation. Default: true directoryIndex [String] Sets a default filename to return for URL's formatted like directory paths (in other words, those ending in '/'). sw-precache will take that translation into account and serve the contents a relative directoryIndex file when there's no other match for a URL ending in '/'. To turn off this behavior, set directoryIndex to false or null. To override this behavior for one or more URLs, use the dynamicUrlToDependencies option to explicitly set up mappings between a directory URL and a corresponding file. Default: 'index.html' dontCacheBustUrlsMatching [Regex] It's very important that the requests sw-precache makes to populate your cache result in the most up-to-date version of a resource at a given URL. Requests that are fulfilled with out-of-date responses (like those found in your browser's HTTP cache) can end up being read from the service worker's cache indefinitely. Jake Archibald's blog post provides more context about this problem. In the interest of avoiding that scenario, sw-precache will, by default, append a cache-busting parameter to the end of each URL it requests when populating or updating its cache. Developers who are explicitly doing ""the right thing"" when it comes to setting HTTP caching headers on their responses might want to opt out of this cache-busting. For example, if all of your static resources already include versioning information in their URLs (via a tool like gulp-rev), and are served with long-lived HTTP caching headers, then the extra cache-busting URL parameter is not needed, and can be safely excluded. dontCacheBustUrlsMatching gives you a way of opting-in to skipping the cache busting behavior for a subset of your URLs (or all of them, if a catch-all value like /./ is used). If set, then the pathname of each URL that's prefetched will be matched against this value. If there's a match, then the URL will be prefetched as-is, without an additional cache-busting URL parameter appended. Note: Prior to sw-precache v5.0.0, dontCacheBustUrlsMatching matched against the entire request URL. As of v5.0.0, it only matches against the URL's pathname. Default: not set dynamicUrlToDependencies [ObjectString,Buffer,ArrayString] Maps a dynamic URL string to an array of all the files that URL's contents depend on. E.g., if the contents of /pages/home are generated server-side via the templates layout.jade and home.jade, then specify '/pages/home': ['layout.jade', 'home.jade']. The MD5 hash is used to determine whether /pages/home has changed will depend on the hashes of both layout.jade and home.jade. An alternative value for the mapping is supported as well. You can specify a string or a Buffer instance rather than an array of file names. If you use this option, then the hash of the string/Buffer will be used to determine whether the URL used as a key has changed. For example, '/pages/dynamic': dynamicStringValue could be used if the contents of /pages/dynamic changes whenever the string stored in dynamicStringValue changes. Default: {} handleFetch [boolean] Determines whether the fetch event handler is included in the generated service worker code. It is useful to set this to false in development builds, to ensure that features like live reload still work. Otherwise, the content would always be served from the service worker cache. Default: true ignoreUrlParametersMatching [ArrayRegex] sw-precache finds matching cache entries by doing a comparison with the full request URL. It's common for sites to support URL query parameters that don't affect the site's content and should be effectively ignored for the purposes of cache matching. One example is the utm_-prefixed parameters used for tracking campaign performance. By default, sw-precache will ignore key=value when key matches any of the regular expressions provided in this option. To ignore all parameters, use [/./]. To take all parameters into account when matching, use []. Default: [/^utm_/] importScripts [ArrayString] Writes calls to importScripts() to the resulting service worker to import the specified scripts. Default: [] logger [function] Specifies a callback function for logging which resources are being precached and a precache size. Use function() {} if you'd prefer that nothing is logged. Within a gulp script, it's recommended that you use gulp-util and pass in gutil.log. Default: console.log maximumFileSizeToCacheInBytes [Number] Sets the maximum allowed size for a file in the precache list. Default: 2097152 (2 megabytes) navigateFallback [String] Sets an HTML document to use as a fallback for URLs not found in the sw-precache cache. This fallback URL needs to be cached via staticFileGlobs or dynamicUrlToDependencies otherwise it won't work. This comes in handy when used with a web application that performs client-side URL routing using the History API. It allows any arbitrary URL that the client generates to map to a fallback cached HTML entry. This fallback entry ideally should serve as an ""application shell"" that is able to load the appropriate resources client-side, based on the request URL. Note: This is not intended to be used to route failed navigations to a generic ""offline fallback"" page. The navigateFallback page is used whether the browser is online or offline. If you want to implement an ""offline fallback"", then using an approach similar to this example is more appropriate. Default: '' navigateFallbackWhitelist [ArrayRegExp] Works to limit the effect of navigateFallback, so that the fallback only applies to requests for URLs with paths that match at least one RegExp. This option is useful if you want to fallback to the cached App Shell for certain specific subsections of your site, but not have that behavior apply to all of your site's URLs. For example, if you would like to have navigateFallback only apply to navigation requests to URLs whose path begins with /guide/ (e.g. https://example.com/guide/1234), the following configuration could be used: If set to [] (the default), the whitelist will be effectively bypassed, and navigateFallback will apply to all navigation requests, regardless of URL. Default: [] replacePrefix [String] Replaces a specified string at the beginning of path URL's at runtime. Use this option when you are serving static files from a different directory at runtime than you are at build time. For example, if your local files are under dist/app/ but your static asset root is at /public/, you'd strip 'dist/app/' and replace it with '/public/'. Default: '' runtimeCaching [ArrayObject] Configures runtime caching for dynamic content. If you use this option, the sw-toolbox library configured with the caching strategies you specify will automatically be included in your generated service worker file. Each Object in the Array needs a urlPattern, which is either a RegExp or a string, following the conventions of the sw-toolbox library's routing configuration. Also required is a handler, which should be either a string corresponding to one of the built-in handlers under the toolbox. namespace, or a function corresponding to your custom request handler. Optionally, method can be added to specify one of the supported HTTP methods (default: 'get'). There is also support for options, which corresponds to the same options supported by a sw-toolbox handler. For example, the following defines runtime caching behavior for two different URL patterns. It uses a different handler for each, and specifies a dedicated cache with maximum size for requests that match /articles/: The sw-precache + sw-toolbox explainer has more information about how and why you'd use both libraries together. Default: [] skipWaiting [Boolean] Controls whether or not the generated service worker will call skipWaiting() inside the install handler. By default, when there's an update to a previously installed service worker, then the new service worker delays activation and stays in a waiting state until all pages controlled by the old service worker are unloaded. Calling skipWaiting() allows a newly registered service worker to bypass the waiting state. When skipWaiting is true, the new service worker's activate handler will be called immediately, and any out of date cache entries from the previous service worker will be deleted. Please keep this in mind if you rely on older cached resources to be available throughout the page's lifetime, because, for example, you defer the loading of some resources until they're needed at runtime. Default: true staticFileGlobs [ArrayString] An array of one or more string patterns that will be passed in to glob. All files matching these globs will be automatically precached by the generated service worker. You'll almost always want to specify something for this. Default: [] stripPrefix [String] Removes a specified string from the beginning of path URL's at runtime. Use this option when there's a discrepancy between a relative path at build time and the same path at run time. For example, if all your local files are under dist/app/ and your web root is also at dist/app/, you'd strip that prefix from the start of each local file's path in order to get the correct relative URL. Default: '' stripPrefixMulti [Object] Maps multiple strings to be stripped and replaced from the beginning of URL paths at runtime. Use this option when you have multiple discrepancies between relative paths at build time and the same path at run time. If stripPrefix and replacePrefix are not equal to '', they are automatically added to this option. Default: {} templateFilePath [String] The path to the (lo-dash) template used to generate service-worker.js. If you need to add additional functionality to the generated service worker code, it's recommended that you use the importScripts option to include extra JavaScript rather than using a different template. But if you do need to change the basic generated service worker code, please make a copy of the original template, modify it locally, and use this option to point to your template file. Default: service-worker.tmpl (in the directory that this module lives in) verbose [boolean] Determines whether there's log output for each individual static/dynamic resource that's precached. Even if this is set to false, there will be a final log entry indicating the total size of all precached resources. Default: false Wrappers and Starter Kits While it's possible to use the sw-precache module's API directly within any JavaScript environment, several wrappers have been developed by members of the community tailored to specific build environments. They include: - sw-precache-webpack-plugin - sw-precache-brunch - grunt-sw-precache - exhibit-builder-sw-precache There are also several starter kits or scaffolding projects that incorporate sw-precache into their build process, giving you a full service worker out of the box. The include: CLIs polymer-cli create-react-pwa Starter Kits react-redux-universal-hot-example Polymer Starter Kit Web Starter Kit Recipes for writing a custom wrapper While there are not always ready-to-use wrappers for specific environments, this list contains some recipes to integrate sw-precache in your workflow: Gradle wrapper for offline JavaDoc Brunch starter for Phoenix Framework Acknowledgements Thanks to Sindre Sorhus and Addy Osmani for their advice and code reviews. Jake Archibald was kind enough to review the service worker logic. License Copyright 2017 Google, Inc. Licensed under the Apache License, Version 2.0 (the ""License""); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
4296,"AndroidAndroidStudio ,MVP,EventBus,,ORM,(HTTPClint,Volley,OkHttps),,(AndroidAnnotations),xutils,,:http://www.lcode.org CSDNhttp://blog.csdn.net/developer_jiangqq ,!,! - : -36KrApp,36Kr ,,,,,,, : 1.Android 5.0(RecyclerView,CardView); 2.:Okhttp,Volley,UIL,Fresco,EventBus.... 3.; 4., 5., 6.APP http://www.cniao5.com/clazz/news.html :jiangqqlmj@163.com /QQ:781931404 Android:99787482 Android1:107086751 Android3:109244103 # FastDev4Android AndroidAndroidStudio ,ORM,(HTTPClint,Volley,OkHttps),,,xutils, . : FastDev4Android libs jar adapter applicationapplication base cache common, db event fragmentfragment html5webview,webview jsonjson listlogic location model push sensor spreferenceSharedPerference test uiActivity UI updateAPP utils widget crash receiver 20151201: .Tab; HorizontalScrollView,Fragment,FragmentStatePagerAdapterTab() DesignTabLayoutTab() CSDN! 20151119: .RecyclerView; RecyclerView,() RecyclerViewGallery() RecyclerViewAA(Android Annotations)() RecyclerViewSwipeRefreshLayout() CardViewRecyclerView() SwipeRefreshLayout+RecyclerView+CardView() .ViewDragHelper; ViewDragHelper,ViewGroupView~() ViewDragHelperQQ5.X() 20151110: .Volley; Volley,Volley,; Volley() Volley() 20151101: AVLoadingIndicatorView() Android MVP() EventBus() EventBusOtto() TextDrawable() WebViewJavaScript() BaseAdapterHelper,Adapter() BaseAdapterHelper,Adapter() 20151029: AndroidAnnotations: AndroidAnnnotationsAndroid Studios() AndroidAnnnotations() AndroidAnnnotationsComponents() AndroidAnnnotationsInjection() AndroidAnnnotationsEvent Binding() AndroidAnnnotationsThreading() AndroidAnnnotationsRoboGuice() AndroidAnnnotationsOtto() AndroidAnnnotationsOrmLite() AndroidAnnnotationsAdapterslists() AndroidAnnnotationsSharedPreferences() V1.1.1_003: .; .MVPDemo; MainActivity; V1.1_002: .(AutoGallery+FlowIndicator); .(PullToRefreshListView); .(ACache); .(CustomCrash); MainActivity; V1.0_001: .Utils 1.DataUtils 2.GuideUtils 3.IoUtils HTTPClient Android 6.0, libsorg.apache.http.legcy.jar 4.JudgeNetWorker 5.Log 6.ManagerActivity Activity 7.StrUtils ) .sperferencesSharePerferencesSP .ActivityBaseActivityBaseFrameActivity Toast,LayoutInFlater,Activity Android~ QQ:781931404 "
4062,"Minify font seamlessly fontmin Minify font seamlessly Homepage English Install Usage You can use gulp-rename to rename your files: API new Fontmin() Creates a new Fontmin instance. .src(file) Type: Array|Buffer|String Set the files to be optimized. Takes a buffer, glob string or an array of glob strings as argument. .dest(folder) Type: String Set the destination folder to where your files will be written. If you don't set any destination no files will be written. .use(plugin) Type: Function Add a plugin to the middleware stack. .run(cb) Type: Function Optimize your files with the given settings. cb(err, files, stream) The callback will return an array of vinyl files in files and a Readable/Writable stream in stream Plugins The following plugins are bundled with fontmin: glyph Compress ttf by glyph. ttf2eot Convert ttf to eot. ttf2woff Convert ttf to woff. ttf2svg Convert ttf to svg. css Generate css from ttf, often used to make iconfont. svg2ttf Convert font format svg to ttf. svgs2ttf Concat svg files to a ttf, just like css sprite. otf2ttf Convert otf to ttf. .glyph() Compress ttf by glyph. .ttf2eot() Convert ttf to eot. .ttf2woff() Convert ttf to woff. .ttf2svg() Convert ttf to svg. you can use imagemin-svgo to compress svg: .css() Generate css from ttf, often used to make iconfont. Alternatively, a transform function can be passed as fontFamily option. .svg2ttf() Convert font format svg to ttf. .svgs2ttf() Concat svg files to a ttf, just like css sprite. awesome work with css plugin: .otf2ttf() Convert otf to ttf. CLI you can use curl to generate font for websites running on PHP, ASP, Rails and more: or you can use html-to-text to make it smaller: what is more, you can use phantom-fetch-cli to generate font for SPA running JS template: Related fontmin-app gulp-fontmin fonteditor Thanks imagemin free chinese font License MIT fontmin"
248,"Grunt: The JavaScript Task RunnerGrunt: The JavaScript Task Runner Documentation Visit the gruntjs.com website for all the things. Support / Contributing Before you make an issue, please read our Contributing guide. You can find the grunt team in #grunt on irc.freenode.net. Release History See the CHANGELOG. License MIT"
4784,"Cast android code and resource changes to the running application through ADB.Android SDK sucks. It's so slow to build and run which waste me a lot of time every day. Motivation Facebook Buck http://github.com/facebook/buck build is fast. However, the biggest problem with Buck is, it requires you to change a lot of codes, and restructs your project in small modules. Indeed, it is troublesome to just make it work properly on the existing android project, especially if you have big project. I have tried using Buck build system instead of Gradle on my test project. However, it took me a week just to make it work. What I needs is a build tool that is easy to setup, fast as Buck, and provide a Run button in Android Studio. So I created LayoutCast. LayoutCast is a little tool to help with that, it will cast every changes in your Java source code or resources (including library project) to your phone or emulator within 5 sec, and does not restart your application. Youtube demo video: https://youtu.be/rc04LK2_suU : http://v.youku.com/v_show/id_XMTMwNTUzOTQ3Mg Features Fast cast code and resource changes, usually less than 5 sec. Cast does not reset your application. The running activity stack will be kept. Easy to setup, only add few lines of code. Support both eclipse and AndroidStudio project. Provide a AndroidStudio plugin to click and cast. Limitations ~~LayoutCast only support Mac (for now)~~ Cast Java code only support ART runtime (Android 5.0) Benchmarks Here is how it compared to Gradle and Facebook Buck: The test machine is a 2015 MBP with a 2014 MotoX. The test project's apk is about 14.3MB, which contains 380k lines of java code and 86k lines of xml files. Getting Started for Android Studio / Intellij 1. Install Plugin If you have already done that, you can skip this step. Download Android Studio / Intellij plugin https://github.com/mmin18/LayoutCast/raw/master/ide/IDEAPlugin/IDEAPlugin.jar In Android Studio, go to Preferences > Plugins > Install plugin from disk... Choose the downloaded file from step #1 to install the plugin. After restart, you should find a button at right of the run section: 2. Android Project & Build System Changes First, you need to setup your project. Add below dependency in your build.gradle: dependencies { compile 'com.github.mmin18.layoutcast:library:1.+@aar' ... } Second, add the following code in your main application class inside onCreate() method. And since LayoutCast only necessary when you develop, you should always check if BuildConfig.DEBUG == true. public class MyApplication extends Application { @Override public void onCreate() { super.onCreate(); if (BuildConfig.DEBUG) { LayoutCast.init(this); } } } Thrid, don't forget to check if your Application class is registered in AndroidManifest.xml: <application android:name="".MyApplication"" ... Fourth, add special activity class (from LayoutCast library) called ResetActivity in your manifest, this activity will be used to restart and restore our application activity stack. <activity android:name=""com.github.mmin18.layoutcast.ResetActivity"" /> And make sure you have the network permission in your AndroidManifest.xml: <uses-permission android:name=""android.permission.INTERNET"" /> 3. Run and cast Run the application (in device or emulator), then try to make some changes for resources file or java file. After that, click the LayoutCast button in toolbar (on the right of Run button) / go to menu Tools> Layout Cast. It will show the result above status bar: Getting started for Eclipse 1. Prepare the cast script I haven't written the Eclipse plugin yet, so if you need to use it on a eclipse project, you can try to use the command line. You can get the script here https://raw.githubusercontent.com/mmin18/LayoutCast/master/cast.py. Put the script in project root dir or anywhere you like. Since it is written in Python 2.7 (make sure you have installed the right version). 2. Android Project & Build System Changes To get it work, we will need to download the LayoutCast library https://github.com/mmin18/LayoutCast/raw/master/libs/lcast.jar and put it to your /libs folder. The project structure will remain the same. 3. Run and Cast Run the application first, and open terminal and execute python cast.py under your project's folder: cd <project path> python cast.py Or you can specify the path in args: python cast.py <project path> How it Works When LayoutCast.init(context); called, the application will start tiny http server in the background, and receive certain commands. Later on, the cast script running on your computer will communicate with your running app which is running through ADB TCP forward. When the cast script runs, it will scan all possible ports on your phone to find the running LayoutCast server, and get the running application's resource list with its id, then compiled to public.xml. In which, it will be used later to keep resource id index consistent with the running application. The cast script scans your project folder to find the /res folder, and all dependencies inside /res folder. You can run the aapt command to package all resources into res.zip, and then upload the zip file to the LayoutCast server to replace the resources of the running process. Then, it calls the Activity.recreate() to restart the visible activity. Usually the activity will keep its running state in onSaveInstanceState() and restore after coming back later. Troubleshootings It can only find /src folder under <project>/src or <project>/src/main/java It can only find /res folder under <project>/res or <project>/src/main/res You can add or replace resources, but you can't delete or rename resources (for now) If cast failed, clean your project, remove /bin and /build and rebuild again may solve the problem"
3091,"A minimalistic ClojureScript interface to React.js A simple ClojureScript interface to React. Reagent provides a way to write efficient React components using (almost) nothing but plain ClojureScript functions. Detailed intro with live examples News Documentation, latest release Documentation, next release: API docs, Tutorials and FAQ Community discussion and support channels #reagent channel in Clojure Slack Reagent Project Mailing List Commercial video material Learn Reagent Free, Learn Reagent Pro (Affiliate link, $30 discount) Learn Re-frame Free, Learn Re-frame Pro (Affiliate link, $30 discount) purelyfunctional.tv Lambda Island Videos Usage To create a new Reagent project using Leiningen template simply run: lein new reagent myproject If you wish to only create the assets for ClojureScript without a Clojure backend then do the following instead: lein new reagent-frontend myproject This will setup a new Reagent project with some reasonable defaults, see here for more details. To use Reagent in an existing project you add this to your dependencies in project.clj: This is all you need to do if you want the standard version of React. If you want to use your own build of React (or React from a CDN), you have to use :exclusions variant of the dependency, and also provide react and react-dom namespaces (by creating .cljs files with just ns form, or by adding your own :foreign-libs entries). [reagent ""0.x.x"" :exclusions [cljsjs/react cljsjs/react-dom]] Examples Reagent uses Hiccup-like markup instead of React's sort-of html. It looks like this: Reagent extends standard Hiccup in one way: it is possible to ""squeeze"" elements together by using a > character. can be written as: Since version 0.8: The :class attribute also supports collections of classes, and nil values are removed: You can use one component inside another: And pass properties from one component to another: You mount the component into the DOM like this: assuming we have imported Reagent like this: State is handled using Reagent's version of atom, like this: Any component that dereferences a reagent.core/atom will be automatically re-rendered. If you want to do some setting up when the component is first created, the component function can return a new function that will be called to do the actual rendering: This way you can avoid using React's lifecycle callbacks like getInitialState and componentWillMount most of the time. But you can still use them if you want to, either using reagent.core/create-class or by attaching meta-data to a component function: See the examples directory for more examples. Performance React is pretty darn fast, and so is Reagent. It should even be faster than plain old javascript React a lot of the time, since ClojureScript allows us to skip a lot of unnecessary rendering (through judicious use of React's shouldComponentUpdate). The ClojureScript overhead is kept down, thanks to lots of caching. Code size is a little bigger than React.js, but still quite small. The todomvc example clocks in at roughly 79K gzipped, using advanced compilation. About The idea and some of the code for making components atom-like comes from pump. The reactive-atom idea (and some code) comes from reflex. The license is MIT."
3074,"Hide screen when boss is approaching.BossSensor Hide your screen when your boss is approaching. Demo The boss stands up. He is approaching. When he is approaching, the program fetches face images and classifies the image. If the image is classified as the Boss, it will monitor changes. Requirements WebCamera Python3.5 OSX Anaconda Lots of images of your boss and other person image Put images into data/boss and data/other. Usage First, Train boss image. Second, start BossSensor. Install Install OpenCV, PyQt4, Anaconda. Change Keras backend from Theano to TensorFlow. Licence MIT Author Hironsan"
4533,"Go Training Class Material :Go Training Review our different courses and material To learn about Corporate training events, options and special pricing please contact: William Kennedy ArdanLabs (www.ardanlabs.com) bill@ardanlabs.com Purchase Video Experience Teachers More About Go Minimal Qualified Student Important Reading Before You Come To Class Starter Material Get The Training Material Purchase Video The entire training class has been recorded to be made available to those who can't have the class taught at their company or who can't attend a conference. This is the entire class material. education.ardanlabs.com Our Experience We have taught Go to thousands of developers all around the world since 2014. There is no other company that has been doing it longer and our material has proven to help jump-start developers 6 to 12 months ahead of their knowledge of Go. We know what knowledge developers need in order to be productive and efficient when writing software in Go. Our classes are perfect for intermediate-level developers who have at least a few months to years of experience writing code in Go. Our classes provide a very deep knowledge of the programming langauge with a big push on language mechanics, design philosophies and guidelines. We focus on teaching how to write code with a priority on consistency, integrity, readability and simplicity. We cover a lot about if performance matters with a focus on mechanical sympathy, data oriented design, decoupling and writing/debugging production software. Our Teachers William Kennedy (@goinggodotnet) William Kennedy is a managing partner at Ardan Labs in Miami, Florida. Ardan Labs is a high-performance development and training firm working with startups and fortune 500 companies. He is also a co-author of the book Go in Action, the author of the blog GoingGo.Net, and a founding member of GoBridge which is working to increase Go adoption through diversity. Video Training Ultimate Go Video Ardan Labs YouTube Channel Blog Going Go Writing Running MongoDB Queries Concurrently With Go Go In Action Articles IT World Canada Video Dgrpah Day (2021) - Getting Started With Dgraph and GraphQL GDN Event #1 (2021) - GoBridge Needs Your Help Training Within The Go Community (2019) GopherCon Australia (2019) - Modules Golab (2019) - You Want To Build a Web Service? GopherCon Singapore (2019) - Garbage Collection Semantics GopherCon India (2019) - Channel Semantics GoWayFest Minsk (2018) - Profiling Web Apps GopherChina (2018) - Composition In Go William GopherCon Singapore (2018) - Optimizing For Correctness GopherCon India (2018) - What is the Legacy You Are Leaving Behind Code::Dive (2017) - Optimizing For Correctness Code::Dive (2017) - Go: Concurrency Design dotGo (2017) - Behavior Of Channels GopherCon Singapore (2017) - Escape Analysis Capital Go (2017) - Concurrency Design GopherCon India (2017) - Package Oriented Design GopherCon India (2015) - Go In Action GolangUK (2016) - Dependency Management GothamGo (2015) - Error Handling in Go GopherCon (2014) - Building an analytics engine Prague Meetup (2021) - Go Module Engineering Decisions Practical Understanding Of Scheduler Semantics (2021) Go Generics Draft Proposal (2020) Hack Potsdam (2017) - Tech Talk with William Kennedy Chicago Meetup (2016) - An Evening Vancouver Meetup (2016) - Go Talk & Ask Me Anything With William Kennedy Vancouver Meetup (2015) - Compiler Optimizations in Go Bangalore Meetup (2015) - OOP in Go GoSF Meetup - The Nature of Constants in Go London Meetup - Mechanical Sympathy Vancouver Meetup - Decoupling From Change Podcasts Ardan Labs Podcast: On Going Series GoTime: Design Philosophy GoTime: Learning and Teaching Go GoTime: Bill Kennedy on Mechanical Sympathy GoTime: Discussing Imposter Syndrome HelloTechPros: Your Tech Interviews are Scaring Away Brilliant People HelloTechPros: The 4 Cornerstones of Writing Software More About Go Go is an open source programming language that makes it easy to build simple, reliable, and efficient software. Although it borrows ideas from existing languages, it has a unique and simple nature that make Go programs different in character from programs written in other languages. It balances the capabilities of a low-level systems language with some high-level features you see in modern languages today. This creates a programming environment that allows you to be incredibly productive, performant and fully in control; in Go, you can write less code and do so much more. Go is the fusion of performance and productivity wrapped in a language that software developers can learn, use and understand. Go is not C, yet we have many of the benefits of C with the benefits of higher level programming languages. The Ecosystem of the Go Programming Language - Henrique Vicente The Why of Go - Carmen Andoh Go Ten Years and Climbing - Rob Pike The eigenvector of ""Why we moved from language X to language Y"" - Erik Bernhardsson Learn More - Go Team Simplicity is Complicated - Rob Pike Getting Started In Go - Aarti Parikh Minimal Qualified Student The material has been designed to be taught in a classroom environment. The code is well commented but missing some of the contextual concepts and ideas that will be covered in class. Students with the following minimal background will get the most out of the class. Studied CS in school or has a minimum of two years of experience programming full time professionally. Familiar with structural and object oriented programming styles. Has worked with arrays, lists, queues and stacks. Understands processes, threads and synchronization at a high level. Operating Systems Has worked with a command shell. Knows how to maneuver around the file system. Understands what environment variables are. Important Reading Please check out this page of important reading. You will find articles and videos around mechanical sympathy, data-oriented design, Go runtime and optimizations and articles about the history of computing. Before You Come To Class The following is a set of tasks that can be done prior to showing up for class. We will also do this in class if anyone has not completed it. However, the more attendees that complete this ahead of time the more time we have to cover additional training material. Prep Work Reading Material http://go.dev/ https://www.ardanlabs.com/blog/ Exercises https://tour.golang.org/welcome/1 https://gophercises.com/ Books https://www.manning.com/books/go-in-action https://bitfieldconsulting.com/books/fundamentals Joining the Go Slack Community We use a slack channel to share links, code, and examples during the training. This is free. This is also the same slack community you will use after training to ask for help and interact with may Go experts around the world in the community. Using the following link, fill out your name and email address: https://gophersinvite.herokuapp.com/ Check your email, and follow the link to the slack application. Join the training channel by clicking on this link: https://gophers.slack.com/messages/training/ Click the Join Channel button at the bottom of the screen. Installing Go Local Installation https://www.ardanlabs.com/blog/2016/05/installing-go-and-your-workspace.html Editors Visual Studio Code https://code.visualstudio.com/Updates https://github.com/microsoft/vscode-go VIM http://www.vim.org/download.php http://farazdagi.com/blog/2015/vim-as-golang-ide/ Goland https://www.jetbrains.com/go/ Installing the Training Material While many of the examples can be done using the online playground (http://play.golang.org), some may find it easier to complete them with their local editor. To do so, you will want to load the training material locally to your machine. From a command prompt, issue the following commands: NOTE: This assumes you have Git installed. If you dont, you can find the installation instructions here: https://git-scm.com/ Twitter Jessie Frazelle (@frazelledazzell) ""@goinggodotnet you were amazing!!! So enthusiastic!!! Thanks for doing this for everyone!"" Kelsey Hightower (@kelseyhightower) ""Day 1 of the [Ultimate] Go workshop was outstanding! Big shoutout to @intel, @golangbridge, and @goinggodotnet for bringing this to Portland."" Katrina Owen (@kytrinyx) ""OH: ""You thought you knew Go..."" (You do Go? You want to do Go?) You should take this workshop. Seriously.) "" Ian Molee (@ianfoo) ""If you're at @GopherCon, get yourself to a session with @goinggodotnet. Superb! Pretty sure his pic appears with the definition of ""dynamo."""" Matt Oswalt (@Mierdin) ""Should be mentioned that though I am no expert, I have been using Go for about a year - and this meetup is kicking my ass."" Testimonials Paul Yeoh _""Todays workshop was just mind blowing! You kept us all on the edge all day long - it was the most exhilarating all day workshop I have attended, period. The content was inspiring, moving - caused me to think deeply and gave me a lot of meat to chew on about what it is we are really doing as programmers, what an awesome day! And most of all, I just got such a kick out of the energy which you were putting out - larger than life, it felt like you were turned up to 200%. I really took a lot from it at many levels. Thank you!!""_ Ana-Maria Lazar, Software Engineer at Sainsbury's ""Intensive crash course in Go that literally takes you to a whole new level. Not only Bill provides lots of examples and exercises to familiarize yourself faster with the language but there is also a lot of information that can be applied to other languages as well. Perfect combination!"" Susan Dady, Software Engineer - GE Digital ""Rarely will you come across a course as worthwhile as this one. I learned many things relevant and useful in my daily work and William's energy kept me engaged. I came back to work excited to get coding in Go."" Richard Stanley, Software Engineer - GE Digital ""Not only does Bill deeply understands the technical details of Go, he also can explain them in an effective, enthusiastic manner that helped me retain somewhat dry material. His passion for the language and its capabilities are obvious through out his training."" Shalab Goel, Ph.D. ""It was a pleasure taking this course learning lot of ""dry"" stuff in such animated and enthusiastic environment. The exercises were spot on for building what you called as ""memory muscle. I have good amount of background in conventional multithreaded and distributed environments, but I have not put that knowledge to use more recently; so it was good refresher from that point of view as well. From Yuck to completely Wow-ed is how I will like to describe my respect for Go within three days. I knew nothing about GO before the course."" Geoff Clitheroe (@gclitheroe) ""Your training is awesome! Myself and three colleagues recently caught variations of the training at GopherCon and OSCON. We all thought the Bootcamp was the best thing at any of these conferences (and I went to both). Awesome work to Bill for presenting and anyone involved in developing the training. I really liked the structure, emphasis on deeper understanding, me doing a small number of examples to emphasize this, and general content. Night and day to other training which is to often just watching someone else live code. Great work."" ACL Services (@ACLServices) ""I'd just like to thank you again for just a phenomenal training session. The feedback from everyone was overwhelmingly positive. You probably could tell first hand that there were skeptics at first, but you've turned many into golang converts and we are really excited in growing golang adoption internally."" Joshua Shuster (@naysaier) ""I would consider Ardan Studio's 3 day course to be invaluable. Bill and his staff, being some of the foremost authorities in the Go language, were able to make many of the complex go topics understandable. Covering everything from memory management, all the way up to building concurrency programs and web API's. It has given me the knowledge to write idiomatic Go, and make the best use of its features. I would highly their courses to anyone new to Go, or to anyone wanting to widen their existing knowledge."" Neeru Dwivedi ""I attended the one day workshop by Bill Kennedy from Ardan Labs. I was in for a surprise as before the workshop I was concerned whether I would understand concepts and whether I would be able to follow along. Bill has this wonderful way of explaining concepts and his knowledge on the concepts is so good that, I didn't feel that I was learning something new & complicated. The Go Workshop got me started on the Go language. This workshop is perfect for beginners and anyone who wants to learn more about Go. I highly recommend this."" Todd Rafferty (@webrat) ""I highly recommend William Kennedy / Ardan Lab for Go Training. William is extremely passionate about the Go language and his energy feeds into his training. Very professional, very informative. My favorite section of his training, if I had to pick, was the segment on MultiWriters. I highly recommend a 3 day course, over a 2 day course. Even after the classes were over, William was always responsive with additional questions via various social media channels."" Georgi Knox (@GeorgiCodes) ""The Intro to Go Workshop enabled me to come into class with very little knowledge of Go and leave having a firm grasp of the key concepts of the language. Each topic was followed up with hands-on coding problems which helped to solidify what I was learning. My teacher Bill was not only approachable, but very excited about the language and his enthusiasm was contagious. I enjoyed that we talked about some of the lower level implementation details of Go which was something that I had found lacking from some books on the language. Overall I would highly recommend this workshop to anyone looking to learn Go quickly and effectively."" All material is licensed under the Apache License Version 2.0, January 2004."
4234,"Simple Dynamic Strings library for CSimple Dynamic Strings Notes about version 2: this is an updated version of SDS in an attempt to finally unify Redis, Disque, Hiredis, and the stand alone SDS versions. This version is NOT* binary compatible with SDS verison 1, but the API is 99% compatible so switching to the new lib should be trivial. Note that this version of SDS may be a slower with certain workloads, but uses less memory compared to V1 since header size is dynamic and depends to the string to alloc. Moreover it includes a few more API functions, notably sdscatfmt which is a faster version of sdscatprintf that can be used for the simpler cases in order to avoid the libc printf family functions performance penalty. How SDS strings work SDS is a string library for C designed to augment the limited libc string handling functionalities by adding heap allocated strings that are: Simpler to use. Binary safe. Computationally more efficient. But yet... Compatible with normal C string functions. This is achieved using an alternative design in which instead of using a C structure to represent a string, we use a binary prefix that is stored before the actual pointer to the string that is returned by SDS to the user. +--------+-------------------------------+-----------+ | Header | Binary safe C alike string... | Null term | +--------+-------------------------------+-----------+ | `-> Pointer returned to the user. Because of meta data stored before the actual returned pointer as a prefix, and because of every SDS string implicitly adding a null term at the end of the string regardless of the actual content of the string, SDS strings work well together with C strings and the user is free to use them interchangeably with other std C string functions that access the string in read-only. SDS was a C string I developed in the past for my everyday C programming needs, later it was moved into Redis where it is used extensively and where it was modified in order to be suitable for high performance operations. Now it was extracted from Redis and forked as a stand alone project. Because of its many years life inside Redis, SDS provides both higher level functions for easy strings manipulation in C, but also a set of low level functions that make it possible to write high performance code without paying a penalty for using an higher level string library. Advantages and disadvantages of SDS Normally dynamic string libraries for C are implemented using a structure that defines the string. The structure has a pointer field that is managed by the string function, so it looks like this: SDS strings as already mentioned don't follow this schema, and are instead a single allocation with a prefix that lives before the address actually returned for the string. There are advantages and disadvantages with this approach over the traditional approach: Disadvantage #1: many functions return the new string as value, since sometimes SDS requires to create a new string with more space, so the most SDS API calls look like this: As you can see s is used as input for sdscat but is also set to the value returned by the SDS API call, since we are not sure if the call modified the SDS string we passed or allocated a new one. Not remembering to assign back the return value of sdscat or similar functions to the variable holding the SDS string will result in a bug. Disadvantage #2: if an SDS string is shared in different places in your program you have to modify all the references when you modify the string. However most of the times when you need to share SDS strings it is much better to encapsulate them into structures with a reference count otherwise it is too easy to incur into memory leaks. Advantage #1: you can pass SDS strings to functions designed for C functions without accessing a struct member or calling a function, like this: In most other libraries this will be something like: Or: Advantage #2: accessing individual chars is straightforward. C is a low level language so this is an important operation in many programs. With SDS strings accessing individual chars is very natural: With other libraries your best chance is to assign string->buf (or call the function to get the string pointer) to a char pointer and work with this. However since the other libraries may reallocate the buffer implicitly every time you call a function that may modify the string you have to get a reference to the buffer again. Advantage #3: single allocation has better cache locality. Usually when you access a string created by a string library using a structure, you have two different allocations for the structure representing the string, and the actual buffer holding the string. Over the time the buffer is reallocated, and it is likely that it ends in a totally different part of memory compared to the structure itself. Since modern programs performances are often dominated by cache misses, SDS may perform better in many workloads. SDS basics The type of SDS strings is just the char pointer char *. However SDS defines an sds type as alias of char * in its header file: you should use the sds type in order to make sure you remember that a given variable in your program holds an SDS string and not a C string, however this is not mandatory. This is the simplest SDS program you can write that does something: The above small program already shows a few important things about SDS: SDS strings are created, and heap allocated, via the sdsnew() function, or other similar functions that we'll see in a moment. SDS strings can be passed to printf() like any other C string. SDS strings require to be freed with sdsfree(), since they are heap allocated. Creating SDS strings There are many ways to create SDS strings: The sdsnew function creates an SDS string starting from a C null terminated string. We already saw how it works in the above example. The sdsnewlen function is similar to sdsnew but instead of creating the string assuming that the input string is null terminated, it gets an additional length parameter. This way you can create a string using binary data: Note: sdslen return value is casted to int because it returns a size_t type. You can use the right printf specifier instead of casting. The sdsempty() function creates an empty zero-length string: The sdsdup() function duplicates an already existing SDS string: Obtaining the string length In the examples above we already used the sdslen function in order to get the length of the string. This function works like strlen of the libc except that: It runs in constant time since the length is stored in the prefix of SDS strings, so calling sdslen is not expensive even when called with very large strings. The function is binary safe like any other SDS string function, so the length is the true length of the string regardless of the content, there is no problem if the string includes null term characters in the middle. As an example of the binary safeness of SDS strings, we can run the following code: Note that SDS strings are always null terminated at the end, so even in that case s[4] will be a null term, however printing the string with printf would result in just ""A"" to be printed since libc will treat the SDS string like a normal C string. Destroying strings The destroy an SDS string there is just to call sdsfree with the string pointer. Note that even empty strings created with sdsempty need to be destroyed as well otherwise they'll result into a memory leak. The function sdsfree does not perform any operation if instead of an SDS string pointer, NULL is passed, so you don't need to check for NULL explicitly before calling it: Concatenating strings Concatenating strings to other strings is likely the operation you will end using the most with a dynamic C string library. SDS provides different functions to concatenate strings to existing strings. The main string concatenation functions are sdscatlen and sdscat that are identical, the only difference being that sdscat does not have an explicit length argument since it expects a null terminated string. Sometimes you want to cat an SDS string to another SDS string, so you don't need to specify the length, but at the same time the string does not need to be null terminated but can contain any binary data. For this there is a special function: Usage is straightforward: Sometimes you don't want to append any special data to the string, but you want to make sure that there are at least a given number of bytes composing the whole string. The sdsgrowzero function will do nothing if the current string length is already len bytes, otherwise it will enlarge the string to len just padding it with zero bytes. Formatting strings There is a special string concatenation function that accepts a printf alike format specifier and cats the formatted string to the specified string. Example: Often you need to create SDS string directly from printf format specifiers. Because sdscatprintf is actually a function that concatenates strings, all you need is to concatenate your string to an empty string: You can use sdscatprintf in order to convert numbers into SDS strings: However this is slow and we have a special function to make it efficient. Fast number to string operations Creating an SDS string from an integer may be a common operation in certain kind of programs, and while you may do this with sdscatprintf the performance hit is big, so SDS provides a specialized function. Use it like this: Trimming strings and getting ranges String trimming is a common operation where a set of characters are removed from the left and the right of the string. Another useful operation regarding strings is the ability to just take a range out of a larger string. SDS provides both the operations with the sdstrim and sdsrange functions. However note that both functions work differently than most functions modifying SDS strings since the return value is void: basically those functions always destructively modify the passed SDS string, never allocating a new one, because both trimming and ranges will never need more room: the operations can only remove characters from the original string. Because of this behavior, both functions are fast and don't involve reallocation. This is an example of string trimming where newlines and spaces are removed from an SDS strings: Basically sdstrim takes the SDS string to trim as first argument, and a null terminated set of characters to remove from left and right of the string. The characters are removed as long as they are not interrupted by a character that is not in the list of characters to trim: this is why the space between ""my"" and ""string"" was preserved in the above example. Taking ranges is similar, but instead to take a set of characters, it takes to indexes, representing the start and the end as specified by zero-based indexes inside the string, to obtain the range that will be retained. Indexes can be negative to specify a position starting from the end of the string, so that -1 means the last character, -2 the penultimate, and so forth: sdsrange is very useful when implementing networking servers processing a protocol or sending messages. For example the following code is used implementing the write handler of the Redis Cluster message bus between nodes: Every time the socket of the node we want to send the message to is writable we attempt to write as much bytes as possible, and we use sdsrange in order to remove from the buffer what was already sent. The function to queue new messages to send to some node in the cluster will simply use sdscatlen in order to put more data in the send buffer. Note that the Redis Cluster bus implements a binary protocol, but since SDS is binary safe this is not a problem, so the goal of SDS is not just to provide an high level string API for the C programmer but also dynamically allocated buffers that are easy to manage. String copying The most dangerous and infamus function of the standard C library is probably strcpy, so perhaps it is funny how in the context of better designed dynamic string libraries the concept of copying strings is almost irrelevant. Usually what you do is to create strings with the content you want, or concatenating more content as needed. However SDS features a string copy function that is useful in performance critical code sections, however I guess its practical usefulness is limited as the function never managed to get called in the context of the 50k lines of code composing the Redis code base. The string copy function of SDS is called sdscpylen and works like that: As you can see the function receives as input the SDS string s, but also returns an SDS string. This is common to many SDS functions that modify the string: this way the returned SDS string may be the original one modified or a newly allocated one (for example if there was not enough room in the old SDS string). The sdscpylen will simply replace what was in the old SDS string with the new data you pass using the pointer and length argument. There is a similar function called sdscpy that does not need a length but expects a null terminated string instead. You may wonder why it makes sense to have a string copy function in the SDS library, since you can simply create a new SDS string from scratch with the new value instead of copying the value in an existing SDS string. The reason is efficiency: sdsnewlen will always allocate a new string while sdscpylen will try to reuse the existing string if there is enough room to old the new content specified by the user, and will allocate a new one only if needed. Quoting strings In order to provide consistent output to the program user, or for debugging purposes, it is often important to turn a string that may contain binary data or special characters into a quoted string. Here for quoted string we mean the common format for String literals in programming source code. However today this format is also part of the well known serialization formats like JSON and CSV, so it definitely escaped the simple goal of representing literals strings in the source code of programs. An example of quoted string literal is the following: The first byte is a zero byte while the last byte is a newline, so there are two non alphanumerical characters inside the string. SDS uses a concatenation function for this goal, that concatenates to an existing string the quoted string representation of the input string. The scscatrepr (where repr means representation) follows the usualy SDS string function rules accepting a char pointer and a length, so you can use it with SDS strings, normal C strings by using strlen() as len argument, or binary data. The following is an example usage: This is the rules sdscatrepr uses for conversion: \ and "" are quoted with a backslash. It quotes special characters '\n', '\r', '\t', '\a' and '\b'. All the other non printable characters not passing the isprint test are quoted in \x.. form, that is: backslash followed by x followed by two digit hex number representing the character byte value. The function always adds initial and final double quotes characters. There is an SDS function that is able to perform the reverse conversion and is documented in the Tokenization section below. Tokenization Tokenization is the process of splitting a larger string into smaller strings. In this specific case, the split is performed specifying another string that acts as separator. For example in the following string there are two substrings that are separated by the |-| separator: A more common separator that consists of a single character is the comma: In many progrems it is useful to process a line in order to obtain the sub strings it is composed of, so SDS provides a function that returns an array of SDS strings given a string and a separator. As usually the function can work with both SDS strings or normal C strings. The first two arguments s and len specify the string to tokenize, and the other two arguments sep and seplen the separator to use during the tokenization. The final argument count is a pointer to an integer that will be set to the number of tokens (sub strings) returned. The return value is a heap allocated array of SDS strings. The returned array is heap allocated, and the single elements of the array are normal SDS strings. You can free everything calling sdsfreesplitres as in the example. Alternativey you are free to release the array yourself using the free function and use and/or free the individual SDS strings as usually. A valid approach is to set the array elements you reused in some way to NULL, and use sdsfreesplitres to free all the rest. Command line oriented tokenization Splitting by a separator is a useful operation, but usually it is not enough to perform one of the most common tasks involving some non trivial string manipulation, that is, implementing a Command Line Interface for a program. This is why SDS also provides an additional function that allows you to split arguments provided by the user via the keyboard in an interactive manner, or via a file, network, or any other mean, into tokens. The sdssplitargs function returns an array of SDS strings exactly like sdssplitlen. The function to free the result is also identical, and is sdsfreesplitres. The difference is in the way the tokenization is performed. For example if the input is the following line: The function will return the following tokens: ""call"" ""Sabrina"" ""and"" ""Mark Smith\n"" Basically different tokens need to be separated by one or more spaces, and every single token can also be a quoted string in the same format that sdscatrepr is able to emit. String joining There are two functions doing the reverse of tokenization by joining strings into a single one. The two functions take as input an array of strings of length argc and a separator and its length, and produce as output an SDS string consisting of all the specified strings separated by the specified separator. The difference between sdsjoin and sdsjoinsds is that the former accept C null terminated strings as input while the latter requires all the strings in the array to be SDS strings. However because of this only sdsjoinsds is able to deal with binary data. Error handling All the SDS functions that return an SDS pointer may also return NULL on out of memory, this is basically the only check you need to perform. However many modern C programs handle out of memory simply aborting the program so you may want to do this as well by wrapping malloc and other related memory allocation calls directly. SDS internals and advanced usage At the very beginning of this documentation it was explained how SDS strings are allocated, however the prefix stored before the pointer returned to the user was classified as an header without further details. For an advanced usage it is better to dig more into the internals of SDS and show the structure implementing it: As you can see, the structure may resemble the one of a conventional string library, however the buf field of the structure is different since it is not a pointer but an array without any length declared, so buf actually points at the first byte just after the free integer. So in order to create an SDS string we just allocate a piece of memory that is as large as the sdshdr structure plus the length of our string, plus an additional byte for the mandatory null term that every SDS string has. The len field of the structure is quite obvious, and is the current length of the SDS string, always computed every time the string is modified via SDS function calls. The free field instead represents the amount of free memory in the current allocation that can be used to store more characters. So the actual SDS layout is this one: +------------+------------------------+-----------+---------------\ | Len | Free | H E L L O W O R L D \n | Null term | Free space \ +------------+------------------------+-----------+---------------\ | `-> Pointer returned to the user. You may wonder why there is some free space at the end of the string, it looks like a waste. Actually after a new SDS string is created, there is no free space at the end at all: the allocation will be as small as possible to just hold the header, string, and null term. However other access patterns will create extra free space at the end, like in the following program: Since SDS tries to be efficient it can't afford to reallocate the string every time new data is appended, since this would be very inefficient, so it uses the preallocation of some free space every time you enlarge the string. The preallocation algorithm used is the following: every time the string is reallocated in order to hold more bytes, the actual allocation size performed is two times the minimum required. So for instance if the string currently is holding 30 bytes, and we concatenate 2 more bytes, instead of allocating 32 bytes in total SDS will allocate 64 bytes. However there is an hard limit to the allocation it can perform ahead, and is defined by SDS_MAX_PREALLOC. SDS will never allocate more than 1MB of additional space (by default, you can change this default). Shrinking strings Sometimes there are class of programs that require to use very little memory. After strings concatenations, trimming, ranges, the string may end having a non trivial amount of additional space at the end. It is possible to resize a string back to its minimal size in order to hold the current content by using the function sdsRemoveFreeSpace. There is also a function that can be used in order to get the size of the total allocation for a given string, and is called sdsAllocSize. NOTE: SDS Low level API use cammelCase in order to warn you that you are playing with the fire. Manual modifications of SDS strings void sdsupdatelen(sds s); Sometimes you may want to hack with an SDS string manually, without using SDS functions. In the following example we implicitly change the length of the string, however we want the logical length to reflect the null terminated C string. The function sdsupdatelen does just that, updating the internal length information for the specified string to the length obtained via strlen. Sharing SDS strings If you are writing a program in which it is advantageous to share the same SDS string across different data structures, it is absolutely advised to encapsulate SDS strings into structures that remember the number of references of the string, with functions to increment and decrement the number of references. This approach is a memory management technique called reference counting and in the context of SDS has two advantages: It is less likely that you'll create memory leaks or bugs due to non freeing SDS strings or freeing already freed strings. You'll not need to update every reference to an SDS string when you modify it (since the new SDS string may point to a different memory location). While this is definitely a very common programming technique I'll outline the basic ideas here. You create a structure like that: When new strings are created, the structure is allocated and returned with refcount set to 1. The you have two functions to change the reference count of the shared string: incrementStringRefCount will simply increment refcount of 1 in the structure. It will be called every time you add a reference to the string on some new data structure, variable, or whatever. decrementStringRefCount is used when you remove a reference. This function is however special since when the refcount drops to zero, it automatically frees the SDS string, and the mySharedString structure as well. Interactions with heap checkers Because SDS returns pointers into the middle of memory chunks allocated with malloc, heap checkers may have issues, however: The popular Valgrind program will detect SDS strings are possibly lost memory and never as definitely lost, so it is easy to tell if there is a leak or not. I used Valgrind with Redis for years and every real leak was consistently detected as ""definitely lost"". OSX instrumentation tools don't detect SDS strings as leaks but are able to correctly handle pointers pointing to the middle of memory chunks. Zero copy append from syscalls At this point you should have all the tools to dig more inside the SDS library by reading the source code, however there is an interesting pattern you can mount using the low level API exported, that is used inside Redis in order to improve performances of the networking code. Using sdsIncrLen() and sdsMakeRoomFor() it is possible to mount the following schema, to cat bytes coming from the kernel to the end of an sds string without copying into an intermediate buffer: sdsIncrLen is documented inside the source code of sds.c. Embedding SDS into your project This is as simple as copying the following files inside your project: sds.c sds.h sdsalloc.h The source code is small and every C99 compiler should deal with it without issues. Using a different allocator for SDS Internally sds.c uses the allocator defined into sdsalloc.h. This header file just defines macros for malloc, realloc and free, and by default libc malloc(), realloc() and free() are used. Just edit this file in order to change the name of the allocation functions. The program using SDS can call the SDS allocator in order to manipulate SDS pointers (usually not needed but sometimes the program may want to do advanced things) by using the API exported by SDS in order to call the allocator used. This is especially useful when the program linked to SDS is using a different allocator compared to what SDS is using. The API to access the allocator used by SDS is composed of three functions: sds_malloc(), sds_realloc() and sds_free(). Credits and license SDS was created by Salvatore Sanfilippo and is released under the BDS two clause license. See the LICENSE file in this source distribution for more information. Oran Agra improved SDS version 2 by adding dynamic sized headers in order to save memory for small strings and allow strings greater than 4GB."
3150,An object-oriented API for business analyticsdimple Dimple is an object-oriented API allowing you to create flexible axis-based charts using d3.js. The intention of this project is to allow analysts who are not necessarily expert JavaScript programmers to create standard (and some not-so-standard) business analytics. The API will also expose the core d3 objects where possible so that as users gain confidence they can extend the base functionality in whatever way they wish. Please visit the main website dimplejs.org for more information and examples.
3011,"Unopinionated utilities for resizeable split viewsSplit Unopinionated utilities for resizeable split views. Zero Deps Tiny: Each is between 1-2kb gzipped. Fast: No overhead or attached window event listeners, uses pure CSS for resizing. Unopinionated: Only compute view sizes. Everything else is up to you. Two utilities: Split.js - The original library, maintained since 2014, works with float and flex layouts. Supports all browsers. Split Grid - Successor to Split.js, for grid layouts. Supports modern browsers. Two React wrappers: React Split - Thin wrapper component for Split.js. React Split Grid - Thin wrapper component for Split Grid. Credits Contributors This project exists thanks to all the people who contribute. [Contribute]. Backers Thank you to all our backers! [Become a backer] Sponsors Support this project by becoming a sponsor. Your logo will show up here with a link to your website. [Become a sponsor] "
746,"CasperJS is no longer actively maintained. Navigation scripting and testing utility for PhantomJS and SlimerJSCasperJS Important note: the master branch hosts the development version of CasperJS, which is now pretty stable and should be the right version to use if you ask me. Users interested in a pretty stable, recent version working with PhantomJS 2.0 and newer should choose the packaged 1.1.0 and following releases. The 1.0 branch is now obsolete. Please note that - it is only recommended if you need to keep old production tests running that could do with the now unmaintained PhantomJS 1.9 - 1.0 tests unfortunately have to be run manually using the casperjs selftest command Note that all versions up to and including 1.1-beta3 do not support PhantomJS 2.0 and newer. The complete documentation for the current releases is hosted on docs.casperjs.org. CasperJS is a navigation scripting & testing utility for PhantomJS and SlimerJS (still experimental). It eases the process of defining a full navigation scenario and provides useful high-level functions, methods & syntactic sugar for doing common tasks such as: defining & ordering navigation steps filling forms clicking links capturing screenshots of a page (or an area) making assertions on remote DOM logging & events downloading resources, even binary ones catching errors and react accordingly writing functional test suites, exporting results as JUnit XML (xUnit) Browse the sample examples repository. Don't hesitate to pull request for any cool example of yours as well! Read the full documentation on casperjs documentation website. Subscribe to the project mailing-list Follow the CasperJS project on twitter and Google+. Show me some code! First install CasperJS, we'll use 1.1 beta here. Sample test to see if some dropdown can be opened: Run the script: Support Help request. If you're stuck using CasperJS and don't understand how to achieve something, please ask on the mailing-list first. If the discussion reveals that you have found a real issue that might need a change within CasperJS, file an issue. Filing issues. It takes a lot of time to review, validate, and de-duplicate filed issues. This time could be spent better on actually improving on CasperJS. Filing an issue might be a helpful contribution, but we expect you to read our CONTRIBUTING.md guidelines first. Professional Support. Need help with getting CasperJS up and running? Got a time-consuming problem you want to get solved quickly? Try to find someone to address your specific problem and post a reward at bountysource. If you need to have a known issue resolved and don't have the time or skills to do it on your own, you could post a reward for any open issue directly. Contributing Contributing code Please read the CONTRIBUTING.md file contents. Contributing documentation CasperJS's documentation is written using the Markdown format, and hosted on Github thanks to the Github Pages Feature. To view the source files on github, head to the gh-pages branch, and check the documentation's README for further instructions. Team Nicolas Perriault (@n1k0) Nick Currier (@hexid) Laurent Jouanneau (@laurentj) Mickal Andrieu (@mickaelandrieu) Matt DuVall (@mduvall) Ryan Null (@BIGjuevos) License MIT"
3103,"TileMill is a modern map design studioLatest Status - Feb 23, 2019 General Info TileMill is a modern map design studio powered by Node.js and Mapnik. TileMill is tested on Linux with Node 8.11.3 LTS, and on MacOS 10.14 with Node 8.15.0 lts/carbon TileMill currently only works in server mode, there is no standalone GUI. Your browser is used for the interface. There are no native packages provided. Installation requires cloning this repo. See details below under Installation. Tilemill should theoretically work on the Windows platform, but it isn't tested. Dependencies Mapnik > v3.6.2 (but may work on earlier versions) Node.js: (earlier Node.js versions may work, but are not tested) Ubuntu: v8.11.x OSX: v8.15.x lts/carbon Protobuf: Ubunto: these need to be installed: libprotobuf-lite and protoc Installation Quick installation instructions for OSX: git clone https://github.com/tilemill-project/tilemill.git cd tilemill nvm install lts/carbon nvm use v8.15.0 npm install npm start Full Installation instructions can be found in the TileMill Documentation. Build Status, Running Tests, Updating Documentation See CONTRIBUTING.md"
2905,"GitBucket iOS AppMVVMReactiveCocoa This repository contains the source code for the GitBucket iOS app. It's a mobile client app for GitHub, building with MVVM architectural pattern and some awesome frameworks, such as ReactiveCocoaMantleoctokit.objc, etc. You can use it for any purpose, free of charge. Purpose The purpose that I developing this app is hope to provide a complete app which is developed using the MVVM architectural pattern and RAC framework, and can help some iOS developers who want to use this technology. Now, GitBucket mainly include the following features: View Owned & Starred repos, repo's README and source code. View Followers & Following, Follow & Unfollow user. Search repos, Star & Unstar repo. The features is little now, but I will add more utility features at the iterative development in the future, such as ActivityGistsIssues, etc. Class diagram Requirements iOS 8.0+ CocoaPods 1.0+ Contribution If you want to make some contributions to this project or just want to build the project, please using the following command: Everything will be done for you, and all you need to do is just waiting for it to finished. Once finished, you can open the project through double-click the MVVMReactiveCocoa.xcworkspace file and build the MVVMReactiveCocoa target. Any pull request will be welcome. Common problems If you encountered the following error when you execute the git clone command: Please execute the following command and then retry the previous git clone command again: License MVVMReactiveCocoa is available under the MIT license. See the LICENSE file for more info. MVVM with ReactiveCocoa ReactiveCocoa v2.5 FunctorApplicative Monad"
2547,"A JavaScript PDF generation library for Node and the browserPDFKit A JavaScript PDF generation library for Node and the browser. Description PDFKit is a PDF document generation library for Node and the browser that makes creating complex, multi-page, printable documents easy. The API embraces chainability, and includes both low level functions as well as abstractions for higher level functionality. The PDFKit API is designed to be simple, so generating complex documents is often as simple as a few function calls. Check out some of the documentation and examples to see for yourself! You can also read the guide as a self-generated PDF with example output displayed inline. If you'd like to see how it was generated, check out the README in the docs folder. You can also try out an interactive in-browser demo of PDFKit here. Installation Installation uses the npm package manager. Just type the following command after installing npm. npm install pdfkit Features Vector graphics HTML5 canvas-like API Path operations SVG path parser for easy path creation Transformations Linear and radial gradients Text Line wrapping Text alignments Bulleted lists Font embedding Supports TrueType (.ttf), OpenType (.otf), WOFF, WOFF2, TrueType Collections (.ttc), and Datafork TrueType (.dfont) fonts Font subsetting See fontkit for more details on advanced glyph layout support. Image embedding Supports JPEG and PNG files (including indexed PNGs, and PNGs with transparency) Annotations Links Notes Highlights Underlines etc. AcroForms Outlines PDF security Encryption Access privileges (printing, copying, modifying, annotating, form filling, content accessibility, document assembly) Accessibility support (marked content, logical structure, Tagged PDF, PDF/UA) Coming soon! Patterns fills Higher level APIs for creating tables and laying out content More performance optimizations Even more awesomeness, perhaps written by you! Please fork this repository and send me pull requests. Example The PDF output from this example (with a few additions) shows the power of PDFKit producing complex documents with a very small amount of code. For more, see the demo folder and the PDFKit programming guide. Browser Usage There are three ways to use PDFKit in the browser: Use Browserify. See demo source code and build script Use webpack. See complete example. Use prebuilt version. Distributed as pdfkit.standalone.js file in the releases or in the package js folder. In addition to PDFKit, you'll need somewhere to stream the output to. HTML5 has a Blob object which can be used to store binary data, and get URLs to this data in order to display PDF output inside an iframe, or upload to a server, etc. In order to get a Blob from the output of PDFKit, you can use the blob-stream module. The following example uses Browserify or webpack to load PDFKit and blob-stream. See here and here for examples of prebuilt version usage. You can see an interactive in-browser demo of PDFKit here. Note that in order to Browserify a project using PDFKit, you need to install the brfs module with npm, which is used to load built-in font data into the package. It is listed as a devDependency in PDFKit's package.json, so it isn't installed by default for Node users. If you forget to install it, Browserify will print an error message. Documentation For complete API documentation and more examples, see the PDFKit website. License PDFKit is available under the MIT license."
2067,"Container view controller that leverages UIKit Dynamics to provide a realistic drawer navigation paradigm.Introduction MSDynamicsDrawerViewController was written by Eric Horacek for Monospace Ltd. What is it? MSDynamicsDrawerViewController is a container view controller that manages the presentation of a single ""pane"" view controller overlaid over one or two ""drawer"" view controllers. The drawer view controllers are hidden by default, but can be exposed by a user-initiated swipe in the direction that that drawer view controller is hidden in. It uses UIKit Dynamics for all animationthere's not a single call to animateWithDuration:animations: in the project. UIKit Dynamics? MSDynamicsDrawerViewController integrates with Apple's UIKit Dynamics APIs (new in iOS7) to provide a realistic new feel to the classic drawer navigation paradigm. While the .gifs below can do it some justice, it's best to just clone, build, and run the example project on a device to get a feel for it how it performs. So what can I do with it? Fling Open and Close Bounce Replace Installation Add the following to your Podfile and run $ pod install. If you don't have CocoaPods installed or integrated into your project, you can learn how to do so here. Documentation CocoaDocs Documentation for MSDynamicsDrawerViewController is available online via CocoaDocs. Xcode If you would like to install the MSDynamicsDrawerViewController documentation into Xcode, you can do so by first installing Appledoc ($ brew install appledoc), and then by running the Documentation target in the MSDynamicsDrawerViewController.xcodeproj in the root of repository. Example Example.xcworkspace in the Example directory serves as an example implementation of MSDynamicsDrawerViewController. It uses Cocoapods to link with the MSDynamicsDrawerViewController source files in the root directory as a development pod. As such, use the example xcworkspace and not the xcproj. Usage Pane View Controller The pane view controller is the primary view controller, displayed centered and covering the drawer view controllers. The user can swipe anywhere on the pane view controller to reveal the drawer view controllers underneath. Instances of UIViewController can be added as the pane view controller via the paneViewController property: Replacing the Pane View Controller The pane view controller can be replaced with an animation that slides the pane off to the side, replaces it with a new pane, and slides the new pane closed. See the ""Replace"" .gif above to view this animation. You can initiate this animation with the the setPaneViewController:animated:completion: method: If you don't want the ""slide off"" portion of this animation, set the value of the paneViewSlideOffAnimationEnabled property on your MSDynamicsDrawerViewController instance to NO. Drawer View Controllers The drawer view controllers are revealed as drawers underneath the pane view controller. Drawer view controllers can be set for any of the cardinal directions (top, left, bottom, or right). The MSDynamicsDrawerDirection typedef is used to communicate these directions to the instance of MSDynamicsDrawerViewController. Instances of UIViewController can be added as drawer view controllers via the setDrawerViewController:forDirection: method: When adding two simultaneous drawer view controllers, they view controllers must be in opposing directions (left/right or top/bottom). Replacing or Removing a Drawer To replace or remove the drawer view controller, just set either the new UIViewController instance or nil for the desired direction using the method above. Opening and Closing the Drawers The various methods that modify the paneState property are the go-to for changing the ""open"" state of the drawer. Non-Animated If you just want to open or close the drawer without an animation and you only have one drawer view controller, use the paneState property: If you have more than one drawer view controller, see the multiple drawer view controllers section below. Animated If you want to make animated changes to the drawer visibility, use the setPaneState:animated:allowUserInterruption:completion: method. As with the paneState property, this method requires that you have added only a single drawer view controller. A key point of consideration when invoking this method is the allowUserInterruption parameter. If set to NO, the user will be able to perform gestures that ""catch"" the sliding pane, interrupting the transition and causing the end paneState to potentially differ from the value passed for the paneState parameter. As such, the completion block is not necessarily called when the pane state has changedjust when it has come to rest. If you require that the pane's state is updated to the specified state without interruption, you must pass YES for this parameter. If you have more than one drawer view controller, see the multiple drawer view controllers section below. With Multiple Drawer View Controllers If you have more than one drawer view controller added to your MSDynamicsDrawerViewController instance, you should to use the ""directional"" equivalents of the methods above: Non-Animated setPaneState:inDirection: Animated setPaneState:inDirection:animated:allowUserInterruption:completion:. Bouncing the Pane Open The pane can be bounced open by invoking the bouncePaneOpen method. If you have more than one drawer view controller, use the bouncePaneOpenInDirection: method and specify a direction. See the ""Bounce"" .gif above for an example of this behavior. A bounce is a good way to indicate that there's a drawer view controller underneath the pane view controller that can be accessed by swiping, similar to the iOS lock screen camera bounce. Stylers MSDynamicsDrawerViewController uses an instances of ""styler"" objects to create unique styles on the child view controllers updated relative to the fraction that drawers are opened/closed. These stylers conform to the MSDynamicsDrawerStyler protocol. Stylers can be combined (assuming they aren't overwriting identical attributes) by setting multiple stylers for a single MSDynamicsDrawerDirection. Instances of MSDynamicsDrawerStyler are added to MSDynamicsDrawerViewController via the addStyler:forDirection: method, and instantiated via the styler class method: Default Styler Classes There are a few default stylers included with MSDynamicsDrawerViewController. The Stylers menu option in the example project enables you to try these individually or in combination. Parallax Styler MSDynamicsDrawerParallaxStyler Creates a parallax effect on the drawerView as the frame of the paneView is adjusted. Modify the parallaxOffsetFraction property to change the amount of parallax that occurs. Fade Styler MSDynamicsDrawerFadeStyler Fades the drawerView as the frame of the paneView is adjusted. Modify the closedAlpha property to change the amount of fade that occurs when the paneView is closed. Scale Styler MSDynamicsDrawerScaleStyler Creates a zoom-in scaling effect on the drawerView as the frame of the paneView is adjusted. Modify the closedScale property to change the scale that occurs when the paneView is closed. Drawer Resize Styler MSDynamicsDrawerResizeStyler Resizes the drawer view controller's view to fit within the visible space that a drawer is opened to as derived from the currentRevealWidth property. Modify the minimumResizeRevealWidth property to change the threshold at which the resizing begins. Creating a Custom Styler As user interacts with a MSDynamicsDrawerViewController, the styler classes that are associated with the active drawer direction are messaged via the method dynamicsDrawerViewController:didUpdatePaneClosedFraction:forDrawerDirection:. This method enables the styler to changes attributes of the drawerView, paneView, etc. relative to the paneClosedFraction. It's recommended that custom stylers don't change the frame attribute of the paneView or the drawerView on the MSDynamicsDrawerViewController instance. These are modified internally both by the user's gestures and the internal UIKit Dynamics within MSDynamicsDrawerViewController. The behavior of MSDynamicsDrawerViewController when the frame is externally modified is undefined. Requirements Requires iOS 7.0, ARC, and the QuartzCore Framework. Contributing Forks, patches and other feedback are welcome. License"
3095,"Generate Java types from JSON or JSON Schema and annotate those types for data-binding with Jackson, Gson, etcjsonschema2pojo jsonschema2pojo generates Java types from JSON Schema (or example JSON) and can annotate those types for data-binding with Jackson 2.x or Gson. Try jsonschema2pojo onlineor brew install jsonschema2pojo You can use jsonschema2pojo as a Maven plugin, an Ant task, a command line utility, a Gradle plugin or embedded within your own Java app. The Getting Started guide will show you how. A very simple Maven example: Useful pages: * Getting started * How to contribute * Reference * Latest Javadocs * Documentation for the Maven plugin * Documentation for the Gradle plugin * Documentation for the Ant task Project resources: * Downloads * Mailing list Licensed under the Apache License, Version 2.0. Special thanks to YourKit, who support this project through a free license for their full-featured YourKit Java Profiler."
2459,"SQL for HumansRecords: SQL for Humans .. image:: https://img.shields.io/pypi/v/records.svg :target: https://pypi.python.org/pypi/records .. image:: https://travis-ci.org/kennethreitz/records.svg?branch=master :target: https://travis-ci.org/kennethreitz/records .. image:: https://img.shields.io/badge/SayThanks.io--1EAEDB.svg :target: https://saythanks.io/to/kennethreitz Records is a very simple, but powerful, library for making raw SQL queries to most relational databases. .. image:: https://farm1.staticflickr.com/569/33085227621_7e8da49b90_k_d.jpg Just write SQL. No bells, no whistles. This common task can be surprisingly difficult with the standard tools available. This library strives to make this workflow as simple as possible, while providing an elegant interface to work with your query results. Database support includes RedShift, Postgres, MySQL, SQLite, Oracle, and MS-SQL (drivers not included). The Basics We know how to write SQL, so let's send some to our database: .. code:: python import records db = records.Database('postgres://...') rows = db.query('select * from active_users') # or db.query_file('sqls/active-users.sql') Grab one row at a time: .. code:: python >>> rows[0] <Record {""username"": ""model-t"", ""active"": true, ""name"": ""Henry Ford"", ""user_email"": ""model-t@gmail.com"", ""timezone"": ""2016-02-06 22:28:23.894202""}> Or iterate over them: .. code:: python for r in rows: print(r.name, r.user_email) Values can be accessed many ways: row.user_email, row['user_email'], or row[3]. Fields with non-alphanumeric characters (like spaces) are also fully supported. Or store a copy of your record collection for later reference: .. code:: python >>> rows.all() [<Record {""username"": ...}>, <Record {""username"": ...}>, <Record {""username"": ...}>, ...] If you're only expecting one result: .. code:: python >>> rows.first() <Record {""username"": ...}> Other options include rows.as_dict() and rows.as_dict(ordered=True). Features Iterated rows are cached for future reference. $DATABASE_URL environment variable support. Convenience Database.get_table_names method. Command-line records tool for exporting queries. Safe parameterization: Database.query('life=:everything', everything=42). Queries can be passed as strings or filenames, parameters supported. Transactions: t = Database.transaction(); t.commit(). Bulk actions: Database.bulk_query() & Database.bulk_query_file(). Records is proudly powered by SQLAlchemy <http://www.sqlalchemy.org> and Tablib <http://docs.python-tablib.org/en/latest/>. Data Export Functionality Records also features full Tablib integration, and allows you to export your results to CSV, XLS, JSON, HTML Tables, YAML, or Pandas DataFrames with a single line of code. Excellent for sharing data with friends, or generating reports. .. code:: pycon >>> print(rows.dataset) username|active|name |user_email |timezone --------|------|----------|-----------------|-------------------------- model-t |True |Henry Ford|model-t@gmail.com|2016-02-06 22:28:23.894202 ... Comma Separated Values (CSV) .. code:: pycon >>> print(rows.export('csv')) username,active,name,user_email,timezone model-t,True,Henry Ford,model-t@gmail.com,2016-02-06 22:28:23.894202 ... YAML Ain't Markup Language (YAML) .. code:: python >>> print(rows.export('yaml')) - {active: true, name: Henry Ford, timezone: '2016-02-06 22:28:23.894202', user_email: model-t@gmail.com, username: model-t} ... JavaScript Object Notation (JSON) .. code:: python >>> print(rows.export('json')) [{""username"": ""model-t"", ""active"": true, ""name"": ""Henry Ford"", ""user_email"": ""model-t@gmail.com"", ""timezone"": ""2016-02-06 22:28:23.894202""}, ...] Microsoft Excel (xls, xlsx) .. code:: python with open('report.xls', 'wb') as f: f.write(rows.export('xls')) Pandas DataFrame .. code:: python >>> rows.export('df') username active name user_email timezone 0 model-t True Henry Ford model-t@gmail.com 2016-02-06 22:28:23.894202 You get the point. All other features of Tablib are also available, so you can sort results, add/remove columns/rows, remove duplicates, transpose the table, add separators, slice data by column, and more. See the Tablib Documentation <http://docs.python-tablib.org/en/latest/>_ for more details. Installation Of course, the recommended installation method is pipenv <http://pipenv.org>_:: $ pipenv install records[pandas] Command-Line Tool As an added bonus, a records command-line tool is automatically included. Here's a screenshot of the usage information: .. image:: http://f.cl.ly/items/0S14231R3p0G3w3A0x2N/Screen%20Shot%202016-02-13%20at%202.43.21%20AM.png :alt: Screenshot of Records Command-Line Interface. Thank You Thanks for checking this library out! I hope you find it useful. Of course, there's always room for improvement. Feel free to open an issue <https://github.com/kennethreitz/records/issues>_ so we can make Records better, stronger, faster."
4749,JAVA WEB + ORM FrameworkJAVA WEB+ORM JFinal JFinal Java WEB + ORM RestfulJava rubypython ;) JFinal MVC COC XML Db + Record ActiveRecord Enjoy 90% Java AOP Plugin EnjoyFreeMarkerJSPVelocity Validator SSH 777 KB JFinal : JFinal Maven JFinalBlog 1. ( EnjoyJSPVelocityJSON) 2.ServicesqlService 3.Model(xmlannotaionattribute) 4.Validator(APIxmlN) 5.(demodemo) JFinal https://jfinal.com 
1507,"prototype of stream based programming languageStreem Streem is a stream based concurrent scripting language. It is based on a programming model similar to the shell, with influences from Ruby, Erlang, and other functional programming languages. Note: Streem is still in the design stage. It's not working yet. Stay tuned. Compiling Installing dependencies bison flex gcc / clang Run make Examples In Streem, a simple cat program looks like this: You can try it out by (firstly cd to streem top directory): or Streem is a (sort of) DSL for data flows. Above code means building data-flow connection between stdin and stdout. Actual data processing will be done in the event loop invoked after program execution. For another example, a simple FizzBuzz will look like this: The second part in the pipeline ({x ->...}) is a function object. If a function object is connected in the pipeline, it will be invoked for each element in the stream. There are more examples under folder examples/. Just play with them! Contributing Send a pull request to https://github.com/matz/streem. We consider you have granted non-exclusive right to your contributed code under MIT license. Use https://github.com/matz/streem/issues for discussion. License MIT license ( 2015-2016 Yukihiro Matsumoto)"
2989,"Xcode plug-in to to use clang-format from in Xcode and consistently format your code with ClangClangFormat-Xcode An Xcode plug-in to format your code using Clang's format tools, by @travisjeffery. With clang-format you can use Clang to format your code to styles such as LLVM, Google, Chromium, Mozilla, WebKit, or your own configuration. Installation: :warning: From XCode 8+, unsigning is required in order to use community-made plugins. Check https://github.com/inket/update_xcode_plugins for more information. Install via Alcatraz. OR Clone this repo, build and run ClangFormat, restart Xcode. Removing ClangFormat To remove ClangFormat, run the following in your terminal: rm -r ""~/Library/Application Support/Developer/Shared/Xcode/Plug-ins/ClangFormat.xcplugin"" Or just find the same file and move it to the trash. You'll need to restart Xcode after deleting the plugin. Usage: Format on save I.e., you press command-s and the file is formatted and wrote to disk. In the menu, open Edit > Clang Format > Click Format on save (a checkmark appears in this menu item indicicating that the feature is active.) Assign keyboard shortcuts You can assign your own keyboard shortcuts like so: Open the System Preferences > Keyboard > Shortcuts > App Shortcuts > Click + Set the application to be Xcode Set the menu title to an action title, e.g. ""Format File in Focus"" Set your shortcut In this example, we'll format the active file when control-i is pressed. Using your own style configuration By using Clang Format > File in the plug-in menu, Clang will look for the nearest .clang-format file from the input file. Most likely, you'll have a .clang-format file at the root of your project. Here are the options for .clang-format and how they're configured. Here's a cool interactive website to help you make your .clang-format file. If one of the built-in styles is close to what you want, you can bootstrap your own configuration with: ./bin/clang-format -style=llvm -dump-config > .clang-format For example, this .clang-format is similar to the Linux Kernel style: And this is similar to Visual Studio's style:"
2922,"A Mac PrefPane to manage all your Homebrew-installed servicesLaunchRocket A Mac PreferencePane for managing services with launchd. For an introduction on launchd, see launchd.info. LaunchRocket was primarily created for managing various services installed by Homebrew, though it should work with most launchd-compatible plists. Of particular note is the ability to run some services as root. With Homebrew, most services can simply run as the current user, and this is the desired behavior for a development environment. However, some services (dnsmasq) require being bound to privileged ports, and others (nginx, apache) don't require it, but might in some circumstances. For example, many times it's just easier to run Apache on port 80 and 443 than to deal with code that might not like port numbers in the URLs. I recommend you only run things as root if you absolutely must, to get them working properly. Features Green/Yellow/Red status indicators Green - launchctl reports process is running Yellow - LaunchRocket is current executing or waiting on a start/stop command Red - launchctl reports process is not running Start/Stop buttons Dynamically updates state based on running state of service As Root option Checking this will cause launchrocket to use root privileges to access launchctl Checking this will NOT restart a running service automatically as root LaunchRocket will prompt you to authenticate and elevate privileges We ask for credentials as seldom as possible, however when launchrocket loads, it checks the current status of every service it's tracking. This means that if you have services running as root, it will prompt you for credentials immediately on load, as an unprivileged account cannot even list launchd services run by a privileged one Preferences file LaunchRocket stores a preferences file in ~/Library/Preferences/com.joshbutts.launchrocket.plist Installing Requirements OS X 10.7 or above Gatekeeper must be set to allow all apps to run (See issues #3 and #25) The binary release should work on Mac OSX 10.7.0 and above, and might even work on older versions, though it has not been tested on those. The latest builds are compiled on 10.9.1 and targeted at 10.7 in Xcode. Direct Download Download and unzip the binary release from the release page Note: This zip was created with Finder's ""Compress"" utility. I've heard that there are issues unzipping it with other tools. I will try to provide a more compatible zipfile on the releases page. (related info here) Homebrew Launchrocket is available as a Cask for Homebrew Cask. As of 3/3/2014 it is no longer maintained in my personal tap, and is now available in the main Homebrew Cask repo. brew cask install launchrocket Further information about running as root LaunchRocket uses an AppleScript helper to obtain root privileges. This is a hacky way of accomplishing it, but it avoids having to actually install a privileged helper outside of the prefpane bundle with SMJobBless and is WAY simpler. This is not the most secure approach and does not use code signing. As such, it is possible that if LaunchRocket's AppleScript helper has cached your privileged authorization, another application maliciously address that helper and request it execute other commands with root level privileges. I considered this a reasonable tradeoff between security, usability and code simplicity. Closing System Preferences or simply switching back to the main view will terminate the helper and drop privileges. If you don't have anything running as root, no programs can request that the helper execute code with privilieges without triggering a credential prompt. Contributing Found a bug? File an issue and I'll take a look. Pull requests are welcome. If you'd like to chat about a feature or issue, I can sometimes be found in #launchrocket on Freenode."
633,"Android library to observe scroll events on scrollable views.Android-ObservableScrollView Android library to observe scroll events on scrollable views. It's easy to interact with the Toolbar introduced in Android 5.0 Lollipop and may be helpful to implement look and feel of Material Design apps. Examples Download from Google Play Please note that the app on the Play store is not always the latest version. Download from wercker If you are a wercker user, you can download the latest build artifact. See here for details. Install manually Just clone and execute installDevDebug task with Gradle. See here for details. Usage Add com.github.ksoichiro:android-observablescrollview to your dependencies in build.gradle. Add ObservableListView or other views you'd like to use. Write some animation codes to the callbacks such as onScrollChanged, onUpOrCancelMotionEvent, etc. See the quick start guide for details, and the documentation for further more. Reference Supported widgets Environment Release notes FAQ Apps that use this library Jair Player by Akshay Chordiya My Gradle by Erick Chavez Alcarraz ThemeDIY by Darkion Avey {Soft} Skills by Fanatic Devs If you're using this library in your app and you'd like to list it here, please let me know via email or pull requests or issues. Contributions Any contributions are welcome! Please check the FAQ and contributing guideline before submitting a new issue. Developed By Soichiro Kashima - soichiro.kashima@gmail.com Thanks Inspired by ObservableScrollView in romannurik-code. License"
4247,"CMS/Wiki system using Javascript for 100% client side single page application using Markdown.MDwiki 100% static single file CMS/Wiki done purely with client-side Javascript and HTML5. See http://www.mdwiki.info for more info and documentation. !! This project is currently unmaintained!! Download See https://github.com/Dynalon/mdwiki/releases for readily precompiled releases. How to build from source (applies to master branch, stable may differ) Install node.js >= 0.10 and npm (if not included) Clone the mdwiki repo Install deps and build MDwiki (you need automake installed - if you are on Windows check the contents of the Makefile for the list of commands to run them manually): Find the mdwiki.html in the dist/ folder Development For development, use grunt devel To get unminified source code compiled to dist/mdwiki-debug.html, as well as auto file watching and livereload support. Symlink the development mdwiki file into your webroot for testing."
1192,"SecLists is the security tester's companion. It's a collection of multiple types of lists used during security assessments, collected in one place. List types include usernames, passwords, URLs, sensitive data patterns, fuzzing payloads, web shells, and many more.About SecLists SecLists is the security tester's companion. It's a collection of multiple types of lists used during security assessments, collected in one place. List types include usernames, passwords, URLs, sensitive data patterns, fuzzing payloads, web shells, and many more. The goal is to enable a security tester to pull this repository onto a new testing box and have access to every type of list that may be needed. This project is maintained by Daniel Miessler, Jason Haddix, and g0tmi1k. Install Zip Git (Small) Git (Complete) Kali Linux (Tool Page) Attribution See CONTRIBUTORS.md Contributing See CONTRIBUTING.md Similar Projects PayloadsAllTheThings FuzzDB Assetnote Wordlists Licensing This project is licensed under the MIT license. NOTE: Downloading this repository is likely to cause a false-positive alarm by your anti-virus or anti-malware software, the filepath should be whitelisted. There is nothing in SecLists that can harm your computer as-is, however it's not recommended to store these files on a server or other important system due to the risk of local file include attacks."
1556,"Soulful docs for Swift & Objective-Cjazzy is a command-line utility that generates documentation for Swift or Objective-C About Both Swift and Objective-C projects are supported. Instead of parsing your source files, jazzy hooks into Clang and SourceKit to use the AST representation of your code and its comments for more accurate results. The output matches the look and feel of Apples official reference documentation, post WWDC 2014. Jazzy can also generate documentation from compiled swift modules using their symbol graph instead of source code. This project adheres to the Contributor Covenant Code of Conduct. By participating, you are expected to uphold this code. Please report unacceptable behavior to info@realm.io. Requirements You need development tools to build the project you wish to document. Jazzy supports both Xcode and Swift Package Manager projects. Jazzy expects to be running on macOS. See below for tips to run Jazzy on Linux. Installation See Installation Problems for solutions to some common problems. Usage Run jazzy from your command line. Run jazzy -h for a list of additional options. If your Swift module is the first thing to build, and it builds fine when running xcodebuild or swift build without any arguments from the root of your project, then just running jazzy (without any arguments) from the root of your project should succeed too! If Jazzy generates docs for the wrong module then use --module to tell it which one you'd prefer. If this doesn't help, and you're using Xcode, then try passing extra arguments to xcodebuild, for example jazzy --build-tool-arguments -scheme,MyScheme,-target,MyTarget. You can set options for your projects documentation in a configuration file, .jazzy.yaml by default. For a detailed explanation and an exhaustive list of all available options, run jazzy --help config. Supported documentation keywords Swift documentation is written in markdown and supports a number of special keywords. For a complete list and examples, see Erica Sadun's post on Swift header documentation in Xcode 7, her book on Swift Documentation Markup, and the Xcode Markup Formatting Reference. For Objective-C documentation the same keywords are supported, but note that the format is slightly different. In Swift you would write - returns:, but in Objective-C you write @return. See Apple's HeaderDoc User Guide for more details. Note: jazzy currently does not support all Objective-C keywords listed in this document, only @param, @return, @warning, @see, and @note. Jazzy can also generate cross-references within your documentation. A symbol name in backticks generates a link, for example: * `MyClass` - a link to documentation for MyClass. * `MyClass.method(param1:)` - a link to documentation for that method. * `MyClass.method(...)` - shortcut syntax for the same thing. * `method(...)` - shortcut syntax to link to method from the documentation of another method or property in the same class. * `[MyClass method1]` - a link to an Objective-C method. * `-[MyClass method2:param1]` - a link to another Objective-C method. Math Jazzy can render math equations written in LaTeX embedded in your markdown: * `$equation$` renders the equation in an inline style. * `$$equation$$` renders the equation in a display style, centered on a line of its own. For example, the markdown: ..renders as: Math support is provided by KaTeX. Swift Swift documentation is generated by default. Example This is how Realm Swift docs are generated: This is how docs are generated for a project that uses the Swift Package Manager: Objective-C To generate documentation for Objective-C headers, you must pass the following parameters to jazzy: --objc --umbrella-header ... --framework-root ... --sdk [iphone|watch|appletv][os|simulator]|macosx (optional, default value of macosx) --hide-declarations [objc|swift] (optional, hides the selected language declarations) Example This is how Realm Objective-C docs are generated: This is how the AFNetworking docs are generated: Mixed Objective-C / Swift This feature is new and has some rough edges. To generate documentation for a mixed Swift and Objective-C project you must first generate two SourceKitten files: one for Swift and one for Objective-C. Then pass these files to Jazzy together using --sourcekitten-sourcefile. Example This is how docs are generated from an Xcode project for a module containing both Swift and Objective-C files: Docs from .swiftmodules or frameworks This feature is new and relies on a new Swift feature: there may be crashes and mistakes: reports welcome. Swift 5.3 adds support for symbol graph generation from .swiftmodule files. This looks to be part of Apple's toolchain for generating their online docs. Jazzy can use this to generate API documentation. This is faster than using the source code directly but does have limitations: for example documentation comments are available only for public declarations, and the presentation of Swift extensions may not match the way they are written in code. Some examples: Generate docs for the Apple Combine framework for macOS: The SDK's library directories are included in the search path by default. 2. Same but for iOS: The target is the LLVM target triple and needs to match the SDK. The default here is the target of the host system that Jazzy is running on, something like x86_64-apple-darwin19.6.0. 3. Generate docs for a personal .swiftmodule: This implies that /Build/Products/MyMod.swiftmodule exists. Jazzy's --source-directory (default current directory) is searched by default, so you only need the -I override if that's not enough. 4. For a personal framework: This implies that /Build/Products/MyMod.framework exists and contains a .swiftmodule. Again the --source-directory is searched by default if -F is not passed in. See swift symbolgraph-extract --help for all the things you can pass via --build-tool-arguments: if your module has dependencies then you may need to add various search path options to let Swift load it. Themes Three themes are provided with jazzy: apple (default), fullwidth and jony. apple example: https://realm.io/docs/swift/latest/api/ fullwidth example: https://reduxkit.github.io/ReduxKit/ jony example: https://harshilshah.github.io/IGListKit/ You can specify which theme to use by passing in the --theme option. You can also provide your own custom theme by passing in the path to your theme directory. Guides | Description | Command | | --- | --- | | Command line option | --documentation={file pattern} | | Example | --documentation=Docs/*.md | | jazzy.yaml example | documentation: Docs/*.md | By default, jazzy looks for one of README.md, README.markdown, README.mdown or README (in that order) in the directory from where it runs to render the index page at the root of the docs output directory. Using the --documentation option, extra markdown files can be integrated into the generated docs and sidebar navigation. Any files found matching the file pattern will be parsed and included as a document with the type 'Guide' when generated. If the files are not included using the custom_categories config option, they will be grouped under 'Other Guides' in the sidebar navigation. There are a few limitations: - File names must be unique from source files. - Readme should be specified separately using the readme option. Section description abstracts | Description | Command | | --- | --- | | Command line option | --abstract={file pattern} | | Example | --abstract=Docs/Sections/*.md | | jazzy.yaml example | abstract: Docs/Sections/*.md | Using the --abstract options, extra markdown can be included after the heading of section overview pages. Think of it as a template include. The list of files matching the pattern is compared against the list of sections generated and if a match is found, it's contents will be included in that section before listing source output. Unlike the --documentation option, these files are not included in navigation and if a file does not match a section title, it is not included at all. This is very helpful when using custom_categories for grouping types and including relevant documentation in those sections. For an example of a project using both --documentation and --abstract see: https://reswift.github.io/ReSwift/ Controlling what is documented In Swift mode, Jazzy by default documents only public and open declarations. To include declarations with a lower access level, set the --min-acl flag to internal, fileprivate, or private. In Objective-C mode, Jazzy documents all declarations found in the --umbrella-header header file and any other header files included by it. You can control exactly which declarations should be documented using --exclude, --include, or :nodoc:. The --include and --exclude flags list source files that should be included/excluded respectively in the documentation. Entries in the list can be absolute pathnames beginning with / or relative pathnames. Relative pathnames are interpreted relative to the directory from where you run jazzy or, if the flags are set in the config file, relative to the directory containing the config file. Entries in the list can match multiple files using * to match any number of characters including /. For example: * jazzy --include=/Users/fred/project/Sources/Secret.swift -- include a specific file * jazzy --exclude=/*/Internal* -- exclude all files with names that begin with Internal and any files under any directory with a name beginning Internal. * jazzy --exclude=Impl1/*,Impl2/* -- exclude all files under the directories Impl1 and Impl2 found in the current directory. Note that the --include option is applied before the --exclude option. For example: jazzy --include=/*/Internal* --exclude=Impl1/*,Impl2/* -- include all files with names that begin with Internal and any files under any directory with a name beginning Internal, except for those under the directories Impl1 and Impl2 found in the current directory Declarations with a documentation comment containing :nodoc: are excluded from the documentation. Documentation structure By default Jazzy does not create separate web pages for declarations that do not have any members: instead they are nested into some parent page. Use the --separate-global-declarations flag to change this and always create pages for declarations that can be directly accessed from client code. Choosing the Swift language version Jazzy normally uses the Swift compiler from the Xcode currently configured by xcode-select. Use the --swift-version flag to compile with a different Xcode. The value you pass to --swift-version must be the Swift language version given by swift --version in the Xcode you want to use. For example to use Xcode 9.4: Linux Jazzy uses SourceKitten to communicate with the Swift build environment and compiler. The sourcekitten binary included in the Jazzy gem is built for macOS and so does not run on other operating systems. To use Jazzy on Linux you first need to install and build sourcekitten following instructions from SourceKitten's GitHub repository. Then to generate documentation for a SwiftPM project, instead of running just jazzy do: We hope to improve this process in the future. Troubleshooting Swift Only extensions are listed in the documentation? Check the --min-acl setting -- see above. Unable to find an Xcode with swift version X The value passed with --swift-version must exactly match the version number from swiftc --version. For example Xcode 10.1 needs --swift-version 4.2.1. See the flag documentation. The Xcode you want to use must be in the Spotlight index. You can check this using mdfind 'kMDItemCFBundleIdentifier == com.apple.dt.Xcode'. Some users have reported this issue being fixed by a reboot; mdutil -E may also help. If none of these work then you can set the DEVELOPER_DIR environment variable to point to the Xcode you want before running Jazzy without the --swift-version flag. Installation Problems Can't find header files / clang Some of the Ruby gems that Jazzy depends on have native C extensions. This means you need the Xcode command-line developer tools installed to build them: run xcode-select --install to install the tools. /Applications/Xcode: No such file or directory The path of your active Xcode installation must not contain spaces. So /Applications/Xcode.app/ is fine, /Applications/Xcode-10.2.app/ is fine, but /Applications/Xcode 10.2.app/ is not. This restriction applies only when installing Jazzy, not running it. MacOS Before 10.14.4 Starting with Jazzy 0.10.0, if you see an error similar to dyld: Symbol not found: _$s11SubSequenceSlTl then you need to install the Swift 5 Runtime Support for Command Line Tools. Alternatively, you can: * Update to macOS 10.14.4 or later; or * Install Xcode 10.2 or later at /Applications/Xcode.app. Development Please review jazzy's contributing guidelines when submitting pull requests. jazzy is composed of two parts: The parser, SourceKitten (written in Swift) The site generator (written in ruby) To build and run jazzy from source: Install bundler. Run bundle install from the root of this repo. Run jazzy from source by running bin/jazzy. Instructions to build SourceKitten from source can be found at SourceKitten's GitHub repository. Design Goals Generate source code docs matching Apple's official reference documentation Support for standard Objective-C and Swift documentation comment syntax Leverage modern HTML templating (Mustache) Leverage the power and accuracy of the Clang AST and SourceKit Support for Dash docsets Support Swift and Objective-C License This project is released under the MIT license. About Jazzy is maintained and funded by Realm Inc. The names and logos for Realm are trademarks of Realm Inc. We :heart: open source software! See our other open source projects, read our blog or say hi on twitter (@realm)."
1592,"Execute SQL against structured text like CSV or TSVTextQL Allows you to easily execute SQL against structured text like CSV or TSV. Example session: Major changes! In the time since the initial release of textql, I've made some improvements as well as made the project much more modular. There've also been additional performance tweaks and added functionality, but this comes at the cost of breaking the original command-line flags and changing the install command. Changes since v1 Additions: Numeric values are automatically recognized in more cases. Date / Time / DateTime values are automatically recognized in reasonable formats. See Time Strings for a list for accepted formats, and how to convert from other formats. Added join support! Multiple files / directories can be loaded by listing them at the end of the command. Directories are read by reading each file inside, and this is non-recursive. You can list as many files / directories as you like. Added flag '-output-file' to save output directly to a file. Added flag '-output-dlm' to modify the output delimiter. Added ""short SQL"" syntax. For the case of a single table, the FROM [table] can be dropped from the query. For simple selects, the SELECT keyword can be dropped from the query. This means the v1 command textql -sql ""select * from tbl"" -source some_file.csv can be shortened to textql -sql ""*"" some_file.csv Changes: The flag '-outputHeader' was renamed to '-output-header'. Removals: Dropped the ability to override table names. This makes less sense after the automatic tablename generation based on filename, joins, and shorter SQL syntax changes. Removed '-source', any files / paths at the end of the command are used, as well as piped-in data. Bug fixes: Writing to a directory no longer fails silently. Key differences between textql and sqlite importing sqlite import will not accept stdin, breaking unix pipes. textql will happily do so. textql supports quote-escaped delimiters, sqlite does not. textql leverages the sqlite in-memory database feature as much as possible and only touches disk if asked. Is it any good? Yes Requirements Go 1.4 or later Install Latest release on Homebrew (OS X) Build from source Docker First build the image. Now use that image mounting your current directory into the container. Alias You can add the following alias to your system to provide quick access to TextQL: Usage I want stdev, average, other functions Just follow the install directions at go-sqlite3-extension-functions and textql will automatically load this library. Full function list: Math: acos, asin, atan, atn2, atan2, acosh, asinh, atanh, difference, degrees, radians, cos, sin, tan, cot, cosh, sinh, tanh, coth, exp, log, log10, power, sign, sqrt, square, ceil, floor, pi. String: replicate, charindex, leftstr, rightstr, ltrim, rtrim, trim, replace, reverse, proper, padl, padr, padc, strfilter. Aggregate: stdev, variance, mode, median, lower_quartile, upper_quartile License New MIT License - Copyright (c) 2015, 2016 Paul Bergeron http://pauldbergeron.com/ See LICENSE for details"
1340,"A utility that reminds your iPhone app's users to review the app.Introduction Appirater is a class that you can drop into any iPhone app (iOS 4.0 or later) that will help remind your users to review your app on the App Store. The code is released under the MIT/X11, so feel free to modify and share your changes with the world. Read on below for how to get started. If you need any help using, the library, post your questions on Stack Overflow under the appirater tag. Getting Started CocoaPods To add Appirater to your app, add pod ""Appirater"" to your Podfile. Configuration Appirater provides class methods to configure its behavior. See Appirater.h for more information. Call [Appirater setAppId:@""yourAppId""] with the app id provided by Apple. A good place to do this is at the beginning of your app delegate's application:didFinishLaunchingWithOptions: method. Call [Appirater appLaunched:YES] at the end of your app delegate's application:didFinishLaunchingWithOptions: method. Call [Appirater appEnteredForeground:YES] in your app delegate's applicationWillEnterForeground: method. (OPTIONAL) Call [Appirater userDidSignificantEvent:YES] when the user does something 'significant' in the app. Development Setting [Appirater setDebug:YES] will ensure that the rating request is shown each time the app is launched. Production Make sure you set [Appirater setDebug:NO] to ensure the request is not shown every time the app is launched. Also make sure that each of these components are set in the application:didFinishLaunchingWithOptions: method. This example states that the rating request is only shown when the app has been launched 5 times and after 7 days. If you wanted to show the request after 5 days only you can set the following: SKStoreReviewController In iOS 10.3, SKStoreReviewController was introduced which allows rating directly within the app without any additional setup. Appirater automatically uses SKStoreReviewController if available. You'll need to manually link StoreKit in your App however. If SKStoreReviewController is used, Appirater is used only to decide when to show the rating dialog to the user. Keep in mind, that SKStoreReviewController automatically limits the number of impressions, so the dialog might be displayed less frequently than your configured conditions might suggest. License Copyright 2017. Arash Payan. This library is distributed under the terms of the MIT/X11. While not required, I greatly encourage and appreciate any improvements that you make to this library be contributed back for the benefit of all who use Appirater. Ports for other SDKs A few people have ported Appirater to other SDKs. The ports are listed here in hopes that they may assist developers of those SDKs. I don't know how closesly (if at all) they track the Objective-C version of Appirater. If you need support for any of the libraries, please contact the maintainer of the port. MonoTouch Binding (using native Appirater). Github"
2321,":zap: Primus, the creator god of the transformers & an abstraction layer for real-time to prevent module lock-in.Primus Primus, the creator god of transformers but now also known as universal wrapper for real-time frameworks. There are a lot of real-time frameworks available for Node.js and they all have different opinions on how real-time should be done. Primus provides a common low level interface to communicate in real-time using various real-time frameworks. Advantages Effortless switching between real-time frameworks by changing one single line of code. No more API rewrites needed when your project requirements change, the framework gets abandoned or simply breaks down. Built-in reconnect, it just works. The reconnect is controlled by a randomised exponential back-off algorithm to reduce server stress. Offline detection, Primus is smart enough to detect when users drop their internet connection (switching WIFI points/cell towers for example) and reconnects when they are back online. Automatically encodes and decodes messages using custom parsers. Can be easily switched for binary encoding for example. A clean, stream-compatible interface for the client and server. You can just stream#pipe data around. In addition to that, the client works on Node.js as well, write once, run it everywhere. Fixes various of bugs in the supported frameworks and additional stability patches to improve real-time communication. Comes with an amazing plugin interface to keep the core library as fast and lean as possible while still allowing the server and the client to be extended. Last but not least, Primus is built with love, passion and dedication to the real-time web. Installation Primus is released on npm and can be installed using: Before Starting If you deploy your application behind a reverse proxy (Nginx, HAProxy, etc.) you might need to add WebSocket specific settings to its configuration files. If you intend to use WebSockets, please ensure that these settings have been added. There are some example configuration files available in the observing/balancerbattle repository. Table of Contents Introduction Advantages Installation Getting started Client library Connecting from the browser Connecting from the server Authorization Broadcasting Destruction Events Heartbeats and latency Supported real-time frameworks BrowserChannel Engine.IO Faye SockJS uws WebSockets Transformer inconsistencies Parsers Middleware Plugins Extending the Spark / Socket Transforming and intercepting messages Primus project plugins Community plugins Community FAQ Scaling Cluster Express RequireJS Custom headers Versioning History Convention Release cycle Other languages Protocol License Getting started Primus doesn't ship with real-time frameworks as dependencies, it assumes that you as user add them yourself as a dependency. This is done to keep the module as lightweight as possible. This works because require in will walk through your directories searching for node_module folders that have these matching dependencies. Primus needs to be ""attached"" to a HTTP compatible server. These includes the built-in http and https servers but also the spdy module as it has the same API as node servers. Creating a new Primus instance is relatively straightforward: The following options can be provided: Name | Description | Default --------------------|-------------------------------------------|--------------- authorization | Authorization handler | null pathname | The URL namespace that Primus can own | /primus parser | Message encoder for all communication | JSON transformer | The transformer we should use internally | websockets plugin | The plugins that should be applied | {} pingInterval | Interval at which heartbeats are sent | 30000 global | Set a custom client class / global name | Primus compression | Use permessage-deflate / HTTP compression | false maxLength | Maximum allowed packet size, in bytes | 10485760 transport | Transformer specific configuration | {} idGenerator | Custom spark id generator function | undefined origins | cors List of origins | * methods | cors List of accepted HTTP methods | GET,HEAD,PUT,POST,DELETE,OPTIONS credentials | cors Allow sending of credentials | true maxAge | cors Cache duration of CORS preflight | 30 days headers | cors Allowed headers | false exposed | cors Headers exposed to the client | false The options that are prefixed with cors are supplied to our access-control module which handles HTTP Access Control (CORS), so for a more detailed explanation of these options check it out. The transport option allows you to use any configuration option supported by the underlying real-time framework. Its use is discouraged as these options are framework specific and no longer work if you change transformer. Our advise is to use it only if you know what you are doing and if you need fine-grained control over the real-time framework. Please also keep in mind that some of these options are overriden by Primus. The pingInterval option specifies the interval at which heartbeats are transmitted. It is possible to completely disable the heartbeats by setting the value of the pingInterval option to false. The idGenerator option can be used to define a function which will be called to set each spark.id. The generator function should return a unique string each time it is invoked. If idGenerator is not defined, Primus will try to use ids provided by the transformer. If the transformer does not provide ids, Primus will use nanoid to generate Spark ids. If you don't have a pre-existing server where you want or can attach your Primus server to you can also use the Primus.createServer convenience method. The createServer method will automatically: Setup a HTTP, HTTPS or SPDY server for you on the given port number. Setup your Primus server with the given configuration. Listen on the HTTP, HTTPS, SPDY server. Attach a primus.on('connection') listener. Return the created Primus instance. In the above example we automatically create a HTTP server which will listen on port 8080, a primus instance with the websockets transformer and start listening for incoming connections. The supplied function in the Primus.createServer method is optional. You can just listen for incoming connections your self using the returned Primus instance. If you want to listen to a HTTPS or SPDY server, which is recommended, you can directly pass the SPDY and HTTPS certs/keys/pfx files in the options object: Primus.createServer returns a warning when it starts a HTTP server. The warning advises you to use a HTTPS server and can be disabled setting the option iknowhttpsisbetter to true. Client library As most libraries come with their own client-side framework for making the connection we've also created a small wrapper for this. The library can be retrieved using: Which returns the client-side library as a string (which can then be minified or even have more code added to it). It does not come pre-minified as that is out of the scope of this project. You can store this on a CDN or on your static server. Do whatever you want with it, but remember to regenerate it every time you change Primus server options. This is important because some properties of the client are set using the server configuration. For example if you change the pathname, the client should be regenerated to reflect that change and work correctly. We advise you to regenerate the library every time you redeploy so you always have a client compatible with your back-end. To save the file you can use: This will store the compiled library in your current directory. If you want to save it asynchronously, you can supply the method with a callback method: But to make it easier for you during development we've automatically added an extra route to the supplied HTTP server, this will serve the library for you so you don't have to save it. Please note, that this route isn't optimised for serving static assets and should only be used during development. In your HTML page add: As you can see, it will use the /primus pathname by default. Primus needs to own the whole path/namespace in order to function properly as it will forward all other requests directly in to the transformers so they can work their magic. If you already have a static folder with the name primus you can change the pathname to something different and still make this work. But you would of course need to update the src attribute of the script tag to set the correct location. It's always available at: Here <pathname> is the pathname set in server options above. The client is cross domain compatible so you don't have to serve it from the same domain you're running Primus on. But please note, that the real-time framework you're using might be tied to same domain restrictions. Once you're all set up you can start listening for connections. These connections are announced through the connection event. Disconnects are announced using a disconnection event: The spark argument is the actual real-time socket/connection. Sparks have a really low level interface and only expose a couple properties that are cross engine supported. The interface is modeled towards a Node.js stream compatible interface. So this will include all methods that are available on the stream interface including Spark#pipe. spark.headers The spark.headers property contains the headers of either the request that started a handshake with the server or the headers of the actual real-time connection. This depends on the module you are using. Please note that sending custom headers from the client to the server is impossible as not all transports that these transformers support can add custom headers to a request (JSONP for example). If you need to send custom data, use a query string when connecting spark.address The spark.address property contains the ip and port of the connection. If you're running your server behind a reverse proxy it will automatically use the x-forwarded-for header. This way you will always have the address of the connecting client and not the IP address of your proxy. Please note that the port is probably out of date by the time you're going to read it as it's retrieved from an old request, not the request that is active at the time you access this property. spark.query The spark.query contains the query string you used to connect to the server. It's parsed as an object. Please note that this may not be available for all supported transformers. spark.socket The spark.socket is set to the underlying socket of the transformer. This is not necessarily a raw Socket and will differ from transformer to transformer. spark.id This is a unique id that we use to identify this single connection with. Normally the frameworks refer to this as a sessionid, which is confusing as it's only used for the duration of one single connection. You should not see this as a ""session id"", and rather expect it to change between disconnects and reconnects. spark.request The spark.request gives you access to the HTTP request that was used to initiate the real-time connection with the server. Please note that this request is already answered and closed (in most cases) so do not attempt to write or answer it anyway. But it might be useful to access methods that get added by middleware layers, etc. spark.write(data) You can use the spark.write method to send data over the socket. The data is automatically encoded for you using the parser that you've set while creating the Primus server instance. This method always returns true on success and false on failure so back pressure isn't handled. spark.end(data, options) You can use spark.end to close the connection. This method takes two optional arguments. The first, if provided, is the data to send to the client before closing the connection. The second is an options object used to customize the behavior of the method. By default the spark.end method closes the connection in a such way that the client knows it was intentional and it doesn't attempt a reconnection. You can change this behavior and trigger a client-side reconnection using the reconnect option. spark.emits(event, parser) This method is mostly used internally. It works similarly to the native bind function, returning a function that emits the assigned event every time it's called. If the last argument is a function, it will be used to parse the arguments of the returned function. The parser is optional and always async, its first argument is a callback that follows the usual error first pattern, all successive arguments are the ones to parse. Using the parser you can reduce the arguments down to a single value, remove them completely or prevent the event from being emitted. See emits for detailed usage instructions. Please note that the data that is received here isn't decoded yet. spark.on('data') The data event is emitted when a message is received from the client. It's automatically decoded by the specified decoder. spark.on('end') The end event is emitted when the client has disconnected. Connecting from the Browser Primus comes with its client framework which can be compiled using primus.library() as mentioned above. To create a connection you can simply create a new Primus instance: The URL should confirm the following conditions: It should include the protocol it needs to connect with. This can either be http or https. We recommend that you're using HTTPS for all your connections as this prevents connection blocking by firewalls and anti-virus programs. The URL should not include a pathname. The pathname is configured by the server (See: getting-started) and needs to be configured there as it will be compiled in to the primus.js client file. If no url argument is passed, it will default to the current URL. The following options can be provided: Name | Description | Default --------------------|-----------------------------------------|--------------- reconnect | Configures the exponential back off | {} timeout | Connect time out | 10000 ms pingTimeout | Max time to wait for a server ping | 45000 ms strategy | Our reconnect strategies | ""disconnect,online,timeout"" manual | Manually open the connection | false websockets | Should we use WebSockets | Boolean, is detected network | Use native online/offline detection | Boolean, is feature detected transport | Transport specific configuration | {} queueSize | Number of messages that can be queued | Infinity There are 2 important options that we're going to look a bit closer at. Reconnect When the connection goes down unexpectedly an automatic reconnect process is started. It uses a randomised exponential back-off algorithm to prevent clients from DDoSing your server when you reboot as they will all be re-connecting at different times. The reconnection can be configured using the options argument in Primus and you should add these options to the reconnect property: Name | Description | Default --------------------|------------------------------------------|--------------- max | Maximum delay for a reconnection attempt | Infinity min | Minimum delay for a reconnection attempt | 500 ms retries | Maximum amount of attempts | 10 reconnect timeout | Maximum time for an attempt to complete | 30000 ms factor | Exponential back off factor | 2 When you're going to customize min please note that it will grow exponentially e.g. 500 -> 1000 -> 2000 -> 4000 -> 8000 and is randomized so expect to have slightly higher or lower values. Please note that when we reconnect, we will receive a new connection event on the server and a new open event on the client, as the previous connection was completely dead and should therefore be considered a new connection. If you are interested in learning more about the backoff algorithm you might want to read http://dthain.blogspot.nl/2009/02/exponential-backoff-in-distributed.html Strategy The strategy allows you to configure when you want a reconnect operation to kick in. We're providing some sane defaults for this but we still want to provide users with highest level of customization: disconnect Reconnect when we detect an unintentional disconnect in the connection. online Reconnect when the browser went from an offline event to an online event. timeout Reconnect when we failed to establish our initial connection. This can happen because we took too long to connect or because there was an error while we tried to connect (which happens when you connect to a dead server) You can supply these options as a comma-separated String: Or as an Array: We'll try to normalize everything as much as possible, we toLowerCase everything and join it back to a readable string so if you wrote dIsconNect it will get normalized to disconnect. If you are using authentication you should disable the timeout strategy as there is no way of detecting the difference between a failed authorization and a failed connect. If you leave this enabled with authorization every unauthorized access will try to reconnect again. We automatically disable this for you when you've set the authorization before you save the library. But there are always use cases where reconnection is not advised for your application. In these cases we've provided a way to completely disable the reconnection, this is done by setting the strategy to false: If you want to manually control the reconnection you can call primus.end() to close the connection and primus.open() to establish a new one. Be sure to use primus.open() correctly, see below for details. transport The transport object allows you to add a transport specific configuration. We only recommend using this if you understand and accept the following consequences: Primus will try to override configuration properties that are needed to ensure a correct functioning. We might start using options without any announcement or major version bump. Expect your client and its connection to malfunction once you switch between different transports, as these configurations are specific to the bundled transformer library/client. Bugs and bug reports caused by using this functionality are closed immediately. Having that said, this gives you total freedom while still getting the benefits of Primus. primus.open() This method opens a connection with the server. By default it is called automatically when the Primus instance is created, but there are cases where it's desirable to open the connection manually. To do this set the manual option to true and when you have the Primus instance call the method: When you call primus.open() you should make sure that the connection is totally dead (e.g. after an end event) and primus isn't already trying or planning to reconnect. primus.write(message) Once you've created your Primus instance you're ready to go. When you want to write data to your server you can just call the .write method: It automatically encodes your messages using the parser that you've specified on the server. So sending objects back and forth between the server is nothing different then just writing: When you are sending messages to the server, you don't have to wait for the open event to happen, the client will automatically buffer all the data you've send and automatically write it to the server once it's connected. The client supports a couple of different events. primus.on('data') The data event is the most important event of the whole library. It's emitted when we receive data from the server. The data that is received is already decoded by the specified parser. primus.on('open') The open event is emitted when we've successfully created a connection with the server. It will also be emitted when we've successfully reconnected after the connection goes down unintentionally. primus.on('error') The error event is emitted when something breaks that is out of our control. Unlike Node.js, we do not throw an error if no error event listener is specified. In general, when there is an active connection, it is not directly closed when an error event is emitted. The cause of an error, in fact, could be that the parser failed to encode or decode a message. In this case we only emit the error, discard the message and keep the connection alive. An error event can also be emitted when a connection fails to establish. When this happens the client automatically tries to reconnect, unless the connection gets closed for some other reason. The only exception is when there is an authorization hook. If we get an error when connecting to a server where authorization is required, we simply close the connection, as we can't determinate if the error is the result of an unauthorized access or not. primus.on('reconnect') The reconnect event is emitted when we're attempting to reconnect to the server. This all happens transparently and it's just a way for you to know when these reconnects are actually happening. primus.on('reconnect scheduled') Looks a lot like the reconnect event mentioned above, but it's emitted when we've detected that connection went/is down and we're going to start a reconnect operation. This event would be ideal to update your application's UI when the connection is down and you are trying to reconnect in x seconds. primus.on('reconnected') The client successfully reconnected with the server. primus.on('reconnect timeout') The reconnect timeout event is emitted when a reconnection attempt takes too much time. This can happen for example when the server does not answer a request in a timely manner. After this event a whole new reconnection procedure is automatically started, so you don't have to worry about it. primus.on('reconnect failed') This event is emitted when the reconnection failed, for example when all attempts to reconnect have been unsuccessful. primus.on('end') The end event is emitted when we've closed the connection. When this event is emitted you should consider your connection to be fully dead with no way of reconnecting. But it's also emitted when the server closes the connection. primus.end() When you want to close the connection you can call the primus.end() method. After this the connection should be considered dead and a new connection needs to be made using Primus.connect(url) or primus = new Primus(url) if you want to talk with the server again. primus.destroy() This method literally destroys the primus instance. Internally it calls the primus.end() method but it also frees some potentially heavy objects like the underlying socket, the timers, the message transformers, etc. It also removes all the event listeners but before doing that it emits a final destroy event. Keep in mind that once this method is executed, you can no longer use primus.open() on the same primus instance. primus.emits(event, parser) This method is analogous to the spark.emits method. It returns a function that emits the given event every time it's called. See emits for detailed usage instructions. primus.id(callback) There are cases where it is necessary to retrieve the spark.id from the client. To make this easier, we added a primus.id() method that takes a callback function to which the id will be passed. Connecting from the server There are two ways of creating a server side client. When you've created your primus instance you can access the Socket property on it. This Socket is automatically configured to connect to the correct pathname, using the same transformer and parser that you've specified when you created your primus instance. You might need to connect from a different node process where you don't have access to your primus instance and the compatible Socket instance. For these cases there a special createSocket method where you can specify the transformer, parser, plugin that you are using on your server to create another compatible socket. When you are using plugins with Primus make sure you add them before you reference the primus.Socket or it will compile a client without your plugins. If you're using the Primus.createSocket api you can directly supply the plugins as part of the options as it supports plugin object: The constructor returned by primus.Socket or Primus.createSocket has the same signature of the constructor used to connect from the browser. This means that you can use all the options mentioned in the previous section: If you do not know which transformer and parser are used on the server, we expose a small JSON ""spec"" file that exposes this information. The specification can be reached on the /<pathname>/spec and will output the following JSON document: Authorization Server Primus has a built-in auth hook that allows you to leverage the basic auth header to validate the connection. To setup the optional auth hook, use the Primus#authorize method: In this particular case, if an error is passed to done by authCheck or the exception handler then the connection attempt will never make it to the primus.on('connection') handler. The error you pass can either be a string or an object. If an object, it can have the following properties which affect the response sent to the client: statusCode: The HTTP status code returned to the client. Defaults to 401. authenticate: If set and statusCode is 401 then a WWW-Authenticate header is added to the response, with a value equal to the authenticate property's value. message: The error message returned to the client. The response body will be {error: message}, JSON-encoded. If the error you pass is a string then a 401 response is sent to the client with no WWW-Authenticate header and the string as the error message. For example to send 500 when an exception is caught, 403 for forbidden users and details of the basic auth scheme being used when authentication fails: Please note that the auth hook is run each and every time a request is made to the server. Client Unfortunately, the amount of detail you get in your client when authorization fails depends on the transformer in use. Most real-time frameworks supported by Primus don't expose the status code, headers or response body. The WebSocket transformer's underlying transport socket will fire an unexpected-response event with the HTTP request and response: If you want to read the response body then you can do something like this: If unexpected-response isn't caught (because the WebSocket transformer isn't being used or you don't listen for it) then you'll get an error event: As noted above, err won't contain any details about the authorization failure so you won't be able to distinguish it from other errors. Broadcasting Broadcasting allows you to write a message to every connected Spark on your server. There are 2 different ways of doing broadcasting in Primus. The easiest way is to use the Primus#write method which will write a message to every connected user: There are cases where you only want to broadcast a message to a smaller group of users. To make it easier to do this, we've added a Primus#forEach method which allows you to iterate over all active connections. The method can be also used asynchronously. To enable the asynchronous iteration you have to call Primus#forEach with two arguments. The first is the iterator function that is called on every step. The iterator is called with a connection from the list and a callback for when it has finished. The second argument is the main callback and is called when the iteration has finished. There are also cases where you want to select a single Spark. To do this you can use the Primus#spark method. This method returns a Spark or undefined if the given id doesn't match any of the active Spark ids on the server. Destruction In rare cases you might need to destroy the Primus instance you've created. You can use the primus.destroy() or primus.end() method for this. This method accepts an Object which allows you to configure the destruction process: close Close the HTTP server that Primus received. Defaults to true. reconnect Automatically reconnect the clients. Defaults to false. timeout Close all active connections and clean up the Primus instance after the specified amount of timeout. Defaults to 0. The timeout is especially useful if you want gracefully shutdown your server but really don't want to wait an infinite amount of time. Events Primus is built upon the Stream and EventEmitter interfaces. This is a summary of the events emitted by Primus. Event | Usage | Location | Description ----------------------|-------------|---------------|---------------------------------------- outgoing::reconnect | private | client | Transformer should reconnect. reconnect scheduled | public | client | We're scheduling a reconnect. reconnect | public | client | Reconnect attempt is about to be made. reconnected | public | client | Successfully reconnected. reconnect timeout | public | client | Reconnect attempt took too much time. reconnect failed | public | client | Failed to reconnect. timeout | public | client | Failed to connect to server. outgoing::open | private | client/spark | Transformer should connect. incoming::open | private | client/spark | Transformer has connected. open | public | client | Connection is open. destroy | public | client | The instance has been destroyed. incoming::error | private | client | Transformer received an error. error | public | client/spark | An error happened. incoming::data | private | client/server | Transformer received data. outgoing::data | private | client/spark | Transformer should write data. data | public | client/spark | We received data. incoming::end | private | client/spark | Transformer closed the connection. outgoing::end | private | client/spark | Transformer should close connection. end | public | client/spark | The connection has ended. close | public | client/server | The connection has closed, we might reconnect. / The server has been destroyed. connection | public | server | We received a new connection. disconnection | public | server | We received a disconnection. initialised | public | server | The server is initialised. plugin | public | server | A new plugin has been added. plugout | public | server | A plugin has been removed. incoming::ping | private | client | We received a ping message. outgoing::ping | private | spark | We're sending a ping message. incoming::pong | private | spark | We received a pong message. outgoing::pong | private | client | We're sending a pong message. heartbeat | public | spark | We've received a response to a heartbeat. online | public | client | We've regained a network connection. offline | public | client | We've lost our internet connection. log | public | server | Log messages. readyStateChange | public | client/spark | The readyState has changed. outgoing::url | private | client | The options used to construct the URL. As a rule of thumb assume that every event that is prefixed with incoming:: or outgoing:: is reserved for internal use only and that emitting such events your self will most likely result in chaos and destruction. To make it easier for developers to emit events on Primus itself, we've added a small helper function that checks if the event you want to emit is reserved for Primus only. This would be all incoming:: and outgoing:: prefixed events and the events listed above. This method is called <class>.reserved() and it's implemented on the Spark: But also the client: And of course the Primus instance as well. Heartbeats and latency Heartbeats are used in Primus to figure out if we still have an active, working and reliable connection with the server. These heartbeats are sent from the server to the client as shown in the following diagram. The heartbeat message that we send over the connection is primus::ping::<timestamp>. Upon receipt of this message, the client will send back a primus::pong::<timestamp> message with the same <timestamp> it received from the server. This allows to calculate the latency between messages by simply getting the <timestamp> and comparing it with the local time. Supported Real-time Frameworks The following transformers/transports are supported in Primus: BrowserChannel BrowserChannel was the original technology that GMail used for their real-time communication. It's designed for same domain communication and does not use WebSockets. To use BrowserChannel you need to install the browserchannel module: And tell Primus that you want to use browserchannel as transformer: The browserchannel transformer comes with built-in node client support and can be accessed using: Please note that you should use at least version 1.0.6 which contains support for query strings. Engine.IO Engine.IO is the low level transport functionality of Socket.IO 1.0. It supports multiple transports for creating a real-time connection. It uses transport upgrading instead of downgrading which makes it more resilient to blocking proxies and firewalls. To enable engine.io you need to install the engine.io module: And tell Primus that you want to use engine.io as transformer: If you want to use the client interface inside of Node.js you also need to install the engine.io-client: And then you can access it from your server instance: Faye Faye is a WebSocket only transformer. It uses the faye-websocket module which is part of the Faye project and supports all protocol specifications. To use this you need to install the faye-websocket module: And tell Primus that you want to use faye as transformer: The faye transformer comes with built-in node client support and can be accessed using: SockJS SockJS is a real-time server that focuses on cross-domain connections and does this by using multiple transports. To use SockJS you need to install the sockjs module: And tell Primus that you want to use sockjs as transformer: If you want to use the client interface inside of Node.js you also need to install the sockjs-client module: And then you can access it from your server instance: uws uws is a WebSocket only transformer. It uses the uws module which is probably the fastest WebSocket server available in Node.js. To use uws you have to install the uws module: And tell Primus that you want to use uws as transformer: If you want to use the client interface inside of Node.js you also need to install the ws module: And then you can access it from your server instance: WebSockets If you are targeting a high end audience or maybe just need something for internal uses you can use a pure WebSocket server. This transformer uses the popular ws module which is battle tested and supports all protocol specifications. To use WebSockets you need to install the ws module: And tell Primus that you want to use WebSockets as transformer: The WebSockets transformer comes with built-in node client support and can be accessed using: As you can see from the examples above, it doesn't matter how you write the name of the transformer, we just toLowerCase() everything. Transformer inconsistencies BrowserChannel does not give you access to the remotePort of the incoming connection. So when you access spark.address the port property will be set to 1337 by default. BrowserChannel is the only transformer that does not support cross domain connections. BrowserChannel and SockJS are written in CoffeeScript and this can make debugging harder when their internals fail. Engine.IO and SockJS do not ship their client-side library with their server side component. We're bundling a snapshot of these libraries inside of Primus. We will always be targeting the latest version of these transformers when we bundle the library. Parsers In addition to support different frameworks we've also made it possible to use custom encoding and decoding libraries. We're using JSON by default but you could also use binary or EJSON for example (but these parsers need to be supported by Primus, so check out the parser folder for examples). To specify the parser to use you can supply a parser configuration option: All parsers have an async interface for error handling. Middleware Primus has two ways of extending the functionality. We have plugins but also support middleware. And there is an important difference between these. The middleware layers allows you to modify the incoming requests before they are passed in to the transformers. Plugins allow you to modify and interact with the sparks. The middleware layer is only run for the requests that are handled by Primus. We support 2 kind of middleware, async and sync middleware. The main difference between these kinds is that sync middleware doesn't require a callback, it is completely optional. In Primus, we eat our own dog food. Various of components in Primus are implemented through middleware layers: cors: Adds the Access Control headers. primus.js: It serves our primus.js client file. spec: It outputs the server specification (version, transformer, path). authorization: Our authorization handler, which is implemented as a middleware. no-cache: Add no-cache headers to every HTTP request. x-xss: Add X-XSS-Protection headers to every HTTP request. Primus.use(name, fn, options, index) The primus.use method is how you add middleware layers to your system. All middleware layers need to be named. This allows you to also enable, disable and remove middleware layers. The supplied function can either be a pre-configured function that is ready to answer request/response or an unconfigured middleware. An unconfigured middleware is a function with less then 2 arguments. We execute this function automatically with Primus as context of the function and optionally, the options that got provided: As you can see in the example above, we assume that you return the actual middleware layer. If you don't need any pre-configuration you can just supply the function directly: You need to be aware that these middleware layers are running for HTTP requests but also for upgrade requests. Certain middleware layers should only run for HTTP or Upgrade requests. To make it possible you can add a http or upgrade property to the middleware function and set it to false if you don't want it to be triggered. By default a new middleware layer is added after the previous one, but there are cases where you need to add a middleware at a specified index in the stack. To accomplish this you can use the optional 0 based index argument. Primus.remove(name) This method allows you to remove configured middleware. This works for the middleware layers that you added but also the middleware layers that we add by default. If you want to use a different way to serve the primus.js file you can simply: And add your own middleware instead. Primus.disable(name) In addition to removing middleware layers, it's also possible to disable them so they are skipped when we iterate over the middleware layers. It might be useful to just disable certain middleware layers in production. Primus.enable(name) Of course, when you can disable middleware there also needs to be way to enable them again. This is exactly what this method does. Re-enable a disabled middleware layer. Plugins Primus was built as a low level interface where you can build your applications upon. At it's core, it's nothing more than something that passes messages back and forth between the client and server. To make it easier for developers to switch to Primus we've developed a simple but effective plugin system that allows you to extend Primus's functionality. Plugins are added on the server side in the form of an Object: Or you can pass the plugin Object directly into the constructor: And last but not least, you can also supply the constructor with a comma or space separated list of plugin names which will be required automatically: To remove added plugins you can use the plugout method: The server function is only executed on the server side and receives 2 arguments: A reference to the initialised Primus server. The options that were passed in the new Primus(server, { options }) constructor. So the plugin can be configured through the same interface. The client receives the same arguments: A reference to the initialised Primus client. The options that were passed in the new Primus(url, { options }) constructor. So the plugin can be configured through the same interface. The only thing you need to remember is that the client is stored in the library using toString() so it cannot have any references outside the client's closure. But luckily, there's a library property that will also be included on the client side when it's specified. The library property should be an absolute path to the library file. Intercepting the connection events The connection event is emitted using a async emitter. It checks if your supplied event emitter function has extra callback function. When it detects this it will wait with the execution of the other assigned listeners until the callback has been called. Please note that the order of assigning event listeners is still respected so if you've assigned a connection listener before an async connection listener it will still be executed first. When an error argument is supplied it will automatically end the connection and emit an error event on the spark. If you are coming from Socket.IO 1.0 >=, this will basically work the same way as their middleware system. Extending the Spark / Socket The server has a .Spark property that can be extended. This allows you to easily add new functionality to the socket. For example adding join room function would be as easy as: Transforming and intercepting messages Intercepting and transforming messages is something that a lot of plugins require. When you're building an EventEmitter plugin or something else you probably don't want the default data event to be emitted but your custom event. There are 2 different types of messages that can be transformed: incoming These messages are being received by the server. outgoing These messages are being sent to the client. The transformer is available on both the client and the server and share, like you would have expected the same identical API. Adding a new transformer is relatively straightforward: These transformations can easily be done in the plugins: We also expose asynchronous interfaces for these transformers. If your function accepts 2 arguments we automatically assume it's async and that the last argument is the callback variable: Primus project plugins The following plugins are part of the Primus project. fortess-maximus Fortress Maximus validates every incoming message on your Primus server as all user input should be seen as a potential security risk. metroplex Metroplex is a Redis based spark/connection registry for Primus. It stores the sparks and their server address. So you can cluster multiple primus's together with Metroplex and Omega Supreme mirage Mirage generates and validates persistent session IDs. omega-supreme Omega Supreme allows you to broadcast messages to Primus using a regular HTTP request. These messages can be broacasted to every spark, single spark or a collection of sparks. primus-analytics Integrates Primus with Google Analytics. primus-emit The emit module adds client -> server and server -> client event emitting to Primus. substream Substream is an opinionated but stream compatible connection multiplexer on top of the Primus connections. These streams can be created without pre-defining them on the server or client. Community plugins These are also plugins created by our amazing community. Do you have a module that you want to have listed here? Make sure it has test suite and runs on Travis CI. After that open a pull request where you added your module to this README.md and see it be merged automatically. backbone.primus Bind primus.io events to backbone models and collections. hapi_primus_sessions A hapi and primus plugin which extends primus' spark with a `getSession(cb)` method which returns the current hapi session object. primus-cluster Scale Primus across multiple servers or with node cluster. primus-emitter A module that adds emitter capabilities to Primus. primus-express-session Share a user session between Express and Primus. primus-multiplex A module that adds multiplexing capabilities to Primus. primus-redis primus-redis is a Redis store for Primus. It takes care of distributing messages to other instances using Redis Pub/Sub. primus-redis-rooms primus-redis-rooms is a Redis store for Primus and primus-rooms. primus-resource Define resources with auto-bound methods that can be called remotely on top of Primus. primus-responder Client and server plugin that adds a request/response cycle to Primus. primus-rooms A module that adds rooms capabilities to Primus. It's based on the rooms implementation of Socket.IO. primus-rooms-redis-adapter A redis adapter for primus-rooms module. Supports integration with metroplex and omega-supreme. primus-spark-latency Adds a latency property to primus sparks server-side. Community Deployed Primus to production or built an awesome demo using the technology? We've set up a special wiki page for it where you can show your awesome creations or learn from demo and example applications how to use Primus. Checkout the wiki page at: https://github.com/primus/primus/wiki/Production FAQ What is the best way to scale Primus Scaling Primus is as simple as sticking it behind a load balancer that supports sticky sessions and run multiple versions of your application. This is a vital feature that your load balancer needs to support. This ensures that the incoming requests always go back to the same server. If your load balancer does not support sticky sessions, get another one. I highly recommend HAProxy. According to my own testing it is the fastest and best proxy available that supports WebSockets. See https://github.com/observing/balancerbattle for more detailed information. The reason for which sticky-sessions are so important is that a lot of frameworks that use polling transports require to save a state in the node process in order to work correctly. This state contains times, sessions ids, handshake data etc. If a request from the same client does not enter the same node process it will be treated as an unknown request and your real-time connection will be closed. If you want more advanced scaling and messaging please take a look at the various plugins we've written for this scope. Plugins like metroplex, omega-supreme and primacron can be time savers. Can I use cluster? Note: The following only applies to websocket emulation transformers like sockjs or engine.io. If you are using ws, uws or faye-websocket, there is no need for sticky sessions, and thus no issue. The cluster module that ships with Node.js does not implement sticky sessions. There are projects like stick-session which attempt to implement sticky-sessions in cluster, but the problem with this specific approach is that it uses the remoteAddress of the connection. For some people this isn't a problem but when you add this behind a load balancer the remote address will be set to the address of the load balancer that forwards the requests. So all in all it only causes more scalability problems instead of solving them. This is why we've opted to warn people about the risks of cluster when we detect that the Primus library is run in a worker environment. USE IT AT YOUR OWN RISK. To turn off the cluster warning in your Primus instance you can set the option iknowclusterwillbreakconnections to true. How do I use Primus with Express Express' express() instance isn't a valid HTTP server. In order to make it work with Primus and other real-time transformers you need to feed the instance to a real http server and supply this server. See example below: Is require.js supported Require.js is supported to a certain degree. The primus.js core file should be compatible with require.js but it could be that the transformer of your choosing isn't compatible with require.js. For example engine.io uses component which introduces it's own require function that causes issues. In addition to that, there are plugins which might use these modules that break require.js. The general advice for this is to drop require.js in favour of plain script loading or use of browserify where possible. If you feel strong about require.js we accept pull requests that improve this behaviour or helps us save guard against these issues. Can I send custom headers to the server It is not possible to send custom headers from the client to the server. This is because these headers need to be set by the actual transports that the transformers are using. The only transport that would support this would be AJAX polling. To send custom data to the server use a query string in your connection URL, as this is something that all transports support. Versioning History You can discover the version history and change logs on the Releases page Convention All 0.x.x releases should be considered unstable and not ready for production. The version number is laid out as: major.minor.patch and tries to follow semver as closely as possible but this is how we use our version numbering: major A major and possible breaking change has been made in the primus core. These changes are not backwards compatible with older versions. minor New features are added or a big change has happened with one of the real-time libraries that we're supporting. patch A bug has been fixed, without any major internal and breaking changes. Release cycle There isn't a steady or monthly release cycle. We usually release a new version when: A critical bug is discovered. There have been a lot of minor changes. A framework did an incompatible update. A new framework is added. People ask for it. Other languages These projects are maintained by our valuable community and allow you to use Primus in a different language than JavaScript: primus-objc A client written in Objective-C for the Primus real-time framework with initial support for web sockets (via SocketRocket) and socket.io (via socket.IO-objc). Easily switch between different real-time Objective-C frameworks without any code changes. primus-android A Primus client written in Java for Android with initial support for web sockets via AndroidAsync. Want to have your project listed here? Add it using a pull-request! Protocol Primus uses some internal protocol messages in order to keep the connection open and stable between a client and a server. If you are planning on implementing Primus in another language you must handle the following primus::* prefixed messages: primus::ping::<ping> server -> client, The ping type contains the time in EPOCH. Ping messages are needed to keep the connection open as certain load balancers, proxies and browsers will close connections automatically when there is inactivity. primus::pong::<ping> client -> server, The pong is the response to the ping packet. It echoes back the exact value that it received. primus::server::close server -> client, Indication that the server intentionally closed the connection and that no reconnection/connection should be made. primus::id:: client -> server, Request of the internal spark.id that's assigned to the connection. primus::id::<spark.id> server -> client, The internal id that we used on the server to identify the connection as we do not sync this information by default and requires a primus.id() call on the client. Any other message that is prefixed with primus:: should be ignored and not emitted to the user. License MIT"
3114,"jQuery form validation pluginjQuery.validationEngine v3.1.0 Looking for official contributors This project has now been going on for more than 7 years, right now I only maintain the project through pull request contributions. However, I would love to have help improving the code quality and maintain an acceptable level of open issues. Summary jQuery validation engine is a Javascript plugin aimed at the validation of form fields in the browser (IE 6-8, Chrome, Firefox, Safari, Opera 10). The plugin provides visually appealing prompts that grab user attention on the subject matter. Validations range from email, phone, and URL, to more complex calls such as ajax processing or custom javascript functions. Bundled with many locales, the error prompts can be translated into the language of your choice. Documentation : Nicer documention Release Notes Installation What's in the archive? Download tar.gz 3.0.0 or zip 3.0.0 The archive holds, of course, the core library along with translations in different languages. It also comes with a set of demo pages and a simple ajax server (built in Java and php). Unpack the archive Include the script jquery.validationEngine.closure.js in your page Pick the locale of the choice and include it in your page: jquery.validationEngine-XX.js Read this manual and understand the API Usage References First include jQuery on your page Include jquery.validationEngine and its locale Finally include the desired theme Field Validations Validations are defined using the field's class attribute. Here are a few examples showing how it happens: For more details about validators, please refer to the section below. Experimental attribute data-validation-engine We are currently in the process of replaceing the class attribute by something more standard, it should normally work but consider this feature in beta. Standard HTML5 attribute for error message Customize error messages with data-errormessage and data-errormessage-* attributes on the form elements. For example: The following attribute's value will be loaded for the relative validation rule: data-errormessage-value-missing required groupRequired condRequired data-errormessage-type-mismatch past future dateRange dateTimeRange data-errormessage-pattern-mismatch creditCard equals data-errormessage-range-underflow minSize min minCheckbox data-errormessage-range-overflow maxSize max maxCheckbox data-errormessage-custom-error custom ajax funcCall data-errormessage a generic fall-back error message Per Field Prompt Direction Prompt direction can be define using the field's data attribute. Here are a few examples showing how it happens: Prompt Position Adjustment Prompt position can be adjusted by providing shiftX and shiftY with position type in the field's data attribute. Prompt will be placed in (defaultX+shiftX),(defaultY+shiftY) position instead of default for selected position type. Here are a few examples showing how it happens: Instantiation The validator is typically instantiated with a call in the following format, the plugin can only be instanciated on form elements: Without any parameters, the init() and attach() methods are automatically called. The method may take one or several parameters, either an action (and parameters) or a list of options to customize the behavior of the engine. Here's a glimpse: say you have a form as such: The code below will instantiate the validation engine and attach it to the form: When using options, the default behavior is to only initialize ValidationEngine, so attachment needs to be done manually. All calls to validationEngine() are chainable, so one can do the following: Actions attach Attaches jQuery.validationEngine to form.submit and field.blur events. detach Unregisters any bindings that may point to jQuery.validaitonEngine. validate Validates a form or field, displays error prompts accordingly. Returns true if the form validates, false if it contains errors. For fields, it returns false on validate and true on errors. When using form validation with ajax, it returns undefined , the result is delivered asynchronously via function options.onAjaxFormComplete. showPrompt (promptText, type, promptPosition, showArrow) Displays a prompt on a given element. Note that the prompt can be displayed on any element by providing an id. The method takes four parameters: 1. the text of the prompt itself 2. a type which defines the visual look of the prompt: 'pass' (green), 'load' (black) anything else (red) 3. an optional position: either ""topLeft"", ""topRight"", ""bottomLeft"", ""centerRight"", ""bottomRight"". Defaults to ""topRight"" 4. an optional boolean which indicates if the prompt should display a directional arrow hide The hide method can be applied to a form or a field. It closes/hides error prompts. hideAll Closes/hides all error prompts on the page no matter what form they are attached to. updatePromptsPosition Update the form prompts positions. hidePrompt & validateField Deprecated and not part of the code base anymore. Use hide and validate instead. Options Options are typically passed to the init or attach action as a parameter. validationEventTrigger Name of the event triggering field validation, defaults to blur. scroll Determines if we should scroll the page to the first error, defaults to true. binded If set to false, it removes blur events and only validates on submit. promptPosition Where should the prompt show? Possible values are ""topLeft"", ""topRight"", ""bottomLeft"", ""centerRight"", ""bottomRight"". Defaults to ""topRight"". Default position adjustment could also be provided. showOneMessage Only display the first incorrect validation message instead of normally stacking it. It will follows the validation hierarchy you used in the input and only show the first error. ajaxFormValidation If set to true, turns Ajax form validation logic on. Defaults to false. Form validation takes place when the validate() action is called or when the form is submitted. ajaxFormValidationURL If set, the ajax submit validation will use this url instead of the form action ajaxFormValidationMethod HTTP method used for ajax validation, defaults to 'get', can be set to 'post' onBeforeAjaxFormValidation(form, options) When ajaxFormValidation is turned on, this is the function that will be called before the asynchronous AJAX form validation call. May return false to stop the Ajax form validation onAjaxFormComplete: function(status, form, errors, options) When ajaxFormValidation is turned on, this function is used to asynchronously process the result of the validation. the status is a boolean. If true, the ajax call completed and all the server side form validations passed. onValidationComplete When defined, it stops by default the form from auto-submitting, and lets you handle the validation status via a function. You can also return true in this function and the form will be allowed to submit. custom_error_messages This is where custom messages for IDs, Classes, or validation types are stored. Custom error messages are exclusive from one another.ID messages will be displayed instead of anything else; Class messages will only be used if there is no ID message, and only the first message found associated with one of the classes will be used; Global Validator messages will only be used if there are no Class messages or ID messages. These custom messages are declared in this manner: focusFirstField Specifies whether or not the first field in a form receives auto-focus after validation returns false. Default is set to true. If you want to disable the auto-focusing use: onSuccess If set, this callback function will be called when all validations passed. onFailure If set, this callback function will be called when it found an error. autoPositionUpdate Auto update prompt position after window resize, disabled by default autoHidePrompt Determines if the prompt should hide itself automatically after a set period. Defaults to false. autoHideDelay Sets the number of ms that the prompt should appear for if autoHidePrompt is set to true. Defaults to 10000. showArrow Show the arrow in the validation popup. Defaults to true showArrowOnRadioAndCheckbox Show the arrow in the validation popup when validating checkboxes and radio buttons. Defaults to false Validators Validators are encoded in the field's class attribute, as follows required Speaks for itself, fails if the element has no value. This validator can apply to pretty much any kind of input field. groupRequired At least one of the field of the group must be filled. It needs to be given a group name that is unique across the form. condRequired This makes the field required, but only if any of the referred fields has a value. custom[regex_name] Validates the element's value to a predefined list of regular expressions. Please refer to the section Custom Regex for a list of available regular expressions. custom[function_name] Validates the element's value to a predefined function included in the language file (compared to funcCall that can be anywhere in your application), Please refer to the section Custom Regex for a list of available regular expressions. funcCall[methodName] Validates a field using a third party function call. If a validation error occurs, the function must return an error message that will automatically show in the error prompt. The following declaration will do ajax[selector] Delegates the validation to a server URL using an asynchronous Ajax request. The selector is used to identify a block of properties in the translation file, take the following for example. ** The validation execution order is taken form the order you put them in the HTML, it is recommended to always put the ajax[] validation last. For example, the custom events might fail if you put ajax[] in the middle. Ajax[] works on submit since 2.6. url - is the remote restful service to call extraData - optional parameters to send extraDataDynamic - optional DOM id's that should have their values sent as parameters alertText - error prompt message if validation fails alertTextOk - optional prompt if validation succeeds (shows green) alertTextLoad - message displayed while the validation is being performed This validator is explained in further details in the Ajax section. equals[field.id] Checks if the current field's value equals the value of the specified field. min[float] Validates when the field's value is less than, or equal to, the given parameter. max[float] Validates when the field's value is more than, or equal to, the given parameter. minSize[integer] Validates if the element content size (in characters) is more than, or equal to, the given integer. integer <= input.value.length maxSize[integer] Validates if the element content size (in characters) is less than, or equal to, the given integer. input.value.length <= integer past[NOW, a date or another element's name] Checks if the element's value (which is implicitly a date) is earlier than the given date. When ""NOW"" is used as a parameter, the date will be calculate in the browser. When a ""#field name"" is used ( The '#' is optional ), it will compare the element's value with another element's value within the same form. Note that this may be different from the server date. Dates use the ISO format YYYY-MM-DD future[NOW, a date or another element's name] Checks if the element's value (which is implicitly a date) is greater than the given date. When ""NOW"" is used as a parameter, the date will be calculate in the browser. When a ""#field name"" is used ( The '#' is optional ), it will compare the element's value with another element's value within the same form. Note that this may be different from the server date. Dates use the ISO format YYYY-MM-DD minCheckbox[integer] Validates when a minimum of integer checkboxes are selected. The validator uses a special naming convention to identify the checkboxes as part of a group. The following example, enforces a minimum of two selected checkboxes Note how the input.name is identical across the fields. maxCheckbox[integer] Same as above but limits the maximum number of selected check boxes. creditCard Validates that a credit card number is at least theoretically valid, according the to the Luhn checksum algorithm, but not whether the specific card number is active with a bank, etc. Selectors We've introduced the notion of selectors without giving many details about them: A selector is a string which is used as a key to match properties in the translation files. Take the following example: onlyNumber, onlyLetter and validate2fields are all selectors. jQuery.validationEngine comes with a standard set but you are welcome to add you own to define AJAX backend services, error messages and/or new regular expressions. The ValidationEngine with a datepicker Using a datepicker with the engine is problematic because the validation is bound to the blur event. since we lose the focus before any data is entered in the field it creates a weird bug. Fortunately we implemented a fix that uses a delay during the datepicker binding. To use this mode you need to add the class datepicker to your input, like this: Ajax Protocol The ajax validator takes a selector as an attribute. the selector points to a structure that defines the URL to call, the different messages to display and any extra parameters to add on the URL (when applicable). Please refer to the ajax[selector] description for more details. Ajax validation comes in two flavors: Field Ajax validations, which take place when the user inputs a value in a field and moves away. Form Ajax validation, which takes place when the form is submitted or when the validate() action is called. Both options are optional. You can see a tutorial that makes the use of php here: http://www.position-absolute.com/articles/using-form-ajax-validation-with-the-jquery-validation-engine-plugin/ Field ajax validation Protocol The client sends the fieldId and the fieldValue as a GET request to the server url. Client calls url?fieldId=id1&fieldValue=value1 ==> Server Server responds with an array: [fieldid, status, errorMsg]. Client receives <== [""id1"", boolean, errorMsg] Server fieldid is the name (id) of the field status is the result of the validation, true if it passes, false if it fails errorMsg is an optional error string (or a selector) to the prompt text. If no error msg is returned, the prompt message is expected to be part of the rule with key ""alertText"" or ""alertTextOk"" (see the structure of the translation file) Form ajax validation Protocol The client sends the form fields and values as a GET request to the form.action url. Client calls url?fieldId=id1&fieldValue=value1&...etc ==> Server (form.action) Server responds with an array of arrays: [fieldid, status, errorMsg]. fieldid is the name (id) of the field status is the result of the validation, true if it passes, false if it fails errorMsg is an error string (or a selector) to the prompt text Client receives <== [[""id1"", boolean,""errorMsg""],[""id2"", false, ""there is an error ""],[""id3"", true, ""this field is good""]] Note that normally errors (status=false) are returned from the server. However you may also decide to return an entry with a status=true in which case the errorMsg will show as a green prompt. Validation URL By default the engine use the form action to validate the form, you can however set a default url using: **ajaxFormValidationURL Callbacks Since the form validation is asynchronously delegated to the form action, we provide two callback methods: onBeforeAjaxFormValidation(form, options) is called before the ajax form validation call, it may return false to stop the request onAjaxFormComplete: function(form, status, json_response_from_server, options) is called after the ajax form validation call Custom Regex jQuery.validationEngine comes with a lot of predefined expressions. Regex validation rules are specified as follows: Note that the selector identifies a given regular expression in the translation file, but also its associated error prompt messages and optional green prompt message. phone a typical phone number with an optional country code and extension. Note that the validation is relaxed, please add extra validations for your specific country. 49-4312 / 777 777 +1 (305) 613-0958 x101 (305) 613 09 58 ext 101 3056130958 +33 1 47 37 62 24 extension 3 (016977) 1234 04312 - 777 777 91-12345-12345 +58 295416 7216 url Matches a URL such as http://myserver.com, https://www.crionics.com or ftp://myserver.ws email Easy, an email : username@hostname.com date An ISO date, YYYY-MM-DD number Floating points with an optional sign. ie. -143.22 or .77 but also +234,23 integer Integers with an optional sign. ie. -635 +2201 738 ipv4 and ipv6 An IP address (v4) ie. 127.0.0.1 or v6 2001:0db8:85a3:08d3:1319:8a2e:0370:7344 onlyNumberSp Only numbers and spaces characters onlyLetterSp Only letters and space characters onlyLetterNumber Only letters and numbers, no space Position fixed and overflow scroll Before 2.5.3 some options were needed to use the engine in a div with overflow scroll or position fixed, now you just have to set position relative on the form and you are good to go. Placeholders The engine support by default placeholders when a field is required. use the attribute data-validation-placeholder in the input to define it. Hooks The plugin provides some hooks using jQuery bind functionality. jqv.form.validating : Trigger when the form is submitted and before it starts the validation process jqv.field.result(event, field, errorFound, prompText) : Triggers when a field is validated with the result. jqv.form.result(event, errorFound) : Triggers when a form is validated with the result An example of binding a custom function to these events would be: Customizations What would a good library be without customization? Adding regular expressions Adding new regular expressions is easy: open your translation file and add a new entry to the list ""onlyLetter"" is a sample selector name ""regex"" is a javascript regular expression ""alertText"" is the message to display when the validation fails You can now use the new regular expression as such Don't forget to contribute! Customizing the look and feel Edit the file validationEngine.jquery.css and customize the stylesheet to your liking. it's trivial if you know CSS. Adding more locales You can easily add a locale by taking jquery.validationEngine-en.js as an example. Feel free to share the translation ;-) Changing defaults options globally You can, for example, disable the scrolling globally by using $.validationEngine.defaults.scroll = false. This need to be added before the initialization, one good way to handle this would be to add your settings in a file. Using the validationEngine with modal & dialog plugins You can have more information about implementing the engine with modal views here: [http://www.position-absolute.com/articles/using-the-jquery-validation-engine-with-modal-plugins/] Rules of thumb field.id is unique across the page From 2.2.4 and up, jquery 1.6+ is required because of prop() for simplicity and consistency field.id and field.name should match (except with minCheckbox and maxCheckbox validators) spaces or special chars should be avoided in field.id or field.name use lower case for input.type ie. text, password, textarea, checkbox, radio validators are evaluated from left to right, use the Ajax validator last e.g. validate[custom[onlyLetter],length[0,100],ajax[ajaxNameCall]] please use only one Ajax validator per field! JSON services should live on the same server (or you will get into browser security issues) in a perfect RESTful world, http GET is used to READ data, http POST is used to WRITE data: which translates into -> Ajax validations should use GET, the actual form post should use a POST request. Contribution Contributions are always welcome, please follow these steps to submit your changes: Install git from http://git-scm.com/ Create a github account on https://github.com Set up your git ssh key using these instructions http://help.github.com/set-up-git-redirect Open the jQuery Validation Engine project home page on github on https://github.com/posabsolute/jQuery-Validation-Engine Click the ""Fork"" button, this will get you to a new page: your own copy of the code. Copy the SSH URL at the top of the page and clone the repository on your local machine Create a branch and switch to it Apply your changes, then commit using a meaningful comment, that's the comment everybody will see! Push the changes back to github (under a different branch, here myfeature-patch) Open your forked repository on github at https://github.com/your-username/jQuery-Validation-Engine Click ""Switch Branches"" and select your branch (mynewfeature-patch) Click ""Pull Request"" Submit your pull request to JQV Developers Support We offer limited support on http://www.stackoverflow.com/ Use the tag jQuery-Validation-Engine License Licensed under the MIT License Authors Copyright(c) 2011 Cedric Dugas http://www.position-absolute.com v2.0 Rewrite by Olivier Refalo http://www.crionics.com"
3481,"Fast and simple OCR library written in Swift This Project is deprecated and no longer gets maintained! Please use Apple's Vision framework instead of SwiftOCR. It is very fast, accurate and much less finicky. SwiftOCR SwiftOCR is a fast and simple OCR library written in Swift. It uses a neural network for image recognition. As of now, SwiftOCR is optimized for recognizing short, one line long alphanumeric codes (e.g. DI4C9CM). We currently support iOS and OS X. Features [x] Easy to use training class [x] High accuracy [x] Great default image preprocessing [x] Fast and accurate character segmentation algorithm [x] Add support for lowercase characters [x] Add support for connected character segmentation Why should I choose SwiftOCR instead of Tesseract? This is a really good question. If you want to recognize normal text like a poem or a news article, go with Tesseract, but if you want to recognize short, alphanumeric codes (e.g. gift cards), I would advise you to choose SwiftOCR because that's where it exceeds. Tesseract is written in C++ and over 30 years old. To use it you first have to write a Objective-C++ wrapper for it. The main issue that's slowing down Tesseract is the way memory is managed. Too many memory allocations and releases slow it down. I did some testing on over 50 difficult images containing alphanumeric codes. The results where astonishing. SwiftOCR beat Tesseract in every category. | | SwiftOCR | Tesseract | | -------- | :-------: | :-------: | | Speed | 0.08 sec. | 0.63 sec. | | Accuracy | 97.7% | 45.2% | | CPU | ~30% | ~90% | | Memory | 45 MB | 73 MB | How does it work? 1) Input image is thresholded (binarized). 2) Characters are extracted from the image, using a technique called Connected-component labeling. 3) Separated characters are converted into numbers, which are then fed into the neural network. How to use it? SwiftOCR is available through CocoaPods. To install it, simply add the following line to your Podfile: pod 'SwiftOCR' If you ever used Tesseract you know how exhausting it can be to implement OCR into your project. SwiftOCR is the exact opposite of Tesseract. It can be implemented using just 6 lines of code. To improve your experience with SwiftOCR you should set your Build Configuration to Release. Training Training SwiftOCR is pretty easy. There are only a few steps you have to do, before it can recognize a new font. The easiest way to train SwiftOCR is using the training app that can be found under /example/OS X/SwiftOCR Training. First select the fonts you want to train from the list. After that, you can change the characters you want to train in the text field. Finally, you have to press the Start Testing button. The only thing that's left now, is waiting. Depending on your settings, this can take between a half and two minutes. After about two minutes you may manually stop the training. Pressing the Save button will save trained network to your desktop. The Test button is used for evaluating the accuracy of the trained neural network. Examples Here is an example image. SwiftOCR has no problem recognizing it. If you try to recognize the same image using Tesseract the output is 'LABMENSW' ?!?!?. This image is difficult to recognize because of two reasons: - The lighting is uneven. This problem is solved by the innovative preprocessing algorithm of SwiftOCR. - The text in this image is distorted. Since SwiftOCR uses a neural network for the recognition, this isn't a real problem. A NN is flexible like a human brain and can recognize even the most distorted image (most of the time). TODO [ ] Port to GPUImage 2 Dependencies Swift-AI GPUImage Union-Find License The code in this repository is licensed under the Apache License, Version 2.0 (the ""License""); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License. NOTE: This software depends on other packages that may be licensed under different open source licenses."
2245,"UI Web Components for Modern Web AppsBrick Brick is a collection of UI components designed for the easy and quick building of web application UIs. Brick components are built using the Web Components standard to allow developers to describe the UI of their app using the HTML syntax they already know. Install Brick can be installed using the Bower package manager: To use Brick in your project, place the following in the <head> of your main HTML: If you are already using Polymer, platform.js or a web browser that supports Web Components, you do not need the above <script> tag. Development Brick (and its components) are developed using tools built in JavaScript running on node.js. The individual components are developed in their own GitHub repositories. The mozbrick/brick repository contains the distributions of all the components packaged together as well as tools for building the distributions. To work on Brick, you will need the following node tools: Building Brick from source Once you have the prerequisites, you're ready to clone and build from source. Run the following: If you'd like to work on all the Brick components at once, try this handy script: Components Here is a list of the components currently in the primary distribution of Brick: brick-action brick-appbar brick-button brick-calendar brick-deck brick-dialog brick-flipbox brick-form brick-input brick-layout brick-listview brick-menu brick-storage-indexeddb brick-tabbar If you encounter issues with a component, please file issues against the individual component repositories."
90,"A boilerplate for Node.js web applicationsHackathon Starter ======================= Live Demo: https://hackathon-starter.walcony.com Jump to What's new? A boilerplate for Node.js web applications. If you have attended any hackathons in the past, then you know how much time it takes to get a project started: decide on what to build, pick a programming language, pick a web framework, pick a CSS framework. A while later, you might have an initial project up on GitHub and only then can other team members start contributing. Or how about doing something as simple as Sign in with Facebook authentication? You can spend hours on it if you are not familiar with how OAuth 2.0 works. When I started this project, my primary focus was on simplicity and ease of use. I also tried to make it as generic and reusable as possible to cover most use cases of hackathon web apps, without being too specific. In the worst case, you can use this as a learning guide for your projects, if for example you are only interested in Sign in with Google authentication and nothing else. Testimonials Nice! That README alone is already gold! Adrian Le Bas Awesome. Simply awesome. Steven Rueter I'm using it for a year now and many projects, it's an awesome boilerplate and the project is well maintained! Kevin Granger Small world with Sahat's project. We were using his hackathon starter for our hackathon this past weekend and got some prizes. Really handy repo! Interview candidate for one of the companies I used to work with. Modern Theme Flatly Bootstrap Theme API Examples Table of Contents Features Prerequisites Getting Started Obtaining API Keys Project Structure List of Packages Useful Tools and Resources Recommended Design Resources Recommended Node.js Libraries Recommended Client-side Libraries Pro Tips FAQ How It Works Cheatsheets ES6 JavaScript Date Mongoose Cheatsheet Deployment Docker Production Changelog Contributing License Features Local Authentication using Email and Password OAuth 1.0a Authentication via Twitter OAuth 2.0 Authentication via Facebook, Google, GitHub, LinkedIn, Instagram Flash notifications MVC Project Structure Node.js clusters support Sass stylesheets (auto-compiled via middleware) Bootstrap 4 + Extra Themes Contact Form (powered by Mailgun, Sendgrid or Mandrill) Account Management Gravatar Profile Details Change Password Forgot Password Reset Password Link multiple OAuth strategies to one account Delete Account CSRF protection API Examples: Facebook, Foursquare, Last.fm, Tumblr, Twitter, Stripe, LinkedIn and more. Prerequisites MongoDB Node.js 10+ Command Line Tools Mac OS X: Xcode (or OS X 10.9+: xcode-select --install) Windows: Visual Studio OR Visual Studio Code + Windows Subsystem for Linux - Ubuntu Ubuntu / Linux Mint: sudo apt-get install build-essential Fedora: sudo dnf groupinstall ""Development Tools"" OpenSUSE: sudo zypper install --type pattern devel_basis Note: If you are new to Node or Express, you may find Node.js & Express From Scratch series helpful for learning the basics of Node and Express. Alternatively, here is another great tutorial for complete beginners - Getting Started With Node.js, Express, MongoDB. Getting Started The easiest way to get started is to clone the repository: Warning: If you want to use some API that need https to work (for example Pinterest or facebook), you will need to download ngrok. You must start ngrok after starting the project. Next, you must use the https URL defined by ngrok, for example, https://hackaton.ngrok.io Note: I highly recommend installing Nodemon. It watches for any changes in your node.js app and automatically restarts the server. Once installed, instead of node app.js use nodemon app.js. It will save you a lot of time in the long run, because you won't need to manually restart the server each time you make a small change in code. To install, run sudo npm install -g nodemon. Obtaining API Keys To use any of the included APIs or OAuth authentication methods, you will need to obtain appropriate credentials: Client ID, Client Secret, API Key, or Username & Password. You will need to go through each provider to generate new credentials. Visit Google reCAPTCHA Admin Console Enter your application's name as the Label Choose reCAPTCHA v2, ""I'm not a robot"" Checkbox Enter localhost as the domain. You can have other domains added in addition to localhost Accept the terms and submit the form Copy the Site Key and the Secret key into .env. These keys will be accessible under Settings, reCAPTCHA keys drop down if you need them again later. Visit Google Cloud Console Click on the Create Project button Enter Project Name, then click on Create button Then click on APIs & auth in the sidebar and select API tab Click on Google+ API under Social APIs, then click Enable API Click on Google Drive API under G Suite, then click Enable API Click on Google Sheets API under G Suite, then click Enable API Next, under APIs & auth in the sidebar click on Credentials tab Click on Create new Client ID button Select Web Application and click on Configure Consent Screen Fill out the required fields then click on Save In the Create Client ID modal dialog: Application Type: Web Application Authorized Javascript origins: http://localhost:8080 Authorized redirect URI: http://localhost:8080/auth/google/callback Click on Create Client ID button Copy and paste Client ID and Client secret keys into .env Note: When you ready to deploy to production don't forget to add your new URL to Authorized Javascript origins and Authorized redirect URI, e.g. http://my-awesome-app.herokuapp.com and http://my-awesome-app.herokuapp.com/auth/google/callback respectively. The same goes for other providers. Visit Snap Kit Developer Portal Click on the + button to create an app Enter a name for your app Enable the scopes that you will want to use in your app Click on the Continue button Find the Kits section and make sure that Login Kit is enabled Find the Redirect URLs section, click the + Add button, and enter http://localhost:8080/auth/snapchat/callback Find the Development Environment section. Click the Generate button next to the Confidential OAuth2 Client heading within it. Copy and paste the generated Private Key and OAuth2 Client ID keys into .env Note: OAuth2 Client ID is SNAPCHAT_ID, Private Key is SNAPCHAT_SECRET in .env To prepare the app for submission, fill out the rest of the required fields: Category, Description, Privacy Policy Url, and App Icon Note: For production use, don't forget to: generate a Confidential OAuth2 Client in the Production Environment and use the production Private Key and OAuth2 Client ID add the production URL to Redirect URLs section, e.g. http://my-awesome-app.herokuapp.com/auth/snapchat/callback submit the app for review and wait for approval Visit Facebook Developers Click My Apps, then select *Add a New App from the dropdown menu Enter a new name for your app Click on the Create App ID button Find the Facebook Login Product and click on Facebook Login Instead of going through their Quickstart, click on Settings for your app in the top left corner Copy and paste App ID and App Secret keys into .env Note: App ID is FACEBOOK_ID, App Secret is FACEBOOK_SECRET in .env Enter localhost under App Domains Choose a Category that best describes your app Click on + Add Platform and select Website Enter http://localhost:8080 under Site URL Click on the Settings tab in the left nav under Facebook Login Enter http://localhost:8080/auth/facebook/callback under Valid OAuth redirect URIs Note: After a successful sign in with Facebook, a user will be redirected back to the home page with appended hash #_=_ in the URL. It is not a bug. See this Stack Overflow discussion for ways to handle it. Go to Account Settings Select Developer settings from the sidebar Then click on OAuth Apps and then on Register new application Enter Application Name and Homepage URL For Authorization Callback URL: http://localhost:8080/auth/github/callback Click Register application Now copy and paste Client ID and Client Secret keys into .env file Sign in at https://apps.twitter.com Click Create a new application Enter your application name, website and description For Callback URL: http://127.0.0.1:8080/auth/twitter/callback Go to Settings tab Under Application Type select Read and Write access Check the box Allow this application to be used to Sign in with Twitter Click Update this Twitter's applications settings Copy and paste Consumer Key and Consumer Secret keys into .env file Sign in at LinkedIn Developer Network From the account name dropdown menu select API Keys It may ask you to sign in once again Click + Add New Application button Fill out all the required fields OAuth 2.0 Redirect URLs: http://localhost:8080/auth/linkedin/callback JavaScript API Domains: http://localhost:8080 For Default Application Permissions make sure at least the following is checked: r_basicprofile Finish by clicking Add Application button Copy and paste API Key and Secret Key keys into .env file API Key is your clientID Secret Key is your clientSecret Sign up or log into your dashboard Click on your profile and click on Account Settings Then click on API Keys Copy the Secret Key. and add this into .env file Visit PayPal Developer Log in to your PayPal account Click Applications > Create App in the navigation bar Enter Application Name, then click Create app Copy and paste Client ID and Secret keys into .env file App ID is client_id, App Secret is client_secret Change host to api.paypal.com if you want to test against production and use the live credentials Go to Foursquare for Developers Click on My Apps in the top menu Click the Create A New App button Enter App Name, Welcome page url, For Redirect URI: http://localhost:8080/auth/foursquare/callback Click Save Changes Copy and paste Client ID and Client Secret keys into .env file Go to http://www.tumblr.com/oauth/apps Once signed in, click +Register application Fill in all the details For Default Callback URL: http://localhost:8080/auth/tumblr/callback Click Register Copy and paste OAuth consumer key and OAuth consumer secret keys into .env file Go to http://steamcommunity.com/dev/apikey Sign in with your existing Steam account Enter your Domain Name, then and click Register Copy and paste Key into .env file Visit the Twitch developer dashboard If prompted, authorize the dashboard to access your twitch account In the Console, click on Register Your Application Enter the name of your application Use OAuth Redirect URLs enter http://localhost:8080/auth/twitch/callback Set Category to Website Integration and press the Create button After the applicaiton has been created, click on the Manage button Copy and paste Client ID into .env If there is no Client Secret displayed, click on New Secret button and then copy and paste the Client secret into .env You can use SendGrid for sending emails. The developer tier allows you to send 100 free emails per day. As an Alternative to SendGrid, you may also choose to use an SMTP service provider. If using SendGrid: - Go to https://sendgrid.com/user/signup - Sign up and confirm your account via the activation email - Then enter your SendGrid API Key into .env file as SENDGRID_API_KEY If using an SMTP service provider instead of SendGrid: - Set SMTP_USER and SMTP_PASSWORD in .env, and remove SENDGRID_API_KEY Go to http://www.mailgun.com Sign up and add your Domain Name From the domain overview, copy and paste the default SMTP Login and Password into .env file Go to https://developer.here.com Sign up and create a Freemium project Create JAVASCRIPT/REST credentials. Copy and paste the APP_ID and APP into .env file. Note that these credentials are available on the client side, and you need to create a domain whitelist for your app credentials when you are publicly launching the app. Go to https://www.twilio.com/try-twilio Sign up for an account. Once logged into the dashboard, expand the link 'show api credentials' Copy your Account Sid and Auth Token Go to https://developer.intuit.com/app/developer/qbo/docs/get-started Use the Sign Up option in the upper right corner of the screen (nav bar) to get a free developer account and a sandbox company. Create a new app by going to your Dashboard using the My Apps option in the top nav bar or by going to https://developer.intuit.com/app/developer/myapps In your App, under Development, Keys & OAuth (right nav), find the Client ID and Client Secret for your .env file Project Structure | Name | Description | | ---------------------------------- | ------------------------------------------------------------ | | config/passport.js | Passport Local and OAuth strategies, plus login middleware. | | controllers/api.js | Controller for /api route and all api examples. | | controllers/contact.js | Controller for contact form. | | controllers/home.js | Controller for home page (index). | | controllers/user.js | Controller for user account management. | | models/User.js | Mongoose schema and model for User. | | public/ | Static assets (fonts, css, js, img). | | public/js/application.js | Specify client-side JavaScript dependencies. | | public/js/main.js | Place your client-side JavaScript here. | | public/css/main.scss | Main stylesheet for your app. | | public/css/themes/default.scss | Some Bootstrap overrides to make it look prettier. | | views/account/ | Templates for login, password reset, signup, profile. | | views/api/ | Templates for API Examples. | | views/partials/flash.pug | Error, info and success flash notifications. | | views/partials/header.pug | Navbar partial template. | | views/partials/footer.pug | Footer partial template. | | views/layout.pug | Base template. | | views/home.pug | Home page template. | | .dockerignore | Folder and files ignored by docker usage. | | .env.example | Your API keys, tokens, passwords and database URI. | | .eslintrc | Rules for eslint linter. | | .gitignore | Folder and files ignored by git. | | .travis.yml | Configuration files for continuous integration. | | app.js | The main application file. | | docker-compose.yml | Docker compose configuration file. | | Dockerfile | Docker configuration file. | | package.json | NPM dependencies. | | package-lock.json | Contains exact versions of NPM dependencies in package.json. | Note: There is no preference how you name or structure your views. You could place all your templates in a top-level views directory without having a nested folder structure, if that makes things easier for you. Just don't forget to update extends ../layout and corresponding res.render() paths in controllers. List of Packages | Package | Description | | ------------------------------- | ------------------------------------------------------------------------| | @octokit/rest | GitHub API library. | | bcrypt | Library for hashing and salting user passwords. | | body-parser | Node.js body parsing middleware. | | chai | BDD/TDD assertion library. | | chalk | Terminal string styling done right. | | cheerio | Scrape web pages using jQuery-style syntax. | | compression | Node.js compression middleware. | | connect-mongo | MongoDB session store for Express. | | dotenv | Loads environment variables from .env file. | | errorhandler | Development-only error handler middleware. | | eslint | Linter JavaScript. | | eslint-config-airbnb-base | Configuration eslint by airbnb. | | eslint-plugin-chai-friendly | Makes eslint friendly towards Chai.js 'expect' and 'should' statements. | | eslint-plugin-import | ESLint plugin with rules that help validate proper imports. | | express | Node.js web framework. | | express-flash | Provides flash messages for Express. | | express-session | Simple session middleware for Express. | | instagram-node | Instagram API library. | | lastfm | Last.fm API library. | | lob | Lob API library. | | lodash | A utility library for working with arrays, numbers, objects, strings. | | lusca | CSRF middleware. | | mailchecker | Verifies that an email address is valid and not a disposable address. | | mocha | Test framework. | | moment | Parse, validate, compute dates and times. | | mongoose | MongoDB ODM. | | morgan | HTTP request logger middleware for node.js. | | multer | Node.js middleware for handling multipart/form-data. | | node-foursquare | Foursquare API library. | | node-sass | Node.js bindings to libsass. | | node-sass-middleware | Sass middleware compiler. | | nyc | Coverage test. | | nodemailer | Node.js library for sending emails. | | node-quickbooks | Quickbooks API library. | | passport | Simple and elegant authentication library for node.js. | | passport-facebook | Sign-in with Facebook plugin. | | passport-github | Sign-in with GitHub plugin. | | passport-google-oauth | Sign-in with Google plugin. | | passport-instagram | Sign-in with Instagram plugin. | | passport-linkedin-oauth2 | Sign-in with LinkedIn plugin. | | passport-local | Sign-in with Username and Password plugin. | | passport-openid | Sign-in with OpenId plugin. | | passport-oauth | Allows you to set up your own OAuth 1.0a and OAuth 2.0 strategies. | | passport-oauth2-refresh | A library to refresh OAuth 2.0 access tokens using refresh tokens. | | passport-snapchat | Sign-in with Snapchat plugin. | | passport-twitter | Sign-in with Twitter plugin. | | passport-twitch-new | Sign-in with Twitch plugin. | | paypal-rest-sdk | PayPal APIs library. | | pug | Template engine for Express. | | sinon | Test spies, stubs and mocks for JavaScript. | | stripe | Offical Stripe API library. | | supertest | HTTP assertion library. | | tumblr.js | Tumblr API library. | | twilio | Twilio API library. | | twitter-lite | Twitter API library. | | validator | A library of string validators and sanitizers. | Useful Tools and Resources JavaScripting - The Database of JavaScript Libraries JS Recipes - JavaScript tutorials for backend and frontend development. HTML to Pug converter - HTML to PUG is a free online converter helping you to convert HTML files to pug syntax in real-time. JavascriptOO - A directory of JavaScript libraries with examples, CDN links, statistics, and videos. Favicon Generator - Generate favicons for PC, Android, iOS, Windows 8. Recommended Design Resources Code Guide - Standards for developing flexible, durable, and sustainable HTML and CSS. Bootsnipp - Code snippets for Bootstrap. Bootstrap Zero - Free Bootstrap templates themes. Google Bootstrap - Google-styled theme for Bootstrap. Font Awesome Icons - It's already part of the Hackathon Starter, so use this page as a reference. Colors - A nicer color palette for the web. Creative Button Styles - awesome button styles. Creative Link Effects - Beautiful link effects in CSS. Medium Scroll Effect - Fade in/out header background image as you scroll. GeoPattern - SVG background pattern generator. Trianglify - SVG low-poly background pattern generator. Recommended Node.js Libraries Nodemon - Automatically restart Node.js server on code changes. geoip-lite - Geolocation coordinates from IP address. Filesize.js - Pretty file sizes, e.g. filesize(265318); // ""265.32 kB"". Numeral.js - Library for formatting and manipulating numbers. Node Inspector - Node.js debugger based on Chrome Developer Tools. node-taglib - Library for reading the meta-data of several popular audio formats. sharp - Node.js module for resizing JPEG, PNG, WebP and TIFF images. Recommended Client-side Libraries Framework7 - Full Featured HTML Framework For Building iOS7 Apps. InstantClick - Makes your pages load instantly by pre-loading them on mouse hover. NProgress.js - Slim progress bars like on YouTube and Medium. Hover - Awesome CSS3 animations on mouse hover. Magnific Popup - Responsive jQuery Lightbox Plugin. jQuery Raty - Star Rating Plugin. Headroom.js - Hide your header until you need it. X-editable - Edit form elements inline. Offline.js - Detect when user's internet connection goes offline. Alertify.js - Sweet looking alerts and browser dialogs. selectize.js - Styleable select elements and input tags. drop.js - Powerful Javascript and CSS library for creating dropdowns and other floating displays. scrollReveal.js - Declarative on-scroll reveal animations. Pro Tips Use async.parallel() when you need to run multiple asynchronous tasks, and then render a page, but only when all tasks are completed. For example, you might want to scrape three different websites for some data and render the results in a template after all three websites have been scraped. Need to find a specific object inside an Array? Use _.find function from Lodash. For example, this is how you would retrieve a Twitter token from database: var token = _.find(req.user.tokens, { kind: 'twitter' });, where 1st parameter is an array, and a 2nd parameter is an object to search for. FAQ Why do I get 403 Error: Forbidden when submitting a form? You need to add the following hidden input element to your form. This has been added in the pull request #40 as part of the CSRF protection. Note: It is now possible to whitelist certain URLs. In other words you can specify a list of routes that should bypass CSRF verification check. Note 2: To whitelist dynamic URLs use regular expression tests inside the CSRF middleware to see if req.originalUrl matches your desired pattern. I am getting MongoDB Connection Error, how do I fix it? That's a custom error message defined in app.js to indicate that there was a problem connecting to MongoDB: You need to have a MongoDB server running before launching app.js. You can download MongoDB here, or install it via a package manager. Windows users, read Install MongoDB on Windows. Tip: If you are always connected to the internet, you could just use MongoDB Atlas or Compose instead of downloading and installing MongoDB locally. You will only need to update database credentials in .env file. I get an error when I deploy my app, why? Chances are you haven't changed the Database URI in .env. If MONGODB is set to localhost, it will only work on your machine as long as MongoDB is running. When you deploy to Heroku, OpenShift or some other provider, you will not have MongoDB running on localhost. You need to create an account with MongoDB Atlas or Compose, then create a free tier database. See Deployment for more information on how to setup an account and a new database step-by-step with MongoDB Atlas. Why Pug (Jade) instead of Handlebars? When I first started this project I didn't have any experience with Handlebars. Since then I have worked on Ember.js apps and got myself familiar with the Handlebars syntax. While it is true Handlebars is easier, because it looks like good old HTML, I have no regrets picking Jade over Handlebars. First off, it's the default template engine in Express, so someone who has built Express apps in the past already knows it. Secondly, I find extends and block to be indispensable, which as far as I know, Handlebars does not have out of the box. And lastly, subjectively speaking, Jade looks much cleaner and shorter than Handlebars, or any non-HAML style for that matter. Why do you have all routes defined in app.js? For the sake of simplicity. While there might be a better approach, such as passing app context to each controller as outlined in this blog, I find such style to be confusing for beginners. It took me a long time to grasp the concept of exports and module.exports, let alone having a global app reference in other files. That to me is backward thinking. The app.js is the ""heart of the app"", it should be the one referencing models, routes, controllers, etc. When working solo on small projects, I prefer to have everything inside app.js as is the case with this REST API server. How do I switch SendGrid for another email delivery service, like Mailgun or SparkPost? Inside the nodemailer.createTransport method arguments, change the service from 'Sendgrid' to some other email service. Also, be sure to update both username and password below that. See the list of all supported services by Nodemailer. How It Works (mini guides) This section is intended for giving you a detailed explanation of how a particular functionality works. Maybe you are just curious about how it works, or perhaps you are lost and confused while reading the code, I hope it provides some guidance to you. Custom HTML and CSS Design 101 HTML5 UP has many beautiful templates that you can download for free. When you download the ZIP file, it will come with index.html, images, css and js folders. So, how do you integrate it with Hackathon Starter? Hackathon Starter uses Bootstrap CSS framework, but these templates do not. Trying to use both CSS files at the same time will likely result in undesired effects. Note: Using the custom templates approach, you should understand that you cannot reuse any of the views I have created: layout, home page, api browser, login, signup, account management, contact. Those views were built using Bootstrap grid and styles. You will have to manually update the grid using a different syntax provided in the template. Having said that, you can mix and match if you want to do so: Use Bootstrap for main app interface, and a custom template for a landing page. Let's start from the beginning. For this example I will use Escape Velocity template: Note: For the sake of simplicity I will only consider index.html, and skip left-sidebar.html, no-sidebar.html, right-sidebar.html. Move all JavaScript files from html5up-escape-velocity/js to public/js. Then move all CSS files from html5up-escape-velocity/css to public/css. And finally, move all images from html5up-escape-velocity/images to public/images. You could move it to the existing img folder, but that would require manually changing every img reference. Grab the contents of index.html and paste it into HTML To Pug. Note: Do not forget to update all the CSS and JS paths accordingly. Create a new file escape-velocity.pug and paste the Pug markup in views folder. Whenever you see the code res.render('account/login') - that means it will search for views/account/login.pug file. Let's see how it looks. Create a new controller escapeVelocity inside controllers/home.js: And then create a route in app.js. I placed it right after the index controller: Restart the server (if you are not using nodemon); then you should see the new template at http://localhost:8080/escape-velocity. I will stop right here, but if you would like to use this template as more than just a single page, take a look at how these Pug templates work: layout.pug - base template, index.pug - home page, partials/header.pug - Bootstrap navbar, partials/footer.pug - sticky footer. You will have to manually break it apart into smaller pieces. Figure out which part of the template you want to keep the same on all pages - that's your new layout.pug. Then, each page that changes, be it index.pug, about.pug, contact.pug will be embedded in your new layout.pug via block content. Use existing templates as a reference. This is a rather lengthy process, and templates you get from elsewhere might have yet another grid system. That's why I chose Bootstrap for the Hackathon Starter. Many people are already familiar with Bootstrap, plus it's easy to get started with it if you have never used Bootstrap. You can also buy many beautifully designed Bootstrap themes at Themeforest, and use them as a drop-in replacement for Hackathon Starter. However, if you would like to go with a completely custom HTML/CSS design, this should help you to get started! How do flash messages work in this project? Flash messages allow you to display a message at the end of the request and access it on next request and only next request. For instance, on a failed login attempt, you would display an alert with some error message, but as soon as you refresh that page or visit a different page and come back to the login page, that error message will be gone. It is only displayed once. This project uses express-flash module for flash messages. And that module is built on top of connect-flash, which is what I used in this project initially. With express-flash you don't have to explicitly send a flash message to every view inside res.render(). All flash messages are available in your views via messages object by default, thanks to express-flash. Flash messages have a two-step process. You use req.flash('errors', { msg: 'Error messages goes here' } to create a flash message in your controllers, and then display them in your views: In the first step, 'errors' is the name of a flash message, which should match the name of the property on messages object in your views. You place alert messages inside if message.errors because you don't want to show them flash messages are present. The reason why you pass an error like { msg: 'Error message goes here' } instead of just a string - 'Error message goes here', is for the sake of consistency. To clarify that, express-validator module which is used for validating and sanitizing user's input, returns all errors as an array of objects, where each object has a msg property with a message why an error has occurred. Here is a more general example of what express-validator returns when there are errors present: To keep consistent with that style, you should pass all flash messages as { msg: 'My flash message' } instead of a string. Otherwise, you will see an alert box without an error message. That is because in partials/flash.pug template it will try to output error.msg (i.e. ""My flash message"".msg), in other words, it will try to call a msg method on a String object, which will return undefined. Everything I just mentioned about errors, also applies to ""info"" and ""success"" flash messages, and you could even create a new one yourself, such as: Data Usage Controller (Example) User Account Page (Example) partials/flash.pug is a partial template that contains how flash messages are formatted. Previously, flash messages were scattered throughout each view that used flash messages (contact, login, signup, profile), but now, thankfully it uses a DRY approach. The flash messages partial template is included in the layout.pug, along with footer and navigation. If you have any further questions about flash messages, please feel free to open an issue, and I will update this mini-guide accordingly, or send a pull request if you would like to include something that I missed. How do I create a new page? A more correct way to say this would be ""How do I create a new route?"" The main file app.js contains all the routes. Each route has a callback function associated with it. Sometimes you will see three or more arguments for a route. In a case like that, the first argument is still a URL string, while middle arguments are what's called middleware. Think of middleware as a door. If this door prevents you from continuing forward, you won't get to your callback function. One such example is a route that requires authentication. It always goes from left to right. A user visits /account page. Then isAuthenticated middleware checks if you are authenticated: If you are authenticated, you let this visitor pass through your ""door"" by calling return next();. It then proceeds to the next middleware until it reaches the last argument, which is a callback function that typically renders a template on GET requests or redirects on POST requests. In this case, if you are authenticated, you will be redirected to the Account Management page; otherwise, you will be redirected to the Login page. Express.js has app.get, app.post, app.put, app.delete, but for the most part, you will only use the first two HTTP verbs, unless you are building a RESTful API. If you just want to display a page, then use GET, if you are submitting a form, sending a file then use POST. Here is a typical workflow for adding new routes to your application. Let's say we are building a page that lists all books from the database. Step 1. Start by defining a route. Note: As of Express 4.x you can define your routes like so: And here is how a route would look if it required an authentication and an authorization middleware: Use whichever style that makes sense to you. Either one is acceptable. I think that chaining HTTP verbs on app.route is a very clean and elegant approach, but on the other hand, I can no longer see all my routes at a glance when you have one route per line. Step 2. Create a new schema and a model Book.js inside the models directory. Step 3. Create a new controller file called book.js inside the controllers directory. Step 4. Import that controller in app.js. Step 5. Create books.pug template. That's it! I will say that you could have combined Step 1, 2, 3 as following: Sure, it's simpler, but as soon as you pass 1000 lines of code in app.js it becomes a little challenging to navigate the file. I mean, the whole point of this boilerplate project was to separate concerns, so you could work with your teammates without running into MERGE CONFLICTS. Imagine you have four developers working on a single app.js, I promise you it won't be fun resolving merge conflicts all the time. If you are the only developer, then it's okay. But as I said, once it gets up to a certain LoC size, it becomes difficult to maintain everything in a single file. That's all there is to it. Express.js is super simple to use. Most of the time you will be dealing with other APIs to do the real work: Mongoose for querying database, socket.io for sending and receiving messages over websockets, sending emails via Nodemailer, form validation using express-validator library, parsing websites using Cheerio, etc. How do I use Socket.io with Hackathon Starter? Dan Stroot submitted an excellent pull request that adds a real-time dashboard with socket.io. And as much as I'd like to add it to the project, I think it violates one of the main principles of the Hackathon Starter: When I started this project, my primary focus was on simplicity and ease of use. I also tried to make it as generic and reusable as possible to cover most use cases of hackathon web apps, without being too specific. When I need to use socket.io, I really need it, but most of the time - I don't. But more importantly, websockets support is still experimental on most hosting providers. As of October 2013, Heroku supports websockets, but not until you opt-in by running this command: And what if you are deploying to OpenShift? They do support websockets, but it is currently in a preview state. So, for OpenShift you would need to change the socket.io connect URI to the following: Wait, why is it on port 8000? Who knows, and if I didn't run across this blog post I wouldn't even know I had to use port 8000. I am really glad that Heroku and OpenShift at least have a websockets support, because many other PaaS providers still do not support it. Due to the aforementioned issues with websockets, I cannot include socket.io as part of the Hackathon Starter. For now... If you need to use socket.io in your app, please continue reading. First, you need to install socket.io: Replace const app = express(); with the following code: I like to have the following code organization in app.js (from top to bottom): module dependencies, import controllers, import configs, connect to database, express configuration, routes, start the server, socket.io stuff. That way I always know where to look for things. Add the following code at the end of app.js: One last thing left to change: to At this point, we are done with the back-end. You now have a choice - to include your JavaScript code in Pug templates or have all your client-side JavaScript in a separate file - in main.js. I admit, when I first started with Node.js and JavaScript in general, I placed all JavaScript code inside templates because I have access to template variables passed in from Express right then and there. It's the easiest thing you can do, but also the least efficient and harder to maintain. Since then I almost never include inline JavaScript inside templates anymore. But it's also understandable if you want to take the easier road. Most of the time you don't even care about performance during hackathons, you just want to ""get shit done"" before the time runs out. Well, either way, use whichever approach makes more sense to you. At the end of the day, it's what you build that matters, not how you build it. If you want to stick all your JavaScript inside templates, then in layout.pug - your main template file, add this to head block. Note: Notice the path of the socket.io.js, you don't actually have to have socket.io.js file anywhere in your project; it will be generated automatically at runtime. If you want to have JavaScript code separate from templates, move that inline script code into main.js, inside the $(document).ready() function: And we are done! Cheatsheets ES6 Cheatsheet Declarations Declares a read-only named constant. Declares a block scope local variable. Template Strings Using the `${}` syntax, strings can embed expressions. Modules To import functions, objects or primitives exported from an external module. These are the most common types of importing. To export functions, objects or primitives from a given file or module. Spread Operator The spread operator allows an expression to be expanded in places where multiple arguments (for function calls) or multiple elements (for array literals) are expected. Promises A Promise is used in asynchronous computations to represent an operation that hasn't completed yet, but is expected in the future. The catch() method returns a Promise and deals with rejected cases only. The then() method returns a Promise. It takes two arguments: callback for the success & failure cases. The Promise.all(iterable) method returns a promise that resolves when all of the promises in the iterable argument have resolved or rejects with the reason of the first passed promise that rejects. Arrow Functions Arrow function expression. Shorter syntax & lexically binds the this value. Arrow functions are anonymous. Classes The class declaration creates a new class using prototype-based inheritance. :gift: Credits: DuckDuckGo and @DrkSephy. :top: back to top JavaScript Date Cheatsheet Unix Timestamp (seconds) Add 30 minutes to a Date object Date Formatting Next week Date object Yesterday Date object :top: back to top Mongoose Cheatsheet Find all users: Find a user by email: Find 5 most recent user accounts: Get the total count of a field from all documents: Let's suppose that each user has a votes field and you would like to count the total number of votes in your database across all users. One very inefficient way would be to loop through each document and manually accumulate the count. Or you could use MongoDB Aggregation Framework instead: :top: back to top Docker You will need docker and docker-compose installed to build the application. Docker installation Common problems setting up docker After installing docker, start the application with the following commands : To view the app, find your docker IP address + port 8080 ( this will typically be http://localhost:8080/ ). To use a port other than 8080, you would need to modify the port in app.js, Dockerfile, and docker-compose.yml. Deployment Once you are ready to deploy your app, you will need to create an account with a cloud platform to host it. These are not the only choices, but they are my top picks. From my experience, the easiest way to get started is with Heroku. It will automatically restart your Node.js process when it crashes, has zero-downtime deployments and supports custom domains on free accounts. Additionally, you can create an account with MongoDB Atlas and then pick one of the 4 providers below. Again, there are plenty of other choices, and you are not limited to just the ones listed below. Deployment to Heroku Download and install Heroku Toolbelt In a terminal, run heroku login and enter your Heroku credentials From your app directory run heroku create Use the command heroku config:set KEY=val to set the different environment variables (KEY=val) for your application (i.e. heroku config:set BASE_URL=[heroku App Name].herokuapp.com or heroku config:set MONGODB_URI=mongodb://dbuser:<password>@cluster0-shard-00-00-sdf32.mongodb.net:27017,cluster0-shard-00-01-sdf32.mongodb.net:27017/<dbname>?ssl=true&retryWrites=true&w=majority (see Hosted MongoDB Atlas below), etc.) Make sure to set the environment variables for SENDGRID_USER, SENDGRID_PASSWORD, and any other API that you are using as well. Lastly, do git push heroku master. Please note that you may also use the Herko Dashboard to set or modify the configurations for your application. Hosted MongoDB Atlas Go to https://www.mongodb.com/cloud/atlas Click the green Get started free button Fill in your information then hit Get started free You will be redirected to Create New Cluster page. Select a Cloud Provider and Region (such as AWS and a free tier region) Select cluster Tier to Free forever Shared Cluster Give Cluster a name (default: Cluster0) Click on green :zap:Create Cluster button Now, to access your database you need to create a DB user. To create a new MongoDB user, from the Clusters view, select the Security tab Under the MongoDB Users tab, click on +Add New User Fill in a username and password and give it either Atlas Admin User Privilege Next, you will need to create an IP address whitelist and obtain the connection URI. In the Clusters view, under the cluster details (i.e. SANDBOX - Cluster0), click on the CONNECT button. Under section (1) Check the IP Whitelist, click on ALLOW ACCESS FROM ANYWHERE. The form will add a field with 0.0.0.0/0. Click SAVE to save the 0.0.0.0/0 whitelist. Under section (2) Choose a connection method, click on Connect Your Application In the new screen, select Node.js as Driver and version 3.6 or later. Finally, copy the URI connection string and replace the URI in MONGODB_URI of .env.example with this URI string. Make sure to replace the with the db User password that you created under the Security tab. Note that after some of the steps in the Atlas UI, you may see a banner stating We are deploying your changes. You will need to wait for the deployment to finish before using the DB in your application. Note: As an alternative to MongoDB Atlas, there is also Compose. OpenShift NOTE These instructions might be out of date due to changes in OpenShift. Heroku is currently a good free alternative. If you the new process, please feel free to help us update this page First, install this Ruby gem: sudo gem install rhc :gem: Run rhc login and enter your OpenShift credentials From your app directory run rhc app create MyApp nodejs-0.10 Note: MyApp is the name of your app (no spaces) Once that is done, you will be provided with URL, SSH and Git Remote links Visit provided URL, and you should see the Welcome to your Node.js application on OpenShift page Copy and paste Git Remote into git remote add openshift YOUR_GIT_REMOTE Before you push your app, you need to do a few modifications to your code Add these two lines to app.js, just place them anywhere before app.listen(): Then change app.listen() to: Add this to package.json, after name and version. This is necessary because, by default, OpenShift looks for server.js file. And by specifying supervisor app.js it will automatically restart the server when node.js process crashes. Finally, you can now push your code to OpenShift by running git push -f openshift master Note: The first time you run this command, you have to pass -f (force) flag because OpenShift creates a dummy server with the welcome page when you create a new Node.js app. Passing -f flag will override everything with your Hackathon Starter project repository. Do not run git pull as it will create unnecessary merge conflicts. And you are done! Azure NOTE Beyond the initial 12 month trial of Azure, the platform does not seem to offer a free tier for hosting NodeJS apps. If you are looking for a free tier service to host your app, Heroku might be a better choice at this point Login to Windows Azure Management Portal Click the + NEW button on the bottom left of the portal Click COMPUTE, then WEB APP, then QUICK CREATE Enter a name for URL and select the datacenter REGION for your web site Click on CREATE WEB APP button Once the web site status changes to Running, click on the name of the web site to access the Dashboard At the bottom right of the Quickstart page, select Set up a deployment from source control Select Local Git repository from the list, and then click the arrow To enable Git publishing, Azure will ask you to create a user name and password Once the Git repository is ready, you will be presented with a GIT URL Inside your Hackathon Starter directory, run git remote add azure [Azure Git URL] To push your changes run git push azure master Note: You will be prompted for the password you created earlier On Deployments tab of your Windows Azure Web App, you will see the deployment history IBM Bluemix Cloud Platform NOTE At this point it appears that Bluemix's free tier to host NodeJS apps is limited to 30 days. If you are looking for a free tier service to host your app, Heroku might be a better choice at this point Create a Bluemix Account Sign up for Bluemix, or use an existing account. Download and install the Cloud Foundry CLI to push your applications to Bluemix. Create a manifest.yml file in the root of your application. The host you use will determinate your application URL initially, e.g. <host>.mybluemix.net. The service name 'myMongo-db-name' is a declaration of your MongoDB service. If you are using other services like Watson for example, then you would declare them the same way. Connect and login to Bluemix via the Cloud-foundry CLI Create a MongoDB service Note: this is a free and experiment verion of MongoDB instance. Use the MongoDB by Compose instance for production applications: Push the application Done, now go to the staging domain (<host>.mybluemix.net) and see your app running. Cloud Foundry Commands More Bluemix samples Simple ToDo app in a programming language of your choice IBM Watson Be sure to check out the full list of Watson services to forwarder enhance your application functionality with a little effort. Watson services are easy to get going; it is simply a RESTful API call. Here is an example of a Watson Toner Analyzer to understand the emotional context of a piece of text that you send to Watson. Watson catalog of services Conversation - Quickly build and deploy chatbots and virtual agents across a variety of channels, including mobile devices, messaging platforms, and even robots. Discovery - Unlock hidden value in data to find answers, monitor trends and surface patterns with the worlds most advanced cloud-native insight engine. Language Translator - Translate text from one language to another. Natural Language Classifier - Interpret and classify natural language with confidence. Natural Language Understanding - Analyze text to extract meta-data from content such as concepts, entities, keywords and more. Personality Insights - Predict personality characteristics, needs and values through written text. Speech to Text - Convert audio and voice into written text for quick understanding of content. Text to Speech - Convert written text into natural sounding audio in a variety of languages and voices. Tone Analyzer - Understand emotions, social tendencies and perceived writing style. Visual Recognition - Tag, classify and search visual content using machine learning. Click here for live demos of each Watson service. Google Cloud Platform Download and install Node.js Select or create a Google Cloud Platform Console project Enable billing for your project (there's a $300 free trial) Install and initialize the Google Cloud SDK Create an app.yaml file at the root of your hackathon-starter folder with the following contents: Make sure you've set MONGODB_URI in .env.example Run the following command to deploy the hackathon-starter app: Monitor your deployed app in the Cloud Console View the logs for your app in the Cloud Console Production If you are starting with this boilerplate to build an application for prod deployment, or if after your hackathon you would like to get your project hardened for production use, see prod-checklist.md. Changelog You can find the changelog for the project in: CHANGELOG.md Contributing If something is unclear, confusing, or needs to be refactored, please let me know. Pull requests are always welcome, but due to the opinionated nature of this project, I cannot accept every pull request. Please open an issue before submitting a pull request. This project uses Airbnb JavaScript Style Guide with a few minor exceptions. If you are submitting a pull request that involves Pug templates, please make sure you are using spaces, not tabs. License The MIT License (MIT) Copyright (c) 2014-2021 Sahat Yalkabov Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the ""Software""), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
1739,"Sweeten your JavaScript.Hygienic Macros for JavaScript! Macros allow you to build the language of your dreams. Sweeten JavaScript by defining new syntax for your code. Currently, Sweet should be considered experimental and under heavy development (re-development more like). As such, the API will be undergoing a bit of churn until probably the end of the year. So, probably best not to try Sweet in production systems just yet. If you're interested in helping out though we'd love to have you! Getting started Install the command line app with npm: Write your sweet code: And compile: Learning More Read the tutorial. Read the reference documentation. Play with the editor. Discuss on Google Groups. Hang out on IRC: #sweet.js at irc.mozilla.org and on Gitter."
26,"Call all Node.js modules directly from DOM/WebWorker and enable a new way of writing applications with all Web technologies.node-webkit is renamed NW.js Official site: https://nwjs.io Introduction NW.js is an app runtime based on Chromium and node.js. You can write native apps in HTML and JavaScript with NW.js. It also lets you call Node.js modules directly from the DOM and enables a new way of writing native applications with all Web technologies. It was created in the Intel Open Source Technology Center. Building a Cross-platform Desktop App with NW.js Creating Desktop Applications With node-webkit WebApp to DesktopApp with node-webkit (slides) Essay on the history and internals of the project Features Apps written in modern HTML5, CSS3, JS and WebGL. Complete support for Node.js APIs and all its third party modules. Good performance: Node and WebKit run in the same thread: Function calls are made straightforward; objects are in the same heap and can just reference each other. Easy to package and distribute apps. Available on Linux, Mac OS X and Windows. Downloads v0.53.0: (Apr 27, 2021, based off of Node.js v15.14.0, Chromium 90.0.4430.93) : release notes NOTE You might want the SDK build. Please read the release notes. Linux: 32bit / 64bit Windows: 32bit / 64bit Mac 10.10+: 64bit Use Legacy build for Win XP and early OSX. latest nightly build from git tip: https://dl.nwjs.io/live-build/ Previous versions; See the mapping file for the version info in previous releases. Demos and real apps You may also be interested in our demos repository and the List of apps and companies using nw.js. Quick Start Create index.html: Create package.json: Run: Note: on Windows, you can drag the folder containing package.json to nw.exe to open it. Note: on OSX, the executable binary is in a hidden directory within the .app file. To run node-webkit on OSX, type: /path/to/nwjs.app/Contents/MacOS/nwjs . (suppose the current directory contains 'package.json') Documents Official documentation: http://docs.nwjs.io/ For more information on how to write/package/run apps, see: How to run apps How to package and distribute your apps How to use Node.js modules in node-webkit And our Wiki for much more. Community We use the google group as our mailing list (use English only). Subscribe via nwjs-general+subscribe@googlegroups.com. NOTE: Links to the old google group (e.g. https://groups.google.com/forum/#!msg/node-webkit/doRWZ07LgWQ/4fheV8FF8zsJ) that are no longer working can be fixed by replacing node-webkit with nwjs-general (e.g https://groups.google.com/forum/#!msg/nwjs-general/doRWZ07LgWQ/4fheV8FF8zsJ). Issues are being tracked here on GitHub. The source code for NW.js and the daily development spans across multiple repositories in this organization. This repository is for the purpose of issue tracking, landing page and part of the source code. Verifying Binaries Starting from 0.32.0 the stable and nightly download directories contain a SHASUMS256.txt file that lists the SHA checksums for each file available for download, as well as the checksums for the files inside the download package. The SHASUMS256.txt can be downloaded using curl. To check that a downloaded file matches the checksum, run it through sha256sum with a command such as: The stable releases (but not Nightlies) also have the GPG detached signature of SHASUMS256.txt available as SHASUMS256.txt.asc. You can use gpg to verify that SHASUMS256.txt has not been tampered with. To verify SHASUMS256.txt has not been altered, you will first need to import the GPG key of NW.js maintainer to create releases. Use this command to import the key: Next, download the SHASUMS256.txt.asc for the release: After downloading the appropriate SHASUMS256.txt and SHASUMS256.txt.asc files, you can then use gpg --verify SHASUMS256.txt.asc SHASUMS256.txt to verify that the file has been signed by an authorized member of the NW.js team. Once verified, use the SHASUMS256.txt file to get the checksum for the binary verification command above. License NW.js's code in this repo uses the MIT license, see our LICENSE file. To redistribute the binary, see How to package and distribute your apps"
287,"The ultimate Free Open Source Solution for team communications. The Ultimate Open Source WebChat Platform NEW! Rocket.Chat Moving to a Single Codebase Community Mobile Apps Desktop Apps Deployment Snaps DigitalOcean RocketChatLauncher Layershift Yunohost.org IndieHosters Ubuntu 16.04 Cloudron.io Helm Kubernetes Scalingo Sloppy.io Docker Ansible Raspberry Pi 4 Koozali SME Ubuntu VPS D2C.io Syncloud.org About Rocket.Chat In the News Features Roadmap How it all started Awards Issues Stack Overflow Integrations Documentation License Development Quick Start Branching Model Translations How to Contribute Credits Help Wanted Donate Moving to a Single Codebase Rocket.Chat is moving to a single codebase. Get to know the reasons and how the community will benefit from it. Read the details. Help Wanted At Rocket.Chat, our community drives everything we do. The Rocket.Chat team is expanding, and we know no better place to find qualified new team members than right here - in our GitHub community. If you are passionate about our project, want to work with a world-leading open source team, and enjoy working remotely at a location of your choice, then we want to talk to you! Get to know more about us and explore current openings at https://jobs.rocket.chat/"" Community Join thousands of members worldwide 24/7 in our community server. for help from our community with general Rocket.Chat questions. for developers needing help from the community to developing new features. You can also join the conversation on Twitter and Facebook. Share your story Wed love to hear about your experience and potentially feature it on our Blog. Subscribe for Updates Once a month our marketing team releases an email update with news about product releases, company related topics, events and use cases. Sign Up! Desktop Apps Download the Native Cross-Platform Desktop Application at Rocket.Chat.Electron Mobile Apps Deployment Instant Server Installation with Snaps Install Rocket.Chat in seconds on Linux (Ubuntu and others) with: Installing snaps is very quick. By running that command you have your full Rocket.Chat server up and running. Snaps are secure. They are isolated with all of their dependencies. Snaps also auto-update when we release new versions. Our snap features a built-in reverse proxy that can request and maintain free Let's Encrypt SSL certificates. You can go from zero to a public-facing SSL-secured Rocket.Chat server in less than 5 minutes. Find out more information about our snaps here. DigitalOcean droplet Deploy to a DigitalOcean droplet with our one-click install listing from the DigitalOcean Marketplace. Layershift Instantly deploy your Rocket.Chat server for free on next generation auto-scaling PaaS. Painless SSL. Automatically scale your server cluster based on usage demand. Yunohost.org Host your own Rocket.Chat server in a few seconds. IndieHosters Get your Rocket.Chat instance hosted in an ""as a Service"" style. You register and we manage it for you! (updates, backup...). Cloudron.io Install Rocket.Chat on Cloudron Smartserver: Helm Kubernetes Deploy on Kubernetes using the official helm chart. Scalingo Deploy your own Rocket.Chat server instantly on Scalingo. Sloppy.io Host your docker container at sloppy.io. Get an account and use the quickstarter. Docker Deploy with docker compose OR Use the automated build image of our most recent release OR select a specific release (details of releases available): OR our official docker registry image, containing recent stable release build approved by Docker: Ansible Automated production-grade deployment in minutes, for RHEL / CentOS 7 or Ubuntu 14.04 LTS / 15.04. Raspberry Pi 4 Run Rocket.Chat on this world famous $35 quad-core server. Koozali SME Add Rocket.Chat to this world famous time tested small enterprise server today. Ubuntu VPS Follow these deployment instructions. D2C.io Deploy Rocket.Chat stack to your server with D2C. Scale with a single click, check live logs and metrics: Syncloud.org Run Rocket.Chat on your easy to use personal device. About Rocket.Chat Rocket.Chat is a Web Chat Server, developed in JavaScript, using the Meteor full stack framework. It is a great solution for communities and companies wanting to privately host their own chat service or for developers looking forward to build and evolve their own chat platforms. In the News Wired Open Sourcers Race to Build Better Versions of Slack Hacker News Yes, we made it to the #1 Product Hunt Your own open source Slack-like chat JavaScript Weekly An open source Web based, channel based chat system (a la Slack) built using Meteor, the full stack JavaScript development platform. Open Source China Rocket.Chat Slack / wwwhatsnew.com Para los programadores que quieran ofrecer un chat en su web clasesdeperiodismo.com Un chat de cdigo abierto que puedes aadir a la web snowulf.com Why Slack when you can Rocket.chat? liminality.xyz Self-hosted alternatives to popular cloud services Features BYOS (Bring Your Own Server) Multiple Rooms Direct Messages Private Groups Public Channels Desktop Notifications Mentions Avatars Markdown Emojis Custom Emojis Reactions One touch Geolocation TeX Math Rendering - inline math typesetting Media Embeds Link Previews Sent Message Edit and Deletion Transcripts / History File Upload / Sharing Scalable file sharing - S3 uploads with CDN downloads Full text search Global search (from all channels/rooms at once) Live chat / Messaging call center LDAP Authentication CAS 1.0, 2.0 support for educational institutions and hosting providers worldwide Support for Okta SSO through SAML v2 I18n - Supports 22 Languages Hubot Friendly (Beta) Face to Face Video Conferencing (aka WebRTC ) (Beta) Multi-users Video Group Chat (Beta) Jitsi integration Audio calls Multi-users Audio Conference Screen sharing Drupal 7.x and 8.x Plug-in (both stable and development flavours) (download and source code ) XMPP bridge (try it) REST APIs Remote Video Monitoring Native real-time APIs for Microsoft C#, Visual Basic, F# and other .NET supported languages (Get it!) API access from Perl and Java (community contributions) Chat-ops powered by Hubot: scalable horizontal app integration (early access) Massively scalable hosting and provisioning (beta testing now) Native Cross-Platform Desktop Application Windows, macOS, or Linux Mobile app for iPhone, iPad, and iPod touch Download on App Store Mobile app for Android phone, tablet, and TV stick Available now on Google Play Available on Cloudron Store Roadmap To see an up to date view of what we have planned, view our milestones. How it all started Read about how it all started. Awards Issues GitHub Issues are used to track bugs and tasks on the roadmap. Feature Requests RocketChat/feature-requests is used to track Rocket.Chat feature requests and discussions. Click here to open a new feature request. Feature Request Forums stores the historical archives of old feature requests (up to 2018). Stack Overflow Please use the Stack Overflow TAG Integrations Hubot The docker image is ready. Everyone can start hacking the adapter code or launch his/her own bot within a few minutes now. Please head over to the Hubot Integration Project for more information. Chat-ops integrations powered by Hubot Integrate your application with fly-in panels today! Early access is available for developers. Many, many, many more to come! We are developing the APIs based on the competition, so stay tuned and you will see a lot happening here. Documentation Check out Rocket.Chat documentation. License Note that Rocket.Chat is distributed under the MIT License. Development Quick start for code developers Prerequisites: Git Meteor Meteor automatically installs a hidden NodeJS v12 and MongoDB v4.2 to be used when you run your app in development mode using the meteor command. Now just clone and start the app: For more detailed step-by-step, see our quick start for developers docs. To debug the server part, use meteor debugging. You should use Chrome for best debugging experience: You'll find a nodejs icon in the developer console. If you are not a developer and just want to run the server - see deployment methods. Branching Model See Branches and Releases. It is based on Gitflow Workflow, reference section below is derived from Vincent Driessen at nvie. See also this Git Workflows Comparison for more details. Translations We are experimenting with Lingohub. If you want to help, send an email to support at rocket.chat to be invited to the translation project. How to Contribute Already a JavaScript developer? Familiar with Meteor? Pick an issue, push a PR and instantly become a member of Rocket.Chat's international contributors' community. For more information, check out our Contributing Guide and our Official Documentation for Contributors. A lot of work has already gone into Rocket.Chat, but we have much bigger plans for it! Contributor License Agreement Please review and sign our CLA at https://cla-assistant.io/RocketChat/Rocket.Chat Credits Thanks to our core team Aaron Ogle, Bradley Hilton, Diego Sampaio, Gabriel Engel, Marcelo Schmidt, Rodrigo Nascimento, Sing Li, and hundreds of awesome contributors. Emoji provided graciously by JoyPixels Testing with BrowserStack Translations done with LingoHub Donate Rocket.Chat will be free forever, but you can help us speed up the development! BountySource"
3250,"A tooltip style toolbar jQuery pluginToolbar.js A jQuery plugin that creates tooltip style toolbars. Update Toolbar.js has been overhauled with new functionality, a completely new design and now makes use of Font Awesome project as the base for icons. Documentation You can find the documentation for the toolbar at the toolbar project page. This is the best source for documentation as it will be updated as new features are released. License (This project is released under the MIT license.) Copyright (c) 2013 - 2015 Paul Kinzett (http://kinzett.co.nz/) Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the ""Software""), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
4752,"Guiders.js: A Javascript library for guiders.Guiders are a user experience design pattern for introducing users to a web application. It's a great way to improve the first time user experience. View an Example Clone the repo, then check out README.html for guiders in action! As seen on Wikipedia: https://blog.wikimedia.org/2013/02/01/guided-tour-launch/ Set Up Here is sample code for initializing a couple of guiders. Guiders are hidden when created, unless .show() is method chained immediately after .createGuider. ~~~ javascript guiders.createGuider({ buttons: [{name: ""Next""}], description: ""Guiders are a user interface design pattern for introducing features of software. This dialog box, for example, is the first in a series of guiders that together make up a guide."", id: ""first"", next: ""second"", overlay: true, title: ""Welcome to Guiders.js!"" }).show(); / .show() means that this guider will get shown immediately after creation. / guiders.createGuider({ attachTo: ""#clock"", buttons: [{name: ""Close, then click on the clock."", onclick: guiders.hideAll}], description: ""Custom event handlers can be used to hide and show guiders. This allows you to interactively show the user how to use your software by having them complete steps. To try it, click on the clock."", id: ""third"", next: ""fourth"", position: 2, title: ""You can also advance guiders from custom event handlers."", width: 450 }); ~~~~ The parameters for creating guiders are: ~~~ attachTo: (optional) selector of the html element you want to attach the guider to autoFocus: (optional) if you want the browser to scroll to the position of the guider, set this to true buttons: array of button objects { name: ""Close"", classString: ""primary-button"", onclick: callback function for when the button is clicked (if name is ""close"", ""next"", or ""back"", onclick defaults to guiders.hideAll, guiders.next, or guiders.prev respectively) } buttonCustomHTML: (optional) custom HTML that gets appended to the buttons div classString: (optional) custom class name that the guider should additionally have closeOnEscape: (optional) if true, the escape key will close the currently open guider description: text description that shows up inside the guider highlight: (optional) selector of the html element you want to highlight (will cause element to be above the overlay) isHashable: (defaults to true) the guider will be shown auto-shown when a page is loaded with a url hash parameter #guider=guider_name offset: fine tune the position of the guider, e.g. { left:0, top: -10 } onClose: (optional) additional function to call if a guider is closed by the x button, close button, or escape key onHide: (optional) additional function to call when the guider is hidden onShow: (optional) additional function to call before the guider is shown overlay: (optional) if true, an overlay will pop up between the guider and the rest of the page position: (optional / required if using attachTo) clock position at which the guider should be attached to the html element. Can also use a description keyword (such as ""topLeft"" for 11 or ""bottom"" for 6) shouldSkip: (optional) if this function evaluates to true, the guider will be skipped title: title of the guider width: (optional) custom width of the guider (it defaults to 400px) xButton: (optional) if true, a X will appear in the top right corner of the guider, as another way to close the guider ~~~ Integration Besides creating guiders, here is sample code you can use in your application to work with guiders: ~~~ javascript guiders.hideAll(); // hides all guiders guiders.next(); // hides the last shown guider, if shown, and advances to the next guider guiders.show(id); // shows the guider, given the id used at creation guiders.prev(); // shows the previous guider ~~~ You'll likely want to change the default values, such as the width (set to 400px). These can be found at the top of guiders.js in the _defaultSettings object. You'll also want to modify the css file to match your application's branding. Creating a multi-page tour? If the URL of the current window is of the form http://www.myurl.com/mypage.html#guider=foo, then the guider with id equal to foo will be shown automatically. To use this, you can set the onHide of the last guider to an anonymous function: function() { window.location.href=http://www.myurl.com/mypage.html#guider=foo; } License Visit Supported Source - Guiders.js to get a license. The exact price will depend on your organization's size. It is free for individual use."
393,"Play FrameworkPlay Framework - The High Velocity Web Framework The Play Framework combines productivity and performance making it easy to build scalable web applications with Java and Scala. Play is developer friendly with a ""just hit refresh"" workflow and built-in testing support. With Play, applications scale predictably due to a stateless and non-blocking architecture. By being RESTful by default, including assets compilers, JSON & WebSocket support, Play is a perfect fit for modern web & mobile applications. Learn More www.playframework.com Download Install Create a new application Play for Scala developers Play for Java developers Build from source Search or create issues Get help Contribute License Copyright (C) Lightbend Inc. (https://www.lightbend.com). Licensed under the Apache License, Version 2.0 (the ""License""); you may not use this project except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0. Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
1438,"DL : dynamic load framework in androidDL : Apk (Development Help) English README Android Stuido APKDL DL 2.0 DL(lab) so(dev) DL plugin Rplugin pluginActivityFragmentActivity 3pluginhost 1 2hostplugin pluginhost 3pluginhostpluginhost DLjarDL android2.x DL activityDLapkapkapk apkRapkRidapkcopycopyapkapkxml activityContextImpl activitymBaseContextcontextContextImpl apk AssetManageraddAssetPathapkResourcesaddAssetPathapizipapkzipapkAssetManagerAssetManagerResourcesapk okayapkR activity apkapkactivityactivityactivityactivityactivityactivityactivityonCreateonStartonResumeonPauseapkactivityactivityFragmentFragment3.0support-v43.0androidFragmentActivityViewFragmentActivityactivityFragmentapkactivityactivityFragmentactivityactivityapkFragmentFragment DLactivityactivityDLPluginactivityDLProxyActivityactivityactivityactivity DLProxyActivity apk apkapk thisthisapkactivityactivityactivitythisthiscontextactivitythis thatthisthatthatapkactivityBaseActivityapkthisactivityanywaythat is better than this activitythatapiapithatapk activityactivityapkactivityapkactivityBaseActivitystartActivityByProxystartActivityForResultByProxyLaunchMode ServiceBroadcastReceiver DLIntentintentactivity UI Bus android /mnt/sdcard/DynamicLoadHostapkapkdemodemoactivityR nealgaologo License Copyright (C) 2014 singwhatiwanna() <singwhatiwanna@gmail.com> collaborator:, Licensed under the Apache License, Version 2.0 (the ""License""); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
1024,"A RESTful API package for the Laravel and Lumen frameworks.The Dingo API package is meant to provide you, the developer, with a set of tools to help you easily and quickly build your own API. While the goal of this package is to remain as flexible as possible it still won't cover all situations and solve all problems. Features This package provides tools for the following, and more: Content Negotiation Multiple Authentication Adapters API Versioning Rate Limiting Response Transformers and Formatters Error and Exception Handling Internal Requests API Blueprint Documentation Documentation Please refer to our extensive Wiki documentation for more information. API Boilerplate If you are looking to start a new project from scratch, consider using the Laravel API Boilerplate, which builds on top of the dingo-api package, and adds a lot of great features. Support For answers you may not find in the Wiki, avoid posting issues. Feel free to ask for support on the dedicated Slack room. Make sure to mention specialtactics so he is notified. License This package is licensed under the BSD 3-Clause license."
2103,"A JavaScript Sound API supporting MP3, MPEG4 and HTML5 audio + RTMP, providing reliable cross-browser/platform audio control in as little as 12 KB. BSD licensed.SoundManager 2: JavaScript Sound for the Web By wrapping and extending HTML5 and Flash Audio APIs, SoundManager 2 brings reliable cross-platform audio to JavaScript. HTML5 Audio() Support 100% Flash-free MP3 + MP4/AAC (and OGG, FLAC, etc.) where supported Compatible with Apple iPad (iOS 3.2), iPhone/iOS 4 and newer Fallback to Flash for MP3/MP4 support, if needed SM2 API is transparent; HTML5/flash switching handled internally HTML5 API support approximates Flash 8 API features Basic API Features Load, stop, play, pause, mute, seek, pan (Flash-only) and volume control of sounds from JavaScript Events: onload, whileloading, whileplaying, onfinish and more Flash-based Features (Legacy Support) (Flash 8+): ID3V1 and ID3V2 tag support for MP3s (title, artist, genre etc.) RTMP / Flash Media Server streaming support MPEG-4 (AAC, HE-AAC, H.264) audio support ""MultiShot"" play (layered / chorusing effects) Waveform/frequency spectrum data Peak (L/R channel volume) data Audio buffering state / event handling General Tech Stuff Full API Documentation with examples and notes console.log()-style debug output and troubleshooting tools GitHub Issues for discussion/support As Heard On The Internets Some places that do or have used SM2 include SoundCloud, Tidal, Beats, Songza, freesound.org, last.fm, 8tracks, Discogs, and The Hype Machine among others - but most importantly, http://nyan.cat. ;) Project Home, Documentation, Live Demos etc. http://www.schillmania.com/projects/soundmanager2/ Compiling JS builds (-nodebug, -jsmin) and Flash components, AS2/AS3 to SWF (Note: This process is pretty outdated and relies on ancient binaries for the Flash bits. Here be dragons.) An Ant build file defines the tasks for compiling JS and SWF components, useful if you make changes to the SM2 source and want to recompile. Google's Closure Compiler is used for the JS. AS2 compilation is done by MTASC, and AS3 is handled by Adobe's Open Source Flex SDK (mxmlc) compiler. Refer to build.xml for compiler downloads and path definitions. Versioning / Development Notes Releases are versioned by date, e.g., V2.97a.20170601 and are tagged as such. The latest official release is always on trunk/master. Post-release development builds may be available on the appropriate +DEV branch, eg., V2.97a.20170601+DEV Forks and Pull Requests Firstly, thank you for wanting to contribute! Bug fixes and tweaks are welcomed, particularly if they follow the general coding style of the project. If making a pull request, use the project's current +DEV development branch as the merge target instead of ""master"", if possible; please and thank-you. Random Trivia: SoundManager / SoundManager 2 History The original ""SoundManager"" implementation was created in 2001 and used JavaScript and Flash 6 (or thereabouts), and was hacked together to get JS-driven sound on a personal portfolio site. It was later used for the ""DHTML Arkanoid"" project in 2002. The original inspiration came from the sonify.org ""Flashsound"" project; they had tutorials and examples on getting Flash to play sounds when an HTML element was hovered on. This was very up my alley at the time. It all started with a cheezy kung-fu demo. http://sonify.org/flashsound/kungfu/ Flash's ExternalInterface API was not introduced until Flash 8, but a limited JS <-> Flash API existed via LiveConnect et al which still let the basics work. The original SoundManager used Flash's TCallLabel() methods, exposed to JS, to perform specific actions within ""Movie Clips"" (essentially, objects). Movie Clips contained Frames (in the animation sense) which could be given IDs (labels), and could also accept name/value parameters via SetVariable(). Thus, it was possible to create a Movie Clip for each sound, which would have a labeled frame for each sound action desired (stop, seek, pause, volume, and pan), e.g., flashMovie.SetVariable('/MySound:volume, 50); http://web.archive.org/web/20020404030916/http://sonify.org:80/flashsound/timeline/actionscript.html When a sound was created, playing it and setting parameters became a matter of having JS tell Flash to go to a specific frame within a Movie Clip to perform the desired ""action"" e.g., flashMovie.TCallLabel('/soundID', 'play'); and then an additional call to set a variable if needed to apply effects like volume, pan and so on. Internet Explorer on the Mac did not support the JS/Flash API via LiveConnect etc., but Netscape on MacOS was OK. The original SoundManager project still lives at http://schillmania.com/projects/soundmanager/ and was deprecated in 2007. SoundManager 2 became a reality when Flash 8 was released, as it introduced ExternalInterface which was a more complete JS <-> Flash API that allowed Flash methods to be exposed to JS, and could also accept full parameters. ExternalInterface is quite an interesting little hack, as the Flash movie injects some JS into the browser to make it work. Under the hood, it uses XML as a transport layer for calls. (Recall that in the 2000s, XML was hugely popular - the JSON of its day.) More here on how SM2 / Flash / EI interaction worked. http://www.schillmania.com/content/entries/2010/how-soundmanager2-works/ SoundManager 2 was released in 2006 and had a much more feature-rich and better-structured API, particularly at the time, thanks to learnings and feedback from the original SoundManager project. SM2 grew to be relatively popular among sites that used sound, whether as effects or a core part of the site experience. (Most sites used either SM2, or the jQuery-library-friendly jPlayer project.) Why version 2.97? SoundManager 2 has been at ""version"" 2.97 for a long time, because 2.97 was arguably the best llama-ass-whipping version of WinAmp. (WinAmp 3 was not as good, and WinAmp 5 was ""the best of 2 and 3 combined."") This MP3 player was my favourite Windows app during the 90's, and is missed as there's nothing quite like it on OS X where I spend most of my time these days."
3774,"Ruby algorithms and data structures. C extensionsalgorithms API Documentation DESCRIPTION: Started as a Google Summer of Code 2008 project Written by Kanwei Li, mentored by Austin Ziegler Original Proposal: Using the right data structure or algorithm for the situation is an important aspect of programming. In computer science literature, many data structures and algorithms have been researched and extensively documented. However, there is still no standard library in Ruby implementing useful structures and algorithms like Red/Black Trees, tries, different sorting algorithms, etc. This project will create such a library with documentation on when to use a particular structure/algorithm. It will also come with a benchmark suite to compare performance in different situations. COMPLETED: * Heaps Containers::Heap, Containers::MaxHeap, Containers::MinHeap * Priority Queue Containers::PriorityQueue * Deque Containers::Deque, Containers::CDeque (C ext) * Stack Containers::Stack * Queue Containers::Queue * Red-Black Trees Containers::RBTreeMap, Containers::CRBTreeMap (C ext) * Splay Trees Containers::SplayTreeMap, Containers::CSplayTreeMap (C ext) * Tries Containers::Trie * Suffix Array Containers::SuffixArray * Search algorithms - Binary Search Algorithms::Search.binary_search - Knuth-Morris-Pratt Algorithms::Search.kmp_search * Sorting algorithms - Bubble sort Algorithms::Sort.bubble_sort - Comb sort Algorithms::Sort.comb_sort - Selection sort Algorithms::Sort.selection_sort - Heapsort Algorithms::Sort.heapsort - Insertion sort Algorithms::Sort.insertion_sort - Shell sort Algorithms::Sort.shell_sort - Quicksort Algorithms::Sort.quicksort - Mergesort Algorithms::Sort.mergesort - Dual-Pivot Quicksort Algorithms::Sort.dualpivotquicksort SYNOPSIS: require 'rubygems' require 'algorithms' max_heap = Containers::MaxHeap.new # To not have to type ""Containers::"" before each class, use: include Containers max_heap = MaxHeap.new REQUIREMENTS: Ruby 1.8, Ruby 1.9, JRuby C extensions (optional, but very much recommended for vast performance benefits) LICENSE: See LICENSE.md."
4385,"Activiti is a light-weight workflow and Business Process Management (BPM) Platform targeted at business people, developers and system admins. Its core is a super-fast and rock-solid BPMN 2 process engine for Java. It's open-source and distributed under the Apache license. Activiti runs in any Java application, on a server, on a cluster or in the cloud. It integrates perfectly with Spring, it is extremely lightweight and based on simple concepts.Activiti Homepage: http://activiti.org Activiti is a light-weight workflow and Business Process Management (BPM) Platform targeted at business people, developers and system admins. Its core is a super-fast and rock-solid BPMN 2 process engine for Java. It's open-source and distributed under the Apache license. Activiti runs in any Java application, on a server, on a cluster or in the cloud. It integrates perfectly with Spring, it is extremely lightweight and based on simple concepts. NOTE: We moved to the master branch all the content of the development branch that we were using to design and code the next major version of the project. If you want to contribute with version 6.x please look at the 6.x branch. If you want to read more about our Repositories structure you can read our GitBook. Configuring IntelliJ Force language level 11, to fail-fast when (accidentally) using features available only in newer Java versions. Open menu File, menu item Project Structure Click list item Modules, for each module, tab Sources, combobox Language level should be automatically set to 11 ... Avoid that changes in some resources are ignored in the next run/debug (and you are forced to use mvn) Open menu File, menu item Settings or menu IntelliJ IDEA, menu item Preferences... if on a Mac Click tree item Compiler, textfield Resource patterns: change to !?*.java (remove other content) Avoid a StackOverflowError when building Open menu File, menu item Settings or menu IntelliJ IDEA, menu item Preferences... if on a Mac Click tree item Compiler, tree item Java Compiler, textfield Additional command line parameters Add -J-Xss1024k Recommended code style: use the Google Java Style Guide with editorconfig Download the IntelliJ code style xml from: [https://google.github.io/styleguide/intellij-java-google-style.xml] Open menu File, menu item Settings or menu IntelliJ IDEA, menu item Preferences... if on a Mac Click tree item Code Style, click cogwheel and select Import scheme, then IntelliJ code style xml Browse where you downloaded the xml and open it. Check that GoogleStyle is the active scheme. Note: IntelliJ IDEA doesn't format your code automatically. You have to press Ctrl+Alt+L keyboard combination to trigger auto formatting when coding is done. There's an .editorconfig what has definition for indents, file encoding, line endings. If you disable it, you need to set the file encoding and number of spaces correctly manually. Eclipse code style xml: [https://google.github.io/styleguide/eclipse-java-google-style.xml] Eclipse needs editorconfig-eclipse plugin in order to support EditorConfig files. Set manually the correct file encoding (UTF-8 except for properties files) and end-of-line characters (unix): Open menu File, menu item Settings or menu IntelliJ IDEA, menu item Preferences... if on a Mac Click tree item Code Style, tree item General Combobox Line separator (for new files): Unix Click tree item File Encodings Combobox IDE Encoding: UTF-8 Combobox Default encoding for properties files: ISO-8859-1 Note: normal i18n properties files must be in ISO-8859-1 as specified by the java ResourceBundle contract. Set manually the correct number of spaces when pressing tab: Open menu File, menu item Settings or menu IntelliJ IDEA, menu item Preferences... if on a Mac Click tree item Code Style, tree item General Click tab Java Checkbox Use tab character: off Textfield Tab size: 4 Textfield Indent: 4 Textfield Continuation indent: 8 Open tab XML Checkbox Use tab character: off Textfield Tab size: 2 Textfield Indent: 2 Textfield Continuation indent: 4 Set the correct file headers (do not include @author or a meaningless javadoc): Open menu File, menu item Settings or menu IntelliJ IDEA, menu item Preferences... if on a Mac Click tree item File templates, tab Includes, list item File Header Remove the line @author Your Name. We do not accept @author lines in source files, see FAQ below. Remove the entire javadoc as automatically templated data is meaningless. Set the correct license header Open menu File, menu item Settings or menu IntelliJ IDEA, menu item Preferences... if on a Mac Click tree item Copyright, tree item Copyright profiles Click import button to import the Copyright profile Select the file: Alfresco_Software.xml Click tree item Copyright Combobox Default project copyright: Alfresco Software FAQ Why do you not accept @author lines in your source code? Because the author tags in the java files are a maintenance nightmare A large percentage is wrong, incomplete or inaccurate. Most of the time, it only contains the original author. Many files are completely refactored/expanded by other authors. Git is accurate, that is the canonical source to find the correct author. Because the author tags promote code ownership, which is bad in the long run. If people work on a piece they perceive as being owned by someone else, they tend to: only fix what they are assigned to fix, instead of everything that's broken discard responsibility if that code doesn't work properly be scared of stepping on the feet of the owner. Credit to the authors is given: with Open Hub which also has statistics in the GitHub web interface. Development commands Add License header To format files with the required license: Checkstyle To check if your code style respect all the rules: Site To generate the maven site: the site will be generated at: target/staging/index.html CI/CD Running on GitHub Actions, requires the following secrets to be set: | Name | Description | |------|-------------| | NEXUS_USERNAME | Internal Maven repository username | | NEXUS_PASSWORD | Internal Maven repository password | | GITHUB_TOKEN | GitHub token |"
254,"A code-searching tool similar to ack, but faster.The Silver Searcher A code searching tool similar to ack, with a focus on speed. Do you know C? Want to improve ag? I invite you to pair with me. What's so great about Ag? It is an order of magnitude faster than ack. It ignores file patterns from your .gitignore and .hgignore. If there are files in your source repo you don't want to search, just add their patterns to a .ignore file. (*cough* *.min.js *cough*) The command name is 33% shorter than ack, and all keys are on the home row! Ag is quite stable now. Most changes are new features, minor bug fixes, or performance improvements. It's much faster than Ack in my benchmarks: ack test_blah ~/code/ 104.66s user 4.82s system 99% cpu 1:50.03 total ag test_blah ~/code/ 4.67s user 4.58s system 286% cpu 3.227 total Ack and Ag found the same results, but Ag was 34x faster (3.2 seconds vs 110 seconds). My ~/code directory is about 8GB. Thanks to git/hg/ignore, Ag only searched 700MB of that. There are also graphs of performance across releases. How is it so fast? Ag uses Pthreads to take advantage of multiple CPU cores and search files in parallel. Files are mmap()ed instead of read into a buffer. Literal string searching uses Boyer-Moore strstr. Regex searching uses PCRE's JIT compiler (if Ag is built with PCRE >=8.21). Ag calls pcre_study() before executing the same regex on every file. Instead of calling fnmatch() on every pattern in your ignore files, non-regex patterns are loaded into arrays and binary searched. I've written several blog posts showing how I've improved performance. These include how I added pthreads, wrote my own scandir(), benchmarked every revision to find performance regressions, and profiled with gprof and Valgrind. Installing macOS brew install the_silver_searcher or port install the_silver_searcher Linux Ubuntu >= 13.10 (Saucy) or Debian >= 8 (Jessie) apt-get install silversearcher-ag Fedora 21 and lower yum install the_silver_searcher * Fedora 22+ dnf install the_silver_searcher * RHEL7+ yum install epel-release.noarch the_silver_searcher * Gentoo emerge -a sys-apps/the_silver_searcher * Arch pacman -S the_silver_searcher Slackware sbopkg -i the_silver_searcher openSUSE zypper install the_silver_searcher CentOS yum install the_silver_searcher NixOS/Nix/Nixpkgs nix-env -iA silver-searcher SUSE Linux Enterprise: Follow these simple instructions. BSD FreeBSDpkg install the_silver_searcher OpenBSD/NetBSD pkg_add the_silver_searcher Windows Win32/64 Unofficial daily builds are available. wingetwinget install ""The Silver Searcher"" Notes: - This installs a release of ag.exe optimized for Windows. - winget is intended to become the default package manager client for Windows. As of June 2020, it's still in beta, and can be installed using instructions there. - The setup script in the Ag's winget package installs ag.exe in the first directory that matches one of these criteria: 1. Over a previous instance of ag.exe from the same origin found in the PATH 2. In the directory defined in environment variable bindir_%PROCESSOR_ARCHITECTURE% 3. In the directory defined in environment variable bindir 4. In the directory defined in environment variable windir Chocolateychoco install ag MSYS2 pacman -S mingw-w64-{i686,x86_64}-ag * Cygwin Run the relevant setup-*.exe, and select ""the_silver_searcher"" in the ""Utils"" category. Building from source Building master Install dependencies (Automake, pkg-config, PCRE, LZMA): macOS: brew install automake pkg-config pcre xz or port install automake pkgconfig pcre xz * Ubuntu/Debian: apt-get install -y automake pkg-config libpcre3-dev zlib1g-dev liblzma-dev * Fedora: yum -y install pkgconfig automake gcc zlib-devel pcre-devel xz-devel * CentOS: yum -y groupinstall ""Development Tools"" yum -y install pcre-devel xz-devel zlib-devel * openSUSE: zypper source-install --build-deps-only the_silver_searcher Windows: It's complicated. See this wiki page. Run the build script (which just runs aclocal, automake, etc): ./build.sh On Windows (inside an msys/MinGW shell): make -f Makefile.w32 Make install:sudo make install Building a release tarball GPG-signed releases are available here. Building release tarballs requires the same dependencies, except for automake and pkg-config. Once you've installed the dependencies, just run: ./configure make make install You may need to use sudo or run as root for the make install. Editor Integration Vim You can use Ag with ack.vim by adding the following line to your .vimrc: let g:ackprg = 'ag --nogroup --nocolor --column' or: let g:ackprg = 'ag --vimgrep' Which has the same effect but will report every match on the line. Emacs You can use ag.el as an Emacs front-end to Ag. See also: helm-ag. TextMate TextMate users can use Ag with my fork of the popular AckMate plugin, which lets you use both Ack and Ag for searching. If you already have AckMate you just want to replace Ack with Ag, move or delete ""~/Library/Application Support/TextMate/PlugIns/AckMate.tmplugin/Contents/Resources/ackmate_ack"" and run ln -s /usr/local/bin/ag ""~/Library/Application Support/TextMate/PlugIns/AckMate.tmplugin/Contents/Resources/ackmate_ack"" Other stuff you might like Ack - Better than grep. Without Ack, Ag would not exist. ack.vim Exuberant Ctags - Faster than Ag, but it builds an index beforehand. Good for really big codebases. Git-grep - As fast as Ag but only works on git repos. fzf - A command-line fuzzy finder ripgrep Sack - A utility that wraps Ack and Ag. It removes a lot of repetition from searching and opening matching files."
426," Now we have become very big, Different from the original idea. Collect premium software in various categories.Awesome Mac Now we have become very big and different from the original idea. Here we collect awesome macOS software in various categories. Feel free to star and fork. Any comments, suggestions? Let us know! We love PRs :) Please take a look at the contributing guidelines before opening one. Follow the awesome list. Explanation English | means open source, click to open open source repo;\ means free to use, or free personal license;\ means App store hyperlink;\ means hyperlink to a corresponding Awesome list for the item; Awesome Mac App for macOS. Installers for the latest stable build for Mac can be downloaded here. Contents Awesome Mac Contents Reading and Writing Tools Text Editors Office Markdown Tools Note-taking Journaling Ebooks RSS Others Developer Tools IDEs Developer Utilities Regular Expression Editors API Development and Analysis Network Analysis Command Line Tools Frameworks For Hybrid Applications Version Control Virtualization Databases Design and Product Design Tools Prototyping and Mind-Mapping Tools Screencapturing Software Other Tools Communication Collaboration and Team Tools Email Clients File Sharing Data Recovery Tools Audio and Video Tools Download Management Tools Cloud Storage Input Methods Browsers Translation Tools Encryption Security Tools Proxy and VPN Tools Utilities Clipboard Tools Menu Bar Tools File Organization Tools General Tools To-Do Lists Productivity Window Management Password Management Finder Tools Quality of Life Improvements System Related Tools Gaming Software Remote Login Software Social Networking QuickLook Plugins Third Party App Markets Package Managers Mac App Download Sites Genuine Sites Pirated software download site blacklist Podcasts Contributors Backers Sponsors License Reading and Writing Tools Applications to edit text, I suggest the open-source editors Text Editors Atom - Hackable text editor for the 21st century made by GitHub. Atom Plugins. Bear Writer - Beautiful, flexible writing app for crafting notes and prose. Bootstrap Studio - A powerful desktop app for creating responsive websites using the Bootstrap framework. Brackets - A modern, open source text editor that understands web design. Chocolat - Native text editor. Coda2 - Fast, clean and powerful text editor. CotEditor - Lightweight plain-text editor for macOS. Emacs - A popular text editor used mainly on Unix-based systems by programmers, scientists, engineers, students, and system administrators. LightTable - The next generation code editor. micro - Modern and intuitive terminal-based text editor. Nova - Modern, extensible text editor, by the makers of Coda. ONI - IDE powered by Neovim. Sublime Text - Sophisticated text editor for code, markup and prose. You'll love the slick user interface, extraordinary features and amazing performance, Sublime Text Plugins. TextMate - Editor that brings Apple's approach to operating systems into the world of text editors. Vim - Highly configurable text editor built to make creating and changing any kind of text very efficient, Vim Plugins. Vimr - Refined Vim Experience for OS X. Office LibreOffice - LibreOffice is free and open-source software office software. Software is tested and used daily by a large and devoted user community. WPS - Is a cross-platform office software suite. Pages Documents that stand apart. Keynote Build stunning presentations. Numbers Create impressive spreadsheets. Microsoft Office Unmistakably Office, designed for Mac. SoftMaker Office A complete office suite that aims for full compatibility with Microsoft Office documents Markdown Tools EME - Open-source Markdown editor with an interface like Chrome. iA Writer - Writing app with an emphasis on simplicity and design. LightPaper - Simple, beautiful, yet powerful text editor for your Mac. MacDown - Open-source Markdown editor for OS X. Marked 2 - This is the Markdown preview with an elegant and powerful set of tools for all writers. MarkText - Next generation markdown editor, running on platforms of MacOS Windows and Linux. Marp - Markdown presentation writer with cross-platform support. Marxico - Delicate Markdown editor for Evernote. Reliable storage and sync. MWeb - Pro Markdown writing, and static blog generator App. TextNut - Rich-format editor featuring Markdown export and Markdown syntax hints. Typora - Truly minimal Markdown editor featuring seamless live preview. Ulysses - The Ultimate Writing App for Mac, iPad and iPhone. Note-taking Agenda - Date-focused note taking app for both planning and documenting your projects. Boostnote - Note-taking app made for programmers. Dnote - A simple command line notebook with multi-device sync and a web interface. Evernote - Infamous note-taking app, available on many platforms. FSNotes - File System Notes is a modern notes manager, native on macOS and iOS. Gooba - Writing app and task manager with a simple and interactive design. Inkdrop - Notebook app for Markdown lovers built on top of Electron. Joplin - Cross platform open-source notepad with markdown support and todo list manager with synchronisation capabilities. MarginNote - In-depth PDF and EPUB reading, learning, managing and note taking app. Notable - The markdown-based note-taking app that doesn't suck. Notebook Note-taking app. Notes - Clean, simple note-taking app. Notion -Notion is the all-in-one workspace. From notes, tasks, wikis, to database, Notion is all you need. Works great for teams and individuals. Obsidian - Obsidian is a powerful knowledge base that works on top of a local folder of plain text Markdown files. OneNote - Note-taking app by Microsoft. SideNotes - Quick notes on the screen side. Take notes while working with other apps. Use Markdown for text formatting. QOwnNotes - Open-source notepad with markdown support and todo list manager. Quiver - The Programmer's Notebook, lets you easily mix text, code, Markdown and LaTeX within one note, edit code with an awesome code editor and live preview Markdown and LaTeX. AliYuQue - Cloud note-taking knowledge management, collaboration platform, Markdown based writing, support embedded flow chart, brain diagram, timing sequence, code rendering, Sketch board creation, personal knowledge sharing, etc. Compared to youdao cloud note and evernote similar products, which include all of its functions, support knowledge sharing and more powerful creation, collaboration and editor, it comes from alibaba ant financial. Journaling Day One - Excellent journaling app using text, photos, video, audio, location data, and more. Journey - Journaling app with many features and with apps for every platform available. linked - Link your thoughts to days, distraction free. Ebooks Calibre - Free and open-source e-book computer software application suite which runs on multiple platforms, allows users to manage e-book collections as well as create, edit, and read e-books. Clearview - Tabbed style e-book reader for PDF, EPUB (DRM free), CHM, and MOBI. iChm - Ebook reader for CHM (Microsoft Compiled HTML help) files. Kindle App - Amazon official reading app of kindle. Klib - New way to manage highlights for Kindle and iBooks. Scribus - Professional layout and publishing software supporting EPS and SVG import/export, and PDF support. Sigil - Multi-platform EPUB ebook Editor. RSS Leaf - Amazing news reader dedicated to help you enjoy your daily news and easily manage your subscriptions. NetNewsWire - Its a free and open source feed reader for macOS. ReadKit - Mac read-later client supporting all major providers: Instapaper, Pocket and Readability. Even more, ReadKit is a full-featured RSS reader as well. Reeder 4 - News reader for Feedbin, Feedly, Feed Wrangler and so on. Vienna - RSS/Atom reader for Mac OS X. Feedy - An elegant and lightweight RSS client and news reader for your Mac. Others bindPDF - Combine multiple PDF files into a single PDF file using a friendly UI. CHM Reader - Read Compiled HTML (.chm) documents on your Mac. Chmox - Read CHM documents on your Mac. PDF Expert - Read, annotate and edit PDFs, change text and images. PDF Reader Pro - You Can view, create, sign, convert and compress any PDF documents. Skim - PDF reader and note-taker for OS X. SkyFonts - The simplest way to try, install, and manage fonts. Spillo - Powerful, beautiful and amazingly fast Pinboard client for OS X. Tad - Application for viewing and analyzing tabular data such as CSV files. texpad - Great LaTeX editor for Mac with auto-update PDF and autocomplete LaTeX commands. Developer Tools IDEs Android Studio - The official IDE for Android, based on Intellij IDEA. Deco IDE - The best IDE for building React Native apps. Eclipse - Popular open-source IDE, mainly for Java but with plugin support for a wide array of languages and platforms. Espresso - The web editor for Mac is back. For people who make delightful, innovative and fast websites. JetBrains Toolbox App - Manage installed JetBrains tools, download new ones and open recent projects. AppCode - Smart IDE for iOS/macOS development CLion - Powerful C and C++ IDE. (Free for Students) DataGrip - Cross-Plaform IDE for Databases and SQL. FREE for Students, check here for more info. GoLand - Provides ergonomic environment for Go development. IntelliJ IDEA - Powerful IDE for JVM languages. (Free for Students) PyCharm - Powerful Python IDE, which has professional version and community version. Rider - Cross-Platform C# IDE. It is an alternative to Visual Studio by Microsoft with the additional benefit of getting Resharper features that are not available on Visual Studio for Mac. WebStorm - The smartest JavaScript IDE by JetBrains. FREE for Students, check here for more info. Haskell for Mac - A Modern Development Environment for Haskell. NetBeans IDE - Free and open-source IDE, mainly used for Java development, but supports many other languages and frameworks. Visual Studio Community for Mac - Fully-featured IDE Free for students, open-source and individual developers. Visual Studio Code - Microsoft's free & open-source editor, TypeScript friendly, VSCode Plugins. Xamarin Studio - Free cross platform C# IDE. Xamarin Studio supports iOS, Android and .Net development Xcode - Essential IDE for iOS/macOS development. Spyder - Powerful scientific environment written in Python, for Python. Developer Utilities BetterRename - The most powerful and complete Mac file renaming application on the market. Beyond Compare - Compare files and folders using simple, powerful commands that focus on the differences you are interested in and ignore those you are not. Bidbar - Manage bash commands from the menu bar and run them with keyboard shortcuts. Cacher - Cloud-based, team-enabled code snippet manager with Gist sync, VSCode/Atom/Sublime packages and Mac/Windows/Linux/Web clients. canSnippet - Powerful snippet management tool that works across the whole operating system, always accessible via simple keyboard shortcut. CodeKit - Web development tool which can automatically compile Less, Sass, CoffeeScript, TypeScript, Jade and JavaScript, auto-refresh browsers and much more. Conduktor - Kafka desktop client. Dash - Awesome API documentation browser and code snippet manager. DiffMerge - Application to visually compare and merge files. EnvPane - OS X preference pane for environment variables. FinderGo - Open terminal quickly from Finder. Finicky - Application that allows you to set up rules that decide which browser is opened for every link that would open the default browser. Gas Mask - Simple hosts file manager for Mac OS X. Gemini - Intelligent duplicate file finder. Hex Fiend - Fast and clever open source hex editor. Hosts.prefpane - System preference pane to manage your hosts file. iHosts - The only /etc/hosts editor on Mac App Store. Integrity - Free website link checker for Mac. Kaleidoscope - Powerful compare tool for text, images and folders. Works perfectly with git, svn or other version control tools. Koala - GUI application for Less, Sass, Compass and CoffeeScript compilation. Loca Studio - Analyze, review, and edit app translations. Supports Xcode Localization Catalog (xcloc) and XLIFF 1.2 file formats. MacSystemColors - Mac app that shows all system colors in light and dark mode for Cocoa developers. MJML - Framework that utilizes a semantic syntax and a rich standard components library, which allow users to easily create responsive emails. PaintCode - PaintCode is a unique vector drawing app that generates Objective-C or Swift code in real time, acting as a bridge between developers and graphic designers. PPRows - Application to calculate how many lines of code you write. PushMate PushMate is a MacOS app that solves common push notification problems by ensuring your push payloads are correct. SCM Breeze - Set of shell scripts (for bash and zsh) that enhance your interaction with git. SecureCRT - Terminal emulation which supports SSH, Telnet or other protocols. Site Sucker - SiteSucker is a Macintosh application that automatically downloads websites from the Internet. SnippetsLab - Easy-to-use code snippets manager. Solarized - Clean and beautiful color theme. Works well with iTerm, JetBrains products, Vim etc. StarUML - Powerful UML app. Swiftify - Objective-C to Swift code converter and Xcode & Finder extensions. SwitchHosts - Free and open-source app for hosts management & switching. SYM - GUI Application to symbolicate iOS crash log. TeXstudio - Integrated writing environment for creating LaTeX documents. Timelane - Visually profile your asynchronous code. Touch Bar Simulator - Use the Touch Bar on any Mac. Visual Paradigm - All-in-one UML, SysML, BPMN Modeling Platform for Agile, EA TOGAF ADM Process Management. Woodpecker - View iOS app's Sandbox files, UserDefaults, Keychain items on a Mac. WWDC - The Mac OS unofficial WWDC app. Xcodes - Install and switch between multiple versions of Xcode. zeplin - Collaboration tool for work between designers and developers. Nib Unlocker - .nib to .xib converter Regular Expression Editors Patterns - Regular expression editor. Regex - Regular expression testing tool with an emphasis on simplicity. RegExRX - Development tool for regular expressions. API Development and Analysis Cocoa Rest Client - Free, open-source, native Apple OS X app for testing HTTP/REST endpoints. Insomnia - The most intuitive cross-platform REST API Client. Paw - Advanced HTTP client. Postman - Powerful GUI platform to make your API development faster & easier, from building API requests through testing, documentation and sharing. Katalon Studio - Simplify API, Web, Mobile Automation Tests Free. Robust. Cross-platform. Automation testers from 160 countries with YouTube channels, GitHub repositories. Network Analysis Charles - HTTP proxy / HTTP monitor / Reverse Proxy that enables a developer to view all of the HTTP and SSL / HTTPS traffic between their machine and the Internet. James - Open-source proxy tool for checking and mapping requests with http as well as https. Little Snitch - Network monitor with a world map for visualizing network connections. mitmproxy - Interactive intercepting HTTP proxy for penetration testers and software developers. Proxie - HTTP debugging proxy. Proxyman - Modern and intuitive HTTP debugging proxy for macOS. Wireshark - The worlds foremost and widely-used network protocol analyzer. Command Line Tools ack - A tool like grep, optimized for programmers. alacritty - A cross-platform, GPU-accelerated terminal emulator. archey-osx - An archey script for OS X. asciinema - Easily record terminal sessions and replay them in a terminal as well as in a web browser. autojump - Replace cd with an intelligent autojump to easily navigate directories from the command line. bash-it - Shameless ripoff of oh-my-zsh for bash. bat - A cat(1) clone with syntax highlighting and Git integration. ccat - The colorizing cat which works similar to cat but displays content with syntax highlighting. cmus - Small, fast and powerful console music player for Unix-like operating systems. cool-retro-term - Good looking terminal emulator which mimics the old cathode display. dark-mode - Control dark mode from the command-line. eureka - CLI tool to input and store your ideas without leaving the terminal. Fish Shell - Smart and user-friendly terminal, which is similar with zsh. fselect - Find files with SQL-like queries. Github CLI - gh is GitHub on the command line. It brings pull requests, issues, and other GitHub concepts to the terminal next to where you are already working with git and your code. Glances - Glances is a cross-platform curses-based system monitoring tool. Go2Shell - Go2Shell opens a terminal window to the current directory in Finder. htop - htop is an interactive text-mode process viewer for Unix systems. It aims to be a better 'top'. httpie - Modern command line HTTP client user-friendly curl alternative with intuitive UI, JSON support, syntax highlighting, wget-like downloads, extensions, etc. hyper - A terminal built on web technologies. iTerm2 - iTerm2 is an amazing terminal emulator for OS X. itunes-remote - Software for controlling iTunes via the terminal. job - JOB, make your short-term command as a long-term job. kitty - A cross-platform, fast, feature full, GPU based terminal emulator. lnav - A log file navigator. m-cli - Swiss Army Knife for macOS. Mac-CLI - The ultimate tool to manage your Mac. Automatize the usage of your OS X system. Magic Wormhole - Get Things From One Computer To Another, Safely. mas - Simple command line interface for the Mac App Store. Miller - Like awk, sed, cut, join, and sort for name-indexed data such as CSV, TSV, and tabular JSON. mycli - CLI for MySQL that can do auto-completion and syntax highlighting. ndm - Manage npm straight from the couch. nushell - nushell is a modern, GitHub-era shell written in Rust. pgcli - Pgcli is a command line interface for Postgres with auto-completion and syntax highlighting. Rebound - Instantly browse Stack Overflow results in your terminal when you get a compiler error. Serial - Full-featured serial terminal for the Mac. shallow-backup - Easily create text documentation of installed applications, dotfiles, and more. silver searcher (ag) - A code searching tool similar to ack, with a focus on speed. spaceship - A Zsh prompt for Astronauts. Taskbook - Tasks, boards & notes for the command-line habitat. Terminus - Free terminal tool, built with TypeScript, heavily inspired by Hyper. Termius - Free terminal tool,comparable to xshell on windows platform. TextQL - Execute SQL against structured text like CSV or TSV. tmux - ""Terminal multiplexer"", it enables a number of terminals (or windows) to be accessed and controlled from a single terminal. tmux is intended to be a simple, modern, BSD-licensed alternative to programs such as GNU screen. tmuxinator - Manage complex tmux sessions easily. trash - Move files and directories to the trash. VisiData - Terminal spreadsheet multitool for discovering and arranging data. xonsh - Python-powered, cross-platform, Unix-gazing shell language and command prompt. Zsh - Zsh is a shell designed for interactive use, although it is also a powerful scripting language. xcodes - A command-line tool to install and switch between multiple versions of Xcode. xxh - Bring your favorite shell wherever you go through the SSH. Frameworks For Hybrid Applications AppJS - Lightweight JavaScript UI library for creating mobile webapps that behave like native apps. create-dmg - Create a good-looking DMG for your macOS app in seconds. Electrino - Desktop runtime for apps built on web technologies, using the system's own web browser engine. Electron - Build cross platform desktop application with JavaScript, HTML and CSS. ionic - Build amazing native and progressive web apps with Angular and open web technologies. One app running on everything. MacGap - Provides a lightweight JavaScript API for OS X integration, such as displaying native notifications or writing data to a file. nw.js - Build desktop application with HTML and JavaScript. It lets you call all Node.js modules directly from DOM and enables a new way of writing applications with all Web technologies. Qt - Cross-platform application framework. React Native for Ubuntu - Build Ubuntu desktop apps using React Native. React Native macOS - Build OS X desktop apps using React Native and Cocoa. react-desktop - React UI Components for macOS Sierra. ReactXP - Microsoft official production, support platform Web, iOS, Android and Windows UWP is still an ongoing work. Version Control Cornerstone - Powerful version control with a gorgeous interface. Fork - Fast and friendly Git client for Mac. Git Cola - Powerful, Fast, Lightweight and Friendly Git GUI. For those caffeine adicting users. Gitbar - Open-sourcedisplay Github contribution statistics on your menu bar. GitFinder - Fast and lightweight Git client for Mac with Finder integration. Gitfox - Commit faster, improve your code quality with superior diffs - and look good doing it. GitHub Desktop - The official GitHub GUI. GitKraken - The most popular Git GUI for Windows, Mac and Linux. GitX-dev - Fork of Pieter's nice git GUI for OS X. Includes branch/tag sidebar and various fixes. Hub - Command-line wrapper for Git that makes you better at GitHub. OhMyStar Beautiful and efficient way to manage, explore and share your Github Stars. SmartGit - Git client with support. SourceTree - Free Git & Mercurial client for Windows or Mac. Sublime Merge - Git client, from the makers of Sublime Text. Tower2 - The most powerful Git client for Mac and Windows. GitUp - A simple & powerful Git client Virtualization Docker - Powerful, performs operating-system-level virtualization. Parallels - Powerful, easy-to-use VM. No free upgrade for each new Mac OS. Vagrant - Tool for building and distributing development environments. Veertu - The lightest VM on Mac. Responsive, sandboxed & native way to run VM on your Mac. Virtual Box - Powerful x86 and AMD64/Intel64 virtualization product. VMware Fusion - Powerful, commercial VM developed by VMware. Databases Apache Directory Studio - LDAP browser and Active Directory client. Azure Data Studio - Cross-platform database tool for using on Microsoft family on-premises and cloud data platforms such as MSSQL Server Another Redis Desktop Manager - A faster, better and more stable redis desktop manager. Base 2 - Application for creating, designing, editing and browsing SQLite 3 database files. Beekeeper Studio - Smooth SQL editor and database manager Bdash - Modern SQL client application, supports MySQL, PostgreSQL (Redshift) and BigQuery. Chrome MySQL Admin - Powerful Chrome app to manage your MySQL. Core Data Editor - Core Data Editor lets you easily view, edit and analyze applications data. DB Browser for SQLite - Official home of the DB Browser for SQLite. DBeaver - Universal SQL Client. ElectroCRUD - Modern MySQL CRUD application. FastoNoSQL - Cross-platform GUI client for Redis, Memcached, SSDB, LevelDB, RocksDB, UnQLite, LMDB, ForestDB, Pika and Dynomite key-value databases. FastoRedis - Cross-platform professional GUI management tool for Redis. JackDB - Secure, collaborative environment for your queries and data-driven insights. Keylord - Desktop GUI client for Redis, Bolt, LevelDB and Memcached key-value databases. MDB Explorer - MDB tool to open, read, export your MDB files to other formats and databases. Medis - GUI Manager for Redis. Mingo - Easy to use MongoDB GUI with mind-blowing features. Mongo Management Studio - Simple MongoDB GUI. mongoDB.app - The easiest way to get started with mongoDB on the Mac. MongoDB - MongoDB is a document database with the scalability and flexibility that you want with the querying and indexing that you need. MySQL Workbench - The official MySQL GUI. Navicat Data Modeler - Powerful and cost-effective database design tool which helps you build high-quality conceptual, logical and physical data models. neo4j - The leading graph database! pgModeler - is an open source data modeling tool designed for PostgreSQL. Postgres.app - The easiest way to get started with PostgreSQL on the Mac. Postico - Modern PostgreSQL client for Mac. PSequel - PostgreSQL GUI tool for Mac OS X. RedisClient - Redis client application on mac, windows and linux. RedisDesktopManager - Cross-platform GUI management tool for Redis. Sequel Pro - MySQL database management for Mac OS X. SQLight - SQLite database manager tool. SQLPro Studio - Simple, powerful database manager for macOS. Tableau Public - Free data-visualization software. TablePlus - Supports: PostgreSQL, MySQL, RedShift, MariaDB... High-end security ensured. Design and Product Design Tools Acorn - Great Mac OS X picture and photo editor, built for humans. Affinity Designer - Professional graphic design software for Mac. Affinity Photo - Professional image editing software for Mac. Alchemy - Experimental, open-source drawing application with an emphasis on creating conceptual art. Amadine - A vector drawing app that has everything a graphic designer needs wrapped in an uncluttered and intuitive interface. Art Text 3 - This is graphic design software specifically tuned for lettering, typography, text mockups and various artistic text effects. Blender - Free and open 3D creation software. Colorpicker - Colorpicker is a complete open-source colors manipulation tool with picking! Figma - The collaborative interface design tool, for vector graphics and UI prototyping. FontForge - Free, open-source font editor. GIMP - The GNU Image Manipulation Program. Gravit Designer - Full featured free vector design app right at your fingertips. inklet - Turn your Mac trackpad into drawing board. Inkscape - Professional vector graphics editor. Krita - Open-source digital painting software for concept artists, digital painters, and illustrators. macSVG - Designing HTML5 SVG art and animation. MagicaVoxel - Free, lightweight 8-bit voxel editor and interactive path tracing renderer. MakeHuman - Powerful and free 3D human modeler. Monodraw - Powerful ASCII art editor designed for the Mac. Nik Collection - Nik Collection by DxO. Paintbrush - Bitmap image editor. Pencil2D - A easy, intuitive tool to make 2D hand-drawn animations. Pixel Perfect - Tool to overlay design images over implementation and make it pixel perfect. Pixelmator - Full-featured image editor for Mac. Principle - Application for designing animated and interactive user interfaces. ScreenToLayers- Easily export your screen into a layered PSD file. Sculptris - 3D sculpting software. Sketch - Professional digital design for mac. Sketch Cache Cleaner - Deletes hidden Sketch history files that can take a lot of space on your hard drive and that you would probably never use. Measure Plugin - Make it a fun to create spec for developers and teammates. Sketch Toolbox Plugin Manager - Simple plugin manager for Sketch. User Flows Plugin - Generating flow diagrams from Artboards. SketchBook - Drawing software for concept design, comic art, and digital sketching. Sparkle - Pro visual web design. Tayasui Sketches - Professional drawing software. Vectr - Free graphics editor used to create vector graphics easily and intuitively. Prototyping and Mind-Mapping Tools Adobe XD (Experience Design) - First all-in-one cross-platform tool for designing and prototyping websites and mobile apps. Axure RP 8 - Prototypes, specifications and diagrams in one tool. Balsamiq Mockups - Wire-framing tool that helps you work faster and smarter. Flinto - Quickly create interactive prototypes of mobile, desktop, or web apps. Framer - Tool for interactive prototyping. Justinmind - Prototyping platform for web and mobile apps. Kite - Powerful animation and prototyping application for Mac & iOS. Lighten - The best way to clarify thinking, boost productivity, brainstorm, and visualize concepts. Loremify - Great Lorem ipsum generator. Marvel - Simple design, prototyping and collaboration. MindNode - Mind-mapping software with an emphasis on simplicity and ease-of-use. MockFlow - Online prototyping suite for web-design and usability testing. Mockplus - Prototype faster, smarter and easier. OmniGraffle - Diagramming and graphic design for Mac, iPhone, and iPad. Origami Studio - Tool for designing modern interfaces, built and used by designers at Facebook. pencil - Free, open-source tool for making diagrams and GUI prototyping. ProtoPie - Create the most advanced prototypes as easy as Pie. Scapple - Practical mind-mapping software with free whiteboard-like layout. SimpleMind - The world leader in cross platform Mind Mapping tools. WriteMapper - Get from idea to final draft in no time. XMind - The most popular mind-mapping tool on the planet. Simple Diagrams - A desktop app for creating hand-drawn-like, fast, clear sketches of problems, processes, workflows, ideas and more! yGraph Editor - High quality diagrams made easy. Screencapturing Software CleanShot - Discover a superior way to capture your Mac's screen. CloudApp - Work at the speed of sight. Gifox - Gif Recording and Sharing. Kap - Open-source screen-recorder built with web technology. KeyCastr - KeyCastr, an open-source keystroke visualizer. Kyapchar - Simple screen and microphone audio recorder for Mac. Licecap - Record your screen and export to GIF. You can change the recording area anytime during recording. Lightshot - The fastest way to take a customizable screenshot. Monosnap - Make screenshots. Draw on it. Shoot video and share your files. It's fast, easy and free. ScreenShot PSD - Capture the screen as a layered PSD for easy editing. Skitch - Screen capture application with a powerful annotation capabilities. Snip - Application for sharing captured images on QQ Mail. Snipaste - Simple but powerful snipping tool. Teampaper Snap - Let your screenshots speak up. Xnip - Handy Screenshot App. Dropbox - Dropbox app offers easy screenshot capturing and sharing Other Tools APNGb - PNG image assembler/disassembler app. Assetizr - Resizing images and optimising them for web and mobile applications. Couleurs - Simple app for grabbing and tweaking the colors you see on your screen. ExifCleaner - Remove exif metadata from images and videos with drag and drop. Frank DeLoupe - Color-picking tool, supports Retina. HEIC Converter - Convert HEIC images to JPEG or PNG. Iconset - Free, cross-platform and fast SVG icon organizer and manager for Mac and Windows. Iconjar - Icon management tool to organize or search your icons. IconKit - App icon generator. Image2icon - Create and personalize icons from your pictures. ImageAlpha - Compress images with PNG format and remove transparency. ImageOptim - Compress images and remove EXIF information. iPic - Easily upload images with Markdown supported. JPEGmini - Reduce image size by up to 80%, without compromising quality. Mark Man - Measure & Spec Fast. Nucleo - Icon manager. Import, export, customize and convert icon libraries. Preset Brewery - Tool to convert Lightroom presets to Adobe Camera Raw. Resize Master - Batch resize and watermark your images fast and easy. RightFont - Preview, sync, install and manage fonts on Mac, Dropbox or Google Drive. Sip - The best way to collect, organize & share your colors. Snagit - Simple, Powerful Screen Capture Software and Screen Recorder. Spectrum - Easily and intuitively creating beautiful color schemes. svgus - Organize, clean and transform your SVGs. TinyPNG4Mac - Open-source tool to compress images. Tropy - Research Photo Management. PicGo - Support for common cdn image hosting tool. Assetizr - Resizing images and optimising them for web and mobile applications. AppIconBuilder - Export icons for multi-platform uPic - macOS native app, powerful terse image hosting client. Communication Collaboration and Team Tools Adium - Free instant messaging application for Mac OS X. Connect to AIM, MSN, SMPP, Yahoo and more. Caprine - Third-party privacy-focused Facebook Messenger app. DingTalk - Free, powerful and professional office tool used by over 5 million enterprises and organizations globally. Discord - All-in-one voice and text chat for gamers that's free, secure, and works on both your desktop and phone. Franz - Electron based, multi-protocol wrapper for web-based chat. One application, 23 messenger services. Gitter - Instant messaging and chat room system for developers as well as GitHub users. Developer friendly with Markdown syntax support. Keybase - Secure groups, files, and chat for everyone! Krisp - An AI-powered noise cancelling app that mutes background noise during calls. LimeChat - Open-source IRC client for Mac OS X. Messenger For Mac - Third-party Facebook messenger for Mac. Muzzle - A simple mac app to silence embarrassing notifications while screensharing. Rambox - Messaging and emailing app that combines common web applications into one. Element - Create, share communicate. Chat and call securely. Signal Desktop - Fast, simple, secure. Privacy that fits in your pocket. Skype - Cross-platform application that provides video chat and voice call services. Users can exchange images, text, video and any other digital documents. Shift - De-clutter your desktop workspace and streamline your accounts, apps, and workflows. Slack - Awesome tool for team collaboration and communication. Stack - Open, organize and use multiple web apps on a single screen. Stack your apps by categories or projects. Teambition - Team collaboration tool, including many features like task plan, schedule, file sharing, instant discussion and everything you need when collaborating with other team members. Telegram - Messaging app with a focus on speed and security. Textual - Internet Relay Chat (IRC) client. WeChat - Official WeChat app for Mac. WeeChat - The extensible command-line chat client. WhatsApp Desktop - Available in the Mac App Store, Whatsapp for Desktop. Email Clients Airmail - Fast email client. For both Mac OS and iOS. Foxmail - Fast email client. MailTags - Use tags to organize email and schedule. N1 - Extensible, open-source mail app, free for developers and $7/month for Pro. Nylas Mail - Extensible desktop mail app built on the modern web. Polymail - Simple, beautiful and powerful email client. Postbox - Powerful, simple and beautiful email client, need to pay for a license. Spark - Fast email client. For both Mac OS and iOS. ThunderBird - Software that makes email easier. Edison Mail - A customisable, simple, and beautiful email client. File Sharing Cyberduck - Free FTP, SFTP, WebDAV, S3, Backblaze B2, Azure and OpenStack Swift browser. Flow - Award-winning, beautiful, fast, and reliable FTP + SFTP client. Transmit - Highly flexible and intuitive FTP client, supports SFTP, S3 and iDisk/WebDAV. Data Recovery Tools Data Rescue - Comprehensive and professional data recovery tool for most cases. DiskWarrior - The worlds most advanced repair and recovery tool for Mac. R-Studio for Mac - Powerful tool for recovering data on disks, even if their partitions are formatted, damaged or deleted. SuperDuper! - Painless fully bootable disk backups. Audio and Video Tools Adapter - Free audio, video and image conversion software. Aegisub - Free, cross-platform open source tool for creating and modifying subtitles. Aegisub makes it quick and easy to time subtitles to audio, and features many powerful tools for styling them, including a built-in real-time video preview. Audio Profile Manager - Allows you to pin input/output devices for each particular combination of connected devices. May suppress HDMI displays from being chosen. Ardour - Cross-platform audio software for multi-track recording and editing. Audacity - Free, open-source, cross-platform audio software for multi-track recording and editing. Audio Hijack - Record any application's audio, including VoIP calls from Skype, web streams from Safari, and much more. Carol - A minimal and beautiful lyrics app for macOS. Cog - Free, open-source audio player. DaVinci Resolve - Free, cross-platform video editing, color grading, video effects and audio editing software. Elmedia Player - This media player is a super versatile app for any file format you probably may think of: FLV, MP4, AVI, MOV, DAT, MKV, MP3, FLAC, M4V are all supported as well as many others. Gifski - Convert videos to high-quality GIFs. HandBrake - Tool for converting video from nearly any format to a selection of modern, widely supported codecs. Hydrogen - Professional yet simple and intuitive pattern-based drum programming for GNU/Linux. iFFmpeg - Comprehensive Media Tool for macOS. Making High Quality Video Encoding Accessible for Everyone. IINA - The modern video player for macOS. Based on mpv, the powerful media player project. Kodi - Award-winning free and open-source (GPL) software media center for playing videos, music, pictures, games, and more. LMMS Formerly ""Linux MultiMedia Studio"", LMMS is a powerful Digital Audio Workstation designed like FL Studio (formerly Fruity Loops). LosslessCut - Cross platform tool for quick and lossless video and audio trimming using ffmpeg. LyricsX - Lyrics for iTunes, Spotify and Vox. Metadatics - Advanced Audio Metadata Editor. Mixxx - The most advanced free DJ software. Movie Catcher - Movie movie and online viewing offline download software, with Baidu cloud to make offline download and online playback. mpv - Free, open-source, and cross-platform media player. MuseScore - Free, open-source music notation software. Natron - Open-source compositing software. Node-graph based. Similar in functionality to Adobe After Effects and Nuke by The Foundry. Perian - (No longer under active development) ~~Let QuickTime play all the common formats of free plug-ins~~. Playback - Experimental video player. Popcorn Time - Watch torrent movies instantly, This Popcorn Time service will never be taken down. Download and enjoy. ScreenFlow - Screencasting and video editing software. Shotcut - Free open-source video editor. Soda Player - Player that can play seed, magnetic links, online video, automatic captions, links and local video files. Sonora - Minimal, beautifully designed music player. SpotMenu - Spotify and iTunes in your menu bar. Stremio - Movies, TV shows, series, live television or web channels like YouTube and Twitch.tv - you can find all this on Stremio. Stringed 2 - Music practice software designed to help users learn how to play their favorite songs. Synfig Studio - Synfig Studio is free, open-source 2D animation software. VLC - Free, open-source, cross-platform multimedia player as well as framework that plays most multimedia files, DVDs, Audio CDs, VCDs and various streaming protocols. VOX Player - High-definition audio player for Mac and iPhone. Music just sounds better! XLD - Tool to decode, convert and play various 'lossless' audio files. MusicPlus - Search, play & download music for free. Recordia - Record audio directly from the menu bar or with a global keyboard shortcut. Omniplayer - Best media player on Mac, support almost all format. Download Management Tools aria2 - Lightweight multi-protocol & multi-source command-line download utility. Downie - Video downloader for macOS with support for YouTube and other 1200 sites. Deluge - Deluge is a lightweight, Free Software, cross-platform BitTorrent client. FOLX - Free download manager for Mac OS X with a true Mac-style interface. Free Download Manager - Powerful, modern download accelerator and organizer for Windows and Mac. (FREE) JDownloader - Free, open-source download management tool with a huge community of developers that makes downloading as easy and fast as it should be. Motrix - Motrix is a full-featured download manager that supports downloading HTTP, FTP, BitTorrent, Magnet, Baidu Net Disk, etc. qBittorrent - A project aims to provide an open-source software alternative to Torrent. Shuttle - Easy Download Manager for any links. Transmission - Fast, easy, free BitTorrent Client. You-Get - Tiny command-line utility to download media contents (videos, audios, images) from the web. youtube-dl - Command-line program to download videos from YouTube.com and other video sites Cloud Storage I recommend using online storage with Mac clients Arq - Cloud storage backup client that supports AWS, GCP, DropBox, and more. Carbonite - Carbonite can protect your Mac from all of the most common forms of data loss. Dropbox - File hosting service that offers cloud storage and file synchronization with collaborative edit features. Mega - Free cloud service, offers 50GB free storage. NextCloud - Actively maintained fork of ownCloud, faster and completely open-source ownCloud - Cloud storage. Seafile - Reliable and High Speed File Sync and Share. Input Methods Kawa - Better input source switcher for OS X. Rocket - Makes typing emoji faster and easier using Slack-style shortcuts. Touch Emoji - emoji picker for MacBook Pro Touch Bar. Type2Phone - Use Your Mac as Keyboard for iPhone, iPad & Apple TV. Browsers Brave - Web browser with an emphasis on privacy and speed. Chrome - Chrome, developed by Google Chromium - Open-source, free web browser project by Google, to provide the source code for Google Chrome. Microsoft Edge Microsoft Edge, based on Chromium, but built by MS Firefox - Meet Firefox Quantum. Fast, free, open-source web browser developed by the Mozilla Foundation. Safari - Native browser for Macs. TorBrowser - Anonymity Online. Protect your privacy. Defend against network surveillance and traffic analysis. Vivaldi - The browser that puts you in control. Translation Tools (Or you could just use the Mac OS built-in dictionary) Grammarly - Refine your english iTranslate - Translate entire website instantly with its built-in browser or with iTranslate Safari extension into over 40 languages. Ludwig - Linguistic search engine that helps you to write better in English. Mate Translate - Translate in Safari and any app on macOS between 103 languages. Encryption Deadbolt - The easiest file encryption tool you'll ever use. macOS-compatible, and open-source so you can trust it. Security Tools BlockBlock - Me: ""Please alert me whenever anything is persistently installed."" BlockBlock: ""You got it"" Dylib Hijack Scanner - Simple utility that will scan your computer for applications that are either susceptible to dylib hijacking or have been hijacked. KextViewer - View all modules on that are loaded in the OS kernel. KnockKnock - See what's persistently installed on your Mac. LinkLiar - Link-Layer MAC spoofing GUI for macOS. LockDown - Open-source tool for El Capitan that audits and remediates security configuration settings. LuLu - is the free macOS firewall that aims to block unauthorized (outgoing) network traffic. MalwareBytes - Malwarebytes crushes the growing threat of Mac malware, so you are protected and your machine keeps running silky smooth. Cybersecurity smart enough for the Mac. OverSight - Monitor mic and webcam, alerting you when the internal mic is activated, or whenever a process accesses the webcam. RansomWhere? - Generic Ransomware Detection. stronghold - Easily configure MacOS security settings from the terminal. TaskExplorer - Explore all processes running on your Mac with TaskExplorer. What's Your Sign? - Adds menu item to Finder.app to display the cryptographic signing information for any file. Proxy and VPN Tools Algo - Personal IPSEC VPN in the cloud. tigerVPN - VPN Client for Mac. Lantern - Free application that delivers fast, reliable and secure access to the open internet. ShadowsocksX-NG - Next generation of ShadowsocksX. ShadowsocksX - Secure socks5 proxy, designed to protect your internet traffic. Shimo - VPN Client for Mac. SpechtLite - Rule-based proxy app for macOS. Surge - Web developer tool and proxy utility for iOS 9. tinc - Secure mesh VPN software. Tunnelbear - Really simple VPN to browse the web privately & securely. Unblock websites around the world with applications for Mac, PC, iOS, Android & Chrome. Tunnelblick - Free, open-source graphic user interface for OpenVPN on OS X. V2rayU - Macos client based on v2ray. Windscribe - Gives 10gb per month free on the spot and gives limited(on free) location control. Connection also takes very less time. ClashX - A rule based proxy For Mac base on Clash. Utilities Clipboard Tools ClipMenu - Clipboard manager for Mac OS X. Clipy - Clipy is a Clipboard extension app for macOS. Based on ClipMenu. CopyQ - Clipboard Manager with Advanced Features. iPaste - Lightweight and efficient clipboard tool. Paste - Smart clipboard history & snippets manager. PasteBot - Powerful clipboard manager. Flycut - Clean and simple clipboard manager for developers. Maccy - Lightweight clipboard manager for macOS. Menu Bar Tools Anvil - Anvil is a beautiful menubar app for managing local websites. Serve up static sites and Rack apps with simple URLs and zero configuration. Bartender - Organize or hide menu bar icons on your Mac. BeardedSpice - Allows you to control web based media players (SoundCloud, YouTube, etc) and some native apps with the media keys on Mac keyboards. BitBar - Place the output from any script or program right in your Mac OS X menu bar. Dato - A better menu bar clock with calendar, events, and time zones. Dozer - Hide MacOS menubar items. Eye Timer - Take Breaks to prevent Eye Strain timer for Mac. Hidden - A ultra-light MacOS utility that helps hide menu bar icons. Hue in the Menu - Philips Hue light management in the menu bar with multi-room support. iGlance - macOS System Monitor for the Status Bar. Itsycal - Tiny calendar for your Mac's menu bar. MeetingBar - Menu bar app for your calendar meetings Streaker - GitHub contribution streak tracking menubar app. Vanilla - Hide menu bar icons on your Mac. Jiffy - Discover and share the best GIFs on GIPHY. Xbar - Put the output from any script or program into your macOS Menu Bar (the BitBar reboot). File Organization Tools BetterZip 3 - Archive tool supports ZIP, TAR, TGZ, TBZ, TXZ (new), 7-ZIP, RAR. eZip - An easy to use, feature-rich archiver for macOS. Supports popular formats such as RAR, ZIP, 7Z, BZ2, GZ etc. Works great with Mojave dark-mode and QuickLook. Fileside - A modern, tiling file manager with unlimited panes. Hazel - Automated file organization for your Mac. Responsibly and beautifully designed. Keka - file archiver for macOS. Compression: 7Z, ZIP, TAR, GZIP, BZIP2, XZ LZIP, DMG, ISO. Extraction: 7Z, ZIP, RAR, TAR, GZIP, BZIP2, XZ, LZIP, DMG, ISO, LZMA, EXE, CAB, WIM, PAX, JAR, APK, APPX, CPGZ, CPIO. muCommander - Lightweight file manager with a dual-pane interface. PDF Archiver - Nice tool for tagging and archiving tasks. The Unarchiver - Unarchive many different kinds of archive files. General Tools AirServer - Most advanced screen mirroring software receiver for Mac, PC and Xbox One. ControlPlane - Manages configuration profiles for your Mac. Determines where you are or what you are doing based on a number of available evidence sources and then automatically reconfigures your Mac based on your preferences. DNS Heaven - Unifies macOS DNS so applications using glibc can resolve DNS with the native stack. Mainly for use with VPNs. HTTrack - Useful tool for downloading a whole website and offline browsing. Lungo - Prevent your Mac from going to sleep. Mac Cache Cleaner - Cache cleaner for Mac MacAssistant - Google Assistant for macOS Manta - Flexible invoicing desktop app with beautiful & customizable templates. Memo - Simple and elegant app. Unlock memos even more quickly using Touch ID. Numi - Beautiful calculator app for Mac. Plash - Make any website your desktop wallpaper. SlowQuitApps - An OS X app that adds a global delay of 1 second to the Cmd-Q shortcut. Torimori Sweeper - MacOS app that lets you declutter your Downloads, one file at a time. Ultra TabSaver - The Open Source Tab Manager for Safari To-Do Lists 2Do - Nice todo app. Day-O 2 - Menu bar clock replacement with built-in calendar. Fantastical - The calendar app you won't be able to live without. Focus - Beautiful pomodoro-based time manager. Microsoft To-Do - Microsoft's successor to Wunderlist. Nozbe - Powerful GTD app for individuals and teams, with support for every Apple device (Mac, iPhone, iPad, Watch). OmniFocus - Nice GTD app, made by OmniGroups. Taskade - Real-time collaborative editor for teams. TaskPaper - Plain text to-do lists. Things - Delightful and easy to use task manager. (Award-winning App) Todoist - Cross-platform todo list app. Tomato 2 - Beautiful and simple Pomodoro timer. TickTick - Simple and effective to-do list and task manager that helps you organize all aspects of life. Productivity 1440 Minutes Left Today - Keep a track of how many minutes you have left until the day is over, right in your menu bar. Alfred - Award-winning app which boosts efficiency with hotkeys, keywords, text expansion and more. Search your Mac and the web, and be more productive with custom actions to control your Mac. BetterTouchTool - Great, feature-packed app that allows you to configure many gestures for your Magic Mouse, Macbook Trackpad, Magic Trackpad and also Mouse Gestures for normal mice. Choosy - UI, URL API and a browser extension set for managing rules where and how to open links. Hammerspoon - Tool for powerful OSX automation with the Lua scripting engine. HapticKey - A simple utility application for MacBook with Touch Bar that triggers a haptic feedback when tapping Touch Bar. HazeOver App that dims your background app windows so you can focus more on your main task! Hungrymark - Useful app to bookmark your files, folders, and webs, quick access your bookmarks through menu bar iCMD - Fuzzy menubar search and vim/easymotion emulation which works globally for every native MacOS app. Karabiner - Powerful and stable keyboard customizer for OS X. Keyboard Maestro - Automate routine actions based on triggers from keyboard, menu, location, added devices, and more. Keytty - App to keep your hands on the keyboard. Move, click, scroll, drag and more with a few strokes. Lazy - Keyboard-driven commands to manage your surroundings directly from your mac. Mos - Simple tool can offer the smooth scrolling and reverse the mouse scrolling direction on your Mac. Mouseless - Master all of the magic keystrokes for your favorite apps & tools. OmniPlan - The best way to visualize, maintain, and simplify your projects. Project Management made easy. Qbserve - Time tracking automation: freelance project tracking, timesheets, invoicing & real-time productivity feedback. RescueTime - Personal analytics service that shows you how you spend your time and provides tools to help you be more productive. SensibleSideButtons Use the side buttons on your mouse to move forward and backward in many apps, like in Windows. nnScreenshots - a super easy way to keep a visual record of your productivity to make it easier to fill out timesheets or just to help you review the day. Built in timesheet editor. skhd - Simple hotkey daemon for macOS. Strategr No-fuss time management app. Stategr helps you maximize your productivity, giving you the quickest and most effective way to time-box your day. Time Out - Easy break reminders, with micro-break and flexible customization if you want it. Timing - Automatic time and productivity tracking for Mac. Helps you stay on track with your work and ensures no billable hours get lost if you are billing hourly. Trello - A collaboration tool that organizes your projects into Kanban boards. Ukelele - Unicode Keyboard Layout Editor. xScope - Powerful set of tools that are ideal for measuring, inspecting & testing on-screen graphics and layouts. Z - Powerful way to navigate easily by typing only a string of directory name in terminal instead of typing exact location of director. Pomodoro Cycle - Pomodoro tracker Window Management AltTab - Open source window switcher with window previews. Amethyst - Tiling window manager. contexts - Provides more power than the native Mac Dock. Especially when you have multiple screens, it can help you switch more quickly. Divvy - Window management at its finest with its amazing Divvy Grid system. Hummingbird - Easily move and resize windows without mouse clicks, from anywhere within a window. IntelliDock - Hides the Dock, Automatically. Magnet - Window manager that keeps your workspace organized. Moom - Allows you to easily move and zoom windows, or to another displayusing either the mouse or the keyboard. Rectangle - Window management app based on Spectacle, written in Swift. ShiftIt - Managing window size and position in OSX. SizeUp - Powerful, keyboard-centric window management. Slate - Window management application similar to Divvy and SizeUp (except better and free!). (Needs config file) Total Spaces - Provides window management much like ubuntu. Creates hotkeys for workspaces which allows you to easily move around. yabai - Tiling window manager for macOS. A rewrite of chunkwm, it provides a more seamless integration with the operating system. Password Management 1Password - Cross-platform password management tool. Authy - Two-factor authentication token manager that backs up and syncs across your devices. Bitwarden - Open source password management tool for Mac OS, iOS and browsers. Buttercup - The Password Manager You Deserve Dashlane - Cloud-based password manager with award-winning design. Enpass - Cross-platform password management tool with cloud integration. Keeweb - Free, cross-platform password manager compatible with KeePass. LastPass - Password management tool for Mac OS and browser. MacPass - Open-source KeePass Mac OS client. SafeInCloud - Cross Platform password management, low cost app! Finder Tools fman - The first dual-pane file manager to integrate features from Sublime Text. ForkLift - The most advanced dual pane file manager and file transfer client for macOS. Path Finder - File management app. QSpace - A clean and efficient Multi-view File Manager. TotalFinder - Chrome-styled Finder substitute. XtraFinder - Adds tabs and cut to Mac Finder. Quality of Life Improvements CheatSheet - Hold the -Key to get a list of all active shortcuts of the current application. It's as simple as that. f.lux - Makes the color of your computer's display adapt to the time of day. Grayscale Mode - An open source macOS app that lets you quickly toggle grayscale filter right from your menu bar or using a keyboard shortcut (G). KeyCastr - Open-source keystroke visualizer. NightOwl - Automatically switch between macOS Mojave's light and dark themes by time of day or with a menu bar or keyboard shortcut. One Switch - Mac menu bar app that adds various switches to the Mac's menu bar. Shifty - A macOS menu bar app that gives you more control over Night Shift. Snap - Launch an app in a snap. Ridiculously easy shortcut management. Shareful - Supercharge the system share menu with copy, save, and open actions. System Related Tools Amphetamine - Override your energy saver settings and keep your Mac awake. AppCleaner - Small application which allows you to thoroughly uninstall unwanted apps. Apple Silicon App Test - Browser-based tool for checking Apple Silicon app compatibility before you buy an M1 Mac. Background Music - Automatically pause your music, set individual apps' volumes and record system audio. Cleaner for Xcode - Helps make your Xcode faster by removing unwanted and deprecated files. coconutBattery - Shows live information about the battery in your Mac. Includes: manufacture date, capacity, cycle count, battery status, temperature, discharging power. Coolant - Menubar app that lets you know when an app is consuming 100% CPU or more than a gigabyte of memory (or any arbitrary limits you choose). DaisyDisk - Gives a great overview of disk usage. Can also make more disk-space available by cleaning up your disk. FruitJuice - Will let you know how long to stay unplugged each day to keep your battery healthy. gfxCardStatus - Unobtrusive menu bar app for OS X that allows MacBook Pro users to see which apps are affecting their battery life by using the more power-hungry graphics. Gray - Pick between the light appearance and the dark appearance on a per-app basis with the click of a button. HandShaker - Mac on the management of Android mobile phone content. HTML5 Player - HTML 5 video player. Keep your Mac from ""burning"". iStat Menus - Advanced Mac system monitor on the menubar. iStats - Command-line tool that allows you to easily grab the CPU temperature, fan speeds and battery information on OSX. Juice - Make your battery information a bit more interesting. KeepingYouAwake - Alternative to Caffeine with better support for dark mode in Mac. Monity - System monitoring widget for OS X. Mounty - Tiny tool to re-mount write-protected NTFS volumes under Mac OS X 10.9+ in read-write mode. NitroShare - Cross-platform network file transfer utility. Noti - Receive Android notifications on your Mac (with Pushbullet). OmniDiskSweeper - Shows you the files on your drive, ordered by size. It can be used to find and remove unused files. OnyX - Multifunction utility to verify disks and files, run cleaning and system maintenance tasks, configure hidden options and more. Paragon NTFS - Read/write access to NTFS in macOS Sierra. Porting Kit - Install Windows Games inside your Mac. Sensei - Sensei is a multi-tool for Mac performance, with features spanning across both hardware and software. SSH Tunnel - Application for managing SSH connections. TG Pro - Temperature monitoring, fan control & hardware diagnostics to help keep your Mac cool and healthy. Tuxera NTFS - Full read-write compatibility with NTFS-formatted drives on a Mac. Overkill - Stop iTunes from opening when you connect your iPhone. Gaming Software OpenEmu - A great video game console emulator, supports many different emulators in a single application. (e.g. Sony PSP, GameBoy, NDS and so on) PPSSPP - A awesome PSP emulator for any OS you can dream of! Remote Login Software AnyDesk - Provides Remote access across multiple machines. Microsoft Remote Desktop - Connect to a remote PC or virtual apps and desktops made available by your admin. RealVNC - The original and best software for remote access across desktop and mobile. RoyalTSX - Royal TSX is an ideal tool for system engineers and other IT professionals who need remote access to system with different protocols. TeamViewer - Proprietary computer software package for remote control, desktop sharing, online meetings, web conferencing and file transfer between computers. Social Networking Chirper - A simple and tiny menu bar app for Buffer/Twitter that helps you tweet your thoughts without opening anything. Flume - A beautiful Instagram experience for your Mac. The free version is good enough if you only want to do the browsing instead of posting. QuickLook Plugins quick-look-plugins - List of useful Quick Look plugins for developers Third Party App Markets If you come across websites offering pirated software or cracks, please post HERE. We love apps, but only authentic ones. :) Setapp - The best apps for Mac in one suite. Package Managers Here are some of the major software download sites, there are a number of OSX Mac software sites Cakebrew - GUI client for Homebrew. Install, check or remove apps, no command-line needed. Homebrew Cask - Command line installation manager which extends Homebrew and brings its elegance, simplicity, and speed to Mac OS applications and large binaries alike. Homebrew - The missing package manager for macOS. MacPorts - Open-source community initiative to design an easy-to-use system for compiling, installing, and upgrading either command-line, X11 or Aqua based open-source software on the Mac OS X operating system. MacUpdate Desktop - Simplifies finding, buying and installing apps for your Mac. Mac App Download Sites Here are some of the major software download sites, there are a number of OSX Mac software sites Genuine Sites alternativeTo - Also a very nice community. If you are looking for some alternative apps FOR Windows or another platform, check this site. Slant - I personally recommend this. This is a platform where you can compare apps side-by-side, you might get an idea by seeing other users recommendations. Please contribute if you find an application from this list! Also, Quora, Reddit, you know the drill. App Shopperhttp://appshopper.com/ MacUpdatehttps://www.macupdate.com/ Other sites like MacStories, LifeHacker, ProductHunt are great resources. Pirated software download site blacklist Refuse piracy from me. Software vendors can go to these places rights. AppKed~~http://www.macbed.com~~ Softasm~~https://softasm.com/~~ Podcasts Mac Power Users - Learn about getting the most from your Apple technology with focused topics and workflow guests. back to top Contributors This project exists thanks to all the people who contribute. Backers Thank you to all our backers! Become a backer Sponsors Support this project by becoming a sponsor. Your logo will show up here with a link to your website. Become a sponsor License This work is licensed under a Creative Commons Attribution 4.0 International License."
2232,"Modern NSURLSession based Networking Framework with built in authentication and HTTP 1.1 caching standards support for iOS 8+ devicesThis is version 2.0 of MKNetworkKit. Version 2 is based on NSURLSession and NSURLConfiguration. Version 1.x of MKNetworkKit is deprecated as NSURLConnection is deprecated in iOS 9 and is not available on tvOS. A Swift version is available here (https://github.com/MugunthKumar/MKNetworkKit-Swift) Why MKNetworkKit? Single network queue for the whole app Auto queue sizing and auto network indicator support High performance background caching (based on HTTP 1.1 caching specs) built in You don't need a separate image cache library Background image decompression Background completion cURL-able debug lines These are just a few of most interesting features on MKNetworkKit. Installation Drag the MKNetworkKit directory to your project. We will be supporting Carthage soon and have a demo app setup, so you can test the features. How to use WIP. Licensing MKNetworkKit is licensed under MIT License Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the ""Software""), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. Attribution free licensing In case you need attribution free licensing for MKNetworkKit, you can buy one from my license store. Documentation Install appledoc from gentlebytes github repo run this on the command line /usr/local/bin/appledoc --project-name MKNetworkKit -v 0.8 --project-company Steinlogic --company-id com.steinlogic.mknetworkkit -o ./Documentation -i .m -s ./MKNetworkKit . AppleDoc License appledoc is licensed with modified BSD license. In plain language: you're allowed to do whatever you wish with the code, modify, redistribute, embed in your products (free or commercial), but you must include copyright, terms of usage and disclaimer as stated in the license, the same way as any other BSD licensed code. You can of course use documentation generated by appledoc for your products (free or commercial), but you must attribute appledoc either in documentation itself or other appropriate place such as your website. If for whatever reason you cannot agree to these terms, contact us through contact form on our about page, we'll do our best to help you out you out and find a workable solution! Copyright (c) 2009-2011, Gentle Bytes All rights reserved. Redistribution and use in source, binary forms and generated documentation, with or without modification, are permitted provided that the following conditions are met: Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer. Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution. Redistributions of documentation generated by appledoc must include attribution to appledoc, either in documentation itself or other appropriate media. Neither the name of the appledoc, Gentle Bytes nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission. THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS"" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE. Gentle Bytes appledoc@gentlebytes.com TODO Operation coaleasing OAuth/client certificate support Add local notification support MKObject data transformers"
4216,"Jupyter Interactive NotebookJupyter Notebook The Jupyter notebook is a web-based notebook environment for interactive computing. Notice Please note that this repository is currently maintained by a skeleton crew of maintainers from the Jupyter community. We encourage users to transition to JupyterLab, where more immediate support can occur. Our approach moving forward will be: To maintain the security of the Jupyter Notebook. That means security-related issues and pull requests are our highest priority. To address JupyterLab feature parity issues. As part of this effort, we are also working on a better notebook-only experience in JupyterLab for users who prefer the UI of the classic Jupyter Notebook. To be responsive to the hard work of community members who have opened pull requests. We are triaging these PRs. We cannot support or maintain new features at this time, but we welcome security and other sustainability fixes. If you have an open pull request with a new feature or if you were planning to open one, please consider shipping it as a notebook extension instead. Alternatives to contributing to notebook Additionally, please consider whether your contribution would be appropriate for either the underlying server for Jupyter front-ends, jupyter_server or in the JupyterLab front-end. Jupyter notebook, the language-agnostic evolution of IPython notebook Jupyter notebook is a language-agnostic HTML notebook application for Project Jupyter. In 2015, Jupyter notebook was released as a part of The Big Split of the IPython codebase. IPython 3 was the last major monolithic release containing both language-agnostic code, such as the IPython notebook, and language specific code, such as the IPython kernel for Python. As computing spans across many languages, Project Jupyter will continue to develop the language-agnostic Jupyter notebook in this repo and with the help of the community develop language specific kernels which are found in their own discrete repos. [The Big Split announcement] [Jupyter Ascending blog post] Installation You can find the installation documentation for the Jupyter platform, on ReadTheDocs. The documentation for advanced usage of Jupyter notebook can be found here. For a local installation, make sure you have pip installed and run: $ pip install notebook Usage - Running Jupyter notebook Running in a local installation Launch with: $ jupyter notebook Running in a remote installation You need some configuration before starting Jupyter notebook remotely. See Running a notebook server. Development Installation See CONTRIBUTING.rst for how to set up a local development installation. Contributing If you are interested in contributing to the project, see CONTRIBUTING.rst. Resources Project Jupyter website Online Demo at jupyter.org/try Documentation for Jupyter notebook [PDF] Korean Version of Installation Documentation for Project Jupyter [PDF] Issues Technical support - Jupyter Google Group"
2414,"Cinder is a community-developed, free and open source library for professional-quality creative coding in C++.Cinder 0.9.3dev: libcinder.org Cinder is a peer-reviewed, free, open source C++ library for creative coding. Please note that Cinder depends on a few submodules. The simplest way to clone it is: You might also prefer one of our pre-packaged downloads. Cinder guides and reference documentation are available on the website. Cinder supports macOS, Windows, Linux, and iOS. It requires Xcode 11.3.1 or later for development on the Mac, and Visual C++ 2019 or later on Windows. Cinder is released under the Modified BSD License. Please visit our website for more information. Also be sure to check out the User Forum."
676,"Clojure to JS compilerWhat is ClojureScript? ClojureScript is a compiler for Clojure that targets JavaScript. It is designed to emit JavaScript code which is compatible with the advanced compilation mode of the Google Closure optimizing compiler. Official web site: http://clojurescript.org Releases and dependency information Latest stable release: 1.10.844 All released versions Leiningen dependency information: Maven dependency information: Getting Started Read the Quick Start guide. Read the Documentation. Try a tutorial. Companies using ClojureScript Questions, Feedback? Please point all of your questions and feedback to the Clojure mailing list. There is a community run ClojureScript user mailing list and the IRC channel, #clojurescript on freenode.net, is quite active. There is also a community run Slack channel. The Jira bug/feature tracking application is located at http://dev.clojure.org/jira/browse/CLJS. Before submitting issues please read the Reporting Issues page first. Developers Welcome ClojureScript operates under the same license as Clojure. All contributors must have a signed CA (Contributor's Agreement) and submit their patch via the appropriate channels. If you're interested in contributing to the project, please see the contributing page on clojure.org. For more information about working on the compiler and testing check the Developer section of the wiki. YourKit YourKit has given an open source license for their profiler, greatly simplifying the profiling of ClojureScript performance. YourKit supports open source projects with its full-featured Java Profiler. YourKit, LLC is the creator of YourKit Java Profiler and YourKit .NET Profiler, innovative and intelligent tools for profiling Java and .NET applications. License Copyright (c) Rich Hickey. All rights reserved. The use and distribution terms for this software are covered by the Eclipse Public License 1.0 (http://opensource.org/licenses/eclipse-1.0.php) which can be found in the file epl-v10.html at the root of this distribution. By using this software in any fashion, you are agreeing to be bound by the terms of this license. You must not remove this notice, or any other, from this software."
1281,"An Android staggered grid view which supports multiple columns with rows of varying sizes.AndroidStaggeredGrid Notice - Deprecated - 09-2015 This library has been deprecated. We will no longer be shipping any updates or approving community pull requests for this project. While the code will remain for anyone who wishes to use it, we suggest you prefer using Google's own RecyclerView with their StaggeredGridLayoutManager. We are doing the same internally at Etsy. Thanks to everyone who used the library and submitted code or issues to improve it. About An Android staggered grid view which supports multiple columns with rows of varying sizes. The StaggeredGridView was developed due to requirements for the Etsy app not met by any existing Android libraries. Namely a stable implementation with the ability to have a different number of columns in landscape & portrait, to sync grid position across orientation changes and support for headers & footers. Features Configurable column count for portrait and landscape orientations. Sync'd row position across orientation changes. Configurable item margin. Support for headers & footers. Internal padding that does not affect the header & footer. Extends AbsListView - ""mostly"" Supports AbsListView.OnScrollListener Setup The library was built for and tested on Android version 2.3.3(SDK 10) and above. It could be modified to support older versions if required. The simplest way to use AndroidStaggeredGrid is to add the library as a gradle aar dependency to your build. See the CHANGELOG.md for the latest version number. Alternatively import the /library project into your Android Studio project and add it as a dependency in your build.gradle. The library is currently configured to be built via Gradle only. It has the following dependencies: Android Gradle plugin v0.9.2 - com.android.tools.build:gradle:0.9.2 Android Support Library v19.1 - com.android.support:support-v4:19.1.+ Still use Eclipse/building with Ant? You can still use AndroidStaggeredGrid, it's just a few extra steps (left up to the reader). Usage Please see the /sample app for a more detailed code example of how to use the library. Add the StaggeredGridView to the layout you want to show. Configure attributes. item_margin - The margin around each grid item (default 0dp). column_count - The number of columns displayed. Will override column_count_portrait and column_count_landscape if present (default 0) column_count_portrait - The number of columns displayed when the grid is in portrait (default 2). column_count_landscape - The number of columns displayed when the grid is in landscape (default 3). grid_paddingLeft - Padding to the left of the grid. Does not apply to headers and footers (default 0). grid_paddingRight - Padding to the right of the grid. Does not apply to headers and footers (default 0). grid_paddingTop - Padding to the top of the grid. Does not apply to headers and footers (default 0). grid_paddingBottom - Padding to the bottom of the grid. Does not apply to headers and footers (default 0). Setup an adapter just like you would with a GridView/ListView. NOTE: As column widths change on orientation change, the grid view expects that all children maintain their own width to height ratio. To assist with this the project includes the DynamicHeightImageView as an example of a view that measures its height based on its width. TODO The StaggeredGridView does not support the following: Item selector drawables Item long press event Scroll bars Row dividers Edge effect Fading edge Overscroll License Copyright (c) 2013 Etsy Licensed under the Apache License, Version 2.0 (the ""License""); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
3479,"Drop in sharing features for all iPhone and iPad appsImportant: The easiest way by far to share content from iOS app is to use UIActivityViewControler. If this is not enough for you, than ShareKit might be useful. Beware though - ShareKit is rather dated, although kept updated as time permits. Some services might have changed their API's or deprecated their SDK's in the meantime. It is a lot of work to keep ShareKit updated, and urgent help is needed, so you are more than welcome to test, add issues or open pull requests. ShareKit allows you to share content easily: Everything else (user authentication, API calls, shareUI etc) is handled by ShareKit. Moreover, you can use and customise SHKAccountsViewController (where users can login/logoff, displays username if someone is logged to a particular service) and SHKUploadsViewController (similar to safari downloads, works with sharers able to report progress). For a brief introduction, check the demo app. To know more about configuration options see DefaultSHKConfigurator.m. To know more about what type of content can be shared, see SHKItem.h. To find out what services and actions are supported, check Sharer implementations. To get a picture of what they are capable of check their .m (implementation) files, methods named: should tell you everything you need. Documentation The latest documentation and installation instructions can be found on the ShareKit Wiki. To get a preview of new features see Changelog. !!! Updated new service creation guidelines for contributors + updated service templates are here !!! ShareKit 2 In order to make it easier for new users to choose a canonical fork of ShareKit, the ShareKit community has decided to band together and take responsibility for collecting useful commits into what we're calling ""ShareKit 2"". It is now ready for you. It is the first officially stable version of ShareKit since February 2010, with more frequent updates expected. Highlights: many new sharers new UI (currently used by Facebook, Plurk and LinkedIn, more to follow) iOS native social.framework based sharers optimised for easy updating (subproject library + 3rd party code as git submodules) uses ARC and block callbacks You can follow the initial planning at https://github.com/ideashower/ShareKit/issues/283. As ShareKit is now community driven, you are welcome to help, to judge new features, review pull requests etc.. There are many ways you can help, see FAQ Credits ShareKit was created by Nate Weiner, is updated by contributors and is maintained by Vilm Kurz."
1222,"Simulating shitty network connections so you can build better systems.Comcast Testing distributed systems under hard failures like network partitions and instance termination is critical, but it's also important we test them under less catastrophic conditions because this is what they most often experience. Comcast is a tool designed to simulate common network problems like latency, bandwidth restrictions, and dropped/reordered/corrupted packets. It works by wrapping up some system tools in a portable(ish) way. On BSD-derived systems such as OSX, we use tools like ipfw and pfctl to inject failure. On Linux, we use iptables and tc. Comcast is merely a thin wrapper around these controls. Windows support may be possible with wipfw or even the native network stack, but this has not yet been implemented in Comcast and may be at a later date. Installation Usage On Linux, Comcast supports several options: device, latency, target/default bandwidth, packet loss, protocol, and port number. On OSX, Comcast will check for pfctl support (as of Yosemite), which supports the same options as above. If pfctl is not available, it will use ipfw instead, which supports device, latency, target bandwidth, and packet-loss options. On BSD (with ipfw), Comcast currently supports only: device, latency, target bandwidth, and packet loss. This will add 250ms of latency, limit bandwidth to 1Mbps, and drop 10% of packets to the targetted (on Linux) destination addresses using the specified protocols on the specified port numbers (slow lane). The default bandwidth specified will apply to all egress traffic (fast lane). To turn this off, run the following: By default, comcast will determine the system commands to execute, log them to stdout, and execute them. The --dry-run flag will skip execution. I don't trust you, this code sucks, I hate Go, etc. If you don't like running code that executes shell commands for you (despite it being open source, so you can read it and change the code) or want finer-grained control, you can run them directly instead. Read the man pages on these things for more details. Linux On Linux, you can use iptables to drop incoming and outgoing packets. Alternatively, you can use tc which supports some additional options. To reset: BSD/OSX To shape traffic in BSD-derived systems, create an ipfw pipe and configure it. You can control incoming and outgoing traffic separately for any specific host or network. To reset: Note: ipfw was removed in OSX Yosemite in favor of pfctl. Network Condition Profiles Here's a list of network conditions with values that you can plug into Comcast. Please add any more that you may come across. Name | Latency | Bandwidth | Packet-loss :-- | --: | --: | --: GPRS (good) | 500 | 50 | 2 EDGE (good) | 300 | 250 | 1.5 3G/HSDPA (good) | 250 | 750 | 1.5 DIAL-UP (good) | 185 | 40 | 2 DSL (poor) | 70 | 2000 | 2 DSL (good) | 40 | 8000 | 0.5 WIFI (good) | 40 | 30000 | 0.2 Satellite | 1500 | - | 0.2"
2749,"A charting tool that produces automatic, shareable charts from any data fileCharted Charted is a tool for automatically visualizing data, originally created by the Product Science team at Medium. Provide the link to a data file and Charted returns a beautiful, interactive, and shareable chart of the data. The charts look like this: Charted is deliberately sparse in formatting and data transformation options, and instead gives you a few powerful core features: * Rendering well on all screen sizes, including monitors * Re-fetching the data and updating the chart every 30 minutes * Moving data series into separate charts * Adjusting the chart type, labels/titles, and background Supported files Charted currently supports the following file types: * .csv files * .tsv files * Google Spreadsheets (set to shareable) * Dropbox share links to supported files Data structure Charted treats the first column of the data file as the labels for the x-axis. All subsequent columns are added as y-series. Charted does not parse the first column (x-axis), but instead always equally spaces the data points along the x-axis. Running Charted To try Charted out, simply download the repo and run npm install to install dependencies. After that you will be able to run npm start. This will start a server at localhost:3000."
3674,"Convenient & secure logging during development & release in Swift 3, 4 & 5Colorful, flexible, lightweight logging for Swift 3, Swift 4 & Swift 5.Great for development & release with support for Console, File & cloud platforms.Log during release to the conveniently built-in SwiftyBeaver Platform, the dedicated Mac App & Elasticsearch!Docs | Website | Twitter | Privacy | License ---- ### During Development: Colored Logging to Xcode Console [Learn more](http://docs.swiftybeaver.com/article/9-log-to-xcode-console) about colored logging to Xcode 8 Console with Swift 3, 4 & 5. For Swift 2.3 [use this Gist](https://gist.github.com/skreutzberger/7c396573796473ed1be2c6d15cafed34). **No need to hack Xcode 8 anymore** to get color. You can even customize the log level word (ATTENTION instead of ERROR maybe?), the general amount of displayed data and if you want to use the s or replace them with something else ### During Development: Colored Logging to File [Learn more](http://docs.swiftybeaver.com/article/10-log-to-file) about logging to file which is great for Terminal.app fans or to store logs on disk. ### On Release: Encrypted Logging to SwiftyBeaver Platform [Learn more](http://docs.swiftybeaver.com/article/11-log-to-swiftybeaver-platform) about logging to the SwiftyBeaver Platform **during release!** ### Browse, Search & Filter via Mac App ![swiftybeaver-demo1](https://cloud.githubusercontent.com/assets/564725/14846071/218c0646-0c62-11e6-92cb-e6e963b68724.gif) Conveniently access your logs during development & release with our [free Mac App](https://swiftybeaver.com). ### On Release: Enterprise-ready Logging to Your Private and Public Cloud [Learn more](https://swiftybeaver.com/enterprise.html) about **legally compliant**, end-to-end encrypted logging your own cloud with **SwiftyBeaver Enterprise**. Install via Docker or manual, fully-featured free trial included! ### Google Cloud & More You can fully customize your log format, turn it into JSON, or create your own destinations. For example our [Google Cloud Destination](https://github.com/SwiftyBeaver/SwiftyBeaver/blob/master/Sources/GoogleCloudDestination.swift) is just another customized logging format which adds the powerful functionality of automatic server-side Swift logging when hosted on Google Cloud Platform. ---- ## Installation - For **Swift 4 & 5** install the latest SwiftyBeaver version - For **Swift 3** install SwiftyBeaver 1.8.4 - For **Swift 2** install SwiftyBeaver 0.7.0 ### Carthage You can use [Carthage](https://github.com/Carthage/Carthage) to install SwiftyBeaver by adding that to your Cartfile: Swift 4 & 5: Swift 3: Swift 2: ### Swift Package Manager For [Swift Package Manager](https://swift.org/package-manager/) add the following package to your Package.swift file. Just Swift 4 & 5 are supported: ### CocoaPods To use [CocoaPods](https://cocoapods.org) just add this to your Podfile: Swift 4 & 5: Swift 3: Swift 2: ## Usage Add that near the top of your `AppDelegate.swift` to be able to use SwiftyBeaver in your whole project. At the the beginning of your `AppDelegate:didFinishLaunchingWithOptions()` add the SwiftyBeaver log destinations (console, file, etc.), optionally adjust the [log format](http://docs.swiftybeaver.com/article/20-custom-format) and then you can already do the following log level calls globally: ## Server-side Swift We server-side Swift 4 & 5 and SwiftyBeaver supports it **out-of-the-box**! Try for yourself and run SwiftyBeaver inside a Ubuntu Docker container. Just install Docker and then go to your the project folder on macOS or Ubuntu and type: Best: for the popular server-side Swift web framework [Vapor](https://github.com/vapor/vapor) you can use **[our Vapor logging provider](https://github.com/SwiftyBeaver/SwiftyBeaver-Vapor)** which makes server logging awesome again ## Documentation **Getting Started:** - [Features](http://docs.swiftybeaver.com/article/7-introduction) - [Installation](http://docs.swiftybeaver.com/article/5-installation) - [Basic Setup](http://docs.swiftybeaver.com/article/6-basic-setup) **Logging Destinations:** - [Colored Logging to Xcode Console](http://docs.swiftybeaver.com/article/9-log-to-xcode-console) - [Colored Logging to File](http://docs.swiftybeaver.com/article/10-log-to-file) - [Encrypted Logging & Analytics to SwiftyBeaver Platform](http://docs.swiftybeaver.com/article/11-log-to-swiftybeaver-platform) - [Encrypted Logging & Analytics to Elasticsearch & Kibana](http://docs.swiftybeaver.com/article/34-enterprise-quick-start-via-docker) **Advanced Topics:** - [Custom Format & Context](http://docs.swiftybeaver.com/article/20-custom-format) - [Filters](http://docs.swiftybeaver.com/article/21-filters) **Stay Informed:** - [Official Website](https://swiftybeaver.com) - [On Twitter](https://twitter.com/SwiftyBeaver) ## Privacy **SwiftyBeaver is not collecting any data without you as a developer knowing about it**. That's why it is **open-source** and developed in a simple way to be easy to inspect and check what it is actually doing under the hood. The only sending to servers is done if you use the `SBPlatformDestination`. That destination is meant for production logging and on default it sends your logs plus additional device information **end-to-end encrypted** to our cloud service. Our cloud service **can not decrypt the data**. Instead, you install our Mac App and that Mac App downloads the encrypted logs from the cloud and decrypts and shows them to you. Additionally, the Mac App stores all data that it downloads in a local SQLite database file on your computer so that you actually ""physically"" own your data. The business model of the SwiftyBeaver cloud service is to provide the most secure logging solution in the market. On purpose we do not provide a web UI for you because it would require us to store your encryption key on our servers. **Only you can see the logging and device data** which is sent from your users' devices. Our servers just see encrypted data and do not know your decryption key. SwiftyBeaver is **fully GDPR compliant** due to its focus on encryption and transparency in what data is collected and also meets **Apples latest requirements** on the privacy of 3rd party frameworks. Our Enterprise offering is an even more secure solution where you are not using anymore our cloud service and Mac App but you send your end-to-end encrypted logs directly to your own servers and you store them in your Elasticsearch cluster. The **Enterprise offering is used by health tech** and governmental institutions which require the highest level of privacy and security. ## End-to-End Encryption SwiftyBeaver is using symmetric AES256CBC encryption in the `SBPlatformDestination` destination. No other officially supported destination uses encryption. The encryption used in the `SBPlatformDestination` destination is end-to-end. The open-source SwiftyBeaver logging framework symmetrically encrypts all logging data on your client's device inside your app (iPhone, iPad, ...) before it is sent to the SwiftyBeaver Crypto Cloud. The decryption is done on your Mac which has the SwiftyBeaver Mac App installed. All logging data stays encrypted in the SwiftyBeaver Crypto Cloud due to the lack of the password. You are using the encryption at your own risk. SwiftyBeavers authors and contributors do not take over any guarantee about the absence of potential security or cryptopgraphy issues, weaknesses, etc.; please also read the LICENSE file for details. Also if you are interested in cryptography in general, please have a look at the file AES256CBC.swift to learn more about the cryptographical implementation. ## License SwiftyBeaver Framework is released under the [MIT License](https://github.com/SwiftyBeaver/SwiftyBeaver/blob/master/LICENSE)."
3142,ThinkPHP3.2 PHP5PHP3.25.05.1 ThinkPHP PHP 2006Apache2WEBThinkPHPWEB WEB ThinkPHPWEB MVC-MVC ORM-ORM -XML RESTFul-RESTRESTFulURL -SAEBAE CLI- RPC-PHPRpcHProsejsonRPCYar MongoDb-NoSQL -MemcacheXcacheRedis ThinkPHPPHP XSS SQL ThinkPHPApache2Apache LicenceApacheBSD
69,"Ansible is a radically simple IT automation platform that makes your applications and systems easier to deploy and maintain. Automate everything from code deployment to network configuration to cloud management, in a language that approaches plain English, using SSH, with no agents to install on remote systems. https://docs.ansible.com.|PyPI version| |Docs badge| |Chat badge| |Build Status| |Code Of Conduct| |Mailing Lists| |License| |CII Best Practices| Ansible Ansible is a radically simple IT automation system. It handles configuration management, application deployment, cloud provisioning, ad-hoc task execution, network automation, and multi-node orchestration. Ansible makes complex changes like zero-downtime rolling updates with load balancers easy. More information on the Ansible website <https://ansible.com/>_. Design Principles Have a dead-simple setup process with a minimal learning curve. Manage machines very quickly and in parallel. Avoid custom-agents and additional open ports, be agentless by leveraging the existing SSH daemon. Describe infrastructure in a language that is both machine and human friendly. Focus on security and easy auditability/review/rewriting of content. Manage new remote machines instantly, without bootstrapping any software. Allow module development in any dynamic language, not just Python. Be usable as non-root. Be the easiest IT automation system to use, ever. Use Ansible You can install a released version of Ansible with pip or a package manager. See our installation guide <https://docs.ansible.com/ansible/latest/installation_guide/intro_installation.html>_ for details on installing Ansible on a variety of platforms. Red Hat offers supported builds of Ansible Engine <https://www.ansible.com/ansible-engine>_. Power users and developers can run the devel branch, which has the latest features and fixes, directly. Although it is reasonably stable, you are more likely to encounter breaking changes when running the devel branch. We recommend getting involved in the Ansible community if you want to run the devel branch. Get Involved Read Community Information <https://docs.ansible.com/ansible/latest/community>_ for all kinds of ways to contribute to and interact with the project, including mailing list information and how to submit bug reports and code to Ansible. Join a Working Group <https://github.com/ansible/community/wiki>_, an organized community devoted to a specific technology domain or platform. Submit a proposed code update through a pull request to the devel branch. Talk to us before making larger changes to avoid duplicate efforts. This not only helps everyone know what is going on, but it also helps save time and effort if we decide some changes are needed. For a list of email lists, IRC channels and Working Groups, see the Communication page <https://docs.ansible.com/ansible/latest/community/communication.html>_ Coding Guidelines We document our Coding Guidelines in the Developer Guide <https://docs.ansible.com/ansible/devel/dev_guide/>_. We particularly suggest you review: Contributing your module to Ansible <https://docs.ansible.com/ansible/devel/dev_guide/developing_modules_checklist.html>_ Conventions, tips, and pitfalls <https://docs.ansible.com/ansible/devel/dev_guide/developing_modules_best_practices.html>_ Branch Info The devel branch corresponds to the release actively under development. The stable-2.X branches correspond to stable releases. Create a branch based on devel and set up a dev environment <https://docs.ansible.com/ansible/latest/dev_guide/developing_modules_general.html#common-environment-setup>_ if you want to open a PR. See the Ansible release and maintenance <https://docs.ansible.com/ansible/devel/reference_appendices/release_and_maintenance.html>_ page for information about active branches. Roadmap Based on team and community feedback, an initial roadmap will be published for a major or minor version (ex: 2.7, 2.8). The Ansible Roadmap page <https://docs.ansible.com/ansible/devel/roadmap/>_ details what is planned and how to influence the roadmap. Authors Ansible was created by Michael DeHaan <https://github.com/mpdehaan>_ and has contributions from over 5000 users (and growing). Thanks everyone! Ansible <https://www.ansible.com> is sponsored by Red Hat, Inc. <https://www.redhat.com> License GNU General Public License v3.0 or later See COPYING <COPYING>_ to see the full text. .. |PyPI version| image:: https://img.shields.io/pypi/v/ansible-core.svg :target: https://pypi.org/project/ansible-core .. |Docs badge| image:: https://img.shields.io/badge/docs-latest-brightgreen.svg :target: https://docs.ansible.com/ansible/latest/ .. |Build Status| image:: https://dev.azure.com/ansible/ansible/_apis/build/status/CI?branchName=devel :target: https://dev.azure.com/ansible/ansible/_build/latest?definitionId=20&branchName=devel .. |Chat badge| image:: https://img.shields.io/badge/chat-IRC-brightgreen.svg :target: https://docs.ansible.com/ansible/latest/community/communication.html .. |Code Of Conduct| image:: https://img.shields.io/badge/code%20of%20conduct-Ansible-silver.svg :target: https://docs.ansible.com/ansible/latest/community/code_of_conduct.html :alt: Ansible Code of Conduct .. |Mailing Lists| image:: https://img.shields.io/badge/mailing%20lists-Ansible-orange.svg :target: https://docs.ansible.com/ansible/latest/community/communication.html#mailing-list-information :alt: Ansible mailing lists .. |License| image:: https://img.shields.io/badge/license-GPL%20v3.0-brightgreen.svg :target: COPYING :alt: Repository License .. |CII Best Practices| image:: https://bestpractices.coreinfrastructure.org/projects/2372/badge :target: https://bestpractices.coreinfrastructure.org/projects/2372 :alt: Ansible CII Best Practices certification"
3163,"Free, responsive, multiple skin admin templateCharisma Free, premium quality, responsive, multiple skin admin template. Live Demo Download Features 9 different themes. Fully responsive, optimized UI for tablets and mobile phones, see how it looks on different devices. Based on Bootstrap. Works on IE9+ Commented code. Custom product tour, see example. Grid system, see example. Charts, including, pie, stack, flot, realtime etc. Data tables Widget boxes, collapsible, closable, see example. Photo gallery see example. Ajaxified menus Full calendar, monthly weekly, daily, with todo list. Custom error page Auto active link detection and much more. Credits Without these open source software Charisma woudn't have been possible: Twitter Bootstrap jQuery Bootswatch Chosen Flot Charts Full Calendar Datatables Colorbox Noty Raty iPhone-style Checkboxes Autogrowing Textarea Animate.css Uploadify Please visit http://usman.it/free-responsive-admin-template/ for more information. 2012 - 2017 Muhammad Usman. Licensed under the Apache License, Version 2.0."
4284,"The Baidu File System.The Baidu File System The Baidu File System (BFS) is a distributed file system designed to support real-time applications. Like many other distributed file systems, BFS is highly fault-tolerant. But different from others, BFS provides low read/write latency while maintaining high throughput rates. Together with Galaxy and Tera, BFS supports many real-time products in Baidu, including Baidu webpage database, Baidu incremental indexing system, Baidu user behavior analysis system, etc. Features Continuous availability Nameserver is implemented as a raft group, no single point failure. High throughput High performance data engine to maximize IO utils. Low latency Global load balance and slow node detection. Linear scalability Support multi data center deployment and up to 10,000 data nodes. Architecture Quick Start Build ./build.sh Standalone BFS cd sandbox ./deploy.sh ./start_bfs.sh How to Contribute Please read the RoadMap or source code. Find something you are interested in and start working on it. Test your code by simply running make test and make check. Make a pull request. Once your code has passed the code-review and merged, it will be run on thousands of servers :) Contact us opensearch@baidu.com ==== HDFS Raft IO 1+ ./build.sh BFS cd sandbox ./deploy.sh ./start_bfs.sh RoadMap make testmake checkcase pull request code-review~ opensearch@baidu.com QQ188471131"
3564,"Custom animation transition for present modal view controllerZFDragableModalTransition Usage ScrollView If you have scrollview in the modal and you want to dismiss modal by drag it, you need to set scrollview to ZFModalTransitionAnimator instance. Direction You can set that which direction will our modal present. (default is ZFModalTransitonDirectionBottom) P.S. Now you can set content scrollview only with ZFModalTransitonDirectionBottom Requirements iOS >= 7.1 ARC Installation ZFDragableModalTransition is available through CocoaPods. To install it, simply add the following line to your Podfile: pod ""ZFDragableModalTransition"" FAQ How can I show modal only part of view ? The current ViewController's view still visible behind the modal, so you just set transparent color to background view. Author Amornchai Kanokpullwad, @zoonref Swift Version by @dimohamdy ZFDragableModalTransitionSwift License ZFDragableModalTransition is available under the MIT license. See the LICENSE file for more info."
1420,"Finally, a ""back to top"" button that behaves like a real elevator.elevator.js Finally, a ""back to top"" button that behaves like a real elevator, by adding elevator music to quietly soothe the awkwardness that can ensue when being smoothly scrolled to the top of the screen. This is very serious stuff, here's a demo! Instructions Elevator.js is a stand alone library (no jquery, or the likes) so usage is pretty straight forward. All styling of elements is up to you. Elevator.js only handles the audio management, and the scroll functionality! JS Elevator.js lives entirely within the js realm, which makes things fairly simple to use. You'll need to create a new instance of Elevator, and pass it some audio elements. You can also add an ""element"" option, clicking this element will invoke the ""Scroll to top"" functionality, we all love and crave. If you don't want to scroll to the top, a custom target can be specified by adding a ""targetElement"" option: If you want to scroll to a point on the page with some extra padding on the top, simply add the ""verticalPadding"" option: If you're really serious (boring), you don't have to use audio... and can also set a fixed time to scroll to the top If you use elevator.js in combination with other code, you might want to use callbacks NPM The package is also available via NPM License Elevator.js is covered by the MIT License. Audio in the Demo was bought via Pond5, you will need to license your own. Copyright (C) ~ Tim Holman ~ timothy.w.holman@gmail.com"
2986,"yargs the modern, pirate-themed successor to optimist. Yargs Yargs be a node.js library fer hearties tryin' ter parse optstrings Description Yargs helps you build interactive command line tools, by parsing arguments and generating an elegant user interface. It gives you: commands and (grouped) options (my-program.js serve --port=5000). a dynamically generated help menu based on your arguments: bash-completion shortcuts for commands and options. and tons more. Installation Stable version: Bleeding edge version with the most recent features: Usage Simple Example Note: hideBin is a shorthand for process.argv.slice(2). It has the benefit that it takes into account variations in some environments, e.g., Electron. Complex Example Run the example above with --help to see the help for the application. Supported Platforms TypeScript yargs has type definitions at @types/yargs. See usage examples in docs. Deno As of v16, yargs supports Deno: ESM As of v16,yargs supports ESM imports: Usage in Browser See examples of using yargs in the browser in docs. Community Having problems? want to contribute? join our community slack. Documentation Table of Contents Yargs' API Examples Parsing Tricks Stop the Parser Negating Boolean Arguments Numbers Arrays Objects Quotes Advanced Topics Composing Your App Using Commands Building Configurable CLI Apps Customizing Yargs' Parser Bundling yargs Contributing Supported Node.js Versions Libraries in this ecosystem make a best effort to track Node.js' release schedule. Here's a post on why we think this is important."
1717,"An IM App like WeChat App has to send text, pictures, audio, video, location messaging, managing local address book, share a circle of friends, drifting friends, shake a fun and more interesting features. MessageDisplayKit AppIM An IM APP like WeChat which has sending text, pictures, audio, video, location messaging, managing local address book, share moments with friends, drift bottle, shake for new friends and some other interesting features. githubissueissuegithub , Most of code has comments with which I believe you can understand them. If you can't understand the code please feel free to open an issue (https://github.com/xhzengAIB/MessageDisplayKit/issues?state=open) I will do my best to answer them. LeanCloundLC Requirements iPhone4/5/6/6+/iPadPortrait Xcode6 or later iOS 6.0+ ARC System Frameworks : 'Foundation', 'CoreGraphics', 'UIKit', 'MobileCoreServices', 'AVFoundation', 'CoreLocation', 'MediaPlayer', 'CoreMedia', 'CoreText', 'AudioToolbox'. Podfile CocoaPods is the recommended method to install MessageDisplayKit, just add the following line to Podfile and run pod install, then you're all done! TODO Delete drawRect code, because of lead to lower FPS. Convert audio format. Build server Features 1 Highly customizable. 2 Arbitrary message sizes. 3& Able to copy & paste messages. 4() Data detectors (recognizes phone numbers, links, dates, etc.). 5 Timestamps. 6 Avatars. 7 Swipe down to hide keyboard. 8 Dynamically resize input text view as you type. 9/() Automatically enable/disable send button according to the content of text view. 10/ Send/Receive sound effects. 11 Send voice messages. 12 Send photos. 13 Send videos. 14 Send geolocations. 15gif Send third party gif message. 16iPhoneiPad Support both iPhone and iPad. 17StoryBorad Support the StoryBorad to user. 18cell Support pull down load more old message, keep visible cells static when inserting old message at top. 19 20 21 22 23 24 25 26 27Menu 28 29 30 Core Network Layer. 31 Core Cache Layer. 32 Core Model Layer. 33TableView Majorization tableView performance. 34gif Keep FPS due wih gif play. How to use Easy to drop into your project. * 1#import ""XHMessageTableViewController.h"" 2Your must be subClass XHMessageTableViewController. 3implementation XHMessageTableViewController delegate due with message send. 4implementation XHMessageTableViewController DataSource due with message source. 5If you went to emotion message / plug function / audio play, must be implementation other delegate or dataSource. Detail look this demo. License : MessageDisplayKit MITLICENSE English: MessageDisplayKit is available under the MIT license, see the LICENSE file for more information. Notes appAppApp If you use this open source components in your project, please Email us to notify us the name of your application(s). Thanks! What app use this open source App leanchat-iosLeanCloud -APPapp PathCover XHImageViewer XHRefreshControlUI molonMLMultiSelectViewController Thanks you lakesoft provide LKBadgeView. Thanks you kishikawakatsumi provide SECoreTextView. Thanks Developer AppAevitgithubApp App LicenseNotes Credits Thanks to jessesquires who created JSMessagesViewController on which my chat list UI work is based."
2499,"Material Design style and animations for IonicThis project / repository is retired This project will not have updates for AngularJS/Ionic 1. Please contact the author (zachfitz) if you have ability and interest in resurrecting it, or (preferrably) porting it to Ionic 2/Angular. Ionic Material Ionic Framework Material Design NB: all versions pre-1.0 are intended as a work in progress 'Alpha' See our releases and other versions Demo and Documentation Codepen Codepen by @raibutera Documentation Documentation Application by @zachsoft @ ionicmaterial.com (Use the menu for Documentation sections) Ionic Material on Readme.io (REALLY WIP) NB: Note: It is recommended that when creating an issue, you demonstrate the problem by forking the codepen. Quick Start Step 1: Install using Bower Step 2: Add RobotoDraft font (by Google) Via CDN: via Bower Check out RobotoDraft by RaiButera on Github using Sass? instructions for raibutera/robotodraft + scss: NB: the above assumes you are using Bower Step 3: Add Ionic Material stylesheets and scripts Add ionic.material.min.css and ionic.material.min.js to your index.html Step 4: Inject Ionic & Ionic Material into your Ionic App Step 5: Where appropriate, inject ionicMaterialInk and/or ionicMaterialMotion The angular services ionicMaterialInk and ionicMaterialMotion are used to activate animations. You are all set to go! :thumbsup: Activating Animations NB: Make sure the relevant services are injected into your controllers. In your controllers: - ionicMaterialInk.displayEffect() (will need to happen once on controller activation and then repeat every time the objects update) - ionicMaterialMotion.ripple() (etc.) Sample App Ionic demo app ""Thronester"" is found within './demo' - You can also run 'index.html' locally to view in a webkit browser on a computer. Builds Instructions: - npm install - gulp build (or gulp style for just the stylesheets) Look at gulpfile.js for how the process works. Development This project uses Webpack Contributing See our CONTRIBUTING INSTRUCTIONS Website http://ionicmaterial.com/ FAQ What is Ionic Material? Ionic material is aimed at being an extension library for the Ionic Framework, meaning you won't change the way you develop your Ionic hybrid apps to have them materialized. Ionic Material aims to integrate the best representations of Material Design into a single add-on library for Ionic Developers. With the Polymer Project, ngMaterial, and other open source projects arising, we aim to be actively engaged and aligned with these, and other, related projects. As a 100% free open-source project, developer participation is encouraged, as much or little as possible. Can I use Ionic and Angular Material together? Ionic and Angular Material are fairly incompatible (you can add them to the same project, but the styling will be extremely inconsistent and none of the UI components will work cross-framework, eg. an ionic side menu with material tabs). Ionic is 1.0 and angular material is still pre-1.0. Ionic Material is best explained as a ""material extension"" to Ionic, rather than to Angular as a whole. The difference isn't just semantics - Ionic Material extends the actual ionic framework namespace (in JS), renders material styles on the ionic elements (following ionic's conventions), and will aim to follow the releases of Ionic, and support material theming, ink, and motion for any new Ionic release. Ionic Material will pull in the best ideas of Angular Material, Paper/Polymer, etc. and by the same tune, Ionic Material will also abstract the parts of the framework that would be beneficial outside of ionic apps (like animations, motions) into their standalone git projects so they can be adopted for use in -any- web project that uses material design. How can I contribute? Please see our contribution guidelines Want to become an official collaborator? Please contact @zachsoft Roadmap and the Future See Milestones Rough Ideas Complete implementation of Material Design specification. Full UI Kit w/ dozens of templates for rapid application development. Inspired by amazing kits like: https://ui8.net/product/material-ui-kit. Increase animation performance. We're really stretching the limits of hybrid app animations - if you have ideas on performance adjustments, we're all ears and would love the insight. Port animate.js with bezier curve adjustments to match ""authentic motion"" spec of Material Design. Bug fixes"
4693,"Crypto 101, the introductory book on cryptography.====================== Crypto 101: the book ====================== .. image:: https://travis-ci.com/crypto101/book.svg?branch=master :target: https://travis-ci.com/crypto101/book This is the source repository for Crypto 101, the introductory book about cryptography by lvh. .. _Crypto 101: https://www.crypto101.io/ .. _lvh: https://twitter.com/lvh License See the LICENSE <LICENSE>_ file. Translations For now, crypto101 is only available in english, but you can help translate it into your own language <https://github.com/crypto101/book/issues/372>_. Building Run make book in the root directory of the repository to convert the source files into rendered versions of all supported formats. Dependencies Due to the high number of dependencies, using docker is highly recommanded: .. code-block:: sh docker build -t crypto101 docker/ docker run --rm -it -v ""$(realpath .)"":/repo -u ""$(id -u)"" crypto101 ./make-lang YOUR_LANGUAGE_CODE html latexpdf epub YOUR_LANGUAGE_CODE must a valid sphinx language code <https://www.sphinx-doc.org/en/master/usage/configuration.html#confval-language>_, like en, fr, ko or zh_CN. You can find the install procedure for the dependencies for ubuntu <docker/Dockerfile.ubuntu> and fedora <docker/Dockerfile.fedora> in their dedicated dockerfiles."
1044,"Ultra lightweight, usable, beautiful autocomplete with zero dependencies.Awesomplete https://leaverou.github.io/awesomplete/ Awesomplete is an ultra lightweight, customizable, simple autocomplete widget with zero dependencies, built with modern standards for modern browsers. Installation There are a few ways to obtain the needed files. Here are 2 of them: 1. CDN server Another way to get up and running is by using yarn or npm: More information about the npm package can be found here. Basic Usage Before you try anything, you need to include awesomplete.css and awesomplete.js in your page, via the usual tags: Then you can add an Awesomplete widget by adding the following input tag: Add class=""awesomplete"" for it to be automatically processed (you can still specify many options via HTML attributes) Otherwise you can instantiate with a few lines of JS code, which allow for more customization. There are many ways to link an input to a list of suggestions. The simple example above could have also been made with the following markup, which provides a nice native fallback in case the script doesnt load: Or the following, if you dont want to use a <datalist>, or if you dont want to use IDs (since any selector will work in data-list): There are multiple customizations and properties able to be instantiated within the JS. Libraries and definitions of the properties are available in the Links below. Options | JS Property | HTML Attribute | Description | Value | Default | | ----------- | -------------- | ------------------------------------------------------------------------------- | ------- | ------------ | | list | data-list | Where to find the list of suggestions. | Array of strings, HTML element, CSS selector (no groups, i.e. no commas), String containing a comma-separated list of items | N/A | | minChars | data-minchars | Minimum characters the user has to type before the autocomplete popup shows up. | Number | 2 | | maxItems | data-maxitems | Maximum number of suggestions to display. | Number | 10 | | autoFirst | data-autofirst | Should the first element be automatically | Boolean | false | | listLabel | data-listlabel | Denotes a label to be used as aria-label on the generated autocomplete list. | String | Results List | License Awesomplete is released under the MIT License. See LICENSE file for details. Links The official site for the library is at https://leaverou.github.io/awesomplete/. Documentation for the API and other topics is at https://leaverou.github.io/awesomplete/#api. Created by Lea Verou and other fantastic contributors."
2313,"APM, (Application Performance Management) tool for large-scale distributed systems.Visit our official web site for more information and Latest updates on Pinpoint. Latest Release (2021/03/05) We're happy to announce the release of Pinpoint v2.2.2. Please check the release note at (https://github.com/pinpoint-apm/pinpoint/releases/tag/v2.2.2). The current stable version is v2.2.2. Live Demo Take a quick look at Pinpoint with our demo! PHP, PYTHON Pinpoint also supports application written in PHP, Python. Check-out our agent repository. About Pinpoint Pinpoint is an APM (Application Performance Management) tool for large-scale distributed systems written in Java / PHP/PYTHON. Inspired by Dapper, Pinpoint provides a solution to help analyze the overall structure of the system and how components within them are interconnected by tracing transactions across distributed applications. You should definitely check Pinpoint out If you want to understand your application topology at a glance monitor your application in Real-Time gain code-level visibility to every transaction install APM Agents without changing a single line of code have minimal impact on the performance (approximately 3% increase in resource usage) Getting Started Quick-start guide for simple test run of Pinpoint Installation guide for further instructions. Overview Services nowadays often consist of many different components, communicating amongst themselves as well as making API calls to external services. How each and every transaction gets executed is often left as a blackbox. Pinpoint traces transaction flows between these components and provides a clear view to identify problem areas and potential bottlenecks. For a more intimate guide, please check out our Introduction to Pinpoint video clip. ServerMap - Understand the topology of any distributed systems by visualizing how their components are interconnected. Clicking on a node reveals details about the component, such as its current status, and transaction count. Realtime Active Thread Chart - Monitor active threads inside applications in real-time. Request/Response Scatter Chart - Visualize request count and response patterns over time to identify potential problems. Transactions can be selected for additional detail by dragging over the chart. CallStack - Gain code-level visibility to every transaction in a distributed environment, identifying bottlenecks and points of failure in a single view. Inspector - View additional details on the application such as CPU usage, Memory/Garbage Collection, TPS, and JVM arguments. Supported Modules JDK 6+ Tomcat 6/7/8/9, Jetty 8/9, JBoss EAP 6/7, Resin 4, Websphere 6/7/8, Vertx 3.3/3.4/3.5, Weblogic 10/11g/12c, Undertow Spring, Spring Boot (Embedded Tomcat, Jetty, Undertow), Spring asynchronous communication Apache HTTP Client 3.x/4.x, JDK HttpConnector, GoogleHttpClient, OkHttpClient, NingAsyncHttpClient, Akka-http, Apache CXF Thrift Client, Thrift Service, DUBBO PROVIDER, DUBBO CONSUMER, GRPC ActiveMQ, RabbitMQ, Kafka, RocketMQ MySQL, Oracle, MSSQL(jtds), CUBRID, POSTGRESQL, MARIA Arcus, Memcached, Redis(Jedis, Lettuce), CASSANDRA, MongoDB, Hbase, Elasticsearch iBATIS, MyBatis DBCP, DBCP2, HIKARICP, DRUID gson, Jackson, Json Lib, Fastjson log4j, Logback, log4j2 Compatibility Java version required to run Pinpoint: Pinpoint Version | Agent | Collector | Web ---------------- | ----- | --------- | --- 1.7.x | 6-8 | 8 | 8 1.8.0 | 6-10 | 8 | 8 1.8.1+ | 6-11 | 8 | 8 2.0.x | 6-13 | 8 | 8 2.1.x | 6-14 | 8 | 8 2.2.x | 7-14 | 8 | 8 2.3.x | 7-17 | 8 | 8 HBase compatibility table: Pinpoint Version | HBase 1.0.x | HBase 1.2.x | HBase 1.4.x | HBase 2.0.x ---------------- | ----------- | ----------- | ----------- | ----------- 1.7.x | not tested | yes | yes | no 1.8.x | not tested | yes | yes | no 2.0.x | not tested | yes | yes | optional 2.1.x | not tested | yes | yes | optional 2.2.x | not tested | yes | yes | optional 2.3.x | not tested | yes | yes | optional Agent - Collector compatibility table: Agent Version | Collector 1.7.x | Collector 1.8.x | Collector 2.0.x | Collector 2.1.x | Collector 2.2.x | Collector 2.3.x | ------------- | --------------- | --------------- | --------------- | --------------- | --------------- | --------------- | 1.7.x | yes | yes | yes | yes | yes | yes 1.8.x | no | yes | yes | yes | yes | yes 2.0.x | no | no | yes | yes | yes | yes 2.1.x | no | no | no | yes | yes | yes 2.2.x | no | no | no | no | yes | yes 2.3.x | no | no | no | no | no | yes Flink compatibility table: Pinpoint Version | flink 1.3.X | flink 1.4.X | flink 1.5.X | flink 1.6.X | flink 1.7.X ---------------- | ----------- | ----------- | ----------- | ----------- | ----------- 1.7.x | yes | yes | no | no | no | 1.8.x | yes | yes | no | no | no | 2.0.x | yes | yes | yes | yes | yes | 2.1.x | yes | yes | yes | yes | yes | 2.2.x | yes | yes | yes | yes | yes | 2.3.x | yes | yes | yes | yes | yes | Community Github issues Google group Gitter We have Chinese community now, welcome to join! QQ Group1: 897594820 | QQ Group2: 812507584 | DING Group : 21981598 :----------------: | :-----------: | :-----------: | | License Pinpoint is licensed under the Apache License, Version 2.0. See LICENSE for full license text."
1497,"HomeKit support for the impatient Homebridge Homebridge is a lightweight NodeJS server you can run on your home network that emulates the iOS HomeKit API. It supports Plugins, which are community-contributed modules that provide a basic bridge from HomeKit to various 3rd-party APIs provided by manufacturers of ""smart home"" devices. Since Siri supports devices added through HomeKit, this means that with Homebridge you can ask Siri to control devices that don't have any support for HomeKit at all. For instance, using just some of the available plugins, you can say: Siri, unlock the back door. [pictured to the right] Siri, open the garage door. Siri, turn on the coffee maker. Siri, turn on the living room lights. Siri, good morning! You can explore all available plugins at the NPM website by searching for the keyword homebridge-plugin. Community The official Homebridge Discord server and Reddit community are where users can discuss Homebridge and ask for help. HomeKit communities can also be found on both Discord and Reddit. Installation The Homebridge Wiki contains step-by-step instruction on how to install Node.js and setup Homebridge and the Homebridge UI as a service so it automatically starts on boot: Official Homebridge Raspberry Pi Image Setup Homebridge on a Raspberry Pi (Raspbian) Setup Homebridge on Debian or Ubuntu Linux Setup Homebridge on Red Hat, CentOS or Fedora Linux Setup Homebridge on macOS Setup Homebridge on Windows 10 Setup Homebridge on Docker (Linux) Other Platforms On other platforms, ensure you have Node.js v10.17.0 or later installed and run: Then start Homebridge in your terminal window by running: Installing Plugins Plugins are Node.js modules published through NPM and tagged with the keyword homebridge-plugin. They must have a name with the prefix homebridge-, like homebridge-mysmartlock. Plugins can publish Accessories and/or Platforms. Accessories are individual devices, like a smart switch or a garage door. Platforms act like a single device but can expose a set of devices, like a house full of smart lightbulbs. You install Plugins using the Homebridge UI, or the same way you installed Homebridge - as a global NPM module. For example: You can explore all available plugins at the NPM website by searching for the keyword homebridge-plugin. Adding Homebridge to iOS Open the Home app on your device. Tap the Home tab, then tap . Tap Add Accessory, then scan the QR code shown in the Homebridge UI or your Homebridge logs. If the bridge does not have any accessories yet, you may receive a message saying Additional Set-up Required, this is ok, as you add plugins they will show up in the Home app without the need to pair again (except for Cameras and TVs). Cameras and most TV devices are exposed as separate accessories and each needs to be paired separately. See this wiki article for instructions. Interacting with your Devices Once your device has been added to HomeKit, you should be able to tell Siri to control your devices. However, realize that Siri is a cloud service, and iOS may need some time to synchronize your device information with iCloud. One final thing to remember is that Siri will almost always prefer its default phrase handling over HomeKit devices. For instance, if you name your Sonos device ""Radio"" and try saying ""Siri, turn on the Radio"" then Siri will probably start playing an iTunes Radio station on your phone. Even if you name it ""Sonos"" and say ""Siri, turn on the Sonos"", Siri will probably just launch the Sonos app instead. This is why, for instance, the suggested name for the Sonos accessory is ""Speakers"". Plugin Development The https://developers.homebridge.io website contains the Homebridge API reference, available service and characteristic types, and plugin examples. The Homebridge Plugin Template project provides a base you can use to create your own platform plugin. There are many existing plugins you can study; you might start with the Homebridge Example Plugins or a plugin that already implements the device type you need. When writing your plugin, you'll want Homebridge to load it from your development directory instead of publishing it to npm each time. Run this command inside your plugin project folder so your global install of Homebridge can discover it: You can undo this using the npm unlink command. Then start Homebridge in debug mode: This will start up Homebridge and load your in-development plugin. Note that you can also direct Homebridge to load your configuration from somewhere besides the default ~/.homebridge, for example: This is very useful when you are already using your development machine to host a ""real"" Homebridge instance (with all your accessories) that you don't want to disturb. Common Issues Home App Says Accessory Already Added To fix this, Reset Homebridge. My iOS App Can't Find Homebridge Try the following: Swap between the Bonjour HAP and Ciao mDNS Advertiser options. See the wiki for more details. iOS DNS cache has gone stale or gotten misconfigured. To fix this, turn airplane mode on and back off to flush the DNS cache. Limitations One bridge can only expose 150 accessories due to a HomeKit limit. You can however run your plugins as a Child Bridge or run Multiple Homebridge Instances to get around this limitation. Once an accessory has been added to the Home app, changing its name via Homebridge won't be automatically reflected in iOS. You must change it via the Home app as well. Why Homebridge? Technically, the device manufacturers should be the ones implementing the HomeKit API. And I'm sure they will - eventually. When they do, this project will be obsolete, and I hope that happens soon. In the meantime, Homebridge is a fun way to get a taste of the future, for those who just can't bear to wait until ""real"" HomeKit devices are on the market. Credit Homebridge was originally created by Nick Farina. The original HomeKit API work was done by Khaos Tian in his HAP-NodeJS project."
4862,"Ghost Driver is an implementation of the Remote WebDriver Wire protocol, using PhantomJS as back-endGhost Driver Ghost Driver is a pure JavaScript implementation of the WebDriver Wire Protocol for PhantomJS. It's a Remote WebDriver that uses PhantomJS as back-end. GhostDriver is designed to be integral part of PhantomJS itself, but it's developed in isolation and progress is tracked by this Repository. Current GhostDriver stable version: see releases PhantomJS-integrated version is ""1.2.0"" (detro@2af7099a9) : contained in PhantomJS ""2.1.1"" Current PhantomJSDriver Java bindings stable version: see Maven For more info, please take a look at the changelog. The project was created and is lead by Ivan De Marino. IRC channel: #phantomjs-ghostdriver. Setup Download latest stable PhantomJS from here Selenium version "">= 3.1.0"" THAT'S IT!! Because of latest stable GhostDriver being embedded in PhantomJS, you shouldn't need anything else to get started. Register GhostDriver with a Selenium Grid hub Launch the grid server, which listens on 4444 by default: java -jar /path/to/selenium-server-standalone-<SELENIUM VERSION>.jar -role hub Register with the hub: phantomjs --webdriver=8080 --webdriver-selenium-grid-hub=http://127.0.0.1:4444 Now you can use your normal webdriver client with http://127.0.0.1:4444 and just request browserName: phantomjs (Java) Bindings This project provides WebDriver bindings for Java under the name PhantomJSDriver. Here is the JavaDoc. Bindings for other languages (C#, Python, Ruby, ...) are developed and maintained under the same name within the Selenium project itself. Include Java Bindings in your Maven project For versions >= 2.0.0, add the following to your pom.xml: Include Java Bindings in your Gradle project Just add the following to your build.gradle: Alternative: how to use it via RemoteWebDriver Launching PhantomJS in Remote WebDriver mode it's simple: Once started, you can use any RemoteWebDriver implementation to send commands to it. I advice to take a look to the /test directory for examples. F.A.Q. What extra WebDriver capabilities GhostDriver offers? GhostDriver extra Capabilities phantomjs.page.settings.SETTING = VALUE - Configure page.settings on PhantomJS internal page objects (windows in WebDriver context) (see reference) phantomjs.page.customHeaders.HEADER = VALUE - Add extra HTTP Headers when loading a URL (see reference) phantomjs.page.whitelist - an array of regex expressions of urls to accept. eg. ['my-awesome-website.com'] phantomjs.page.blacklist - array of regex expressions of urls to ignore. The blacklist overrides the whitelist. eg. ['google.com', 'github.com'] unhandledPromptBehavior - set to dismiss to automatically dismiss all user prompts or set to accept to automatically accept all user prompts loggingPrefs - ghostdriver has two logs browser and har. The logs default to ""OFF"". follow the DesiredCapabilities documentation to enable the logs. PhantomJSDriver Java-binding Capabilities phantomjs.binary.path - Specify path to PhantomJS executable to use phantomjs.ghostdriver.path - Specify path to GhostDriver main/src.js script to use; allows to use a different version of GhostDriver then the one embed in PhantomJS phantomjs.cli.args - Specify command line arguments to pass to the PhantomJS executable phantomjs.ghostdriver.cli.args - Specify command line argument to pass to GhostDriver (works only in tandem with phantomjs.ghostdriver.path) Want to help? Read on! GhostDriver pushed the evolution of PhantomJS from the start. All the features required by PhantomJS to fit GhostDriver were designed to still feel ""consistent"" and ""at home"" with PhantomJS alone. To drive that effort, I worked on a PhantomJS fork, and then pushed changes to PhantomJS master once agreed with the rest of the team on the changes. If you are planning to contribute, that is the PhantomJS you should use. Run validation tests Here I show how to clone this repo and kick start the (Java) tests. You need Java SDK to run them. ghostdriver requires Java 1.8. git clone https://github.com/detro/ghostdriver.git Configure phantomjs_exec_path inside ghostdriver/test/config.ini to point at the build of PhantomJS you just did cd ghostdriver/test/java; ./gradlew test Alternative: Run GhostDriver yourself and launch tests against that instance phantomjs --webdriver=PORT Configure driver inside ghostdriver/test/config.ini to point at the URL http://localhost:PORT cd ghostdriver/test/java; ./gradlew test Project Directory Structure Here follows the output of the tree -hd -L 3 command, trimmed of files and ""build directories"": WebDriver Atoms Being GhostDriver a WebDriver implementation, it embeds the standard/default WebDriver Atoms to operate inside open webpages. In the specific, the Atoms cover scenarios where the ""native"" PhantomJS require('webpage') don't stretch. Documentation about how those work can be found here and here. How are those Atoms making their way into GhostDriver? If you look inside the /tools directory you can find a bash script: /tools/import_atoms.sh. That script accepts the path to a Selenium local repo, runs the CrazyFunBuild to produce the compressed/minified Atoms, grabs those and copies them over to the /src/third_party/webdriver-atoms directory. The Atoms original source lives inside the Selenium repo in the subtree of /javascript. To understand how the build works, you need to spend a bit of time reading about CrazyFunBuild: worth your time if you want to contribute to GhostDriver (or any WebDriver, as a matter of fact). One thing it's important to mention, is that CrazyFunBuild relies on the content of build.desc file to understand what and how to build it. Those files define what exactly is built and what it depends on. In the case of the Atoms, the word ""build"" means ""run Google Closure Compiler over a set of files and compress functions into Atoms"". The definition of the Atoms that GhostDriver uses lives at /tools/atoms_build_dir/build.desc. Let's take this small portion of our build.desc: The first part (js_library(name = ""deps""...) declares what are the dependency of this build.desc: with that CrazyFunBuild knows what to build before fulfilling our build. The second part (js_fragment(...) defines an Atom: the get_element_from_cache is going to be the name of an Atom to build; it can be found in the module bot.inject.cache and is realised by the function named bot.inject.cache.getElement. The third part (js_library(name = ""build_atoms""...) is a list of the Atoms (either defined by something like the second part or in one of the files we declared as dependency) that we want to build. If you reached this stage in understanding the Atoms, you are ready to go further by yourself. Contributions and/or Bug Report You can contribute by testing GhostDriver, reporting bugs and issues, or submitting Pull Requests. Any help is welcome, but bear in mind the following base principles: Issue reporting requires a reproducible example, otherwise will most probably be closed without warning Squash your commits by theme: I prefer a clean, readable log Maintain consistency with the code-style you are surrounded by If you are going to make a big, substantial change, let's discuss it first I HATE CoffeeScript: assume I'm going to laugh off any ""contribution"" that contains such aberrational crap! Open Source is NOT a democracy (and I mean it!) License GhostDriver is distributed under BSD License. Release names See here."
109,"Node Version Manager - POSIX-compliant bash script to manage multiple active node.js versionsNode Version Manager Table of Contents About Installing and Updating Install & Update Script Additional Notes Troubleshooting on Linux Troubleshooting on macOS Ansible Verify Installation Important Notes Git Install Manual Install Manual Upgrade Usage Long-term Support Migrating Global Packages While Installing Default Global Packages From File While Installing io.js System Version of Node Listing Versions Setting Custom Colors Persisting custom colors Suppressing colorized output Restoring PATH Set default node version Use a mirror of node binaries .nvmrc Deeper Shell Integration bash Automatically call nvm use zsh Calling nvm use automatically in a directory with a .nvmrc file fish Calling nvm use automatically in a directory with a .nvmrc file Running Tests Environment variables Bash Completion Usage Compatibility Issues Installing nvm on Alpine Linux Uninstalling / Removal Manual Uninstall Docker For Development Environment Problems macOS Troubleshooting Maintainers License Copyright notice About nvm is a version manager for node.js, designed to be installed per-user, and invoked per-shell. nvm works on any POSIX-compliant shell (sh, dash, ksh, zsh, bash), in particular on these platforms: unix, macOS, and windows WSL. Installing and Updating Install & Update Script To install or update nvm, you should run the install script. To do that, you may either download and run the script manually, or use the following cURL or Wget command: Running either of the above commands downloads a script and runs it. The script clones the nvm repository to ~/.nvm, and attempts to add the source lines from the snippet below to the correct profile file (~/.bash_profile, ~/.zshrc, ~/.profile, or ~/.bashrc). Additional Notes If the environment variable $XDG_CONFIG_HOME is present, it will place the nvm files there. You can add --no-use to the end of the above script (...nvm.sh --no-use) to postpone using nvm until you manually use it. You can customize the install source, directory, profile, and version using the NVM_SOURCE, NVM_DIR, PROFILE, and NODE_VERSION variables. Eg: curl ... | NVM_DIR=""path/to/nvm"". Ensure that the NVM_DIR does not contain a trailing slash. The installer can use git, curl, or wget to download nvm, whichever is available. Troubleshooting on Linux On Linux, after running the install script, if you get nvm: command not found or see no feedback from your terminal after you type command -v nvm, simply close your current terminal, open a new terminal, and try verifying again. Alternatively, you can run run the following commands for the different shells on the command line: bash: source ~/.bashrc zsh: source ~/.zshrc ksh: . ~/.profile These should pick up the nvm command. Troubleshooting on macOS Since OS X 10.9, /usr/bin/git has been preset by Xcode command line tools, which means we can't properly detect if Git is installed or not. You need to manually install the Xcode command line tools before running the install script, otherwise, it'll fail. (see #1782) If you get nvm: command not found after running the install script, one of the following might be the reason: Since macOS 10.15, the default shell is zsh and nvm will look for .zshrc to update, none is installed by default. Create one with touch ~/.zshrc and run the install script again. If you use bash, the previous default shell, your system may not have a .bash_profile file where the command is set up. Create one with touch ~/.bash_profile and run the install script again. Then, run source ~/.bash_profile to pick up the nvm command. You have previously used bash, but you have zsh installed. You need to manually add these lines to ~/.zshrc and run . ~/.zshrc. You might need to restart your terminal instance or run . ~/.nvm/nvm.sh. Restarting your terminal/opening a new tab/window, or running the source command will load the command and the new configuration. If the above didn't help, you might need to restart your terminal instance. Try opening a new tab/window in your terminal and retry. If the above doesn't fix the problem, you may try the following: If you use bash, it may be that your .bash_profile (or ~/.profile) does not source your ~/.bashrc properly. You could fix this by adding source ~/<your_profile_file> to it or follow the next step below. Try adding the snippet from the install section, that finds the correct nvm directory and loads nvm, to your usual profile (~/.bash_profile, ~/.zshrc, ~/.profile, or ~/.bashrc). For more information about this issue and possible workarounds, please refer here Ansible You can use a task: Verify Installation To verify that nvm has been installed, do: which should output nvm if the installation was successful. Please note that which nvm will not work, since nvm is a sourced shell function, not an executable binary. Important Notes If you're running a system without prepackaged binary available, which means you're going to install nodejs or io.js from its source code, you need to make sure your system has a C++ compiler. For OS X, Xcode will work, for Debian/Ubuntu based GNU/Linux, the build-essential and libssl-dev packages work. Note: nvm also support Windows in some cases. It should work through WSL (Windows Subsystem for Linux) depending on the version of WSL. It should also work with GitBash (MSYS) or Cygwin. Otherwise, for Windows, afew alternatives exist, which are neither supported nor developed by us: nvm-windows nodist nvs Note: nvm does not support Fish either (see #303). Alternatives exist, which are neither supported nor developed by us: bass allows you to use utilities written for Bash in fish shell fast-nvm-fish only works with version numbers (not aliases) but doesn't significantly slow your shell startup plugin-nvm plugin for Oh My Fish, which makes nvm and its completions available in fish shell fnm - fisherman-based version manager for fish fish-nvm - Wrapper around nvm for fish, delays sourcing nvm until it's actually used. Note: We still have some problems with FreeBSD, because there is no official pre-built binary for FreeBSD, and building from source may need patches; see the issue ticket: [#900] [Bug] nodejs on FreeBSD may need to be patched nodejs/node#3716 Note: On OS X, if you do not have Xcode installed and you do not wish to download the ~4.3GB file, you can install the Command Line Tools. You can check out this blog post on how to just that: How to Install Command Line Tools in OS X Mavericks & Yosemite (Without Xcode) Note: On OS X, if you have/had a ""system"" node installed and want to install modules globally, keep in mind that: When using nvm you do not need sudo to globally install a module with npm -g, so instead of doing sudo npm install -g grunt, do instead npm install -g grunt If you have an ~/.npmrc file, make sure it does not contain any prefix settings (which is not compatible with nvm) You can (but should not?) keep your previous ""system"" node install, but nvm will only be available to your user account (the one used to install nvm). This might cause version mismatches, as other users will be using /usr/local/lib/node_modules/* VS your user account using ~/.nvm/versions/node/vX.X.X/lib/node_modules/* Homebrew installation is not supported. If you have issues with homebrew-installed nvm, please brew uninstall it, and install it using the instructions below, before filing an issue. Note: If you're using zsh you can easily install nvm as a zsh plugin. Install zsh-nvm and run nvm upgrade to upgrade. Note: Git versions before v1.7 may face a problem of cloning nvm source from GitHub via https protocol, and there is also different behavior of git before v1.6, and git prior to v1.17.10 can not clone tags, so the minimum required git version is v1.7.10. If you are interested in the problem we mentioned here, please refer to GitHub's HTTPS cloning errors article. Git Install If you have git installed (requires git v1.7.10+): clone this repo in the root of your user profile cd ~/ from anywhere then git clone https://github.com/nvm-sh/nvm.git .nvm cd ~/.nvm and check out the latest version with git checkout v0.38.0 activate nvm by sourcing it from your shell: . ./nvm.sh Now add these lines to your ~/.bashrc, ~/.profile, or ~/.zshrc file to have it automatically sourced upon login: (you may have to add to more than one of the above files) Manual Install For a fully manual install, execute the following lines to first clone the nvm repository into $HOME/.nvm, and then load nvm: Now add these lines to your ~/.bashrc, ~/.profile, or ~/.zshrc file to have it automatically sourced upon login: (you may have to add to more than one of the above files) Manual Upgrade For manual upgrade with git (requires git v1.7.10+): change to the $NVM_DIR pull down the latest changes check out the latest version activate the new version Usage To download, compile, and install the latest release of node, do this: To install a specific version of node: The first version installed becomes the default. New shells will start with the default version of node (e.g., nvm alias default). You can list available versions using ls-remote: And then in any new shell just use the installed version: Or you can just run it: Or, you can run any arbitrary command in a subshell with the desired version of node: You can also get the path to the executable to where it was installed: In place of a version pointer like ""0.10"" or ""5.0"" or ""4.2.1"", you can use the following special default aliases with nvm install, nvm use, nvm run, nvm exec, nvm which, etc: node: this installs the latest version of node iojs: this installs the latest version of io.js stable: this alias is deprecated, and only truly applies to node v0.12 and earlier. Currently, this is an alias for node. unstable: this alias points to node v0.11 - the last ""unstable"" node release, since post-1.0, all node versions are stable. (in SemVer, versions communicate breakage, not stability). Long-term Support Node has a schedule for long-term support (LTS) You can reference LTS versions in aliases and .nvmrc files with the notation lts/* for the latest LTS, and lts/argon for LTS releases from the ""argon"" line, for example. In addition, the following commands support LTS arguments: nvm install --lts / nvm install --lts=argon / nvm install 'lts/*' / nvm install lts/argon nvm uninstall --lts / nvm uninstall --lts=argon / nvm uninstall 'lts/*' / nvm uninstall lts/argon nvm use --lts / nvm use --lts=argon / nvm use 'lts/*' / nvm use lts/argon nvm exec --lts / nvm exec --lts=argon / nvm exec 'lts/*' / nvm exec lts/argon nvm run --lts / nvm run --lts=argon / nvm run 'lts/*' / nvm run lts/argon nvm ls-remote --lts / nvm ls-remote --lts=argon nvm ls-remote 'lts/*' / nvm ls-remote lts/argon nvm version-remote --lts / nvm version-remote --lts=argon / nvm version-remote 'lts/*' / nvm version-remote lts/argon Any time your local copy of nvm connects to https://nodejs.org, it will re-create the appropriate local aliases for all available LTS lines. These aliases (stored under $NVM_DIR/alias/lts), are managed by nvm, and you should not modify, remove, or create these files - expect your changes to be undone, and expect meddling with these files to cause bugs that will likely not be supported. To get the latest LTS version of node and migrate your existing installed packages, use Migrating Global Packages While Installing If you want to install a new version of Node.js and migrate npm packages from a previous version: This will first use ""nvm version node"" to identify the current version you're migrating packages from. Then it resolves the new version to install from the remote server and installs it. Lastly, it runs ""nvm reinstall-packages"" to reinstall the npm packages from your prior version of Node to the new one. You can also install and migrate npm packages from specific versions of Node like this: Note that reinstalling packages explicitly does not update the npm version this is to ensure that npm isn't accidentally upgraded to a broken version for the new node version. To update npm at the same time add the --latest-npm flag, like this: or, you can at any time run the following command to get the latest supported npm version on the current node version: If you've already gotten an error to the effect of ""npm does not support Node.js"", you'll need to (1) revert to a previous node version (nvm ls & nvm use <your latest _working_ version from the ls>, (2) delete the newly created node version (nvm uninstall <your _broken_ version of node from the ls>), then (3) rerun your nvm install with the --latest-npm flag. Default Global Packages From File While Installing If you have a list of default packages you want installed every time you install a new version, we support that too -- just add the package names, one per line, to the file $NVM_DIR/default-packages. You can add anything npm would accept as a package argument on the command line. io.js If you want to install io.js: If you want to install a new version of io.js and migrate npm packages from a previous version: The same guidelines mentioned for migrating npm packages in node are applicable to io.js. System Version of Node If you want to use the system-installed version of node, you can use the special default alias ""system"": Listing Versions If you want to see what versions are installed: If you want to see what versions are available to install: Setting Custom Colors You can set five colors that will be used to display version and alias information. These colors replace the default colors. Initial colors are: g b y r e Color codes: r/R = red / bold red g/G = green / bold green b/B = blue / bold blue c/C = cyan / bold cyan m/M = magenta / bold magenta y/Y = yellow / bold yellow k/K = black / bold black e/W = light grey / white Persisting custom colors If you want the custom colors to persist after terminating the shell, export the NVM_COLORS variable in your shell profile. For example, if you want to use cyan, magenta, green, bold red and bold yellow, add the following line: Suppressing colorized output nvm help (or -h or --help), nvm ls, nvm ls-remote and nvm alias usually produce colorized output. You can disable colors with the --no-colors option (or by setting the environment variable TERM=dumb): Restoring PATH To restore your PATH, you can deactivate it: Set default node version To set a default Node version to be used in any new shell, use the alias 'default': Use a mirror of node binaries To use a mirror of the node binaries, set $NVM_NODEJS_ORG_MIRROR: To use a mirror of the io.js binaries, set $NVM_IOJS_ORG_MIRROR: nvm use will not, by default, create a ""current"" symlink. Set $NVM_SYMLINK_CURRENT to ""true"" to enable this behavior, which is sometimes useful for IDEs. Note that using nvm in multiple shell tabs with this environment variable enabled can cause race conditions. .nvmrc You can create a .nvmrc file containing a node version number (or any other string that nvm understands; see nvm --help for details) in the project root directory (or any parent directory). Afterwards, nvm use, nvm install, nvm exec, nvm run, and nvm which will use the version specified in the .nvmrc file if no version is supplied on the command line. For example, to make nvm default to the latest 5.9 release, the latest LTS version, or the latest node version for the current directory: [NB these examples assume a POSIX-compliant shell version of echo. If you use a Windows cmd development environment, eg the .nvmrc file is used to configure a remote Linux deployment, then keep in mind the ""s will be copied leading to an invalid file. Remove them.] Then when you run nvm: nvm use et. al. will traverse directory structure upwards from the current directory looking for the .nvmrc file. In other words, running nvm use et. al. in any subdirectory of a directory with an .nvmrc will result in that .nvmrc being utilized. The contents of a .nvmrc file must be the <version> (as described by nvm --help) followed by a newline. No trailing spaces are allowed, and the trailing newline is required. Deeper Shell Integration You can use avn to deeply integrate into your shell and automatically invoke nvm when changing directories. avn is not supported by the nvm maintainers. Please report issues to the avn team. If you prefer a lighter-weight solution, the recipes below have been contributed by nvm users. They are not supported by the nvm maintainers. We are, however, accepting pull requests for more examples. bash Automatically call nvm use Put the following at the end of your $HOME/.bashrc: This alias would search 'up' from your current directory in order to detect a .nvmrc file. If it finds it, it will switch to that version; if not, it will use the default version. zsh Calling nvm use automatically in a directory with a .nvmrc file Put this into your $HOME/.zshrc to call nvm use automatically whenever you enter a directory that contains an .nvmrc file with a string telling nvm which node to use: fish Calling nvm use automatically in a directory with a .nvmrc file This requires that you have bass installed. Running Tests Tests are written in Urchin. Install Urchin (and other dependencies) like so: npm install There are slow tests and fast tests. The slow tests do things like install node and check that the right versions are used. The fast tests fake this to test things like aliases and uninstalling. From the root of the nvm git repository, run the fast tests like this: npm run test/fast Run the slow tests like this: npm run test/slow Run all of the tests like this: npm test Nota bene: Avoid running nvm while the tests are running. Environment variables nvm exposes the following environment variables: NVM_DIR - nvm's installation directory. NVM_BIN - where node, npm, and global packages for the active version of node are installed. NVM_INC - node's include file directory (useful for building C/C++ addons for node). NVM_CD_FLAGS - used to maintain compatibility with zsh. NVM_RC_VERSION - version from .nvmrc file if being used. Additionally, nvm modifies PATH, and, if present, MANPATH and NODE_PATH when changing versions. Bash Completion To activate, you need to source bash_completion: Put the above sourcing line just below the sourcing line for nvm in your profile (.bashrc, .bash_profile). Usage nvm: $ nvm Tab nvm alias: $ nvm alias Tab $ nvm alias my_alias Tab nvm use: $ nvm use Tab nvm uninstall: $ nvm uninstall Tab Compatibility Issues nvm will encounter some issues if you have some non-default settings set. (see #606) The following are known to cause issues: Inside ~/.npmrc: Environment Variables: Shell settings: Installing nvm on Alpine Linux In order to provide the best performance (and other optimisations), nvm will download and install pre-compiled binaries for Node (and npm) when you run nvm install X. The Node project compiles, tests and hosts/provides these pre-compiled binaries which are built for mainstream/traditional Linux distributions (such as Debian, Ubuntu, CentOS, RedHat et al). Alpine Linux, unlike mainstream/traditional Linux distributions, is based on BusyBox, a very compact (~5MB) Linux distribution. BusyBox (and thus Alpine Linux) uses a different C/C++ stack to most mainstream/traditional Linux distributions - musl. This makes binary programs built for such mainstream/traditional incompatible with Alpine Linux, thus we cannot simply nvm install X on Alpine Linux and expect the downloaded binary to run correctly - you'll likely see ""...does not exist"" errors if you try that. There is a -s flag for nvm install which requests nvm download Node source and compile it locally. If installing nvm on Alpine Linux is still what you want or need to do, you should be able to achieve this by running the following from you Alpine Linux shell: The Node project has some desire but no concrete plans (due to the overheads of building, testing and support) to offer Alpine-compatible binaries. As a potential alternative, @mhart (a Node contributor) has some Docker images for Alpine Linux with Node and optionally, npm, pre-installed. Uninstalling / Removal Manual Uninstall To remove nvm manually, execute the following: Edit ~/.bashrc (or other shell resource config) and remove the lines below: Docker For Development Environment To make the development and testing work easier, we have a Dockerfile for development usage, which is based on Ubuntu 14.04 base image, prepared with essential and useful tools for nvm development, to build the docker image of the environment, run the docker command at the root of nvm repository: This will package your current nvm repository with our pre-defined development environment into a docker image named nvm-dev, once it's built with success, validate your image via docker images: If you got no error message, now you can easily involve in: Please note that it'll take about 8 minutes to build the image and the image size would be about 650MB, so it's not suitable for production usage. For more information and documentation about docker, please refer to its official website: https://www.docker.com/ https://docs.docker.com/ Problems If you try to install a node version and the installation fails, be sure to run nvm cache clear to delete cached node downloads, or you might get an error like the following: curl: (33) HTTP server doesn't seem to support byte ranges. Cannot resume. Where's my sudo node? Check out #43 After the v0.8.6 release of node, nvm tries to install from binary packages. But in some systems, the official binary packages don't work due to incompatibility of shared libs. In such cases, use -s option to force install from source: If setting the default alias does not establish the node version in new shells (i.e. nvm current yields system), ensure that the system's node PATH is set before the nvm.sh source line in your shell profile (see #658) macOS Troubleshooting nvm node version not found in vim shell If you set node version to a version other than your system node version nvm use 6.2.1 and open vim and run :!node -v you should see v6.2.1 if you see your system version v0.12.7. You need to run: More on this issue in dotphiles/dotzsh. nvm is not compatible with the npm config ""prefix"" option Some solutions for this issue can be found here There is one more edge case causing this issue, and that's a mismatch between the $HOME path and the user's home directory's actual name. You have to make sure that the user directory name in $HOME and the user directory name you'd see from running ls /Users/ are capitalized the same way (See this issue). To change the user directory and/or account name follow the instructions here Homebrew makes zsh directories unsecure Homebrew causes insecure directories like /usr/local/share/zsh/site-functions and /usr/local/share/zsh. This is not an nvm problem - it is a homebrew problem. Refer here for some solutions related to the issue. Macs with M1 chip January 2021: there are no pre-compiled NodeJS binaries for versions prior to 15.x for Apple's new M1 chip (arm64 architecture). Some issues you may encounter: using nvm to install, say, v14.15.4: the C code compiles successfully but crashes with an out of memory error when used increasing the memory available to node still produces the out of memory errors: when using nvm to install some versions, the compilation fails One solution to this issue is to change the architecture of your shell from arm64 to x86. Let's assume that: - you already have versions 12.20.1 and 14.15.4 installed using nvm - the current version in use is 14.15.4 - you are using the zsh shell - you have Rosetta 2 installed (macOS prompts you to install Rosetta 2 the first time you open a Intel-only non-command-line application, or you may install Rosetta 2 from the command line with softwareupdate --install-rosetta) Maintainers Currently, the sole maintainer is @ljharb - more maintainers are quite welcome, and we hope to add folks to the team over time. Governance will be re-evaluated as the project evolves. License See LICENSE.md. Copyright notice Copyright OpenJS Foundation and nvm contributors. All rights reserved. The OpenJS Foundation has registered trademarks and uses trademarks. For a list of trademarks of the OpenJS Foundation, please see our Trademark Policy and Trademark List. Node.js is a trademark of Joyent, Inc. and is used with its permission. Trademarks and logos not indicated on the list of OpenJS Foundation trademarks are trademarks or registered trademarks of their respective holders. Use of them does not imply any affiliation with or endorsement by them. The OpenJS Foundation | Terms of Use | Privacy Policy | OpenJS Foundation Bylaws | Trademark Policy | Trademark List | Cookie Policy"
2615,"Android component which presents a dismissible view from the bottom of the screenBottomSheet BottomSheet is an Android component which presents a dismissible view from the bottom of the screen. BottomSheet can be a useful replacement for dialogs and menus but can hold any view so the use cases are endless. This repository includes the BottomSheet component itself but also includes a set of common view components presented in a bottom sheet. These are located in the commons module. BottomSheet has been used in production at Flipboard for a while now so it is thoroughly tested. Here is a GIF of it in action inside of Flipboard! Installation If all you want is the BottomSheet component and don't need things from commons you can skip that dependency. Getting Started Get started by wrapping your layout in a BottomSheetLayout. So if you currently have this: You would have to update it to look like this: Back in your activity or fragment you would get a reference to the BottomSheetLayout like any other view. Now all you need to do is show a view in the bottomSheet: You could also use one of the sheet views from the commons module. That's it for the simplest of use cases. Check out the API documentation to find out how to customize BottomSheet to fit your use cases. For more examples, also see the Recipes wiki. Common Components These are located in the optional bottomsheet-commons dependency and implement common use cases for bottom sheet. Intent Picker | Menu Sheet | ImagePicker Sheet --- | --- | --- | | IntentPickerSheetView This component presents an intent chooser in the form of a BottomSheet view. Give it an intent such as a share intent and let the user choose what activity they want to share the intent with in a BottomSheet. Example from the sample app. MenuSheetView This component presents a BottomSheet view that's backed by a menu. It behaves similarly to the new NavigationView in the Design support library, and is intended to mimic the examples in the Material Design spec. It supports list and grid states, with the former adding further support for separators and subheaders. Example from the sample app. Contributing We welcome pull requests for bug fixes, new features, and improvements to BottomSheet. Contributors to the main BottomSheet repository must accept Flipboard's Apache-style Individual Contributor License Agreement (CLA) before any changes can be merged."
1747,"[DEPRECATED] Android floating action buttonDEPRECATED Use the FloatingActionButton from the support library instead. FloatingActionButton Description Android floating action button which reacts on scrolling events. Becomes visible when an attached target is scrolled up and invisible when scrolled down. Demo Integration 1) Add as a dependency to your build.gradle: 2) Add the com.melnykov.fab.FloatingActionButton to your layout XML file. The button should be placed in the bottom right corner of the screen. The width and height of the floating action button are hardcoded to 56dp for the normal and 40dp for the mini button as specified in the guidelines. 3) Attach the FAB to AbsListView, RecyclerView or ScrollView : Check the sample project to see how to use custom listeners if you need to track scroll events. 4) Add the namespace xmlns:fab=""http://schemas.android.com/apk/res-auto"" to your layout file. Set the button type (normal or mini) via the fab_type xml attribute (default is normal): or Set the normal and pressed colors via the xml attributes: or Enable/disable the button shadow with the fab_shadow xml attribite (it's enabled by default): or Show/hide the button expliciltly: Specify the ripple color for API 21+: or 5) Set an icon for the FloatingActionButton using android:src xml attribute. Use drawables of size 24dp as specified by guidelines. Icons of desired size can be generated with Android Asset Studio. Changelog Version 1.3.0 + Add the disabled state for the FAB (thanks to Aleksey Malevaniy); + Fix shadow assets. Rename shadow drawables with a prefix; + Generate default pressed and ripple colors (thanks to Aidan Follestad). Version 1.2.0 + Respect an elevation set manually for the FAB; + Don't emit a scroll when the listview is empty; + Add an ability to attach normal listeners for scroll operations (thanks to Bill Donahue). Version 1.1.0: + Do not ignore negative margins on pre-Lollipop; + Disable clicks on the FAB when it's hidden on pre-Honeycomb; + Some shadow tuning. Version 1.0.9: + Support API 7; + Fixed extra margins on pre-Lollipop devices; + Fixed mini FAB size; + Updated shadow assets to more accurately match 8dp elevation. Version 1.0.8: + ATTENTION! Breaking changes for custom listeners. Check an updated sample how to use them. + Added support for the ScrollView; + Significantly optimized scroll detection for the RecyclerView; + Fixed laggy animation for a list view with items of different height; + Added isVisible getter; + Deleted deprecated methods. Version 1.0.7: + Updated shadow assets to better match material design guidelines; + Make FabOnScrollListener and FabRecyclerOnViewScrollListener implement ScrollDirectionListener for easier custom listeners usage. Version 1.0.6: + Added support for the RecyclerView; + Added ripple effect and elevation for API level 21. Thanks to Aidan Follestad. Version 1.0.5: + Updated shadow to more accurately match the material design spec; Version 1.0.4: Allow a custom OnScrollListeners to be attached to a list view; Work properly with list of different height rows; Ignore tiny shakes of fingers. Version 1.0.3: + Add methods to show/hide without animation; + Fix show/hide when a view is not measured yet. Applications using FloatingActionButton Please ping me or send a pull request if you would like to be added here. Icon | Application | Icon | Application ------------ | ------------- | ------------- | ------------- | Finger Gesture Launcher | | Vocabletrainer | Lanekeep GPS Mileage Tracker | | Score It | | | App Swap | QKSMS - Quick Text Messenger | | Uninstaller - Beta Version | Device Control | | Confide | Date Night | | Jair Player The Music Rainbow | Taskr - Lista de Tareas | | Festivos: Conoce el mundo! | nowPaper | | Vicious chain - Don't do that! | My Football Stats | | The ScoreBoard | NavPoint | | Just Reminder | Early Notes | | Ranch - Smart Tip Calculator | Thiengo Calopsita | | Tinycore - CPU, RAM monitor | | Battery Aid Saver & Manager | | GameRaven | Polaris Office | | Call Utils | Colorful Note | | CallSticker - Links Country flag icons used in the sample are taken from www.icondrawer.com License"
1432,"Free cross-platform password manager compatible with KeePassFree cross-platform password manager compatible with KeePass This webapp is a browser and desktop password manager compatible with KeePass databases. It doesn't require any server or additional resources. The app can run either in browser, or as a desktop app. Quick Links Apps: Web, Desktop Timeline: Release Notes, TODO On one page: Features, FAQ Website: keeweb.info Twitter: kee_web Donate: OpenCollective, GitHub Status The app is quite stable now. Basic stuff, as well as more advanced operations, should be rather reliable. Self-hosting Everything you need to host this app on your server is any static file server. The app is a single HTML file + a service worker (optionally; for offline access). You can download the latest distribution files from gh-pages branch. If you are using Docker: put your dh.pem, cert.pem, key.pem to /etc/nginx/external/ run this script: To make Dropbox work in your self-hosted app, go to this Wiki page. Building The easiest way to clone all KeeWeb repos is: The app can be built with grunt: grunt (html files will be in dist/). Desktop apps are built with grunt desktop. This requires some magic and currently works only on CI, you can find more details in the GitHub Actions workflow. To run the desktop (electron) app without building an installer, build the app with grunt and start it this way: For debug build: run npm run dev open http://localhost:8085 To build desktop apps, use these goals, the result can be found in tmp: Contributing Please read contribution guidelines for pull requests. Here's a list of issues where your help would be very welcome. Also you can help by translating KeeWeb to your language. Other ways of contribution can be found on this page. Important notes for pull requests please branch from develop, not master don't edit translation files except base.json, they will be replaced Donations KeeWeb is not free to develop. It takes time, requires paid code signing certificates and domains. You can help the project or say ""thank you"" with this button: You can also sponsor the developer directly on GitHub. Please note: donation does not imply any type of service contract. Thank you Notable contributions to KeeWeb: Florian Reuschel (@Loilo): German translation Dennis Ploeger (@dploeger): auto-type improvements Hackmanit (hackmanit.de): penetration test Peter Bittner (@bittner): Wikipedia article License MIT"
937,"Self-hosted CMS platform based on the Laravel PHP Framework. October is a Content Management System (CMS) and web platform whose sole purpose is to make your development workflow simple again. It was born out of frustration with existing systems. We feel building websites has become a convoluted and confusing process that leaves developers unsatisfied. We want to turn you around to the simpler side and get back to basics. October's mission is to show the world that web development is not rocket science. Please note: October is open source but it is not free software. A license with a small fee is required for each website you build with October CMS. Installing October Instructions on how to install October can be found at the installation guide. Quick Start Installation If you have composer installed, run this in your terminal to install October CMS from command line. This will place the files in a directory named myoctober. composer create-project october/october myoctober If you plan on using a database, run this command inside the application directory. php artisan october:install Learning October The best place to learn October CMS is by reading the documentation or following some tutorials. You may also watch these introductory videos for beginners and advanced users. There is also the excellent video series by Watch & Learn. Coding Standards Please follow the following guides and code standards: PSR 4 Coding Standards PSR 2 Coding Style Guide PSR 1 Coding Standards Security Vulnerabilities Please review our security policy on how to report security vulnerabilities. Development Team October CMS was created by Alexey Bobkov and Samuel Georges, who both continue to develop the platform. Foundation library The CMS uses Laravel as a foundation PHP framework. Contact For announcements and updates: Contact Us Page Follow us on Twitter Like us on Facebook To chat or hang out: Join us on Slack Join us on Discord Join us on Telegram License The October CMS platform is licensed software, see End User License Agreement (EULA) for more details."
811,"PowerShell for every system!PowerShell Welcome to the PowerShell GitHub Community! PowerShell Core is a cross-platform (Windows, Linux, and macOS) automation and configuration tool/framework that works well with your existing tools and is optimized for dealing with structured data (e.g. JSON, CSV, XML, etc.), REST APIs, and object models. It includes a command-line shell, an associated scripting language and a framework for processing cmdlets. Windows PowerShell vs. PowerShell Core Although this repository started as a fork of the Windows PowerShell code base, changes made in this repository do not make their way back to Windows PowerShell 5.1 automatically. This also means that issues tracked here are only for PowerShell Core 6 and higher. Windows PowerShell specific issues should be opened on UserVoice. New to PowerShell? If you are new to PowerShell and would like to learn more, we recommend reviewing the getting started documentation. Get PowerShell You can download and install a PowerShell package for any of the following platforms. | Supported Platform | Download (LTS) | Downloads (stable) | Downloads (preview) | How to Install | | -------------------------------------------| ------------------------| ------------------------| ----------------------| ------------------------------| | Windows (x64) | .msi | .msi | .msi | Instructions | | Windows (x86) | .msi | .msi | .msi | Instructions | | Ubuntu 20.04 | | .deb | .deb | Instructions | | Ubuntu 18.04 | .deb | .deb | .deb | Instructions | | Ubuntu 16.04 | .deb | .deb | .deb | Instructions | | Debian 9 | .deb | .deb | .deb | Instructions | | Debian 10 | .deb | .deb | .deb | Instructions | | Debian 11 | | .deb | .deb | | | CentOS 7 | .rpm | .rpm | .rpm | Instructions | | CentOS 8 | .rpm | .rpm | .rpm | | | Red Hat Enterprise Linux 7 | .rpm | .rpm | .rpm | Instructions | | openSUSE 42.3 | .rpm | .rpm | .rpm | Instructions | | Fedora 30 | .rpm | .rpm | .rpm | Instructions | | macOS 10.13+ | .pkg | .pkg | .pkg | Instructions | | Docker | | | | Instructions | You can download and install a PowerShell package for any of the following platforms, which are supported by the community. | Platform | Downloads (stable) | Downloads (preview) | How to Install | | -------------------------| ------------------------| ----------------------------- | ------------------------------| | Arch Linux | | | Instructions | | Kali Linux | .deb | .deb | Instructions | | Many Linux distributions | Snapcraft | Snapcraft | | You can also download the PowerShell binary archives for Windows, macOS and Linux. | Platform | Downloads (stable) | Downloads (preview) | How to Install | | ---------------| --------------------------------------------------- | ------------------------------------------------| -----------------------------------------------| | Windows | 32-bit/64-bit | 32-bit/64-bit | Instructions | | macOS | 64-bit | 64-bit | Instructions | | Linux | 64-bit | 64-bit | Instructions | | Windows (Arm) | 64-bit (preview) | 64-bit | Instructions | | Raspbian (Arm) | 32-bit/64-bit | 32-bit/64-bit | Instructions | To install a specific version, visit releases. Community Dashboard Dashboard with visualizations for community contributions and project status using PowerShell, Azure, and PowerBI. For more information on how and why we built this dashboard, check out this blog post. Discussions GitHub Discussions is a feature to enable fluid and open discussions within the community for topics that are not related to code, unlike issues. This is an experiment we are trying in our repositories to see if it helps move discussions out of issues so that issues remain actionable by the team or members of the community. There should be no expectation that PowerShell team members are regular participants in the discussions. Individual PowerShell team members may choose to participate in discussions, but the expectation is that community members help drive discussions so that team members can focus on issues. Create or join a discussion. Chat Want to chat with other members of the PowerShell community? We have a Gitter Room which you can join below. There is also the community-driven PowerShell Virtual User Group, which you can join on: Slack Discord Add-ons and libraries Awesome PowerShell has a great curated list of add-ons and resources. Building the Repository | Linux | Windows | macOS | |--------------------------|----------------------------|------------------------| | Instructions | Instructions | Instructions | If you have any problems building, please consult the developer FAQ. Build status of nightly builds | Azure CI (Windows) | Azure CI (Linux) | Azure CI (macOS) | Code Coverage Status | CodeFactor Grade | |:-----------------------------------------|:-----------------------------------------------|:-----------------------------------------------|:-------------------------|:-------------------------| | | | | | | Downloading the Source Code You can just clone the repository: See working with the PowerShell repository for more information. Developing and Contributing Please see the Contribution Guide for how to develop and contribute. If you are developing .NET Core C# applications targeting PowerShell Core, please check out our FAQ to learn more about the PowerShell SDK NuGet package. Also, make sure to check out our PowerShell-RFC repository for request-for-comments (RFC) documents to submit and give comments on proposed and future designs. Support For support, please see the Support Section. Legal and Licensing PowerShell is licensed under the MIT license. Windows Docker Files and Images License: By requesting and using the Container OS Image for Windows containers, you acknowledge, understand, and consent to the Supplemental License Terms available on Docker Hub: Windows Server Core Nano Server Telemetry By default, PowerShell collects the OS description and the version of PowerShell (equivalent to $PSVersionTable.OS and $PSVersionTable.GitCommitId) using Application Insights. To opt-out of sending telemetry, create an environment variable called POWERSHELL_TELEMETRY_OPTOUT set to a value of 1 before starting PowerShell from the installed location. The telemetry we collect falls under the Microsoft Privacy Statement. Governance The governance policy for the PowerShell project is described here. Code of Conduct This project has adopted the Microsoft Open Source Code of Conduct. For more information see the Code of Conduct FAQ or contact opencode@microsoft.com with any additional questions or comments."
4223,"Guard::LiveReload automatically reload your browser when 'view' files are modified.:warning: :warning: :warning: Security Vulnerability: please upgrade to v2.5.2 - details here . (Credits: Michael Coyne) Guard::LiveReload LiveReload guard allows to automatically reload your browser when 'view' files are modified. Support :warning: Guard::LiveReload is looking for a new maintainer. Please contact me if you're interested. For any support question/issue related to livereload please ask on support@livereload.com. Install Please be sure to have Guard installed before continuing. Install the gem: Add it to your Gemfile (inside development group): Add guard definition to your Guardfile by running this command: And to get everything running in the browser, use rack-livereload or install the LiveReload Safari/Chrome/Firefox extension. Usage For a quick start, check out the wiki. If you're using Rails or Rack based apps, check out rack-livereload how it works readme section. For info about Guard and it's plugins, see Guard usage doc For more info about LiveReload extensions, see LiveReload extension usage doc from version 1.x Guardfile You can adapt your 'view' files like you want. Please read Guard doc for more info about Guardfile DSL. Options LiveReload guard has 6 options that you can set like this: Available options: Additional custom JS template options (see livereload.js.erb for details): notify uses Guard's system notifications. See LiveReload configuration doc from version 1.x for more info about other options. Troubleshooting To work out what's wrong and where, just follow this easy guide: https://github.com/guard/guard-livereload/wiki/Troubleshooting Other issues: 1. ""hw.ncpu"" is an unknown key. Solution: just upgrade the listen gem to '3.x' (Listen is used by Guard). (Details: https://github.com/guard/guard-livereload/issues/134) Development Source hosted at GitHub. Report issues and feature requests to GitHub Issues. Pull requests are very welcome! Please try to follow these simple ""rules"", though: Please create a topic branch for every separate change you make. Make sure your patches are well tested. Update the README (if applicable). Please do not change the version number. For questions please join us on our Google group or on #guard (irc.freenode.net). Author Thibaud Guillaume-Gentil"
599,"A high performance Node.js Redis client. Node Redis A high performance Node.js Redis client. Installation Usage Example Note that the API is entirely asynchronous. To get data back from the server, you'll need to use a callback. Promises Node Redis currently doesn't natively support promises (this is coming in v4), however you can wrap the methods you want to use with promises using the built-in Node.js util.promisify method on Node.js >= v8; Commands This library is a 1 to 1 mapping of the Redis commands. Each Redis command is exposed as a function on the client object. All functions take either an args Array plus optional callback Function or a variable number of individual arguments followed by an optional callback. Examples: Care should be taken with user input if arrays are possible (via body-parser, query string or other method), as single arguments could be unintentionally interpreted as multiple args. Note that in either form the callback is optional: If the key is missing, reply will be null. Only if the Redis Command Reference states something else it will not be null. Minimal parsing is done on the replies. Commands that return a integer return JavaScript Numbers, arrays return JavaScript Array. HGETALL returns an Object keyed by the hash keys. All strings will either be returned as string or as buffer depending on your setting. Please be aware that sending null, undefined and Boolean values will result in the value coerced to a string! API Connection and other Events client will emit some events about the state of the connection to the Redis server. ""ready"" client will emit ready once a connection is established. Commands issued before the ready event are queued, then replayed just before this event is emitted. ""connect"" client will emit connect as soon as the stream is connected to the server. ""reconnecting"" client will emit reconnecting when trying to reconnect to the Redis server after losing the connection. Listeners are passed an object containing delay (in ms from the previous try) and attempt (the attempt #) attributes. ""error"" client will emit error when encountering an error connecting to the Redis server or when any other in Node Redis occurs. If you use a command without callback and encounter a ReplyError it is going to be emitted to the error listener. So please attach the error listener to Node Redis. ""end"" client will emit end when an established Redis server connection has closed. ""warning"" client will emit warning when password was set but none is needed and if a deprecated option / function / similar is used. redis.createClient() If you have redis-server running on the same machine as node, then the defaults for port and host are probably fine and you don't need to supply any arguments. createClient() returns a RedisClient object. Otherwise, createClient() accepts these arguments: redis.createClient([options]) redis.createClient(unix_socket[, options]) redis.createClient(redis_url[, options]) redis.createClient(port[, host][, options]) Tip: If the Redis server runs on the same machine as the client consider using unix sockets if possible to increase throughput. Note: Using 'rediss://... for the protocol in a redis_url will enable a TLS socket connection. However, additional TLS options will need to be passed in options, if required. options object properties | Property | Default | Description | | -------------------------- | --------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | | host | 127.0.0.1 | IP address of the Redis server | | port | 6379 | Port of the Redis server | | path | null | The UNIX socket string of the Redis server | | url | null | The URL of the Redis server. Format: [redis[s]:]//[[user][:password@]][host][:port][/db-number][?db=db-number[&password=bar[&option=value]]] (More info avaliable at IANA). | | string_numbers | null | Set to true, Node Redis will return Redis number values as Strings instead of javascript Numbers. Useful if you need to handle big numbers (above Number.MAX_SAFE_INTEGER === 2^53). Hiredis is incapable of this behavior, so setting this option to true will result in the built-in javascript parser being used no matter the value of the parser option. | | return_buffers | false | If set to true, then all replies will be sent to callbacks as Buffers instead of Strings. | | detect_buffers | false | If set to true, then replies will be sent to callbacks as Buffers. This option lets you switch between Buffers and Strings on a per-command basis, whereas return_buffers applies to every command on a client. Note: This doesn't work properly with the pubsub mode. A subscriber has to either always return Strings or Buffers. | | socket_keepalive | true | If set to true, the keep-alive functionality is enabled on the underlying socket. | | socket_initial_delay | 0 | Initial Delay in milliseconds, and this will also behave the interval keep alive message sending to Redis. | | no_ready_check | false | When a connection is established to the Redis server, the server might still be loading the database from disk. While loading, the server will not respond to any commands. To work around this, Node Redis has a ""ready check"" which sends the INFO command to the server. The response from the INFO command indicates whether the server is ready for more commands. When ready, node_redis emits a ready event. Setting no_ready_check to true will inhibit this check. | | enable_offline_queue | true | By default, if there is no active connection to the Redis server, commands are added to a queue and are executed once the connection has been established. Setting enable_offline_queue to false will disable this feature and the callback will be executed immediately with an error, or an error will be emitted if no callback is specified. | | retry_unfulfilled_commands | false | If set to true, all commands that were unfulfilled while the connection is lost will be retried after the connection has been reestablished. Use this with caution if you use state altering commands (e.g. incr). This is especially useful if you use blocking commands. | | password | null | If set, client will run Redis auth command on connect. Alias auth_pass Note Node Redis < 2.5 must use auth_pass | | user | null | The ACL user (only valid when password is set) | | db | null | If set, client will run Redis select command on connect. | | family | IPv4 | You can force using IPv6 if you set the family to 'IPv6'. See Node.js net or dns modules on how to use the family type. | | disable_resubscribing | false | If set to true, a client won't resubscribe after disconnecting. | | rename_commands | null | Passing an object with renamed commands to use instead of the original functions. For example, if you renamed the command KEYS to ""DO-NOT-USE"" then the rename_commands object would be: { KEYS : ""DO-NOT-USE"" } . See the Redis security topics for more info. | | tls | null | An object containing options to pass to tls.connect to set up a TLS connection to Redis (if, for example, it is set up to be accessible via a tunnel). | | prefix | null | A string used to prefix all used keys (e.g. namespace:test). Please be aware that the keys command will not be prefixed. The keys command has a ""pattern"" as argument and no key and it would be impossible to determine the existing keys in Redis if this would be prefixed. | | retry_strategy | function | A function that receives an options object as parameter including the retry attempt, the total_retry_time indicating how much time passed since the last time connected, the error why the connection was lost and the number of times_connected in total. If you return a number from this function, the retry will happen exactly after that time in milliseconds. If you return a non-number, no further retry will happen and all offline commands are flushed with errors. Return an error to return that specific error to all offline commands. Example below. | | connect_timeout | 3600000 | In milliseconds. This should only be the timeout for connecting to redis, but for now it interferes with retry_strategy and stops it from reconnecting after this timeout. | detect_buffers example: retry_strategy example: client.auth(password[, callback]) When connecting to a Redis server that requires authentication, the AUTH command must be sent as the first command after connecting. This can be tricky to coordinate with reconnections, the ready check, etc. To make this easier, client.auth() stashes password and will send it after each connection, including reconnections. callback is invoked only once, after the response to the very first AUTH command sent. NOTE: Your call to client.auth() should not be inside the ready handler. If you are doing this wrong, client will emit an error that looks something like this Error: Ready check failed: ERR operation not permitted. client.quit(callback) This sends the quit command to the redis server and ends cleanly right after all running commands were properly handled. If this is called while reconnecting (and therefore no connection to the redis server exists) it is going to end the connection right away instead of resulting in further reconnections! All offline commands are going to be flushed with an error in that case. client.end(flush) Forcibly close the connection to the Redis server. Note that this does not wait until all replies have been parsed. If you want to exit cleanly, call client.quit() as mentioned above. You should set flush to true, if you are not absolutely sure you do not care about any other commands. If you set flush to false all still running commands will silently fail. This example closes the connection to the Redis server before the replies have been read. You probably don't want to do this: client.end() without the flush parameter set to true should NOT be used in production! Error Handling Currently the following Error subclasses exist: RedisError: All errors returned by the client ReplyError subclass of RedisError: All errors returned by Redis itself AbortError subclass of RedisError: All commands that could not finish due to what ever reason ParserError subclass of RedisError: Returned in case of a parser error (this should not happen) AggregateError subclass of AbortError: Emitted in case multiple unresolved commands without callback got rejected in debug_mode instead of lots of AbortErrors. All error classes are exported by the module. Example Every ReplyError contains the command name in all-caps and the arguments (args). If Node Redis emits a library error because of another error, the triggering error is added to the returned error as origin attribute. Error codes Node Redis returns a NR_CLOSED error code if the clients connection dropped. If a command unresolved command got rejected a UNCERTAIN_STATE code is returned. A CONNECTION_BROKEN error code is used in case Node Redis gives up to reconnect. client.unref() Call unref() on the underlying socket connection to the Redis server, allowing the program to exit once no more commands are pending. This is an experimental feature, and only supports a subset of the Redis protocol. Any commands where client state is saved on the Redis server, e.g. *SUBSCRIBE or the blocking BL* commands will NOT work with .unref(). Hash Commands Most Redis commands take a single String or an Array of Strings as arguments, and replies are sent back as a single String or an Array of Strings. When dealing with hash values, there are a couple of useful exceptions to this. client.hgetall(hash, callback) The reply from an HGETALL command will be converted into a JavaScript Object. That way you can interact with the responses using JavaScript syntax. Example: client.hmset(hash, key1, val1, ...keyN, valN, [callback]) Multiple values may also be set by supplying more arguments. Example: PubSub Example This example opens two client connections, subscribes to a channel on one of them, and publishes to that channel on the other. When a client issues a SUBSCRIBE or PSUBSCRIBE, that connection is put into a ""subscriber"" mode. At that point, the only valid commands are those that modify the subscription set, and quit (also ping on some redis versions). When the subscription set is empty, the connection is put back into regular mode. If you need to send regular commands to Redis while in subscriber mode, just open another connection with a new client (use client.duplicate() to quickly duplicate an existing client). Subscriber Events If a client has subscriptions active, it may emit these events: ""message"" (channel, message): Client will emit message for every message received that matches an active subscription. Listeners are passed the channel name as channel and the message as message. ""pmessage"" (pattern, channel, message): Client will emit pmessage for every message received that matches an active subscription pattern. Listeners are passed the original pattern used with PSUBSCRIBE as pattern, the sending channel name as channel, and the message as message. ""message_buffer"" (channel, message): This is the same as the message event with the exception, that it is always going to emit a buffer. If you listen to the message event at the same time as the message_buffer, it is always going to emit a string. ""pmessage_buffer"" (pattern, channel, message): This is the same as the pmessage event with the exception, that it is always going to emit a buffer. If you listen to the pmessage event at the same time as the pmessage_buffer, it is always going to emit a string. ""subscribe"" (channel, count): Client will emit subscribe in response to a SUBSCRIBE command. Listeners are passed the channel name as channel and the new count of subscriptions for this client as count. ""psubscribe"" (pattern, count): Client will emit psubscribe in response to a PSUBSCRIBE command. Listeners are passed the original pattern as pattern, and the new count of subscriptions for this client as count. ""unsubscribe"" (channel, count): Client will emit unsubscribe in response to a UNSUBSCRIBE command. Listeners are passed the channel name as channel and the new count of subscriptions for this client as count. When count is 0, this client has left subscriber mode and no more subscriber events will be emitted. ""punsubscribe"" (pattern, count): Client will emit punsubscribe in response to a PUNSUBSCRIBE command. Listeners are passed the channel name as channel and the new count of subscriptions for this client as count. When count is 0, this client has left subscriber mode and no more subscriber events will be emitted. client.multi([commands]) MULTI commands are queued up until an EXEC is issued, and then all commands are run atomically by Redis. The interface returns an individual Multi object by calling client.multi(). If any command fails to queue, all commands are rolled back and none is going to be executed (For further information see the Redis transactions documentation). Multi.exec([callback]) client.multi() is a constructor that returns a Multi object. Multi objects share all of the same command methods as client objects do. Commands are queued up inside the Multi object until Multi.exec() is invoked. If your code contains an syntax error an EXECABORT error is going to be thrown and all commands are going to be aborted. That error contains a .errors property that contains the concrete errors. If all commands were queued successfully and an error is thrown by redis while processing the commands that error is going to be returned in the result array! No other command is going to be aborted though than the ones failing. You can either chain together MULTI commands as in the above example, or you can queue individual commands while still sending regular client command as in this example: In addition to adding commands to the MULTI queue individually, you can also pass an array of commands and arguments to the constructor: Multi.exec_atomic([callback]) Identical to Multi.exec but with the difference that executing a single command will not use transactions. Optimistic Locks Using multi you can make sure your modifications run as a transaction, but you can't be sure you got there first. What if another client modified a key while you were working with it's data? To solve this, Redis supports the WATCH command, which is meant to be used with MULTI: The above snippet shows the correct usage of watch with multi. Every time a watched key is changed before the execution of a multi command, the execution will return null. On a normal situation, the execution will return an array of values with the results of the operations. As stated in the snippet, failing the execution of a multi command being watched is not considered an error. The execution may return an error if, for example, the client cannot connect to Redis. An example where we can see the execution of a multi command fail is as follows: WATCH limitations Redis WATCH works only on whole key values. For example, with WATCH you can watch a hash for modifications, but you cannot watch a specific field of a hash. The following example would watch the keys foo and hello, not the field hello of hash foo: This limitation also applies to sets (you can not watch individual set members) and any other collections. client.batch([commands]) Identical to .multi() without transactions. This is recommended if you want to execute many commands at once but don't need to rely on transactions. BATCH commands are queued up until an EXEC is issued, and then all commands are run atomically by Redis. The interface returns an individual Batch object by calling client.batch(). The only difference between .batch and .multi is that no transaction is going to be used. Be aware that the errors are - just like in multi statements - in the result. Otherwise both, errors and results could be returned at the same time. If you fire many commands at once this is going to boost the execution speed significantly compared to firing the same commands in a loop without waiting for the result! See the benchmarks for further comparison. Please remember that all commands are kept in memory until they are fired. Monitor mode Redis supports the MONITOR command, which lets you see all commands received by the Redis server across all client connections, including from other client libraries and other computers. A monitor event is going to be emitted for every command fired from any client connected to the server including the monitoring client itself. The callback for the monitor event takes a timestamp from the Redis server, an array of command arguments and the raw monitoring string. Example: Extras Some other things you might find useful. client.server_info After the ready probe completes, the results from the INFO command are saved in the client.server_info object. The versions key contains an array of the elements of the version string for easy comparison. redis.print() A handy callback function for displaying return values when testing. Example: Multi-word commands To execute redis multi-word commands like SCRIPT LOAD or CLIENT LIST pass the second word as first parameter: client.duplicate([options][, callback]) Duplicate all current options and return a new redisClient instance. All options passed to the duplicate function are going to replace the original option. If you pass a callback, duplicate is going to wait until the client is ready and returns it in the callback. If an error occurs in the meanwhile, that is going to return an error instead in the callback. One example of when to use duplicate() would be to accommodate the connection- blocking redis commands BRPOP, BLPOP, and BRPOPLPUSH. If these commands are used on the same Redis client instance as non-blocking commands, the non-blocking ones may be queued up until after the blocking ones finish. Another reason to use duplicate() is when multiple DBs on the same server are accessed via the redis SELECT command. Each DB could use its own connection. client.sendCommand(command_name[, [args][, callback]]) All Redis commands have been added to the client object. However, if new commands are introduced before this library is updated or if you want to add individual commands you can use sendCommand() to send arbitrary commands to Redis. All commands are sent as multi-bulk commands. args can either be an Array of arguments, or omitted / set to undefined. redis.addCommand(command_name) Calling addCommand will add a new command to the prototype. The exact command name will be used when calling using this new command. Using arbitrary arguments is possible as with any other command. client.connected Boolean tracking the state of the connection to the Redis server. client.command_queue_length The number of commands that have been sent to the Redis server but not yet replied to. You can use this to enforce some kind of maximum queue depth for commands while connected. client.offline_queue_length The number of commands that have been queued up for a future connection. You can use this to enforce some kind of maximum queue depth for pre-connection commands. Commands with Optional and Keyword arguments This applies to anything that uses an optional [WITHSCORES] or [LIMIT offset count] in the redis.io/commands documentation. Example Performance Much effort has been spent to make Node Redis as fast as possible for common operations. Debugging To get debug output run your Node Redis application with NODE_DEBUG=redis. This is also going to result in good stack traces opposed to useless ones otherwise for any async operation. If you only want to have good stack traces but not the debug output run your application in development mode instead (NODE_ENV=development). Good stack traces are only activated in development and debug mode as this results in a significant performance penalty. Comparison: Standard stack trace: Debug stack trace: Contributing Please see the contributing guide. License This repository is licensed under the ""MIT"" license. See LICENSE."
416,A spinning activity indicatorspin.js An animated loading spinner No images No dependencies Highly configurable Resolution independent Uses CSS keyframe animations Works in all major browsers Includes TypeScript definitions Distributed as a native ES6 module MIT License Installation npm install spin.js Usage CSS TypeScript or JavaScript For an interactive demo and a list of all supported options please refer to the project's homepage.
1335,"A Spring Framework based, pragmatic style JavaEE application reference architecture. VJToolsJava SpringSide SpringSideSpring FrameworkPragmaticJavaEEJavaEE Utils - Java(). BootApi - Spring BootWeb Service, SOAAjax. BootWeb - Spring BootWeb, (). Showcase - . P2PP2P (JDK7.0+) quick-start.sh quick-start.bat modulesmaven BootApi http://localhost:8080/ Offical Site: http://springside.io Document: https://github.com/springside/springside4/wiki"
4454,"msysGit has been superseded by Git for Windows 2.xPlease note! Git for Windows 1.x was retired on August 18th, 2015, superseded by Git for Windows 2.x. The development environment of Git for Windows 2.x is no longer maintained in a monolithic Git repository but rather as the Git SDK, a friendly fork of MSys2 pre-configured to ease the development of Git for Windows. Build environment for Git for Windows 1.x This is the build environment -- also known as msysGit -- for Git for Windows. The easiest way is to install it via the net installer. This installer will clone our two repositories, including all the necessary components to build Git for Windows, and perform an initial build. The build environment msysGit brings a few components that are required to build Git: Bash, a Unix-type command-line shell. Quite a few components of Git itself are still shell scripts. Therefore, Bash is required to execute Git commands (see the output of cd /git && git ls-files \*.sh for a full list). the GNU C Compiler. Since we try to rely only on free software (apart from the Operating System, of course), we think it makes more sense to rely on GCC than on Visual Studio express. Also, it makes the maintenance burden lighter, as upstream Git also targets mainly GCC. GNU Make. Perl. Still required for a couple of Git components (see the output of cd /git && git ls-files \*.perl), most notably git svn. Tcl/Tk, a scripting language making it easy to implement cross-platform graphical user interfaces. We need this for gitk and git gui. cURL, a library implementing HTTP and FTP transport. many more libraries. some Unix programs required by the shell scripts in Git. The relationship between msysGit and Git for Windows Git for Windows is the software package that installs a minimal environment to run Git on Windows. It comes with a Bash (a Unix-type shell), with a Perl interpreter and with the Git executable and its dependencies. On the other hand, msysGit is the software package installing the build environment that can build Git for Windows. The easiest way is to install it via the net installer. The difference between MSys and MinGW The MinGW project's goal is to provide a way to compile native Windows binaries with no POSIX layer using the GNU C Compiler. However, at least the Bash needs a POSIX layer (most notably due to the absence of the fork() call on Windows). Therefore, MSys (the minimal system) is thrown in, offering the minimal system necessary to offer Bash (and Perl) functionality on Windows. Consequently, MSys ships with a POSIX layer (based on an old version of Cygwin) that is only used by the Bash and Perl, but not by anything compiled within that environment. Further information For more information and documentation, please have a look and enhance our Wiki. For code contributions and discussions, please see our mailing list."
2080,"Isomorphic flux implementationalt Check out the API Reference for full in-depth docs. For a high-level walk-through on flux, take a look at the Getting Started guide. What follows below applies only to the master branch of alt and not the latest distribution. Any questions? ask in the gitter room. Why you should be using Alt It is pure flux. Stores have no setters, the flow is unidirectional. Isomorphic and works with react-native. Actively maintained and being used in production. Extremely flexible and unopinionated in how you use flux. Create traditional singletons or use dependency injection. It is terse. No boilerplate. What does it look like? Alt Actions Store View Using the connectToStores util from alt-utils package (npm install alt-utils) or In the Wild Examples Airbnb Airpal Alt Notify Chrome Devtool Example Tests Github Example Isomorphic Alt Jumar's Tindahan Maple.js Webcomponents React Native Example React Router Example React Router Loopback React Webpack Rails Example React Webpack Altjs Example React Weather Shopping Cart Todo Typeahead Isomorphic React Examples Typescript Project Why did Social Tables choose Alt? Boilerplates Isomorphic Flux Boilerplate React + Webpack + Node Web-React Generator-React-Webpack-Alt Isomorphic Alt Generator Pure Flux + More Unidirectional data flow Stores have no setters Inversion of control Single central dispatcher All Stores receive the dispatch Read about the Principles of Flux. One really cool aspect of alt is that you can save snapshots of the entire application's state at any given point in time. This has many different use cases like: Time traveling through the state of your application. For fun and profit. Being able to debug from a broken state. Have your team send you the exact state the app was in when it crashed. Isomorphism. You save a snapshot that you send from the server to the client and then bootstrap back on the client. Rolling back to previous stable states. There are also many utils available which interface well with alt: ActionListener lets you listen to individual actions without having to create a store. AltContainer a higher-order container component that is your swiss army knife for React. AltIso addon that uses iso to render your application on both server and client. atomic enables your stores for atomic transactions. connectToStores a higher-order function that wraps your React components for store listening. decorators a collection of useful ES7 decorators for working with alt. DispatchRecorder lets you record all your dispatches and replay them back at a later time. FinalStore is a Store that you can listen to that only emits when all your other stores have received all their data. ImmutableUtil makes working with immutable-js easy. TimeTravel enhances your stores so they are able to travel through different states in time. Topical Guide First we install alt through npm. Although alt is also available through bower. The following topical guide covers on using alt as a singleton in a traditional flux way. We'll be referring back to this code a lot by using the alt reference declared. ES6 Alt is written in, and encourages ES6. It is completely optional but it is pleasant to write. You can use the es6 transpiler that comes with react courtesy of jstransform or you can use one of the other popular ES6 transpilers: babel or traceur. You won't need an es6-shim but you can use one for further goodies in your javascripts. Alt does depend on ES5 features, the good news is so does React. You can use es5-shim to support those pesky old browsers. Typescript Definitions and Support The typescript definitions for alt are located in the typings directory. This should be included in your project under typings/alt or whatever folder you use to manage your definitions files. You can import the dependencies react and es6-promises, easily with TSD. From here you can reference your typings as per usual with a reference tag . Check the alt-typescript-tutorial for more information and project examples. Using Typescript 1.5 you can import with the legacy syntax: Creating Actions Actions are the way you update state. They're kind of a big deal. alt.createActions :: Class -> Actions You return the data from your action that you wish to dispatch. If you want to run async in your actions then you simply return a function where the first argument is the dispatch: alt.createActions then returns an Object containing all the methods defined. You can then call your actions directly. Writing out actions that pass data through directly can get quite tedious so there's a shorthand for writing these what are essentially identity functions Remember, dispatch only takes one argument. Therefore, if you need to pass multiple arguments into a store you can use an Object. A shorthand function created in the constructor will pass through the multiple parameters as an Array There's even a shorthand for the shorthand if all you're doing is generating a list of actions Stores Stores are where you keep a part of your application's state. You can either define your stores as a class/constructor-prototype or as an Object. alt.createStore :: Class, string -> Store You can also use a regular old JavaScript Object to create your stores. This is more about aesthetic preference. If you're creating a store using a class/constructor then you also have the option of assigning your state values to your instance directly and then you're able to update them in place. Store instances returned by alt.createStore can be listened to for updates by calling listen. listen is meant to be used by your View components in order to await changes made to each store. It returns a function you can use to un-listen to your store. Alternatively, you can use the unlisten method. It takes in the same function you used for listen and unregisters it. Another important method is getState, which returns a copy of the current store's state. Important Note All defined methods in your Store class will not be available on the store instance. They are accessible within the class but not on the returned Object via alt.createStore. This ensures that stores have no direct setters and the state remains mutable only through actions keeping the flow unidirectional. If you want to attach public/static functions to your store the recommended method is to call the exportPublicMethods method from the constructor: An alternative is to declare the method as static, which will cause alt to expose the method on the store: Canceling An Event If you don't want the store to inform the view of an action you can call this.preventDefault() (or you can return false) from inside an action handler method. Constants I thought you said there were no constants? Well, yeah, sort of. The thing is, they're automagically created for you. Feel free to use them to bind your actions or use the method itself, whatever reads better in your opinion. Listening To Multiple Actions Using the function bindListeners you're able to specify which action handlers belong to which actions this way you have ultimate control over what gets called and handled. The function bindListeners is the inverse of bindAction. bindListeners takes an object of action handlers as keys and actions as a value. Alternatively, you can bind all the actions inside locationActions using the shortcut bindActions Actions who have a onCamelCasedAction method or an actionName method available in the store will be bound. In this example locationActions.updateCity will be handled by onUpdateCity. There is no difference between calling the action handler updateCity or onUpdateCity it's just a matter of aesthetic preference. Managing Store Data Dependencies waitFor is mostly an alias to Flux's Dispatcher waitFor. Here's an excerpt from the flux docs on what waitFor is designed for: As an application grows, dependencies across different stores are a near certainty. Store A will inevitably need Store B to update itself first, so that Store A can know how to update itself. We need the dispatcher to be able to invoke the callback for Store B, and finish that callback, before moving forward with Store A. To declaratively assert this dependency, a store needs to be able to say to the dispatcher, ""I need to wait for Store B to finish processing this action."" The dispatcher provides this functionality through its waitFor() method. You can use waitFor like so: You can also waitFor multiple stores by passing in an Array: this.waitFor([store1.dispatchToken, store2.dispatchToken]) Views Your choice of view isn't important to alt. What's important is to know how the view consumes the store's data, and that is via event listeners. In this example I'll be using React, but you're free to use your library of choice. Full Circle Restart the loop by making your views kick off new actions. Alt Features Snapshots takeSnapshot :: ?...string -> string Snapshots are a core component of alt. The idea is that at any given point in time you can takeSnapshot and have your entire application's state serialized for persistence, transferring, logging, or debugging. Taking a snapshot is as easy as calling alt.takeSnapshot(). It can also take an optional number of arguments as strings which correspond to the store names you would like to include in the snapshot. This allows you to take a snapshot of a subset of your app's data. Bootstrapping bootstrap :: string -> undefined Bootstrapping can be done as many times as you wish, but it is common to use when initializing your application. The alt.bootstrap() function takes in a snapshot (JSON string) you've saved and reloads all the state with that snapshot, no events will be emitted to your components during this process, so again, it's best to do this on init before the view has even rendered. If you need to emit a change event, you can use this.emitChange inside of your bootstrap life cycle method. Bootstrap is great if you're running an isomorphic app, or if you're persisting state to localstorage and then retrieving it on init later on. You can save a snapshot on the server side, send it down, and then bootstrap it back on the client. If you're bootstrapping then it is recommended you pass in a unique Identifier, name of the class is good enough, to createStore so that it can be referenced later for bootstrapping. Rollback rollback :: undefined If you've screwed up the state, or you just feel like rolling back you can call alt.rollback(). Rollback is pretty dumb in the sense that it's not automatic in case of errors, and it only rolls back to the last saved snapshot, meaning you have to save a snapshot first in order to roll back. Flushing flush :: string Flush takes a snapshot of the current state and then resets all the stores back to their original initial state. This is useful if you're using alt stores as singletons and doing server side rendering because of concurrency. In this particular scenario you would load the data in via bootstrap and then use flush to take a snapshot, render the data, and reset your stores so they are ready for the next request. Recycling recycle :: ?...string -> undefined If you wish to reset a particular, or all, store's state back to their original initial state you would call recycle. Recycle takes an optional number of arguments as strings which correspond to the store's names you would like reset. If no argument is provided then all stores are reset. Lifecycle Methods When bootstrapping, snapshotting, or recycling there are special methods you can assign to your store to ensure any bookeeping that needs to be done. You would place these in your store's constructor. bootstrap is called after the store has been bootstrapped. Here you can add some logic to take your bootstrapped data and manipulate it. init is called when the store is initialized as well as whenever a store is recycled. rollback is called whenever all the stores are rolled back. error is called whenever an error occurs in your store during a dispatch. You can use this listener to catch errors and perform any cleanup tasks. See all the lifecycle methods Single Dispatcher A single dispatcher instance is made available for listening to all events passing through. You can access this via the dispatcher property: alt.dispatcher and listening to all events is as easy as Each store has a reference to the dispatcher as well Flexibility You can choose to use alt in many ways just like you'd use flux. This means your asynchronous data fetching can live in the actions, or they can live in the stores. Stores may also be traditional singletons as in flux, or you can create an instance and have multiple store copies. This leads us into server side rendering. Server Side Rendering Alt was built with isomorphism in mind. This means that you can run full flux server-side and pick back up on the client-side. There are two options for using flux on the server: Keep stores as singletons, keep data loading synchronous, bootstrap, and flush. Create multiple instances of flux and inject the context into your app. Stores as Singletons With this approach your stores are singletons. Any actions that load data must be synchronous, meaning you can fetch your data outside of actions and stores, and once done you fire off a synchronous action which loads the store. Alternatively, you can gather all of your data, and once complete, you call bootstrap() which seeds all the stores with some initial data. Once you've completed loading the stores with data you call flush() which takes a snapshot to send to the client and then resets all the stores' state back to their initial state. This allows the stores to be ready for the next server request. Flux Instances Creating separate instances of flux rather than relying on singletons can help when building isomorphic applications. The problem with singletons is that you need to manage them by clearing out all their state and reloading them with new state on every request because requests happen concurrently. This isn't a problem if you already have your data and just need to load it into flux, or if you don't want to share your data fetching logic with the client -- in which case you can just load all your data at once on the server and render once that is all complete. Singletons only become a problem if you wish to share data fetching with client and server, don't want to use something like Render to define your data fetching at the component level, or if you have a really complex data fetching scheme where some fetches depend on the result of other ones. In these cases creating separate instances (or copies) keeps flux sandboxed to each request so other async requests won't mutate the state in the stores. Taking this approach means you're making the trade-off of injecting the flux instance into your application in order to retrieve the stores and use the actions. This approach is similar to how fluxible solves isomorphic applications. Creating a new alt instances is fairly simple. Picking back up on the client To help facilitate with isomorphism alt recommends you use iso, a helper function which serializes the data on the server into markup and then parses that data back into usable JavaScript on the client. Iso is a great complement to alt for a full-stack flux approach. Converting a flux application to alt Importing the chat project. Adding alt and removing boilerplate. Converting some actions and the last action. Converting the stores MessageStore, ThreadStore, and UnreadThreadStore. Finishing touches. Differences Example Flux has constants, the dispatcher is also pretty dumb as in it just takes what you passed in the action and pipes it through to the store. This is completely fine but not something you should be expected to write. The nice thing about constants is that you can easily grep for them in your application and see where all the actions are being called, with alt you get the same benefit without having to manage them. Before: Flux After: Alt TL;DR Isomorphic Pure Flux No constants No static string checking No giant switch statement Save state snapshots Rollbacks Bootstrap components on app load Light-weight and terse ES6 Syntax, code your actions and stores with classes Flexible No direct setters on stores Single dispatcher Global listening for debugging Small library License"
2765,"Software-Defined Networking tools for LXC (LinuX Containers)Pipework Software-Defined Networking for Linux Containers Pipework lets you connect together containers in arbitrarily complex scenarios. Pipework uses cgroups and namespace and works with ""plain"" LXC containers (created with lxc-start), and with the awesome Docker. Table of Contents generated with DocToc Things to note vCenter / vSphere / ESX / ESXi Virtualbox Docker LAMP stack with a private network between the MySQL and Apache containers Docker integration Peeking inside the private network Setting container internal interface Setting host interface name Using a different netmask Setting a default gateway Connect a container to a local physical interface Use MAC address to specify physical interface Let the Docker host communicate over macvlan interfaces Wait for the network to be ready Add the interface without an IP address Add a dummy interface DHCP DHCP Options Specify a custom MAC address Virtual LAN (VLAN) Control routes Support Open vSwitch Support InfiniBand IPoIB Cleanup Integrating pipework with other tools About this file Things to note vCenter / vSphere / ESX / ESXi If you use vCenter / VSphere / ESX / ESXi, set or ask your administrator to set Network Security Policies of the vSwitch as below: Promiscuous mode: Accept MAC address changes: Accept Forged transmits: Accept After starting the guest OS and creating a bridge, you might also need to fine-tune the br1 interface as follows: brctl stp br1 off (to disable the STP protocol and prevent the switch from disabling ports) brctl setfd br1 2 (to reduce the time taken by the br1 interface to go from blocking to forwarding state) brctl setmaxage br1 0 Virtualbox If you use VirtualBox, you will have to update your VM network settings. Open the settings panel for the VM, go the the ""Network"" tab, pull down the ""Advanced"" settings. Here, the ""Adapter Type"" should be pcnet (the full name is something like ""PCnet-FAST III""), instead of the default e1000 (Intel PRO/1000). Also, ""Promiscuous Mode"" should be set to ""Allow All"". If you don't do that, bridged containers won't work, because the virtual NIC will filter out all packets with a different MAC address. If you are running VirtualBox in headless mode, the command line equivalent of the above is modifyvm --nicpromisc1 allow-all. If you are using Vagrant, you can add the following to the config for the same effect: Note: it looks like some operating systems (e.g. CentOS 7) do not support pcnet anymore. You might want to use the virtio-net (Paravirtualized Network) interface with those. Docker Before using Pipework, please ask on the docker-user mailing list if there is a ""native"" way to achieve what you want to do without Pipework. In the long run, Docker will allow complex scenarios, and Pipework should become obsolete. If there is really no other way to plumb your containers together with the current version of Docker, then okay, let's see how we can help you! The following examples show what Pipework can do for you and your containers. LAMP stack with a private network between the MySQL and Apache containers Let's create two containers, running the web tier and the database tier: APACHE=$(docker run -d apache /usr/sbin/httpd -D FOREGROUND) MYSQL=$(docker run -d mysql /usr/sbin/mysqld_safe) Now, bring superpowers to the web tier: pipework br1 $APACHE 192.168.1.1/24 This will: create a bridge named br1 in the docker host; add an interface named eth1 to the $APACHE container; assign IP address 192.168.1.1 to this interface, connect said interface to br1. Now (drum roll), let's do this: pipework br1 $MYSQL 192.168.1.2/24 This will: not create a bridge named br1, since it already exists; add an interface named eth1 to the $MYSQL container; assign IP address 192.168.1.2 to this interface, connect said interface to br1. Now, both containers can ping each other on the 192.168.1.0/24 subnet. Docker integration Pipework can resolve Docker containers names. If the container ID that you gave to Pipework cannot be found, Pipework will try to resolve it with docker inspect. This makes it even simpler to use: docker run -name web1 -d apache pipework br1 web1 192.168.12.23/24 Peeking inside the private network Want to connect to those containers using their private addresses? Easy: ip addr add 192.168.1.254/24 dev br1 Voil! Setting container internal interface By default pipework creates a new interface eth1 inside the container. In case you want to change this interface name like eth2, e.g., to have more than one interface set by pipework, use: pipework br1 -i eth2 ... Note:: for InfiniBand IPoIB interfaces, the default interface name is ib0 and not eth1. Setting host interface name By default pipework will create a host-side interface with a fixed prefix but random suffix. If you would like to specify this interface name use the -l flag (for local): pipework br1 -i eth2 -l hostapp1 ... Using a different netmask The IP addresses given to pipework are directly passed to the ip addr tool; so you can append a subnet size using traditional CIDR notation. I.e.: pipework br1 $CONTAINERID 192.168.4.25/20 Don't forget that all containers should use the same subnet size; pipework is not clever enough to use your specified subnet size for the first container, and retain it to use it for the other containers. Setting a default gateway If you want outbound traffic (i.e. when the containers connects to the outside world) to go through the interface managed by Pipework, you need to change the default route of the container. This can be useful in some usecases, like traffic shaping, or if you want the container to use a specific outbound IP address. This can be automated by Pipework, by adding the gateway address after the IP address and subnet mask: pipework br1 $CONTAINERID 192.168.4.25/20@192.168.4.1 Connect a container to a local physical interface Let's pretend that you want to run two Hipache instances, listening on real interfaces eth2 and eth3, using specific (public) IP addresses. Easy! pipework eth2 $(docker run -d hipache /usr/sbin/hipache) 50.19.169.157/24 pipework eth3 $(docker run -d hipache /usr/sbin/hipache) 107.22.140.5/24 Note that this will use macvlan subinterfaces, so you can actually put multiple containers on the same physical interface. If you don't want to virtualize the interface, you can use the --direct-phys option to namespace an interface exclusively to a container without using a macvlan bridge. pipework --direct-phys eth1 $CONTAINERID 192.168.1.2/24 This is useful for assigning SR-IOV VFs to containers, but be aware of added latency when using the NIC to switch packets between containers on the same host. Use MAC address to specify physical interface In case you want to connect a local physical interface with a specific name inside the container, it will also rename the physical one, this behaviour is not idempotent: pipework --direct-phys eth1 -i container0 $CONTAINERID 0/0 # second call would fail because physical interface eth1 has been renamed We can use the interface MAC address to identify the interface the same way any time (udev networking rules use a similar method for interfaces persistent naming): pipework --direct-phys mac:00:f3:15:4a:42:c8 -i container0 $CONTAINERID 0/0 Let the Docker host communicate over macvlan interfaces If you use macvlan interfaces as shown in the previous paragraph, you will notice that the host will not be able to reach the containers over their macvlan interfaces. This is because traffic going in and out of macvlan interfaces is segregated from the ""root"" interface. If you want to enable that kind of communication, no problem: just create a macvlan interface in your host, and move the IP address from the ""normal"" interface to the macvlan interface. For instance, on a machine where eth0 is the main interface, and has address 10.1.1.123/24, with gateway 10.1.1.254, you would do this: ip addr del 10.1.1.123/24 dev eth0 ip link add link eth0 dev eth0m type macvlan mode bridge ip link set eth0m up ip addr add 10.1.1.123/24 dev eth0m route add default gw 10.1.1.254 Then, you would start a container and assign it a macvlan interface the usual way: CID=$(docker run -d ...) pipework eth0 $CID 10.1.1.234/24@10.1.1.254 Wait for the network to be ready Sometimes, you want the extra network interface to be up and running before starting your service. A dirty (and unreliable) solution would be to add a sleep command before starting your service; but that could break in ""interesting"" ways if the server happens to be a bit slower at one point. There is a better option: add the pipework script to your Docker image, and before starting the service, call pipework --wait. It will wait until the eth1 interface is present and in UP operational state, then exit gracefully. If you need to wait on an interface other than eth1, pass the -i flag like this: pipework --wait -i ib0 Add the interface without an IP address If for some reason you want to set the IP address from within the container, you can use 0/0 as the IP address. The interface will be created, connected to the network, and assigned to the container, but without configuring an IP address: pipework br1 $CONTAINERID 0/0 Add a dummy interface If for some reason you want a dummy interface inside the container, you can add it like any other interface. Just set the host interface to the keyword dummy. All other options - IP, CIDR, gateway - function as normal. pipework dummy $CONTAINERID 192.168.21.101/24@192.168.21.1 Of course, a gateway does not mean much in the context of a dummy interface, but there it is. DHCP You can use DHCP to obtain the IP address of the new interface. Just specify the name of the DHCP client that you want to use instead on an IP address; for instance: pipework eth1 $CONTAINERID dhclient You can specify the following DHCP clients: dhclient udhcpc dhcpcd dhcp The first three are ""normal"" DHCP clients. They have to be installed on your host for this option to work. The last one works differently: it will run a DHCP client in a Docker container sharing its network namespace with your container. This allows to use DHCP configuration without worrying about installing the right DHCP client on your host. It will use the Docker busybox image and its embedded udhcpc client. The value of $CONTAINERID will be provided to the DHCP client to use as the hostname in the DHCP request. Depending on the configuration of your network's DHCP server, this may enable other machines on the network to access the container using the $CONTAINERID as a hostname; therefore, specifying $CONTAINERID as a container name rather than a container id may be more appropriate in this use-case. You need three things for this to work correctly: obviously, a DHCP server (in the example above, a DHCP server should be listening on the network to which we are connected on eth1); a DHCP client (either udhcpc, dhclient or dhcpcp) must be installed on your Docker host (you don't have to install it in your containers, but it must be present on the host), unless you specify dhcp as the client, in which case the Docker busybox image should be available; the underlying network must support bridged frames. The last item might be particularly relevant if you are trying to bridge your containers with a WPA-protected WiFi network. I'm not 100% sure about this, but I think that the WiFi access point will drop frames originating from unknown MAC addresses; meaning that you have to go through extra hoops if you want it to work properly. It works fine on plain old wired Ethernet, though. Lease Renewal All of the DHCP options - udhcpc, dhcp, dhclient, dhcpcd - exit or are killed by pipework when they are done assigning a lease. This is to prevent zombie processes from existing after a container exits, but the dhcp client still exists. However, if the container is long-running - longer than the life of the lease - then the lease will expire, no dhcp client renews the lease, and the container is stuck without a valid IP address. To resolve this problem, you can cause the dhcp client to remain alive. The method depends on the dhcp client you use. dhcp: see the next section DHCP Options dhclient: use DHCP client dhclient-f udhcpc: use DHCP client udhcpc-f dhcpcd: not yet supported. Note: If you use this option you will be responsible for finding and killing those dhcp client processes in the future. pipework is a one-time script; it is not intended to manage long-running processes for you. In order to find the processes, you can look for pidfiles in the following locations: dhcp: see the next section DHCP Options dhclient: pidfiles in /var/run/dhclient.$GUESTNAME.pid udhcpc: pidfiles in /var/run/udhcpc.$GUESTNAME.pid dhcpcd: not yet supported $GUESTNAME is the name or ID of the guest as you passed it to pipework on instantiation. DHCP Options You can specify extra DHCP options to be passed to the DHCP client by adding them with a colon. For instance: pipework eth1 $CONTAINERID dhcp:-f This will tell Pipework to setup the interface using the DHCP client of the Docker busybox image, and pass -f as an extra flag to this DHCP client. This flag instructs the client to remain in the foreground instead of going to the background. Let's see what this means. Without this flag, a new container is started, in which the DHCP client is executed. The DHCP client obtains a lease, then goes to the background. When it goes to the background, the PID 1 in this container exits, causing the whole container to be terminated. As a result, the ""pipeworked"" container has its IP address, but the DHCP client has gone. On the up side, you don't have any cleanup to do; on the other, the DHCP lease will not be renewed, which could be problematic if you have short leases and the server and other clients don't validate their leases before using them. With this flag, a new container is started, it runs the DHCP client just like before; but when it obtains the lease, it remains in the foreground. As a result, the lease will be properly renewed. However, when you terminate the ""pipeworked"" container, you should also take care of removing the container that runs the DHCP client. This can be seen as an advantage if you want to reuse this network stack even if the initial container is terminated. Specify a custom MAC address If you need to specify the MAC address to be used (either by the macvlan subinterface, or the veth interface), no problem. Just add it as the command-line, as the last argument: pipework eth0 $(docker run -d haproxy) 192.168.1.2/24 26:2e:71:98:60:8f This can be useful if your network environment requires whitelisting your hardware addresses (some hosting providers do that), or if you want to obtain a specific address from your DHCP server. Also, some projects like Orchestrator rely on static MAC-IPv6 bindings for DHCPv6: pipework br0 $(docker run -d zerorpcworker) dhcp fa:de:b0:99:52:1c Note: if you generate your own MAC addresses, try remember those two simple rules: the lowest bit of the first byte should be 0, otherwise, you are defining a multicast address; the second lowest bit of the first byte should be 1, otherwise, you are using a globally unique (OUI enforced) address. In other words, if your MAC address is ?X:??:??:??:??:??, X should be 2, 6, a, or e. You can check Wikipedia if you want even more details. If you want a consistent MAC address across container restarts, but don't want to have to keep track of the messy MAC addresses, ask pipework to generate an address for you based on a specified string, e.g. the hostname. This guarantees a consistent MAC address: pipework eth0 <container> dhcp U:<some_string> pipework will take some_string and hash it using MD5. It will then take the first 40 bits of the MD5 hash, add those to the locally administered prefix of 0x02, and create a unique MAC address. For example, if your unique string is ""myhost.foo.com"", then the MAC address will always be 02:72:6c:cd:9b:8d. This is particularly useful in the case of DHCP, where you might want the container to stop and start, but always get the same address. Most DHCP servers will keep giving you a consistent IP address if the MAC address is consistent. Note: Setting the MAC address of an IPoIB interface is not supported. Virtual LAN (VLAN) If you want to attach the container to a specific VLAN, the VLAN ID can be specified using the [MAC]@VID notation in the MAC address parameter. Note: VLAN attachment is currently only supported for containers to be attached to either an Open vSwitch bridge or a physical interface. Linux bridges are currently not supported. The following will attach container zerorpcworker to the Open vSwitch bridge ovs0 and attach the container to VLAN ID 10. pipework ovsbr0 $(docker run -d zerorpcworker) dhcp @10 Control Routes If you want to add/delete/replace routes in the container, you can run any iproute2 route command via pipework. All you have to do is set the interface to be route, followed by the container ID or name, followed by the route command. Here are some examples. pipework route $CONTAINERID add 10.0.5.6/24 via 192.168.2.1 pipework route $CONTAINERID replace default via 10.2.3.5.78 Everything after the container ID (or name) will be run as an argument to ip route inside the container's namespace. Use the iproute2 man page. Control Rules If you want to add/delete/replace IP rules in the container, you can do the same thing with ip rule that you can with ip route. Specify the interface to be rule, followed by the container ID or name, followed by the rule command. Here are some examples, to specify a route table: pipework rule $CONTAINERID add from 172.19.0.2/32 table 1 pipework rule $CONTAINERID add to 172.19.0.2/32 table 1 Note that for these rules to work you first need to execute the following in your container: echo ""1 admin"" >> /etc/iproute2/rt_tables You can read more on using route tables, specifically to setup multiple NICs with different default gateways, here: https://kindlund.wordpress.com/2007/11/19/configuring-multiple-default-routes-in-linux/ Control tc If you want to use tc from within the container namespace, you can do so with the command pipework tc $CONTAINERID <tc_args>. Example, to simulate 30% packet loss on eth0 within the container: pipework tc $CONTAINERID qdisc add dev eth0 root netem loss 30% Support Open vSwitch If you want to attach a container to the Open vSwitch bridge, no problem. ovs-vsctl list-br ovsbr0 pipework ovsbr0 $(docker run -d mysql /usr/sbin/mysqld_safe) 192.168.1.2/24 If the ovs bridge doesn't exist, it will be automatically created Support InfiniBand IPoIB Passing an IPoIB interface to a container is supported. The IPoIB device is created as a virtual device, similarly to how macvlan devices work. The interface also supports setting a partition key for the created virtual device. The following will attach a container to ib0 pipework ib0 $CONTAINERID 10.10.10.10/24 The following will do the same but connect it to ib0 with pkey 0x8001 pipework ib0 $CONTAINERID 10.10.10.10/24 @8001 Gratuitous ARP If arping is installed, it will be used to send a gratuitous ARP reply to the container's neighbors. This can be useful if the container doesn't emit any network traffic at all, and seems unreachable (but suddenly becomes reachable after it generates some traffic). Note, however, that Ubuntu/Debian distributions contain two different arping packages. The one you want is iputils-arping. Cleanup When a container is terminated (the last process of the net namespace exits), the network interfaces are garbage collected. The interface in the container is automatically destroyed, and the interface in the docker host (part of the bridge) is then destroyed as well. Integrating pipework with other tools @dreamcat4 has built an amazing fork of pipework that can be integrated with other tools in the Docker ecosystem, like Compose or Crane. It can be used in ""one shot,"" to create a bunch of network connections between containers; it can run in the background as a daemon, watching the Docker events API, and automatically invoke pipework when containers are started, and it can also expose pipework itself through an API. For more info, check the dreamcat4/pipework image on the Docker Hub. About this file This README file is currently the only documentation for pipework. When updating it (specifically, when adding/removing/moving sections), please update the table of contents. This can be done very easily by just running: docker-compose up This will build a container with doctoc and run it to regenerate the table of contents. That's it!"
3402,"Rails application preloaderSpring Spring is a Rails application preloader. It speeds up development by keeping your application running in the background so you don't need to boot it every time you run a test, rake task or migration. Features Totally automatic; no need to explicitly start and stop the background process Reloads your application code on each run Restarts your application when configs / initializers / gem dependencies are changed Compatibility Ruby versions: MRI 2.5, MRI 2.6 Rails versions: 5.2, 6.0 (Spring is installed by default when you do rails new to generate your application) Spring makes extensive use of Process.fork, so won't be able to provide a speed up on platforms which don't support forking (Windows, JRuby). Walkthrough Setup Add Spring to your Gemfile: (Note: using gem ""spring"", git: ""..."" won't work and is not a supported way of using Spring.) It's recommended to 'springify' the executables in your bin/ directory: This generates a bin/spring executable, and inserts a small snippet of code into relevant existing executables. The snippet looks like this: On platforms where Spring is installed and supported, this snippet hooks Spring into the execution of commands. In other cases, the snippet will just be silently ignored and the lines after it will be executed as normal. If you don't want to prefix every command you type with bin/, you can use direnv to automatically add ./bin to your PATH when you cd into your application. Simply create an .envrc file with the command PATH_add bin in your Rails directory. Usage For this walkthrough I've generated a new Rails application, and run rails generate scaffold post name:string. Let's run a test: That wasn't particularly fast because it was the first run, so Spring had to boot the application. It's now running: The next run is faster: If we edit any of the application files, or test files, the changes will be picked up on the next run without the background process having to restart. This works in exactly the same way as the code reloading which allows you to refresh your browser and instantly see changes during development. But if we edit any of the files which were used to start the application (configs, initializers, your gemfile), the application needs to be fully restarted. This happens automatically. Let's ""edit"" config/application.rb: The application detected that config/application.rb changed and automatically restarted itself. If we run a command that uses a different environment, then that environment gets booted up: There's no need to ""shut down"" Spring. This will happen automatically when you close your terminal. However if you do want to do a manual shut down, use the stop command: From within your code, you can check whether Spring is active with if defined?(Spring). Removal To remove Spring: 'Unspring' your bin/ executables: bin/spring binstub --remove --all Remove spring from your Gemfile Deployment You must not install Spring on your production environment. To prevent it from being installed, provide the --without development test argument to the bundle install command which is used to install gems on your production machines: Commands rake Runs a rake task. Rake tasks run in the development environment by default. You can change this on the fly by using the RAILS_ENV environment variable. The environment is also configurable with the Spring::Commands::Rake.environment_matchers hash. This has sensible defaults, but if you need to match a specific task to a specific environment, you'd do it like this: rails console, rails generate, rails runner These execute the rails command you already know and love. If you run a different sub command (e.g. rails server) then Spring will automatically pass it through to the underlying rails executable (without the speed-up). Additional commands You can add these to your Gemfile for additional commands: spring-commands-rspec spring-commands-cucumber spring-commands-spinach spring-commands-testunit - useful for running Test::Unit tests on Rails 3, since only Rails 4 allows you to use rake test path/to/test to run a particular test/directory. spring-commands-parallel-tests - Adds the parallel_* commands from parallel_tests. spring-commands-teaspoon spring-commands-m spring-commands-rubocop spring-commands-rackup spring-commands-rack-console Use without adding to bundle If you don't want Spring-related code checked into your source repository, it's possible to use Spring without adding to your Gemfile. However, using Spring binstubs without adding Spring to the Gemfile is not supported. To use Spring like this, do a gem install spring and then prefix commands with spring. For example, rather than running bin/rake -T, you'd run spring rake -T. Temporarily disabling Spring If you're using Spring binstubs, but temporarily don't want commands to run through Spring, set the DISABLE_SPRING environment variable. Class reloading Spring uses Rails' class reloading mechanism (ActiveSupport::Dependencies) to keep your code up to date between test runs. This is the same mechanism which allows you to see changes during development when you refresh the page. However, you may never have used this mechanism with your test environment before, and this can cause problems. It's important to realise that code reloading means that the constants in your application are different objects after files have changed: Suppose you have an initializer config/initializers/save_user_class.rb like so: This saves off the first version of the User class, which will not be the same object as User after the code has been reloaded: So to avoid this problem, don't save off references to application constants in your initialization code. Using Spring with a containerized development environment As of Spring 1.7, there is some support for doing this. See this example repository for information about how to do it with Docker. Configuration Spring will read ~/.spring.rb and config/spring.rb for custom settings. Note that ~/.spring.rb is loaded before bundler, but config/spring.rb is loaded after bundler. So if you have any spring-commands-* gems installed that you want to be available in all projects without having to be added to the project's Gemfile, require them in your ~/.spring.rb. config/spring_client.rb is also loaded before bundler and before a server process is started, it can be used to add new top-level commands. Application root Spring must know how to find your Rails application. If you have a normal app everything works out of the box. If you are working on a project with a special setup (an engine for example), you must tell Spring where your app is located: Running code before forking There is no Spring.before_fork callback. To run something before the fork, you can place it in ~/.spring.rb or config/spring.rb or in any of the files which get run when your application initializes, such as config/application.rb, config/environments/*.rb or config/initializers/*.rb. Running code after forking You might want to run code after Spring forked off the process but before the actual command is run. You might want to use an after_fork callback if you have to connect to an external service, do some general cleanup or set up dynamic configuration. If you want to register multiple callbacks you can simply call Spring.after_fork multiple times with different blocks. Watching files and directories Spring will automatically detect file changes to any file loaded when the server boots. Changes will cause the affected environments to be restarted. If there are additional files or directories which should trigger an application restart, you can specify them with Spring.watch: By default Spring polls the filesystem for changes once every 0.2 seconds. This method requires zero configuration, but if you find that it's using too much CPU, then you can use event-based file system listening by installing the spring-watcher-listen gem. Quiet output To disable the ""Running via Spring preloader"" message which is shown each time a command runs: Environment variables The following environment variables are used by Spring: DISABLE_SPRING - If set, Spring will be bypassed and your application will boot in a foreground process SPRING_LOG - The path to a file which Spring will write log messages to. SPRING_TMP_PATH - The directory where Spring should write its temporary files (a pidfile and a socket). By default we use the XDG_RUNTIME_DIR environment variable, or else Dir.tmpdir, and then create a directory in that named spring-$UID. We don't use your Rails application's tmp/ directory because that may be on a filesystem which doesn't support UNIX sockets. SPRING_APPLICATION_ID - Used to identify distinct Rails applications. By default it is an MD5 hash of the current RUBY_VERSION, and the path to your Rails project root. SPRING_SOCKET - The path which should be used for the UNIX socket which Spring uses to communicate with the long-running Spring server process. By default this is SPRING_TMP_PATH/SPRING_APPLICATION_ID. SPRING_PIDFILE - The path which should be used to store the pid of the long-running Spring server process. By default this is related to the socket path; if the socket path is /foo/bar/spring.sock the pidfile will be /foo/bar/spring.pid. SPRING_SERVER_COMMAND - The command to run to start up the Spring server when it is not already running. Defaults to spring _[version]_ server --background. Troubleshooting If you want to get more information about what Spring is doing, you can run Spring explicitly in a separate terminal: Logging output will be printed to stdout. You can also send log output to a file with the SPRING_LOG environment variable."
3895,"The jQuery Mockjax Plugin provides a simple and extremely flexible interface for mocking or simulating ajax requests and responsesjQuery Mockjax: Ajax request mocking http://github.com/jakerella/jquery-mockjax/ There are some minor breaking changes in v2, so if you need an older version, please check the v1.x branch or the list of releases in Github. jQuery Mockjax provides request/response mocking for ajax requests using the jQuery API and provides all standard behaviors in the request/response flow. You may report any issues you may find in the github issue tracking. Table of Contents About Mockjax and Its History Basic Documentation API Methods Overview: Your First Mock Mockjax in Depth Detailed Request and Response Definition Defining a Request to Match Defining Multiple Requests Defining a Response Advanced Mocking Techniques Simulating Response Time and Latency Simulating HTTP Response Statuses Setting the Content-Type Setting Additional HTTP Response Headers Dynamically Generating Mock Definitions Accessing Request Headers Forced Simulation of Server Timeouts Dynamically Generating Mock Responses Data Types Performing Actions After Request Completion Globally Defining Mockjax Settings Setting a Global URL Namespace Removing Mockjax Handlers Miscellaneous Information jQuery Version Support Browsers Tested Using Mockjax in Other Ways (Node, require, browserify, etc) Logging Release History License About Mockjax and Its History Most backend developers are familiar with the concepts of mocking objects or stubbing in methods for unit testing. For those not familiar with mocking, it's the simulation of an interface or API for testing or integration development purposes. Mocking with front-end development though is still quite new. Mockjax gives front end developers the ability to define ajax requests that should be mocked out, as well as how those requests should be responded to. These mocks can be extremely simple or quite complex, representing the entire request-response workflow. At appendTo we developed a lot of applications which use RESTFUL web services, but much of the time those services are not yet created. We spec out the service contract and data format at the beginning of a project and develop the front-end interface against mock data while the back end team builds the production services. This plugin was originally developed by appendTo in March 2010 and the team has been using it in many projects since. Basic Documentation API Methods Mockjax consists of just a few methods, each listed below. You'll find plenty of examples in the sections below, but if you're looking for a specific option, checkout this list: Number $.mockjax(/* Object */ options) Sets up a mockjax handler for a matching request Returns that handler's index, can be used to clear individual handlers options: [Object] Defines the settings to use for the mocked request url: [String | RegExp] Specifies the url of the request that the data should be mocked for. If it is a string and contains any asterisks ( * ), they will be treated as a wildcard by translating to a regular expression. Any * will be replaced with .+. If you run into trouble with this shortcut, switch to using a full regular expression instead of a string and asterisk combination data: [Object | Function] In addition to the URL, match parameters type: [String] Specify what HTTP method to match, usually GET or POST. Case-insensitive, so get and post also work headers: [Object] Keys will be simulated as additional headers returned from the server for the request (NOTE: This is NOT used to match request headers!) status: [Number] An integer that specifies a valid server response code. This simulates a server response code statusText: [String] Specifies a valid server response code description. This simulates a server response code description responseTime: [Number] An integer that specifies a simulated network and server latency (in milliseconds). Default is 500. Setting this to 0 will minimize the simulated latency isTimeout: [Boolean] Determines whether or not the mock will force a timeout on the request contentType: [String] Specifies the content type for the response response: [Function] A function that accepts the request settings and allows for the dynamic setting of response settings (including the body of the response) upon each request (see examples below) responseText: [String] Specifies the mocked text, or a mocked object literal, for the request responseXML: [String] Specifies the mocked XML for the request proxy: [String] Specifies a path to a file, from which the contents will be returned for the request lastModified: [String] A date string specifying the mocked last-modified time for the request. This is used by $.ajax to determine if the requested data is new since the last request etag: [String] Specifies a unique identifier referencing a specific version of the requested data. This is used by $.ajax to determine if the requested data is new since the last request. (see HTTP_ETag) onAfterSuccess: [Function] A callback that will be called after the success method has been called, this is useful to check a condition after the call has been completed onAfterError: [Function] A callback that will be called after the error method has been called, this is useful to check a condition after the call has been completed onAfterComplete: [Function] Similar to onAfterSuccess, but will be executed after the complete method has been called Object $.mockjax.handler(/* Number */ id) Returns the mock request settings for the handler with the provided id. Be careful here, you're accessing the inner workings of the plugin, any changes to this object could be bad. Array $.mockjax.handlers() Returns the array of mock handlers. NOTE: This array is NOT modified when a handler is cleared, the cleared handler position is simply set to null. As such, the array length will only change when new mocks are added. Be careful here, you're accessing the inner workings of the plugin, any changes to the array could be very bad. void $.mockjax.clear([/* Number || String */ identifier]) If the identifier provided is a Number, the handler with that ID is cleared (that is, requests matching it will no longer do so, the handler is completely removed) If the identifier provided is a String, the handler with that matching URL is cleared. If no identifier is provided, ALL handlers are cleared, resetting Mockjax to its initial state Array<Object> $.mockjax.mockedAjaxCalls() Returns an array of all mocked ajax calls with each entry being the request settings object as passed into the $.mockjax() function If `$.mockjaxSettings.retainAjaxCalls is set to false, this will always be empty Array<Object> $.mockjax.unfiredHandlers() Returns an array of all mock handler settings that have not been used. In other words, if a handler has been used for a $.ajax() call then it will not appear in this array Array<Object> $.mockjax.unmockedAjaxCalls() Returns an array of all unmocked Ajax calls that were made. The array contains the settings object passed into $.ajax({...}) If `$.mockjaxSettings.retainAjaxCalls is set to false, this will always be empty void $.mockjax.clearRetainedAjaxCalls() Empties the arrays returned by $.mockjax.mockedAjaxCalls and $.mockjax.unmockedAjaxCalls Overview: Your First Mock Our first example will be for a simple REST service for a fortune app with the REST endpoint being /restful/fortune which returns the following JSON message: To pull the fortune into our page, we'd use the following HTML and jQuery code: At this point if we were to run this code it would fail since the REST service has yet to be implemented. This is where the benefit of the Mockjax plugin starts to pay off. The first step in using Mockjax is to include the plugin by just adding a regular script tag: Once you have that included, you can start intercepting Ajax requests and mocking the responses. So let's mock out the service by including the following code: Defining a JSON string inline requires a JSON.stringify() method to be available. For some browsers you may need to include json2.js, which is included in the lib folder. However, you could also simply provide an already stringified version of your JSON in the responseText property. If you plan on mocking xml responses, you may also have to include jquery.xmldom.js, which can also be found in the lib folder. Mockjax in Depth What Mockjax does at this point is replace the $.ajax() method with a wrapper that transparently checks the URL being requested. If the URL matches one defined by $.mockjax(), it intercepts the request and sets up a mock XMLHttpRequest object before executing the jQuery.ajax() handler. Otherwise, the request is handed back to the native $.ajax() method for normal execution. One benefit in this implementation detail is that by simulating the XMLHttpRequest object, the plugin continues to make use of jQuery's native ajax handling, so there are no concerns with implementing a custom Ajax workflow. As you write code to mock responses, there's great value in the fact that there are no modifications required to production code. The mocks can be transparently inserted. This provides easy integration into most frameworks by including the plugin and mock definitions through your build framework. It's also possible to include it at run time by listening for a query string flag and injecting the plugin and definitions. Now let's look at the various approaches to defining mocks as offered by the plugin. The sections below feature an extensive overview of the flexibility in Mockjax and creating responses. Data Types Available for Mocking jQuery is able to handle and parse Text, HTML, JSON, JSONP, Script and XML data formats and Mockjax is able to mock any of those formats. Two things to note: depending upon how you mock out JSON and JSONP you may need to include json2.js for the JSON.stringify() method (older browsers only, typically). Additionally if you mock XML inline, you'll need to include the xmlDOM plugin that transforms a string of XML into a DOM object. However, if you use the proxy approach outlined below then there should be no need to include either the JSON or XMLDOM plugins in any case. Detailed Request and Response Definition Defining a Request to Match The first thing you need to do when mocking a request is define the URL end-point to intercept and mock. As with our example above this can be a simple string: or contain a * as a wildcard: or a full regular expression: You can also match against the data option in addition to url: The data option may be a custom matching function returning true of false whether the data is expected or not: The data function is a recommended place for assertions. Return true and let a testing framework of choice do the rest: To capture URL parameters, use a capturing regular expression for the URL and a urlParams array to indicate, ordinally, the names of the paramters that will be captured: Defining Multiple Requests Since version 2.2 it is allowed to define several requests at once. $.mockjax([...]) returns a array of handlers' indexes. It is possible to reset handler by index. Read more in Removing Mockjax Handlers. Defining a Response The second step is to define the type and content of the response. The two main properties you will be dealing with are either responseText or responseXML. These properties mirror the native XMLHttpRequest object properties that are set during a live response. There are three different patterns for specifying the responses: Inline, Proxy, and Callback. Inline Responses A simple text response would be: A simple JSON response would be: Also note that a JSON response is really just a text response that jQuery will parse as JSON for you (and return a JSON object to the success and complete callbacks). A simple XML response would be: As you can see, if you have a significant amount of data being mocked this becomes unwieldy. So that brings us to the next pattern: the proxy. Proxy In this example below, the Mockjax plugin will intercept requests for /restful/api and redirect them to /mocks/data.json: The /mocks/data.json file can have any valid JSON content you want, and allows you to maintain that mock data in its own file for maintainability. Note: If you're testing your code with a poxy, it is best to run an actual web server for the tests. Simply loading test/index.html from the file system may result in the proxy file not being loaded correctly. We recommend using something like the http-server npm module. Callback In the final response pattern, we can define a callback function on the response property and have it set responseText or responseXML as needed: The default version of this callback is synchronous. If you provide both parameters to the callback function, you can use asynchronous code to set the dynamic response. Note that the callback is given the settings provided to the $.mockjax({...}) method merged with any Ajax settings defined by jQuery or your application. This allows you to thoroughly investigate the request before setting the response body (or headers). Advanced Mocking Techniques At this point we've looked at a series of basic mocking techniques with Mockjax and will now unpack some of the additional functionality contained in the plugin. Simulating Response Time and Latency Simulating network and server latency for a mock is as simple as adding a responseTime property to your mock definition: You can also use an interval for responseTime to randomize latency: Simulating HTTP Response Statuses It's also possible to simulate response statuses other than 200 (default for Mockjax) by simply adding a status property. The ability to provide an array of possible response statuses (from which the response for a given request will be randomly picked from): These forced error status codes will be handled just as if the server had returned the error: the error callback will get executed with the proper arguments. Setting the Content-Type You can set the content type to associate with the mock response, in the example below, we're setting a JSON content type. Setting Additional HTTP Response Headers Additional HTTP Response Headers may be provided by setting a key in the headers object literal: Dynamically Generating Mock Definitions In some situations, all of your REST calls are based upon a URL schema. Mockjax has the ability for you to specify a callback function that is handed the $.ajax request settings. The callback function may then either return false to allow the request to be handled natively, or return an object literal with relevant Mockjax parameters set. Below is an example that rewrites all Ajax requests to proxy to static mocks: Accessing Request Headers In some situations, you may need access to the request headers to determine matching or response bodies. To do this, you will need to specify a callback function that is handed the $.ajax request settings: Forced Simulation of Server Timeouts Because of the way Mockjax was implemented, it takes advantage of jQuery's internal timeout handling for requests. But if you'd like to force a timeout for a request you can do so by setting the isTimeout property to true: Dynamically Generating Mock Responses It's also possible to dynamically generate the response text upon each request by implementing a callback function on the response parameter: Data Types Many of the examples above mock a json response. You can also mock xml: (Don't forget that it's likely you'll need the xmlDOM library as well!) And html: Performing Actions After Request Completion If you need to perform some actions after a call has completed you can use one of the onAfter{Xxxxx} options. For example, to fire a method when a request completes (either successfully or not): Globally Defining Mockjax Settings It is also possible to define the global defaults for all Mockjax requests by overwriting the $.mockjaxSettings object. By default the settings are as follows: To overwrite a particular settings such as the default content-type, you would do the following: Setting a Global URL Namespace The namespace option in $.mockjaxSettings allows you to apply a prefix to all of your mocked urls, such as /api/v1. Then the following mock will match /api/v1/rest: AswillthefollowingRegExppattern: The global namespace option can also be overwritten on a particular mock. Note that the namespace prefix does not apply to proxies. Globally defining match order By default, Mockjax matches requests in registration order (mockjax considers the handlers registered first before handlers registered last). To reverse this behavior: Setting matchInRegistrationOrder to false lets you override previously defined handlers. Suppose you had: The default behavior is that Mockjax returns ""hello"", but with matchInRegistrationOrder set to false, Mockjax would return ""byebye"". This behavior allows you to override older handlers after they are initially set. Removing Mockjax Handlers If you need to reset the Mockjax handlers you've added, just call $.mockjax.clear(). This will NOT reset the $.mockjaxSettings! You can also clear individual mock handlers using their ID: Or you can clear a handler by the URL that it matches with either a String or RegExp: Miscellaneous Information jQuery Version Support We strive to ensure that Mockjax is tested on the furthest patch version of all minor (and major) versions of jQuery beginning with 1.5.2 going all the way through 3.x. In other words, we don't test 1.6.1, but rather 1.6.4 (the furthest patch version on the 1.6.x line). The QUnit tests in the /test directory include links to each version of jQuery tested in the header. Browsers Tested We use BrowserStack's awesome open source collaboration to test Mockjax in real browsers using VMs on their platform. We run all of our tests on the current versions of the major browsers below, plus the specific versions of Internet Explorer specified. Edge Firefox Chrome Safari Internet Explorer 11 (although it may work on IE 9 & 10) Each PR will run these tests using TravisCI for continuous integration before code is merged into master to ensure we do not introduce regressions. Using Mockjax in Other Ways You can use Mockjax as a Node module, with require.js, or with Browserify... and presumably in other ways as well. We have tests for each of the methods above. When using Mockjax as a Node module (including with Browserify), you must provide the module with the jQuery library and a window. Here is an example using a module intended for use as a ""browserified"" module: Logging Mockjax logs various pieces of information to the console (on window) in browsers, or to stdout in Node). You can customize various aspects of the logging to suit your needs. By default, only 'error', 'warn' or 'info' messages will be shown, but detailed information may be available in debug logs. Below are some common things you might need to do to get better logging information. Show different levels of log messages (Note that each level enables that level plus any lower number... thus setting logging to 2 also enables warnings and errors.) Implement a custom logger If you don't want to use the console object, you can pass in your own logging implementation with the logger setting. Note that your logger must either implement the debug, log, info, warn, and error methods, or you must also provide what methods map to the 5 levels (0 through 4). Your logger methods may receive any number of arguments to log out, either as strings or objects, similar to how the window.console object methods work. If you have a logger that uses different methods names, specify them in this array: Note that the first entry in this array (index 0) will be errors while the last entry will be verbose output. Anything beyond index 4 will be ignored. What about the old log setting? This was an undocumented feature whereby you could provide a log method using $.mockjaxSettings, however, it is no longer used internally. This undocumented option is now deprecated, and while it will work, log messages of ALL levels will be sent to it. If you have no idea what we're talking about... good! Don't worry about it. The proper way to implement your own logger is via $.mockjaxSettings.logger. Release History Please read the CHANGELOG for a list of changes per release. Note that all releases are tagged in Github for easy reference, the master branch should not be considered a stable release! License Copyright (c) 2014 Jordan Kasper, formerly appendTo NOTE: This repository was taken over by Jordan Kasper (@jakerella) October, 2014 Dual licensed under the MIT or GPL licenses: http://opensource.org/licenses/MIT http://www.gnu.org/licenses/gpl-2.0.html Troubleshooting If mockjax appears to be behaving unexpectedly, be sure to check the console logs for warnings. Contributing We welcome any contributions by the community, whether in the form of a Pull Request, issue submission and comments, or just sharing on social media! If you want to contribute code to the project, please read our Contribution guidelines to see what you need to do to get your Pull Request ready for merging."
177,"A powerful Android chart view / graph view library, supporting line- bar- pie- radar- bubble- and candlestick charts as well as scaling, panning and animations.:zap: A powerful & easy to use chart library for Android :zap: Charts is the iOS version of this library Table of Contents Quick Start Gradle Maven Documentation Examples Questions Donate Social Media More Examples License Creators Gradle Setup Maven Setup Documentation :notebook_with_decorative_cover: See the documentation for examples and general use of MPAndroidChart. See the javadocs for more advanced documentation. Examples :eyes: Download the MPAndroidChart Example App or look at the source code. Questions & Issues :thinking: This repository's issue tracker is only for bugs and feature requests. The maintainers ask that you refrain from asking questions about how to use MPAndroidChart through the issue tracker. Please read the documentation first, then ask all your questions on stackoverflow.com for the fastest answer. Donations :heart: This project needs you! If you would like to support this project's further development, the creator of this project or the continuous maintenance of this project, feel free to donate. Your donation is highly appreciated (and I love food, coffee and beer). Thank you! My Bitcoin Wallet (Bitcoin only) 1G8G6tqQ3oh38BvDH3xq8o6gGVMvBTkcUg My Ethereum Wallet (Ethereum only) 0x04ef098bf9f91871391363e3caf791afa3adc39b Lightning Network (tippin.me) PayPal Donate 5 $: Thank's for creating this project, here's a coffee (or some beer) for you! Donate 10 $: Wow, I am stunned. Let me take you to the movies! Donate 15 $: I really appreciate your work, let's grab some lunch! Donate 25 $: That's some awesome stuff you did right there, dinner is on me! Or you can also choose what you want to donate, all donations are awesome! Social Media :fire: If you like this library, please tell others about it :two_hearts: :two_hearts: If you like, you can follow me on Twitter @PhilippJahoda. More Examples :+1: LineChart (with legend, simple design) LineChart (with legend, simple design) LineChart (cubic lines) LineChart (gradient fill) BarChart (with legend, simple design) BarChart (grouped DataSets) Horizontal-BarChart Combined-Chart (bar- and linechart in this case) PieChart (with selection, ...) ScatterChart (with squares, triangles, circles, ... and more) CandleStickChart (for financial data) BubbleChart (area covered by bubbles indicates the yValue) RadarChart (spider web chart) License :page_facing_up: Copyright 2020 Philipp Jahoda Licensed under the Apache License, Version 2.0 (the ""License""); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License. Special Thanks :heart: These people rock! danielgindi - Daniel Gindi mikegr - Michael Greifeneder tony - Tony almic - Mick A. jitpack.io - JitPack.io"
3983,"It's a small library to provide the I18n translations on the Javascript. It comes with Rails support. It's a small library to provide the Rails I18n translations on the JavaScript. Features: Pluralization Date/Time localization Number localization Locale fallback Asset pipeline support Lots more! :) Version Notice The main branch (including this README) is for latest 3.0.0 instead of 2.x. Usage Installation Rails app Add the gem to your Gemfile. Rails with webpacker If you're using webpacker, you may need to add the dependencies to your client with: For more details, see: - this gist - https://github.com/fnando/i18n-js/issues/597 Rails app with Asset Pipeline If you're using the asset pipeline, then you must add the following line to your app/assets/javascripts/application.js. Rails app without Asset Pipeline First, put this in your application.html (layout file). Then get the JS files following the instructions below. There are two ways to get translations.js (For Rails app without Asset Pipeline). This translations.js file can be automatically generated by the I18n::JS::Middleware. Just add config.middleware.use I18n::JS::Middleware to your config/application.rb file. If you can't or prefer not to generate this file, you can move the middleware line to your config/environments/development.rb file and run rake i18n:js:export before deploying. This will export all translation files, including the custom scopes you may have defined on config/i18n-js.yml. If I18n.available_locales is set (e.g. in your Rails config/application.rb file) then only the specified locales will be exported. Current version of i18n.js will also be exported to avoid version mismatching by downloading. Export Configuration (For translations) Exported translation files generated by I18n::JS::Middleware or rake i18n:js:export can be customized with config file config/i18n-js.yml (use rails generate i18n:js:config to create it). You can even get more files generated to different folders and with different translations to best suit your needs. The config file also affects developers using Asset Pipeline to require translations. Except the option file, since all translations are required by adding //= require i18n/translations. Examples: If only is omitted all the translations will be saved. Also, make sure you add that initial *; it specifies that all languages will be exported. If you want to export only one language, you can do something like this: Optionally, you can auto generate a translation file per available locale if you specify the %{locale} placeholder. You can also include ERB in your config file. You are able to exclude certain phrases or whole groups of phrases by specifying the YAML key(s) in the except configuration option. The outputted JS translations file (exported or generated by the middleware) will omit any keys listed in except configuration param: Export Configuration (For other things) I18n::JS.config_file_path Expected Type: String Default: config/i18n-js.yml Behaviour: Try to read the config file from that location I18n::JS.export_i18n_js_dir_path Expected Type: String Default: public/javascripts Behaviour: Any String: considered as a relative path for a folder to Rails.root and export i18n.js to that folder for rake i18n:js:export Any non-String (nil, false, :none, etc): Disable i18n.js exporting I18n::JS.sort_translation_keys Expected Type: Boolean Default: true Behaviour: Sets whether or not to deep sort all translation keys in order to generate identical output for the same translations Set to true to ensure identical asset fingerprints for the asset pipeline You may also set export_i18n_js and sort_translation_keys in your config file, e.g.: To find more examples on how to use the configuration file please refer to the tests. Fallbacks If you specify the fallbacks option, you will be able to fill missing translations with those inside fallback locale(s). Default value is true. Examples: This will enable merging fallbacks into each file. (set to false to disable). If you use I18n with fallbacks, the fallbacks defined there will be used. Otherwise I18n.default_locale will be used. Here, the specified locale :de will be used as fallback for all locales. Fallbacks defined will be used, if not defined (e.g. :pl) I18n.fallbacks or I18n.default_locale will be used. Setting the option to :default_locale will enforce the fallback to use the I18n.default_locale, ignoring I18n.fallbacks. Examples: You must disable this feature by setting the option to false. To find more examples on how to use the configuration file please refer to the tests. Namespace Setting the namespace option will change the namespace of the output Javascript file to something other than I18n. This can be useful in no-conflict scenarios. Example: will create: Adding prefix & suffix to the translations file(s) Setting the prefix: ""import I18n from 'i18n-js';\n"" option will add the line at the beginning of the resultant translation file. This can be useful to use this gem with the i18n-js npm package, which is quite useful to use it with webpack. The user should provide the semi-colon and the newline character if needed. For example: will create: suffix option is added in https://github.com/fnando/i18n-js/pull/561. It's similar to prefix so won't explain it in details. Pretty Print Set the pretty_print option if you would like whitespace and indentation in your output file (default: false) Javascript Deep Merge (:js_extend option) By default, the output file Javascript will call the I18n.extend method to ensure that newly loaded locale files are deep-merged with any locale data already in memory. To disable this either globally or per-file, set the js_extend option to false Vanilla JavaScript Just add the i18n.js file to your page. You'll have to build the translations object by hand or using your favorite programming language. More info below. Via NPM with webpack and CommonJS Add the following line to your package.json dependencies where version is the version you want: Run npm install then use via Setting up You don't need to set up a thing. The default settings will work just okay. But if you want to split translations into several files or specify contexts, you can follow the rest of this setting up section. Set your locale is easy as NOTE: You can now apply your configuration before I18n is loaded like this: In practice, you'll have something like the following in your application.html.erb: You can use translate your messages: You can also interpolate values: You can set default values for missing scopes: You can also provide a list of default fallbacks for missing scopes: Default values must be provided as an array of hashes where the key is the type of translation desired, a scope or a message. The translation returned will be either the first scope recognized, or the first message defined. The translation will fallback to the defaultValue translation if no scope in defaults matches and if no default of type message is found. Translation fallback can be enabled by enabling the I18n.fallbacks option: By default missing translations will first be looked for in less specific versions of the requested locale and if that fails by taking them from your I18n.defaultLocale. Custom fallback rules can also be specified for a particular language. There are three different ways of doing it so: Translation Missing Behaviour Control By default a missing translation will be displayed as [missing ""name of scope"" translation] While you are developing or if you do not want to provide a translation in the default language you can set this will take the last section of your scope and guess the intended value. Camel case becomes lower cased text and underscores are replaced with space questionnaire.whatIsYourFavorite_ChristmasPresent becomes ""what is your favorite Christmas present"" Option missingTranslationPrefix In order to still detect untranslated strings, you can set I18n.missingTranslationPrefix to something like: And result will be: This will help you doing automated tests against your localisation assets. Customize return when translation entry missing Some people prefer returning null/undefined for missing translation: Option defaultSeparator (global) / separator (local) Default separator of translation key is . (dot) Meaning I18n.t(""scope.entry"") would search for translation entry I18n.translations[locale].scope.entry Using a different separator can be done either globally or locally. Globally: I18n.defaultSeparator = newSeparator Locally: I18n.t(""full_sentences|Server Busy. Please retry later"", {separator: '|'}) Pluralization Pluralization is possible as well and by default provides English rules: The sample above expects the following translation: NOTE: Rails I18n recognizes the zero option. If you need special rules just define them for your language, for example Russian, just add a new pluralizer: You can find all rules on https://unicode-org.github.io/cldr-staging/charts/37/supplemental/language_plural_rules.html. If you're using the same scope over and over again, you may use the scope option. You can also provide an array as scope. Number formatting Similar to Rails helpers, you have localized number and currency formatting. To have more control over number formatting, you can use the I18n.toNumber, I18n.toPercentage, I18n.toCurrency and I18n.toHumanSize functions. The toNumber and toPercentage functions accept the following options: precision: defaults to 3 separator: defaults to . delimiter: defaults to , strip_insignificant_zeros: defaults to false See some number formatting examples: The toCurrency function accepts the following options: precision: sets the level of precision separator: sets the separator between the units delimiter: sets the thousands delimiter format: sets the format of the output string unit: sets the denomination of the currency strip_insignificant_zeros: defaults to false sign_first: defaults to true You can provide only the options you want to override: The toHumanSize function accepts the following options: precision: defaults to 1 separator: defaults to . delimiter: defaults to """" strip_insignificant_zeros: defaults to false format: defaults to %n%u scope: defaults to """" Date formatting You can also add placeholders to the date format: If you prefer, you can use the I18n.toTime and I18n.strftime functions to format dates. The accepted formats for I18n.strftime are: %a - The abbreviated weekday name (Sun) %A - The full weekday name (Sunday) %b - The abbreviated month name (Jan) %B - The full month name (January) %c - The preferred local date and time representation %d - Day of the month (01..31) %-d - Day of the month (1..31) %H - Hour of the day, 24-hour clock (00..23) %-H/%k - Hour of the day, 24-hour clock (0..23) %I - Hour of the day, 12-hour clock (01..12) %-I/%l - Hour of the day, 12-hour clock (1..12) %m - Month of the year (01..12) %-m - Month of the year (1..12) %M - Minute of the hour (00..59) %-M - Minute of the hour (0..59) %p - Meridian indicator (AM or PM) %P - Meridian indicator (am or pm) %S - Second of the minute (00..60) %-S - Second of the minute (0..60) %w - Day of the week (Sunday is 0, 0..6) %y - Year without a century (00..99) %-y - Year without a century (0..99) %Y - Year with century %z/%Z - Timezone offset (+0545) Check out spec/*.spec.js files for more examples! Using pluralization and number formatting together Sometimes you might want to display translation with formatted number, like adding thousand delimiters to displayed number You can do this: Output should be 1,000 points Using multiple exported translation files on a page. This method is useful for very large apps where a single contained translations.js file is not desirable. Examples would be a global translations file and a more specific route translation file. Rails without asset pipeline Setup your config/i18n-js.yml to have multiple files and try to minimize any overlap. When rake i18n:js:export is executed it will create 3 translations files that can be loaded via the javascript_include_tag Add the javascript_include_tag to your layout and to any route specific files that will require it. and in the route specific Make sure that you add these files to your config/application.rb Using require.js / r.js To use this with require.js we are only going to change a few things from above. In your config/i18n-js.yml we need to add a better location for the i18n to be exported to. You want to use this location so that it can be properly precompiled by r.js. In your config/require.yml we need to add a map, shim all the translations, and include them into the appropriate modules When rake assets:precompile is executed it will optimize the translations into the correct modules so they are loaded with their assigned module, and loading them with requirejs is as simple as requiring any other shim. (optional) As an additional configuration we can make a task to be run before the requirejs optimizer. This will allow any automated scripts that run the requirejs optimizer to export the strings before we run r.js. Using I18n.js with other languages (Python, PHP, ...) The JavaScript library is language agnostic; so you can use it with PHP, Python, [your favorite language here]. The only requirement is that you need to set the translations attribute like following: Known Issues Missing translations in precompiled file(s) after adding any new locale file Due to the design of sprockets: depend_on only takes file paths, not directory paths registered preprocessors are only run when the fingerprint of any asset file, including .erb files, is changed This means that new locale files will not be detected, and so they will not trigger a i18n-js refresh. There are a few approaches to work around this: You can force i18n-js to update its translations by completely clearing the assets cache. Use one of the following: These commands will remove all fingerprinted assets, and you will have to recompile them with or similar commands. If you are precompiling assets on the target machine(s), cached pages may be broken by this, so they will need to be refreshed. You can change something in a different locale file. Finally, you can change config.assets.version. Note: See issue #213 for more details and discussion of this issue. Translations in JS are not updated when Sprockets not loaded before this gem The ""rails engine"" declaration will try to detect existence of ""sprockets"" before adding the initailizer If sprockets is loaded after this gem, the preprocessor for making JS translations file cache to depend on content of locale files will not be hooked. So ensure sprockets is loaded before this gem by moving the entry of sprockets in the Gemfile or adding ""require"" statements for sprockets somewhere. Note: See issue #404 for more details and discussion of this issue. JS I18n.toCurrency & I18n.toNumber cannot handle large integers The above methods use toFixed and it only supports 53 bit integers. Ref: http://2ality.com/2012/07/large-integers.html Feel free to find & discuss possible solution(s) at issue #511 Only works with Simple backend If you set I18n.backend to something other than the default Simple backend, you will likely get an exception like this: For now, i18n-js is only compatible with the Simple backend. If you need a more sophisticated backend for your rails application, like I18n::Backend::ActiveRecord, you can setup i18n-js to get translations from a separate Simple backend, by adding the following in an initializer: This will use your backend with the default Simple backend as fallback, while i18n-js only sees and uses the simple backend. This means however, that only translations from your static locale files will be present in JavaScript. If you do cannot use a Chain-Backend for some reason, you can also set However, the automatic reloading of translations in developement will not work in this case. This is because Rails calls I18n.reload! for each request in development, but reload! will not be called on I18n::JS.backend, since it is a different object. One option would be to patch I18n.reload! in an initializer: See issue #428 for more details and discussion of this issue. Maintainer Nando Vieira - http://nandovieira.com Contributing Once you've made your great commits: Fork I18n.js Create a branch with a clear name Make your changes (Please also add/change spec, README and CHANGELOG if applicable) Push changes to the created branch Create an Pull Request That's it! Please respect the indentation rules and code style. And use 2 spaces, not tabs. And don't touch the versioning thing. Running tests You can run I18n tests using Node.js or your browser. To use Node.js, install the jasmine-node library: $ npm install jasmine-node Then execute the following command from the lib's root directory: $ npm test To run using your browser, just open the spec/js/specs.html file. You can run both Ruby and JavaScript specs with rake spec. License (The MIT License) Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the 'Software'), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED 'AS IS', WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
763,"A jQuery plugin for inflating web typeFitText.js, a jQuery plugin for inflating web type FitText makes font-sizes flexible. Use this plugin on your responsive design for ratio-based resizing of your headlines. How it works Here is a simple FitText setup: Your text should now fluidly resize, by default: Font-size = 1/10th of the element's width. The Compressor If your text is resizing poorly, you'll want to turn tweak up/down ""The Compressor"". It works a little like a guitar amp. The default is 1. This will hopefully give you a level of ""control"" that might not be pixel perfect, but resizes smoothly & nicely. minFontSize & maxFontSize FitText now allows you to specify two optional pixel values: minFontSize and maxFontSize. Great for situations when you want to preserve hierarchy. CSS FAQ :warning: Run FitText before anything that hides the element you're trying to size (e.g. before Carousels, Scrollers, Accordions, Tabs, etc). Hiding an element's container removes its width. It can't resize without a width. :warning: Make sure your container has a width! display: inline elements don't have a width. Use display: block OR display: inline-block+ a specified width (i.e. width: 100%). position:absolute elements need a specified width as well. Tweak until you like it. Set a No-JS fallback font-size in your CSS. :new: If your text is full width, you might want to NOT use FitText and just use CSS vw units instead. Supported in all major browsers. Don't use jQuery? That's okay. Check out these handy non-jQuery versions maintained by other people. non-jQuery FitText from @adactio Angular.js FitText.js from @patrickmarabeas AMP-HTML FitText FitText UMD by @peacechen Changelog v 1.2 - Added onorientationchange event v 1.1 - FitText now ignores font-size and has minFontSize & maxFontSize options v 1.0.1 - Fix for broken font-size. v 1.0 - Initial Release In Use: Trent Walton If you want more exact fitting text, there are plugins for that! We recommend checking out BigText by Zach Leatherman or SlabText by Brian McAllister. Download, Fork, Commit. If you think you can make this better, please Download, Fork, & Commit. We'd love to see your ideas."
907,"A simple micro-library for defining and dispatching keyboard shortcuts. It has no dependencies.keymaster.js Keymaster is a simple micro-library for defining and dispatching keyboard shortcuts in web applications. It has no dependencies. Its a work in progress (e.g. beta), so spare me your nerdrage and instead contribute! Patches are welcome, but they are not guaranteed to make it in. Usage Include keymaster.js in your web app*, by loading it as usual: Keymaster has no dependencies and can be used completely standalone. It should not interfere with any JavaScript libraries or frameworks. *Preferably use a minified version that fits your workflow. You can run make to have UglifyJS (if you have it installed) create a keymaster.min.js file for you. Defining shortcuts One global method is exposed, key which defines shortcuts when called directly. The handler method is called with two arguments set, the keydown event fired, and an object containing, among others, the following two properties: shortcut: a string that contains the shortcut used, e.g. ctrl+r scope: a string describing the scope (or all) Supported keys Keymaster understands the following modifiers: , shift, option, , alt, ctrl, control, command, and . The following special keys can be used for shortcuts: backspace, tab, clear, enter, return, esc, escape, space, up, down, left, right, home, end, pageup, pagedown, del, delete and f1 through f19. Modifier key queries At any point in time (even in code other than key shortcut handlers), you can query the key object for the state of any keys. This allows easy implementation of things like shift+click handlers. For example, key.shift is true if the shift key is currently pressed. Other key queries At any point in time (even in code other than key shortcut handlers), you can query the key object for the state of any key. This is very helpful for game development using a game loop. For example, key.isPressed(77) is true if the M key is currently pressed. You can also get these as an array using... Scopes If you want to reuse the same shortcut for separate areas in your single page app, Keymaster supports switching between scopes. Use the key.setScope method to set scope. Filter key presses By default, when an INPUT, SELECT or TEXTAREA element is focused, Keymaster doesn't process any shortcuts. You can change this by overwriting key.filter with a new function. This function is called before Keymaster processes shortcuts, with the keydown event as argument. If your function returns false, then the no shortcuts will be processed. Here's the default implementation for reference: If you only want some shortcuts to work while in an input element, you can change the scope in the key.filter function. Here's an example implementation, setting the scope to either 'input' or 'other'. Don't forget to return true so the any shortcuts get processed. However a more robust way to handle this is to use proper focus and blur event handlers on your input element, and change scopes there as you see fit. noConflict mode You can call to remove the function from global scope and restore whatever was defined to before Keymaster was loaded. Calling will return the Keymaster function. Unbinding shortcuts Similar to defining shortcuts, they can be unbound using key.unbind. Notes Keymaster should work with any browser that fires keyup and keydown events, and is tested with IE (6+), Safari, Firefox and Chrome. See http://madrobby.github.com/keymaster/ for a live demo. CoffeeScript If you're using CoffeeScript, configuring key shortcuts couldn't be simpler: Contributing To contribute, please fork Keymaster, add your patch and tests for it (in the test/ folder) and submit a pull request. TODOs Finish test suite Keymaster is (c) 2011-2013 Thomas Fuchs and may be freely distributed under the MIT license. See the MIT-LICENSE file."
4329,"Library providing easy-to-use interface for displaying tree structures on iOS and tvOS.RATreeView (iOS 7.0+, tvOS 9.0+) Project created and maintained by Rafa Augustyniak. You can find me on twitter (@RaAugustyniak). Introduction iOS | tvOS :-------------------------:|:-------------------------: | RATreeView is a class designed to provide easy and pleasant way to work with tree views on iOS and tvOS. It works as a wrapper for the UITableView, defining its own delegate and data source methods which make working with tree data structures really easy. RATreeView is highly customizable and has a lot of features. Installation CocoaPods CocoaPods is the recommended way to add RATreeView to your project. Add additional entry to your Podfile. Install Pod(s) running pod install command. Include RATreeView using #import <RATreeView.h>. Source files Downloaded the latest version of the library using link. Copy content of the downloaded (and unzipped) zip file into your project by dragging it into Project's navigator files structure. Requirements Xcode 5 iOS 7 or newer/tvOS 9 or newer Usage Check out the demo for example usage of library. Make sure you read the RATreeView documentation on Cocoa Docs. Basics Add following import in file of your project when you want to use RATreeView: Simplest way to initialize and configure RATreeView: Implement required methods of the RATreeView's data source: Adding Pull to Refresh control Adding pull to refresh gesture is really easy using RATreeView and standard UIRefreshControl control. Documentation Documentation is available on CocoaPods. TODO Better delegate callbacks in case of recursive collapse and expand operations. Improved documentation. Unit tests. Re-order rows feature. Author RATreeView was created by Rafa Augustyniak. You can find me on twitter (@RaAugustyniak). Release Notes Information about newer versions of the library can be found in the releases section of the repository. Version 1.0.2 - Fixed bug in select and deselect operations. - Fixed bug in recursive expand operation (via @Arrnas). Version 1.0.1 - Fixed bug in recursive expand operation. Version 1.0.0 Improved performance. Added recursive expand operation. It can be performed by using expandRowForItem: expandChildren:withRowAnimation: method. Default behavior is non recursive expand. Added recursive collapse operation. It can be performed by using collapseRowForItem: expandChildren:withRowAnimation: method. Default behavior is non recursive collapse. Fixed bug in itemForRowAtPoint: method when passed point isn't inside any cell. Version 0.9.2 Fixed bug in endUpdates method. Version 0.9.1 Fixed behaviour of treeView:willSelectRowForItem: delegate method. Version 0.9.0 Added possiblity to change content of the RATreeView dynamically. Possible row operations: additions deletions repositions Added additional 'cell accessing' methods. Removed RATreeNodeInfo class. Added additional instance methods in RATreeView which substitute functionality provided by RATreeNodeInfo class. Bug fixes. License MIT licensed, Copyright (c) 2014 Rafa Augustyniak, @RaAugustyniak"
4409,"Deep Convolutional Generative Adversarial NetworksUnsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks Alec Radford, Luke Metz, Soumith Chintala All images in this paper are generated by a neural network. They are NOT REAL. Full paper here: http://arxiv.org/abs/1511.06434 Other implementations of DCGAN Torch Chainer TensorFlow Summary of DCGAN We - stabilize Generative Adversarial networks with some architectural constraints - Replace any pooling layers with strided convolutions (discriminator) and fractional-strided convolutions (generator). - Use batchnorm in both the generator and the discriminator - Remove fully connected hidden layers for deeper architectures. Just use average pooling at the end. - Use ReLU activation in generator for all layers except for the output, which uses Tanh. - Use LeakyReLU activation in the discriminator for all layers. - use the discriminator as a pre-trained net for CIFAR-10 classification and show pretty decent results. - generate really cool bedroom images that look super real - To convince you that the network is not cheating: - show the interpolated latent space, where transitions are really smooth and every image in the latent space is a bedroom. - show bedrooms after one epoch of training (with a 0.0002 learning rate), come on the network cant really memorize at this stage. - To explore what the representations that the network learnt, - show deconvolution over the filters, to show that maximal activations occur at objects like windows and beds - figure out a way to identify and remove filters that draw windows in generation. - Now you can control the generator to not output certain objects. - Because we are tripping - Smiling woman - neutral woman + neutral man = Smiling man. Whuttttt! - man with glasses - man without glasses + woman without glasses = woman with glasses. Omg!!!! - learnt a latent space in a completely unsupervised fashion where ROTATIONS ARE LINEAR in this latent space. WHHHAAATT????!!!!!! - Figure 11, trained on imagenet has a plane with bird legs. so cooool. Bedrooms after 5 epochs Generated bedrooms after five epochs of training. There appears to be evidence of visual under-fitting via repeated textures across multiple samples. Bedrooms after 1 epoch Generated bedrooms after one training pass through the dataset. Theoretically, the model could learn to memorize training examples, but this is experimentally unlikely as we train with a small learning rate and minibatch SGD. We are aware of no prior empirical evidence demonstrating memorization with SGD and a small learning rate in only one epoch. Walking from one point to another in bedroom latent space Interpolation between a series of 9 random points in Z show that the space learned has smooth transitions, with every image in the space plausibly looking like a bedroom. In the 6th row, you see a room without a window slowly transforming into a room with a giant window. In the 10th row, you see what appears to be a TV slowly being transformed into a window. Forgetting to draw windows Top row: un-modified samples from model. Bottom row: the same samples generated with dropping out window filters. Some windows are removed, others are transformed into objects with similar visual appearance such as doors and mirrors. Although visual quality decreased, overall scene composition stayed similar, suggesting the generator has done a good job disentangling scene representation from object representation. Extended experiments could be done to remove other objects from the image and modify the objects the generator draws. Google image search from generations Arithmetic on faces Rotations are linear in latent space More faces Album covers Imagenet generations"
4753,"Examples and Code snippets from the first AngularJS O'Reilly book which is now heavily out of date!angularjs-book OUTDATED! NOTE: This book is outdated, as are the examples in it. Examples and Code snippets from the first AngularJS O'Reilly book."
1788,"A UINavigationController's category to enable fullscreen pop gesture with iOS7+ system style.FDFullscreenPopGesture An UINavigationController's category to enable fullscreen pop gesture in an iOS7+ system style with AOP. Overview @J_ http://www.jianshu.com/p/d39f7d22db6c Usage AOP, just add 2 files and no need for any setups, all navigation controllers will be able to use fullscreen pop gesture automatically. To disable this pop gesture of a navigation controller: To disable this pop gesture of a view controller: Require at least iOS 7.0. View Controller Based Navigation Bar Appearance It handles navigation bar transition properly when using fullscreen gesture to push or pop a view controller: with bar -> without bar without bar -> with bar without bar -> without bar This opmiziation is enabled by default, from now on you don't need to call UINavigationController's -setNavigationBarHidden:animated: method, instead, use view controller's specific API to hide its bar: And this property is NO by default. View Controller With ScrollView If you want to use fullscreen pop gesture in ViewController with scrollView or subclass of scrollView , you should customize the scrollView or subclass of scrollView and overload the gestureRecognizer:shouldRecognizeSimultaneouslyWithGestureRecognizer: method . like this: Installation Use CocoaPods Release Notes 1.1 - View controller based navigation bar appearance and transition. 1.0 - Fullscreen pop gesture. License MIT"
3256,"Swipe to ""like"" or ""dislike"" any view, just like Tinder.app. Build a flashcard app, a photo viewer, and more, in minutes, not hours!MDCSwipeToChoose Swipe to ""like"" or ""dislike"" any view, just like Tinder.app. Build a flashcard app, a photo viewer, and more, in minutes, not hours! Use UIView+MDCSwipeToChoose to add a swipe gesture and callbacks to any UIView. Use MDCSwipeToChooseView to get a UI nearly identical to Tinder.app in just a few lines of code. You may view slides on some the architecture decisions that went into this library here. How to Install via CocoaPods Place the following in your Podfile and run pod install: How to Use Check out the sample app for an example of how to use MDCSwipeToChooseView to build the UI in the GIF above. NOTE: You must run pod install in the Examples/LikedOrNope directory before building the example app. Every public class contains documentation in its header file. Swiping Yes/No The following is an example of how you can use MDCSwipeToChooseView to display a photo. The user can choose to delete it by swiping left, or save it by swiping right. Objective-C Swift To use objective-c code from swift, you need to use bridging-header. If you're using CocoaPods 0.36+ (perhaps because you want to include pods that contain Swift code) and you've included the use_frameworks! directive in your Podfile, then you've converted all your pods (including MDCSwipeToChoose) into frameworks. Therefore, you'll need to include the line ...in your Swift files (even if you're using a bridging header). More Generic Swiping You don't have to use a subclass of MDCChooseView. You can use the mdc_swipeToChooseSetup: method on any UIView to enable swipe-to-choose. In the following example, we adjust the opacity of a UIWebView when it's panned left and right. Swiping in Swift The following is an example of how you can use MDCSwipeToChooseView to display a photo in swift. The user can choose to delete it by swiping left, or save it by swiping right. First you must create a BridgingHeader.h file You must then add the bridging header file to the project by navigating to Build Settings then searching for 'Bridging Header'. Double click the field and type: ProjectName/BridgingHeader.h as the value Swiping programmatically As of version 0.2.0, you may also swipe a view programmatically: Objective-C Swift Disable swiping gesture You may also disable the swiping gesture and only allowed to swipe programmatically Objective-C Swift License All the source code is distributed under the MIT license. See the LICENSE file for details. The license does not apply to the images used in the sample apps."
93,"Scrapy, a fast high-level web crawling & scraping framework for Python.====== Scrapy ====== .. image:: https://img.shields.io/pypi/v/Scrapy.svg :target: https://pypi.python.org/pypi/Scrapy :alt: PyPI Version .. image:: https://img.shields.io/pypi/pyversions/Scrapy.svg :target: https://pypi.python.org/pypi/Scrapy :alt: Supported Python Versions .. image:: https://github.com/scrapy/scrapy/workflows/Ubuntu/badge.svg :target: https://github.com/scrapy/scrapy/actions?query=workflow%3AUbuntu :alt: Ubuntu .. image:: https://github.com/scrapy/scrapy/workflows/macOS/badge.svg :target: https://github.com/scrapy/scrapy/actions?query=workflow%3AmacOS :alt: macOS .. image:: https://github.com/scrapy/scrapy/workflows/Windows/badge.svg :target: https://github.com/scrapy/scrapy/actions?query=workflow%3AWindows :alt: Windows .. image:: https://img.shields.io/badge/wheel-yes-brightgreen.svg :target: https://pypi.python.org/pypi/Scrapy :alt: Wheel Status .. image:: https://img.shields.io/codecov/c/github/scrapy/scrapy/master.svg :target: https://codecov.io/github/scrapy/scrapy?branch=master :alt: Coverage report .. image:: https://anaconda.org/conda-forge/scrapy/badges/version.svg :target: https://anaconda.org/conda-forge/scrapy :alt: Conda Version Overview Scrapy is a fast high-level web crawling and web scraping framework, used to crawl websites and extract structured data from their pages. It can be used for a wide range of purposes, from data mining to monitoring and automated testing. Scrapy is maintained by Zyte_ (formerly Scrapinghub) and many other contributors_. .. _many other contributors: https://github.com/scrapy/scrapy/graphs/contributors .. _Zyte: https://www.zyte.com/ Check the Scrapy homepage at https://scrapy.org for more information, including a list of features. Requirements Python 3.6+ Works on Linux, Windows, macOS, BSD Install The quick way:: pip install scrapy See the install section in the documentation at https://docs.scrapy.org/en/latest/intro/install.html for more details. Documentation Documentation is available online at https://docs.scrapy.org/ and in the docs directory. Releases You can check https://docs.scrapy.org/en/latest/news.html for the release notes. Community (blog, twitter, mail list, IRC) See https://scrapy.org/community/ for details. Contributing See https://docs.scrapy.org/en/master/contributing.html for details. Code of Conduct Please note that this project is released with a Contributor Code of Conduct (see https://github.com/scrapy/scrapy/blob/master/CODE_OF_CONDUCT.md). By participating in this project you agree to abide by its terms. Please report unacceptable behavior to opensource@zyte.com. Companies using Scrapy See https://scrapy.org/companies/ for a list. Commercial Support See https://scrapy.org/support/ for details."
1623,"jsoup: the Java HTML parser, built for HTML editing, cleaning, scraping, and XSS safety.jsoup: Java HTML Parser jsoup is a Java library for working with real-world HTML. It provides a very convenient API for fetching URLs and extracting and manipulating data, using the best of HTML5 DOM methods and CSS selectors. jsoup implements the WHATWG HTML5 specification, and parses HTML to the same DOM as modern browsers do. scrape and parse HTML from a URL, file, or string find and extract data, using DOM traversal or CSS selectors manipulate the HTML elements, attributes, and text clean user-submitted content against a safe-list, to prevent XSS attacks output tidy HTML jsoup is designed to deal with all varieties of HTML found in the wild; from pristine and validating, to invalid tag-soup; jsoup will create a sensible parse tree. See jsoup.org for downloads and the full API documentation. Example Fetch the Wikipedia homepage, parse it to a DOM, and select the headlines from the In the News section into a list of Elements: Online sample, full source. Open source jsoup is an open source project distributed under the liberal MIT license. The source code is available at GitHub. Getting started Download the latest jsoup jar (or add it to your Maven/Gradle build) Read the cookbook Enjoy! Development and support If you have any questions on how to use jsoup, or have ideas for future development, please get in touch via the mailing list. If you find any issues, please file a bug after checking for duplicates. The colophon talks about the history of and tools used to build jsoup. Status jsoup is in general, stable release."
1812,"Customizable Icons for React Native with support for image source and full styling.Perfect for buttons, logos and nav/tab bars. Easy to extend, style and integrate into your project. Table of Contents Bundled Icon Sets Installation iOS Android OSX Windows Web Upgrading Icon Component Icon.Button Component Usage as PNG image/source object TabBar Multi-style fonts Custom Fonts Animation Examples Generating your own icon set from a CSS file Changelog Troubleshooting License Sponsoring If you find the library useful, please consider sponsoring. Things I have planned is to split up the repo into a monorepo, that would enable individual versioning of icon sets, better performance, smaller bundle and easier for the community to publish their own. Bundled Icon Sets Browse all. AntDesign by AntFinance (297 icons) Entypo by Daniel Bruce (411 icons) EvilIcons by Alexander Madyankin & Roman Shamin (v1.10.1, 70 icons) Feather by Cole Bemis & Contributors (v4.28.0, 285 icons) FontAwesome by Dave Gandy (v4.7.0, 675 icons) FontAwesome 5 by Fonticons, Inc. (v5.13.0, 1588 (free) 7842 (pro) icons) Fontisto by Kenan Gndoan (v3.0.4, 615 icons) Foundation by ZURB, Inc. (v3.0, 283 icons) Ionicons by Iconic Framework (v5.0.1, 1227 icons) MaterialIcons by Google, Inc. (v4.0.0, 1547 icons) MaterialCommunityIcons by MaterialDesignIcons.com (v5.3.45, 5346 icons) Octicons by Github, Inc. (v8.4.1, 184 icons) Zocial by Sam Collins (v1.0, 100 icons) SimpleLineIcons by Sabbir & Contributors (v2.4.1, 189 icons) Installation Run: $ npm install --save react-native-vector-icons For each platform (iOS/Android/Windows) you plan to use, follow one of the options for the corresponding platform. If you intend to use FontAwesome 5, check out this guide to get you started. iOS Option: Manually If you want to use any of the bundled icons, you need to add the icon fonts to your Xcode project. Just follow these steps: Browse to node_modules/react-native-vector-icons and drag the folder Fonts (or just the ones you want) to your project in Xcode. Make sure your app is checked under ""Add to targets"" and that ""Create groups"" is checked if you add the whole folder. Not familiar with Xcode? Try this article Edit Info.plist and add a property called Fonts provided by application (or UIAppFonts if Xcode won't autocomplete/not using Xcode) and type in the files you just added. It will look something like this: List of all available fonts to copy & paste in Info.plist Note: you need to recompile your project after adding new fonts, also ensure that they also appear under Copy Bundle Resources in Build Phases. If you want to use getImageSource/getImageSourceSync, then you need to add RNVectorIcons.xcodeproj to Libraries and add libRNVectorIcons.a to Link Binary With Libraries under Build Phases. More info and screenshots about how to do this is available in the React Native documentation. Option: With react-native link $ react-native link react-native-vector-icons Note: Some users are having trouble using this method, try one of the others if you are too. Option: With CocoaPods Add the following to your Podfile and run pod update: Edit Info.plist as described above. If you are using use_frameworks! in your Podfile you instead need to dynamically load the icon font by doing Icon.loadFont() when boostrapping your application. Note: You must be consuming React itself via CocoaPods for this to work, see React Native documentation on how to set that up. Android Option: With Gradle (recommended) This method has the advantage of fonts being copied from this module at build time so that the fonts and JS are always in sync, making upgrades painless. Edit android/app/build.gradle ( NOT android/build.gradle ) and add the following: To customize the files being copied, add the following instead: Option: Manually Copy the contents in the Fonts folder to android/app/src/main/assets/fonts (note lowercase fonts folder). Integrating library for getImageSource support These steps are optional and only needed if you want to use the Icon.getImageSource function. Edit android/settings.gradle to look like this (without the +): Edit android/app/build.gradle (note: app folder) to look like this: Edit your MainApplication.java (deep in android/app/src/main/java/...) to look like this (note two places to edit): OSX via react-native-desktop Browse to node_modules/react-native-vector-icons and drag the folder Fonts to your project in Xcode. Make sure your app is checked under ""Add to targets"" and that ""Create folder references"" is checked. Edit Info.plist and add a property called Application fonts resource path (or ATSApplicationFontsPath if Xcode won't autocomplete/not using Xcode) and type Fonts as the value. Note: you need to recompile your project after adding new fonts, also ensure that the Fonts folder also appear under Copy Bundle Resources in Build Phases. Windows via react-native-windows In the top level projects (/windows/project-name/Assets), copy and paste the font files. Open your solution in Visual Studio, right click the Assets folder in your solution, click Add > Existing Item. Select the fonts that were into /windows/project-name/assets and click Add. Note: you need to recompile your project after adding new fonts. Web (with webpack) In your webpack configuration file, add a section to handle ttf files using url-loader (or file-loader) Then consume those files in your JavaScript entry point to get the bundled url and inject a style tag in your page: Upgrading Upgrading this package often requires the font files linked to your projects to be updated as well. If the automatic linking works for you, running this again should update the fonts. Otherwise you need to follow the steps outlined in the installation section. Icon Component You can either use one of the bundled icons above or roll your own custom font. Properties Any Text property and the following: | Prop | Description | Default | | ----------- | ----------------------------------------------------------------------- | ----------- | | size | Size of the icon, can also be passed as fontSize in the style object. | 12 | | name | What icon to show, see Icon Explorer app or one of the links above. | None | | color | Color of the icon. | Inherited | Static Methods | Prop | Description | | ------------------------ | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | | getFontFamily | Returns the font family that is currently used to retrieve icons as text. Usage: const fontFamily = Icon.getFontFamily() | | getImageSource | Returns a promise that resolving to the source of a bitmap version of the icon for use with Image component et al. Usage: const source = await Icon.getImageSource(name, size, color) | | getImageSourceSync | Same as getImageSource but synchronous. Usage: const source = Icon.getImageSourceSync(name, size, color) | | getRawGlyphMap | Returns the raw glyph map of the icon set. Usage: const glyphMap = Icon.getRawGlyphMap() | | hasIcon | Checks if the name is valid in current icon set. Usage: const isNameValid = Icon.hasIcon(name) | Styling Since Icon builds on top of the Text component, most style properties will work as expected, you might find it useful to play around with these: backgroundColor borderWidth borderColor borderRadius padding margin color fontSize NOTE: On android Text doesn't currently support border* styles, to circumvent this simply wrap your Icon with a View. By combining some of these you can create for example : Icon.Button Component A convenience component for creating buttons with an icon on the left side. Properties Any Text, TouchableHighlight or TouchableWithoutFeedback property in addition to these: | Prop | Description | Default | | --------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------- | ------------------- | | color | Text and icon color, use iconStyle or nest a Text component if you need different colors. | white | | size | Icon size. | 20 | | iconStyle | Styles applied to the icon only, good for setting margins or a different color. Note: use iconStyle for margins or expect unstable behaviour. | {marginRight: 10} | | backgroundColor | Background color of the button. | #007AFF | | borderRadius | Border radius of the button, set to 0 to disable. | 5 | | onPress | A function called when the button is pressed. | None | Usage as PNG image/source object Convenient way to plug this in into other components that rely on bitmap images rather than scalable vector icons. Takes the arguments name, size and color as described above. Alternatively you may use the synchronous method Icon.getImageSourceSync to avoid rendering glitches. Keep in mind that this method is blocking and might incur performance penalties. Subsequent calls will use cache however. Multi-style fonts Some fonts today use multiple styles, FontAwesome 5 for example, which is supported by this library. The usage is pretty much the same as the standard Icon component: Static methods All static methods from Icon is supported by multi-styled fonts. | Prop | Description | | ------------------------ | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | | getFontFamily | Returns the font family that is currently used to retrieve icons as text. Usage: const fontFamily = Icon.getFontFamily(style) | | getImageSource | Returns a promise that resolving to the source of a bitmap version of the icon for use with Image component et al. Usage: const source = await Icon.getImageSource(name, size, color) | | getImageSourceSync | Same as getImageSource but synchronous. Usage: const source = Icon.getImageSourceSync(name, size, color) | | getRawGlyphMap | Returns the raw glyph map of the icon set. Usage: const glyphMap = Icon.getRawGlyphMap(style) | | hasIcon | Checks if the name is valid in current icon set. Usage: const isNameValid = Icon.hasIcon(name, style) | | getStyledIconSet | Use this to get a Icon component for a single style. Usage. const StyledIcon = Icon.getStyledIconSet(style) | If no style argument is passed (or if it's invalid) the methods will default to a pre-defineds fallback. Components Icon.Button is supported, usage is just like Icon: Custom Fonts createIconSet(glyphMap, fontFamily[, fontFile]) Returns your own custom font based on the glyphMap where the key is the icon name and the value is either a UTF-8 character or it's character code. fontFamily is the name of the font NOT the filename. Open the font in Font Book.app or similar to learn the name. Optionally pass the third fontFile argument for android support, it should be the custom font file name. createIconSetFromFontello(config[, fontFamily[, fontFile]]) Convenience method to create a custom font based on a fontello config file. Don't forget to import the font as described above and drop the config.json somewhere convenient in your project. createIconSetFromIcoMoon(config[, fontFamily[, fontFile]]) Make sure you're using the Download option in IcoMoon, and use the .json file that's included in the .zip you've downloaded. You'll also need to import the .ttf font file into your project, following the instructions above. createMultiStyleIconSet(styles [, options]) | option | Description | default | | -------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ | ---------------------------------- | | defaultStyle | The name of the style to be used if no style is supplied during rendering. | Object.keys(styles)[0] | | fallbackFamily | Function for selecting a family if a glyph is not available. The function should accept the name of the glyph as a parameter. Returns the name if the family. | (name) => Object.keys(styles)[0] | | glyphValidator | Function for validating that a glyph is available for a chosen style. It has name and style as parameters, in that order. Returns true if the glyph is valid or false if it's not. | (name, style) => true | iOS You have to manually make a reference of your .ttf on your xcodeproj Resources folder and in Info.plist. Animation React Native comes with an amazing animation library called Animated. To use it with an icon, simply create an animated component with this line: const AnimatedIcon = Animated.createAnimatedComponent(Icon). You can also use the higher level animation library react-native-animatable. Examples IconExplorer Try the IconExplorer project in Examples/IconExplorer folder, there you can also search for any icon. Basic Example TabBar Since TabBarIOS was removed from core in favor of @react-navigation/bottom-tabs, it is also removed as a convenience component from this library. Simply use the Icon instead, but don't forget to import and link to this project as described above first. Below is an example taken from react-navigation: ToolbarAndroid Since ToolbarAndroid was removed from core, it is also removed as a convenience component from this library. Simply use getImageSourceSync instead, but don't forget to import and link to this project as described above first. Inline Icons Generating your own icon set from a CSS file If you already have an icon font with associated CSS file then you can easily generate a icon set with the generate-icon script. Example usage: Options Any flags not listed below, like --componentName and --fontFamily, will be passed on to the template. -p, --prefix CSS selector prefix [default: "".icon-""] -t, --template Template in lodash format [default: ""./template/iconSet.tpl""] For default template please provide --componentName and --fontFamily. -o, --output Save output to file, defaults to STDOUT Changelog Troubleshooting The icons show up as a crossed out box on Android Make sure you've copied the font to android/app/src/main/assets/fonts. Delete the build folder with rm -rf android/app/build. Recompile the project. Red screen with ""Unrecognized font family"" error on iOS Make sure you've added manually the reference of your .ttf on your xcodeproj Resources folder. Check that the font you are trying to use appears in Info.plist, if you've added the whole folder and it's blue in color, then you need to add it to the path. Check that the font is copied in the Copy Bundle Resources in Build Phases. Delete the build folder with rm -rf ios/build Recompile the project. Android build fails on Windows for no good reason Both npm and android file hierarchies tend to get very deep and even worse when you combine them. Since Windows file system has a max length, long file name addresses will result in numerous errors including Execution failed for task ':react-native-vector-icons:processReleaseResources'. So try to keep the path to your project folder as short as possible. Wrong icons are shown after upgrading this package You probably didn't update the font files linked to your native project after upgrading. However, this only applies to Android targets since iOS bundles the fonts when building the app (try to clean your build from Xcode if the problem exists). On android you can relink the project or you manually update the fonts. To have them automatically synced use the gradle approach. Some icons are missing after upgrading this package Sometimes vendors decides to remove some icons from newer releases, this has nothing to do with this package. If you depend on an older version of a font you can add it as a custom font. License This project is licenced under the MIT License. Any bundled fonts are copyright to their respective authors and mostly under MIT or SIL OFL."
3089,Course materials for the Data Science Specialization: https://www.coursera.org/specialization/jhudatascience/1Data Science Specialization These are the course materials for the Johns Hopkins Data Science Specialization on Coursera https://www.coursera.org/specialization/jhudatascience/1 Materials are under development and subject to change. Contributors Brian Caffo Jeff Leek Roger Peng Nick Carchedi Sean Kross License These course materials are available under the Creative Commons Attribution NonCommercial ShareAlike (CC-NC-SA) license (http://www.tldrlegal.com/l/CC-NC-SA).
1258,"Old apex/apexNo longer maintained This software is no longer being maintainted and should not be chosen for new projects. See this issue for more information Apex lets you build, deploy, and manage AWS Lambda functions with ease. With Apex you can use languages that are not natively supported by AWS Lambda through the use of a Node.js shim injected into the build. A variety of workflow related tooling is provided for testing functions, rolling back deploys, viewing metrics, tailing logs, hooking into the build system and more. This project is designed for event-driven pipelines as it does not abstract away FaaS (functions as a service). If you are building web applications, APIs, or sites, consider using Apex Up, which provides a more out-of-the-box experience for these use-cases. Installation On macOS, Linux, or OpenBSD run the following: Note that you may need to run the sudo version below, or alternatively chown /usr/local: On Windows download binary. After downloading, rename binary file 'apex.exe', then add to PATH. If already installed, upgrade with: Runtimes Currently supports: Node.js Golang Python Ruby Java Rust Clojure Example projects for all supported runtimes can be found in _examples directory. Features Supports languages Lambda does not natively support via shim Binary install (install apex quickly for continuous deployment in CI etc) Hook support for running commands (transpile code, lint, dependency management, etc) Batteries included but optional (opt-in to higher level abstractions) Environment variable population via command-line, file, or inline config Idempotent deployments (checksums skip already-deployed code) Multiple environments via project.ENV.json and function.ENV.json files Configuration inheritance and overrides Command-line function invocation with JSON streams Command & function name autocompletion Function name globbing (ex: apex deploy api_*) Transparently generates a zip for your deploy Project bootstrapping with optional Terraform support Function metrics and cost analysis Ignore deploying files with .apexignore Function rollback support Tail function logs Concurrency for quick deploys Dry-run to preview changes VPC support Multiple region support Lambda@Edge support Sponsors Does your company use Apex? Help keep the project bug-free and feature rich by sponsoring the project. Backers Love our work and community? Become a backer. Example Apex projects are made up of a project.json configuration file, and zero or more Lambda functions defined in the ""functions"" directory. Here's an example file structure: The project.json file defines project level configuration that applies to all functions, and defines dependencies. For this simple example the following will do: Each function uses a function.json configuration file to define function-specific properties such as the runtime, amount of memory allocated, and timeout. This file is completely optional, as you can specify defaults in your project.json file. For example: Now the directory structure for your project would be: Finally the source for the functions themselves look like this in Node.js: Apex operates at the project level, but many commands allow you to specify specific functions. For example you may deploy the entire project with a single command: Or whitelist functions to deploy: Invoke it! See the Documentation for more information. Links Website Medium Slack "
4694,"implementing deep dream on videoDeepDreamVideo Implementing #deepdream on video Creative Request It would be very helpful for other deepdream researchers, if you could include the used parameters in the description of your youtube videos. You can find the parameters in the image filenames. Included experiment: Deep Dreaming Fear & Loathing in Las Vegas: the Great Fan Francisco Acid Wave The results can be seen on youtube: https://www.youtube.com/watch?v=oyxSerkkP4o Mp4 not yet destroyed by youtube compression also at mega.nz together with original video file. All single processed + unprocessed frames are also at github Advise also at https://github.com/graphific/DeepDreamVideo/wiki INSTALL Dependencies A good overview (constantly being updated) on which software libraries to install & list of web resources/howto is at reddit: https://www.reddit.com/r/deepdream/comments/3cawxb/what_are_deepdream_images_how_do_i_make_my_own/ On using a CPU as opposed to GPU As there's been a lot of interest in using this code, and deepdream in general, on machines without a decent graphic card (GPU), heres a minor benchmark to let you decide if its worth the time on your pc: (note that the timing also depends on how far down in the layers of the network you want to go: the deeper, the longer time it takes) GPU K20 (amazon ec2 g2.2xlarge, 2x 4Gb GPU): 1 picture, 540x360px = 1 second = 60 min for 2 min video (3600 frames/framerate 30) 1 picture, 1024x768px = 3 seconds = 3h for 2 min video (3600 frames/framerate 30) CPU (amazon ec2 g2.2xlarge, Intel Xeon E5-2670 (Sandy Bridge) Processor, 8 cores, 2.6 GHz, 3.3 GHz turbo ): 1 picture, 540x360px = 45 seconds = 1d 21h for 2 min video (3600 frames/framerate 30) 1 picture, 1024x768px = 144 seconds = 6d for 2 min video (3600 frames/framerate 30) Usage: Extract frames from the source movie in the selected format (png or jpg). ./1_movie2frames.sh ffmpeg [original_video] [frames_directory] [png / jpg] or ./1_movie2frames.sh avconv [original_video] [frames_directory] [png / jpg] or ./1_movie2frames.sh mplayer [original_video] [frames_directory] [png / jpg] Let a pretrained deep neural network dream on it frames, one by one, taking each new frame and adding 0-50% of the old frame into it for continuity of the hallucinated artifacts, and go drink your caffe usage: 2_dreaming_time.py [-h] -i INPUT -o OUTPUT -it IMAGE_TYPE [--gpu GPU] [-t MODEL_PATH] [-m MODEL_NAME] [-p PREVIEW] [-oct OCTAVES] [-octs OCTAVESCALE] [-itr ITERATIONS] [-j JITTER] [-z ZOOM] [-s STEPSIZE] [-b BLEND] [-l LAYERS [LAYERS ...]] [-v VERBOSE] [-gi GUIDE_IMAGE] [-sf START_FRAME] [-ef END_FRAME] Dreaming in videos. optional arguments: -h, --help show this help message and exit -i INPUT, --input INPUT Input directory where extracted frames are stored -o OUTPUT, --output OUTPUT Output directory where processed frames are to be stored -it IMAGE_TYPE, --image_type IMAGE_TYPE Specify whether jpg or png --gpu GPU Switch for gpu computation. -t MODEL_PATH, --model_path MODEL_PATH Model directory to use -m MODEL_NAME, --model_name MODEL_NAME Caffe Model name to use -p PREVIEW, --preview PREVIEW Preview image width. Default: 0 -oct OCTAVES, --octaves OCTAVES Octaves. Default: 4 -octs OCTAVESCALE, --octavescale OCTAVESCALE Octave Scale. Default: 1.4 -itr ITERATIONS, --iterations ITERATIONS Iterations. Default: 10 -j JITTER, --jitter JITTER Jitter. Default: 32 -z ZOOM, --zoom ZOOM Zoom in Amount. Default: 1 -s STEPSIZE, --stepsize STEPSIZE Step Size. Default: 1.5 -b BLEND, --blend BLEND Blend Amount. Default: ""0.5"" (constant), or ""loop"" (0.5-1.0), or ""random"" -l LAYERS [LAYERS ...], --layers LAYERS [LAYERS ...] Array of Layers to loop through. Default: [customloop] - or choose ie [inception_4c/output] for that single layer -v VERBOSE, --verbose VERBOSE verbosity [0-3] -gi GUIDE_IMAGE, --guide_image GUIDE_IMAGE path to guide image -sf START_FRAME, --start_frame START_FRAME starting frame nr -ef END_FRAME, --end_frame END_FRAME end frame nr gpu: python 2_dreaming_time.py -i frames_directory -o processed_frames_dir --gpu 0 cpu: python 2_dreaming_time.py -i frames_directory -o processed_frames_dir different models can be loaded with: python 2_dreaming_time.py -i frames_directory -o processed_frames_dir --model_path ../caffe/models/Places205-CNN/ --model_name Places205.caffemodel --gpu 0 or python 2_dreaming_time.py -i frames_directory -o processed_frames_dir --model_path ../caffe/models/bvlc_googlenet/ --model_name bvlc_googlenet.caffemodel --gpu 0 (again eat your heart out, Not a free lunch, but free models are here) and sticking to one specific layer: python 2_dreaming_time.py -i frames_directory -o processed_frames_dir -l inception_4c/output --gpu 0 (don't forget the --gpu 0 flag if you got a gpu to run on) Once enough frames are processed (the script will cut the audio to the needed length automatically) or once all frames are done, put the frames + audio back together: ./3_frames2movie.sh [ffmpeg / avconv / mplayer] [processed_frames_dir] [original_video] [png / jpg] Guided Dreaming command: python 2_dreaming_time.py -i frames_directory -o processed_frames_dir -l inception_4c/output --guide-image image_file.jpg --gpu 0 or python 2_dreaming_time.py -i frames_directory -o processed_frames_dir -l inception_4c/output --guide-image image_file.jpg if you're running cpu mode Batch Processing with different parameters python 2_dreaming_time.py -i frames -o processed -l inception_4c/output --guide-image flower.jpg --gpu 0 --start-frame 1 --end-frame 100; python 2_dreaming_time.py -i frames -o processed -l inception_4b/output --guide-image disco.jpg --gpu 0 --start-frame 101 --end-frame 200 Blending Options The best results come from a well selected blending factor, used to blend each frame into the next, keeping consitancy between the frames and the dreamed up artefacts, but without the added dreamed artefacts overruling the original scene, or in the opposite case, switching too rapidly. blending can be set by --blend and can be a float, default 0.5, ""random"" (a random float between 0.5 and 1., where 1 means disregarding all info from the old frame and starting from scratch with dreaming up artefacts), and ""loop"" which loops back and forth from 0.5 to 1.0, as originally done in the Fear and Loathing clip. Constant (default): python 2_dreaming_time.py -i frames_directory -o processed_frames_dir -b 0.5 Loop: python 2_dreaming_time.py -i frames_directory -o processed_frames_dir -b loop Random: python 2_dreaming_time.py -i frames_directory -o processed_frames_dir -b random More information: This repo implements a deep neural network hallucinating Fear & Loathing in Las Vegas. Visualizing the internals of a deep net we let it develop further what it think it sees. We're using the #deepdream technique developed by Google, first explained in the Google Research blog post about Neural Network art. http://googleresearch.blogspot.nl/2015/06/inceptionism-going-deeper-into-neural.html Code: https://github.com/google/deepdream parameters used (and useful to play with): network: standard reference GoogLeNet model trained on ImageNet from the Caffe Model Zoo (https://github.com/BVLC/caffe/wiki/Model-Zoo) iterations: 5 jitter: 32 (default) octaves: 4 (default) layers locked to moving upwards from inception_4c/output to inception_5b/output (only the output layers, as they are most sensitive to visualizing ""objects"", where reduce layers are more like ""edge detectors"") and back again every next unprocessed frame in the movie clip is blended with the previous processed frame before being ""dreamed"" on, moving the alpha from 0.5 to 1 and back again (so 50% previous image net created, 50% the movie frame, to taking 100% of the movie frame only). This takes care of ""overfitting"" on the frames and makes sure we don't iteratively build more and more ""hallucinations"" of the net and move away from the original movie clip. An investigation of using the MIT Places trained CNN (mainly landscapes): https://www.youtube.com/watch?v=6IgbMiEaFRY Installing DeepDream: original Google code is relatively straightforward to use: https://github.com/google/deepdream/blob/master/dream.ipynb gist for osx: https://gist.github.com/robertsdionne/f58a5fc6e5d1d5d2f798 docker image: https://registry.hub.docker.com/u/mjibson/deepdream/ booting preinstalled ami + installing caffe at amazon: https://github.com/graphific/dl-machine general overview of convolutinal nets using Caffe: https://github.com/graphific/DL-Meetup-intro/blob/master/PyConSe15-cat-vs-dog.ipynb or using lasagne: http://www.slideshare.net/roelofp/python-for-image-understanding-deep-learning-with-convolutional-neural-nets Credits Roelof | KTH & Graph Technologies | @graphific"
3624,"PHP library allowing thumbnail, snapshot or PDF generation from a url or a html page. Wrapper for wkhtmltopdf/wkhtmltoimageSnappy Snappy is a PHP library allowing thumbnail, snapshot or PDF generation from a url or a html page. It uses the excellent webkit-based wkhtmltopdf and wkhtmltoimage available on OSX, linux, windows. You will have to download wkhtmltopdf 0.12.x in order to use Snappy. Please, check FAQ before opening a new issue. Snappy is a tiny wrapper around wkhtmltox, so lots of issues are already answered, resolved or wkhtmltox ones. Following integrations are available: * knplabs/knp-snappy-bundle, for Symfony * barryvdh/laravel-snappy, for Laravel * mvlabs/mvlabs-snappy, for Zend Framework Installation using Composer Usage Initialization Display the pdf in the browser Download the pdf from the browser Merge multiple urls into one pdf Generate local pdf file Pass options to snappy Reset options Options can be reset to their initial values with resetOptions() method. wkhtmltopdf binary as composer dependencies If you want to download wkhtmltopdf and wkhtmltoimage with composer you add to composer.json: or this if you are in 64 bit based system: And then you can use it N.B. These static binaries are extracted from Debian7 packages, so it might not be compatible with non-debian based linux distros Some use cases If you want to generate table of contents and you want to use custom XSL stylesheet, do the following: Bugs & Support If you found a bug please fill a detailed issue with all the following points. If you need some help, please at least provide a complete reproducer so we could help you based on facts rather than assumptions. OS and its version Wkhtmltopdf, its version and how you installed it A complete reproducer with relevant php and html/css/js code If your reproducer is big, please try to shrink it. It will help everyone to narrow the bug. Maintainers KNPLabs is looking for maintainers (see why). If you are interested, feel free to open a PR to ask to be added as a maintainer. Well be glad to hear from you :) This library is maintained by the following people (alphabetically sorted) : @alexpozzi Credits Snappy has been originally developed by the KnpLabs team."
3528,"Terminal based YouTube player and downloadermps-youtube .. image:: https://img.shields.io/pypi/v/mps-youtube.svg :target: https://pypi.python.org/pypi/mps-youtube .. image:: https://img.shields.io/pypi/dm/mps-youtube.svg :target: https://pypi.python.org/pypi/mps-youtube .. image:: https://img.shields.io/pypi/wheel/mps-youtube.svg :target: http://pythonwheels.com/ :alt: Wheel Status Features Search and play audio/video from YouTube Search tracks of albums by album title Search and import YouTube playlists Create and save local playlists Download audio/video Convert to mp3 & other formats (requires ffmpeg or avconv) View video comments Works with Python 3.x Works with Windows, Linux and Mac OS X Requires mplayer or mpv This project is based on mps <https://web.archive.org/web/20180429034221/https://github.com/np1/mps>, a terminal based program to search, stream and download music. This implementation uses YouTube as a source of content and can play and download video as well as audio. The pafy <https://github.com/mps-youtube/pafy> library handles interfacing with YouTube. FAQ / Troubleshooting common issues <https://github.com/mps-youtube/mps-youtube/wiki/Troubleshooting>_ Screenshots Search ~~~~~~ .. image:: http://mps-youtube.github.io/mps-youtube/std-search.png A standard search is performed by entering / followed by search terms. You can play all of the search results by giving 1- as input Repeating song/songs can be done with song_number[loop], for example: 1[3] or 4-6[2] Local Playlists ~~~~~~~~~~~~~~~ .. image:: http://mps-youtube.github.io/mps-youtube/local-playlist.png Search result items can easily be stored in local playlists. YouTube Playlists ~~~~~~~~~~~~~~~~~ .. image:: http://mps-youtube.github.io/mps-youtube/playlist-search.png YouTube playlists can be searched and played or saved as local playlists. A playlist search is performed by // followed by search term. Download ~~~~~~~~ .. image:: http://mps-youtube.github.io/mps-youtube/download.png Content can be downloaded in various formats and resolutions. Comments ~~~~~~~~ .. image:: http://mps-youtube.github.io/mps-youtube/comments.png A basic comments browser is available to view YouTube user comments. Music Album Matching ~~~~~~~~~~~~~~~~~~~~ .. image:: http://mps-youtube.github.io/mps-youtube/album-1.png .. image:: http://mps-youtube.github.io/mps-youtube/album-2.png An album title can be specified and mps-youtube will attempt to find matches for each track of the album, based on title and duration. Type help search for more info. Customisation ~~~~~~~~~~~~~ .. image:: http://mps-youtube.github.io/mps-youtube/customisation2.png Search results can be customised to display additional fields and ordered by various criteria. This configuration was set up using the following commands:: set order views set columns user:14 date comments rating likes dislikes category:9 views Type help config for help on configuration options Installation Linux ~~~~~ Note: ~/.local/bin should be in your PATH for --user installs. Using pip <http://www.pip-installer.org>_:: $ pip3 install --user mps-youtube To install the experimental development version and try the latest features:: $ pip3 install --user -U git+https://github.com/mps-youtube/mps-youtube.git Installing youtube-dl is highly recommended:: $ pip3 install --user youtube-dl and to upgrade: $ pip3 install --user youtube-dl --upgrade (youtube-dl version dowloaded directly from youtube-dl website can't be used by mps-youtube. While the version in the repositories is usually outdated) For mpris2 support, install the python bindings for dbus and gobject:: $ pip3 install --user dbus-python pygobject Ubuntu ~~~~~~ You can install mps-youtube directly from the official repositories:: [sudo] apt install mps-youtube Arch Linux ~~~~~~ You can install mps-youtube directly from the official repositories:: [sudo] pacman -S mps-youtube macOS X ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Install mpv (recommended player) with Homebrew <http://brew.sh>_:: brew cask install mpv Alternately, you can install mplayer with MacPorts <http://www.macports.org>_:: sudo port install MPlayer Or with Homebrew <http://brew.sh>_:: brew install mplayer Install mps-youtube using Homebrew <http://brew.sh>_:: brew install mps-youtube Additional Windows installation notes ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ As an alternative to installing with pip, there is a standalone binary available. Go to Releases <https://github.com/mps-youtube/mps-youtube/releases>_ and download mpsyt-VERSION.exe under downloads for the latest release. Install the python colorama <https://pypi.python.org/pypi/colorama>_ module to get colors (optional):: pip3 install colorama Mpsyt requires a player to use as a backend, with either mpv or mplayer supported. Mpv is the recommended option. Mpv can be downloaded from https://mpv.srsfckn.biz/ Extract both mpv.exe and mpv.com to the same folder as mpsyt.exe or to a folder in the system path. Alternately, mplayer can be downloaded from http://oss.netfarm.it/mplayer Extract the mplayer.exe file, saving it to the folder that mpsyt.exe resides in (usually C:\PythonXX\Scripts\) or to a folder in the system path. Run via Docker container ~~~~~~~~~~~~~~~~~~~~~~~~ Using Docker <http://www.docker.com>_, run with:: sudo docker run --device /dev/snd -it --rm --name mpsyt rothgar/mpsyt Additional Docker notes ~~~~~~~~~~~~~~~~~~~~~~~ If you would like to locally build the container you can run the following steps Check out this repo:: git clone https://github.com/mps-youtube/mps-youtube.git Enter the directory and run docker build:: cd mps-youtube sudo docker build -t mpsyt . Now run the container interactively with:: sudo docker run -v /dev/snd:/dev/snd -it --rm --privileged --name mpsyt mpsyt In order to have access to the local sound device (/dev/snd) the container needs to be privileged. Upgrading Upgrade pip installation:: [sudo] pip3 install mps-youtube --upgrade Usage mps-youtube is run on the command line using the command:: mpsyt Enter h from within the program for help. IRC An IRC channel #mps-youtube for the project is available on Freenode (chat.freenode.net:6697). You can join directly by clicking this link <https://webchat.freenode.net/?randomnick=1&channels=%23mps-youtube&uio=d4>_. How to Contribute Contributions are welcomed! However, please check out the contributing page <CONTRIBUTING.md>_ before making a contribution."
2503,"Scipy library main repository.. raw:: html <p> <h1> <a href=""https://docs.scipy.org/doc/scipy/reference/""><img valign=""middle"" src=""doc/source/_static/scipyshiny_small.png"" height=""50"" height=""50"" alt=""SciPy logo""/></a> SciPy </h1> </p> .. image:: https://img.shields.io/circleci/project/github/scipy/scipy/master.svg?label=CircleCI :target: https://circleci.com/gh/scipy/scipy .. image:: https://dev.azure.com/scipy-org/SciPy/_apis/build/status/scipy.scipy?branchName=master :target: https://dev.azure.com/scipy-org/SciPy/_build/latest?definitionId=1?branchName=master .. image:: https://github.com/scipy/scipy/workflows/macOS%20tests/badge.svg?branch=master :target: https://github.com/scipy/scipy/actions?query=workflow%3A%22macOS+tests%22 .. image:: https://img.shields.io/pypi/dm/scipy.svg?label=Pypi%20downloads :target: https://pypi.org/project/scipy/ .. image:: https://img.shields.io/conda/dn/conda-forge/scipy.svg?label=Conda%20downloads :target: https://anaconda.org/conda-forge/scipy .. image:: https://codecov.io/gh/scipy/scipy/branch/master/graph/badge.svg :target: https://codecov.io/gh/scipy/scipy .. image:: https://img.shields.io/badge/stackoverflow-Ask%20questions-blue.svg :target: https://stackoverflow.com/questions/tagged/scipy .. image:: https://img.shields.io/badge/DOI-10.1038%2Fs41592--019--0686--2-blue :target: https://www.nature.com/articles/s41592-019-0686-2 SciPy (pronounced ""Sigh Pie"") is an open-source software for mathematics, science, and engineering. It includes modules for statistics, optimization, integration, linear algebra, Fourier transforms, signal and image processing, ODE solvers, and more. Website: https://docs.scipy.org/doc/scipy/reference/ Documentation: https://docs.scipy.org/ Mailing list: https://scipy.org/scipylib/mailing-lists.html Source code: https://github.com/scipy/scipy Contributing: https://scipy.github.io/devdocs/dev/index.html Bug reports: https://github.com/scipy/scipy/issues Code of Conduct: https://scipy.github.io/devdocs/dev/conduct/code_of_conduct.html Report a security vulnerability: https://tidelift.com/docs/security Citing in your work: https://www.scipy.org/citing.html SciPy is built to work with NumPy arrays, and provides many user-friendly and efficient numerical routines, such as routines for numerical integration and optimization. Together, they run on all popular operating systems, are quick to install, and are free of charge. NumPy and SciPy are easy to use, but powerful enough to be depended upon by some of the world's leading scientists and engineers. If you need to manipulate numbers on a computer and display or publish the results, give SciPy a try! For the installation instructions, see our install guide <https://scipy.github.io/devdocs/getting_started.html#installation>__. Call for Contributions We appreciate and welcome contributions. Small improvements or fixes are always appreciated; issues labeled as ""good first issue"" may be a good starting point. Have a look at our contributing guide <http://scipy.github.io/devdocs/dev/hacking.html>__. Writing code isnt the only way to contribute to SciPy. You can also: review pull requests triage issues develop tutorials, presentations, and other educational materials maintain and improve our website <https://github.com/scipy/scipy.org>__ develop graphic design for our brand assets and promotional materials help with outreach and onboard new contributors write grant proposals and help with other fundraising efforts If youre unsure where to start or how your skills fit in, reach out! You can ask on the mailing list or here, on GitHub, by leaving a comment on a relevant issue that is already open. If you are new to contributing to open source, this guide <https://opensource.guide/how-to-contribute/>__ helps explain why, what, and how to get involved. .. image:: https://img.shields.io/badge/powered%20by-NumFOCUS-orange.svg?style=flat&colorA=E1523D&colorB=007D8A :target: https://numfocus.org"
1173,"A lightweight online game frameworkSkynet is a lightweight online game framework which can be used in many other fields. Build For Linux, install autoconf first for jemalloc: Or: For FreeBSD , use gmake instead of make. Test Run these in different consoles: About Lua version Skynet now uses a modified version of lua 5.4.2 ( https://github.com/ejoy/lua/tree/skynet54 ) for multiple lua states. Official Lua versions can also be used as long as the Makefile is edited. How To Use Read Wiki for documents https://github.com/cloudwu/skynet/wiki The FAQ in wiki https://github.com/cloudwu/skynet/wiki/FAQ"
1862,"A next-generation package manager for the front-endDuo is a next-generation package manager that blends the best ideas from Component, Browserify and Go to make organizing and writing front-end code quick and painless. Features Installation Getting Started Command Line Usage Javascript API Duo.js Plugins FAQ Mailing List #duojs on freenode Features has first-class support for Javascript, HTML and CSS exposes a unix-y command line interface pulls source directly from GitHub with semantic versioning supports source transforms, like Coffeescript or Sass does not require a manifest Installation Install Duo straight from npm with: Getting Started To get started just write normal Javascript, requiring dependencies straight from the file system or from GitHub as you need them: Then use duo to install your dependencies and build your file: Finally, drop a single <script> onto your page and you're done! Same goes for CSS! You can require dependencies and assets from the file system or straight from GitHub: Then bundle up your CSS with duo: And add your bundled-up stylesheet to your page! Authenticate with Github We recommend that you authenticate with Github so you can increase your rate limit and allow you to pull from private repositories. To do that, add the following entry to your ~/.netrc file: machine api.github.com login <username> password <token> You can create a new token here: https://github.com/settings/tokens/new Debugging If you run into an issue with Duo, often times you can resolve it by prepending DEBUG=duo* to your $COMMAND: Example: If you can't figure it out, you should open an issue: https://github.com/duojs/duo/issues Test Download this repository and run: Authors Matthew Mueller Amir Abu Shareb Plus many more wonderful contributors! License The MIT License Copyright 2014 Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the ""Software""), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
1244,":a: web framework for building virtual reality experiences.A-Frame A web framework for building virtual reality experiences. Site Docs School Slack Blog Newsletter Special Sponsors Examples Find more examples on the homepage, A Week of A-Frame, and WebVR Directory. Features :eyeglasses: Virtual Reality Made Simple: A-Frame handles the 3D and WebVR boilerplate required to get running across platforms including mobile, desktop, Vive, and Rift just by dropping in <a-scene>. :heart: Declarative HTML: HTML is easy to read and copy-and-paste. Since A-Frame can be used from HTML, A-Frame is accessible to everyone: web developers, VR enthusiasts, educators, artists, makers, kids. :electric_plug: Entity-Component Architecture: A-Frame is a powerful framework on top of three.js, providing a declarative, composable, reusable entity-component structure for three.js. While A-Frame can be used from HTML, developers have unlimited access to JavaScript, DOM APIs, three.js, WebVR, and WebGL. :zap: Performance: A-Frame is a thin framework on top of three.js. Although A-Frame uses the DOM, A-Frame does not touch the browser layout engine. Performance is a top priority, being battle-tested on highly interactive WebVR experiences. :globe_with_meridians: Cross-Platform: Build VR applications for Vive, Rift, Daydream, GearVR, and Cardboard. Don't have a headset or controllers? No problem! A-Frame still works on standard desktop and smartphones. :mag: Visual Inspector: A-Frame provides a built-in visual 3D inspector with a workflow similar to a browser's developer tools and interface similar to Unity. Open up any A-Frame scene and hit <ctrl> + <alt> + i. :runner: Features: Hit the ground running with A-Frame's built-in components such as geometries, materials, lights, animations, models, raycasters, shadows, positional audio, tracked controllers. Get even further with community components such as particle systems, physics, multiuser, oceans, mountains, speech recognition, or teleportation! Usage Example Build VR scenes in the browser with just a few lines of HTML! To start playing and publishing now, remix the starter example on: With A-Frame's entity-component architecture, we can drop in community components from the ecosystem (e.g., ocean, physics) and plug them into our objects straight from HTML: Builds To use the latest stable build of A-Frame, include aframe.min.js: To check out the stable and master builds, see the dist/ folder. npm Local Development And open in your browser http://localhost:9000. Generating Builds Questions For questions and support, ask on StackOverflow. Stay in Touch To hang out with the community, join the A-Frame Slack. Follow A Week of A-Frame on the A-Frame blog. Follow @aframevr on Twitter. Subscribe to the Newsletter. And get in touch with the maintainers! Diego Marcos Don McCurdy Kevin Ngo Contributing Get involved! Check out the Contributing Guide for how to get started. You can also support development by buying a gorgeous A-Frame t-shirt with exclusive designs License This program is free software and is distributed under an MIT License."
2759,"Chronic is a pure Ruby natural language date parser.Chronic Chronic is a natural language date/time parser written in pure Ruby. See below for the wide variety of formats Chronic will parse. Installation Usage If the parser can find a date or time, either a Time or Chronic::Span will be returned (depending on the value of :guess). If no date or time can be found, nil will be returned. See Chronic.parse for detailed usage instructions. Examples Chronic can parse a huge variety of date and time formats. Following is a small sample of strings that will be properly parsed. Parsing is case insensitive and will handle common abbreviations and misspellings. Simple thursday november summer friday 13:00 mon 2:35 4pm 10 to 8 10 past 2 half past 2 6 in the morning friday 1pm sat 7 in the evening yesterday today tomorrow last week next week this tuesday next month last winter this morning last night this second yesterday at 4:00 last friday at 20:00 last week tuesday tomorrow at 6:45pm afternoon yesterday thursday last week Complex 3 years ago a year ago 5 months before now 7 hours ago 7 days from now 1 week hence in 3 hours 1 year ago tomorrow 3 months ago saturday at 5:00 pm 7 hours before tomorrow at noon 3rd wednesday in november 3rd month next year 3rd thursday this september 4th day last week fourteenth of june 2010 at eleven o'clock in the evening may seventh '97 at three in the morning Specific Dates January 5 22nd of june 5th may 2017 February twenty first dec 25 may 27th October 2006 oct 06 jan 3 2010 february 14, 2004 february 14th, 2004 3 jan 2000 17 april 85 5/27/1979 27/5/1979 05/06 1979-05-27 Friday 5 4:00 17:00 0800 Specific Times (many of the above with an added time) January 5 at 7pm 22nd of june at 8am 1979-05-27 05:00:00 03/01/2012 07:25:09.234567 2013-08-01T19:30:00.345-07:00 2013-08-01T19:30:00.34-07:00 etc Time Zones Chronic allows you to set which Time class to use when constructing times. By default, the built in Ruby time class creates times in your system's local time zone. You can set this to something like ActiveSupport's TimeZone class to get full time zone support. Limitations Chronic uses Ruby's built in Time class for all time storage and computation. Because of this, only times that the Time class can handle will be properly parsed. Parsing for times outside of this range will simply return nil. Support for a wider range of times is planned for a future release. Contribute If you'd like to hack on Chronic, start by forking the repo on GitHub: https://github.com/mojombo/chronic The best way to get your changes merged back into core is as follows: Clone down your fork Create a thoughtfully named topic branch to contain your change Install the development dependencies by running bundle install Hack away Add tests and make sure everything still passes by running bundle exec rake Ensure your tests pass in multiple timezones. ie TZ=utc bundle exec rake TZ=BST bundle exec rake If you are adding new functionality, document it in the README Do not change the version number, we will do that on our end If necessary, rebase your commits into logical chunks, without errors Push the branch up to GitHub Send a pull request for your branch"
3484,"A Control Center-esque control with blurred background and toggle animations.RNFrostedSidebar Add your own Control Center-esque UI to your app to work as navigation or even toggle different settings. Blend right into the new iOS 7 design with animated blurs, flat design, and custom animations. This project is another UI control built after finding some inspiration on Dribbble. The original design was created by Jakub Antalik. For some thoughts on live blur in iOS apps, check out my blog post. You'll notice that this control's use of blur does not match Jakub's original design exactly. In the original design the background of the buttons is blurred, while the overlay of the control is simply shaded. There have been attempts at recreating this effect, but it is rumored that live-blurring takes place at a much lower level on the GPU and there would be security concerns were we to have access. Apple is being a little deceptive with their use of blurring in iOS 7. Bottom line, don't animate blurs in your designs. If you examine the source of this project you'll see that I'm actually cheating to get the blur layer to animate overtop the original view. Installation The preferred method of installation is with CocoaPods. Just add this line to your Podfile. Or if you want to install manually, drag and drop the RNFrostedSidebar .h and .m files into your project. To get this working, you'll need to include the following frameworks in Link Binary with Libraries: QuartzCore Accelerate Usage The simplest usage is to create a list of images, initialize a RNFrostedSidebar object, then call the -show method. If you use RNFrostedSidebar with a UINavigationController, you can push another UIViewController after selecting a button. Simply initialize it in sidebar:didTapItemAtIndex:, then push it onto the navigation stack after dimissing the sidebar with -dismissAnimated:completion:. Customization I've exposed a healthy amount of options for you to customize the appearance and animation of the control. Use the parameter selectedIndices to add pre-selected options. Without using the init method below there wont be any visualization of selection. But, you will get the proper enabled/disabled BOOL in the delegate -sidebar:didEnable:itemAtIndex: method. Use the parameter borderColors to add border effect animations when selecting and deselecting a view. The width of the blurred region. Default 150. Toggle showing the control from the right side of the device. Default NO. The duration of the show and dismiss animations. Default 0.25. The size of the item views. Default is width: 75, height: 75. The tint color of the blur. This can be a tricky property to set. I recommend using the provided alpha. Avoid using solid colors with an alpha of 1. Default white: 0.2, alpha: 0.73. The background color for item views. Note: This property must be set with either colorWithWhite:alpha or colorWithRed:green:blue:alpha or it will crash. This is for highlight effects on tapping so the control can derive a darker background when highlighted. Default white: 1, alpha 0.25. The border width for item views. Default 2. An optional delegate to respond to selection of item views. Optional delegate methods, provided by George Villasboas, include: Credits UI Control structure and View Controller containment practices adopted from Matthias Tretter. Sample icons provided by Pixeden. The blur algorithm comes from WWDC 2013's session 208, ""What's New in iOS User Interface Design"". Apps If you've used this project in a live app, please let me know! Nothing makes me happier than seeing someone else take my work and go wild with it. Contact @nystrorm on Twitter @rnystrom on Github rnystrom [at] whoisryannystrom [dot] com License See LICENSE."
491,"Universal markup converter Pandoc The universal markup converter Pandoc is a Haskell library for converting from one markup format to another, and a command-line tool that uses this library. It can convert from - `bibtex` ([BibTeX](https://ctan.org/pkg/bibtex) bibliography) - `biblatex` ([BibLaTeX](https://ctan.org/pkg/biblatex) bibliography) - `commonmark` ([CommonMark](https://commonmark.org) Markdown) - `commonmark_x` ([CommonMark](https://commonmark.org) Markdown with extensions) - `creole` ([Creole 1.0](http://www.wikicreole.org/wiki/Creole1.0)) - `csljson` ([CSL JSON](https://citeproc-js.readthedocs.io/en/latest/csl-json/markup.html) bibliography) - `csv` ([CSV](https://tools.ietf.org/html/rfc4180) table) - `docbook` ([DocBook](https://docbook.org)) - `docx` ([Word docx](https://en.wikipedia.org/wiki/Office_Open_XML)) - `dokuwiki` ([DokuWiki markup](https://www.dokuwiki.org/dokuwiki)) - `epub` ([EPUB](http://idpf.org/epub)) - `fb2` ([FictionBook2](http://www.fictionbook.org/index.php/Eng:XML_Schema_Fictionbook_2.1) e-book) - `gfm` ([GitHub-Flavored Markdown](https://help.github.com/articles/github-flavored-markdown/)), or the deprecated and less accurate `markdown_github`; use [`markdown_github`](https://pandoc.org/MANUAL.html#markdown-variants) only if you need extensions not supported in [`gfm`](https://pandoc.org/MANUAL.html#markdown-variants). - `haddock` ([Haddock markup](https://www.haskell.org/haddock/doc/html/ch03s08.html)) - `html` ([HTML](https://www.w3.org/html/)) - `ipynb` ([Jupyter notebook](https://nbformat.readthedocs.io/en/latest/)) - `jats` ([JATS](https://jats.nlm.nih.gov) XML) - `jira` ([Jira](https://jira.atlassian.com/secure/WikiRendererHelpAction.jspa?section=all)/Confluence wiki markup) - `json` (JSON version of native AST) - `latex` ([LaTeX](https://www.latex-project.org/)) - `markdown` ([Pandocs Markdown](https://pandoc.org/MANUAL.html#pandocs-markdown)) - `markdown_mmd` ([MultiMarkdown](https://fletcherpenney.net/multimarkdown/)) - `markdown_phpextra` ([PHP Markdown Extra](https://michelf.ca/projects/php-markdown/extra/)) - `markdown_strict` (original unextended [Markdown](https://daringfireball.net/projects/markdown/)) - `mediawiki` ([MediaWiki markup](https://www.mediawiki.org/wiki/Help:Formatting)) - `man` ([roff man](https://man.cx/groff_man(7))) - `muse` ([Muse](https://amusewiki.org/library/manual)) - `native` (native Haskell) - `odt` ([ODT](https://en.wikipedia.org/wiki/OpenDocument)) - `opml` ([OPML](http://dev.opml.org/spec2.html)) - `org` ([Emacs Org mode](https://orgmode.org)) - `rst` ([reStructuredText](https://docutils.sourceforge.io/docs/ref/rst/introduction.html)) - `t2t` ([txt2tags](https://txt2tags.org)) - `textile` ([Textile](https://www.promptworks.com/textile)) - `tikiwiki` ([TikiWiki markup](https://doc.tiki.org/Wiki-Syntax-Text#The_Markup_Language_Wiki-Syntax)) - `twiki` ([TWiki markup](https://twiki.org/cgi-bin/view/TWiki/TextFormattingRules)) - `vimwiki` ([Vimwiki](https://vimwiki.github.io)) It can convert to - `asciidoc` ([AsciiDoc](https://www.methods.co.nz/asciidoc/)) or `asciidoctor` ([AsciiDoctor](https://asciidoctor.org/)) - `beamer` ([LaTeX beamer](https://ctan.org/pkg/beamer) slide show) - `bibtex` ([BibTeX](https://ctan.org/pkg/bibtex) bibliography) - `biblatex` ([BibLaTeX](https://ctan.org/pkg/biblatex) bibliography) - `commonmark` ([CommonMark](https://commonmark.org) Markdown) - `commonmark_x` ([CommonMark](https://commonmark.org) Markdown with extensions) - `context` ([ConTeXt](https://www.contextgarden.net/)) - `csljson` ([CSL JSON](https://citeproc-js.readthedocs.io/en/latest/csl-json/markup.html) bibliography) - `docbook` or `docbook4` ([DocBook](https://docbook.org) 4) - `docbook5` (DocBook 5) - `docx` ([Word docx](https://en.wikipedia.org/wiki/Office_Open_XML)) - `dokuwiki` ([DokuWiki markup](https://www.dokuwiki.org/dokuwiki)) - `epub` or `epub3` ([EPUB](http://idpf.org/epub) v3 book) - `epub2` (EPUB v2) - `fb2` ([FictionBook2](http://www.fictionbook.org/index.php/Eng:XML_Schema_Fictionbook_2.1) e-book) - `gfm` ([GitHub-Flavored Markdown](https://help.github.com/articles/github-flavored-markdown/)), or the deprecated and less accurate `markdown_github`; use [`markdown_github`](https://pandoc.org/MANUAL.html#markdown-variants) only if you need extensions not supported in [`gfm`](https://pandoc.org/MANUAL.html#markdown-variants). - `haddock` ([Haddock markup](https://www.haskell.org/haddock/doc/html/ch03s08.html)) - `html` or `html5` ([HTML](https://www.w3.org/html/), i.e.[HTML5](https://html.spec.whatwg.org/)/XHTML [polyglot markup](https://www.w3.org/TR/html-polyglot/)) - `html4` ([XHTML](https://www.w3.org/TR/xhtml1/) 1.0 Transitional) - `icml` ([InDesign ICML](https://wwwimages.adobe.com/www.adobe.com/content/dam/acom/en/devnet/indesign/sdk/cs6/idml/idml-cookbook.pdf)) - `ipynb` ([Jupyter notebook](https://nbformat.readthedocs.io/en/latest/)) - `jats_archiving` ([JATS](https://jats.nlm.nih.gov) XML, Archiving and Interchange Tag Set) - `jats_articleauthoring` ([JATS](https://jats.nlm.nih.gov) XML, Article Authoring Tag Set) - `jats_publishing` ([JATS](https://jats.nlm.nih.gov) XML, Journal Publishing Tag Set) - `jats` (alias for `jats_archiving`) - `jira` ([Jira](https://jira.atlassian.com/secure/WikiRendererHelpAction.jspa?section=all)/Confluence wiki markup) - `json` (JSON version of native AST) - `latex` ([LaTeX](https://www.latex-project.org/)) - `man` ([roff man](https://man.cx/groff_man(7))) - `markdown` ([Pandocs Markdown](https://pandoc.org/MANUAL.html#pandocs-markdown)) - `markdown_mmd` ([MultiMarkdown](https://fletcherpenney.net/multimarkdown/)) - `markdown_phpextra` ([PHP Markdown Extra](https://michelf.ca/projects/php-markdown/extra/)) - `markdown_strict` (original unextended [Markdown](https://daringfireball.net/projects/markdown/)) - `mediawiki` ([MediaWiki markup](https://www.mediawiki.org/wiki/Help:Formatting)) - `ms` ([roff ms](https://man.cx/groff_ms(7))) - `muse` ([Muse](https://amusewiki.org/library/manual)), - `native` (native Haskell), - `odt` ([OpenOffice text document](https://en.wikipedia.org/wiki/OpenDocument)) - `opml` ([OPML](http://dev.opml.org/spec2.html)) - `opendocument` ([OpenDocument](http://opendocument.xml.org)) - `org` ([Emacs Org mode](https://orgmode.org)) - `pdf` ([PDF](https://www.adobe.com/pdf/)) - `plain` (plain text), - `pptx` ([PowerPoint](https://en.wikipedia.org/wiki/Microsoft_PowerPoint) slide show) - `rst` ([reStructuredText](https://docutils.sourceforge.io/docs/ref/rst/introduction.html)) - `rtf` ([Rich Text Format](https://en.wikipedia.org/wiki/Rich_Text_Format)) - `texinfo` ([GNU Texinfo](https://www.gnu.org/software/texinfo/)) - `textile` ([Textile](https://www.promptworks.com/textile)) - `slideous` ([Slideous](https://goessner.net/articles/slideous/) HTML and JavaScript slide show) - `slidy` ([Slidy](https://www.w3.org/Talks/Tools/Slidy2/) HTML and JavaScript slide show) - `dzslides` ([DZSlides](https://paulrouget.com/dzslides/) HTML5 + JavaScript slide show), - `revealjs` ([reveal.js](https://revealjs.com/) HTML5 + JavaScript slide show) - `s5` ([S5](https://meyerweb.com/eric/tools/s5/) HTML and JavaScript slide show) - `tei` ([TEI Simple](https://github.com/TEIC/TEI-Simple)) - `xwiki` ([XWiki markup](https://www.xwiki.org/xwiki/bin/view/Documentation/UserGuide/Features/XWikiSyntax/)) - `zimwiki` ([ZimWiki markup](https://zim-wiki.org/manual/Help/Wiki_Syntax.html)) - the path of a custom Lua writer, see [Custom writers](https://pandoc.org/MANUAL.html#custom-writers) below Pandoc can also produce PDF output via LaTeX, Groff ms, or HTML. Pandocs enhanced version of Markdown includes syntax for tables, definition lists, metadata blocks, footnotes, citations, math, and much more. See the Users Manual below under Pandocs Markdown. Pandoc has a modular design: it consists of a set of readers, which parse text in a given format and produce a native representation of the document (an abstract syntax tree or AST), and a set of writers, which convert this native representation into a target format. Thus, adding an input or output format requires only adding a reader or writer. Users can also run custom pandoc filters to modify the intermediate AST (see the documentation for filters and Lua filters). Because pandocs intermediate representation of a document is less expressive than many of the formats it converts between, one should not expect perfect conversions between every format and every other. Pandoc attempts to preserve the structural elements of a document, but not formatting details such as margin size. And some document elements, such as complex tables, may not fit into pandocs simple document model. While conversions from pandocs Markdown to all formats aspire to be perfect, conversions from formats more expressive than pandocs Markdown can be expected to be lossy. Installing Heres how to install pandoc. Documentation Pandocs website contains a full Users Guide. It is also available here as pandoc-flavored Markdown. The website also contains some examples of the use of pandoc and a limited online demo. Contributing Pull requests, bug reports, and feature requests are welcome. Please make sure to read the contributor guidelines before opening a new issue. License 2006-2021 John MacFarlane (jgm@berkeley.edu). Released under the GPL, version 2 or greater. This software carries no warranty of any kind. (See COPYRIGHT for full copyright and warranty notices.)"
3551,"Plasma is an interactive disassembler for x86/ARM/MIPS. It can generates indented pseudo-code with colored syntax.PLASMA The old project name was Reverse. PLASMA is an interactive disassembler. It can generate a more readable assembly (pseudo code) with colored syntax. You can write scripts with the available Python api (see an example below). The project is still in big development. wiki : TODO list and some documentation. It supports : * architectures : x86{64}, ARM, MIPS{64} (partially for ARM and MIPS) * formats : ELF, PE, RAW Warning: until structures and type definitions are not implemented, the database compatibility could be broken. Requirements python >= 3.4 capstone, tested with 4.0-alpha5 python-pyelftools pefile + python3-future python-msgpack >= 0.4.6 c++filt (available in the binutils Linux package) terminal should support UTF8 and 256 colors (if not, use the option --nocolor) Optional : * python-qt4 used for the memory map * keystone for the script asm.py Installation ./install.sh Or if you have already installed requirements with the previous command: ./install.sh --update Check tests : make .................................................................................... 84/84 tests passed successfully in 2.777975s analyzer tests... ... Pseudo-decompilation of functions $ plasma -i tests/server.bin >> v main # you can press tab to show the pseudo decompilation # | to split the window # See the command help for all shortcuts Take the control of the flow graph by inverting conditional jumps: Scripting (Python API) See more on the wiki for the API. Some examples (these scripts are placed in plasma/scripts) : $ plasma -i FILE plasma> py !strings.py # print all strings plasma> py !xrefsto.py FUNCTION # xdot call graph plasma> py !crypto.py # detect some crypto constants plasma> py !asm.py CODE # assemble with keystone plasma> py !disasm.py HEX_STRING # disassemble a buffer"
4811,"Offline-capable Pokdex web site (unmaintained)Pokedex.org An index of Pokmon, built as a client-side JavaScript webapp. Powered by ServiceWorker, PouchDB, virtual-dom, and web workers. See the Introducing Pokedex.org blog post for details on the architecture. Developing First, be sure to install dependencies: npm install Then start a dev server on localhost:9000: npm run serve To disable ServiceWorker: NODE_ENV=testing npm run serve Building npm run build This will write files to www/. Bumping the ServiceWorker version The ServiceWorker version is tied to the package.json version. So you can bump it by simply doing: npm version patch Building up the database via PokAPI Note: you don't need to build up the database to start developing; these are just steps to generate the database files (src/assets/*.txt) from scratch. This site uses data provided by PokAPI. To build up the database, you'll need to run: Some of the build scripts pull from src/js/shared/data (which contains some files that I had to build myself by scraping Bulbapedia), whereas the main ones pull from the live PokeAPI. (I never got the local PokeAPI working correctly, so I just pulled from the remote.) Debugging You can add ?highPerfAnims=1 to the URL to force high-performance animations to run. (Normally they are disabled for Firefox and Android <5.) Credits Thanks to PokeAPI and Bulbapedia for the Pokmon data, and of course to Nintendo, Game Freak, and The Pokmon Company for making such an awesome series of games."
1513,"Simple and portable (but not inflexible) GUI library in C that uses the native GUI technologies of each platform it supports.libui: a portable GUI library for C This README is being written. Status It has come to my attention that I have not been particularly clear about how usable or feature-complete libui is, and that this has fooled many people into expecting more from libui right this moment than I have explicitly promised to make available. I apologize for not doing this sooner. libui is currently mid-alpha software. Much of what is currently present runs stabily enough for the examples and perhaps some small programs to work, but the stability is still a work-in-progress, much of what is already there is not feature-complete, some of it will be buggy on certain platforms, and there's a lot of stuff missing. In short, here's a list of features that I would like to add to libui, but that aren't in yet: trees clipboard support, including drag and drop more and better dialogs printing accessibility for uiArea and custom controls document-based programs tighter OS integration (especially for document-based programs), to allow programs to fully feel native, rather than merely look and act native better support for standard dialogs and features (search bars, etc.) OpenGL support In addition, here is a list of issues generalizing existing problems. Furthermore, libui is not properly fully documented yet. This is mainly due to the fact that the API was initially unstable enough so as to result in rewriting documentation multiple times, in addition to me not being happy with really any existing C code documentation tool. That being said, I have started to pin down my ideal code documentation style in parts of ui.h, most notably in the uiAttributedString APIs. Over time, I plan on extending this to the rest of the headers. You can also use the documentation for libui's Go bindings as a reference, though it is somewhat stale and not optimally written. But libui is not dead; I am working on it whenever I can, and I hope to get it to a point of real quality soon! News Note that today's entry (Eastern Time) may be updated later today. 7 April 2019 The build system has been switched to Meson. See below for instructions. This change was made because the previous build system, CMake, caused countless headaches over trivial issues. Meson was chosen due to how unproblematic setting up libui's build just right was, as well as having design goals that are by coincidence closely aligned with what libui wants. Travis CI has been replaced with Azure Pipelines and much of the AppVeyor CI configuration was integrated into the Azure Pipelines configuration. This shouldn't affect most developers. 1 September 2018 Alpha 4.1 is here. This is an emergency fix to Alpha 4 to fix uiImageAppend() not working as documented. It now works properly, with one important difference you'll need to care about: it now requires image data to be alpha-premultiplied. In addition, uiImage also is implemented slightly more nicely now, and ui.h has minor documentation typo fixes. Alpha 4.1 also tries to make everything properly PIC-enabled. 10 August 2018 Alpha 4 is finally here. Everything from Alpha 3.5 and what's listed below is in this release; the two biggest changes are still the new text drawing API and new uiTable control. In between all that is a whole bunch of bugfixes, and hopefully more stability too. Thanks to everybody who helped contribute! Alpha 4 should hopefully also include automated binary releases via CI. Thanks to those who helped set that up! 8 August 2018 Finally introduced an API for loading images, uiImage, and a new control, uiTable, for displaying tabular data. These provide enough basic functionality for now, but will be improved over time. You can read the documentation for the new features as they are here. Thanks to everyone who helped get to this point, in particular @bcampbell for the initial Windows code, and to everyone else for their patience! 30 May 2018 Merged the previous Announcements and Updates section of this README into a single News section, and merged the respective archive files into a single NEWS.md file. 16 May 2018 Thanks to @parro-it and @msink, libui now has better CI, including AppVeyor for Windows CI, and automated creation of binary releases when I make a tagged release. 13 May 2018 Added new functions to work with uiDateTimePickers: uiDateTimePickerTime(), uiDateTimePickerSetTime(), and uiDateTimePickerOnChanged(). These operate on standard <time.h> struct tms. Thanks @cody271! Release builds on Windows with MSVC should be fixed now; thanks @l0calh05t, @slahn, @mischnic, and @zentner-kyle. 12 May 2018 GTK+ and OS X now have a cleaner build process for static libraries which no longer has intermediate files and differing configurations. As a result, certain issues should no longer be present. New naming rules for internal symbols of libui have also started being drafted; runtime symbols and edge cases still need to be handled (and the rules applied to Windows) before this can become a regular thing. 2 May 2018 On Windows, you no longer need to carry around a libui.res file with static builds. You do need to link in the appropriate manifest file, such as the one in the windows/ folder (I still need to figure out exactly what is needed apart from the Common Controls v6 dependency, or at least to create a complete-ish template), or at least include it alongside your executables. This also means you should no longer see random cmake errors when building the static libraries. 18 April 2018 Introduced a new uiTimer() function for running code on a timer on the main thread. (Thanks to @cody271.) Migrated all code in the common/ directory to use uipriv prefixes for everything that isn't static. This is the first step toward fixing static library oddities within libui, allowing libui to truly be safely used as either a static library or a shared library. 18 March 2018 Introduced an all-new formatted text API that allows you to process formatted text in ways that the old API wouldn't allow. You can read on the whole API here. There is also a new examples for it: drawtext, which shows the whole API at a glance. It doesn't yet support measuring or manipulating text, nor does it currently support functions that would be necessary for things like text editors; all of this will be added back later. libui also now uses my utf library for UTF-8 and UTF-16 processing, to allow consistent behavior across platforms. This usage is not completely propagated throughout libui, but the Windows port uses it in most places now, and eventually this will become what libui will use throughout. Also introduced a formal set of contribution guidelines, see CONTRIBUTING.md for details. They are still WIP. 17 February 2018 The longstanding Enter+Escape crashes on Windows have finally been fixed (thanks to @lxn). Alpha 3.5 is now here. This is a quickie release primiarly intended to deploy the above fix to package ui itself. It is a partial binary release; sorry! More new things will come in the next release, which will also introduce semver (so it will be called v0.4.0 instead). Alpha 3.5 also includes a new control gallery example. The screenshots below have not been updated yet. Old announcements can be found in the NEWS.md file. Runtime Requirements Windows: Windows Vista SP2 with Platform Update or newer Unix: GTK+ 3.10 or newer Mac OS X: OS X 10.8 or newer Build Requirements All platforms: Meson 0.48.0 or newer Any of Meson's backends; this section assumes you are using Ninja, but there is no reason the other backends shouldn't work. Windows: either Microsoft Visual Studio 2013 or newer (2013 is needed for va_copy()) you can build either a static or a shared library MinGW-w64 (other flavors of MinGW may not work) you can only build a static library; shared library support will be re-added once the following features come in: Isolation awareness, which is how you get themed controls from a DLL without needing a manifest Unix: nothing else specific Mac OS X: nothing else specific, so long as you can build Cocoa programs Building libui uses only the standard Meson build options, so a libui build can be set up just like any other: Once this completes, everything will be under build/meson-out/. (Note that unlike the previous build processes, everything is built by default, including tests and examples.) The most important options are: --buildtype=(debug|release|...) controls the type of build made; the default is debug. For a full list of valid values, consult the Meson documentation. --default-library=(shared|static) controls whether libui is built as a shared library or a static library; the default is shared. You currently cannot specify both, as the build process changes depending on the target type (though I am willing to look into changing things if at all possible). -Db_sanitize=which allows enabling the chosen sanitizer on a system that supports sanitizers. The list of supported values is in the Meson documentation. --backend=backend allows using the specified backend for builds instead of ninja (the default). A list of supported values is in the Meson documentation. Most other built-in options will work, though keep in mind there are a handful of options that cannot be overridden because libui depends on them holding a specific value; if you do override these, though, libui will warn you when you run meson. The Meson website and documentation has more in-depth usage instructions. For the sake of completeness, I should note that the default value of --layout is flat, not the usual mirror. This is done both to make creating the release archives easier as well as to reduce the chance that shared library builds will fail to start on Windows because the DLL is in another directory. You can always specify this manually if you want. Backends other than ninja should work, but are untested by me. Installation Meson also supports installing from source; if you use Ninja, just do When running meson, the --prefix option will set the installation prefix. The Meson documentation has more information, and even lists more fine-grained options that you can use to control the installation. Arch Linux Can be built from AUR: https://aur.archlinux.org/packages/libui-git/ Documentation Needs to be written. Consult ui.h and the examples for details for now. Language Bindings libui was originally written as part of my package ui for Go. Now that libui is separate, package ui has become a binding to libui. As such, package ui is the only official binding. Other people have made bindings to other languages: Language | Bindings --- | --- C++ | libui-cpp, cpp-libui-qtlike C# / .NET Framework | LibUI.Binding C# / .NET Core | DevZH.UI, SharpUI, TCD.UI CHICKEN Scheme | wasamasa/libui Common Lisp | jinwoo/cl-ui Crystal | libui.cr, hedron D | DerelictLibui (flat API), libuid (object-oriented) Euphoria | libui-euphoria Harbour | hbui Haskell | haskell-libui JavaScript/Node.js | libui-node, libui.js (merged into libui-node?), proton-native, vuido Julia | Libui.jl Kotlin | kotlin-libui Lua | libuilua, libui-lua, lui, lui Nim | ui Perl6 | perl6-libui PHP | ui Python | pylibui Ruby | libui-ruby, libui Rust | libui-rs Scala | scalaui Swift | libui-swift Frequently Asked Questions Why does my program start in the background on OS X if I run from the command line? OS X normally does not start program executables directly; instead, it uses Launch Services to coordinate the launching of the program between the various parts of the system and the loading of info from an .app bundle. One of these coordination tasks is responsible for bringing a newly launched app into the foreground. This is called ""activation"". When you run a binary directly from the Terminal, however, you are running it directly, not through Launch Services. Therefore, the program starts in the background, because no one told it to activate! Now, it turns out there is an API that we can use to force our app to be activated. But if we use it, then we'd be trampling over Launch Services, which already knows whether it should activate or not. Therefore, libui does not step over Launch Services, at the cost of requiring an extra user step if running directly from the command line. See also this and this. Contributing See CONTRIBUTING.md. Screenshots From examples/controlgallery:"
2464,"The Microsoft Build Engine (MSBuild) is the build platform for .NET and Visual Studio.Microsoft.Build (MSBuild) The Microsoft Build Engine is a platform for building applications. This engine, also known as MSBuild, provides an XML schema for a project file that controls how the build platform processes and builds software. Visual Studio uses MSBuild, but MSBuild can run without Visual Studio. By invoking msbuild.exe on your project or solution file, you can orchestrate and build products in environments where Visual Studio isn't installed. For more information on MSBuild, see the MSBuild documentation on docs.microsoft.com. Build Status The current development branch is main. Changes in main will go into a future update of MSBuild, which will release with Visual Studio 17.0 and a corresponding version of the .NET Core SDK. We have forked for MSBuild 16.11 in the branch vs16.11. Changes to that branch need special approval. MSBuild 16.9 builds from the branch vs16.9. Only high-priority bugfixes will be considered for servicing 16.9. MSBuild 16.7 builds from the branch vs16.7. Only high-priority bugfixes will be considered for servicing 16.7. MSBuild 16.4 builds from the branch vs16.4. Only high-priority bugfixes will be considered for servicing 16.4. MSBuild 15.9 builds from the branch vs15.9. Only very-high-priority bugfixes will be considered for servicing 15.9. Building Building MSBuild with Visual Studio 2019 on Windows For the full supported experience, you will need to have Visual Studio 2019 or higher. To get started on Visual Studio 2019: Install Visual Studio 2019. Select the following Workloads: .NET desktop development .NET Core cross-platform development Open a Developer Command Prompt for VS 2019 prompt. Clone the source code: git clone https://github.com/dotnet/msbuild You may have to download Git first. Run .\build.cmd from the root of the repo to build the code. This also restores packages needed to open the projects in Visual Studio. Open MSBuild.sln or MSBuild.Dev.slnf in Visual Studio 2019. Note: To create a usable MSBuild with your changes, run .\build.cmd /p:CreateBootstrap=true. To build release, add -c Release: .\build.cmd -c Release /p:CreateBootstrap=true. This newly-built MSBuild will be located at artifacts\bin\bootstrap\net472\MSBuild\Current\Bin\MSBuild.exe. It may not work for all scenarios, including C++ builds. Building MSBuild in Unix (Mac & Linux) MSBuild can be run on Unix systems that support .NET Core. Set-up instructions can be viewed on the wiki: Building Testing and Debugging on .Net Core MSBuild Localization You can turn on localized builds via the /p:LocalizedBuild=true command line argument. For more information on localized builds and how to make contributions to MSBuild's translations, see our localization documentation Getting Started Before you contribute, please read through the contributing and developer guides to get an idea of what kinds of pull requests we accept. Contributing Guide Developer Guide on: .NET Core Full Framework Mono Looking for something to work on? This list of up for grabs issues is a great place to start. You are also encouraged to start a discussion by filing an issue or creating a gist. MSBuild Components MSBuild. Microsoft.Build.CommandLine is the entrypoint for the Microsoft Build Engine (MSBuild.exe). Microsoft.Build. The Microsoft.Build namespaces contain types that provide programmatic access to, and control of, the MSBuild engine. Microsoft.Build.Framework. The Microsoft.Build.Framework namespace contains the types that define how tasks and loggers interact with the MSBuild engine. For additional information on this component, see our Microsoft.Build.Framework wiki page. Microsoft.Build.Tasks. The Microsoft.Build.Tasks namespace contains the implementation of all tasks shipping with MSBuild. Microsoft.Build.Utilities. The Microsoft.Build.Utilities namespace provides helper classes that you can use to create your own MSBuild loggers and tasks. License MSBuild is licensed under the MIT license."
1487,"A streaming approach to JSON. Oboe.js speeds up web applications by providing parsed objects before the response completes.Oboe.js is an open source Javascript library for loading JSON using streaming, combining the convenience of DOM with the speed and fluidity of SAX. It can parse any JSON as a stream, is small enough to be a micro-library, doesn't have dependencies, and doesn't care which other libraries you need it to speak to. We can load trees larger than the available memory. Or we can instantiate classical OOP models from JSON, or completely transform your JSON while it is being read. Oboe makes it really easy to start using json from a response before the ajax request completes. Or even if it never completes. Where next? The website Visualise faster web applications through streaming Visit the project homepage Browse code examples Learn the Oboe.js API Download the library Discuss Oboe.js"
1108,"Pythonic command line arguments parser, that will make you smiledocopt creates beautiful command-line interfaces .. image:: https://travis-ci.org/docopt/docopt.svg?branch=master :target: https://travis-ci.org/docopt/docopt .. image:: https://img.shields.io/pypi/v/docopt.svg :target: https://pypi.python.org/pypi/docopt Video introduction to docopt: PyCon UK 2012: Create *beautiful* command-line interfaces with Python <http://youtu.be/pXhcPJK5cMc>_ New in version 0.6.1: - Fix issue `#85 <https://github.com/docopt/docopt/issues/85>`_ which caused improper handling of ``[options]`` shortcut if it was present several times. New in version 0.6.0: - New argument ``options_first``, disallows interspersing options and arguments. If you supply ``options_first=True`` to ``docopt``, it will interpret all arguments as positional arguments after first positional argument. - If option with argument could be repeated, its default value will be interpreted as space-separated list. E.g. with ``[default: ./here ./there]`` will be interpreted as ``['./here', './there']``. Breaking changes: - Meaning of ``[options]`` shortcut slightly changed. Previously it meant *""any known option""*. Now it means *""any option not in usage-pattern""*. This avoids the situation when an option is allowed to be repeated unintentionally. - ``argv`` is ``None`` by default, not ``sys.argv[1:]``. This allows ``docopt`` to always use the *latest* ``sys.argv``, not ``sys.argv`` during import time. Isn't it awesome how optparse and argparse generate help messages based on your code?! Hell no! You know what's awesome? It's when the option parser is generated based on the beautiful help message that you write yourself! This way you don't need to write this stupid repeatable parser-code, and instead can write only the help message--the way you want it. docopt helps you create most beautiful command-line interfaces easily: .. code:: python """"""Naval Fate. Usage: naval_fate.py ship new <name>... naval_fate.py ship <name> move <x> <y> [--speed=<kn>] naval_fate.py ship shoot <x> <y> naval_fate.py mine (set|remove) <x> <y> [--moored | --drifting] naval_fate.py (-h | --help) naval_fate.py --version Options: -h --help Show this screen. --version Show version. --speed=<kn> Speed in knots [default: 10]. --moored Moored (anchored) mine. --drifting Drifting mine. """""" from docopt import docopt if __name__ == '__main__': arguments = docopt(__doc__, version='Naval Fate 2.0') print(arguments) Beat that! The option parser is generated based on the docstring above that is passed to docopt function. docopt parses the usage pattern (""Usage: ..."") and option descriptions (lines starting with dash ""-"") and ensures that the program invocation matches the usage pattern; it parses options, arguments and commands based on that. The basic idea is that a good help message has all necessary information in it to make a parser. Also, PEP 257 <http://www.python.org/dev/peps/pep-0257/>_ recommends putting help message in the module docstrings. Installation Use pip <http://pip-installer.org>_ or easy_install:: pip install docopt==0.6.2 Alternatively, you can just drop docopt.py file into your project--it is self-contained. docopt is tested with Python 2.7, 3.4, 3.5, and 3.6. Testing You can run unit tests using the command: python setup.py test API .. code:: python from docopt import docopt .. code:: python docopt(doc, argv=None, help=True, version=None, options_first=False) docopt takes 1 required and 4 optional arguments: doc could be a module docstring (__doc__) or some other string that contains a help message that will be parsed to create the option parser. The simple rules of how to write such a help message are given in next sections. Here is a quick example of such a string: .. code:: python """"""Usage: my_program.py [-hso FILE] [--quiet | --verbose] [INPUT ...] -h --help show this -s --sorted sorted output -o FILE specify output file [default: ./test.txt] --quiet print less text --verbose print more text """""" argv is an optional argument vector; by default docopt uses the argument vector passed to your program (sys.argv[1:]). Alternatively you can supply a list of strings like ['--verbose', '-o', 'hai.txt']. help, by default True, specifies whether the parser should automatically print the help message (supplied as doc) and terminate, in case -h or --help option is encountered (options should exist in usage pattern, more on that below). If you want to handle -h or --help options manually (as other options), set help=False. version, by default None, is an optional argument that specifies the version of your program. If supplied, then, (assuming --version option is mentioned in usage pattern) when parser encounters the --version option, it will print the supplied version and terminate. version could be any printable object, but most likely a string, e.g. ""2.1.0rc1"". Note, when docopt is set to automatically handle -h, --help and --version options, you still need to mention them in usage pattern for this to work. Also, for your users to know about them. options_first, by default False. If set to True will disallow mixing options and positional argument. I.e. after first positional argument, all arguments will be interpreted as positional even if the look like options. This can be used for strict compatibility with POSIX, or if you want to dispatch your arguments to other programs. The return value is a simple dictionary with options, arguments and commands as keys, spelled exactly like in your help message. Long versions of options are given priority. For example, if you invoke the top example as:: naval_fate.py ship Guardian move 100 150 --speed=15 the return dictionary will be: .. code:: python {'--drifting': False, 'mine': False, '--help': False, 'move': True, '--moored': False, 'new': False, '--speed': '15', 'remove': False, '--version': False, 'set': False, '<name>': ['Guardian'], 'ship': True, '<x>': '100', 'shoot': False, '<y>': '150'} Help message format Help message consists of 2 parts: Usage pattern, e.g.:: Usage: my_program.py [-hso FILE] [--quiet | --verbose] [INPUT ...] Option descriptions, e.g.:: -h --help show this -s --sorted sorted output -o FILE specify output file [default: ./test.txt] --quiet print less text --verbose print more text Their format is described below; other text is ignored. Usage pattern format Usage pattern is a substring of doc that starts with usage: (case insensitive) and ends with a visibly empty line. Minimum example: .. code:: python """"""Usage: my_program.py """""" The first word after usage: is interpreted as your program's name. You can specify your program's name several times to signify several exclusive patterns: .. code:: python """"""Usage: my_program.py FILE my_program.py COUNT FILE """""" Each pattern can consist of the following elements: , ARGUMENTS. Arguments are specified as either upper-case words, e.g. my_program.py CONTENT-PATH or words surrounded by angular brackets: my_program.py <content-path>. --options. Options are words started with dash (-), e.g. --output, -o. You can ""stack"" several of one-letter options, e.g. -oiv which will be the same as -o -i -v. The options can have arguments, e.g. --input=FILE or -i FILE or even -iFILE. However it is important that you specify option descriptions if you want your option to have an argument, a default value, or specify synonymous short/long versions of the option (see next section on option descriptions). commands are words that do not follow the described above conventions of --options or <arguments> or ARGUMENTS, plus two special commands: dash ""-"" and double dash ""--"" (see below). Use the following constructs to specify patterns: [ ] (brackets) optional elements. e.g.: my_program.py [-hvqo FILE] ( ) (parens) required elements. All elements that are not put in [ ] are also required, e.g.: my_program.py --path=<path> <file>... is the same as my_program.py (--path=<path> <file>...). (Note, ""required options"" might be not a good idea for your users). | (pipe) mutually exclusive elements. Group them using ( ) if one of the mutually exclusive elements is required: my_program.py (--clockwise | --counter-clockwise) TIME. Group them using [ ] if none of the mutually-exclusive elements are required: my_program.py [--left | --right]. ... (ellipsis) one or more elements. To specify that arbitrary number of repeating elements could be accepted, use ellipsis (...), e.g. my_program.py FILE ... means one or more FILE-s are accepted. If you want to accept zero or more elements, use brackets, e.g.: my_program.py [FILE ...]. Ellipsis works as a unary operator on the expression to the left. options (case sensitive) shortcut for any options. You can use it if you want to specify that the usage pattern could be provided with any options defined below in the option-descriptions and do not want to enumerate them all in usage-pattern. ""[--]"". Double dash ""--"" is used by convention to separate positional arguments that can be mistaken for options. In order to support this convention add ""[--]"" to your usage patterns. ""[-]"". Single dash ""-"" is used by convention to signify that stdin is used instead of a file. To support this add ""[-]"" to your usage patterns. ""-"" acts as a normal command. If your pattern allows to match argument-less option (a flag) several times:: Usage: my_program.py [-v | -vv | -vvv] then number of occurrences of the option will be counted. I.e. args['-v'] will be 2 if program was invoked as my_program -vv. Same works for commands. If your usage patterns allows to match same-named option with argument or positional argument several times, the matched arguments will be collected into a list:: Usage: my_program.py <file> <file> --path=<path>... I.e. invoked with my_program.py file1 file2 --path=./here --path=./there the returned dict will contain args['<file>'] == ['file1', 'file2'] and args['--path'] == ['./here', './there']. Option descriptions format Option descriptions consist of a list of options that you put below your usage patterns. It is necessary to list option descriptions in order to specify: synonymous short and long options, if an option has an argument, if option's argument has a default value. The rules are as follows: Every line in doc that starts with - or -- (not counting spaces) is treated as an option description, e.g.:: Options: --verbose # GOOD -o FILE # GOOD Other: --bad # BAD, line does not start with dash ""-"" To specify that option has an argument, put a word describing that argument after space (or equals ""="" sign) as shown below. Follow either or UPPER-CASE convention for options' arguments. You can use comma if you want to separate options. In the example below, both lines are valid, however you are recommended to stick to a single style.:: -o FILE --output=FILE # without comma, with ""="" sign -i , --input # with comma, without ""="" sign Use two spaces to separate options with their informal description:: --verbose More text. # BAD, will be treated as if verbose option had # an argument ""More"", so use 2 spaces instead -q Quit. # GOOD -o FILE Output file. # GOOD --stdout Use stdout. # GOOD, 2 spaces If you want to set a default value for an option with an argument, put it into the option-description, in form [default: <my-default-value>]:: --coefficient=K The K coefficient [default: 2.95] --output=FILE Output file [default: test.txt] --directory=DIR Some directory [default: ./] If the option is not repeatable, the value inside [default: ...] will be interpreted as string. If it is repeatable, it will be splited into a list on whitespace:: Usage: my_program.py [--repeatable= --repeatable=] [--another-repeatable=]... [--not-repeatable=] will be ['./here', './there'] --repeatable= [default: ./here ./there] will be ['./here'] --another-repeatable= [default: ./here] will be './here ./there', because it is not repeatable --not-repeatable= [default: ./here ./there] Examples We have an extensive list of examples <https://github.com/docopt/docopt/tree/master/examples>_ which cover every aspect of functionality of docopt. Try them out, read the source if in doubt. Subparsers, multi-level help and huge applications (like git) If you want to split your usage-pattern into several, implement multi-level help (with separate help-screen for each subcommand), want to interface with existing scripts that don't use docopt, or you're building the next ""git"", you will need the new options_first parameter (described in API section above). To get you started quickly we implemented a subset of git command-line interface as an example: examples/git <https://github.com/docopt/docopt/tree/master/examples/git>_ Data validation docopt does one thing and does it well: it implements your command-line interface. However it does not validate the input data. On the other hand there are libraries like python schema <https://github.com/halst/schema> which make validating data a breeze. Take a look at validation_example.py <https://github.com/docopt/docopt/tree/master/examples/validation_example.py> which uses schema to validate data and report an error to the user. Using docopt with config-files Often configuration files are used to provide default values which could be overriden by command-line arguments. Since docopt returns a simple dictionary it is very easy to integrate with config-files written in JSON, YAML or INI formats. config_file_example.py <examples/config_file_example.py>_ provides and example of how to use docopt with JSON or INI config-file. Development We would love to hear what you think about docopt on our issues page <http://github.com/docopt/docopt/issues>_ Make pull requests, report bugs, suggest ideas and discuss docopt. You can also drop a line directly to vladimir@keleshev.com. Porting docopt to other languages We think docopt is so good, we want to share it beyond the Python community! All official docopt ports to other languages can be found under the docopt organization page <http://github.com/docopt>_ on GitHub. If your favourite language isn't among then, you can always create a port for it! You are encouraged to use the Python version as a reference implementation. A Language-agnostic test suite is bundled with Python implementation <http://github.com/docopt/docopt>_. Porting discussion is on issues page <http://github.com/docopt/docopt/issues>_. Changelog docopt follows semantic versioning <http://semver.org>_. The first release with stable API will be 1.0.0 (soon). Until then, you are encouraged to specify explicitly the version in your dependency tools, e.g.:: pip install docopt==0.6.2 0.6.2 Bugfix release. 0.6.1 Bugfix release. 0.6.0 options_first parameter. Breaking changes: Corrected [options] meaning. argv defaults to None. 0.5.0 Repeated options/commands are counted or accumulated into a list. 0.4.2 Bugfix release. 0.4.0 Option descriptions become optional, support for ""--"" and ""-"" commands. 0.3.0 Support for (sub)commands like git remote add. Introduce [options] shortcut for any options. Breaking changes: docopt returns dictionary. 0.2.0 Usage pattern matching. Positional arguments parsing based on usage patterns. Breaking changes: docopt returns namespace (for arguments), not list. Usage pattern is formalized. 0.1.0 Initial release. Options-parsing only (based on options description)."
3427,"Reactive, responsive, beautiful charts for AngularJS using Chart.js: http://jtblin.github.io/angular-chart.jsangular-chart.js Beautiful, reactive, responsive charts for Angular.JS using Chart.js. Have a look at the demo site to see examples with detailed markup, script and options. Installation This is the 1.x branch which requires Chart.js 2.x version. Following semantic versioning, there are numerous breaking changes since 0.x, notably: all options now need to use the chart- prefix chart-colours is now chart-colors and chart-get-colour is now chart-get-color chart types are in camelCase e.g. line and polarArea legend is now a Chart.js option so the chart-legend attribute has been removed events emitted on creation and update are now prefixed with chart- e.g. chart-create $scope.$apply is not called anymore on mouse hover functions calls obviously all Chart.js breaking changes as well in how options are set, etc. disabling the responsive option doesn't work via global Chart.defaults.global.responsive anymore, but must be set via standard options e.g. ChartJsProvider.setOptions({ responsive: false }); factory now returns a module name instead of a module instance npm npm install --save angular-chart.js cdn //cdn.jsdelivr.net/angular.chartjs/latest/angular-chart.min.js bower bower install --save angular-chart.js manually or copy the files from dist/. Then add the sources to your code (adjust paths as needed) after adding the dependencies for Angular and Chart.js first: Utilisation There are 8 types of charts so 8 directives: chart-line, chart-bar, chart-horizontal-bar, chart-radar, chart-pie, chart-polar-area, chart-doughnut, chart-bubble. Here are the options for all directives: chart-data: series data chart-labels: x axis labels (line, bar, horizontal bar, radar, bubble) or series labels (pie, doughnut, polar area) chart-options: chart options (as from Chart.js documentation) chart-series: (default: []): series labels (line, bar, radar) chart-colors: data colors (will use default colors if not specified) chart-get-color: function that returns a color in case there are not enough (will use random colors if not specified) chart-click: onclick event handler chart-hover: onmousemove event handler chart-dataset-override: override individual datasets to allow per dataset configuration e.g. y-axis, mixed type chart There is another directive chart-base that takes an extra attribute chart-type to define the type dynamically. You can create mixed type chart using the chart-dataset-override, see bar-line example. See also stacked bar example. Example Markup Javascript AMD RequireJS See a simple AMD example CommonJS e.g. webpack Module should work with CommonJS out of the box e.g. browserify or webpack, see a webpack example. Reactive angular-chart.js watch updates on data, series, labels, colors and options and will update, or destroy and recreate, the chart on changes. Events angular-chart.js listens to the following events on the scope and acts accordingly: $destroy: call .destroy() on the chart $resize: call .resize() on the chart angular-chart.js emits the following events on the scope and pass the chart as argument: chart-create: when chart is created chart-update: when chart is updated chart-destroy: when chart is destroyed Note: the event can be emitted multiple times for each chart as the chart can be destroyed and created multiple times during angular watch lifecycle. angular-chart.js listens to the scope $destroy event and destroys the chart when it happens. Colors There are a set of 7 default colors. Colors can be replaced using the colors attribute. If there is more data than colors, colors are generated randomly or can be provided via a function through the getColor attribute. Hex colors are converted to Chart.js colors automatically, including different shades for highlight, fill, stroke, etc. RGB colors may be input by using a string in the format ""rgb(r,g,b)"". Example - RGB Colors RGBA colors may also be input by using a string in the format ""rgba(r,g,b,a)"". They may be used alongside RGB colors and/or Hex colors. Example - RGBA Colors Colors may also be input as an object by using the format in the example below. Colors input as objects, Hex colors, RGB, and RGBA colors may be mixed and matched. Example - input color as an object Browser compatibility For IE8 and older browsers, you will need to include excanvas. You will also need a shim for ES5 functions. You also need to have and attributes for the tag of your chart if using IE8 and older browsers. If you do not have these attributes, you will need a getComputedStyle shim and the line , but there still may be errors (due to code in Chart.js). Issues Issues or feature requests for Chart.js (e.g. new chart type, new axis, etc.) need to be opened on Chart.js issues tracker For general questions about usage, please use http://stackoverflow.com/ Please check if issue exists first, otherwise open issue in github. Ensure you add a link to a plunker, jsbin, or equivalent. Here is a jsbin template for convenience. v0.x - Chart.js v1.x - deprecated This is the deprecated version of angular-chart.js that uses the v1.x version of Chart.js. If you want to use this version, please checkout the chartjs-1.x branch Contributing Pull requests welcome! See CONTRIBUTING.md. Contributors Thank you to the contributors! Author Jerome Touffe-Blin, @jtblin, About me License angular-chart.js is copyright 2016 Jerome Touffe-Blin and contributors. It is licensed under the BSD license. See the include LICENSE file for details."
1210,"Config files for vim and tmux.Maximum Awesome Config files for vim and tmux, lovingly tended by a small subculture of peace-loving hippies. Built for Mac OS X. What's in it? MacVim (independent or for use in a terminal) iTerm 2 tmux Awesome syntax highlighting with the Solarized color scheme Want to know more? Fly Vim, First Class vim ,d brings up NERDTree, a sidebar buffer for navigating and manipulating files ,t brings up ctrlp.vim, a project file filter for easily opening specific files ,b restricts ctrlp.vim to open buffers ,a starts project search with ag.vim using the silver searcher (like ack, but faster) ds/cs delete/change surrounding characters (e.g. ""Hey!"" + ds"" = Hey!, ""Hey!"" + cs""' = 'Hey!') with vim-surround gcc toggles current line comment gc toggles visual selection comment lines vii/vai visually select in or around the cursor's indent Vp/vp replaces visual selection with default register without yanking selected text (works with any visual selection) ,[space] strips trailing whitespace <C-]> jump to definition using ctags ,l begins aligning lines on a string, usually used as ,l= to align assignments <C-hjkl> move between windows, shorthand for <C-w> hjkl tmux <C-a> is the prefix mouse scroll initiates tmux scroll prefix v makes a vertical split prefix s makes a horizontal split If you have three or more panes: * prefix + opens up the main-horizontal-layout * prefix = opens up the main-vertical-layout You can adjust the size of the smaller panes in tmux.conf by lowering or increasing the other-pane-height and other-pane-width options. Install rake Update rake This will update all installed plugins using Vundle's :PluginInstall! command. Any errors encountered during this process may be resolved by clearing out the problematic directories in ~/.vim/bundle. :help PluginInstall provides more detailed information about Vundle. Customize In your home directory, Maximum Awesome creates .vimrc.local, .vimrc.bundles.local and .tmux.conf.local files where you can customize Vim and tmux to your hearts content. However, wed love to incorporate your changes and improve Vim and tmux for everyone, so feel free to fork Maximum Awesome and open some pull requests! Uninstall rake uninstall Note that this won't remove everything, but your vim configuration should be reset to whatever it was before installing. Some uninstallation steps will be manual. Contribute Before creating your pull request, consider whether the feature you want to add is something that you think every user of maximum-awesome should have. Is it support for a very common language people would ordinarily use vim to write? Is it a useful utility that does not change many defaults and composes well with other parts of maximum-awesome? If so then perhaps it would be a good fit. If not, perhaps keep it in your *.local files. This does not apply to bug fixes. Fork it Create your feature branch (git checkout -b my-new-feature) Commit your changes (git commit -am 'Add some feature') Push to the branch (git push origin my-new-feature) Create new Pull Request Any contributors to the master maximum-awesome repository must sign the Individual Contributor License Agreement (CLA). It's a short form that covers our bases and makes sure you're eligible to contribute. When you have a change you'd like to see in the master repository, send a pull request. Before we merge your request, we'll make sure you're in the list of people who have signed a CLA. Acknowledgements Thanks to the vimsters at Square who put this together. Thanks to Tim Pope for his awesome vim plugins."
721,"Forms made easy for Rails! It's tied to a simple DSL, with no opinion on markup.Rails forms made easy. Simple Form aims to be as flexible as possible while helping you with powerful components to create your forms. The basic goal of Simple Form is to not touch your way of defining the layout, letting you find the better design for your eyes. Most of the DSL was inherited from Formtastic, which we are thankful for and should make you feel right at home. INFO: This README refers to Simple Form 5.0. For older releases, check the related branch for your version. Installation Add it to your Gemfile: Run the following command to install it: Run the generator: Bootstrap Simple Form can be easily integrated to the Bootstrap. To do that you have to use the bootstrap option in the install generator, like this: You have to be sure that you added a copy of the Bootstrap assets on your application. For more information see the generator output, our example application code and the live example app. Zurb Foundation 5 To generate wrappers that are compatible with Zurb Foundation 5, pass the foundation option to the generator, like this: Please note that the Foundation wrapper does not support the :hint option by default. In order to enable hints, please uncomment the appropriate line in config/initializers/simple_form_foundation.rb. You will need to provide your own CSS styles for hints. Please see the instructions on how to install Foundation in a Rails app. Country Select If you want to use the country select, you will need the country_select gem, add it to your Gemfile: If you don't want to use the gem you can easily override this behaviour by mapping the country inputs to something else, with a line like this in your simple_form.rb initializer: Usage Simple Form was designed to be customized as you need to. Basically it's a stack of components that are invoked to create a complete html input for you, which by default contains label, hints, errors and the input itself. It does not aim to create a lot of different logic from the default Rails form helpers, as they do a great job by themselves. Instead, Simple Form acts as a DSL and just maps your input type (retrieved from the column definition in the database) to a specific helper method. To start using Simple Form you just have to use the helper it provides: This will generate an entire form with labels for user name and password as well, and render errors by default when you render the form with invalid data (after submitting for example). You can overwrite the default label by passing it to the input method. You can also add a hint, an error, or even a placeholder. For boolean inputs, you can add an inline label as well: In some cases you may want to disable labels, hints or errors. Or you may want to configure the html of any of them: It is also possible to pass any html attribute straight to the input, by using the :input_html option, for instance: If you want to pass the same options to all inputs in the form (for example, a default class), you can use the :defaults option in simple_form_for. Specific options in input call will overwrite the defaults: Since Simple Form generates a wrapper div around your label and input by default, you can pass any html attribute to that wrapper as well using the :wrapper_html option, like so: Required fields are marked with an * prepended to their labels. By default all inputs are required. When the form object includes ActiveModel::Validations (which, for example, happens with Active Record models), fields are required only when there is presence validation. Otherwise, Simple Form will mark fields as optional. For performance reasons, this detection is skipped on validations that make use of conditional options, such as :if and :unless. And of course, the required property of any input can be overwritten as needed: By default, Simple Form will look at the column type in the database and use an appropriate input for the column. For example, a column created with type :text in the database will use a textarea input by default. See the section Available input types and defaults for each column type for a complete list of defaults. Simple Form also lets you overwrite the default input type it creates: So instead of a checkbox for the accepts attribute, you'll have a pair of radio buttons with yes/no labels and a textarea instead of a text field for the description. You can also render boolean attributes using as: :select to show a dropdown. It is also possible to give the :disabled option to Simple Form, and it'll automatically mark the wrapper as disabled with a CSS class, so you can style labels, hints and other components inside the wrapper as well: Simple Form inputs accept the same options as their corresponding input type helper in Rails: Simple Form also allows you to use label, hint, input_field, error and full_error helpers (please take a look at the rdocs for each method for more info): Any extra option passed to these methods will be rendered as html option. Stripping away all wrapper divs Simple Form also allows you to strip away all the div wrappers around the <input> field that is generated with the usual f.input. The easiest way to achieve this is to use f.input_field. Example: For check boxes and radio buttons you can remove the label changing boolean_style from default value :nested to :inline. Example: To view the actual RDocs for this, check them out here - http://rubydoc.info/github/heartcombo/simple_form/master/SimpleForm/FormBuilder:input_field Collections And what if you want to create a select containing the age from 18 to 60 in your form? You can do it overriding the :collection option: Collections can be arrays or ranges, and when a :collection is given the :select input will be rendered by default, so we don't need to pass the as: :select option. Other types of collection are :radio_buttons and :check_boxes. Those are added by Simple Form to Rails set of form helpers (read Extra Helpers section below for more information). Collection inputs accept two other options beside collections: label_method => the label method to be applied to the collection to retrieve the label (use this instead of the text_method option in collection_select) value_method => the value method to be applied to the collection to retrieve the value Those methods are useful to manipulate the given collection. Both of these options also accept lambda/procs in case you want to calculate the value or label in a special way eg. custom translation. You can also define a to_label method on your model as Simple Form will search for and use :to_label as a :label_method first if it is found. By default, Simple Form will use the first item from an array as the label and the second one as the value. If you want to change this behavior you must make it explicit, like this: All other options given are sent straight to the underlying Rails helper(s): collection_select, collection_check_boxes, collection_radio_buttons. For example, you can pass prompt and selected as: It may also be useful to explicitly pass a value to the optional :selected like above, especially if passing a collection of nested objects. It is also possible to create grouped collection selects, that will use the html optgroup tags, like this: Grouped collection inputs accept the same :label_method and :value_method options, which will be used to retrieve label/value attributes for the option tags. Besides that, you can give: group_method => the method to be called on the given collection to generate the options for each group (required) group_label_method => the label method to be applied on the given collection to retrieve the label for the optgroup (Simple Form will attempt to guess the best one the same way it does with :label_method) Priority Simple Form also supports :time_zone and :country. When using such helpers, you can give :priority as an option to select which time zones and/or countries should be given higher priority: Those values can also be configured with a default value to be used on the site through the SimpleForm.country_priority and SimpleForm.time_zone_priority helpers. Note: While using country_select if you want to restrict to only a subset of countries for a specific drop down then you may use the :collection option: Associations To deal with associations, Simple Form can generate select inputs, a series of radios buttons or checkboxes. Lets see how it works: imagine you have a user model that belongs to a company and has_and_belongs_to_many roles. The structure would be something like: Now we have the user form: Simple enough, right? This is going to render a :select input for choosing the :company, and another :select input with :multiple option for the :roles. You can, of course, change it to use radio buttons and checkboxes as well: The association helper just invokes input under the hood, so all options available to :select, :radio_buttons and :check_boxes are also available to association. Additionally, you can specify the collection by hand, all together with the prompt: In case you want to declare different labels and values: Please note that the association helper is currently only tested with Active Record. It currently does not work well with Mongoid and depending on the ORM you're using your mileage may vary. Buttons All web forms need buttons, right? Simple Form wraps them in the DSL, acting like a proxy: The above will simply call submit. You choose to use it or not, it's just a question of taste. The button method also accepts optional parameters, that are delegated to the underlying submit call: To create a <button> element, use the following syntax: Wrapping Rails Form Helpers Say you wanted to use a rails form helper but still wrap it in Simple Form goodness? You can, by calling input with a block like so: In the above example, we're taking advantage of Rails 3's select method that allows us to pass in a hash of additional attributes for each option. Extra helpers Simple Form also comes with some extra helpers you can use inside rails default forms without relying on simple_form_for helper. They are listed below. Simple Fields For Wrapper to use Simple Form inside a default rails form. It works in the same way that the fields_for Rails helper, but change the builder to use the SimpleForm::FormBuilder. Collection Radio Buttons Creates a collection of radio inputs with labels associated (same API as collection_select): Collection Check Boxes Creates a collection of checkboxes with labels associated (same API as collection_select): To use this with associations in your model, you can do the following: To add a CSS class to the label item, you can use the item_label_class option: Available input types and defaults for each column type The following table shows the html element you will get for each attribute according to its database definition. These defaults can be changed by specifying the helper method in the column Mapping as the as: option. Mapping | Generated HTML Element | Database Column Type --------------- |--------------------------------------|--------------------- boolean | input[type=checkbox] | boolean string | input[type=text] | string citext | input[type=text] | citext email | input[type=email] | string with name =~ /email/ url | input[type=url] | string with name =~ /url/ tel | input[type=tel] | string with name =~ /phone/ password | input[type=password] | string with name =~ /password/ search | input[type=search] | - uuid | input[type=text] | uuid color | input[type=color] | string text | textarea | text hstore | textarea | hstore json | textarea | json jsonb | textarea | jsonb file | input[type=file] | string responding to file methods hidden | input[type=hidden] | - integer | input[type=number] | integer float | input[type=number] | float decimal | input[type=number] | decimal range | input[type=range] | - datetime | datetime select | datetime/timestamp date | date select | date time | time select | time select | select | belongs_to/has_many/has_and_belongs_to_many associations radio_buttons | collection of input[type=radio] | belongs_to associations check_boxes | collection of input[type=checkbox] | has_many/has_and_belongs_to_many associations country | select (countries as options) | string with name =~ /country/ time_zone | select (timezones as options) | string with name =~ /time_zone/ Custom inputs It is very easy to add custom inputs to Simple Form. For instance, if you want to add a custom input that extends the string one, you just need to add this file: And use it in your views: Note, you may have to create the app/inputs/ directory and restart your webserver. You can also redefine existing Simple Form inputs by creating a new class with the same name. For instance, if you want to wrap date/time/datetime in a div, you can do: Or if you want to add a class to all the select fields you can do: If needed, you can namespace your custom inputs in a module and tell Simple Form to look for their definitions in this module. This can avoid conflicts with other form libraries (like Formtastic) that look up the global context to find inputs definition too. And in the SimpleForm initializer : Custom form builder You can create a custom form builder that uses Simple Form. Create a helper method that calls simple_form_for with a custom builder: Create a form builder class that inherits from SimpleForm::FormBuilder. I18n Simple Form uses all power of I18n API to lookup labels, hints, prompts and placeholders. To customize your forms you can create a locale file like this: And your forms will use this information to render the components for you. Simple Form also lets you be more specific, separating lookups through actions. Let's say you want a different label for new and edit actions, the locale file would be something like: This way Simple Form will figure out the right translation for you, based on the action being rendered. And to be a little bit DRYer with your locale file, you can specify defaults for all models under the 'defaults' key: Simple Form will always look for a default attribute translation under the ""defaults"" key if no specific is found inside the model key. In addition, Simple Form will fallback to default human_attribute_name from Rails when no other translation is found for labels. Finally, you can also overwrite any label, hint or placeholder inside your view, just by passing the option manually. This way the I18n lookup will be skipped. For :prompt and :include_blank the I18n lookup is optional and to enable it is necessary to pass :translate as value. Simple Form also has support for translating options in collection helpers. For instance, given a User with a :role attribute, you might want to create a select box showing translated labels that would post either :admin or :editor as value. With Simple Form you could create an input like this: And Simple Form will try a lookup like this in your locale file, to find the right labels to show: You can also use the defaults key as you would do with labels, hints and placeholders. It is important to notice that Simple Form will only do the lookup for options if you give a collection composed of symbols only. This is to avoid constant lookups to I18n. It's also possible to translate buttons, using Rails' built-in I18n support: There are other options that can be configured through I18n API, such as required text and boolean. Be sure to check our locale file or the one copied to your application after you run rails generate simple_form:install. It should be noted that translations for labels, hints and placeholders for a namespaced model, e.g. Admin::User, should be placed under admin_user, not under admin/user. This is different from how translations for namespaced model and attribute names are defined: They should be placed under admin/user. Form labels, hints and placeholders for those attributes, though, should be placed under admin_user: This difference exists because Simple Form relies on object_name provided by Rails' FormBuilder to determine the translation path for a given object instead of i18n_key from the object itself. Thus, similarly, if a form for an Admin::User object is defined by calling simple_form_for @admin_user, as: :some_user, Simple Form will look for translations under some_user instead of admin_user. When translating simple_fields_for attributes be sure to use the same name you pass to it, e.g. simple_fields_for :posts should be placed under posts not post: Configuration Simple Form has several configuration options. You can read and change them in the initializer created by Simple Form, so if you haven't executed the command below yet, please do: rails generate simple_form:install The wrappers API With Simple Form you can configure how your components will be rendered using the wrappers API. The syntax looks like this: The Form components will generate the form tags like labels, inputs, hints or errors contents. The available components are: The Form extensions are used to generate some attributes or perform some lookups on the model to add extra information to your components. You can create new Form components using the wrappers API as in the following example: this will wrap the hint and error components within a div tag using the class 'separator'. You can customize Form components passing options to them: This sets the input and label classes to 'label-input-class' and will set the class 'is-invalid' if the input has errors and 'is-valid' if the input is valid. If you want to customize the custom Form components on demand you can give it a name like this: and now you can pass options to your input calls to customize the :my_wrapper Form component. You can also define more than one wrapper and pick one to render in a specific form or input. To define another wrapper you have to give it a name, as the follow: and use it in this way: Simple Form also allows you to use optional elements. For instance, let's suppose you want to use hints or placeholders, but you don't want them to be generated automatically. You can set their default values to false or use the optional method. Is preferable to use the optional syntax: By setting it as optional, a hint will only be generated when hint: true is explicitly used. The same for placeholder. It is also possible to give the option :unless_blank to the wrapper if you want to render it only when the content is present. Custom Components When you use custom wrappers, you might also be looking for a way to add custom components to your wrapper. The default components are: A custom component might be interesting for you if your views look something like this: A cleaner method to create your views would be: To use the number option on the input, first, tells to Simple Form the place where the components will be: Create a new component within the path specified above: Finally, add a new wrapper to the config/initializers/simple_form.rb file: HTML 5 Notice By default, Simple Form will generate input field types and attributes that are supported in HTML5, but are considered invalid HTML for older document types such as HTML4 or XHTML1.0. The HTML5 extensions include the new field types such as email, number, search, url, tel, and the new attributes such as required, autofocus, maxlength, min, max, step. Most browsers will not care, but some of the newer ones - in particular Chrome 10+ - use the required attribute to force a value into an input and will prevent form submission without it. Depending on the design of the application this may or may not be desired. In many cases it can break existing UI's. It is possible to disable all HTML 5 extensions in Simple Form by removing the html5 component from the wrapper used to render the inputs. For example, change: To: If you want to have all other HTML 5 features, such as the new field types, you can disable only the browser validation: This option adds a new novalidate property to the form, instructing it to skip all HTML 5 validation. The inputs will still be generated with the required and other attributes, that might help you to use some generic javascript validation. You can also add novalidate to a specific form by setting the option on the form itself: Please notice that none of the configurations above will disable the placeholder component, which is an HTML 5 feature. We believe most of the newest browsers are handling this attribute just fine, and if they aren't, any plugin you use would take care of applying the placeholder. In any case, you can disable it if you really want to, by removing the placeholder component from the components list in the Simple Form configuration file. HTML 5 date / time inputs are not generated by Simple Form by default, so using date, time or datetime will all generate select boxes using normal Rails helpers. We believe browsers are not totally ready for these yet, but you can easily opt-in on a per-input basis by passing the html5 option: Using non Active Record objects There are few ways to build forms with objects that don't inherit from Active Record, as follows: You can include the module ActiveModel::Model. If you are using Presenters or Decorators that inherit from SimpleDelegator you can delegate it to the model. You can define all methods required by the helpers. If your object doesn't implement those methods, you must make explicit it when you are building the form Information RDocs You can view the Simple Form documentation in RDoc format here: http://rubydoc.info/github/heartcombo/simple_form/master/frames Supported Ruby / Rails versions We intend to maintain support for all Ruby / Rails versions that haven't reached end-of-life. For more information about specific versions please check Ruby and Rails maintenance policies, and our test matrix. Bug reports If you discover any bugs, feel free to create an issue on GitHub. Please add as much information as possible to help us in fixing the potential bug. We also encourage you to help even more by forking and sending us a pull request. https://github.com/heartcombo/simple_form/issues If you have discovered a security related bug, please do NOT use the GitHub issue tracker. Send an e-mail to heartcombo@googlegroups.com. Maintainers Carlos Antonio da Silva (https://github.com/carlosantoniodasilva) Rafael Mendona Frana (https://github.com/rafaelfranca) Felipe Renan (https://github.com/feliperenan) License MIT License. Copyright 2020 Rafael Frana, Carlos Antnio da Silva. Copyright 2009-2019 Plataformatec. The Simple Form logo is licensed under Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International License."
2572,"Zero watches binding for AngularJsBindonce High performance binding for AngularJs Usage download, clone or fork it or install it using bower bower install angular-bindonce Include the bindonce.js script provided by this component into your app. Add 'pasvaz.bindonce' as a module dependency to your app: angular.module('app', ['pasvaz.bindonce']) Demo Here is an example of how AngularJs can freeze your UI, try to press and hold a key inside the input field, when the table is filled with only 1 person everything is ok, you can see how the DOM is updated by the input in real time, however if you try to load 1000 person (or even 500 if the testing device is not powerfull) and repeat the experiment you can see how the UI is frozen. In this other demo BindOnce will take care of your watchers and the UI will be reactive as it should be. The code is the same for both demos, the only difference is that I replaced any ng-* tag inside the table with the equivalent bo-* tag. * AngularJs regular Demo * Demo with Bindonce Overview AngularJs provides a great data binding system but if you abuse of it the page can run into some performance issues, it's known that more of 2000 watchers can lag the UI and that amount can be reached easily if you don't pay attention to the data-binding. Sometime you really need to bind your data using watchers, especially for SPA because the data are updated in real time, but often you can avoid it with some efforts, most of the data presented in your page, once rendered, are immutable so you shouldn't keep watching them for changes. For instance, take a look to this snippet: Angular internally creates a $watch for each ng-* directive in order to keep the data up to date, so in this example just for displaying few info it creates 6 + 1 (ngRepeatWatch) watchers per person, even if the person is supposed to remain the same once shown. Iterate this amount for each person and you can have an idea about how easy is to reach 2000 watchers. Now if you need it because those data could change while you show the page or are bound to some models, it's ok. But most of the time they are static data that don't change once rendered. This is where bindonce can really help you. The above example done with bindonce: Now this example uses 0 watches per person and renders exactly the same result as the above that uses ng-. (Angular still uses 1 watcher for ngRepeatWatch)* The smart approach OK until here nothing completely new, with a bit of efforts you could create your own directive and render the person inside the link function, or you could use watch fighters that has a similar approach, but there is still one problem that you have to face and bindonce already handles it: the existence of the data when the directive renders the content. Usually the directives, unless you use watchers or bind their attributes to the scope (still a watcher), render the content when they are loaded into the markup, but if at that given time your data is not available, the directive can't render it. Bindonce can wait until the data is ready before to rendering the content. Let's take a look at the follow snippet to better understand the concept: This basic directive works as expected, it renders the Person data without using any watchers. However, if Person is not yet available inside the $scope when the page is loaded (say we get Person via $http or via $resource), the directive is useless, scope.$eval(attr.myCustomSetText) simply renders nothing and exits. Here is how we can solve this issue with bindonce: bindonce=""Person"" does the trick, any bo-* attribute belonging to bindonce waits until the parent bindonce=""{somedata}"" is validated and then renders its content. Once the scope contains the value Person then each bo- child gets filled with the proper values. In order to accomplish this task, bindonce uses just one* temporary watcher, no matters how many children need to be rendered. As soon as it gets Person the watcher is promptly removed. If the $scope already contains the data bindonce is looking for, then it doesn't create the temporary watcher and simply starts rendering its children. You may have noticed that the first example didn't assign any value to the bindonce attribute: when used with ng-repeat bindonce doesn't need to check if person is defined because ng-repeat creates the directives only when person exists. You could be more explicit: <li bindonce=""person"" ng-repeat=""person in Persons"">, however assigning a value to bindonce in an ng-repeat won't make any difference. Interpolation Some directives (ng-href, ng-src) use interpolation, ie: ng-href=""/profile/{{User.profileId}}"". Both ng-href and ng-src have the bo- equivalent directives: bo-href-i and bo-src-i (pay attention to the -i, it stands for interpolate). As expected they don't use watchers however Angular creates one watcher per interpolation, for instance bo-href-i=""/profile/{{User.profileId}}"" sets the element's href once*, as expected, but Angular keeps a watcher active on {{User.profileId}} even if bo-href-i doesn't use it. That's why by default the bo-href doesn't use interpolation or watchers. The above equivalent with 0 watchers would be bo-href=""'/profile/' + User.profileId"". Nevertheless, bo-href-i and bo-src-i are still maintained for compatibility reasons. Filters Almost every bo-* directive replace the equivalent ng-* and works in the same ways, except it is evaluated once. Consequentially you can use any valid angular expression, including filters. This is an example how to use a filter: Attribute Usage | Directive | Description | Example | |------------|----------------|-----| | bindonce=""{somedata}""| bindonce is the main directive. {somedata} is optional, and if present, forces bindonce to wait until somedata is defined before rendering its children | <div bindonce=""Person"">...<div> | | bo-if = ""condition"" | equivalent to ng-if but doesn't use watchers |<ANY bo-if=""Person.isPublic""></ANY>| | bo-switch = ""expression"" | equivalent to ng-switch but doesn't use watchers |<div bo-switch=""Person.isPublic""> <span bo-switch-when=""'yes"">public</span> <span bo-switch-default>private</span> </div>| | bo-show = ""condition"" | equivalent to ng-show but doesn't use watchers |<ANY bo-show=""Person.isPublic""></ANY>| | bo-hide = ""condition"" | equivalent to ng-hide but doesn't use watchers |<ANY bo-hide=""Person.isPrivate""></ANY>| | bo-disabled = ""condition"" | equivalent to ng-disabled but doesn't use watchers |<ANY bo-disabled=""Person.isUnavailable""></ANY>| | bo-text = ""text"" | evaluates ""text"" and print it as text inside the element | <span bo-text=""Person.name""></span> | | bo-bind = ""text"" | alias for bo-text, equivalent to ng-bind but doesn't use watchers | <span bo-bind=""Person.name""></span> | | bo-html = ""markup"" | evaluates ""markup"" and render it as html inside the element |bo-html=""Person.description""| | bo-href-i = ""url""use bo-href instead | equivalent to ng-href.Heads up! Using interpolation {{}} it creates one watcher: bo-href-i=""/p/{{Person.id}}"". Use bo-href to avoid the watcher: bo-href=""'/p/' + Person.id"" |<a bo-href-i=""/profile{{Person.id}}""></a>| | bo-href = ""url"" | similar to ng-href but doesn't allow interpolation using {{}} like ng-href. Heads up! You can't use interpolation {{}} inside the url, use bo-href-i for that purpose |<a bo-href=""'/profile' + Person.id""></a> or <a bo-href=""link"" bo-text=""Link""></a>| | bo-src-i = ""url""use bo-src instead | equivalent to ng-src. Heads up! It creates one watcher |<img bo-src-i=""{{picture}}"" bo-alt=""title"">| | bo-src = ""url"" | similar to ng-src but doesn't allow interpolation using {{}} like ng-src. Heads up! You can't use interpolation {{}}, use bo-src-i for that purpose |<img bo-src=""picture"" bo-alt=""title"">| | bo-class = ""object/string"" | equivalent to ng-class but doesn't use watchers |<span bo-class=""{'fancy':Person.condition}"">| | bo-alt = ""text"" | evaluates ""text"" and render it as alt for the element |<ANY bo-alt=""title"">| | bo-title = ""text"" | evaluates ""text"" and render it as title for the element |<ANY bo-title=""title"">| | bo-id = ""#id"" | evaluates ""#id"" and render it as id for the element |<ANY bo-id=""id"">| | bo-style = ""object"" | equivalent to ng-style but doesn't use watchers |<ANY bo-style=""{'color':Person.color}"">| | bo-value = ""expression"" | evaluates ""expression"" and render it as value for the element |<input type=""radio"" bo-value=""value"">| | bo-attr bo-attr-foo = ""text"" | evaluates ""text"" and render it as a custom attribute for the element |<div bo-attr bo-attr-foo=""bar""></div>| Build Todo Tests Copyright BindOnce was written by Pasquale Vazzana, you can follow him on google+ or on @twitter Thanks to all the contributors LICENSE - ""MIT License"" Copyright (c) 2013-2014 Pasquale Vazzana Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the ""Software""), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
3322,rmremove for some reason.
43,"Based on a true storyEnglish | Hacker Scripts Based on a true story: xxx: OK, so, our build engineer has left for another company. The dude was literally living inside the terminal. You know, that type of a guy who loves Vim, creates diagrams in Dot and writes wiki-posts in Markdown... If something - anything - requires more than 90 seconds of his time, he writes a script to automate that. xxx: So we're sitting here, looking through his, uhm, ""legacy"" xxx: You're gonna love this xxx: smack-my-bitch-up.sh - sends a text message ""late at work"" to his wife (apparently). Automatically picks reasons from an array of strings, randomly. Runs inside a cron-job. The job fires if there are active SSH-sessions on the server after 9pm with his login. xxx: kumar-asshole.sh - scans the inbox for emails from ""Kumar"" (a DBA at our clients). Looks for keywords like ""help"", ""trouble"", ""sorry"" etc. If keywords are found - the script SSHes into the clients server and rolls back the staging database to the latest backup. Then sends a reply ""no worries mate, be careful next time"". xxx: hangover.sh - another cron-job that is set to specific dates. Sends automated emails like ""not feeling well/gonna work from home"" etc. Adds a random ""reason"" from another predefined array of strings. Fires if there are no interactive sessions on the server at 8:45am. xxx: (and the oscar goes to) fucking-coffee.sh - this one waits exactly 17 seconds (!), then opens a telnet session to our coffee-machine (we had no frikin idea the coffee machine is on the network, runs linux and has a TCP socket up and running) and sends something like sys brew. Turns out this thing starts brewing a mid-sized half-caf latte and waits another 24 (!) seconds before pouring it into a cup. The timing is exactly how long it takes to walk to the machine from the dudes desk. xxx: holy sh*t I'm keeping those Original: http://bash.im/quote/436725 (in Russian) Pull requests with other implementations (Python, Perl, Shell, etc) are welcome. Usage You need these environment variables: For Ruby scripts you need to install gems: gem install dotenv twilio-ruby gmail Cron jobs Code is released under WTFPL."
2462,"[Archived] A really simple but powerful packaged personal site that has social integrations like twitter, github, dribbble, instagram, foursquare, tumblr, wordpress, linkedin, spotify/last.fm, and much more...:warning: Unmaintained Sorry, but this project is no longer maintained. Please use the new version, called Syte2. PS. The project as of June 2016 still works fine if you want to use it. Syte Syte is a really simple but powerful packaged personal site that has social integrations like Twitter, GitHub, Dribbble, Instagram, Foursquare, Tumblr, Wordpress, Linkedin, Spotify/Last.fm, SoundCloud, Bitbucket, StackOverflow, Flickr and Steam. You can see it in action on my personal site. Social Integrations Blog Syte uses Tumblr or Wordpress.com for blogging and your blog will be the primary page of the site. Twitter Syte has Twitter integration, which means that when someone clicks on a link that points to a user's Twitter profile the profile is loaded within your site along with the user's latest tweets. GitHub Syte has GitHub integration, which means that when someone clicks on a link that points to a user's GitHub profile the profile is loaded within your site along with a list of the user's repos. Dribbble Syte has Dribbble integration, which means that when someone clicks on a link that points to a user's Dribbble profile the profile is loaded within your site along with the user's latest shots. Instagram Syte has Instagram integration, which means that you can show your Instagram pictures within your site like a profile. Foursquare Syte has foursquare integration, which means that you can show your foursquare check-ins within your site like a profile. Last.fm Syte has Last.fm integration, which means that when someone clicks on a link that points to a user's Last.fm profile the profile information will be loaded directly in the site along with a listing of the most recently scrobbled tracks. SoundCloud Syte has SoundCloud integration, which means that when someone clicks on a link that points to a user's SoundCloud profile the profile information will be loaded directly in the site along with a listing of the user's SoundCloud tracks. Since I don't use SoundCloud, you can see an example on Guram's website Bitbucket Syte has Bitbucket integration, which means that when someone clicks on a link that points to a user's Bitbucket profile the profile is loaded within your site along with a list of the user's repos. Tent.io Syte has Tent.io integration, which means that you can show your Tent.io public posts within your site like a profile. Steam Syte has Steam integration, which means that you can show your Steam Community profile within your site. StackOverflow Syte has StackOverflow integration, which means that you can show your StackOverflow profile within your site. Flickr Syte has Flickr integration, which means that you can show your Flickr photos within your site. LinkedIn Syte has LinkedIn integration, which means that you can show your LinkedIn profile information within your site. Responsive UI Syte is responsive, which means that it scales down to a mobile device screen size. Technologies Used Syte uses the Django web framework to handle requests and call the integration APIs (with python). However it doesn't necessarily need to be in Django since the majority of the work is on the frontend (I would love to see a fork using Node.js, maybe I'll put one together sometime.) On the frontend Syte uses HTML5 and CSS3 while using the LESS CSS preprocessor. Syte also uses several JS libraries listed below: require.js handlebars.js moment.js spin.js bootstrap-modal.js jQuery URL Parser google-code-prettify For static compression and minification Syte uses some Node.js libraries: less uglify-js For deployment Syte uses Heroku since it's free for 750 dyno-hours per month. While the included instructions are for Heroku, Syte doesn't necessarily need to be deployed there. Setup Instructions There are a few steps in order to get Syte configured, but don't worry they are pretty easy. Note I recommend you branching your fork and not checking in sensitive settings to GitHub! Warning Do not place OAuth keys and tokens in a public repository. Base content changes There are a few things that are defaulted to have my information so you have the initial structure of the site. To start off change the pictures to have your picture, navigate to syte > static > imgs and replace pic.png with your picture and favicon.ico with your favicon in this case I use my picture as well. Please make sure you keep the same sizes. pic.png is 84x84px and favicon.ico is 32x32px. Then make some text and link changes. Open base.html located in syte > templates > base.html and make the following changes: Change the meta=""description"" content to have a description about you. Change the meta=""keywords"" content to have keywords about you. Change the title tag to have your name. Inside the header tag change the h1 tag to have your name. Inside the header tag change the h2 tag to have a short description about you. Inside the nav tag change the twitter-link href to point to your twitter profile, if you don't have twitter just remove that whole line. Inside the nav tag change the github-link href to point to your GitHub profile, if you don't have GitHub just remove that whole line. Inside the nav tag change the dribbble-link href to point to your Dribbble profile, if you don't have Dribbble just remove that whole line. Inside the nav tag change the steam-link href to point to your Steam community profile, if you don't have Steam just remove that whole line. Inside the nav tag change the stackoverflow-link href to point to your StackOverflow profile, if you don't have StackOverflow just remove that whole line. Inside the nav tag change the flickr-link href to point to your Flickr profile, if you don't have Flickr just remove that whole line. Inside the nav tag change the contact-link href to point to your email address. Under class=""mobile-nav"" div change the h3 link text to have your domain name or your name. Then pick your adjacent color and change the @adjacent-color hex value in variables.less located in syte > static > less > variables.less Make sure the color you chose is not used by anyone on the list up above. If you want blue pick a different shade of blue, there are hundreds out there... Setting up your blog Syte uses Tumblr or Wordpress for blogging. Setting up Tumblr If you have a Tumblr blog you will need to get the api_key needed to call their APIs. In order to do that register your site with them by going to http://www.tumblr.com/oauth/register, fill in the information about your site, there is no need to enter a default callback url or an icon. Once you are done your website will be listed under http://www.tumblr.com/oauth/apps, save the OAuth Consumer Key value that's the api_key we need for Syte. Once you have the api_key from Tumblr you have to enter it in syte_settings.py located in syte > syte_settings.py. Once you open that file enter the key under TUMBLR_API_KEY, also please enter your Tumblr url under TUMBLR_BLOG_URL see the example on how it should be formatted. Setting up Wordpress For now Syte only support wordpress blogs that are build using wordpress.com. Open syte > syte_settings.py and under WORDPRESS_BLOG_URL enter ther url of your wordpress.com blog, also under BLOG_PLATFORM set it to ""wordpress"". Comments Comments are available through Disqus in order to get yours setup, make sure to signup through their website. Once you are done you will be given a Disqus shortname. Grab the shortname and enter it in syte_settings.py under DISQUS_SHORTNAME, also make sure to have DISQUS_INTEGRATION_ENABLED set to True in order to work. Setting up Twitter integration Twitter has another level of security, therefore we need more information instead of just an api_key like Tumblr. To get started create a new application on Twitter for your website by going to https://dev.twitter.com/apps/new. Once you are done creating your application you will be taken to your application page on Twitter, there you already have two pieces of the puzzle, the Consumer key and the Consumer secret make sure you save those. Next you will need your access tokens, on the bottom of that page there is a link called Create my access token click on that. Once you are done you will be given the other two pieces of the puzzle, the Access token and the Access token secret make sure you save those as well. Once you have those four items from Twitter you have to enter them in your syte_settings.py located in syte > syte_settings.py. Once you open that file enter the following: Consumer key string you saved under TWITTER_CONSUMER_KEY Consumer secret string you saved under TWITTER_CONSUMER_SECRET Access token string you saved under TWITTER_USER_KEY Access token secret string you saved under TWITTER_USER_SECRET If you want to turn off the Twitter integration just set TWITTER_INTEGRATION_ENABLED to False. Setting up GitHub integration GitHub has the same level of security as Twitter, but they don't provide a button that makes it easy to get the access token, so instead we have to get the access token ourselves. To get started sign in to GitHub and go to https://github.com/settings/applications/new to register your application. Enter the Application Name, Main URL and Callback URL. For the Callback URL enter http://127.0.0.1:8000/github/auth for now since we will get the access token while running it locally. Once you are done registering your application you will be given the Client ID and Client Secret. Once you have those two items from GitHub you have to enter them in your syte_settings.py located in syte > syte_settings.py. Once you open that file enter the following: Client ID under GITHUB_CLIENT_ID Client Secret under GITHUB_CLIENT_SECRET After you have entered those two items, follow the steps below for running your Syte locally on your machine. Once you have your Syte running navigate to http://127.0.0.1:8000/github/auth, you will be taken to GitHub's website and will be asked to sign in and authorize your application. After you authorized your application you will be taken back to your Syte and you will be given your Access Token You can also get your access token via the GitHub api using curl: Once you have your access token from GitHub you have to enter them in your syte_settings.py located in syte > syte_settings.py. Once you open that file enter it under GITHUB_ACCESS_TOKEN After you validated that your GitHub integration worked go back to GitHub page and change the Callback URL field to have your domain info (this is not required), then make sure you turn off the GitHub OAuth integration setting so you don't make that available to everyone in the Internet. You can do that by setting GITHUB_OAUTH_ENABLED to False. If you want to turn off GitHub integration just set GITHUB_INTEGRATION_ENABLED to False. Setting up Dribbble integration To get started go to http://developer.dribbble.com/ and click on Register a New Application. Enter Name, Description, Website URL and Callback URL. After that is done Dribbble will give you a Client Access Token to use. Once you have your access token from Dribbble you have to enter them in your syte_settings.py located in syte > syte_settings.py. Once you open that file enter it under DRIBBBLE_ACCESS_TOKEN If you want to turn off this feature just set DRIBBBLE_INTEGRATION_ENABLED setting to False in syte_settings.py. Setting up Instagram integration Instagram has the same level of security as GitHub and similar steps on getting the access token ourselves. To get started go to http://instagram.com/developer/, sign in and crate a new client by clicking on the Manage Clients link on the top right side. Enter the Application Name, Description, Website and OAuth redirect_Uri. For the OAuth redirect_uri enter http://127.0.0.1:8000/instagram/auth/ for now since we will get the access token while running it locally. The trailing slash is required for Instagram not to complain that the redirect_Uri is wrong. Once you are done registering your client you will be given the Client ID and Client Secret. Once you have those two items from Instagram you have to enter them in your syte_settings.py located in syte > syte_settings.py. Once you open that file enter the following: Client ID under INSTAGRAM_CLIENT_ID Client Secret under INSTAGRAM_CLIENT_SECRET After you have entered those two items, follow the steps below for running your Syte locally on your machine. Once you have your Syte running navigate to http://127.0.0.1:8000/instagram/auth, you will be taken to Instagram's website and will be asked to sign in and authorize your application. After you authorized your application you will be taken back to your Syte and you will be given your Access Token and your User ID Once you have those two items from Instagram you have to enter them in your syte_settings.py located in syte > syte_settings.py. Once you open that file enter the following: Access Token under INSTAGRAM_ACCESS_TOKEN User ID under INSTAGRAM_USER_ID After you validated that your Instagram integration worked go back to Instagram page and change the OAuth redirect_uri field to have your domain info (this is not required), then make sure you turn off the Instagram OAuth integration setting so you don't make that available to everyone in the Internet. You can do that by setting INSTAGRAM_OAUTH_ENABLED to False. If you want to turn off Instagram integration just set INSTAGRAM_INTEGRATION_ENABLED to False. Setting up Foursquare integration Foursquare has the same level of security as Instagram and similar steps on getting the access token ourselves. To get started go to https://foursquare.com/oauth/register, sign in and register a new consumer. Enter the Application Name, Application Website and Callback URL. For the callback url enter http://127.0.0.1:8000/foursquare/auth for now since we will get the access token while running it locally. Once you are done registering your consumer you will be given the Client ID and Client Secret. Once you have those two items from Foursquare you have to enter them in your syte_settings.py located in syte > syte_settings.py. Once you open that file enter the following: Client ID under FOURSQUARE_CLIENT_ID Client Secret under FOURSQUARE_CLIENT_SECRET After you have entered those two items, follow the steps below for running your Syte locally on your machine. Once you have your Syte running navigate to http://127.0.0.1:8000/foursquare/auth, you will be taken to Foursquare's website and will be asked to sign in and authorize your application. After you authorized your application you will be taken back to your Syte and you will be given your Access Token. Once you have the access token from Foursquare you have to enter them in your syte_settings.py located in syte > syte_settings.py. Once you open that file enter the following: Access Token under FOURSQUARE_ACCESS_TOKEN After you validated that your foursquare integration worked go back to Foursquare page and change the Callback URL field to have your domain info (this is not required), then make sure you turn off the foursquare OAuth integration setting so you don't make that available to everyone in the Internet. You can do that by setting FOURSQUARE_OAUTH_ENABLED to False. If you want to turn off Instagram integration just set FOURSQUARE_INTEGRATION_ENABLED to False. Additionally if you don't want people to know where you are currently at, you can set 'FOURSQUARE_SHOW_CURRENT_DAY' to False and it will only show check-ins more than a day old. Setting up Last.fm integration The Last.fm integration does not make any authenticated calls so setting it up only requires that you register an application with Last.fm and get an API key. To get an API key simply follow the Getting started instructions. You can then view your API Key from your api account page. Once you have your API Key from Last.fm you have to enter it in your syte_settings.py located in syte > syte_settings.py. Once you open that file enter the following: API_KEY under LASTFM_API_KEY USERNAME under LASTFM_USERNAME If you want to turn off Last.fm integration just set LASTFM_INTEGRATION_ENABLED to False. Setting up SoundCloud integration In order to setup the SoundCloud integration you first need to create a SoundCloud application by going to http://soundcloud.com/you/apps. Once you have the CLIENT_ID from SoundCloud open the syte_settings.py file and enter it under the SOUNDCLOUD_CLIENT_ID setting. Inside syte_settings.py there are two other options to configure how your SoundCloud tracks will be shown. SOUNDCLOUD_SHOW_ARTWORK (Boolean) set this option to true if you want to show your track artwork on page. SOUNDCLOUD_PLAYER_COLOR you can set your widget theme color here. Use Hex values only without # If you want to turn off SoundCloud integration just set SOUNDCLOUD_INTEGRATION_ENABLED to False. Setting up Bitbucket integration The Bitbucket integration does not make any authenticated calls nor does it require a registered API key. If you want to turn off Bitbucket integration just set BITBUCKET_INTEGRATION_ENABLED to False. Comment To display the fork count on repositories set BITBUCKET_SHOW_FORKS to True. The Bitbucket API require one call for each repository to get fork count, which is disabled by default. The Bitbucket API throttles the user resource to 100 calls every 30 minutes. Setting up Tent.io integration The Tent.io integration does not make any authenticated calls nor does it require a registered API key. If you want to turn off Tent.io integration just set TENT_INTEGRATION_ENABLED to False. Inside syte_settings.py there are two other options to configure your Tent.io entity. Your Entity-URI under TENT_ENTITY_URI URL to a Feed or Tent-Status under TENT_FEED_URL Setting up Steam integration In order to setup Steam integration you first need to create a Steam Web API key by going to http://steamcommunity.com/dev/apikey. Once you have the STEAM WEB API KEY from Steam open the syte_settings.py file and enter it under the STEAM_API_KEY setting. If you want to turn off Steam integration just set STEAM_INTEGRATION_ENABLED to False. Setting up StackOverflow integration The StackOverflow integration does not make any authenticated calls nor does it require a registered API key. If you want to turn off StackOverflow integration just set STACKOVERFLOW_INTEGRATION_ENABLED to False. Setting up Flickr integration The Flickr integration does not make any authenticated calls nor does it require a registered API key. To make it work, you'll need to find your Flickr ID. This is different to your username, and you can do the lookup here: http://idgettr.com/ If you want to turn off Flickr integration just set FLICKR_INTEGRATION_ENABLED to False. Setting up LinkedIn integration LinkedIn has the same level of security as Instagram and Foursquare and similar steps on getting the access token ourselves. To get started create a new application on LinkedIn for your website by going to https://developer.linkedin.com/. Once you are done creating your application you will be taken to your application page on LinkedIn, there you already have a few pieces of the puzzle, the Api Key, Secret Key, make sure you save those. In that same page make sure to enter http://127.0.0.1:8000/linkedin/auth/ under Oauth 2.0 Redirect URls. Once you have those items from LinkedIn you have to enter them in your syte_settings.py located in syte > syte_settings.py. Once you open that file enter the following: Consumer key string you saved under LINKEDIN_API_KEY Consumer secret string you saved under LINKEDIN_API_SECRET After you have entered those two items, follow the steps below for running your Syte locally on your machine. Once you have your Syte running navigate to http://127.0.0.1:8000/linkedin/auth, you will be taken to Linkedin's website and will be asked to sign in and authorize your application. After you authorized your application you will be taken back to your Syte and you will be given your Access Token. Once you have the access token from Foursquare you have to enter them in your syte_settings.py located in syte > syte_settings.py. Once you open that file enter the following: Access Token under LINKEDIN_TOKEN If you want to turn off the LinkedIn integration just set LINKEDIN_INTEGRATION_ENABLED to False. Running & Deployment Instructions Now that you have everything setup and ready to go we will be able to run the project locally and deploy to Heroku or AWS with the instructions below. Please note that these instructions are for Mac, which should be the same for Linux systems. If you have problems with these instructions on Windows, let me know or send a pull request. Running Syte locally Running locally is really easy if you are on a Mac since you already have some stuff installed out of the box. To start off install these python packages: virtualenv virtualenvwrapper Once you have those two installed go to your Syte directory and run the following commands: Note On Mac/Linux you need to modify your shell startup file to add mkvirtualenv and workon commands, see virtualenvwrapper installation instructions This will install all the project dependencies listed in requirements.txt including Django. Now all you have to do is run the Django project and go to http://127.0.0.1:8000. Compressing Statics Compressing static files like CSS and JS are done using Node.js. This step is important since it will get all your static files and make tiny bit small so your site can be run faster when it's out there on the so called World Wide Web :) In order to get there you need to first install node.js, they have automatic installers which makes installation really easy. Then you need to install Node Package Manager (npm) by running the following command: After npm is installed you need to install two node packages less and uglify-js. To do that run the following commands: Note windows users be sure to create the directories syte > static > css and syte > static > js > min first if it doesn't already exist. Then whenever you want to release a new version of static update the COMPRESS_REVISION_NUMBER in syte-settings.py and run the compress python command from your syte directory: This will create a minified version of your CSS in syte > static > css and the minified version of your JavaScript in syte > static > js > min. Note If you are using Windows and is having problems on compressing statics checkout issue #14 to see if it helps. Deploying to Heroku Deploying to Heroku is extremely easy and free, that's why I chose it over Amazon or similar. That's another fork I would love to see, different deployment instructions maybe to an Amazon EC2 micro instance. First signup to Heroku then follow these simple Django deployment instructions I already have the requirements.txt and the Procfile ready to go, but before you actually deploy there are two things you need to change: Change the DEPLOYMENT_MODE value to prod in syte_settings.py located in syte > syte_settings.py Change the SITE_ROOT_URI value to your Heroku app url in syte_settings.py see the available example to how it should be formatted. Deploying to AWS Deploying to AWS is a little more complicated than Heroku, but is a nice alternative. The easiest way to deploy your application to AWS is by using AWS Elastic Beanstalk. To help keep costs low, we will deploy to micro instances. First signup to AWS then follow the instructions below. I have already included some of the required files for you (see syte.config in .ebextensions directory). The other required files will be created automatically, but some of the settings may need to be altered slightly. Change the DEPLOYMENT_MODE value to prod in syte_settings.py located in syte > syte_settings.py Change the SITE_ROOT_URI value to your AWS app url in syte_settings.py see the available example to how it should be formatted. Install the eb command-line tools and add to your path. Download from here. This will allow us to control AWS from the command-line. Execute the eb init command in the root of the syte repo and follow the on-screen instructions. This will help get our project ready to be deployed into AWS. Please note: during this step you will be asked to provide security credentials. If you are not sure what to use, see here Execute the eb start command to deploy a sample application to AWS. Once this command completes execute eb status --verbose and confirm that the sample application is running at the provided url. Let's make sure our configurations are right. First, open ./ebextensions/syte.config and confirm the settings here. You should not have to update anything. Second, open the ./elasticbeanstalk/opensettings.XXX-env (where XXX-env is the name of your environment). Update this by updating: DJANGO_SETTINGS_MODULE=syte.settings StaticFiles=syte/static= WSGIPath=syte/wsgi.py To make sure the above changes are not reverted, execute eb update. Deploy the repo to AWS by executing git aws.push. This command can be rerun whenever you have changes that you want to deploy. Execute eb status --verbose or monitor the provisioning process on AWS' website. To troubleshoot, go to the ElasticBeanstalk section of AWS, get a snapshot of the logs and review them for errors. Contributing There are plans for several services to be added in the TODO file. One of these services is a good place to start when looking for ways to help. Also posting/fixing issues is always helpful. If you would like to add support for a new service you might find the HELP file useful on how to get started and where your new code might go, etc. Also, the DESIGN file can be a useful resource when starting out with the project and trying to understand roughly how it all fits together. Credit Syte was developed by Rigo (rodrigo neri). Check his personal site out at http://rigoneri.com and follow him on twitter @rigoneri License The MIT License Copyright (c) 2012, Rodrigo Neri <@rigoneri> Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the ""Software""), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
210,"API server module for Node/Express Parse Server is an open source backend that can be deployed to any infrastructure that can run Node.js. Our Sponsors Our backers and sponsors help to ensure the quality and timely development of the Parse Platform. Bronze Sponsors Parse Server works with the Express web application framework. It can be added to existing web applications, or run by itself. The full documentation for Parse Server is available in the wiki. The Parse Server guide is a good place to get started. An API reference and Cloud Code guide are also available. If you're interested in developing for Parse Server, the Development guide will help you get set up. Getting Started Running Parse Server Compatibility Node.js MongoDB PostgreSQL Locally Docker Container Saving an Object Connect an SDK Running Parse Server elsewhere Sample Application Parse Server + Express Configuration Basic Options Client Key Options Email Verification and Password Reset Password and Account Policy Custom Routes Example Reserved Paths Parameters Custom Pages Using Environment Variables Available Adapters Configuring File Adapters Idempotency Enforcement Localization Pages Localization with Directory Structure Localization with JSON Resource Dynamic placeholders Reserved Keys Parameters Logging Deprecations Live Query GraphQL Running Using the CLI Using Docker Using Express.js Checking the API health Creating your first class Using automatically generated operations Customizing your GraphQL Schema Learning more Upgrading to 3.0.0 Want to ride the bleeding edge? Contributing Contributors Sponsors Backers Getting Started The fastest and easiest way to get started is to run MongoDB and Parse Server locally. Running Parse Server Before you start make sure you have installed: NodeJS that includes npm MongoDB or PostgreSQL(with PostGIS 2.2.0 or higher) Optionally Docker Compatibility Node.js Parse Server is continuously tested with the most recent releases of Node.js to ensure compatibility. We follow the Node.js Long Term Support plan and only test against versions that are officially supported and have not reached their end-of-life date. | Version | Latest Version | End-of-Life Date | Compatibility | |------------|----------------|------------------|--------------------| | Node.js 12 | 12.22.1 | April 2022 | Fully compatible | | Node.js 14 | 14.16.1 | April 2023 | Fully compatible | | Node.js 15 | 15.14.0 | June 2021 | Fully compatible | MongoDB Parse Server is continuously tested with the most recent releases of MongoDB to ensure compatibility. We follow the MongoDB support schedule and only test against versions that are officially supported and have not reached their end-of-life date. | Version | Latest Version | End-of-Life Date | Compatibility | |-------------|----------------|------------------|--------------------| | MongoDB 4.0 | 4.0.23 | January 2022 | Fully compatible | | MongoDB 4.2 | 4.2.13 | TBD | Fully compatible | | MongoDB 4.4 | 4.4.4 | TBD | Fully compatible | PostgreSQL Parse Server is continuously tested with the most recent releases of PostgreSQL and PostGIS to ensure compatibility, using PostGIS docker images. We follow the PostgreSQL support schedule and PostGIS support schedule and only test against versions that are officially supported and have not reached their end-of-life date. Due to the extensive PostgreSQL support duration of 5 years, Parse Server drops support if a version is older than 3.5 years and a newer version has been available for at least 2.5 years. | Version | PostGIS Version | End-of-Life Date | Parse Server Support End | Compatibility | |-------------|-----------------|------------------|--------------------------|--------------------| | Postgres 11 | 3.0, 3.1 | November 2023 | April 2022 | Fully compatible | | Postgres 12 | 3.1 | November 2024 | April 2023 | Fully compatible | | Postgres 13 | 3.1 | November 2025 | April 2024 | Fully compatible | Locally Note: If installation with -g fails due to permission problems (npm ERR! code 'EACCES'), please refer to this link. Docker Container Running the Parse Server Image Note: If you want to use Cloud Code, add -v cloud-code-vol:/parse-server/cloud --cloud /parse-server/cloud/main.js to the command above. Make sure main.js is in the cloud-code-vol directory before starting Parse Server. You can use any arbitrary string as your application id and master key. These will be used by your clients to authenticate with the Parse Server. That's it! You are now running a standalone version of Parse Server on your machine. Using a remote MongoDB? Pass the --databaseURI DATABASE_URI parameter when starting parse-server. Learn more about configuring Parse Server here. For a full list of available options, run parse-server --help. Saving an Object Now that you're running Parse Server, it is time to save your first object. We'll use the REST API, but you can easily do the same using any of the Parse SDKs. Run the following: You should get a response similar to this: You can now retrieve this object directly (make sure to replace 2ntvSpRGIK with the actual objectId you received when the object was created): Keeping tracks of individual object ids is not ideal, however. In most cases you will want to run a query over the collection, like so: To learn more about using saving and querying objects on Parse Server, check out the Parse documentation. Connect an SDK Parse provides SDKs for all the major platforms. Refer to the Parse Server guide to learn how to connect your app to Parse Server. Running Parse Server elsewhere Once you have a better understanding of how the project works, please refer to the Parse Server wiki for in-depth guides to deploy Parse Server to major infrastructure providers. Read on to learn more about additional ways of running Parse Server. Sample Application We have provided a basic Node.js application that uses the Parse Server module on Express and can be easily deployed to various infrastructure providers: Heroku and mLab AWS and Elastic Beanstalk Google App Engine Microsoft Azure SashiDo Digital Ocean Pivotal Web Services Back4app Glitch Flynn Parse Server + Express You can also create an instance of Parse Server, and mount it on a new or existing Express website: For a full list of available options, run parse-server --help or take a look at Parse Server Configurations. Configuration Parse Server can be configured using the following options. You may pass these as parameters when running a standalone parse-server, or by loading a configuration file in JSON format using parse-server path/to/configuration.json. If you're using Parse Server on Express, you may also pass these to the ParseServer object as options. For the full list of available options, run parse-server --help or take a look at Parse Server Configurations. Basic Options appId (required) - The application id to host with this server instance. You can use any arbitrary string. For migrated apps, this should match your hosted Parse app. masterKey (required) - The master key to use for overriding ACL security. You can use any arbitrary string. Keep it secret! For migrated apps, this should match your hosted Parse app. databaseURI (required) - The connection string for your database, i.e. mongodb://user:pass@host.com/dbname. Be sure to URL encode your password if your password has special characters. port - The default port is 1337, specify this parameter to use a different port. serverURL - URL to your Parse Server (don't forget to specify http:// or https://). This URL will be used when making requests to Parse Server from Cloud Code. cloud - The absolute path to your cloud code main.js file. push - Configuration options for APNS and GCM push. See the Push Notifications quick start. Client Key Options The client keys used with Parse are no longer necessary with Parse Server. If you wish to still require them, perhaps to be able to refuse access to older clients, you can set the keys at initialization time. Setting any of these keys will require all requests to provide one of the configured keys. clientKey javascriptKey restAPIKey dotNetKey Email Verification and Password Reset Verifying user email addresses and enabling password reset via email requires an email adapter. There are many email adapters provided and maintained by the community. The following is an example configuration with an example email adapter. See the Parse Server Options for more details and a full list of available options. Email adapters contributed by the community: - parse-server-api-mail-adapter (localization, templates, universally supports any email provider) - parse-smtp-template (localization, templates) - parse-server-postmark-adapter - parse-server-sendgrid-adapter - parse-server-mandrill-adapter - parse-server-simple-ses-adapter - parse-server-mailgun-adapter-template - parse-server-sendinblue-adapter - parse-server-mailjet-adapter - simple-parse-smtp-adapter - parse-server-generic-email-adapter Password and Account Policy Set a password and account policy that meets your security requirements. The following is an example configuration. See the Parse Server Options for more details and a full list of available options. Custom Routes Caution, this is an experimental feature that may not be appropriate for production. Custom routes allow to build user flows with webpages, similar to the existing password reset and email verification features. Custom routes are defined with the pages option in the Parse Server configuration: Example The above route can be invoked by sending a GET request to: https://[parseServerPublicUrl]/[parseMount]/[pagesEndpoint]/[appId]/[customRoute] The handler receives the request and returns a custom_page.html webpage from the pages.pagesPath directory as response. The advantage of building a custom route this way is that it automatically makes use of Parse Server's built-in capabilities, such as page localization and dynamic placeholders. Reserved Paths The following paths are already used by Parse Server's built-in features and are therefore not available for custom routes. Custom routes with an identical combination of path and method are ignored. | Path | HTTP Method | Feature | |-----------------------------|-------------|--------------------| | verify_email | GET | email verification | | resend_verification_email | POST | email verification | | choose_password | GET | password reset | | request_password_reset | GET | password reset | | request_password_reset | POST | password reset | Parameters | Parameter | Optional | Type | Default value | Example values | Environment variable | Description | |------------------------------|----------|-----------------|---------------|-----------------------|------------------------------------|--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------| | pages | yes | Object | undefined | - | PARSE_SERVER_PAGES | The options for pages such as password reset and email verification. | | pages.enableRouter | yes | Boolean | false | - | PARSE_SERVER_PAGES_ENABLE_ROUTER | Is true if the pages router should be enabled; this is required for any of the pages options to take effect. Caution, this is an experimental feature that may not be appropriate for production. | | pages.customRoutes | yes | Array | [] | - | PARSE_SERVER_PAGES_CUSTOM_ROUTES | The custom routes. The routes are added in the order they are defined here, which has to be considered since requests traverse routes in an ordered manner. Custom routes are traversed after build-in routes such as password reset and email verification. | | pages.customRoutes.method | | String | - | GET, POST | - | The HTTP method of the custom route. | | pages.customRoutes.path | | String | - | custom_page | - | The path of the custom route. Note that the same path can used if the method is different, for example a path custom_page can have two routes, a GET and POST route, which will be invoked depending on the HTTP request method. | | pages.customRoutes.handler | | AsyncFunction | - | async () => { ... } | - | The route handler that is invoked when the route matches the HTTP request. If the handler does not return a page, the request is answered with a 404 Not found. response. | Custom Pages Its possible to change the default pages of the app and redirect the user to another path or domain. Using Environment Variables You may configure the Parse Server using environment variables: The default port is 1337, to use a different port set the PORT environment variable: For the full list of configurable environment variables, run parse-server --help or take a look at Parse Server Configuration. Available Adapters All official adapters are distributed as scoped packages on npm (@parse). Some well maintained adapters are also available on the Parse Server Modules organization. You can also find more adapters maintained by the community by searching on npm. Configuring File Adapters Parse Server allows developers to choose from several options when hosting files: GridFSBucketAdapter, which is backed by MongoDB; S3Adapter, which is backed by Amazon S3; or GCSAdapter, which is backed by Google Cloud Storage GridFSBucketAdapter is used by default and requires no setup, but if you're interested in using S3 or Google Cloud Storage, additional configuration information is available in the Parse Server guide. Idempotency Enforcement Caution, this is an experimental feature that may not be appropriate for production. This feature deduplicates identical requests that are received by Parse Server multiple times, typically due to network issues or network adapter access restrictions on mobile operating systems. Identical requests are identified by their request header X-Parse-Request-Id. Therefore a client request has to include this header for deduplication to be applied. Requests that do not contain this header cannot be deduplicated and are processed normally by Parse Server. This means rolling out this feature to clients is seamless as Parse Server still processes requests without this header when this feature is enabled. This feature needs to be enabled on the client side to send the header and on the server to process the header. Refer to the specific Parse SDK docs to see whether the feature is supported yet. Deduplication is only done for object creation and update (POST and PUT requests). Deduplication is not done for object finding and deletion (GET and DELETE requests), as these operations are already idempotent by definition. Configuration example Parameters | Parameter | Optional | Type | Default value | Example values | Environment variable | Description | |----------------------------|----------|-----------------|---------------|-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|-----------------------------------------------|------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------| | idempotencyOptions | yes | Object | undefined | | PARSE_SERVER_EXPERIMENTAL_IDEMPOTENCY_OPTIONS | Setting this enables idempotency enforcement for the specified paths. | | idempotencyOptions.paths | yes | Array<String> | [] | .* (all paths, includes the examples below), functions/.* (all functions), jobs/.* (all jobs), classes/.* (all classes), functions/.* (all functions), users (user creation / update), installations (installation creation / update) | PARSE_SERVER_EXPERIMENTAL_IDEMPOTENCY_PATHS | An array of path patterns that have to match the request path for request deduplication to be enabled. The mount path must not be included, for example to match the request path /parse/functions/myFunction specify the path pattern functions/myFunction. A trailing slash of the request path is ignored, for example the path pattern functions/myFunction matches both /parse/functions/myFunction and /parse/functions/myFunction/. | | idempotencyOptions.ttl | yes | Integer | 300 | 60 (60 seconds) | PARSE_SERVER_EXPERIMENTAL_IDEMPOTENCY_TTL | The duration in seconds after which a request record is discarded from the database. Duplicate requests due to network issues can be expected to arrive within milliseconds up to several seconds. This value must be greater than 0. | Notes This feature is currently only available for MongoDB and not for Postgres. Localization Pages Caution, this is an experimental feature that may not be appropriate for production. Custom pages as well as feature pages (e.g. password reset, email verification) can be localized with the pages option in the Parse Server configuration: Localization is achieved by matching a request-supplied locale parameter with localized page content. The locale can be supplied in either the request query, body or header with the following keys: - query: locale - body: locale - header: x-parse-page-param-locale For example, a password reset link with the locale parameter in the query could look like this: Localization is only available for pages in the pages directory as set with pages.pagesPath. Localization for feature pages (e.g. password reset, email verification) is disabled if pages.customUrls are set, even if the custom URLs point to the pages within the pages path. Only .html files are considered for localization when localizing custom pages. Pages can be localized in two ways: Localization with Directory Structure Pages are localized by using the corresponding file in the directory structure where the files are placed in subdirectories named after the locale or language. The file in the base directory is the default file. Example Directory Structure: Files are matched with the locale in the following order: 1. Locale match, e.g. locale de-AT matches file in folder de-AT. 1. Language match, e.g. locale de-CH matches file in folder de. 1. Default; file in base folder is returned. Configuration Example: Pros: - All files are complete in their content and can be easily opened and previewed by viewing the file in a browser. Cons: - In most cases, a localized page differs only slightly from the default page, which could cause a lot of duplicate code that is difficult to maintain. Localization with JSON Resource Pages are localized by adding placeholders in the HTML files and providing a JSON resource that contains the translations to fill into the placeholders. Example Directory Structure: The JSON resource file loosely follows the i18next syntax, which is a syntax that is often supported by translation platforms, making it easy to manage translations, exporting them for use in Parse Server, and even to automate this workflow. Example JSON Content: Configuration Example: Pros: - There is only one HTML file to maintain that contains the placeholders that are filled with the translations according to the locale. Cons: - Files cannot be easily previewed by viewing the file in a browser because the content contains only placeholders and even HTML or CSS changes may be dynamically applied, e.g. when a localization requires a Right-To-Left layout direction. - Style and other fundamental layout changes may be more difficult to apply. Dynamic placeholders In addition to feature related default parameters such as appId and the translations provided via JSON resource, it is possible to define custom dynamic placeholders as part of the router configuration. This works independently of localization and, also if enableLocalization is disabled. Configuration Example: The placeholders can also be provided as function or as async function, with the locale and other feature related parameters passed through, to allow for dynamic placeholder values: Reserved Keys The following parameter and placeholder keys are reserved because they are used related to features such as password reset or email verification. They should not be used as translation keys in the JSON resource or as manually defined placeholder keys in the configuration: appId, appName, email, error, locale, publicServerUrl, token, username. Parameters | Parameter | Optional | Type | Default value | Example values | Environment variable | Description | |-------------------------------------------------|----------|---------------------------------------|----------------------------------------|------------------------------------------------------|-----------------------------------------------------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------| | pages | yes | Object | undefined | - | PARSE_SERVER_PAGES | The options for pages such as password reset and email verification. | | pages.enableRouter | yes | Boolean | false | - | PARSE_SERVER_PAGES_ENABLE_ROUTER | Is true if the pages router should be enabled; this is required for any of the pages options to take effect. Caution, this is an experimental feature that may not be appropriate for production. | | pages.enableLocalization | yes | Boolean | false | - | PARSE_SERVER_PAGES_ENABLE_LOCALIZATION | Is true if pages should be localized; this has no effect on custom page redirects. | | pages.localizationJsonPath | yes | String | undefined | ./private/translations.json | PARSE_SERVER_PAGES_LOCALIZATION_JSON_PATH | The path to the JSON file for localization; the translations will be used to fill template placeholders according to the locale. | | pages.localizationFallbackLocale | yes | String | en | en, en-GB, default | PARSE_SERVER_PAGES_LOCALIZATION_FALLBACK_LOCALE | The fallback locale for localization if no matching translation is provided for the given locale. This is only relevant when providing translation resources via JSON file. | | pages.placeholders | yes | Object, Function, AsyncFunction | undefined | { exampleKey: 'exampleValue' } | PARSE_SERVER_PAGES_PLACEHOLDERS | The placeholder keys and values which will be filled in pages; this can be a simple object or a callback function. | | pages.forceRedirect | yes | Boolean | false | - | PARSE_SERVER_PAGES_FORCE_REDIRECT | Is true if responses should always be redirects and never content, false if the response type should depend on the request type (GET request -> content response; POST request -> redirect response). | | pages.pagesPath | yes | String | ./public | ./files/pages, ../../pages | PARSE_SERVER_PAGES_PAGES_PATH | The path to the pages directory; this also defines where the static endpoint /apps points to. | | pages.pagesEndpoint | yes | String | apps | - | PARSE_SERVER_PAGES_PAGES_ENDPOINT | The API endpoint for the pages. | | pages.customUrls | yes | Object | {} | { passwordReset: 'https://example.com/page.html' } | PARSE_SERVER_PAGES_CUSTOM_URLS | The URLs to the custom pages | | pages.customUrls.passwordReset | yes | String | password_reset.html | - | PARSE_SERVER_PAGES_CUSTOM_URL_PASSWORD_RESET | The URL to the custom page for password reset. | | pages.customUrls.passwordResetSuccess | yes | String | password_reset_success.html | - | PARSE_SERVER_PAGES_CUSTOM_URL_PASSWORD_RESET_SUCCESS | The URL to the custom page for password reset -> success. | | pages.customUrls.passwordResetLinkInvalid | yes | String | password_reset_link_invalid.html | - | PARSE_SERVER_PAGES_CUSTOM_URL_PASSWORD_RESET_LINK_INVALID | The URL to the custom page for password reset -> link invalid. | | pages.customUrls.emailVerificationSuccess | yes | String | email_verification_success.html | - | PARSE_SERVER_PAGES_CUSTOM_URL_EMAIL_VERIFICATION_SUCCESS | The URL to the custom page for email verification -> success. | | pages.customUrls.emailVerificationSendFail | yes | String | email_verification_send_fail.html | - | PARSE_SERVER_PAGES_CUSTOM_URL_EMAIL_VERIFICATION_SEND_FAIL | The URL to the custom page for email verification -> link send fail. | | pages.customUrls.emailVerificationSendSuccess | yes | String | email_verification_send_success.html | - | PARSE_SERVER_PAGES_CUSTOM_URL_EMAIL_VERIFICATION_SEND_SUCCESS | The URL to the custom page for email verification -> resend link -> success. | | pages.customUrls.emailVerificationLinkInvalid | yes | String | email_verification_link_invalid.html | - | PARSE_SERVER_PAGES_CUSTOM_URL_EMAIL_VERIFICATION_LINK_INVALID | The URL to the custom page for email verification -> link invalid. | | pages.customUrls.emailVerificationLinkExpired | yes | String | email_verification_link_expired.html | - | PARSE_SERVER_PAGES_CUSTOM_URL_EMAIL_VERIFICATION_LINK_EXPIRED | The URL to the custom page for email verification -> link expired. | Notes In combination with the Parse Server API Mail Adapter Parse Server provides a fully localized flow (emails -> pages) for the user. The email adapter sends a localized email and adds a locale parameter to the password reset or email verification link, which is then used to respond with localized pages. Logging Parse Server will, by default, log: * to the console * daily rotating files as new line delimited JSON Logs are also viewable in Parse Dashboard. Want to log each request and response? Set the VERBOSE environment variable when starting parse-server. Usage :- VERBOSE='1' parse-server --appId APPLICATION_ID --masterKey MASTER_KEY Want logs to be placed in a different folder? Pass the PARSE_SERVER_LOGS_FOLDER environment variable when starting parse-server. Usage :- PARSE_SERVER_LOGS_FOLDER='<path-to-logs-folder>' parse-server --appId APPLICATION_ID --masterKey MASTER_KEY Want to log specific levels? Pass the logLevel parameter when starting parse-server. Usage :- parse-server --appId APPLICATION_ID --masterKey MASTER_KEY --logLevel LOG_LEVEL Want new line delimited JSON error logs (for consumption by CloudWatch, Google Cloud Logging, etc)? Pass the JSON_LOGS environment variable when starting parse-server. Usage :- JSON_LOGS='1' parse-server --appId APPLICATION_ID --masterKey MASTER_KEY Deprecations The following Parse Server options and APIs are deprecated and will change in future versions. The ""Deprecation"" version indicates from when an item has been deprecated with runtime warnings. The ""End-of-Life"" version indicates when the deprecation period has ended and the breaking change came into effect. In rare cases, deprecations may be revoked without any breaking change coming into effect. | Type | Item | Deprecation | End-of-Life | Details | |--------|----------------|-------------|-------------|-----------------------------------------| | Option | directAccess | 5.0.0 | tbd | Default changes from false to true. | Live Query Live queries are meant to be used in real-time reactive applications, where just using the traditional query paradigm could cause several problems, like increased response time and high network and server usage. Live queries should be used in cases where you need to continuously update a page with fresh data coming from the database, which often happens in (but is not limited to) online games, messaging clients and shared to-do lists. Take a look at Live Query Guide, Live Query Server Setup Guide and Live Query Protocol Specification. You can setup a standalone server or multiple instances for scalability (recommended). GraphQL GraphQL, developed by Facebook, is an open-source data query and manipulation language for APIs. In addition to the traditional REST API, Parse Server automatically generates a GraphQL API based on your current application schema. Parse Server also allows you to define your custom GraphQL queries and mutations, whose resolvers can be bound to your cloud code functions. Running Using the CLI The easiest way to run the Parse GraphQL API is through the CLI: After starting the server, you can visit http://localhost:1337/playground in your browser to start playing with your GraphQL API. Note: Do NOT use --mountPlayground option in production. Parse Dashboard has a built-in GraphQL Playground and it is the recommended option for production apps. Using Docker You can also run the Parse GraphQL API inside a Docker container: Running the Parse Server Image Note: If you want to use Cloud Code, add -v cloud-code-vol:/parse-server/cloud --cloud /parse-server/cloud/main.js to the command above. Make sure main.js is in the cloud-code-vol directory before starting Parse Server. After starting the server, you can visit http://localhost:1337/playground in your browser to start playing with your GraphQL API. Note: Do NOT use --mountPlayground option in production. Parse Dashboard has a built-in GraphQL Playground and it is the recommended option for production apps. Using Express.js You can also mount the GraphQL API in an Express.js application together with the REST API or solo. You first need to create a new project and install the required dependencies: Then, create an index.js file with the following content: And finally start your app: After starting the app, you can visit http://localhost:1337/playground in your browser to start playing with your GraphQL API. Note: Do NOT mount the GraphQL Playground in production. Parse Dashboard has a built-in GraphQL Playground and it is the recommended option for production apps. Checking the API health Run the following: You should receive the following response: Creating your first class Since your application does not have any schema yet, you can use the createClass mutation to create your first class. Run the following: You should receive the following response: Using automatically generated operations Parse Server learned from the first class that you created and now you have the GameScore class in your schema. You can now start using the automatically generated operations! Run the following to create your first object: You should receive a response similar to this: You can also run a query to this new class: You should receive a response similar to this: Customizing your GraphQL Schema Parse GraphQL Server allows you to create a custom GraphQL schema with own queries and mutations to be merged with the auto-generated ones. You can resolve these operations using your regular cloud code functions. To start creating your custom schema, you need to code a schema.graphql file and initialize Parse Server with --graphQLSchema and --cloud options: Creating your first custom query Use the code below for your schema.graphql and main.js files. Then restart your Parse Server. You can now run your custom query using GraphQL Playground: You should receive the response below: Learning more The Parse GraphQL Guide is a very good source for learning how to use the Parse GraphQL API. You also have a very powerful tool inside your GraphQL Playground. Please look at the right side of your GraphQL Playground. You will see the DOCS and SCHEMA menus. They are automatically generated by analyzing your application schema. Please refer to them and learn more about everything that you can do with your Parse GraphQL API. Additionally, the GraphQL Learn Section is a very good source to learn more about the power of the GraphQL language. Upgrading to 3.0.0 Starting 3.0.0, parse-server uses the JS SDK version 2.0. In short, parse SDK v2.0 removes the backbone style callbacks as well as the Parse.Promise object in favor of native promises. All the Cloud Code interfaces also have been updated to reflect those changes, and all backbone style response objects are removed and replaced by Promise style resolution. We have written up a migration guide, hoping this will help you transition to the next major release. Want to ride the bleeding edge? It is recommend to use builds deployed npm for many reasons, but if you want to use the latest not-yet-released version of parse-server, you can do so by depending directly on this branch: Experimenting You can also use your own forks, and work in progress branches by specifying them: And don't forget, if you plan to deploy it remotely, you should run npm install with the --save option. Contributing We really want Parse to be yours, to see it grow and thrive in the open source community. Please see the Contributing to Parse Server guide. Contributors This project exists thanks to all the people who contribute... we'd love to see your face on this list! Sponsors Support this project by becoming a sponsor. Your logo will show up here with a link to your website. Become a sponsor! Backers Support us with a monthly donation and help us continue our activities. Become a backer! As of April 5, 2017, Parse, LLC has transferred this code to the parse-community organization, and will no longer be contributing to or distributing this code."
354,"A datepicker for twitter bootstrap (@twbs)bootstrap-datepicker Versions are incremented according to semver. CDN You can use the CloudFlare powered cdnjs.com on your website. bootstrap-datepicker on cdnjs Please note: It might take a few hours until a new version is available on cdnjs. Links Online Demo Online Docs (ReadTheDocs.com) Google Group Travis CI Snippets Booking demo with two pickers Development Once you cloned the repo, you'll need to install grunt and the development dependencies using a package manager: yarn (recommended): npm:"
3731,A library for implementing an OAuth2 Server in phpoauth2-server-php View the complete documentation
2144,"A JavaScript polyfill for Flexboxflexibility A JavaScript polyfill for Flexbox Flexibility is a polyfill for the Flexible Box Layout, commonly known as Flexbox. With Flexibility, you get to design beautiful, flexible layouts on the web without sacrificing the experience in older browsers. Flexbox lays out, aligns, and distributes elements in a container, even when their size is unknown or dynamic. To better understand Flexbox, read Chris Coyiers excellent Complete Guide to Flexbox. To start using Flexbox in Internet Explorer 8 & 9 or any older browser, download the flexibility.js script and include it anywhere on your page. If youre only targeting Internet Explorer 10 and lower, add a -js-display: flex declaration before any display: flex declarations in your CSS, or use PostCSS Flexibility to automate this during your build process. If youre targeting other browsers, use the data-style attribute to alert these browsers to your changes. When youre ready to polyfill flexbox with JavaScript, use the flexibility method on the outermost element you would like to polyfill. API The global flexibility method contains child functions for use within your own framework. flexibility.read Argument: Element Return flexbox related styles from an element. flexibility.readAll Argument: Element Return a list of flexbox details from a matching element or its descendants. flexibility.write Argument: Details Writes flexbox details back to their respective elements. flexibility.writeAll Argument: Array Writes a list of flexbox details back to their respective elements. To learn more about Flexibility, read the support section. If you experience an issue, read the contributing section before creating an issue."
856,"A modern dialog library which is highly configurable and easy to style. #hubspot-open-sourcevex Demo Documentation vex is a modern dialog library which is highly configurable, easily stylable, and gets out of the way. You'll love vex because it's tiny (5.6kb minified and gzipped), has a clear and simple API, works on mobile devices, and can be customized to match your style in seconds. Features Drop-in replacement for alert, confirm, and prompt Easily configurable animations which are smooth as butter Lightweight with no external dependencies Looks and behaves great on mobile devices Open multiple dialogs at once and close them individually or all at once Built in CSS spinner for asynchronous dialogs (TODO) UMD support Documentation Getting started API Docs Plugins"
1609,"It's a new file uploader solution!bugfixPR WebUploader WebUploaderHTML5FLASHHTML5IEFLASHIE6+Andorid 4+IOS 6+ http://fex.baidu.com/webuploader/ ISSUEShttps://github.com/fex-team/webuploader/issues pr, @zensh@ushelp@duanlixin jpg,jpeg,gif,bmp,png jpegmetaorientationmeta (&) QQ(Ctrl + ALT + A), Ctrl + V HTML5 & FLASH FlashUIflash MD5 md5 md520ms , AMD"
1057,":memo: Today I LearnedTIL Today I Learned A collection of concise write-ups on small things I learn day to day across a variety of languages and technologies. These are things that don't really warrant a full blog post. These are things I've picked up by Learning In Public and pairing with smart people at Hashrocket. For a steady stream of TILs, sign up for my newsletter. 1122 TILs and counting... Categories Ack Amplify Chrome Clojure CSS Devops Elixir Gatsby Git GitHub Actions Go HTML HTTP Internet JavaScript jq Kitty Linux Mac MongoDB MySQL Netlify Next.js Phoenix PostgreSQL Python Rails React React Native React Testing Library ReasonML Ruby sed Shell Tailwind CSS tmux TypeScript Unix Vercel Vim VSCode Webpack Workflow YAML Ack ack --bar Case-Insensitive Search List Available File Types Amplify Sign Up User With Email And Password Chrome Access A Value Logged To The Console Chrome Supports Many Unix Keyboard Shortcuts Copy Some Data From The Console Duplicate The Current Tab Easier Access To Network Throttling Controls Pretty Print Tabular Data Reference The Selected Node Selecting DOM Elements Faster Than Ever Simulating Various Connection Speeds Toggle Device Mode Toggle Open The Console Drawer View Network Traffic For New Tabs Clojure Aggregation Using merge-with Argument Requirements For A Function Combinations Of Items From A Sequence Define Something Only Once Evaluate One Liners With lein-exec Expanding Macros Get The Value Of An Environment Variable List Functions For A Namespace Load A File Into The REPL Mapping With An Index Open JavaDocs Pretty Print The Last Thing Quick Clojure Docs Reductions Set Max Heap Size Specify the Directory of a Shell Command Splitting On Whitespace Swap Two Items in a Vector Try A Clojure Project In The REPL Type of Anything When Overflow Is Desired CSS Add Fab Icons To Your Site With FontAwesome 5 Animate Smoothly Between Two Background Colors Apply Multiple Box Shadows To Single Element Apply Styles Based On Dark-Mode Preferences Apply Styles To The Last Child Of A Specific Type Change The Orientation Of An Image Circular Icons With A Massive Border Radius Clean Up Repetition With :is() Pseudo-Class Conditional Styling For Unsupported CSS Features Create A Pulsing Background With CSS Animation Define CSS Custom Properties With CSS Variables Define HSL Colors With Alpha Values Display Responsive iframe Maintaining Aspect Ratio Dry Up SCSS With Mixins Give Elements The Same Width With Flexbox Let Pointer Events Pass Through An Element Lighten And Darken With CSS Brightness Filter Lighten And Darken With SCSS Make A Block Of Text Respect New Lines Parameterized SCSS Mixins :root Has Higher Specificity Than html Style A Background With A Linear Gradient Using Maps In SCSS Devops Aliasing An Ansible Host Allow Cross-Origin Requests To Include Cookies Allow HTTPS Through Your UFW Firewall Check The Status of All Services Check The Syntax Of nginx Files Connect To An RDS PostgreSQL Database Determine The IP Address Of A Domain Path Of The Packets Push Non-master Branch To Heroku Reload The nginx Configuration Resolve The Public IP Of A URL Running Out Of inode Space SSH Into A Docker Container SSL Certificates Can Cover Multiple Domains Wipe A Heroku Postgres Database Elixir All Values For A Key In A Keyword List Append To A Keyword List Assert An Exception Is Raised Binary Representation Of A String Check For A Substring Match Check List Membership Comparing DateTime Structs Compute Intermediate Values In A With Construct Compute md5 Digest Of A String Counting Records With Ecto Create A Date With The Date Sigil Create A List Of Atoms Creating A PID Creating Indexes With Ecto Defining Multiple Clauses In An Anonymous Function Determine The Latest Release Of A Hex Package Do You Have The Time? Do You Have The Time? - Part 2 Documentation Lookup With Vim And Alchemist Dynamically Generating Atoms Execute Raw SQL In An Ecto Migration Expose Internal Representation Include Captures With String.split Inspecting The Process Message Queue List Functions For A Module Listing Files In IEx Match On A Map In A With Construct Passing Around And Using Modules Pattern Matching In Anonymous Functions Pipe Into A Case Statement Quitting IEx Range Into List Using Comprehensions Refer To A Module Within Itself Referencing Values In IEx's History Remove One List From Another Replace Duplicates In A Keyword List Requiring Keys For Structs Reversing A List Reversing A List - Part 2 Root Directory Of A Project Round Floats To Integers Run ExUnit Tests In A Deterministic Order Run The Test At A Specific Line Number Same Functions Should Be Grouped Together Skip A Specific Test String Interpolation With Just About Anything Unique Indexes With Ecto Updating Values In A Map Using When Clauses In A With Construct Virtual Fields With Ecto Schemas When Things Don't Match The With Statements Word Lists For Atoms Gatsby Add JavaScript To Body Of The Document Git Accessing a Lost Commit Amend Author Of Previous Commit Auto-Squash Those Fixup Commits Caching Credentials Change The Start Point Of A Branch Checking Commit Ancestry Checkout Old Version Of A File Checkout Previous Branch Cherry Pick A Range Of Commits Clean Out All Local Branches Clean Up Old Remote Tracking References Clone A Repo Just For The Files, Without History Clone A Repo Locally From .git Configure Global gitignore File Configuring The Pager Copy A File From Another Branch Create A New Branch With Git Switch Delete All Untracked Files Determine The Hash Id For A Blob Diffing With Patience Dropping Commits With Git Rebase Dry Runs in Git Exclude A File From A Diff Output Excluding Files Locally Find The Date That A File Was Added To The Repo Find The Initial Commit Get The Name Of The Current Branch Get The Short Version Of The Latest Commit Grab A Single File From A Stash Grep For A Pattern On Another Branch Grep Over Commit Messages Ignore Changes To A Tracked File Ignore Files Specific To Your Workflow Include A Message With Your Stashed Changes Include Or Exclude Remaining Patch Changes Include Some Stats In Your Git Log Intent To Add Interactively Unstage Changes Last Commit A File Appeared In List All Files Changed Between Two Branches List Branches That Contain A Commit List Commits On A Branch List Different Commits Between Two Branches List Filenames Without The Diffs List Just The Files Involved In A Commit List Most Git Commands List Untracked Files List Untracked Files For Scripting Move The Latest Commit To A New Branch Pick Specific Changes To Stash Pulling In Changes During An Interactive Rebase Quicker Commit Fixes With The Fixup Flag Rebase Commits With An Arbitrary Command Reference A Commit Via Commit Message Pattern Matching Rename A Remote Renaming A Branch Resetting A Reset Resolve A Merge Conflict From Stash Pop Run A Git Command From Outside The Repo Set A Custom Pager For A Specific Command Show All Commits For A File Beyond Renaming Show Changes For Files That Match A Pattern Show Changes In The Compose Commit Message View Show File Diffs When Viewing Git Log Show List Of Most Recently Committed Branches Show Only Commits That Touch Specific Lines Show The diffstat Summary Of A Commit Show The Good And The Bad With Git Bisect Show What Is In A Stash Single Key Presses in Interactive Mode Skip A Bad Commit When Bisecting Skip Pre-Commit Hooks Staging Changes Within Vim Staging Stashes Interactively Stash A Single Untracked File Stash Everything Stashing Only Unstaged Changes Stashing Untracked Files Switch To A Recent Branch With FZF Turn Off The Output Pager For One Command Two Kinds Of Dotted Range Notation Unstage Changes Wih Git Restore Untrack A Directory Of Files Without Deleting Untrack A File Without Deleting It Update The URL Of A Remote Using Commands With A Relative Date Format Verbose Commit Message Viewing A File On Another Branch What Changed? What Is The Current Branch? Whitespace Warnings GitHub Actions Capture An Output Value For Use In A Later Step Reference An Encrypted Secret In An Action Go Access Go Docs Offline Build For A Specific OS And Architecture Not So Random Replace The Current Process With An External Command Sleep For A Duration Upgrading From An Older Version On Mac Heroku Set And Show Heroku Env Variables HTML Adding Alt Text To An Image Disable Auto-Completion For A Form Input Prevent Search Engines From Indexing A Page Render Text As Superscript Submit A Form With A Button Outside The Form HTTP What Counts As Cross-Origin With CORS? Internet Add Emoji To GitHub Repository Description Enable Keyboard Shortcuts In Gmail Exclude Whitespace Changes From GitHub Diffs Figure Out Your Public IP Address Focus The URL Bar Get Random Images From Unsplash Search Tweets By Author Show All Pivotal Stories With Blockers JavaScript Accessing Arguments To A Function Basic Date Formatting Without A Library Character Codes from Keyboard Listeners Check Classes On A DOM Element Check If Something Is An Array Check The Password Confirmation With Yup Compare The Equality Of Two Date Objects Computed Property Names In ES6 Conditionally Include Pairs In An Object Configure Jest To Run A Test Setup File Create A Cancelable Promise With PCancelable Create An Array Containing 1 To N Create An Object With No Properties Create Bootstrapped Apps With Yarn Create Future And Past Dates From Today Custom Type Checking Error Messages With Yup Default And Named Exports From The Same Module Define A Custom Jest Matcher Destructure With Access To Nested Value And Parent Value; Destructuring The Rest Of An Array Enable ES7 Transforms With react-rails Ensure Shell Can Find Global npm Binaries Easy Date Comparison With DayJS Expand Emojis With The Spread Operator Fill An Input With A Ton Of Text Find Where Yarn Is Installing Binaries for...in Iterates Over Object Properties Formatting Values With Units For Display Freeze An Object, Sorta Generate Random Integers Get The Location And Size Of An Element Get The Time Zone Of The Client Computer Globally Install A Package With Yarn Immutable Remove With The Spread Operator Initialize A New JavaScript Project With Yarn Install The Latest Version Of Node With Nvm Interpolate A String Into A Regex ISO-8601 Formatted Dates Are Interpreted As UTC Link A JavaScript Package Locally List Top-Level NPM Dependencies Make The Browser Editable With Design Mode Matching A Computed Property In Function Args Matching Multiple Values In A Switch Statement Mock A Function With Return Values Using Jest New Dates Can Take Out Of Bounds Values Numbers Are Empty Object Initialization With Shorthand Property Names Obtain Undefined Value With The Void Operator Parse A Date From A Timestamp Random Cannot Be Seeded Reach Into An Object For Nested Data With Get Render An Array Of Elements With React 16 Resolve And Pass Multiple Values From A Then Running ES6 Specs With Mocha Scoping Variables With A Block Statement Sorting Arrays Of Objects With Lodash Splat Arguments To A Function Spread The Rest With ES6 Start Node Process In Specific Timezone String Interpolation With Template Literals Support Nested Matching In Custom Jest Matchers Tell Prettier To Not Format A Statement Test Coverage Stats With Jest Test Timing-Based Code With Jest Fake Timers The Comma Operator Throttling A Function Call Timing Processes Transforming ES6 and JSX With Babel 6 Truthiness of Integer Arrays Turn An HTMLCollection Into An Array Turn Off Console Error Messages In A Test Waiting On Multiple Promises Who Am I: NPM Edition Yarn Commands Without The Emojis Yup Schemas Are Validated Asynchronously jq Extract A List Of Values Kitty Set The Title Of A Window Use The Built-In Emoji Picker Linux Check Ubuntu Version Configure Your Server Timezone List The Statuses Of All Upstart Jobs Show Current System Time And Settings Upgrading Ubuntu Mac Access All Screen And Video Capture Options Access System Information On OS X Access Unsupported Screen Resolutions With RDM Clean Up Old Homebrew Files Convert An HEIC Image File To JPG Default Screenshot Location Disable Swipe Navigation For A Specific App Display A Message With Alfred Find The Process Using A Specific Port Gesture For Viewing All Windows Of Current App Insert A Non-Breaking Space Character List All The Say Voices Quickly Type En Dashes And Em Dashes Require Additional JS Libraries In Postman Resize App Windows With AppleScript Resizing Both Corners Of A Window Run A Hardware Check Run AppleScript Commands Inline In The Terminal Set A Window To Its Default Zoom Level Specify App When Opening From Command Line Use Default Screenshot Shortcuts With CleanShot X View All Windows Of The Current App MongoDB Determine The Database Version Dump A Remote Database Get Size Stats For A Collection List Size Stats For All Collections MySQL Display Output In A Vertical Format Doing Date Math Dump A Database To A File List Databases And Tables Show Create Statement For A Table Show Tables That Match A Pattern Show Indexes For A Table Netlify Override The Default Yarn Version Next.js Create Files And Directories For Dynamic Routes Define URL Redirects In The Next Config Remove A Query Param From The URL Ship Public Assets With A Next.js App Phoenix Bypass Template Rendering Check The Installed Version Generate New App Without Brunch Render A Template To A String Serve Static Assets From Custom Directory Specifying The Digest Directory Specifying The Server Port PostgreSQL A Better Null Display Character Add Foreign Key Constraint Without A Full Lock Add ON DELETE CASCADE To Foreign Key Constraint Adding Composite Uniqueness Constraints Aggregate A Column Into An Array Assumed Radius Of The Earth Auto Expanded Display Between Symmetric Capitalize All The Words Change The Current Directory For psql Check If The Local Server Is Running Check Table For Any Oprhaned Records Checking Inequality Checking The Type Of A Value Clear The Screen In psql Clear The Screen In psql (2) Compute Hashes With pgcrypto Compute The Levenshtein Distance Of Two Strings Compute The md5 Hash Of A String Configure The Timezone Constructing A Range Of Dates Convert A String To A Timestamp Count How Many Records There Are Of Each Type Count Records By Type Count The Number Of Trues In An Aggregate Query Create A Composite Primary Key Create An Index Without Locking The Table Create Database Uses Template1 Create hstore From Two Arrays Create Table Adds A Data Type Creating Conditional Constraints Creating Custom Types Day Of Week By Name For A Date Day Of Week For A Date Default Schema Defining Arrays Determine Types Of JSONB Records Determining The Age Of Things Difference Between Explain And Explain Analyze Dump All Databases To A SQL File Dump And Restore A Database Duplicate A Local Database Edit Existing Functions Escaping A Quote In A String Escaping String Literals With Dollar Quoting Export Query Results To A CSV Extracting Nested JSON Data Find Records That Contain Duplicate Values Find Records That Have Multiple Associated Records Find The Data Directory Find The Location Of Postgres Config Files Fizzbuzz With Common Table Expressions Force SSL When Making A psql Connection Generate A UUID Generate Random UUIDs Without An Extension Generate Series Of Numbers Generating UUIDs With pgcrypto Get The Size Of A Database Get The Size Of A Table Get The Size Of An Index Getting A Slice Of An Array Group By The Result Of A Function Call Insert Just The Defaults Install Postgres With uuid-ossp Using asdf Integers In Postgres Intervals Of Time By Week Is It Null Or Not Null? Limit Execution Time Of Statements List All Columns Of A Specific Type List All Rows In A Table List All The Databases List All Versions Of A Function List Available Schemas List Connections To A Database List Database Objects With Disk Usage List Database Users List Various Kinds Of Objects Lower Is Faster Than ilike Max Identifier Length Is 63 Bytes pg Prefix Is Reserved For System Schemas Prepare, Execute, And Deallocate Statements Pretty Print Data Sizes Pretty Printing JSONB Rows Prevent A Query From Running Too Long Print The Query Buffer In psql Remove Not Null Constraint From A Column Renaming A Sequence Renaming A Table Restart A Sequence Restarting Sequences When Truncating Tables Salt And Hash A Password With pgcrypto Send A Command To psql Set Inclusion With hstore Set A Seed For The Random Number Generator Set A Statement Timeout Threshold For A Session Sets With The Values Command Shorthand Absolute Value Operator Show All Versions Of An Operator Sleeping Special Math Operators Storing Emails With citext String Contains Another String Switch Non-Castable Column Type With Using Clause Switch The Running Postgres Server Version Temporarily Disable Triggers Temporary Tables Terminating A Connection Timestamp Functions Toggling The Pager In PSQL Track psql History Separately Per Database Truncate All Rows Truncate Tables With Dependents Turning Timing On Two Ways To Compute Factorial Types By Category Use A psqlrc File For Common Settings Use Argument Indexes Use Not Valid To Immediately Enforce A Constraint Using Expressions In Indexes Using Intervals To Offset Time Who Is The Current User Word Count for a Column Write A Query Result To File Python Access Instance Variables Create A Dummy DataFrame In Pandas Test A Function With Pytest Rails Add A Check Constraint To A Table Add A Foreign Key Reference To A Table Add A Reference Column With An Index Add React With Webpacker To A New Rails App Add timestamptz Columns With The Migration DSL Access Secrets In A Rails 5.2 App ActiveRecord Query For This Or That Advance The Date Allow List Params Anywhere With Strong Params All or Nothing Database Transactions Assert Two Arrays Have The Same Items With RSpec Attach A File With Capybara Attribute Getter without the Recursion Attribute Was Autosave False On ActiveRecord Associations Bind Parameters To ActiveRecord SQL Query Build A Hash Of Model Attributes Capture Development Emails With Mailhog Capybara Page Status Code Cast Common Boolean-Like Values To Booleans Change The Nullability Of A Column Change The Time Zone Offset Of A DateTime Object Check If ActiveRecord Update Fails Check If Any Records Have A Null Value Check Specific Attributes On ActiveRecord Array Code Statistics For An Application Columns With Default Values Are Nil On Create Comparing DateTimes Down To Second Precision Conditional Class Selectors in Haml Convert A Symbol To A Constant Count The Number Of Records By Attribute Create A Custom Named References Column Create A Join Table With The Migration DSL Creating Records of Has_One Associations Custom Validation Message Customize Paths And Helpers For Devise Routes Customize The Path Of A Resource Route Delete Paranoid Records Demodulize A Class Name Different Ways To Add A Foreign Key Reference Disambiguate Where In A Joined Relation Ensure Migrations Use The Latest Schema Force All Users To Sign Out Generating And Executing SQL Get An Array Of Values From The Database Get An Empty ActiveRecord Relation Get The Column Names For A Model Get The Current Time Hash Slicing Ignore Poltergeist JavaScript Errors Include Devise Helpers In Your Controller Tests Inspect Previous Changes To ActiveRecord Object Link To The Current Page With Query Params List All Installable Rails Versions List The Enqueued Jobs Load Records In Batches With find_each Log SQL Queries Executed By ActiveRecord Mark A Migration As Irreversible Make ActionMailer Synchronous In Test Manually Run A Migration From Rails Console Mark For Destruction Mask An ActiveRecord Attribute Merge A Scope Into An ActiveRecord Query Migrating Up Down Up Order Matters For rescue_from Blocks Params Includes Submission Button Info Parse Query Params From A URL Perform SQL Explain With ActiveRecord Polymorphic Path Helpers Pretend Generations Query A Single Value From The Database Read In Environment-Specific Config Values Read-Only Models Remove The Default Value On A Column Render An Alternative ActionMailer Template Render The Response Body In Controller Specs Rescue From Retrieve An Object If It Exists Rollback A Specific Migration Out Of Order Rounding Numbers With Precision Schedule Sidekiq Jobs Out Into The Future Secure Passwords With Rails And Bcrypt Select A Select By Selector Select Value For SQL Counts Serialize With fast_jsonapi In A Rails App Set A Timestamp Field To The Current Time Set default_url_options For Entire Application Set Schema Search Path Set Statement Timeout For All Postgres Connections Set The Default Development Port Show Pending Migrations Show Rails Models With Pry Show Rails Routes With Pry Skip Validations When Creating A Record Specify New Attributes For #find_or_create_by Temporarily Disable strong_params Test If An Instance Variable Was Assigned Truncate Almost All Tables Update Column Versus Update Attribute Upgrading Your Manifest For Sprocket's 4 Verify And Read A Signed Cookie Value Where Am I In The Partial Iteration? Wipe Out All Precompiled Assets Write Reversible Migration To Set Default Write Safer Where Clauses With Placeholders React A Component Is Just A Bag Of Data Access The Latest Lifecycle Methods In An Old App Accessing Env Vars In create-react-app Accessing Location Within @reach/router Allow md As An Extension With gatsby-mdx Alter The Display Name Of A Component Building A React App In The Browser Check The Type Of A Child Component Conditionally Including Event Handler Functions Create A Snowpack-Bundled React App Create Dynamically Named Custom React Components create-react-app Comes With Lodash create-react-app Has A Default Test Setup File CSS !important Is Not Supported By Inline Styles Debug Jest Tests In create-react-app Defining State In A Simple Class Component Destructure Variables As Props To A Component Details Tags Are A Controllable Component Dispatch Anywhere With Redux Dynamically Add Props To A Child Component Dynamically Create HTML Elements Enforce Specific Values With PropTypes Focus An Input With useRef Hook Force A Component To Only Have One Child Forcing A Child Remount With The Key Prop Formik Connected Components Formik's Validation Schema As A Function Inactive And Active Component Styles With Radium Inline Style Attributes Should Be Camel Cased Manage State In A Functional Component Mapping Over One Or Many Children Mock A Function That A Component Imports Navigate With State Via @reach/router Pairing A Callback With A useState Hook Pass A Function To A useState Updater Passing Props Down To React-Router Route Prevent reach/router Redirect Error Screen In Dev Proxy To An API Server In Development With CRA Quickly Search For A Component With React DevTools @reach/router Renders To A Div Read Only Input Elements Rendering Multiple Nodes With Fragments Set The Type For A useState Hook Specifying Dependencies Of A useEffect Hook Spelunking Through Components With Enzyme's Dive Sync Your react-router State With Redux Test Files In create-react-app Test That Element Does Not Render In The Component Trigger Effect Only When The Component Mounts Update Formik Initial Values When Props Change Upgrading To The Latest React In CodeSandbox Use A Ref To Autofocus An Input Use React 16 With Gatsby Use withRouter To Pass Down React-Router History Visually Select A React Element For Inspection Who Is Your Favorite Child? Wrap The Root Of A Gatsby App In A Component React Native Avoid The Notch With SafeAreaView React Testing Library Check That A Component Renders As Null findBy* Queries Have Async Built In Pretty Print Some DOM To Debug A Test Test A Component That Uses React Portals ReasonML Break Out Of A While Loop Compile Reason To Native With Dune Compile Reason With An OCaml Package Using Dune Create A Map Of Strings Create A Stream From An Array Creating A 2D Array Data Structures With Self-Referential Types Defining Variants With Constructor Arguments Dynamically Create A Printf String Format Exhaustive Pattern Matching Of List Variants Format The Current File Within Vim Generate A Native ReasonML Project With Pesy Generate Starter Reason Projects Helping The Compiler Help Us With Variants Inline Component Styles With Reason React Is This A Directory Or A File? Making Things Mutable Modifying A String With blit_string Multi-Argument Functions As Syntactic Sugar Pattern Match On Exceptions Quickly Bootstrap A React App Using Reason Seeding And Generating Random Integers Stream A File Line By Line String Interpolation With Integers And Sprintf String Interpolation With Quoted Strings Trying Out ReasonML In CodeSandbox Two Ways To Find An Item In A List Using Optional Labeled Function Arguments Wrapping A Component For Use In JavaScript Ruby A Shorthand For Rerunning Failed Tests With RSpec Add Linux As A Bundler Platform Are They All True? Assert About An Object's Attributes With RSpec Assoc For Hashes Block Comments Chaining Multiple RSpec Change Matchers Check Return Status Of Running A Shell Command Click On Text With Capybara Colorful Output With MiniTest Comparing Class Hierarchy Relationships Comparing Arrays In RSpec Construct A Constant From A String Create an Array of Stringed Numbers Create a CSV::Table Object Create A Hash From An Array Of Arrays Create Listing Of All Middleman Pages Create Named Structs With Struct.new Create Thumbnail Image For A PDF Defaulting To Frozen String Literals Define A Custom RSpec Matcher Destructuring Arrays In Blocks Disassemble Some Codes Double Splat To Merge Hashes Edit Previous Parts Of The Pry Buffer History Editing Code In Pry Encode A String As URL-Safe Base64 Enumerate A Pairing Of Every Two Sequential Items Evaluating One-Off Commands Exclude Values From An Array Expect A Method To Be Called And Actually Call It FactoryGirl Sequences Fail Find The Min And Max With A Single Call Finding The Source of Ruby Methods Generate A Signed JWT Token Generate Ruby Version And Gemset Files With RVM Get Info About Your RubyGems Environment Identify Outdated Gems If You Detect None Iterate With An Offset Index Ins And Outs Of Pry Invoking Rake Tasks Multiple Times IRB Has Built-In Benchmarking With Ruby 3 Jump Out Of A Nested Context With Throw/Catch Last Raised Exception In The Call Stack Limit Split List The Running Ruby Version Listing Local Variables Map With Index Over An Array Mock Method Chain Calls With RSpec Mocking Requests With Partial URIs Using Regex Named Regex Captures Are Assigned To Variables Navigate Back In The Browser With Capybara Next And Previous Floats Or Operator Precedence Override The Initial Sequence Value Parallel Bundle Install Parsing A CSV With Quotes In The Data Pass A Block To Count Passing Arbitrary Methods As Blocks Passing Arguments To A Rake Task Pattern Match Values From A Hash Percent Notation Question Mark Operator Rake Only Lists Tasks With Descriptions Read The First Line From A File Rendering ERB Replace The Current Process With An External Command Require Entire Gemfile In Pry Session Rerun Only Failures With RSpec Retry A Block After An Exception Returning With Sequel rexml Is A Bundled Gem As Of Ruby 3.0.0 Run An Older Version Of Bundler Running A Single MiniTest Example Safe Navigation Operator Scripting With RVM Scroll To Top Of Page With Capybara Set RVM Default Ruby Show Public Methods With Pry Silence The Output Of A Ruby Statement In Pry Single And Double Quoted String Notation Squeeze Out The Extra Space String Interpolation With Instance Variables Summing Collections Turn Key And Value Arrays Into A Hash Turning Any Class Into An Enumerator Turning Things Into Hashes Uncaught Exceptions In Pry undef_method And The Inheritance Hierarchy Uninstall Specific Version Of A Ruby Gem Unpacking Strings Into Binary Up And Down With Integers Update The Gemfile Bundled With Version Use A Case Statement As A Cond Statement Use dotenv In A Non-Rails Project Use Tap For Better Test Data Setup Using BCrypt To Create And Check Hashed Passwords What To Do When You Don't Rescue Who Are My Ancestors? Wrap Things In An Array, Even Hashes Zero Padding sed Apply Multiple Substitutions To The Input Equivalence Classes Of Repetition MetaChars Extract Value From Command Output With Sed Grab All The Method Names Defined In A Ruby File Grab The First Line Of A File OSX sed Does Regex A Bit Different Output Only Lines Involved In A Substitution Reference A Capture In The Regex Use An Alternative Delimiter In A Substitution Shell Check If The First Argument Is Given Format And Print The Current Date And Time Streaming Monitor An Audio Input Device In OBS Tailwind CSS Base Styles For Text Link Specify Paths For Purging Unused CSS Use Tailwind Typography Prose In Dark Mode tmux Access Past Copy Buffer History Adjusting Window Pane Size Break Current Pane Out To Separate Window Change Base Directory Of Existing Session Change The Default Prefix Key Create A Named tmux Session Create A New Session In A New Server Cycle Through Layouts Enabling Vi Mode Get Mouse Copy/Paste Working In Kitty Hiding The Status Bar Jumping Between Sessions Kill All Your tmux Sessions Kill Other Connections To A Session Kill The Current Session List All Key Bindings List Sessions Open New Window With A Specific Directory Organizing Windows Paging Up And Down Pane Killer Reclaiming The Entire Window Remove The Delay On The Escape Key Rename The Current Session Reset An Option Back To Its Default Value Show The Current Value For An Option Swap Split Panes Switch To A Specific Session And Window tmux in your tmux Toggle Between Two Common Sessions TypeScript Add Types To An Object Destructuring Compiler Checks For Unused Params And Variables Re-Export An Imported Type Type Narrowing With Similarly Shaped Objects Use An Array Check For Type Narrowing Zero-Config Environments For Trying Out Types Unix All The Environment Variables Cat A File With Line Numbers Cat Files With Color Using Bat Change Default Shell For A User Change To That New Directory Check If A Port Is In Use Check If Command Is Executable Before Using Check The Current Working Directory Clear The Screen Command Line Length Limitations Compare Two Variables In A Bash Script Configure cd To Behave Like pushd In Zsh Copying File Contents To System Paste Buffer Copying Nested Directories With Ditto Create A File Descriptor with Process Substitution Curl With Cookies Curling For Headers Curling With Basic Auth Credentials Display All The Terminal Colors Display Free Disk Space Display The Contents Of A Directory As A Tree Do A Dry Run Of An rsync Do Not Overwrite Existing Files Enable Multi-Select Of Results With fzf Exclude A Directory With Find Exclude Certain Files From An rsync Run Figure Out The Week Of The Year From The Terminal File Type Info With File Find A File Installed By Brew Find Files With fd Find Newer Files Fix Unlinked Node Binaries With asdf Forward Multiple Ports Over SSH Generate A SAML Key And Certificate Pair Get Matching Filenames As Output From Grep Get The Unix Timestamp Global Substitution On The Previous Command Globbing For All Directories In Zsh Globbing For Filenames In Zsh Grep For Files Without A Match Grep For Files With Multiple Matches Grep For Multiple Patterns Hexdump A Compiled File Ignore The Alias When Running A Command Interactively Browse Available Node Versions Jump To The Ends Of Your Shell History Kill Everything Running On A Certain Port Killing A Frozen SSH Session Last Argument Of The Last Command Less With Style List All Users List Files Ordered By Modification Date List Names Of Files With Matches List Of Sessions To A Machine List Parent pid With ps List Stats For A File List The Available JDKs List The Stack Of Remembered Directories Map A Domain To localhost Only Show The Matches Open The Current Command In An Editor Partial String Matching In Bash Scripts PID Of The Current Shell Print A Range Of Lines For A File With Bat Print Out Files In Reverse Provide A Fallback Value For Unset Parameter Repeat Yourself Saying Yes Search Files Specific To A Language Search History Search Man Page Descriptions Securely Remove Files Set The asdf Package Version For A Single Shell Show A File Preview When Searching With FZF Show Disk Usage For The Current Directory Show The Size Of Everything In A Directory Skip Paging If Output Fits On Screen With Less SSH Escape Sequences SSH With Port Forwarding Specify The Language For A File With Bat Sort In Numerical Order Switch Versions of a Brew Formula Touch Access And Modify Times Individually Undo Some Command Line Editing Update Package Versions Known By asdf Plugin Use fzf To Change Directories Use Regex Pattern Matching With Grep View A Web Page In The Terminal Watch The Difference Watch This Run Repeatedly Where Are The Binaries? Vercel Add Web Server Layer Redirects Deploy An App Without Pushing An Empty Commit Naming Of The Vercel Config File Share Development Environment Variables Via CLI Vim Aborting Git Commits And Rebases Absolute And Relative Line Numbers Add A File Without Loading It Add Custom Dictionary Words All The Ways To Write And Quit In Vim Allow Neovim To Copy/Paste With System Clipboard Almost The End Of The Line Alternate Files With vim-rails Always Keep The Gutter Open Amend Commits With Fugitive Backspace Options Beginning And End Of Previous Change The Black Hole Register Blank Lines Above And Below Breaking The Undo Sequence Buffer Time Travel Build And Install A Go Program Case-Aware Substitution With vim-abolish Case-Insensitive Substitution Center The Cursor Check For An Executable Check Your Current Color Scheme Clear Out The Jump List Close All Other Splits Close All Other Windows Close the Current Buffer Coerce The Current Filetype Coercing Casing With vim-abolish Configure FZF To Use fd For File Finding Count the Number of Matches Create A New Directory In netrw Create A New File In A New Directory Creating Non-Existent Directories Default netrw To Tree Liststyle Delete Every Other Line Delete Lines That Match A Pattern Delete To The End Of The Line Deleting Buffers In BufExplorer Deleting Directories Of Files From netrw Detect If You Are On A Mac Difference Between :wq and :x Display Word Count Stats Edges Of The Selection Edit A File At A Specific Line Number Edit A File Starting On The Last Line End Of The Word Escaping Terminal-Mode In An Nvim Terminal Filter Lines Through An External Program Fix The Spelling Of A Word Fold A Visual Selection And Expand It Back For When That Escape Key Is Hard To Reach Format Long Lines To Text Width From Ruby Variables To JavaScript Variables Generate and Edit Rails Migration Get The pid Of The Session Go Back To The Previous Window Go To File With Line Number Grepping Through The Vim Help Files Head of File Name Help For Non-Normal Mode Features Highlighting Search Matches Horizontal to Vertical and Back Again Increment All The Numbers Incremental Searching Interact With The Alternate File Interactive Buffer List Joining Lines Together Jump Back To The Latest Jump Position Jump Between And Stage Git Hunks With Fugitive Jump To Matching Pair Jump To The Next Misspelling List All Buffers List Of Plugins Load A Directory Of Files Into The Buffer List Make Directories For The Current File Marks Across Vim Sessions Match The Beginning And End Of Words Moving To A Specific Line Navigate To The Nth Column On A Line Navigating By Blank Lines NETRW Listing Styles Next Modified Buffer Normal Node Binding To Just Quit Open A Tag In A Split Window Open an Unnamed Buffer Open FZF Result In A Split Open Routes File With vim-rails Open The Directory Of The Current File Open The Fugitive Git Summary Window Open The Gemfile Open The Latest Rails Migration Open The Selected Lines In GitHub With Gbrowse Open Vim To A Tag Definition Opening a URL Opening Man Pages In Vim Paste A Register From Insert Mode Preventing Typos with Abbreviations Previous Buffer Previous Visual Selection Print The Relative Path Of The Current File Print Version Information Quick File Info Quick Man Pages Quick Quickfix List Navigation Quickly Fix A Misspelled Word Quickly Switch To A Buffer By Number Quit When There Is An Argument List Re-indenting Your Code Read In The Contents Of A Rails File Rename A File Through netrw Rename Current File Repeat The Previous Change Repeating Characters Replace A Character Reset Target tslime Pane Reverse A Group Of Lines Rotate Everything By 13 Letters Rotate The Orientation Of Split Windows Running Bundle With vim-bundler Scrolling Relative to the Cursor Search Backward Through A File Searching For Hex Digits Select Several Results From An FZF Search Set End Of Line Markers Set Your Color Scheme Set Up Vim-Plug With Neovim Setting Filetype With Modelines Show All Syntax Highlighting Rules Show Matching Entries For Help Specify The Line Height Of The Quick Fix Window Split Different Split The Current Window Splitting For New Files Source Original vimrc When Using Neovim Swap Occurrences Of Two Words Swapping Split Windows Tabs To Spaces The Vim Info File Toggle Absolute And Relative Paths In BufExplorer Toggling Syntax Highlighting Turning Off Search Highlighting Unloading A Buffer Use Active Window With BufExplorer Use The Terminal Inside A Vim Session Using vim-surround With A Visual Selection Verbose Commits With Fugitive View Commit History of a File Viewing Man Pages with man.vim Vim Without The Extras What Is On The Runtime Path? Whole Line Auto-Completion Wrap With Some Room VSCode Add The VSCode CLI To Your Path Advance Through Search Results Enable Breadcrumbs For Version 1.26 Release Open An Integrated Terminal Window Toggle Between Terminals Webpack Better Module Imports With Aliases Debugging With Full Source Maps Run ESLint As A Preloader Specify Port Of CRA's Webpack Dev Server Use A Specific Config File Workflow Change Window Name In iTerm Convert An ePub Document To PDF On Mac Create A Public URL For A Local Server Enable Dev Tools For Safari Forward Stripe Events To Local Server Get Your Public IP Address Import A Github Project Into CodeSandbox Interactively Kill A Process With fkill Open Slack's Keyboard Shortcuts Reference Panel Prune The Excess From node_modules Rotate An Image To Be Oriented Upright Set Recurring Reminders In Slack Toggle Between Stories In Storybook Update asdf Plugins With Latest Package Versions View The PR For The Current GitHub Branch XState Use An XState Machine With React YAML Create Multi-Line Strings Without The Line Breaks Usage The .vimrc file for this project contains a function CountTILs that can be invoked with <leader>c. This will do a substitution count of the current number of TILs and display the result in the command tray. About I shamelessly stole this idea from thoughtbot/til. Other TIL Collections Today I Learned by Hashrocket jwworth/til thoughtbot/til License 2015-2021 Josh Branchaud This repository is licensed under the MIT license. See LICENSE for details."
3864,"A unified API to ask for permissions on iOS Permission exposes a unified API to request permissions on iOS. Usage Example Installation License Usage Permission Permission.swift PermissionStatus.swift Supported Permissions PermissionType.swift Types/ Bluetooth Camera Contacts Events Motion Microphone Notifications Photos Reminders LocationAlways LocationWhenInUse MediaLibrary SpeechRecognizer Siri PermissionAlert PermissionAlert.swift Denied and disabled alerts When you first request a permission, a system alert is presented to the user. If you request a permission that was denied/disabled, a PermissionAlert will be presented. You might want to change the default title, message, cancel and settings text: Set permission.presentDeniedAlert = false or permission.presentDisabledAlert = false if you don't want to present these alerts. Pre-permission alerts In order not to burn your only chance of displaying the system alert, you can present a pre-permission alert. See this article for more informations. The system alert will only be presented if the user taps ""Give Access"". PermissionSet PermissionSet.swift Use a PermissionSet to check the status of a group of Permission and to react when a permission is requested. PermissionButton PermissionButton A PermissionButton requests the permission when tapped and updates itself when its underlying permission status changes. PermissionButton is a subclass of UIButton. All the getters and setters of UIButton have their equivalent in PermissionButton. Third-party libraries: sunshinejr/RxPermission RxSwift bindings for Permissions API in iOS. Example Installation Carthage Carthage is a decentralized dependency manager that automates the process of adding frameworks to your Cocoa application. You can install Carthage with Homebrew using the following command: To integrate Permission into your Xcode project using Carthage, specify it in your Cartfile: Configuration Due to Apple's new policy regarding permission access, binaries may be rejected due to a perceived attempt to access privacy-sensitive data without a usage key, and then further rejected for not actually requesting permissions. As a workaround, you can provide custom build flags before building the dynamic framework to only compile with permissions you request. This is done by adding a configuration file named PermissionConfiguration.xcconfig to the root of your project. For convenience, you can use PermissionConfiguration.xcconfig in the Permission/ repo directory. Just comment out the permissions you want to use, and compile the framework. To compile with only notifications and photos permissions: Cocoapods CocoaPods is a dependency manager for Cocoa projects. You can install it with the following command: To integrate Permission into your Xcode project using CocoaPods, specify it in your Podfile. Due to Apple's new policy regarding permission access you need to specifically define what kind of permissions you want to access using subspecs. For example if you want to access the Camera and the Notifications you define the following: Please see Permission.podspec for more information about which subspecs are available. License Copyright (c) 2015-2019 Damien (http://delba.io) Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the ""Software""), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
4686,"Write C# apps with a text editor, nuget and the power of Roslyn!scriptcs What is it? scriptcs makes it easy to write and execute C# with a simple text editor. While Visual Studio, and other IDEs, are powerful tools, they can sometimes hinder productivity more than they promote it. You dont always need, or want, the overhead of a creating a new solution or project. Sometimes you want to just type away in your favorite text editor. scriptcs frees you from Visual Studio, without sacrificing the advantages of a strongly-typed language. Write C# in your favorite text editor. Use NuGet to manage your dependencies. The relaxed C# scripting syntax means you can write and execute an application with only one line of code. Script Packs allow you to bootstrap the environment for new scripts, further reduces the amount of code necessary to take advantage of your favorite C# frameworks. Getting scriptcs Releases and nightly builds should be installed using Chocolatey. To install Chocolatey, execute the following command in your command prompt: @powershell -NoProfile -ExecutionPolicy Unrestricted -Command ""iex ((New-Object Net.WebClient).DownloadString('https://chocolatey.org/install.ps1'))"" && SET PATH=%PATH%;%systemdrive%\chocolatey\bin If the above fails with the error indicating that proxy authentication is required (i.e. HTTP 407) then try again with the following on the command prompt that uses your default credentials: @powershell -NoProfile -ExecutionPolicy Unrestricted -Command ""[Net.WebRequest]::DefaultWebProxy.Credentials = [Net.CredentialCache]::DefaultCredentials; iex ((New-Object Net.WebClient).DownloadString('https://chocolatey.org/install.ps1'))"" && SET PATH=%PATH%;%systemdrive%\chocolatey\bin Note: If you are using a version of Chocolatey > 0.9.9.0 you can pass the -y into the install and upgrade commands to prevent the confirmation that will appear. Installing scriptcs Once Chocolatey has been installed, you can install the latest stable version of scriptcs from your command prompt: choco install scriptcs Chocolatey will install scriptcs to %LOCALAPPDATA%\scriptcs\ and update your PATH accordingly. Note: You may need to restart your command prompt after the installation completes. Staying up-to-date With Chocolatey, keeping scriptcs updated is just as easy: choco upgrade scriptcs Note: If you are using a version of Chocolatey < 0.9.0.0 you will need to use choco update scriptcs, but also think about updating Chocolatey itself. Nightly builds Nightly builds are hosted on MyGet, and can also be installed through with Chocolatey: choco install scriptcs -pre -source https://www.myget.org/F/scriptcsnightly/ Building from source Windows Ensure you have .NET Framework 4.6.1 installed. Execute the build script. build.cmd Linux Ensure you have Mono 5.12 or later installed. Execute the build script ./build.sh Getting Started Using the REPL The scriptcs REPL can be started by running scriptcs without any parameters. The REPL allows you to execute C# statements directly from your command prompt. REPL supports all C# language constructs (i.e. class definition, method definition), as well as multi-line input. For example: Writing a script In an empty directory, create a new file named app.csx: Install the RavenDB.Embedded package from NuGet using the install command. Execute your script. Note that listening on a port requires that the command prompt be launched using the Run as Administrator option. Navigating to the URL that Raven is listening on will now bring up the RavenDB management studio. Bootstrap scripts with Script Packs Script Packs can be used to further reduce the amount of code you need to write when working with common frameworks. In an empty directory, install the ScriptCs.WebApi script pack from NuGet. The script pack automatically imports the Web API namespaces and provides a convenient factory method for initializing the Web API host. It also replaces the default ControllerResolver with a custom implementation that allows Web API to discover controllers declared in scripts. Script packs can be imported into a script by calling Require<TScriptPack>(). Create a file named server.csx that contains the following code: In a command prompt running as administrator, execute the server.csx file. Browse to http://localhost:8888/test/ to see the result of the TestController.Get method. Referencing scripts Move the TestController class from the previous example into a new file named controller.csx with the following content. On the first line of server.csx, reference controller.csx using the #load directive. Note: #load directives must be placed at the top of a script, otherwise they will be ignored. In a command prompt running as administrator, execute the server.csx file. Browse to http://localhost:8888/test/ to see the result of the TestController.Get method. Referencing assemblies You can reference additional assemblies from the GAC or from the bin folder in your script's directory using the #r directive: Debugging Instructions for debugging scripts using Visual Studio can be found on the wiki. Package installation You can install any NuGet packages directly from the scriptcs CLI. This will pull the relevant packages from NuGet, and install them in the scriptcs_packages folder. Once the packages are installed, you can simply start using them in your script code directly (just import the namespaces - no additional bootstrapping or DLL referencing is needed). The install command will also create a scriptcs_packages.config file if you don't have one - so that you can easily redistribute your script (without having to copy the package binaries). scriptcs -install {package name} will install the desired package from NuGet. For example: scriptcs -install ServiceStack scriptcs -install (without package name) will look for the scriptcs_packages.config file located in the current execution directory, and install all the packages specified there. You only need to specify top level packages. For example, you might create the following scriptcs_packages.config: <?xml version=""1.0"" encoding=""utf-8""?> <packages> <package id=""Nancy.Hosting.Self"" version=""0.16.1"" targetFramework=""net40"" /> <package id=""Nancy.Bootstrappers.Autofac"" version=""0.16.1"" targetFramework=""net40"" /> <package id=""Autofac"" version=""2.6.3.862"" targetFramework=""net40"" /> </packages> And then just call: scriptcs -install As a result, all packages specified in the scriptcs_packages.config, including all dependencies, will be downloaded and installed in the scriptcs_packages folder. Contributing Read our Contribution Guidelines. Samples and Documentation Additional samples can be contributed to our samples repository. Documentation can be found on our wiki. Community Want to chat? In addition to Twitter, you can find us on Google Groups and JabbR! Coordinators Glenn Block (@gblock) Justin Rusbatch (@jrusbatch) Filip Wojcieszyn (@filip_woj) Core Committers Damian Schenkelman (@dschenkelman) Kristian Hellang (@khellang) Adam Ralph (@adamralph) Paul Bouwer (@pbouwer) Credits Check out the list of developers responsible for getting scriptcs to where it is today! Special thanks to Filip Wojcieszyn for being the inspiration behind this with his Roslyn Web API posts. Thanks to the Roslyn team who helped point me in the right direction. License Apache 2 License"
2182,"The leading native Python SSHv2 protocol library.======== Paramiko ======== .. Continuous integration and code coverage badges .. image:: https://travis-ci.org/paramiko/paramiko.svg?branch=master :target: https://travis-ci.org/paramiko/paramiko .. image:: https://codecov.io/gh/paramiko/paramiko/branch/master/graph/badge.svg :target: https://codecov.io/gh/paramiko/paramiko :Paramiko: Python SSH module :Copyright: Copyright (c) 2009 Robey Pointer robeypointer@gmail.com :Copyright: Copyright (c) 2020 Jeff Forcier jeff@bitprophet.org :License: LGPL <https://www.gnu.org/copyleft/lesser.html>_ :Homepage: http://www.paramiko.org/ :API docs: http://docs.paramiko.org :Development: https://github.com/paramiko/paramiko What ""Paramiko"" is a combination of the Esperanto words for ""paranoid"" and ""friend"". It's a module for Python 2.7/3.4+ that implements the SSH2 protocol for secure (encrypted and authenticated) connections to remote machines. Unlike SSL (aka TLS), SSH2 protocol does not require hierarchical certificates signed by a powerful central authority. You may know SSH2 as the protocol that replaced Telnet and rsh for secure access to remote shells, but the protocol also includes the ability to open arbitrary channels to remote services across the encrypted tunnel (this is how SFTP works, for example). It is written entirely in Python (though it depends on third-party C wrappers for low level crypto; these are often available precompiled) and is released under the GNU Lesser General Public License (LGPL <https://www.gnu.org/copyleft/lesser.html>_). The package and its API is fairly well documented in the docs folder that should have come with this repository. Installation For most users, the recommended method to install is via pip:: pip install paramiko For more detailed instructions, see the Installing <http://www.paramiko.org/installing.html>_ page on the main Paramiko website. Portability Issues Paramiko primarily supports POSIX platforms with standard OpenSSH implementations, and is most frequently tested on Linux and OS X. Windows is supported as well, though it may not be as straightforward. Bugs & Support :Bug Reports: Github <https://github.com/paramiko/paramiko/issues/> :Mailing List: paramiko@librelist.com (see the LibreList website <http://librelist.com/> for usage details). :IRC: #paramiko on Freenode Kerberos Support Paramiko ships with optional Kerberos/GSSAPI support; for info on the extra dependencies for this, see the GSS-API section <http://www.paramiko.org/installing.html#gssapi>_ on the main Paramiko website. Demo Several demo scripts come with Paramiko to demonstrate how to use it. Probably the simplest demo is this:: import base64 import paramiko key = paramiko.RSAKey(data=base64.b64decode(b'AAA...')) client = paramiko.SSHClient() client.get_host_keys().add('ssh.example.com', 'ssh-rsa', key) client.connect('ssh.example.com', username='strongbad', password='thecheat') stdin, stdout, stderr = client.exec_command('ls') for line in stdout: print('... ' + line.strip('\n')) client.close() This prints out the results of executing ls on a remote server. The host key b'AAA...' should of course be replaced by the actual base64 encoding of the host key. If you skip host key verification, the connection is not secure! The following example scripts (in demos/) get progressively more detailed: :demo_simple.py: Calls invoke_shell() and emulates a terminal/TTY through which you can execute commands interactively on a remote server. Think of it as a poor man's SSH command-line client. :demo.py: Same as demo_simple.py, but allows you to authenticate using a private key, attempts to use an SSH agent if present, and uses the long form of some of the API calls. :forward.py: Command-line script to set up port-forwarding across an SSH transport. :demo_sftp.py: Opens an SFTP session and does a few simple file operations. :demo_server.py: An SSH server that listens on port 2200 and accepts a login for 'robey' (password 'foo'), and pretends to be a BBS. Meant to be a very simple demo of writing an SSH server. :demo_keygen.py: A key generator similar to OpenSSH ssh-keygen(1) program with Paramiko keys generation and progress functions. Use The demo scripts are probably the best example of how to use this package. Also a lot of documentation is generated by Sphinx autodoc, in the doc/ folder. There are also unit tests here:: $ pip install -r dev-requirements.txt $ pytest Which will verify that most of the core components are working correctly. To test Kerberos/GSSAPI, you need a Kerberos environment. On UNIX you can use the package k5test to setup a Kerberos environment on the fly:: $ pip install -r dev-requirements.txt $ pip install k5test gssapi pyasn1 $ pytest"
1025,"Liquid markup language. Safe, customer facing template language for flexible web apps.Liquid template engine Contributing guidelines Version history Liquid documentation from Shopify Liquid Wiki at GitHub Website Introduction Liquid is a template engine which was written with very specific requirements: It has to have beautiful and simple markup. Template engines which don't produce good looking markup are no fun to use. It needs to be non evaling and secure. Liquid templates are made so that users can edit them. You don't want to run code on your server which your users wrote. It has to be stateless. Compile and render steps have to be separate so that the expensive parsing and compiling can be done once and later on you can just render it passing in a hash with local variables and objects. Why you should use Liquid You want to allow your users to edit the appearance of your application but don't want them to run insecure code on your server. You want to render templates directly from the database. You like smarty (PHP) style template engines. You need a template engine which does HTML just as well as emails. You don't like the markup of your current templating engine. What does it look like? How to use Liquid Install Liquid by adding gem 'liquid' to your gemfile. Liquid supports a very simple API based around the Liquid::Template class. For standard use you can just pass it the content of a file and call render with a parameters hash. Error Modes Setting the error mode of Liquid lets you specify how strictly you want your templates to be interpreted. Normally the parser is very lax and will accept almost anything without error. Unfortunately this can make it very hard to debug and can lead to unexpected behaviour. Liquid also comes with a stricter parser that can be used when editing templates to give better error messages when templates are invalid. You can enable this new parser like this: If you want to set the error mode only on specific templates you can pass :error_mode as an option to parse: This is useful for doing things like enabling strict mode only in the theme editor. It is recommended that you enable :strict or :warn mode on new apps to stop invalid templates from being created. It is also recommended that you use it in the template editors of existing apps to give editors better error messages. Undefined variables and filters By default, the renderer doesn't raise or in any other way notify you if some variables or filters are missing, i.e. not passed to the render method. You can improve this situation by passing strict_variables: true and/or strict_filters: true options to the render method. When one of these options is set to true, all errors about undefined variables and undefined filters will be stored in errors array of a Liquid::Template instance. Here are some examples: If you want to raise on a first exception instead of pushing all of them in errors, you can use render! method: Usage tracking To help track usages of a feature or code path in production, we have released opt-in usage tracking. To enable this, we provide an empty Liquid:: Usage.increment method which you can customize to your needs. The feature is well suited to https://github.com/Shopify/statsd-instrument. However, the choice of implementation is up to you. Once you have enabled usage tracking, we recommend reporting any events through Github Issues that your system may be logging. It is highly likely this event has been added to consider deprecating or improving code specific to this event, so please raise any concerns."
2510," Your Own URL Shortener Your Own URL Shortener YOURLS is a set of PHP scripts that will allow you to run Your Own URL Shortener, on your server. You'll have full control over your data, detailed stats, analytics, plugins, and more. It's free and open-source. Quick Start Get YOURLS : * Download the latest release * Using Composer? You can simply composer create-project yourls/yourls . in an empty directory. Install YOURLS: * Read yourls.org for starters * There are important additional information on the Wiki documentation. Community news, tips and tricks Read and subscribe to the The Official YOURLS Blog Check what the user community makes: plugins, tools, guides and more on Awesome YOURLS Engage users and ask for help in our community discussions Keep track of development: ""Star"" and ""Watch"" this project, follow commit messages Contributing Feature suggestion? Bug to report? Before opening any issue, please search for existing issues (open and closed) and read the Contributing Guidelines. Backers Do you use and enjoy YOURLS? Become a backer and show your support to our open source project. Sponsors Does your company use YOURLS? Ask your manager or marketing team if your company would be interested in supporting our project. Your company logo will show here. Help support our open-source development efforts by becoming a sponsor. License Free software. Do whatever the hell you want with it. YOURLS is released under the MIT license."
2962,"Production Quality Meteor Deployment to AnywhereMeteor Up Production Quality Meteor Deployments Meteor Up is a command line tool that allows you to deploy any Meteor app to your own server. You can install and use Meteor Up on Linux, Mac and Windows. It can deploy to servers running Ubuntu 14 or newer. This version of Meteor Up is powered by Docker, making deployment easy to manage and reducing server specific errors. Read the getting started tutorial. Features Single command server setup Single command deployment Deploy to multiple servers, with optional load balancing and sticky sessions Environment Variable management Support for settings.json Password or Private Key (pem) based server authentication Access logs from the terminal (supports log tailing) Support for custom docker images Support for Let's Encrypt and custom SSL certificates Roadmap Server Configuration Auto-restart if the app crashes Auto-start after server reboot Runs with docker for better security and isolation Reverts to the previous version if the deployment failed Installation Meteor Up requires Node v8 or newer. It runs on Windows, Mac, and Linux. mup should be installed on the computer you are deploying from. Using Mup Getting Started Docs Meteor compatibility Mup supports Meteor 1.2 and newer. To use Meteor 1.4 and newer, you will need to change the docker image. A list of docker images is available here. Support First, look at the troubleshooting and common problems sections of the docs. You can also search the github issues. If that doesn't solve the problem, you can: Create a Github issue Chat on Gitter Contributors This project exists thanks to all the people who contribute. Contribute. Backers Thank you to all our backers! [Become a backer] Sponsors Support this project by becoming a sponsor. Your logo will show up here with a link to your website. [Become a sponsor] "
2685,Enterprise Stream Process Engine Please refer to http://jstorm.io for all documents Getting help Google Groups: jstorm-user QQ:228374502
3213,"Minimalistic C client for Redis >= 1.2This Readme reflects the latest changed in the master branch. See v1.0.0 for the Readme and documentation for the latest release (API/ABI history). HIREDIS Hiredis is a minimalistic C client library for the Redis database. It is minimalistic because it just adds minimal support for the protocol, but at the same time it uses a high level printf-alike API in order to make it much higher level than otherwise suggested by its minimal code base and the lack of explicit bindings for every Redis command. Apart from supporting sending commands and receiving replies, it comes with a reply parser that is decoupled from the I/O layer. It is a stream parser designed for easy reusability, which can for instance be used in higher level language bindings for efficient reply parsing. Hiredis only supports the binary-safe Redis protocol, so you can use it with any Redis version >= 1.2.0. The library comes with multiple APIs. There is the synchronous API, the asynchronous API and the reply parsing API. Upgrading to 1.0.0 Version 1.0.0 marks the first stable release of Hiredis. It includes some minor breaking changes, mostly to make the exposed API more uniform and self-explanatory. It also bundles the updated sds library, to sync up with upstream and Redis. For code changes see the Changelog. Note: As described below, a few member names have been changed but most applications should be able to upgrade with minor code changes and recompiling. IMPORTANT: Breaking changes from 0.14.1 -> 1.0.0 redisContext has two additional members (free_privdata, and privctx). redisOptions.timeout has been renamed to redisOptions.connect_timeout, and we've added redisOptions.command_timeout. redisReplyObjectFunctions.createArray now takes size_t instead of int for its length parameter. IMPORTANT: Breaking changes when upgrading from 0.13.x -> 0.14.x Bulk and multi-bulk lengths less than -1 or greater than LLONG_MAX are now protocol errors. This is consistent with the RESP specification. On 32-bit platforms, the upper bound is lowered to SIZE_MAX. Change redisReply.len to size_t, as it denotes the the size of a string User code should compare this to size_t values as well. If it was used to compare to other values, casting might be necessary or can be removed, if casting was applied before. Upgrading from <0.9.0 Version 0.9.0 is a major overhaul of hiredis in every aspect. However, upgrading existing code using hiredis should not be a big pain. The key thing to keep in mind when upgrading is that hiredis >= 0.9.0 uses a redisContext* to keep state, in contrast to the stateless 0.0.1 that only has a file descriptor to work with. Synchronous API To consume the synchronous API, there are only a few function calls that need to be introduced: Connecting The function redisConnect is used to create a so-called redisContext. The context is where Hiredis holds state for a connection. The redisContext struct has an integer err field that is non-zero when the connection is in an error state. The field errstr will contain a string with a description of the error. More information on errors can be found in the Errors section. After trying to connect to Redis using redisConnect you should check the err field to see if establishing the connection was successful: Note: A redisContext is not thread-safe. Sending commands There are several ways to issue commands to Redis. The first that will be introduced is redisCommand. This function takes a format similar to printf. In the simplest form, it is used like this: The specifier %s interpolates a string in the command, and uses strlen to determine the length of the string: When you need to pass binary safe strings in a command, the %b specifier can be used. Together with a pointer to the string, it requires a size_t length argument of the string: Internally, Hiredis splits the command in different arguments and will convert it to the protocol used to communicate with Redis. One or more spaces separates arguments, so you can use the specifiers anywhere in an argument: Using replies The return value of redisCommand holds a reply when the command was successfully executed. When an error occurs, the return value is NULL and the err field in the context will be set (see section on Errors). Once an error is returned the context cannot be reused and you should set up a new connection. The standard replies that redisCommand are of the type redisReply. The type field in the redisReply should be used to test what kind of reply was received: RESP2 REDIS_REPLY_STATUS: The command replied with a status reply. The status string can be accessed using reply->str. The length of this string can be accessed using reply->len. REDIS_REPLY_ERROR: The command replied with an error. The error string can be accessed identical to REDIS_REPLY_STATUS. REDIS_REPLY_INTEGER: The command replied with an integer. The integer value can be accessed using the reply->integer field of type long long. REDIS_REPLY_NIL: The command replied with a nil object. There is no data to access. REDIS_REPLY_STRING: A bulk (string) reply. The value of the reply can be accessed using reply->str. The length of this string can be accessed using reply->len. REDIS_REPLY_ARRAY: A multi bulk reply. The number of elements in the multi bulk reply is stored in reply->elements. Every element in the multi bulk reply is a redisReply object as well and can be accessed via reply->element[..index..]. Redis may reply with nested arrays but this is fully supported. RESP3 Hiredis also supports every new RESP3 data type which are as follows. For more information about the protocol see the RESP3 specification. REDIS_REPLY_DOUBLE: The command replied with a double-precision floating point number. The value is stored as a string in the str member, and can be converted with strtod or similar. REDIS_REPLY_BOOL: A boolean true/false reply. The value is stored in the integer member and will be either 0 or 1. REDIS_REPLY_MAP: An array with the added invariant that there will always be an even number of elements. The MAP is functionally equivalent to REDIS_REPLY_ARRAY except for the previously mentioned invariant. REDIS_REPLY_SET: An array response where each entry is unique. Like the MAP type, the data is identical to an array response except there are no duplicate values. REDIS_REPLY_PUSH: An array that can be generated spontaneously by Redis. This array response will always contain at least two subelements. The first contains the type of PUSH message (e.g. message, or invalidate), and the second being a sub-array with the PUSH payload itself. REDIS_REPLY_ATTR: An array structurally identical to a MAP but intended as meta-data about a reply. As of Redis 6.0.6 this reply type is not used in Redis REDIS_REPLY_BIGNUM: A string representing an arbitrarily large signed or unsigned integer value. The number will be encoded as a string in the str member of redisReply. REDIS_REPLY_VERB: A verbatim string, intended to be presented to the user without modification. The string payload is stored in the str member, and type data is stored in the vtype member (e.g. txt for raw text or md for markdown). Replies should be freed using the freeReplyObject() function. Note that this function will take care of freeing sub-reply objects contained in arrays and nested arrays, so there is no need for the user to free the sub replies (it is actually harmful and will corrupt the memory). Important: the current version of hiredis (1.0.0) frees replies when the asynchronous API is used. This means you should not call freeReplyObject when you use this API. The reply is cleaned up by hiredis after the callback returns. We may introduce a flag to make this configurable in future versions of the library. Cleaning up To disconnect and free the context the following function can be used: This function immediately closes the socket and then frees the allocations done in creating the context. Sending commands (cont'd) Together with redisCommand, the function redisCommandArgv can be used to issue commands. It has the following prototype: It takes the number of arguments argc, an array of strings argv and the lengths of the arguments argvlen. For convenience, argvlen may be set to NULL and the function will use strlen(3) on every argument to determine its length. Obviously, when any of the arguments need to be binary safe, the entire array of lengths argvlen should be provided. The return value has the same semantic as redisCommand. Pipelining To explain how Hiredis supports pipelining in a blocking connection, there needs to be understanding of the internal execution flow. When any of the functions in the redisCommand family is called, Hiredis first formats the command according to the Redis protocol. The formatted command is then put in the output buffer of the context. This output buffer is dynamic, so it can hold any number of commands. After the command is put in the output buffer, redisGetReply is called. This function has the following two execution paths: The input buffer is non-empty: Try to parse a single reply from the input buffer and return it If no reply could be parsed, continue at 2 The input buffer is empty: Write the entire output buffer to the socket Read from the socket until a single reply could be parsed The function redisGetReply is exported as part of the Hiredis API and can be used when a reply is expected on the socket. To pipeline commands, the only things that needs to be done is filling up the output buffer. For this cause, two commands can be used that are identical to the redisCommand family, apart from not returning a reply: After calling either function one or more times, redisGetReply can be used to receive the subsequent replies. The return value for this function is either REDIS_OK or REDIS_ERR, where the latter means an error occurred while reading a reply. Just as with the other commands, the err field in the context can be used to find out what the cause of this error is. The following examples shows a simple pipeline (resulting in only a single call to write(2) and a single call to read(2)): This API can also be used to implement a blocking subscriber: Errors When a function call is not successful, depending on the function either NULL or REDIS_ERR is returned. The err field inside the context will be non-zero and set to one of the following constants: REDIS_ERR_IO: There was an I/O error while creating the connection, trying to write to the socket or read from the socket. If you included errno.h in your application, you can use the global errno variable to find out what is wrong. REDIS_ERR_EOF: The server closed the connection which resulted in an empty read. REDIS_ERR_PROTOCOL: There was an error while parsing the protocol. REDIS_ERR_OTHER: Any other error. Currently, it is only used when a specified hostname to connect to cannot be resolved. In every case, the errstr field in the context will be set to hold a string representation of the error. Asynchronous API Hiredis comes with an asynchronous API that works easily with any event library. Examples are bundled that show using Hiredis with libev and libevent. Connecting The function redisAsyncConnect can be used to establish a non-blocking connection to Redis. It returns a pointer to the newly created redisAsyncContext struct. The err field should be checked after creation to see if there were errors creating the connection. Because the connection that will be created is non-blocking, the kernel is not able to instantly return if the specified host and port is able to accept a connection. Note: A redisAsyncContext is not thread-safe. The asynchronous context can hold a disconnect callback function that is called when the connection is disconnected (either because of an error or per user request). This function should have the following prototype: On a disconnect, the status argument is set to REDIS_OK when disconnection was initiated by the user, or REDIS_ERR when the disconnection was caused by an error. When it is REDIS_ERR, the err field in the context can be accessed to find out the cause of the error. The context object is always freed after the disconnect callback fired. When a reconnect is needed, the disconnect callback is a good point to do so. Setting the disconnect callback can only be done once per context. For subsequent calls it will return REDIS_ERR. The function to set the disconnect callback has the following prototype: ac->data may be used to pass user data to this callback, the same can be done for redisConnectCallback. Sending commands and their callbacks In an asynchronous context, commands are automatically pipelined due to the nature of an event loop. Therefore, unlike the synchronous API, there is only a single way to send commands. Because commands are sent to Redis asynchronously, issuing a command requires a callback function that is called when the reply is received. Reply callbacks should have the following prototype: The privdata argument can be used to curry arbitrary data to the callback from the point where the command is initially queued for execution. The functions that can be used to issue commands in an asynchronous context are: Both functions work like their blocking counterparts. The return value is REDIS_OK when the command was successfully added to the output buffer and REDIS_ERR otherwise. Example: when the connection is being disconnected per user-request, no new commands may be added to the output buffer and REDIS_ERR is returned on calls to the redisAsyncCommand family. If the reply for a command with a NULL callback is read, it is immediately freed. When the callback for a command is non-NULL, the memory is freed immediately following the callback: the reply is only valid for the duration of the callback. All pending callbacks are called with a NULL reply when the context encountered an error. Disconnecting An asynchronous connection can be terminated using: When this function is called, the connection is not immediately terminated. Instead, new commands are no longer accepted and the connection is only terminated when all pending commands have been written to the socket, their respective replies have been read and their respective callbacks have been executed. After this, the disconnection callback is executed with the REDIS_OK status and the context object is freed. Hooking it up to event library X There are a few hooks that need to be set on the context object after it is created. See the adapters/ directory for bindings to libev and libevent. Reply parsing API Hiredis comes with a reply parsing API that makes it easy for writing higher level language bindings. The reply parsing API consists of the following functions: The same set of functions are used internally by hiredis when creating a normal Redis context, the above API just exposes it to the user for a direct usage. Usage The function redisReaderCreate creates a redisReader structure that holds a buffer with unparsed data and state for the protocol parser. Incoming data -- most likely from a socket -- can be placed in the internal buffer of the redisReader using redisReaderFeed. This function will make a copy of the buffer pointed to by buf for len bytes. This data is parsed when redisReaderGetReply is called. This function returns an integer status and a reply object (as described above) via void **reply. The returned status can be either REDIS_OK or REDIS_ERR, where the latter means something went wrong (either a protocol error, or an out of memory error). The parser limits the level of nesting for multi bulk payloads to 7. If the multi bulk nesting level is higher than this, the parser returns an error. Customizing replies The function redisReaderGetReply creates redisReply and makes the function argument reply point to the created redisReply variable. For instance, if the response of type REDIS_REPLY_STATUS then the str field of redisReply will hold the status as a vanilla C string. However, the functions that are responsible for creating instances of the redisReply can be customized by setting the fn field on the redisReader struct. This should be done immediately after creating the redisReader. For example, hiredis-rb uses customized reply object functions to create Ruby objects. Reader max buffer Both when using the Reader API directly or when using it indirectly via a normal Redis context, the redisReader structure uses a buffer in order to accumulate data from the server. Usually this buffer is destroyed when it is empty and is larger than 16 KiB in order to avoid wasting memory in unused buffers However when working with very big payloads destroying the buffer may slow down performances considerably, so it is possible to modify the max size of an idle buffer changing the value of the maxbuf field of the reader structure to the desired value. The special value of 0 means that there is no maximum value for an idle buffer, so the buffer will never get freed. For instance if you have a normal Redis context you can set the maximum idle buffer to zero (unlimited) just with: This should be done only in order to maximize performances when working with large payloads. The context should be set back to REDIS_READER_MAX_BUF again as soon as possible in order to prevent allocation of useless memory. Reader max array elements By default the hiredis reply parser sets the maximum number of multi-bulk elements to 2^32 - 1 or 4,294,967,295 entries. If you need to process multi-bulk replies with more than this many elements you can set the value higher or to zero, meaning unlimited with: SSL/TLS Support Building SSL/TLS support is not built by default and requires an explicit flag: make USE_SSL=1 This requires OpenSSL development package (e.g. including header files to be available. When enabled, SSL/TLS support is built into extra libhiredis_ssl.a and libhiredis_ssl.so static/dynamic libraries. This leaves the original libraries unaffected so no additional dependencies are introduced. Using it First, you'll need to make sure you include the SSL header file: You will also need to link against libhiredis_ssl, in addition to libhiredis and add -lssl -lcrypto to satisfy its dependencies. Hiredis implements SSL/TLS on top of its normal redisContext or redisAsyncContext, so you will need to establish a connection first and then initiate an SSL/TLS handshake. Hiredis OpenSSL Wrappers Before Hiredis can negotiate an SSL/TLS connection, it is necessary to initialize OpenSSL and create a context. You can do that in two ways: Work directly with the OpenSSL API to initialize the library's global context and create SSL_CTX * and SSL * contexts. With an SSL * object you can call redisInitiateSSL(). Work with a set of Hiredis-provided wrappers around OpenSSL, create a redisSSLContext object to hold configuration and use redisInitiateSSLWithContext() to initiate the SSL/TLS handshake. RESP3 PUSH replies Redis 6.0 introduced PUSH replies with the reply-type >. These messages are generated spontaneously and can arrive at any time, so must be handled using callbacks. Default behavior Hiredis installs handlers on redisContext and redisAsyncContext by default, which will intercept and free any PUSH replies detected. This means existing code will work as-is after upgrading to Redis 6 and switching to RESP3. Custom PUSH handler prototypes The callback prototypes differ between redisContext and redisAsyncContext. redisContext redisAsyncContext Installing a custom handler There are two ways to set your own PUSH handlers. Set push_cb or async_push_cb in the redisOptions struct and connect with redisConnectWithOptions or redisAsyncConnectWithOptions. Call redisSetPushCallback or redisAsyncSetPushCallback on a connected context. Note redisSetPushCallback and redisAsyncSetPushCallback both return any currently configured handler, making it easy to override and then return to the old value. Specifying no handler If you have a unique use-case where you don't want hiredis to automatically intercept and free PUSH replies, you will want to configure no handler at all. This can be done in two ways. 1. Set the REDIS_OPT_NO_PUSH_AUTOFREE flag in redisOptions and leave the callback function pointer NULL. Call redisSetPushCallback with NULL once connected. Note: With no handler configured, calls to redisCommand may generate more than one reply, so this strategy is only applicable when there's some kind of blockingredisGetReply() loop (e.g. MONITOR or SUBSCRIBE workloads). Allocator injection Hiredis uses a pass-thru structure of function pointers defined in alloc.h that contain the currently configured allocation and deallocation functions. By default they just point to libc (malloc, calloc, realloc, etc). Overriding One can override the allocators like so: To reset the allocators to their default libc function simply call: AUTHORS Salvatore Sanfilippo (antirez at gmail),\ Pieter Noordhuis (pcnoordhuis at gmail)\ Michael Grunder (michael dot grunder at gmail) Hiredis is released under the BSD license."
2380,"Fuzzy String Matching in Python.. image:: https://travis-ci.org/seatgeek/fuzzywuzzy.svg?branch=master :target: https://travis-ci.org/seatgeek/fuzzywuzzy FuzzyWuzzy Fuzzy string matching like a boss. It uses Levenshtein Distance <https://en.wikipedia.org/wiki/Levenshtein_distance>_ to calculate the differences between sequences in a simple-to-use package. Requirements Python 2.7 or higher difflib python-Levenshtein <https://github.com/ztane/python-Levenshtein/> (optional, provides a 4-10x speedup in String Matching, though may result in differing results for certain cases <https://github.com/seatgeek/fuzzywuzzy/issues/128>) For testing ~~~~~~~~~~~ - pycodestyle - hypothesis - pytest Installation Using PIP via PyPI .. code:: bash pip install fuzzywuzzy or the following to install python-Levenshtein too .. code:: bash pip install fuzzywuzzy[speedup] Using PIP via Github .. code:: bash pip install git+git://github.com/seatgeek/fuzzywuzzy.git@0.18.0#egg=fuzzywuzzy Adding to your requirements.txt file (run pip install -r requirements.txt afterwards) .. code:: bash git+ssh://git@github.com/seatgeek/fuzzywuzzy.git@0.18.0#egg=fuzzywuzzy Manually via GIT .. code:: bash git clone git://github.com/seatgeek/fuzzywuzzy.git fuzzywuzzy cd fuzzywuzzy python setup.py install Usage .. code:: python >>> from fuzzywuzzy import fuzz >>> from fuzzywuzzy import process Simple Ratio ~~~~~~~~~~~~ .. code:: python >>> fuzz.ratio(""this is a test"", ""this is a test!"") 97 Partial Ratio ~~~~~~~~~~~~~ .. code:: python >>> fuzz.partial_ratio(""this is a test"", ""this is a test!"") 100 Token Sort Ratio ~~~~~~~~~~~~~~~~ .. code:: python >>> fuzz.ratio(""fuzzy wuzzy was a bear"", ""wuzzy fuzzy was a bear"") 91 >>> fuzz.token_sort_ratio(""fuzzy wuzzy was a bear"", ""wuzzy fuzzy was a bear"") 100 Token Set Ratio ~~~~~~~~~~~~~~~ .. code:: python >>> fuzz.token_sort_ratio(""fuzzy was a bear"", ""fuzzy fuzzy was a bear"") 84 >>> fuzz.token_set_ratio(""fuzzy was a bear"", ""fuzzy fuzzy was a bear"") 100 Process ~~~~~~~ .. code:: python >>> choices = [""Atlanta Falcons"", ""New York Jets"", ""New York Giants"", ""Dallas Cowboys""] >>> process.extract(""new york jets"", choices, limit=2) [('New York Jets', 100), ('New York Giants', 78)] >>> process.extractOne(""cowboys"", choices) (""Dallas Cowboys"", 90) You can also pass additional parameters to extractOne method to make it use a specific scorer. A typical use case is to match file paths: .. code:: python >>> process.extractOne(""System of a down - Hypnotize - Heroin"", songs) ('/music/library/good/System of a Down/2005 - Hypnotize/01 - Attack.mp3', 86) >>> process.extractOne(""System of a down - Hypnotize - Heroin"", songs, scorer=fuzz.token_sort_ratio) (""/music/library/good/System of a Down/2005 - Hypnotize/10 - She's Like Heroin.mp3"", 61) .. |Build Status| image:: https://api.travis-ci.org/seatgeek/fuzzywuzzy.png?branch=master :target: https:travis-ci.org/seatgeek/fuzzywuzzy Known Ports FuzzyWuzzy is being ported to other languages too! Here are a few ports we know about: Java: xpresso's fuzzywuzzy implementation <https://github.com/WantedTechnologies/xpresso/wiki/Approximate-string-comparison-and-pattern-matching-in-Java>_ Java: fuzzywuzzy (java port) <https://github.com/xdrop/fuzzywuzzy>_ Rust: fuzzywuzzy-rs (Rust port) <https://github.com/logannc/fuzzywuzzy-rs>_ JavaScript: fuzzball.js (JavaScript port) <https://github.com/nol13/fuzzball.js>_ C++: Tmplt/fuzzywuzzy <https://github.com/Tmplt/fuzzywuzzy>_ C#: fuzzysharp (.Net port) <https://github.com/BoomTownRoi/BoomTown.FuzzySharp>_ Go: go-fuzzywuzz (Go port) <https://github.com/paul-mannino/go-fuzzywuzzy>_ Free Pascal: FuzzyWuzzy.pas (Free Pascal port) <https://github.com/DavidMoraisFerreira/FuzzyWuzzy.pas>_ Kotlin multiplatform: FuzzyWuzzy-Kotlin <https://github.com/willowtreeapps/fuzzywuzzy-kotlin>_ R: fuzzywuzzyR (R port) <https://github.com/mlampros/fuzzywuzzyR>_"
1833,"Objective-c code Apple style documentation set generator.About appledoc IMPORTANT NOTICE: collaborators needed appledoc is command line tool that helps Objective-C developers generate Apple-like source code documentation from specially formatted source code comments. It's designed to take as readable source code comments as possible for the input and use comments as well as surrounding source code to generate visually appealing documentation in the form of HTML as well as fully indexed and browsable Xcode documentation set. Although there are several tools that can create HTML documentation for Objective-C, all of those known to me fall short in meeting the minimum of goals described below. Main goals of appledoc: Human-readable source code comments. Simple cross references to objects and members. Generate Apple-like source code HTML documentation. Generate and install fully indexed and browsable Xcode documentation set. Single tool to drive generation from source code parsing to documentation set installation. Easily customizable output. 100% Objective-C implementation for easy debugging. To make your experience with appledoc as smooth as possible, we warmly suggest reading this whole document as well as all online documentation mentioned in ""using appledoc"" section below! Usage of appledoc is allowed under the terms listed in LICENSE section at the bottom of this file! Want to keep updated? Follow us on Twitter - @gentlebytes. Quick install The recommended way is to clone GitHub project and compile the tool from Xcode. As cloning GitHub project will create the link to the main repository, it greatly simplifies future upgrading too. To install, type the following in the Terminal: git clone git://github.com/tomaz/appledoc.git This creates appledoc directory. Within you can find appledoc.xcworkspace Xcode workspace; open it and compile appledoc target - this should work out of the box, however your system must meet minimum system requirements, see below. I recommend you copy resulting appledoc executable from build directory to one of the directories in your path (echo $PATH) to make it easily accessible. Optional: Appledoc is selfcontained and contains the necessary template files. IF you want to modify these default from Templates subdirectory to one of the expected locations: ~/Library/Application Support/appledoc ~/.appledoc You can also use install-appledoc.sh script to perform quick installation. Open Terminal and switch to appledoc directory. Type following command: sudo sh install-appledoc.sh (if you need templates add '-t default') It compiles appledoc and installs its binary to /usr/local/bin and templates (if wanted) to ~/.appledoc by default. You can override this directories with -b and -t options respectively. For example: sudo sh install-appledoc.sh -b /usr/bin -t ~/Library/Application\ Support/appledoc Alternatively with Homebrew: brew install appledoc Homebrew does not install templates by default. Using appledoc Use appledoc --help to see the list of all command line switches. Read more about appledoc on appledoc site. Also read wiki pages for some more in-depth articles. Use appledoc Google group as a forum for questions on usage or other general questions. Use appledoc issues page to submit bug and feature requests. Before submitting new issues, check the forums to see if your question is answered there - unless you can confirm your issue as a new feature request or a bug, you should start at the forum to keep GitHub issues clean. Also read through issues to see if the issue is already there and vote on it or add a comment (don't forget about closed issues). Installation tips To keep up to date, just go to Terminal and cd into appledoc directory, issue git pull and recompile appledoc.xcodeproj. Don't forget to overwrite appledoc executable you've copied to $PATH :) If you also want to compile and run AppledocTests (unit tests) target, you need to copy all the frameworks indicated within Libraries & Frameworks group to shared frameworks directory before building unit tests target! This is not required for building the appledoc tool itself. Integrating with Xcode You can setup Xcode to automate appledoc document creation. Find out how using a Run Script and your project's Build Phases. Docset usage tips Pre-generated documentation and docsets for most Cocoa frameworks are available at: - CocoaDocs Once you have a docset, you might want to use it with a documentation browser: - Xcode - Dash Troubleshooting Have problems? This is what you can do to troubleshoot: Make sure you have the latest appledoc version. Try git pull and run with latest version again. IF you have template files installed, make sure you're using the latest - delete the predefined folders and have appledoc copy the files from its embedded archive again (see Quick Install section above). Increase verbosity level with --verbose command line switch. Default level is 2, but you can progressively increment verbosity up to 6 with each level giving you more detailed information. As this will give you a lot more information, you may want to concentrate only on specific set of source files you have problem with. Note that increasing verbosity will result in slower performance so using levels above 4 for every day use is not recommended. Appledoc is open source project! You have all the source code available, so run it from Xcode. You can setup Xcode to pass the desired command line arguments and add breakpoints to help you isolate your issue. If you feel you'd like to contribute more to community, you are welcome to fork the project on GitHub and add features to it. Keep us posted so we can add these features to main repository as well - include unit tests if possible. If you think you found a bug or want to request new feature, go to appledoc issues page. First read existing issues to see if there is already a request there (if you're using master branch, also read closed issues as your request may have already been covered but isn't yet merged on master branch). You can vote on existing requests to help us decide which features to concentrate on or you can add a comment to aid in solving it. If you don't find the request there, create a new issue; include parts of source files that give you problems if possible and/or description or steps that lead to it. If you're having problems with some of your source files and don't want to publish them online, you can contact us through email below. We'll do our best to help you out, but bear in mind appledoc is not commercial product; it's created and maintained in our spare time, so resources are limited. Developer notes If you wish to contribute, see the Developer Notes file for short overview of how appledoc works internally. Minimum system requirements Xcode 4.5 or greater for compiling OS X 10.7 for compiling and running License appledoc is licensed with modified BSD license. In plain language: you're allowed to do whatever you wish with the code, modify, redistribute, embed in your products (free or commercial), but you must include copyright, terms of usage and disclaimer as stated in the license, the same way as any other BSD licensed code. You can of course use documentation generated by appledoc for your products (free or commercial), but you must attribute appledoc either in documentation itself or other appropriate place such as your website. If for whatever reason you cannot agree to these terms, contact us through contact form on our about page, we'll do our best to help you out you out and find a workable solution! Copyright (c) 2009-2011, Gentle Bytes All rights reserved. Redistribution and use in source, binary forms and generated documentation, with or without modification, are permitted provided that the following conditions are met: Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer. Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution. Redistributions of documentation generated by appledoc must include attribution to appledoc, either in documentation itself or other appropriate media. Neither the name of the appledoc, Gentle Bytes nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission. THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS"" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE. Gentle Bytes appledoc@gentlebytes.com"
3008,"get colors in your node.js consolecolors.js Please check out the roadmap for upcoming features and releases. Please open Issues to provide feedback, and check the develop branch for the latest bleeding-edge updates. get color and style in your node.js console Installation npm install colors colors and styles! text colors black red green yellow blue magenta cyan white gray grey bright text colors brightRed brightGreen brightYellow brightBlue brightMagenta brightCyan brightWhite background colors bgBlack bgRed bgGreen bgYellow bgBlue bgMagenta bgCyan bgWhite bgGray bgGrey bright background colors bgBrightRed bgBrightGreen bgBrightYellow bgBrightBlue bgBrightMagenta bgBrightCyan bgBrightWhite styles reset bold dim italic underline inverse hidden strikethrough extras rainbow zebra america trap random Usage By popular demand, colors now ships with two types of usages! The super nifty way or a slightly less nifty way which doesn't extend String.prototype I prefer the first way. Some people seem to be afraid of extending String.prototype and prefer the second way. If you are writing good code you will never have an issue with the first approach. If you really don't want to touch String.prototype, the second usage will not touch String native object. Enabling/Disabling Colors The package will auto-detect whether your terminal can use colors and enable/disable accordingly. When colors are disabled, the color functions do nothing. You can override this with a command-line flag: Or in code: Console.log string substitution Custom themes Using standard API Using string safe API Combining Colors Protip: There is a secret undocumented style in colors. If you find the style you can summon him."
1351,"Real-time metrics for nginx server================================================================ ngxtop - real-time metrics for nginx server (and others) ================================================================ ngxtop parses your nginx access log and outputs useful, top-like, metrics of your nginx server. So you can tell what is happening with your server in real-time. ``ngxtop`` is designed to run in a short-period time just like the ``top`` command for troubleshooting and monitoring your Nginx server at the moment. If you need a long running monitoring process or storing your webserver stats in external monitoring / graphing system, you can try `Luameter <https://luameter.com>`_. ngxtop tries to determine the correct location and format of nginx access log file by default, so you can just run ngxtop and having a close look at all requests coming to your nginx server. But it does not limit you to nginx and the default top view. ngxtop is flexible enough for you to configure and change most of its behaviours. You can query for different things, specify your log and format, even parse remote Apache common access log with ease. See sample usages below for some ideas about what you can do with it. Installation :: pip install ngxtop Note: ngxtop is primarily developed and tested with python2 but also supports python3. Usage :: Usage: ngxtop [options] ngxtop [options] (print|top|avg|sum) <var> ngxtop info Options: -l <file>, --access-log <file> access log file to parse. -f <format>, --log-format <format> log format as specify in log_format directive. --no-follow ngxtop default behavior is to ignore current lines in log and only watch for new lines as they are written to the access log. Use this flag to tell ngxtop to process the current content of the access log instead. -t <seconds>, --interval <seconds> report interval when running in follow mode [default: 2.0] -g <var>, --group-by <var> group by variable [default: request_path] -w <var>, --having <expr> having clause [default: 1] -o <var>, --order-by <var> order of output for default query [default: count] -n <number>, --limit <number> limit the number of records included in report for top command [default: 10] -a <exp> ..., --a <exp> ... add exp (must be aggregation exp: sum, avg, min, max, etc.) into output -v, --verbose more verbose output -d, --debug print every line and parsed record -h, --help print this help message. --version print version information. Advanced / experimental options: -c <file>, --config <file> allow ngxtop to parse nginx config file for log format and location. -i <filter-expression>, --filter <filter-expression> filter in, records satisfied given expression are processed. -p <filter-expression>, --pre-filter <filter-expression> in-filter expression to check in pre-parsing phase. Samples Default output ~~~~~~~~~~~~~~ :: $ ngxtop running for 411 seconds, 64332 records processed: 156.60 req/sec Summary: | count | avg_bytes_sent | 2xx | 3xx | 4xx | 5xx | |---------+------------------+-------+-------+-------+-------| | 64332 | 2775.251 | 61262 | 2994 | 71 | 5 | Detailed: | request_path | count | avg_bytes_sent | 2xx | 3xx | 4xx | 5xx | |------------------------------------------+---------+------------------+-------+-------+-------+-------| | /abc/xyz/xxxx | 20946 | 434.693 | 20935 | 0 | 11 | 0 | | /xxxxx.json | 5633 | 1483.723 | 5633 | 0 | 0 | 0 | | /xxxxx/xxx/xxxxxxxxxxxxx | 3629 | 6835.499 | 3626 | 0 | 3 | 0 | | /xxxxx/xxx/xxxxxxxx | 3627 | 15971.885 | 3623 | 0 | 4 | 0 | | /xxxxx/xxx/xxxxxxx | 3624 | 7830.236 | 3621 | 0 | 3 | 0 | | /static/js/minified/utils.min.js | 3031 | 1781.155 | 2104 | 927 | 0 | 0 | | /static/js/minified/xxxxxxx.min.v1.js | 2889 | 2210.235 | 2068 | 821 | 0 | 0 | | /static/tracking/js/xxxxxxxx.js | 2594 | 1325.681 | 1927 | 667 | 0 | 0 | | /xxxxx/xxx.html | 2521 | 573.597 | 2520 | 0 | 1 | 0 | | /xxxxx/xxxx.json | 1840 | 800.542 | 1839 | 0 | 1 | 0 | View top source IPs of clients ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ :: $ ngxtop top remote_addr running for 20 seconds, 3215 records processed: 159.62 req/sec top remote_addr | remote_addr | count | |-----------------+---------| | 118.173.177.161 | 20 | | 110.78.145.3 | 16 | | 171.7.153.7 | 16 | | 180.183.67.155 | 16 | | 183.89.65.9 | 16 | | 202.28.182.5 | 16 | | 1.47.170.12 | 15 | | 119.46.184.2 | 15 | | 125.26.135.219 | 15 | | 125.26.213.203 | 15 | List 4xx or 5xx responses together with HTTP referer ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ :: $ ngxtop -i 'status >= 400' print request status http_referer running for 2 seconds, 28 records processed: 13.95 req/sec request, status, http_referer: | request | status | http_referer | |-----------+----------+----------------| | - | 400 | - | Parse apache log from remote server with common format ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ :: $ ssh user@remote_server tail -f /var/log/apache2/access.log | ngxtop -f common running for 20 seconds, 1068 records processed: 53.01 req/sec Summary: | count | avg_bytes_sent | 2xx | 3xx | 4xx | 5xx | |---------+------------------+-------+-------+-------+-------| | 1068 | 28026.763 | 1029 | 20 | 19 | 0 | Detailed: | request_path | count | avg_bytes_sent | 2xx | 3xx | 4xx | 5xx | |------------------------------------------+---------+------------------+-------+-------+-------+-------| | /xxxxxxxxxx | 199 | 55150.402 | 199 | 0 | 0 | 0 | | /xxxxxxxx/xxxxx | 167 | 47591.826 | 167 | 0 | 0 | 0 | | /xxxxxxxxxxxxx/xxxxxx | 25 | 7432.200 | 25 | 0 | 0 | 0 | | /xxxx/xxxxx/x/xxxxxxxxxxxxx/xxxxxxx | 22 | 698.727 | 22 | 0 | 0 | 0 | | /xxxx/xxxxx/x/xxxxxxxxxxxxx/xxxxxx | 19 | 7431.632 | 19 | 0 | 0 | 0 | | /xxxxx/xxxxx/ | 18 | 7840.889 | 18 | 0 | 0 | 0 | | /xxxxxxxx/xxxxxxxxxxxxxxxxx | 15 | 7356.000 | 15 | 0 | 0 | 0 | | /xxxxxxxxxxx/xxxxxxxx | 15 | 9978.800 | 15 | 0 | 0 | 0 | | /xxxxx/ | 14 | 0.000 | 0 | 14 | 0 | 0 | | /xxxxxxxxxx/xxxxxxxx/xxxxx | 13 | 20530.154 | 13 | 0 | 0 | 0 |"
805,"The Clojure programming languageClojure Copyright (c) Rich Hickey. All rights reserved. The use and distribution terms for this software are covered by the Eclipse Public License 1.0 (http://opensource.org/licenses/eclipse-1.0.php) which can be found in the file epl-v10.html at the root of this distribution. By using this software in any fashion, you are agreeing to be bound by the terms of this license. You must not remove this notice, or any other, from this software. Docs: https://clojure.org Feedback: http://groups.google.com/group/clojure Getting Started: https://clojure.org/guides/getting_started To build and run locally with Ant: One-time setup: ./antsetup.sh To build: ant local To run: java -jar clojure.jar To build locally with Maven: To build (output JARs in target/): mvn package To build without testing: mvn package -Dmaven.test.skip=true To build and install in local Maven repository: mvn install To build a standalone jar with dependencies included: mvn -Plocal -Dmaven.test.skip=true package To run with the standalone jar: java -jar clojure.jar This program uses the ASM bytecode engineering library which is distributed with the following notice: ASM: a very small and fast Java bytecode manipulation framework Copyright (c) 2000-2011 INRIA, France Telecom All rights reserved. Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met: 1. Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer. 2. Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution. 3. Neither the name of the copyright holders nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission. THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS"" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE. This program uses the Guava Murmur3 hash implementation which is distributed under the Apache License: Apache License Version 2.0, January 2004 http://www.apache.org/licenses/ TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION Definitions. ""License"" shall mean the terms and conditions for use, reproduction, and distribution as defined by Sections 1 through 9 of this document. ""Licensor"" shall mean the copyright owner or entity authorized by the copyright owner that is granting the License. ""Legal Entity"" shall mean the union of the acting entity and all other entities that control, are controlled by, or are under common control with that entity. For the purposes of this definition, ""control"" means (i) the power, direct or indirect, to cause the direction or management of such entity, whether by contract or otherwise, or (ii) ownership of fifty percent (50%) or more of the outstanding shares, or (iii) beneficial ownership of such entity. ""You"" (or ""Your"") shall mean an individual or Legal Entity exercising permissions granted by this License. ""Source"" form shall mean the preferred form for making modifications, including but not limited to software source code, documentation source, and configuration files. ""Object"" form shall mean any form resulting from mechanical transformation or translation of a Source form, including but not limited to compiled object code, generated documentation, and conversions to other media types. ""Work"" shall mean the work of authorship, whether in Source or Object form, made available under the License, as indicated by a copyright notice that is included in or attached to the work (an example is provided in the Appendix below). ""Derivative Works"" shall mean any work, whether in Source or Object form, that is based on (or derived from) the Work and for which the editorial revisions, annotations, elaborations, or other modifications represent, as a whole, an original work of authorship. For the purposes of this License, Derivative Works shall not include works that remain separable from, or merely link (or bind by name) to the interfaces of, the Work and Derivative Works thereof. ""Contribution"" shall mean any work of authorship, including the original version of the Work and any modifications or additions to that Work or Derivative Works thereof, that is intentionally submitted to Licensor for inclusion in the Work by the copyright owner or by an individual or Legal Entity authorized to submit on behalf of the copyright owner. For the purposes of this definition, ""submitted"" means any form of electronic, verbal, or written communication sent to the Licensor or its representatives, including but not limited to communication on electronic mailing lists, source code control systems, and issue tracking systems that are managed by, or on behalf of, the Licensor for the purpose of discussing and improving the Work, but excluding communication that is conspicuously marked or otherwise designated in writing by the copyright owner as ""Not a Contribution."" ""Contributor"" shall mean Licensor and any individual or Legal Entity on behalf of whom a Contribution has been received by Licensor and subsequently incorporated within the Work. Grant of Copyright License. Subject to the terms and conditions of this License, each Contributor hereby grants to You a perpetual, worldwide, non-exclusive, no-charge, royalty-free, irrevocable copyright license to reproduce, prepare Derivative Works of, publicly display, publicly perform, sublicense, and distribute the Work and such Derivative Works in Source or Object form. Grant of Patent License. Subject to the terms and conditions of this License, each Contributor hereby grants to You a perpetual, worldwide, non-exclusive, no-charge, royalty-free, irrevocable (except as stated in this section) patent license to make, have made, use, offer to sell, sell, import, and otherwise transfer the Work, where such license applies only to those patent claims licensable by such Contributor that are necessarily infringed by their Contribution(s) alone or by combination of their Contribution(s) with the Work to which such Contribution(s) was submitted. If You institute patent litigation against any entity (including a cross-claim or counterclaim in a lawsuit) alleging that the Work or a Contribution incorporated within the Work constitutes direct or contributory patent infringement, then any patent licenses granted to You under this License for that Work shall terminate as of the date such litigation is filed. Redistribution. You may reproduce and distribute copies of the Work or Derivative Works thereof in any medium, with or without modifications, and in Source or Object form, provided that You meet the following conditions: (a) You must give any other recipients of the Work or Derivative Works a copy of this License; and (b) You must cause any modified files to carry prominent notices stating that You changed the files; and (c) You must retain, in the Source form of any Derivative Works that You distribute, all copyright, patent, trademark, and attribution notices from the Source form of the Work, excluding those notices that do not pertain to any part of the Derivative Works; and (d) If the Work includes a ""NOTICE"" text file as part of its distribution, then any Derivative Works that You distribute must include a readable copy of the attribution notices contained within such NOTICE file, excluding those notices that do not pertain to any part of the Derivative Works, in at least one of the following places: within a NOTICE text file distributed as part of the Derivative Works; within the Source form or documentation, if provided along with the Derivative Works; or, within a display generated by the Derivative Works, if and wherever such third-party notices normally appear. The contents of the NOTICE file are for informational purposes only and do not modify the License. You may add Your own attribution notices within Derivative Works that You distribute, alongside or as an addendum to the NOTICE text from the Work, provided that such additional attribution notices cannot be construed as modifying the License. You may add Your own copyright statement to Your modifications and may provide additional or different license terms and conditions for use, reproduction, or distribution of Your modifications, or for any such Derivative Works as a whole, provided Your use, reproduction, and distribution of the Work otherwise complies with the conditions stated in this License. Submission of Contributions. Unless You explicitly state otherwise, any Contribution intentionally submitted for inclusion in the Work by You to the Licensor shall be under the terms and conditions of this License, without any additional terms or conditions. Notwithstanding the above, nothing herein shall supersede or modify the terms of any separate license agreement you may have executed with Licensor regarding such Contributions. Trademarks. This License does not grant permission to use the trade names, trademarks, service marks, or product names of the Licensor, except as required for reasonable and customary use in describing the origin of the Work and reproducing the content of the NOTICE file. Disclaimer of Warranty. Unless required by applicable law or agreed to in writing, Licensor provides the Work (and each Contributor provides its Contributions) on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied, including, without limitation, any warranties or conditions of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A PARTICULAR PURPOSE. You are solely responsible for determining the appropriateness of using or redistributing the Work and assume any risks associated with Your exercise of permissions under this License. Limitation of Liability. In no event and under no legal theory, whether in tort (including negligence), contract, or otherwise, unless required by applicable law (such as deliberate and grossly negligent acts) or agreed to in writing, shall any Contributor be liable to You for damages, including any direct, indirect, special, incidental, or consequential damages of any character arising as a result of this License or out of the use or inability to use the Work (including but not limited to damages for loss of goodwill, work stoppage, computer failure or malfunction, or any and all other commercial damages or losses), even if such Contributor has been advised of the possibility of such damages. Accepting Warranty or Additional Liability. While redistributing the Work or Derivative Works thereof, You may choose to offer, and charge a fee for, acceptance of support, warranty, indemnity, or other liability obligations and/or rights consistent with this License. However, in accepting such obligations, You may act only on Your own behalf and on Your sole responsibility, not on behalf of any other Contributor, and only if You agree to indemnify, defend, and hold each Contributor harmless for any liability incurred by, or claims asserted against, such Contributor by reason of your accepting any such warranty or additional liability. END OF TERMS AND CONDITIONS"
4001,"Distributing instrumentation tests to all your Androids.Spoon Distributing instrumentation tests to all your Androids. Introduction Android's ever-expanding ecosystem of devices creates a unique challenge to testing applications. Spoon aims to simplify this task by distributing instrumentation test execution and displaying the results in a meaningful way. Instead of attempting to be a new form of testing, Spoon makes existing instrumentation tests more useful. Using the application APK and instrumentation APK, Spoon runs the tests on multiple devices simultaneously. Once all tests have completed a static HTML summary is generated with detailed information about each device and test. Spoon will run on all targets which are visible to adb devices. Plug in multiple different phones and tablets, start different configurations of emulators, or use some combination of both! The greater diversity of the targets in use, the more useful the output will be in visualizing your applications. Screenshots In addition to simply running instrumentation tests, Spoon has the ability to snap screenshots at key points during your tests which are then included in the output. This allows for visual inspection of test executions across different devices. Taking screenshots requires that you include the spoon-client JAR in your instrumentation app. For Spoon to save screenshots your app must have the WRITE_EXTERNAL_STORAGE permission. In your tests call the screenshot method with a human-readable tag. The tag specified will be used to identify and compare screenshots taken across multiple test runs. You can also view each test's screenshots as an animated GIF to gauge the actual sequence of interaction. Files If you have files that will help you in debugging or auditing a test run, for example a log file or a SQLite database you can save these files easily and have them attached to your test report. This will let you easily drill down any issues that occurred in your test run. Attaching files to your report requires that you include the spoon-client jar and that you have WRITE_EXTERNAL_STORAGE permission. You download the files by clicking on the filename in the device report. Download Download the latest runner JAR or the latest client JAR, or just add to your dependencies: Maven: Snapshots of the development version are available in Sonatype's snapshots repository. Gradle: There are two Gradle plugins maintained by the community which provide integration with the Android Gradle plugin (AGP): https://github.com/stanfy/spoon-gradle-plugin (for AGP 2.x) https://github.com/jaredsburrows/gradle-spoon-plugin (for AGP 3.x) Execution Spoon was designed to be run both as a standalone tool or directly as part of your build system. You can run Spoon as a standalone tool with your application and instrumentation APKs. By default the output will be placed in a spoon-output/ folder of the current directory. You can control additional parameters of the execution using other flags. If you are using Maven for compilation, a plugin is provided for easy execution. Declare the plugin in the pom.xml for the instrumentation test module. The plugin will look for an apk dependency for the corresponding application. Typically this is specified in parallel with the jar dependency on the application. You can invoke the plugin by running mvn spoon:run. The execution result will be placed in the target/spoon-output/ folder. If you want to specify a test class to run, add -Dspoon.test.class=fully.qualified.ClassName. If you only want to run a single test in that class, add -Dspoon.test.method=testAllTheThings. For a working example see the sample application and instrumentation tests in the spoon-sample/ folder. Test Sharding The Android Instrumentation runner supports test sharding using the numShards and shardIndex arguments (documentation). If you are specifying serials for multiple devices, you may use spoon's built in auto-sharding by specifying --shard: This will automatically shard across all specified serials, and merge the results. When this option is running with --coverage flag. It will merge all the coverage files generated from all devices into a single file called merged-coverage.ec. If you'd like to use a different sharding strategy, you can use the --e option with Spoon to pass those arguments through to the instrumentation runner, e.g. However, it will be up to you to merge the output from the shards. If you use Jenkins, a good way to set up sharding is inside a ""Multi-configuration project"". Add a ""User-defined Axis"". Choose a name for the shard index variable, and define the index values you want (starting at zero). In your ""Execute shell"" step, use the same execution command as above, but inject the shard index for each slave node using the variable you defined above, e.g. --e shardIndex=${shard_index}. Make sure you're passing in the correct total number of shards too, e.g. --e numShards=4. Running Specific Tests There are numerous ways to run a specific test, or set of tests. You can use the Spoon --size, --class-name or --method-name options, or you can use the --e option to pass arguments to the instrumentation runner, e.g. See the documentation for your instrumentation runner to find the full list of supported options (e.g. AndroidJUnitRunner). License Copyright 2013 Square, Inc. Licensed under the Apache License, Version 2.0 (the ""License""); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
3351,"Hibernate's core Object/Relational Mapping functionality Hibernate ORM is a library providing Object/Relational Mapping (ORM) support to applications, libraries, and frameworks. It also provides an implementation of the JPA specification, which is the standard Java specification for ORM. This is the repository of its source code: see Hibernate.org for additional information. Building from sources The build requires a Java 8 JDK as JAVA_HOME. You will need Git to obtain the source. Hibernate uses Gradle as its build tool. See the Gradle Primer section below if you are new to Gradle. Contributors should read the Contributing Guide. See the guides for setting up IntelliJ or Eclipse as your development environment. Check out the Getting Started section in CONTRIBUTING.md for getting started working on Hibernate source. Continuous Integration Hibernate makes use of Jenkins for its CI needs. The project is built continuous on each push to the upstream repository. Overall there are a few different jobs, all of which can be seen at http://ci.hibernate.org/view/ORM/ Gradle primer This section describes some of the basics developers and contributors new to Gradle might need to know to get productive quickly. The Gradle documentation is very well done; 2 in particular that are indispensable: Gradle User Guide is a typical user guide in that it follows a topical approach to describing all of the capabilities of Gradle. Gradle DSL Guide is unique and excellent in quickly getting up to speed on certain aspects of Gradle. Using the Gradle Wrapper For contributors who do not otherwise use Gradle and do not want to install it, Gradle offers a very cool feature called the wrapper. It lets you run Gradle builds without a previously installed Gradle distro in a zero-conf manner. Hibernate configures the Gradle wrapper for you. If you would rather use the wrapper and not install Gradle (or to make sure you use the version of Gradle intended for older builds) you would just use the command gradlew (or gradlew.bat) rather than gradle (or gradle.bat) in the following discussions. Note that gradlew is only available in the project's root dir, so depending on your working directory you may need to adjust the path to gradlew as well. Examples use the gradle syntax, but just swap gradlew (properly relative) for gradle if you wish to use the wrapper. Another reason to use gradlew is that it uses the exact version of Gradle that the build is defined to work with. Executing Tasks Gradle uses the concept of build tasks (equivalent to Ant targets or Maven phases/goals). You can get a list of available tasks via gradle tasks To execute a task across all modules, simply perform that task from the root directory. Gradle will visit each sub-project and execute that task if the sub-project defines it. To execute a task in a specific module you can either: cd into that module directory and execute the task name the ""task path"". For example, to run the tests for the hibernate-core module from the root directory you could say gradle hibernate-core:test Common Java related tasks build - Assembles (jars) and tests this project buildDependents - Assembles and tests this project and all projects that depend on it. So think of running this in hibernate-core, Gradle would assemble and test hibernate-core as well as hibernate-envers (because envers depends on core) classes - Compiles the main classes testClasses - Compiles the test classes compile (Hibernate addition) - Performs all compilation tasks including staging resources from both main and test jar - Generates a jar archive with all the compiled classes test - Runs the tests publish - Think Maven deploy publishToMavenLocal - Installs the project jar to your local maven cache (aka ~/.m2/repository). Note that Gradle never uses this, but it can be useful for testing your build with other local Maven-based builds. eclipse - Generates an Eclipse project idea - Generates an IntelliJ/IDEA project (although the preferred approach is to use IntelliJ's Gradle import). clean - Cleans the build directory Testing and databases Testing against a specific database can be achieved in 2 different ways: Using the ""Matrix Testing Plugin"" for Gradle. Coming soon... Using ""profiles"" The Hibernate build defines several database testing ""profiles"" in databases.gradle. These profiles can be activated by name using the db build property which can be passed either as a JVM system prop (-D) or as a Gradle project property (-P). Examples below use the Gradle project property approach. gradle clean build -Pdb=pgsql To run a test from your IDE, you need to ensure the property expansions happen. Use the following command: gradle clean compile -Pdb=pgsql NOTE: If you are running tests against a JDBC driver that is not available via Maven central be sure to add these drivers to your local Maven repo cache (~/.m2/repository) or (better) add it to a personal Maven repo server Running database-specific tests from the IDE using ""profiles"" You can run any test on any particular database that is configured in a databases.gradle profile. All you have to do is run the following command: gradlew setDataBase -Pdb=pgsql or you can use the shortcut version: gradlew sDB -Pdb=pgsql You can do this from the module which you are interested in testing or from the hibernate-orm root folder. Afterward, just pick any test from the IDE and run it as usual. Hibernate will pick the database configuration from the hibernate.properties file that was set up by the setDataBase Gradle task. Starting test databases locally as docker containers You don't have to install all databases locally to be able to test against them in case you have docker available. The script docker_db.sh allows you to start a pre-configured database which can be used for testing. All you have to do is run the following command: ./docker_db.sh postgresql_9_5 omitting the argument will print a list of possible options. When the database is properly started, you can run tests with special profiles that are suffixed with _ci e.g. pgsql_ci for PostgreSQL. By using the system property dbHost you can configure the IP address of your docker host. The command for running tests could look like the following: gradlew test -Pdb=pgsql_ci ""-DdbHost=192.168.99.100"""
2827,"Pure text, CSS only, font independent, inline loading indicatorstext-spinners Pure text, CSS only, font independent, inline loading indicators. Part of tawian-frontend. Thanks to cli-spinners and hack! Usage or Preview Tested on Chrome 53 Firefox 49 Internet Explorer 11 Edge 25 Safari 10 iOS 9 Safari Android Chrome 53 If you have access to other browsers or earlier versions, please open an issue."
106,"An extensible iOS and OS X animation library, useful for physics-based interactions.Pop is an extensible animation engine for iOS, tvOS, and OS X. In addition to basic static animations, it supports spring and decay dynamic animations, making it useful for building realistic, physics-based interactions. The API allows quick integration with existing Objective-C or Swift codebases and enables the animation of any property on any object. It's a mature and well-tested framework that drives all the animations and transitions in Paper. Installation Pop is available on CocoaPods. Just add the following to your project Podfile: Bugs are first fixed in master and then made available via a designated release. If you tend to live on the bleeding edge, you can use Pop from master with the following Podfile entry: Framework (manual) By adding the project to your project and adding pop.embedded framework to the Embedded Binaries section on the General tab of your app's target, you can set up pop in seconds! This also enables @import pop syntax with header modules. Note: because of some awkward limitations with Xcode, embedded binaries must share the same name as the module and must have .framework as an extension. This means that you'll see three pop.frameworks when adding embedded binaries (one for OS X, one for tvOS, and one for iOS). You'll need to be sure to add the right one; they appear identically in the list but note the list is populated in order of targets. You can verify the correct one was chosen by checking the path next to the framework listed, in the format <configuration>-<platform> (e.g. Debug-iphoneos). Note 2: this method does not currently play nicely with workspaces. Since targets can only depend on and embed products from other targets in the same project, it only works when pop.xcodeproj is added as a subproject to the current target's project. Otherwise, you'll need to manually set the build ordering in the scheme and copy in the product. Static Library (manual) Alternatively, you can add the project to your workspace and adopt the provided configuration files or manually copy the files under the pop subdirectory into your project. If installing manually, ensure the C++ standard library is also linked by including -lc++ to your project linker flags. Usage Pop adopts the Core Animation explicit animation programming model. Use by including the following import: Objective-C or if you're using the embedded framework: Swift Start, Stop & Update To start an animation, add it to the object you wish to animate: Objective-C Swift To stop an animation, remove it from the object referencing the key specified on start: Objective-C Swift The key can also be used to query for the existence of an animation. Updating the toValue of a running animation can provide the most seamless way to change course: Objective-C Swift While a layer was used in the above examples, the Pop interface is implemented as a category addition on NSObject. Any NSObject or subclass can be animated. Types There are four concrete animation types: spring, decay, basic and custom. Spring animations can be used to give objects a delightful bounce. In this example, we use a spring animation to animate a layer's bounds from its current value to (0, 0, 400, 400): Objective-C Swift Decay animations can be used to gradually slow an object to a halt. In this example, we decay a layer's positionX from it's current value and velocity 1000pts per second: Objective-C Swift Basic animations can be used to interpolate values over a specified time period. To use an ease-in ease-out animation to animate a view's alpha from 0.0 to 1.0 over the default duration: Objective-C Swift POPCustomAnimation makes creating custom animations and transitions easier by handling CADisplayLink and associated time-step management. See header for more details. Properties The property animated is specified by the POPAnimatableProperty class. In this example we create a spring animation and explicitly set the animatable property corresponding to -[CALayer bounds]: Objective-C Swift The framework provides many common layer and view animatable properties out of box. You can animate a custom property by creating a new instance of the class. In this example, we declare a custom volume property: Objective-C Swift For a complete listing of provided animatable properties, as well more information on declaring custom properties see POPAnimatableProperty.h. Debugging Here are a few tips when debugging. Pop obeys the Simulator's Toggle Slow Animations setting. Try enabling it to slow down animations and more easily observe interactions. Consider naming your animations. This will allow you to more easily identify them when referencing them, either via logging or in the debugger: Objective-C Swift Each animation comes with an associated tracer. The tracer allows you to record all animation-related events, in a fast and efficient manner, allowing you to query and analyze them after animation completion. The below example starts the tracer and configures it to log all events on animation completion: Objective-C Swift See POPAnimationTracer.h for more details. Testing Pop has extensive unit test coverage. To install test dependencies, navigate to the root pop directory and type: Assuming CocoaPods is installed, this will include the necessary OCMock dependency to the unit test targets. SceneKit Due to SceneKit requiring iOS 8 and OS X 10.9, POP's SceneKit extensions aren't provided out of box. Unfortunately, weakly linked frameworks cannot be used due to issues mentioned in the Xcode 6.1 Release Notes. To remedy this, you can easily opt-in to use SceneKit! Simply add this to the Preprocessor Macros section of your Xcode Project: Resources A collection of links to external resources that may prove valuable: AGGeometryKit+POP - Animating Quadrilaterals with Pop Apple Core Animation Programming Guide iOS Development Tips UIScrollView-like deceleration with Pop Pop Playground Repository of Pop animation examples Pop Playground 2 Playing with Facebook's framework POP-MCAnimate Concise syntax for the Pop animation framework Popping - Great examples in one project Rebound Spring Animations for Android Tapity Tutorial Getting Started with Pop Tweaks Easily adjust parameters for iOS apps in development POP Tutorial in 5 steps VBFPopFlatButton Flat animatable button, using Pop to transition between states Contributing See the CONTRIBUTING file for how to help out. License Pop is released under a BSD License. See LICENSE file for details."
1583,"Most popular Mocking framework for unit tests written in Java Most popular mocking framework for Java Current version is 3.x Still on Mockito 1.x? See what's new in Mockito 2! Mockito 3 does not introduce any breaking API changes, but now requires Java 8 over Java 6 for Mockito 2. Mockito for enterprise Available as part of the Tidelift Subscription The maintainers of org.mockito:mockito-core and thousands of other packages are working with Tidelift to deliver commercial support and maintenance for the open source dependencies you use to build your applications. Save time, reduce risk, and improve code health, while paying the maintainers of the exact dependencies you use. Learn more. Development Mockito publishes every change as a -SNAPSHOT version to a public Sonatype repository. Roughly once a month, we publish a new minor or patch version to Maven Central. For release automation we use Shipkit library (http://shipkit.org), Gradle Nexus Publish Plugin, and Allegro's Axion Release Plugin. Fully automated releases are awesome, and you should do that for your libraries, too! See the latest release notes and latest documentation. Docs in javadoc.io are available 24h after release. Read also about semantic versioning in Mockito. Older 1.x and 2.x releases are available in Central Repository and javadoc.io (documentation). More information All you want to know about Mockito is hosted at The Mockito Site which is Open Source and likes pull requests, too. Want to contribute? Take a look at the Contributing Guide. Enjoy Mockito! Need help? Search / Ask question on stackoverflow Go to the mockito mailing-list (moderated) Open a ticket in GitHub issue tracker How to develop Mockito? To build locally: ./gradlew build To develop in IntelliJ IDEA you can use built-in Gradle import wizard in IDEA. Alternatively generate the importable IDEA metadata files using: ./gradlew idea Then, open the generated *.ipr file in IDEA. How to release new version? Every change on the main development branch is released as -SNAPSHOT version to Sonatype snapshot repo at https://s01.oss.sonatype.org/content/repositories/snapshots/org/mockito/mockito-core. In order to release a non-snapshot version to Maven Central push an annotated tag, for example: At the moment, you may not create releases from GitHub Web UI. Doing so will make the CI build fail because the CI creates the changelog and posts to GitHub releases. We'll support this in the future."
3574,"blueimp Gallery is a touch-enabled, responsive and customizable image & video gallery, carousel and lightbox, optimized for both mobile and desktop web browsers. It features swipe, mouse and keyboard navigation, transition effects, slideshow functionality, fullscreen support and on-demand content loading.blueimp Gallery Contents Demo Description Setup Lightbox setup Controls Contain Carousel setup Responsive images Keyboard shortcuts Options Default options Event callbacks Carousel options Indicator options Fullscreen options Video options Video factory options YouTube options Vimeo options Container and element options Property options API Initialization API methods Videos HTML5 video player Video controls Video preloading Fullscreen video Multiple video sources YouTube Vimeo Additional Gallery elements Additional content types Example HTML text factory implementation jQuery plugin jQuery plugin setup HTML5 data-attributes Container ids and link grouping Gallery object jQuery events Requirements Browser support License Credits Description blueimp Gallery is a touch-enabled, responsive and customizable image and video gallery, carousel and lightbox, optimized for both mobile and desktop web browsers. It features swipe, mouse and keyboard navigation, transition effects, slideshow functionality, fullscreen support and on-demand content loading and can be extended to display additional content types. Setup Install the blueimp-gallery package with NPM: Lightbox setup Copy the css, img and js directories to your website. Include the Gallery stylesheet in the head section of your webpage: Add the following HTML snippet with the Gallery widget to the body of your webpage: Please note that each aria-controls attribute should have the same value as the id attribute of the Gallery widget. Include the Gallery script at the bottom of the body of your webpage: Create a list of links to image files, optionally with enclosed thumbnails and add them to the body of your webpage, before including the Gallery script: Add the following JavaScript code after including the Gallery script, to display the images in the Gallery lightbox on click of one of those links: Controls To initialize the Gallery with visible controls (previous slide, next slide, etc.), add the CSS class blueimp-gallery-controls to the Gallery widget: Please also note that by default, a click on an image slide or any Gallery widget element with the toggle class will toggle the display of the Gallery controls. Contain To stretch smaller images to the dimensions of the Gallery container while keeping their aspect ratio, add the CSS class blueimp-gallery-contain to the Gallery widget: Carousel setup To display the images in an inline carousel instead of a lightbox, follow the lightbox setup and add the CSS class blueimp-gallery-carousel to the Gallery widget and remove the child element with the close class, or add a new Gallery widget with a different id to your webpage: Add the following JavaScript code after including the Gallery script to initialize the carousel: Responsive images The Gallery supports the concept of responsive images with the srcset, sizes and sources object properties, e.g. using the API: With link elements, those same properties can be defined via data-srcset, data-sizes and data-sources attributes: Please note that data-sources must be a valid JSON string listing the sources array. Keyboard shortcuts The Gallery can be controlled with the following keyboard shortcuts: Enter: Toggle controls visibility. Escape: Close the Gallery lightbox. Space: Toggle the slideshow (play/pause). ArrowLeft: Move to the previous slide. ArrowRight: Move to the next slide. Please note that setting the carousel option to true disables the keyboard shortcuts by default. Options Default options The following are the default options set by the core Gallery library: Event callbacks Event callbacks can be set as function properties of the options object passed to the Gallery initialization function: Carousel options If the carousel option is true, the following options are set to different default values: The options object passed to the Gallery function extends the default options and also those options set via carousel mode. Indicator options The following are the additional default options set for the slide position indicator: Fullscreen options The following are the additional default options set for the fullscreen mode: Video options Video factory options The following are the additional default options set for the video factory: YouTube options Options for YouTube videos: Vimeo options Options for Vimeo videos: Container and element options The widget container, slidesContainer, titleElement and indicatorContainer options can be set as CSS selector or HTMLElement node, so the following are equivalent: CSS selectors are passed as argument to querySelectorAll, which is supported by IE8+ and all modern web browsers and queried with getElementById or getElementsByTagName in older browsers. If the helper script is replaced with jQuery, the container and element options can be any valid jQuery selector. Property options The options ending with ""Property"" define how the properties of each link element are accessed. For example, the urlProperty is by default set to href. This allows to define link elements with href or data-href attributes: If the links are provided as JavaScript array, it is also possible to define nested property names, by using the native JavaScript accessor syntax for the property string: API Initialization The blueimp Gallery can be initialized by simply calling it as a function with an array of links as first argument and an optional options object as second argument: The links array can be a list of URL strings or a list of objects with URL properties: The URL property name defined by each list object can be configured via the urlProperty option. By default, it is set to href, which allows to pass a list of HTML link elements as first argument. For images, the thumbnail property defines the URL of the image thumbnail, which is used for the indicator navigation displayed at the bottom of the Gallery, if the controls are visible. The object returned by executing the Gallery function (the gallery variable in the example code above) is a new instance of the Gallery and allows to access the public API methods provided by the Gallery. The Gallery initialization function returns false if the given list was empty, the Gallery widget is missing, or the browser doesn't pass the functionality test. API methods The Gallery object returned by executing the Gallery function provides the following public API methods: Videos HTML5 video player The Gallery can be initialized with a list of videos instead of images, or a combination of both: The Gallery uses the type property to determine the content type of the object to display. If the type property is empty or doesn't exist, the default type image is assumed. Objects with a video type will be displayed in a HTML5 video element if the browser supports the video content type. For videos, the poster property defines the URL of the poster image to display, before the video is started. Video controls To start video playback, you can either click on the video play icon or on the video slide itself. Starting the video playback enables the native HTML5 video controls. To toggle the Gallery controls (previous slide, next slide, etc.) instead of starting video playback on click of a video slide, add the toggle class to the video cover element using the videoCoverClass Gallery option: Video preloading You can set the preload property of a Gallery video object to a valid value defined by the HTML5 video preload attribute: none: Indicates that the video should not be preloaded. metadata: Indicates that only video metadata (e.g. length) is fetched. auto: Indicates that the whole video file can be preloaded. By default, preload is set to none to save on network bandwidth consumption. Fullscreen video By default, videos are displayed with the HTML5 video playsinline attribute set, which indicates that the video is to be played inline. To disable this behavior, you can set the Gallery option videoPlaysInline to false: Please note that this attribute only has an effect on some mobile browsers, e.g. Safari on iOS 10 and later. However, all browsers provide video controls to switch between fullscreen and inline mode on user request. Multiple video sources To provide multiple video formats, the sources property of a list object can be set to an array of objects with type and src properties for each video source. The first video format in the list that the browser can play will be displayed: It is also possible to define the video sources as data-sources attribute as a JSON string listing the sources array: YouTube The Gallery can display YouTube videos for Gallery items with a type of text/html and a youtube property (configurable via YouTube options) with the YouTube video-ID: If the href and poster properties are undefined, they are set automatically based on the video ID. Please note that the Gallery YouTube integration requires a browser with postMessage support, which excludes IE7. Vimeo The Gallery can display Vimeo videos for Gallery items with a type of text/html and a vimeo property (configurable via Vimeo options) with the Vimeo video-ID: If the href property is undefined, it is set automatically based on the video ID. Please note that the Gallery Vimeo integration requires a browser with postMessage support, which excludes IE7. Additional Gallery elements It is possible to add additional elements to the Gallery widget, e.g. a description label. First, add the desired HTML element to the Gallery widget: Next, add the desired element styles to your CSS file: Then, add the additional element information to each of your links: Finally, initialize the Gallery with an onslide callback option, to set the element content based on the information from the current link: Additional content types By extending the Gallery prototype with new factory methods, additional content types can be displayed. By default, blueimp Gallery provides the imageFactory and videoFactory methods for image and video content types respectively. The Gallery uses the type property of each content object to determine which factory method to use. The type defines the Internet media type of the content object and is composed of two or more parts: A type, a subtype, and zero or more optional parameters, e.g. text/html; charset=UTF-8 for an HTML document with UTF-8 encoding. The main type (the string in front of the slash, text in the example above) is concatenated with the string Factory to create the factory method name, e.g. textFactory. Example HTML text factory implementation Please note that the textFactory script has to be included after the core Gallery script, but before including the YouTube and Vimeo integration plugins, which extend the textFactory implementation to handle YouTube and Vimeo video links. Please also note that although blueimp Gallery doesn't require jQuery, the following example uses it for convenience. Extend the Gallery prototype with the textFactory method: Next, add the text-content class to the Gallery CSS: With the previous changes in place, the Gallery can now handle HTML content types: jQuery plugin jQuery plugin setup The blueimp Gallery jQuery plugin registers a global click handler to open links with data-gallery attribute in the Gallery lightbox. To use it, follow the lightbox setup guide, but replace the minified Gallery script with the jQuery plugin version and include it after including jQuery: Next, add the attribute data-gallery to your Gallery links: The onclick handler from the lightbox setup guide is not required and can be removed. HTML5 data-attributes Options for the Gallery lightbox opened via the jQuery plugin can be defined as HTML5 data-attributes on the Gallery widget container. The jQuery plugin also introduces the additional filter option, which is applied to the Gallery links via jQuery's filter method and allows to remove duplicates from the list: This will initialize the Gallery with the option startSlideshow set to true. It will also filter the Gallery links so that only links with an even index number will be included. Container ids and link grouping If the data-gallery attribute value is a valid id string (e.g. ""#blueimp-gallery""), it is used as container option. Setting data-gallery to a non-empty string also allows to group links into different sets of Gallery images: This will open the links with the data-gallery attribute #blueimp-gallery-fruits in the Gallery widget with the id blueimp-gallery-fruits, and the links with the data-gallery attribute #blueimp-gallery-vegetables in the Gallery widget with the id blueimp-gallery-vegetables. Gallery object The gallery object is stored via jQuery data storage on the Gallery widget when the Gallery is opened and can be retrieved the following way: This gallery object provides all methods outlined in the API methods section. jQuery events The jQuery plugin triggers Gallery events on the widget container, with event names equivalent to the gallery event callbacks: Requirements blueimp Gallery doesn't require any other libraries and can be used standalone without any dependencies. You can also use the individual source files instead of the standalone minified version: The helper script can be replaced by jQuery v. 1.7+. The fullscreen, indicator, video, YouTube and Vimeo source files are optional if their functionality is not required. The jQuery plugin requires jQuery v. 1.7+ and the basic Gallery script, while the fullscreen, indicator, video, YouTube and Vimeo source files are also optional: Please note that the jQuery plugin is an optional extension and not required for the Gallery functionality. Browser support blueimp Gallery has been tested with and supports the following browsers: Chrome 14.0+ Safari 4.0+ Firefox 4.0+ Opera 10.0+ Mobile Safari 6.0+ Mobile Chrome 30.0+ Default Browser on Android 2.3+ Opera Mobile 12.0+ Edge 74+ Edge Legacy 41.0+ Internet Explorer 7.0+ License Released under the MIT license. Credits The swipe implementation is based on code from the Swipe library."
4128,":bookmark_tabs: Presentation helps you to make tutorials, release notes and animated pages. DEPRECATED, NO LONGER MAINTAINED Looking for the easiest way of presenting something in your iOS app? Then you are in the right place. Presentation will help you make your tutorials, release notes and any kind of animated pages with the minimum amount of effort. Presentation includes the following features: Custom positioning: You can use Position for percentage-based position declaration. Content: View model used for custom positioning and animations. It translates your percents to AutoLayout constraints behind the scenes. Slides: You can use any kind of UIViewController as a slide. SlideController is your good friend if you want to use custom positioning and animation features on your pages. Background: You can add views that are visible across all the pages. Also it's possible to animate those views during the transition to the specific page. Animations: You can easily animate the appearance of a view on the specific page. Presentation works both on the iPhone and the iPad. You can use it with both Swift and Objective-C. Try one of our demos to see how it works: Table of Contents Usage Presentation controller Position Content view model Slides Page animations Background views Installation Components Contributing Credits License Usage Presentation controller If that's the only thing you need, look into Pages. Position Position is percentage-based; you can use left, right, top, bottom to set a position. Content view model Content view model is a layer between UIView and Position. The current position is the center of a view by default, but can also be changed to the origin of a view. Slides Page animations Background views Installation Presentation is available through CocoaPods. To install it, simply add the following line to your Podfile: Presentation is also available through Carthage. To install just write into your Cartfile: Components Presentation wouldnt be possible without the help of these components: Pages: The easiest way of setting up a UIPageViewController Cartography: Helps you set up your Auto Layout constraints declaratively and without any stringly typing! Contributing Please see our playbook for guidelines on contributing. Credits Hyper made this. Were a digital communications agency with a passion for good code and delightful user experiences. If youre using this library we probably want to hire you (we consider remote employees, too; the only requirement is that youre awesome). License Presentation is available under the MIT license. See the LICENSE."
2373,"[DEPRECATED]WARNING: THIS PROJECT IS DEPRECATED It will not receive any future updates or bug fixes. If you are using it, please migrate to another solution. Purpose FXForms is an Objective-C library for easily creating table-based forms on iOS. It is ideal for settings pages or data-entry tasks. Unlike other solutions, FXForms works directly with strongly-typed data models that you supply (instead of dictionaries or complicated dataSource protocols), and infers as much information as possible from your models using introspection, to avoid the need for tedious duplication of type information. Supported iOS & SDK Versions Supported build target - iOS 9.0 (Xcode 7.0, Apple LLVM compiler 7.0) Earliest supported deployment target - iOS 7.0 Earliest compatible deployment target - iOS 5.0 NOTE: 'Supported' means that the library has been tested with this version. 'Compatible' means that the library should work on this iOS version (i.e. it doesn't rely on any unavailable SDK features) but is no longer being tested for compatibility and may require tweaking or bug fixes to run correctly. ARC Compatibility FXForms requires ARC. If you wish to use FXForms in a non-ARC project, just add the -fobjc-arc compiler flag to the FXForms.m class. To do this, go to the Build Phases tab in your target settings, open the Compile Sources group, double-click FXForms.m in the list and type -fobjc-arc into the popover. If you wish to convert your whole project to ARC, comment out the #error line in FXForms.m, then run the Edit > Refactor > Convert to Objective-C ARC... tool in Xcode and make sure all files that you wish to use ARC for (including FXForms.m) are checked. Creating a form To create a form object, just make any new NSObject subclass that conforms to the FXForm protocol, like this: The FXForm protocol has no compulsory methods or properties. The FXForms library will inspect your object and identify all public and private properties and use them to generate the form. For example, suppose you wanted to have a form containing an ""Email"" and ""Password"" field, and a ""Remember Me"" switch; you would define it like this: That's literally all you have to do. FXForms is really smart; much more so than you might expect: Fields will appear in the same order you declare them in your class Fields will automatically be assigned suitable control types, for example, the rememberMe field will be displayed as a UISwitch, the email field will automatically have a keyboard of type UIKeyboardTypeEmailAddress and the password field will automatically have secureTextEntry enabled. Field titles are based on the key name, but camelCase is automatically converted to a Title Case, with intelligent handling of ACRONYMS, etc. Modifying values in the form will automatically assign those values back to your model object. You can use custom setter methods and/or KVO to intercept the changes if you need to perform additional logic. If your form contains subforms (properties that conform to the FXForm protocol), or view controllers (e.g for terms and conditions pages), they will automatically be instantiated if they are nil - no need to set default values. These default behaviors are all inferred by inspecting the property type and name using Objective-C's runtime API, but they can also all be overridden if you wish - that's covered later under Tweaking form behavior Displaying a form (basic) To display your form in a view controller, you have two options: FXForms provides a UIViewController subclass called FXFormViewController that is designed to make getting started as simple as possible. To set up FXFormViewController, just create it as normal and set your form as follows: You can then display the form controller just as you would do any ordinary view controller. FXFormViewController contains a UITableView, which it will create automatically as needed. If you prefer however, you can assign your own UITableView to the tableView property and use that instead. You can even initialize the FXFormViewController with a nib file that creates the tableView. FXFormViewController is designed to be subclassed, just like a regular UIViewController or UITableViewController. In most cases, you'll want to subclass FXFormViewController so you can add your form setup logic and action handlers. It is a good idea to place the FXFormViewController (or subclass) inside a UINavigationController. This is not mandatory, but if the form contains subforms, these will be pushed onto its navigationController, and if that does not exist, the forms will not be displayed. Like UITableViewController, FXFormViewController will normally assign the tableView as the main view of the controller. Unlike UITableViewController, it doesn't have to be - you can make your tableView a subview of your main view if you prefer. Like UITableViewController, FXFormViewController implements the UITableViewDelegate protocol, so if you subclass it, you can override the UITableViewDelegate and UIScrollViewDelegate methods to implement custom behaviors. FXFormViewController is not actually the direct delegate of the tableView however, it is the delegate of its formController, which is an instance of FXFormController. The formController acts as the tableView's delegate and datasource, and proxies the UITableViewDelegate methods back to the FXFormViewController via the FXFormControllerDelegate protocol. Unlike UITableViewController, FXFormViewController does not implement UITableViewDataSource protocol. This is handled entirely by the FXFormController, and it is not recommended that you try to override or intercept any of the datasource methods. Displaying a form (advanced) The FXFormViewController is pretty flexible, but sometimes it's inconvenient to be forced to use a particular base controller class. For example, you may wish to use a common base class for all your view controllers, or display a form inside a view that does not have an associated controller. In the former case, you could add an FXFormViewController as a child controller, but in the latter case that wouldn't work. To use FXForms without using FXFormViewController, you can use the FXFormController directly. To display a form using FXFormController, you just need to set the form and tableView properties, and it will do the rest. You can optionally bind the FXFormController's delegate property to be notified of UITableView events. When using a custom form view controller in this way, some interactions are still handled for you (e.g. adjusting the table view content inset when the keyboard is presented), but you will need to add other view logic yourself, such as reloading the table when the UIViewController appears on screen. Here is example code for a custom form view controller: Tweaking form behavior FXForm's greatest strength is that it eliminates work by guessing as much as possible. It can't guess everything however, and it sometimes guesses wrong. So how do you correct it? You may find that you don't want all of your object properties to become form fields; you may have private properties that are used internally by your form model for example, or you may just wish to order the fields differently to how you've arranged your properties in the interface. To override the list of form fields, implement the optional -fields method of your form: The fields method should return an array of strings, dictionaries, or a mixture. In the example we have returned strings; these map to the names of properties of the form object. If you return an array of names like this, these fields will replace the automatically generated field list. The -fields method will be called again every time the form is reassigned to the formController. That means that you can generate the fields dynamically, based on application logic. For example, you could show or hide certain fields based on other properties. In addition to omitting and rearranging fields, you may wish to override their attributes. There are two ways to do this: One way is to add a method to the form object, such as -(NSDictionary *)[name]Field; where name is the property that the field relates to. This method returns a dictionary of properties that you wish to override (see Form field properties, below). For example, if we wanted to override the title of the email field, we could do it like this: Alternatively, you can return a dictionary in the -fields array instead of a string. If you do this, you must include the FXFormFieldKey so that FXForms knows which field you are overriding: These two approaches are equivalent. You may wish to add additional, virtual form fields (e.g. buttons or labels) that don't correspond to any properties on your form class. You can do this by implementing the -fields method, but if you're happy with the default fields and just want to add some extra fields at the end, you can override the -extraFields method instead, which works the same way, but leaves in place the default fields inferred from the form class: Similarly, if you only want to display a subset of the form object's properties in your form, but don't want to have to list all the properties you want to keep in the -fields method just for the sake of excluding a few of them, you can use the -excludedFields method to specify just the names of properties you don't want to include. Grouping fields You may wish to group your form fields into sections in the form to make it ease to use. FXForms handles grouping in a very simple way - you just add an FXFormFieldHeader or FXFormFieldFooter attribute to any field and it will start/end the section at that point. The FXFormFieldHeader/Footer can be either a string that will be displayed as the header or footer text for the section, or a custom UIView instance or subclass. If you don't want a header or footer, just supply an empty string or NSNull value. In the following example, we have four fields, and we've split them into two groups, each with a header: Alternatively, since we aren't overriding any other field properties, we could have done this more cleanly by using the following approach: Form field properties The list of form field properties that you can set are as follows. Most of these have sensible defaults set automatically. Note that the string values of these constants are declared in the interface - you can assume that the string values of these constants will no change in future releases, and you can safely use these values in (for example) a plist used to configure the form. This is the name of the related property of the form object. If your field isn't backed by a real property, this might be the name of a getter method used to populate the field value. It's also possible to have completely virtual fields (such as buttons) that do not have a key at all. This is the field type, which is used to decide how the field will be displayed in the table. The type is used to determine which type of cell to use to represent the field, but it may also be used to configure the cell (a single cell class may support multiple field types). The type is automatically inferred from the field property declaration, but can be overridden. Supported types are listed under Form field types below, however you can supply any string as the type and implement a custom form cell to display and/or edit it. This is the class of the field value. For primitive types, this will be the class used to box the value when accessed via KVC (e.g. NSNumber for numeric values, or NSValue for struct types). This is automatically determined for all properties of the form, so you rarely need to set it yourself. For form properties that you add yourself using the -fields or -extraFields methods, it is sometimes helpful to specify this explicitly. A good example would be if you are adding view controller or subform fields, where the class cannot usually be inferred automatically. The value provided can be either a Class object or a string representing the class name. This is the class of the cell used to represent the field. By default this value is not specified on the field-level; instead, the FXFormController maintains a map of fields types to cell classes, which allows you to override the default cells used to display a given field type on a per-form level rather than having to do it per-field. If you do need to provide a special one-off cell type, you can use this property to do so. The value provided can be either a Class object or a string representing the class name. This is the display title for the field. This is automatically generated from the key by converting from camelCase to Title Case, and then localised by running it through the NSLocalizedString() macro. That means that instead of overriding the title using this key, you can do so in your strings file instead if you prefer. This is the placeholder value to display when the field value is nil or empty. This is typically a string, but doesn't have to be, for example it could be an NSDate for a date field, or a UIImage for an image field. When used with an options or multi-select field, the placeholder will appear as the first item in the options list, and can be used to reset the field to nil / no value. This is a default value to use when the field value is nil. This can be useful when creating forms dynamically as the default values can be set directly in the fields array instead of separately in the form's values. It's also a way to ensure that a field value can never be set to nil by the user. Note that the default value is different from the placeholder value, as it will actually be stored in the form itself. If a default value is set, the placeholder will never appear. Default values only work reliably for object types - since zero is potentially a meaningful value for an integer or float property, it will not be replaced by the default value. For any field type, you can supply an array of supported values, which will override the standard field with a checklist of options to be selected instead. The options can be NSStrings, NSNumbers or any other object type. You can supply an FXFormFieldValueTransformer to control how the option values are displayed in the list. Alternatively, if you use a custom object for the values, you can implement the -(NSString *)fieldDescription; method to control how it is displayed. See Form field options below for more details. If the field is an NSArray or NSOrderedSet, FXForms allows the user to add, edit and remove items. By default FXForms assumes that the values in the collection are of type FXFormFieldTypeText, however you can override this using the FXFormFieldTemplate dictionary. The FXFormFieldTemplate dictionary can contains most of the same types of value as an ordinary field dictionary, and should be used to describe all the attributes of the elements in the collection. Sometimes the value you wish to display for a field may not match the value you store. For example, you might want to display a date in a particular format, or convert a locale code into its human-readable equivalent. The FXFormFieldValueTransformer property lets you specify either a conversion block or an NSValueTransformer to use for converting the field value to a string. If a value transformer is provided, it will be used instead of calling the -fieldDescription method of the field's value object. You can supply either an instance of NSValueTransformer or the name of an NSValueTransformer subclass. If the form field has an options array, the value transformer will also be used to control how the options are displayed in the list. The FXFormFieldValueTransformer can be reversible, in which case it will be also be used to convert input values before storing them in the form. This is an optional action to be performed by the field. The value can be either a string representing the name of a selector, or a block, and will be executed when the field is activated. If the action is specified as a selector, the target is determined by cascading up the responder chain from the cell until an object is encountered that responds to it. That means that you could choose to implement this action method on the tableview, its superview, the view controller, the app delegate, or even the window. If your form is presented as a subform of another form, you can also implement actions methods for subforms in the view controller for their parent form. For non-interactive fields, the action will be called when the cell is selected; for fields such as switches or textfields, it will fire when the value is changed. When using a selector, the action method can accept either zero or one argument. The argument supplied will be the sender, which is typically a form field cell, (a UITableViewCell conforming to the FXFormFieldCell protocol), from which you can access the field model, and from that the form itself. This is a UIStoryboardSegue to be performed when the field is tapped. This can be either be a UIStoryboardSegue subclass (or a string containing the name of a UIStoryboardSegue subclass), an instance of a UIStoryboardSegue subclass, or a string representing the identifier of a segue attached to the form view controller. Note that in the latter case, the segue must be attached to the same controller as the form, or it will crash when invoked. If the FXFormFieldSegue property is a segue instance or identifier, it will be invoked when the field is tapped. If it is a segue subclass, this segue will be instantiated and used to handle the transition when displaying a subform or sub-controller. This property provides an optional section header to display before the field. The value can be either a string or a UIView instance or subclass (or a string containing the name of a UIView subclass). The height of the header will be inferred from the view, or you can override it using the UITableViewDelegate. By default, its value will be inferred automatically for subforms based on the name of the subform property. Supply an empty string or NSNull value to create a section partition without a title. This property provides an optional section footer string to display after the field. The value can be either a string or a UIView instance or subclass (or a string containing the name of a UIView subclass). The height of the footer will be inferred from the view, or you can override it using the UITableViewDelegate. Supply an empty string or NSNull value to create a section partition without a footer, or just omit the FXFormFieldFooter key altogether. Fields whose values is another FXForm, or which have a supplied options array, will normally be displayed in a new FXFormViewController, which is pushed onto the navigation stack when you tap the field. You may wish to display such fields inline within same tableView instead. You can do this by setting the FXFormFieldInline property to @YES. Fields of type NSArray or NSOrderedSet can optionally display sorting controls so that the user can change the item order. Set the FXFormFieldSortable property to YES to enabled this feature. Some types of field may be displayed in another view controller, which will be pushed onto the navigation stack when the field is selected. By default this class is not specified on the field-level; instead, the FXFormController maintains a map of fields types to controller classes, which allows you to override the default controller used to display a given field type on a per-form level rather than having to do it per-field. If you do need to provide a special one-off controller type, the FXFormFieldViewController property lets you specify the controller to be used on a per-field basis. FXFormViewController can be either a UIViewController instance or class (or a string containing the name of a class). The controller specified must conform to the FXFormFieldViewController protocol. By default, such fields will be displayed using the FXFormViewController class. Form field types This is the default field type, used if no specific type can be determined. This type can be used if you want the field to be treated as non-interactive/read-only. Form values will be displayed by converting the value to a string using the -fieldDescription method. This maps to the standard NSObject -description method for all built-in types, but you can override it for your own custom value classes. By default, this field type will be represented by an ordinary UITextField with default autocorrection. This type represents multiline text. By default, this field type will be represented by an expanding UITextView. Like FXFormFieldTypeText, but with a keyboard type of UIKeyboardTypeURL, and no autocorrection. Like FXFormFieldTypeText, but with a keyboard type of UIKeyboardTypeEmailAddress, and no autocorrection. Like FXFormFieldTypeText, but with secure text entry enabled, and no autocorrection. Like FXFormFieldTypeText, but with a numeric keyboard, and input restricted to a valid number. Like FXFormFieldTypeNumber, but restricted to integer input. Like FXFormFieldTypeInteger, but for unsigned values. Uses number pad by default. Like FXFormFieldTypeNumber, but indicates value is primitive (not-nillable) A boolean value, set using a UISwitch control by default. Like FXFormFieldTypeBoolean, but this type is used for toggle options and by default it creates a checkmark control instead of a switch. A date value, selected using a UIDatePicker. A time value, selected using a UIDatePicker. A date and time, selected using a UIDatePicker. An image, selected using a UIImagePickerController. Form field options When you provide an options array for a form field, the field input will be presented as a list of options to tick. How this list of options is converted to the form value depends on the type of field: If the field type matches the values in the options array, selecting the option will set the selected value directly, but that may not be what you want. For example, if you have a list of strings, you may be more interested in the selected index than the value (which may have been localised and formatted for human consumption, not machine interpretation). If the field type is numeric, and the options values are not numeric, it will be assumed that the field value should be set to the index of the selected item, instead of the value. If the field is a collection type (such as NSArray, NSSet, etc.), the form will allow the user to select multiple options instead of one. Collections are handled as followed, depending on the class of the property: If you use NSArray, NSSet and NSOrderedSet, the selected values will be stored directly in the collection; If you use an NSIndexSet, the indexes of the values will be stored; If you use NSDictionary, both the values and their indexes will be stored. For ordered collection types, the order of the selected values is guaranteed to match the order in the options array. Multi-select fields can also be used with NS_OPTIONS-style bitfield enum values. Just use an integer or enum as your property type, and then specify a field type of FXFormFieldTypeBitfield. You can then either specify explicit bit values in your options by using NSNumber values, or let FXForms infer the bit value from the option index. NOTE: the actual values defined in your enum are not available to FXForms at runtime, so the selected values will be purely determined by the index of value of the options in the FXFormFieldOptions value. If your enum values are non-sequential, or do not begin at zero, the indices won't match the options indexes. To define enum options with non-sequential values, you can specify explicit numeric option values and use FXFormFieldValueTransformer to display human readable labels, like this: Cell configuration If you want to tweak some properties of the field cells, without subclassing them, you can actually set any cell property by keyPath, just by adding extra values to your field dictionary. For example, this code would turn the textLabel for the email field red: This code would disable auto-capitalisation for the name field: Cells are not recycled in the FXForm controller, so you don't need to worry about cleaning up any properties that you set in this way. Be careful of overusing ""stringly typed"" code such as this however, as errors can't be caught at compile time. For heavy customisation, it is better to create cell subclasses and override properties in the -setField: method. Custom cells FXForms provides default cell implementations for all supported fields. You may wish to provide additional cell classes for custom field types, or even replace all of the FXForm cells with custom versions for your application. There are two levels of customisation possible for cells. The simplest option is to subclass one of the existing FXFormCell classes, which all inherit from FXFormBaseCell. These cell classes contain a lot of logic for handling the various different field types, but also expose the views and controls used, for easy customisation. When subclassing an existing cell type, you can override the setUp, update and didSelectWithTableView:controller: methods (optionally calling [super ...] if you want to inherit the original cell's behaviors). The setUp method will be called once when the cell is created, and the update method will be called each time the field value is updated. If you already have a base cell class and don't want to base your cells on FXFormBaseCell, you can create an FXForms-compatible cell from scratch by subclassing UITableViewCell and adopting the FXFormFieldCell protocol. Your custom cell must have a property called field, of type FXFormField. FXFormField is a wrapper class used to encapsulate the properties of a field, and also provides a way to set and get the associated form value (via the field.value virtual property). You cannot instantiate FXFormField objects directly, however they can be accessed and enumerated via methods on the FXFormController. Once you have created your custom cell, you can use it as follows: If your cell is used only for a few specific fields, you can use the FXFormFieldCell property to use it for a particular form field If your cell is designed to handle a particular field type (or types), you can tell the formController to use your custom cell class for a particular type using the -registerCellClass:forFieldType: method of FXFormController. If your cell is designed to handle a particular field value class (or subclass), you can tell the formController to use your custom cell class for a particular value class using the -registerCellClass:forFieldClass: method of FXFormController. If you want to completely replace all cells with your own classes, use the -registerDefaultFieldCellClass: method of FXFormController. This replaces all default cell associations for all field types with your new cell class. You can then use -registerCellClass:forFieldType: to add additional cell classes for specific types. Swift Compatibility FXForms is fully compatible with Swift, with the following caveats: Your forms objects must inherit from NSObject, or de declared using the @objc qualifier. For collection fields, you must use NSArray, NSDictionary, NSOrderedSet, etc. Swift's strongly typed collections won't work. If your form objects are declared in a different module to your main app, FXForm's field value class inference may not work correctly, in which case you can explicitly specify the field class by adding the following method to your form object for each field that doesn't work: Release notes Version 1.2.14 Fixed issues wth keyboard show/hide Removed namespaces from nib names for Swift compatibility Fixed over-large margins in landscape mode on iPad Set accessibility values for text labels Fixed image picker being presented when cancel pressed Version 1.2.13 Exposed nextCell property on FXFormBaseCell Fixed long UITextView's to scroll to the the cursor position instead of the bottom of the UITextView. Made sure that when the keyboard is dismissed the former tableView contentInsets are restored. Make custom cell config cascade down to options views Fix to resolve crash bug when used with BaseModel Fixed warnings on Xcode 7 beta (well, suppressed mostly) Version 1.2.12 Custom titles for template fields are no longer displayed inside each field item, they are only used for the ""Add Item"" button title. Fixed another crash relating to using scalar default values for collection type fields Reverse value transforms should now work correctly Version 1.2.11 Field descriptions for collections now respect FXFieldValueTransformer Using Scalar values as default value for collection type fields now works transparently Version 1.2.10 Fixed crash when displaying photo picker on iPad Version 1.2.9 Cells defined using nibs now infer their height form the nib unless overridden Option picker can now be dismissed by tapping field again, like date picker Version 1.2.8 Fixed incorrect type inference for fields with a segue property Date picker can now be dismissed by tapping date field again Version 1.2.7 Fixed bug where button-type fields (ones with an action but no editable value) were not correctly inferred Version 1.2.6 Improved valueClass inference, especially for template fields FXFormImagePickerCell now lets you select camera or photo library Version 1.2.5 Fixed crash when form section has a footer but no header Version 1.2.4 hash, description, etc. no longer show up on iOS7 for builds built with the 8.1 SDK FXFormViewController can now be either a view controller class or instance Version 1.2.3 Added a fix when using Swift to allow FXForms to automatically infer the types of forms and controllers, as it can with Objective-C Now throws an exception if you try to present a subform when not embedded inside a UINavigationController Version 1.2.2 Fixed bug where subforms would be overwritten by a new instance Version 1.2.1 Fixed issue where table footer spacing would incorrectly be shown even when no footer text was set Fixed crash relating to the use of default values Made a small compatibility fix for Swift Added Swift example project Version 1.2 Collection fields types, such as NSArray, NSSet, NSOrderedSet, etc. can now be edited by adding, removing and sorting items Exposed the setUp and update methods of FXFormsBaseCell for simpler subclassing Added FXFormsDefaultCell that implements standard behaviors (for simpler subclassing) Added FXFormFieldTemplate for creating template values for collections Added FXFormFieldSegue property for specifying a segue to perform when field is tapped Added FXFormFieldTypePhone field type Added FXFormFieldTypeUnsigned field type Added FXFormOptionSegmentsCell class Added FXFormFieldDefault for specifying a default value for form fields Added ability to register cell and controller classes based on field value class as well as type Fixed bug in stepper field where labels didn't resize after value change Fixed bug where image preview in FXImagePickerCell would be displayed with incorrect width Fixed handling of NSURL fields Type inference now works better for dynamic fields Added dynamic fields example (loading form field descriptions from a JSON file) Added indexPathForField: method to FXFormController FXForm tableView is now always in edit mode - this may affect layout for custom cells Specified FXFormFieldValueTransformer object can now be reversible Textfield form values are now updated live during editing Added -excludedFields method for excluding certain fields from form Now ignores standard @properties such as hash and description, introduced in iOS 8 You can now use a UIView class or instance as the value for FXFormFieldHeader/Footer Version 1.1.6 Options fields with numeric values are now correctly displayed Action block will now be called when an options field is updated Action blocks are no longer called when tapping subform field cells Fixed crash when using placeholder values with options fields Added FXFormFieldTypeFloat Added dependent fields example Version 1.1.5 Virtual fields without keys no longer crash when the form object is an NSManagedObject subclass Version 1.1.4 FXForms now nils out all control delegates & datasources correctly to prevent crashes when form is dismissed The FXFormImagePickerCell image is no longer drawn with incorrect alignment FXFormTextViewCell can now display placeholder text when empty Version 1.1.3 Using Field method to set form properties is no longer overridden by defaults Only mess with the content inset/offset when the view controller is not a UITableViewController It should now be easier to use nibs to lay out cell subclasses without losing standard functionality Using FXFormFieldTypeLabel now works more consistently Version 1.1.2 Fixed incorrect forwarding of scrollViewWillBeginDragging event Fields of type FXFormFieldTypeBitfield are now handled correctly again (broken in 1.1.1) It is now possible to create custom cell classes without inheriting all the standard styling logic Added example of creating a custom form cell subclass using a nib file (CustomButtonExample) FXForms will no longer try to auto-instantiate NSManagedObjects if they are nil (this would crash previously) Version 1.1.1 Fixed bug with indexed options fields FXFormOptionPickerCell selected index is now set correctly when tabbing between fields Version 1.1 Added support for multi-select option fields - just use a collection type such NSArray, NSSet or NSIndexSet for your options field Added FXFormFieldTypeBitfield for NS_OPTIONS-type multi-select enum values Added FXFormFieldOptionPickerCell as an alternative way to display options fields (does not support multi-select) Nested forms now propagate form actions back to their parent form view controller as well as up to the app delegate Added parentFormController property to FXFormController FXFormField action property is now a block instead a of a selector (can be specified as either in form dictionary) Added FXFormFieldPlaceholder value to be displayed when value is nil / empty Keyboard will now display ""next"" in cases where next cell acceptsFirstResponder Added FXFormFieldTypeImage and FXFormImagePickerCell Added FXFormFieldTypeLongText for multiline text Added FXFormFieldValueTransformer for adapting field values for display It is now possible to create completely virtual form objects by overriding setValue:forKey: to set properties Added FXFormFieldViewController property for specifying custom form field view controllers Added additional example projects to demonstrate the new features Button-type fields (ones with only an action and no key) now have centered text by default It is now possible to override UITableViewCellStyle without subclassing by using ""style"" keypath in field config Version 1.0.2 Fixed crash when attempting to set UITextInputTraits properties on a FXFormTextFieldCell Fixed potential crash when numeric field type is used with string properties Version 1.0.1 Subform FXFormController instances now correctly inherit registered cells from the parent controller Fields of type FXFormFieldOption with associated actions will now still be toggled before action fires Version 1.0 Initial release"
3286,"Google ()Google () ReadTheDocs : <https://google-styleguide.readthedocs.io/zh_CN/latest/>_ GitHub zh-google-styleguide <https://github.com/zh-google-styleguide/zh-google-styleguide>_ release <https://github.com/zh-google-styleguide/zh-google-styleguide/releases>_ .. note:: . Google , . Google , `Google Style Guide <https://github.com/google/styleguide>`_ : (). , . """" , "" (camelCase)"" """" """". Google . Google, , . : . Google C++ <https://google-styleguide.readthedocs.io/zh_CN/latest/google-cpp-styleguide/contents.html>_ . Google Objective-C <https://google-styleguide.readthedocs.io/zh_CN/latest/google-objc-styleguide/contents.html>_ . Google Python <https://google-styleguide.readthedocs.io/zh_CN/latest/google-python-styleguide/contents.html>_ . Google JavaScript <https://google-styleguide.readthedocs.io/zh_CN/latest/google-javascript-styleguide/contents.html>_ . Google Shell <https://google-styleguide.readthedocs.io/zh_CN/latest/google-shell-styleguide/contents.html>_ . Google JSON <https://github.com/darcyliu/google-styleguide/blob/master/JSONStyleGuide.md>_ reStructuredText , Sphinx HTML / CHM / PDF . cpplint <https://github.com/google/styleguide/tree/gh-pages/cpplint> - , google-c-style.el <https://raw.githubusercontent.com/google/styleguide/gh-pages/google-c-style.el>, Google Emacs . , JavaScript Style Guide <http://google.github.io/styleguide/javascriptguide.xml> XML Document Format Style Guide <http://google.github.io/styleguide/xmlstyle.html>, Yang.Y <https://github.com/yangyubo>_."
3231,"TensorFlow CNN for fast style transfer Fast Style Transfer in TensorFlow Add styles from famous paintings to any photo in a fraction of a second! You can even style videos! It takes 100ms on a 2015 Titan X to style the MIT Stata Center (1024680) like Udnie, by Francis Picabia. Our implementation is based off of a combination of Gatys' A Neural Algorithm of Artistic Style, Johnson's Perceptual Losses for Real-Time Style Transfer and Super-Resolution, and Ulyanov's Instance Normalization. Sponsorship Please consider sponsoring my work on this project! License Copyright (c) 2016 Logan Engstrom. Contact me for commercial use (or rather any use that is not academic research) (email: engstrom at my university's domain dot edu). Free for research use, as long as proper attribution is given and this copyright notice is retained. Video Stylization Here we transformed every frame in a video, then combined the results. Click to go to the full demo on YouTube! The style here is Udnie, as above. See how to generate these videos here! Image Stylization We added styles from various paintings to a photo of Chicago. Click on thumbnails to see full applied style images. Implementation Details Our implementation uses TensorFlow to train a fast style transfer network. We use roughly the same transformation network as described in Johnson, except that batch normalization is replaced with Ulyanov's instance normalization, and the scaling/offset of the output tanh layer is slightly different. We use a loss function close to the one described in Gatys, using VGG19 instead of VGG16 and typically using ""shallower"" layers than in Johnson's implementation (e.g. we use relu1_1 rather than relu1_2). Empirically, this results in larger scale style features in transformations. Virtual Environment Setup (Anaconda) - Windows/Linux Tested on | Spec | | |-----------------------------|-------------------------------------------------------------| | Operating System | Windows 10 Home | | GPU | Nvidia GTX 2080 TI | | CUDA Version | 11.0 | | Driver Version | 445.75 | Step 1Install Anaconda https://docs.anaconda.com/anaconda/install/ Step 2Build a virtual environment Run the following commands in sequence in Anaconda Prompt: Run the following command in the notebook or just conda install the package: Follow the commands below to use fast-style-transfer Documentation Training Style Transfer Networks Use style.py to train a new style transfer network. Run python style.py to view all the possible parameters. Training takes 4-6 hours on a Maxwell Titan X. More detailed documentation here. Before you run this, you should run setup.sh. Example usage: python style.py --style path/to/style/img.jpg \ --checkpoint-dir checkpoint/path \ --test path/to/test/img.jpg \ --test-dir path/to/test/dir \ --content-weight 1.5e1 \ --checkpoint-iterations 1000 \ --batch-size 20 Evaluating Style Transfer Networks Use evaluate.py to evaluate a style transfer network. Run python evaluate.py to view all the possible parameters. Evaluation takes 100 ms per frame (when batch size is 1) on a Maxwell Titan X. More detailed documentation here. Takes several seconds per frame on a CPU. Models for evaluation are located here. Example usage: python evaluate.py --checkpoint path/to/style/model.ckpt \ --in-path dir/of/test/imgs/ \ --out-path dir/for/results/ Stylizing Video Use transform_video.py to transfer style into a video. Run python transform_video.py to view all the possible parameters. Requires ffmpeg. More detailed documentation here. Example usage: python transform_video.py --in-path path/to/input/vid.mp4 \ --checkpoint path/to/style/model.ckpt \ --out-path out/video.mp4 \ --device /gpu:0 \ --batch-size 4 Requirements You will need the following to run the above: - TensorFlow 0.11.0 - Python 2.7.9, Pillow 3.4.2, scipy 0.18.1, numpy 1.11.2 - If you want to train (and don't want to wait for 4 months): - A decent GPU - All the required NVIDIA software to run TF on a GPU (cuda, etc) - ffmpeg 3.1.3 if you want to stylize video Citation Attributions/Thanks This project could not have happened without the advice (and GPU access) given by Anish Athalye. The project also borrowed some code from Anish's Neural Style Some readme/docs formatting was borrowed from Justin Johnson's Fast Neural Style The image of the Stata Center at the very beginning of the README was taken by Juan Paulo Related Work Michael Ramos ported this network to use CoreML on iOS"
1055,"iOS Objective-C headers as derived from runtime introspectionDynamically Generated iOS Headers Here are iOS Objective-C headers as derived from runtime introspection. The headers were generated using RuntimeBrowser for iPhone. Search You can search the headers with github search: https://github.com/search?type=Code&q=repo:nst/iOS-Runtime-Headers+hack Diffs You can compare versions based on their tags, see the tags page: $ git difftool 6.0 6.1 . Sample usage You can use the headers this way: NSBundle *b = [NSBundle bundleWithPath:@""/System/Library/PrivateFrameworks/FTServices.framework""]; BOOL success = [b load]; Class FTDeviceSupport = NSClassFromString(@""FTDeviceSupport""); id si = [FTDeviceSupport valueForKey:@""sharedInstance""]; NSLog(@""-- %@"", [si valueForKey:@""deviceColor""]); Timeline Green == public Red == private Blue == dylib The code to draw this picture is in https://github.com/nst/RuntimeBrowser/tree/master/tools/ios_headers_history. Nicolas Seriot"
1020,"Guard is a command line tool to easily handle events on file system modifications.Guard IMPORTANT: Please upgrade to Ruby >= 2.4 before installing Guard! To install for older versions, update Bundler at least 1.12: gem update bundler and Bundler should correctly resolve to earlier gems for your given Ruby version. Ruby 2.1 is officially outdated and unsupported! Ruby 2.2 is officially outdated and unsupported! Ruby 2.3 is officially outdated and unsupported! :exclamation: Guard is currently accepting more maintainers. Please read this if you're interested in joining the team. Guard automates various tasks by running custom rules whenever file or directories are modified. It's frequently used by software developers, web designers, writers and other specialists to avoid mundane, repetitive actions and commands such as ""relaunching"" tools after changing source files or configurations. Common use cases include: an IDE replacement, web development tools, designing ""smart"" and ""responsive"" build systems/workflows, automating various project tasks and installing/monitoring various system services. For a full categorized list of known Guard plugins, look here: https://github.com/guard/guard/wiki/Guard-Plugins If you have any questions about Guard or want to share some information with the Guard community, please go to one of the following places: Guard Wiki Google group. StackOverflow. IRC channel #guard (irc.freenode.net) for chatting. Before you file an issue, make sure you have read the known issues and file an issue sections that contains some important information. Features File system changes handled by our awesome Listen gem. Support for visual system notifications. Huge eco-system with more than 300 Guard plugins. Tested against the latest Ruby 2.4.x, 2.5.x, 2.6.x, JRuby & Rubinius. See .travis-ci.yml for the exact versions. Screencast Two nice screencasts are available to help you get started: Guard on RailsCast. Guard is Your Best Friend on Net Tuts+. Installation The simplest way to install Guard is to use Bundler. Add Guard (and any other dependencies) to a Gemfile in your projects root: then install it by running Bundler: Generate an empty Guardfile with: Run Guard through Bundler with: If you are on Mac OS X and have problems with either Guard not reacting to file changes or Pry behaving strange, then you should add proper Readline support to Ruby on macOS. Avoiding gem/dependency problems It's important that you always run Guard through Bundler to avoid errors. If you're getting sick of typing bundle exec all the time, try one of the following: (Recommended) Running bundle binstub guard will create bin/guard in your project, which means running bin/guard (tab completion will save you a key stroke or two) will have the exact same result as bundle exec guard. Or, you can alias be=""bundle exec"" in your .bashrc or similar and the execute only be guard. Protip: It will work for all comands executed in bundle exec context! Or, for RubyGems >= 2.2.0 (at least, though the more recent the better), simply set the RUBYGEMS_GEMDEPS environment variable to - (for autodetecting the Gemfile in the current or parent directories) or set it to the path of your Gemfile. (To upgrade RubyGems from RVM, use the rvm rubygems command). NOTE: this Rubygems feature is still under development still lacks many features of bundler Or, for RubyGems < 2.2.0 check out the Rubygems Bundler. Add Guard plugins Guard is now ready to use and you should add some Guard plugins for your specific use. Start exploring the many Guard plugins available by browsing the Guard organization on GitHub or by searching for guard- on RubyGems. When you have found a Guard plugin of your interest, add it to your Gemfile: See the init section of the Guard usage below to see how to install the supplied plugin template that you can install and to suit your needs. Usage Guard is run from the command line. Please open your terminal and go to your project work directory. Look here for a full list of Guard commands Start Just launch Guard inside your Ruby or Rails project with: Guard will look for a Guardfile or guardfile.rb in your current directory. If it does not find one, it will look in your $HOME directory for a .Guardfile. Please look here to see all the command line options for Guard Interactions Please read how to interact with Guard on the console and which signals Guard accepts Guardfile DSL For details on extending your Guardfile look at Guardfile examples or look at a list of commands Guardfile-DSL / Configuring-Guard Issues Before reporting a problem, please read how to File an issue. Development / Contributing See the Contributing Guide. Releasing Prerequisites You must have commit rights to the GitHub repository. You must have push rights for rubygems.org. How to release Determine which would be the correct next version number according to semver. Update the version in ./lib/guard/version.rb. Commit the version in a single commit, the message should be ""Bump VERSION to X.Y.Z"". Push and open a pull request. Once CI is green, merge the pull request. Pull the changes locally and run bundle exec rake release:full; this will tag, push to GitHub, publish to rubygems.org, and publish the release notes . Author Thibaud Guillaume-Gentil (@thibaudgg) Core Team R.I.P. :broken_heart: Michael Kessler. Rmy Coutable. Thibaud Guillaume-Gentil (@thibaudgg, thibaud.gg). Contributors https://github.com/guard/guard/graphs/contributors"
4422,"Sandbox for developing and testing UI components in isolation React Cosmos Sandbox for developing and testing UI components in isolation. Visual TDD. Develop one component at a time. Isolate the UI you're working on and iterate quickly. Reloading your whole app on every change is slowing you down! Component library. Bookmark component states, from blank states to edge cases. Your component library keeps you organized and provides a solid foundation of test cases. Open platform. React Cosmos can be used in powerful ways. Including snapshot and visual regression testing, as well as custom integrations tailored to your needs. Live demo Documentation Sponsor Why React Cosmos? React Cosmos Makes developers more productive Leads to high-quality, reusable UI components Makes it easy to share component libraries Helps with automated testing React Cosmos is An isolated component environment Simple, detail-oriented and battle-tested The result of over 5 years of fine-tuning React-only Compatible with other bundlers (aside from webpack) React Cosmos is not A style guide generator A documentation tool A testing framework Many other similar tools have emerged since React Cosmos was created. Choose wisely based on your unique needs and personal taste. A Brief History of React Cosmos 2014 Cosmos.js, autonomous components for scaling user interfaces | Reddit 2015 Can components be truly encapsulated? | React Europe 2016 Fighting for Component Independence | Medium 2017 UI Development Made Simple | JSHeroes 2019 React Cosmos 5 in 21 tweets | Twitter 2019 I made a tool for creating React components with visual TDD | SourceSort 2020 A development environment for ambitious developers | SurviveJS Credits Hi there. I'm Ovidiu, the core maintainer of React Cosmos. I spend ridiculous amounts of time perfecting this project because I love building user interfaces and making useful things. React Cosmos is licensed as MIT and will always be free. If you want to support me, however, become a Sponsor and ensure this journey continues! Special thanks to @maxsalven and @xavxyz for the long conversations and recurring support along the years. @catalinmiron, @flaviusone, @NiGhTTraX, @ovidiubute, @RadValentin, @tkjone, and all the other contributors. Kreativa Studio for the iconic Cosmonaut illustration. React Cosmos is still alive because of you! "
3620,"Modular search for Django.. image:: https://github.com/django-haystack/django-haystack/actions/workflows/test.yml/badge.svg :target: https://github.com/django-haystack/django-haystack/actions/workflows/test.yml .. image:: https://img.shields.io/pypi/v/django-haystack.svg :target: https://pypi.python.org/pypi/django-haystack/ .. image:: https://img.shields.io/pypi/pyversions/django-haystack.svg :target: https://pypi.python.org/pypi/django-haystack/ .. image:: https://img.shields.io/pypi/dm/django-haystack.svg :target: https://pypi.python.org/pypi/django-haystack/ .. image:: https://readthedocs.org/projects/django-haystack/badge/ :target: https://django-haystack.readthedocs.io/ .. image:: https://img.shields.io/badge/code%20style-black-000.svg :target: https://github.com/psf/black .. image:: https://img.shields.io/badge/%20imports-isort-%231674b1?style=flat&labelColor=ef8336 :target: https://pycqa.github.io/isort/ ======== Haystack ======== :author: Daniel Lindsley :date: 2013/07/28 Haystack provides modular search for Django. It features a unified, familiar API that allows you to plug in different search backends (such as Solr_, Elasticsearch_, Whoosh_, Xapian_, etc.) without having to modify your code. .. _Solr: http://lucene.apache.org/solr/ .. _Elasticsearch: https://www.elastic.co/products/elasticsearch .. _Whoosh: https://github.com/mchaput/whoosh/ .. _Xapian: http://xapian.org/ Haystack is BSD licensed, plays nicely with third-party app without needing to modify the source and supports advanced features like faceting, More Like This, highlighting, spatial search and spelling suggestions. You can find more information at http://haystacksearch.org/. Getting Help There is a mailing list (http://groups.google.com/group/django-haystack/) available for general discussion and an IRC channel (#haystack on irc.freenode.net). Documentation Development version: http://docs.haystacksearch.org/ v2.8.X: https://django-haystack.readthedocs.io/en/v2.8.1/ v2.7.X: https://django-haystack.readthedocs.io/en/v2.7.0/ v2.6.X: https://django-haystack.readthedocs.io/en/v2.6.0/ See the changelog <docs/changelog.rst>_ Requirements Haystack has a relatively easily-met set of requirements. Python 3.5+ A supported version of Django: https://www.djangoproject.com/download/#supported-versions Additionally, each backend has its own requirements. You should refer to https://django-haystack.readthedocs.io/en/latest/installing_search_engines.html for more details."
4652,"A command-line installer for Windows. Scoop Features | Installation | Documentation Scoop is a command-line installer for Windows. What does Scoop do? Scoop installs programs from the command line with a minimal amount of friction. It tries to eliminate things like: Permission popup windows GUI wizard-style installers Path pollution from installing lots of programs Unexpected side-effects from installing and uninstalling programs The need to find and install dependencies The need to perform extra setup steps to get a working program Scoop is very scriptable, so you can run repeatable setups to get your environment just the way you like, e.g.: If you've built software that you'd like others to use, Scoop is an alternative to building an installer (e.g. MSI or InnoSetup) you just need to zip your program and provide a JSON manifest that describes how to install it. Requirements Windows 7 SP1+ / Windows Server 2008+ PowerShell 5 (or later, include PowerShell Core) and .NET Framework 4.5 (or later) PowerShell must be enabled for your user account e.g. Set-ExecutionPolicy -ExecutionPolicy RemoteSigned -Scope CurrentUser Installation Run the following command from your PowerShell to install scoop to its default location (C:\Users\<user>\scoop) Once installed, run scoop help for instructions. The default setup is configured so all user installed programs and Scoop itself live in C:\Users\<user>\scoop. Globally installed programs (--global) live in C:\ProgramData\scoop. These settings can be changed through environment variables. Install Scoop to a Custom Directory by changing SCOOP Configure Scoop to install global programs to a Custom Directory by changing SCOOP_GLOBAL Documentation Multi-connection downloads with aria2 Scoop can utilize aria2 to use multi-connection downloads. Simply install aria2 through Scoop and it will be used for all downloads afterward. You can tweak the following aria2 settings with the scoop config command: aria2-enabled (default: true) aria2-retry-wait (default: 2) aria2-split (default: 5) aria2-max-connection-per-server (default: 5) aria2-min-split-size (default: 5M) Inspiration Homebrew sub What sort of apps can Scoop install? The apps that install best with Scoop are commonly called ""portable"" apps: i.e. compressed program files that run stand-alone when extracted and don't have side-effects like changing the registry or putting files outside the program directory. Since installers are common, Scoop supports them too (and their uninstallers). Scoop is also great at handling single-file programs and Powershell scripts. These don't even need to be compressed. See the runat package for an example: it's really just a GitHub gist. Support this project If you find Scoop useful and would like to support ongoing development and maintenance, here's how: PayPal (one-time donation) Known application buckets The following buckets are known to scoop: main - Default bucket for the most common (mostly CLI) apps extras - Apps that don't fit the main bucket's criteria games - Open source/freeware games and game-related tools nerd-fonts - Nerd Fonts nirsoft - A subset of the 250 Nirsoft apps java - Installers for Oracle Java, OpenJDK, Zulu, ojdkbuild, AdoptOpenJDK, Amazon Corretto, BellSoft Liberica & SapMachine jetbrains - Installers for all JetBrains utilities and IDEs nonportable - Non-portable apps (may require UAC) php - Installers for most versions of PHP versions - Alternative versions of apps found in other buckets The main bucket is installed by default. To add any of the other buckets, type: For example, to add the extras bucket, type: Other application buckets Many other application buckets hosted on Github can be found in the Scoop Directory."
1615,"json incremental diggerjid Json Incremental Digger It's a very simple tool. You can drill down JSON interactively by using filtering queries like jq. Suggestion and Auto completion of this tool will provide you a very comfortable JSON drill down. Demo Installation With homebrew (for Mac) With pkg (for FreeBSD) With scoop (for Windows) Other package management system Simply use ""jid"" command Build With homebrew (for Mac) With pkg (for FreeBSD) With scoop (for Windows) Other package management systems Jid can install by package management systems of below OS. Simply use ""jid"" command If you simply want to use jid command, please download binary from below. https://github.com/simeji/jid/releases Build Usage Quick start simple json example simple json example2 with initial query with curl simple json example Please execute the below command. then, jid will be running. You can dig JSON data incrementally. When you enter .bb.aaa[2], you will see the following. Then, you press Enter key and output [1,2] and exit. simple json example2 This json is used by demo section. With a initial query First argument of jid is initial query. (Use JSON same as Demo) with curl Sample for using RDAP data. Load JSON from a file Keymaps |key|description| |:-----------|:----------| |TAB / CTRL + I |Show available items and choice them| |CTRL + W |Delete from the cursor to the start of the word| |CTRL + U |Delete whole query| |CTRL + F / Right Arrow (:arrow_right:)|Move cursor a character to the right| |CTRL + B / Left Arrow (:arrow_left:)|Move cursor a character to the left| |CTRL + A|To the first character of the 'Filter'| |CTRL + E|To the end of the 'Filter'| |CTRL + J|Scroll json buffer 1 line downwards| |CTRL + K|Scroll json buffer 1 line upwards| |CTRL + G|Scroll json buffer to bottom| |CTRL + T|Scroll json buffer to top| |CTRL + N|Scroll json buffer 'Page Down'| |CTRL + P|Scroll json buffer 'Page Up'| |CTRL + L|Change view mode whole json or keys (only object)| |ESC|Hide a candidate box| Option |option|description| |:-----------|:----------| |First argument ($1) | Initial query| |-h | print a help| |-help | print a help| |-version | print the version and exit| |-q | Output query mode (for jq)| |-M | monochrome output mode|"
1918,"Ruby JavaScript Opal Opal is a Ruby to JavaScript source-to-source compiler. It also has an implementation of the Ruby corelib and stdlib. Community: Code: Sponsors: Usage See the website for more detailed instructions and guides for Rails, jQuery, Sinatra, rack, CDN, etc. https://opalrb.com. Compiling Ruby code with the CLI (Command Line Interface) Contents of app.rb: Then from the terminal The resulting JavaScript file can be used normally from an HTML page: Be sure to set the page encoding to UTF-8 inside your <head> tag as follows: Just open this page in a browser and check the JavaScript console. Compiling Ruby code from Ruby Opal.compile is a simple interface to just compile a string of Ruby into a string of JavaScript code. Running this by itself is not enough; you need the opal runtime/corelib. Using Opal::Builder Opal::Builder can be used to build the runtime/corelib into a string. or to build an entire app including dependencies declared with require: Compiling Ruby code from HTML (or using it as you would with inline JavaScript) opal-parser allows you to eval Ruby code directly from your HTML (and from Opal) files without needing any other building process. So you can create a file like the one below, and start writing ruby for your web applications. Just open this page and check the JavaScript console. NOTE: Although this is possible, this is not really recommended for production and should only be used as a quick way to get your hands on opal. Running tests Setup the project: $ bin/setup The test suite can be run using: $ bundle exec rake This will command will run all RSpec and MSpec examples in sequence. Automated runs A Guardfile with decent mappings between specs and lib/corelib/stdlib files is in place. Run bundle exec guard -i to start guard. MSpec MSpec tests can be run with: $ rake mspec Alternatively, you can just load up a rack instance using rackup, and visit http://localhost:9292/ in any web browser. RSpec RSpec tests can be run with: $ rake rspec Code Overview What code is supposed to run where? lib/ code runs inside your Ruby env. It compiles Ruby to JavaScript. opal/ is the runtime+corelib for our implementation (runs in browser). stdlib/ is our implementation of Ruby's stdlib. It is optional (runs in browser). lib/ The lib directory holds the Opal parser/compiler used to compile Ruby into JavaScript. It is also built ready for the browser into opal-parser.js to allow compilation in any JavaScript environment. opal/ This directory holds the Opal runtime and corelib implemented in Ruby and JavaScript. stdlib/ Holds the stdlib currently supported by Opal. This includes Observable, StringScanner, Date, etc. Browser support Internet Explorer 11 Firefox (Current - 1) or Current Chrome (Current - 1) or Current Safari (Current - 1) or Current Opera (Current - 1) or Current Any problems encountered using the browsers listed above should be reported as bugs. (Current - 1) or Current denotes that we support the current stable version of the browser and the version that preceded it. For example, if the current version of a browser is 24.x, we support the 24.x and 23.x versions. 12.1x or (Current - 1) or Current denotes that we support Opera 12.1x as well as the last 2 versions of Opera. For example, if the current Opera version is 20.x, then we support Opera 12.1x, 19.x and 20.x but not Opera 15.x through 18.x. Contributors This project exists thanks to all the people who contribute. Backers Thank you to all our backers! [Become a backer] Sponsors Donations Support this project by becoming a sponsor. Your logo will show up here with a link to your website. [Become a sponsor] Sponsored Contributions License (The MIT License) Copyright (C) 2013-2021 by Adam Beynon and the Opal contributors Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the ""Software""), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
322,"Realm is a mobile database: a replacement for Core Data & SQLiteRealm is a mobile database that runs directly inside phones, tablets or wearables. This repository holds the source code for the iOS, macOS, tvOS & watchOS versions of Realm Swift & Realm Objective-C. Features Mobile-first: Realm is the first database built from the ground up to run directly inside phones, tablets and wearables. Simple: Data is directly exposed as objects and queryable by code, removing the need for ORM's riddled with performance & maintenance issues. Most of our users pick it up intuitively, getting simple apps up & running in minutes. Modern: Realm supports relationships, generics, vectorization and Swift. Fast: Realm is faster than even raw SQLite on common operations, while maintaining an extremely rich feature set. Getting Started Please see the detailed instructions in our docs to add Realm Objective-C or Realm Swift to your Xcode project. Documentation Realm Objective-C The documentation can be found at realm.io/docs/objc/latest. The API reference is located at realm.io/docs/objc/latest/api/. Realm Swift The documentation can be found at realm.io/docs/swift/latest. The API reference is located at realm.io/docs/swift/latest/api/. Getting Help Need help with your code?: Look for previous questions with therealm tag on Stack Overflow or ask a new question. For general discussion that might be considered too broad for Stack Overflow, use the Community Forum. Have a bug to report? Open a GitHub issue. If possible, include the version of Realm, a full log, the Realm file, and a project that shows the issue. Have a feature request? Open a GitHub issue. Tell us what the feature should do and why you want the feature. Building Realm In case you don't want to use the precompiled version, you can build Realm yourself from source. Prerequisites: Building Realm requires Xcode 11.x or newer. Building Realm documentation requires jazzy Once you have all the necessary prerequisites, building Realm.framework just takes a single command: sh build.sh build. You'll need an internet connection the first time you build Realm to download the core binary. Run sh build.sh help to see all the actions you can perform (build ios/osx, generate docs, test, etc.). Contributing See CONTRIBUTING.md for more details! This project adheres to the Contributor Covenant Code of Conduct. By participating, you are expected to uphold this code. Please report unacceptable behavior to info@realm.io. License Realm Objective-C & Realm Swift are published under the Apache 2.0 license. Realm Core is also published under the Apache 2.0 license and is available here. This product is not being made available to any person located in Cuba, Iran, North Korea, Sudan, Syria or the Crimea region, or to any other person that is not eligible to receive the product under U.S. law. Feedback If you use Realm and are happy with it, all we ask is that you please consider sending out a tweet mentioning @realm to share your thoughts! And if you don't like it, please let us know what you would like improved, so we can fix it!"
538,"High performance, full-stack PHP framework delivered as a C extension.Phalcon Framework Phalcon is an open source web framework delivered as a C extension for the PHP language providing high performance and lower resource consumption. A big thank you to our Backers; you rock! Getting Started Phalcon is written in Zephir/C with platform independence in mind. As a result, Phalcon is available on Microsoft Windows, GNU/Linux, FreeBSD and MacOS. You can either download a binary package for the system of your choice or build it from source. NOTE: Phalcon requires the PSR PHP extension to be installed and enabled. Installation For detailed installation instructions you can check our installation page in the docs. Generating API Documentation Generating new documentation files for docs repository can be done using the script in tests/__config/generate-api-docs.php. Steps: - Clone the phalcon repo - Checkout the tag you would like to generate docs for. - Run php tests/__config/generate-api-docs.php - The files *.md files in nikos/api/ will contain the documentation - For publishing to the Phalcon website this repo is used. Links General Contributing to Phalcon Official Documentation Zephir - The language Phalcon is written on Incubator - Community driven plugins and classes extending the framework (written in PHP) Support Forum Discord Stack Overflow Social Media Telegram Gab Parler MeWe Facebook Twitter Sponsors Become a sponsor and get your logo on our README on Github with a link to your site. [Become a sponsor] Backers Support us with a monthly donation and help us continue our activities. [Become a backer] License Phalcon is open source software licensed under the BSD 3-Clause License. Copyright 2011-present, Phalcon Team. See the LICENSE.txt file for more. Additional licenses of packages that Phalcon uses, is inspired by or has adapted is located in the 3rdparty/licenses directory."
3975,"A cross platform XAML framework for .NET About AvaloniaUI Avalonia is a cross-platform XAML-based UI framework providing a flexible styling system and supporting a wide range of Operating Systems such as Windows via .NET Framework and .NET Core, Linux via Xorg, macOS. Avalonia is ready for General-Purpose Desktop App Development. However, there may be some bugs and breaking changes as we continue along into this project's development. (Xaml Control Gallery) To see the status of some of our features, please see our Roadmap. You can also see what breaking changes we have planned and what our past breaking changes have been. Awesome Avalonia is community-curated list of awesome Avalonia UI tools, libraries, projects and resources. Go and see what people are building with Avalonia! Getting Started The Avalonia Visual Studio Extension contains project and control templates that will help you get started, or you can use the .NET Core CLI. For a starter guide see our documentation. Avalonia is delivered via NuGet package manager. You can find the packages here: https://www.nuget.org/packages/Avalonia/ Use these commands in the Package Manager console to install Avalonia manually: Showcase Examples of UIs built with Avalonia (Synfonia) (Xaml Control Gallery) (Xaml Control Gallery) (Xaml Control Gallery) JetBrains Rider JetBrains Rider now has official support for Avalonia. Code completion, inspections and refactorings are supported out of the box, for XAML previewer add https://plugins.jetbrains.com/plugins/dev/14839 to plugin repositories and install AvaloniaRider plugin. Bleeding Edge Builds We also have a nightly build which tracks the current state of master. Although these packages are less stable than the release on NuGet.org, you'll get all the latest features and bugfixes right away and many of our users actually prefer this feed! Documentation Documentation can be found on our website at https://avaloniaui.net/docs/. We also have a tutorial over there for newcomers. Building and Using See the build instructions here. Contributing Please read the contribution guidelines before submitting a pull request. Code of Conduct This project has adopted the code of conduct defined by the Contributor Covenant to clarify expected behavior in our community. For more information see the .NET Foundation Code of Conduct. Licence Avalonia is licenced under the MIT licence. Contributors This project exists thanks to all the people who contribute. [Contribute]. Backers Thank you to all our backers! [Become a backer] Sponsors Support this project by becoming a sponsor. Your logo will show up here with a link to your website. [Become a sponsor] .NET Foundation This project is supported by the .NET Foundation."
3240,"Get the password of the wifi you're on (bash)wifi-password People ask you for the Wi-Fi password. Answer quickly. macOS only. Windows version. How to use 1. Install it With bpkg: With Homebrew: With Antigen: Add antigen bundle rauchg/wifi-password to your .zshrc with your other antigen commands With Zgen Add zgen load rauchg/wifi-password to your .zshrc with your other zgen commands or with curl: If you don't have ~/bin in your $PATH, replace it with /usr/local/bin or similar. 2. Use it: To get the password for the WiFi you're currently logged onto: To get it for a specific SSID: To put it straight in your clipboard for pasting elsewhere (OS X only): License MIT"
4759,:computer: Data Structures and Algorithms in PythonAlgorithms in Python Implementations of a few algorithms and datastructures for fun and profit! Completed Karatsuba Multiplication Basic Sorting Rabin-Miller primality test Sieve of Eratosthenes for prime numbers Binary Search Counting Inversions in an array Selecting ith order statistic in an array Graph datastructure (directed & undirected) Graph Algos Topological Sorting Shortest hops DFS BFS Connected Components Dijkstra's Shortest Path - O(mlogn) Prim's Minimum Cost Spanning Tree - O(mlogn) Kruskal's Minimum Spanning Tree - O(mlogn) Max k Clustering Bellman Ford Floyd Warshall Johnson's Algorithm Heap datastructure Max heaps Min heaps (priority queue) Heapsort Job Scheduling UnionFind Data Structure Binary Search Tree Kandane's Algorithm Knapsack Problem (0/1 and unbounded) Longest Increasing Subsequence Longest Common Subsequence Prefix Tries Stack ADT (with example problems) String Reverse Parenthesis Matching Infix to Postfix Modular exponentiation Modular multiplicative inverse Tests python -m tests.graph_test python -m tests.digraph_test python -m tests.graph_algorithms_test python -m tests.heap_test python -m tests.unionfind_test python -m tests.singly_linked_list_test python -m tests.modular_exponentiation_test python -m tests.modular_multiplicative_inverse_test
2331,"Safely store secrets in Git/Mercurial/SubversionBlackBox Safely store secrets in a VCS repo (i.e. Git, Mercurial, Subversion or Perforce). These commands make it easy for you to Gnu Privacy Guard (GPG) encrypt specific files in a repo so they are ""encrypted at rest"" in your repository. However, the scripts make it easy to decrypt them when you need to view or edit them, and decrypt them for use in production. Originally written for Puppet, BlackBox now works with any Git or Mercurial repository. A slide presentation about an older release is on SlideShare. Join our mailing list: https://groups.google.com/d/forum/blackbox-project Table of Contents BlackBox Table of Contents Overview Why is this important? Installation Instructions Commands Compatibility How is the encryption done? What does this look like to the typical user? Configuration Management How to use the secrets with Ansible? How to use the secrets with Puppet? Entire files Small strings File Management How to enroll a new file into the system? How to remove a file from the system? User Management How to indoctrinate a new user into the system? How to remove a user from the system? Repo Management Enabling BlackBox For a Repo Set up automated users or role accounts Replacing expired keys Some common errors Using BlackBox on Windows Using BlackBox without a repo Some Subversion gotchas Using Blackbox when gpg2 is installed next to gpg How to submit bugs or ask questions? Developer Info Alternatives License Overview Suppose you have a VCS repository (i.e. a Git or Mercurial repo) and certain files contain secrets such as passwords or SSL private keys. Often people just store such files ""and hope that nobody finds them in the repo"". That's not safe. With BlackBox, those files are stored encrypted using GPG. Access to the VCS repo without also having the right GPG keys makes it worthless to have the files. As long as you keep your GPG keys safe, you don't have to worry about storing your VCS repo on an untrusted server. Heck, even if you trust your server, now you don't have to trust the people that do backups of that server, or the people that handle the backup tapes! Rather than one GPG passphrase for all the files, each person with access has their own GPG keys in the system. Any file can be decrypted by anyone with their GPG key. This way, if one person leaves the company, you don't have to communicate a new password to everyone with access. Simply disable the one key that should no longer have access. The process for doing this is as easy as running 2 commands (1 to disable their key, 1 to re-encrypt all files.) Automated processes often need access to all the decrypted files. This is easy too. For example, suppose Git is being used for Puppet files. The master needs access to the decrypted version of all the files. Simply set up a GPG key for the Puppet master (or the role account that pushes new files to the Puppet master) and have that user run blackbox_postdeploy after any files are updated. Getting started If you don't have a GPG key, set it up using instructions such as: Set up GPG key. \ Now you are ready to go. cd into a Git, Mercurial, Subversion or Perforce repository and run blackbox_initialize. If a file is to be encrypted, run blackbox_register_new_file and you are done. Add and remove keys with blackbox_addadmin and blackbox_removeadmin. To view and/or edit a file, run blackbox_edit; this will decrypt the file and open with whatever is specified by your $EDITOR environment variable. \ When you close the editor the file will automatically be encrypted again and the temporary plaintext file will be shredded. \ If you need to leave the file decrypted while you update you can use theblackbox_edit_start to decrypt the file and blackbox_edit_end when you want to ""put it back in the box."" Why is this important? OBVIOUSLY we don't want secret things like SSL private keys and passwords to be leaked. NOT SO OBVIOUSLY when we store ""secrets"" in a VCS repo like Git or Mercurial, suddenly we are less able to share our code with other people. Communication between subteams of an organization is hurt. You can't collaborate as well. Either you find yourself emailing individual files around (yuck!), making a special repo with just the files needed by your collaborators (yuck!!), or just deciding that collaboration isn't worth all that effort (yuck!!!). The ability to be open and transparent about our code, with the exception of a few specific files, is key to the kind of collaboration that DevOps and modern IT practitioners need to do. Installation Instructions The hard way (manual): Copy all the files in ""bin"" to your ""bin"". The hard way (automatic): make copy-install will copy the bin files into $PREFIX/bin, default is /usr/local (uninstall with make copy-uninstall). The symlinks way: make symlinks-install will make symlinks of the bin files into $PREFIX/bin, default is /usr/local (uninstall with make copy-uninstall) (useful when doing development) The MacPorts Way: sudo port install vcs_blackbox The Homebrew Way: brew install blackbox The RPM way: Check out the repo and make an RPM via make packages-rpm; now you can distribute the RPM via local methods. (Requires fpm.) The Debian/Ubuntu way: Check out the repo and make a DEB via make packages-deb; now you can distribute the DEB via local methods. (Requires fpm.) The Antigen Way: Add antigen bundle StackExchange/blackbox to your .zshrc The Zgen Way: Add zgen load StackExchange/blackbox to your .zshrc where you're loading your other plugins. The Nix Way: nix-env -i blackbox The Pkgsrc Way: pkgin in scm-blackbox Commands | Name: | Description: | |-------------------------------------|-------------------------------------------------------------------------| | blackbox_edit <file> | Decrypt, run $EDITOR, re-encrypt a file | | blackbox_edit_start <file> | Decrypt a file so it can be updated | | blackbox_edit_end <file> | Encrypt a file after blackbox_edit_start was used | | blackbox_cat <file> | Decrypt and view the contents of a file | | blackbox_view <file> | Like blackbox_cat but pipes to less or $PAGER | | blackbox_diff | Diff decrypted files against their original crypted version | | blackbox_initialize | Enable blackbox for a GIT or HG repo | | blackbox_register_new_file <file> | Encrypt a file for the first time | | blackbox_deregister_file <file> | Remove a file from blackbox | | blackbox_list_files | List the files maintained by blackbox | | blackbox_list_admins | List admins currently authorized for blackbox | | blackbox_decrypt_file <file> | Decrypt a file | | blackbox_decrypt_all_files | Decrypt all managed files (INTERACTIVE) | | blackbox_postdeploy | Decrypt all managed files (batch) | | blackbox_addadmin <gpg-key> | Add someone to the list of people that can encrypt/decrypt secrets | | blackbox_removeadmin <gpg-key> | Remove someone from the list of people that can encrypt/decrypt secrets | | blackbox_shred_all_files | Safely delete any decrypted files | | blackbox_update_all_files | Decrypt then re-encrypt all files. Useful after keys are changed | | blackbox_whatsnew <file> | show what has changed in the last commit for a given file | Compatibility BlackBox automatically determines which VCS you are using and does the right thing. It has a plug-in architecture to make it easy to extend to work with other systems. It has been tested to work with many operating systems. Version Control systems git -- The Git hg -- Mercurial svn -- SubVersion (Thanks, Ben Drasin!) p4 -- Perforce none -- The files can be decrypted outside of a repo if the .blackbox directory is intact Operating system CentOS / RedHat MacOS X Cygwin (Thanks, Ben Drasin!) See Note Below MinGW (git bash on windows) See Note Below NetBSD SmartOS To add or fix support for a VCS system, look for code at the end of bin/_blackbox_common.sh To add or fix support for a new operating system, look for the case statements in bin/_blackbox_common.sh and bin/_stack_lib.sh and maybe tools/confidence_test.sh Using BlackBox on Windows BlackBox can be used with Cygwin or MinGW. Protect the line endings BlackBox assumes that blackbox-admins.txt and blackbox-files.txt will have LF line endings. Windows users should be careful to configure Git or other systems to not convert or ""fix"" those files. If you use Git, add the following lines to your .gitattributes file: **/blackbox-admins.txt text eol=lf **/blackbox-files.txt text eol=lf The latest version of blackbox_initialize will create a .gitattributes file in the $BLACKBOXDATA directory (usually .blackbox) for you. Cygwin Cygwin support requires the following packages: Normal operation: gnupg git or mercurial or subversion or perforce (as appropriate) Development (if you will be adding code and want to run the confidence test) procps make git (the confidence test currently only tests git) MinGW MinGW (comes with Git for Windows) support requires the following: Normal operation: Git for Windows (not tested with Mercurial) Git Bash MINTTY returns a MinGW console. So when you install make sure you pick MINTTY instead of windows console. You'll be executing blackbox from the Git Bash prompt. You need at least version 2.8.1 of Git for Windows. GnuWin32 - needed for various tools not least of which is mktemp which is used by blackbox after downloading the install just provides you with some batch files. Because of prior issues at sourceforge and to make sure you get the latest version of each package the batch files handle the brunt of the work of getting the correct packages and installing them for you. from a windows command prompt run download.bat once it has completed run install.bat then add the path for those tools to your PATH (ex: PATH=%PATH%;c:\GnuWin32\bin) Development: unknown (if you develop Blackbox under MinGW, please let us know if any additional packages are required to run make test) How is the encryption done? GPG has many different ways to encrypt a file. BlackBox uses the mode that lets you specify a list of keys that can decrypt the message. If you have 5 people (""admins"") that should be able to access the secrets, each creates a GPG key and adds their public key to the keychain. The GPG command used to encrypt the file lists all 5 key names, and therefore any 1 key can decrypt the file. To remove someone's access, remove that admin's key name (i.e. email address) from the list of admins and re-encrypt all the files. They can still read the .gpg file (assuming they have access to the repository) but they can't decrypt it any more. What if they kept a copy of the old repo before you removed access? Yes, they can decrypt old versions of the file. This is why when an admin leaves the team, you should change all your passwords, SSL certs, and so on. You should have been doing that before BlackBox, right? Why don't you use symmetric keys? In other words, why mess with all this GPG key stuff and instead why don't we just encrypt all the files with a single passphrase. Yes, GPG supports that, but then we are managing a shared password, which is fraught with problems. If someone ""leaves the team"" we would have to communicate to everyone a new password. Now we just have to remove their key. This scales better. How do automated processes decrypt without asking for a password? GPG requires a passphrase on a private key. However, it permits the creation of subkeys that have no passphrase. For automated processes, create a subkey that is only stored on the machine that needs to decrypt the files. For example, at Stack Exchange, when our Continuous Integration (CI) system pushes a code change to our Puppet masters, they run blackbox_postdeploy to decrypt all the files. The user that runs this code has a subkey that doesn't require a passphrase. Since we have many masters, each has its own key. And, yes, this means our Puppet Masters have to be very secure. However, they were already secure because, like, dude... if you can break into someone's puppet master you own their network. If you use Puppet, why didn't you just use hiera-eyaml? There are 4 reasons: This works with any Git or Mercurial repo, even if you aren't using Puppet. hiera-eyaml decrypts ""on demand"" which means your Puppet Master now uses a lot of CPU to decrypt keys every time it is contacted. It slows down your master, which, in my case, is already slow enough. This works with binary files, without having to ASCIIify them and paste them into a YAML file. Have you tried to do this with a cert that is 10K long and changes every few weeks? Ick. hiera-eyaml didn't exist when I wrote this. What does this look like to the typical user? If you need to, start the GPG Agent: eval $(gpg-agent --daemon) Decrypt the file so it is editable: blackbox_edit_start FILENAME (You will need to enter your GPG passphrase.) Edit FILENAME as you desire: vim FILENAME Re-encrypt the file: blackbox_edit_end FILENAME Commit the changes. git commit -a or hg commit Wait... it can be even easier than that! Run blackbox_edit FILENAME, and it'll decrypt the file in a temp file and call $EDITOR on it, re-encrypting again after the editor is closed. How to use the secrets with Ansible? Ansible Vault provides functionality for encrypting both entire files and strings stored within files; however, keeping track of the password(s) required for decryption is not handled by this module. Instead one must specify a password file when running the playbook. Ansible example for password file: my_secret_password.txt.gpg Alternatively, one can specify this in the ANSIBLE_VAULT_PASSWORD_FILE environment variable. How to use the secrets with Puppet? Entire files: Entire files, such as SSL certs and private keys, are treated just like regular files. You decrypt them any time you push a new release to the puppet master. Puppet example for an encrypted file: secret_file.key.gpg Small strings: Small strings, such as passwords and API keys, are stored in a hiera yaml file, which you encrypt with blackbox_register_new_file. For example, we use a file called blackbox.yaml. You can access them using the hiera() function. Setup: Configure hiera.yaml by adding ""blackbox"" to the search hierarchy: In blackbox.yaml specify: In your Puppet Code, access the password as you would any hiera data: The variable $the_password will contain ""my secret password"" and can be used anywhere strings are used. How to enroll a new file into the system? If you need to, start the GPG Agent: eval $(gpg-agent --daemon) Add the file to the system: Multiple file names can be specified on the command line: Example 1: Register 2 files: Example 2: Register all the files in $DIR: How to remove a file from the system? This happens quite rarely, but we've got it covered: How to indoctrinate a new user into the system? FYI: Your repo may use keyrings/live instead of .blackbox. See ""Where is the configuration stored?"" .blackbox/blackbox-admins.txt is a file that lists which users are able to decrypt files. (More pedantically, it is a list of the GnuPG key names that the file is encrypted for.) To join the list of people that can edit the file requires three steps; You create a GPG key and add it to the key ring. Then, someone that already has access adds you to the system. Lastly, you should test your access. Step 1: NEW USER creates a GPG key pair on a secure machine and adds to public keychain. If you don't already have a GPG key, here's how to generate one: WARNING: New versions of GPG generate keys which are not understood by old versions of GPG. If you generate a key with a new version of GPG, this will cause problems for users of older versions of GPG. Therefore it is recommended that you either assure that everyone using Blackbox have the exact same version of GPG, or generate GPG keys using a version of GPG as old as the oldest version of GPG used by everyone using Blackbox. Pick defaults for encryption settings, 0 expiration. Pick a VERY GOOD passphrase. Store a backup of the private key someplace secure. For example, keep the backup copy on a USB drive that is locked in safe. Or, at least put it on a secure machine with little or no internet access, full-disk-encryption, etc. Your employer probably has rules about how to store such things. FYI: If generating the key is slow, this is usually because the system isn't generating enough entropy. Tip: Open another window on that machine and run this command: ls -R / Now that you have a GPG key, add yourself as an admin: ...where ""KEYNAME"" is the email address listed in the gpg key you created previously. For example: When the command completes successfully, instructions on how to commit these changes will be output. Run the command as given to commit the changes. It will look like this: Then push it to the repo: NOTE: Creating a Role Account? If you are adding the pubring.gpg of a role account, you can specify the directory where the pubring.gpg file can be found as a 2nd parameter: blackbox_addadmin puppetmaster@puppet-master-1.example.com /path/to/the/dir Step 2: EXISTING ADMIN adds new user to the system. Ask someone that already has access to re-encrypt the data files. This gives you access. They simply decrypt and re-encrypt the data without making any changes. Pre-check: Verify the new keys look good. For example, examine the key name (email address) to make sure it conforms to corporate standards. Import the keychain into your personal keychain and reencrypt: Push the re-encrypted files: Step 3: NEW USER tests. Make sure you can decrypt a file. (Suggestion: Keep a dummy file in VCS just for new people to practice on.) How to remove a user from the system? Simply run blackbox_removeadmin with their keyname then re-encrypt: Example: When the command completes, you will be given a reminder to check in the change and push it. Note that their keys will still be in the key ring, but they will go unused. If you'd like to clean up the keyring, use the normal GPG commands and check in the file. FYI: Your repo may use keyrings/live instead of .blackbox. See ""Where is the configuration stored?"" FYI: Your repo may use keyrings/live instead of .blackbox. See ""Where is the configuration stored?"" The key ring only has public keys. There are no secret keys to delete. Remember that this person did have access to all the secrets at one time. They could have made a copy. Therefore, to be completely secure, you should change all passwords, generate new SSL keys, and so on just like when anyone that had privileged access leaves an organization. Where is the configuration stored? .blackbox vs. keyrings/live Blackbox stores its configuration data in the .blackbox subdirectory. Older repos use keyrings/live. For backwards compatibility either will work. All documentation refers to .blackbox. You can convert an old repo by simply renaming the directory: There is no technical reason to convert old repos except that it is less confusing to users. This change was made in commit 60e782a0, release v1.20180615. The details: First Blackbox checks $BLACKBOXDATA. If this environment variable is set, this is the directory that will be used. If it lists a directory that does not exist, Blackbox will print an error and exit. If $BLACKBOXDATA is not set: (which is the typical use case) Blackbox will first try keyrings/live and use it if it exists. Otherwise the default .blackbox will be used. If .blackbox does not exist, Blackbox will print an error and exit. Enabling BlackBox For a Repo Overview: To add ""blackbox"" to a git or mercurial repo, you'll need to do the following: Run the initialize script. This adds a few files to your repo in a directory called "".blackbox"". For the first user, create a GPG key and add it to the key ring. Encrypt the files you want to be ""secret"". For any automated user (one that must be able to decrypt without a passphrase), create a GPG key and create a subkey with an empty passphrase. FYI: Your repo may use keyrings/live instead of .blackbox. See ""Where is the configuration stored?"" Run the initialize script. You'll want to include blackbox's ""bin"" directory in your PATH: If you're using antigen, adding antigen bundle StackExchange/blackbox to your .zshrc will download this repository and add it to your $PATH. For the first user, create a GPG key and add it to the key ring. Follow the instructions for ""How to indoctrinate a new user into the system?"". Only do Step 1. Once that is done, is a good idea to test the system by making sure a file can be added to the system (see ""How to enroll a new file into the system?""), and a different user can decrypt the file. Make a new file and register it: Decrypt it: Re-encrypt it: You should only see foo.txt.gpg as foo.txt should be gone. The next step is to commit foo.txt.gpg and make sure another user can check out, view, and change the contents of the file. That is left as an exercise for the reader. If you are feel like taking a risk, don't commit foo.txt.gpg and delete it instead. Set up automated users or ""role accounts"" i.e. This is how a Puppet Master can have access to the unencrypted data. FYI: Your repo may use keyrings/live instead of .blackbox. See ""Where is the configuration stored?"" An automated user (a ""role account"") is one that that must be able to decrypt without a passphrase. In general you'll want to do this for the user that pulls the files from the repo to the master. This may be automated with Jenkins CI or other CI system. GPG keys have to have a passphrase. However, passphrases are optional on subkeys. Therefore, we will create a key with a passphrase then create a subkey without a passphrase. Since the subkey is very powerful, it should be created on a very secure machine. There's another catch. The role account probably can't check files into Git/Mercurial. It probably only has read-only access to the repo. That's a good security policy. This means that the role account can't be used to upload the subkey public bits into the repo. Therefore, we will create the key/subkey on a secure machine as yourself. From there we can commit the public portions into the repo. Also from this account we will export the parts that the role account needs, copy them to where the role account can access them, and import them as the role account. ProTip: If asked to generate entropy, consider running this on the same machine in another window: sudo dd if=/dev/sda of=/dev/null For the rest of this doc, you'll need to make the following substitutions: ROLEUSER: svc_deployacct or whatever your role account's name is. NEWMASTER: the machine this role account exists on. SECUREHOST: The machine you use to create the keys. NOTE: This should be more automated/scripted. Patches welcome. On SECUREHOST, create the puppet master's keys: NOTE: Rather than a real email address, use the username@FQDN of the host the key will be used on. If you use this role account on many machines, each should have its own key. By using the FQDN of the host, you will be able to know which key is which. In this doc, we'll refer to username@FQDN as $KEYNAME Save the passphrase somewhere safe! Create a sub-key that has no password: Now securely export this directory to NEWMASTER: On NEWMASTER, receive the new GnuPG config: Back on SECUREHOST, add the new email address to .blackbox/blackbox-admins.txt: Verify that secring.gpg is a zero-length file. If it isn't, you have somehow added a private key to the keyring. Start over. Commit the recent changes: Regenerate all encrypted files with the new key: On NEWMASTER, import the keys and decrypt the files: ProTip: If you get ""gpg: decryption failed: No secret key"" then you forgot to re-encrypt blackbox.yaml with the new key. On SECUREHOST, securely delete your files: Also shred any other temporary files you may have made. Replacing expired keys If someone's key has already expired, blackbox will stop encrypting. You see this error: FYI: Your repo may use keyrings/live instead of .blackbox. See ""Where is the configuration stored?"" You can also detect keys that are about to expire by issuing this command and manually reviewing the ""expired:"" dates: gpg --homedir=.blackbox --list-keys or... list UIDs that will expire within 1 month from today: (Warning: this also lists keys without an expiration date) gpg --homedir=.blackbox --list-keys --with-colons --fixed-list-mode | grep ^uid | awk -F: '$6 < '$(( $(date +%s) + 2592000)) Here's how to replace the key: Step 1. Administrator removes expired user: Warning: This process will erase any unencrypted files that you were in the process of editing. Copy them elsewhere and restore the changes when done. Step 2. Expired user adds an updated key: Step 3. Administrator re-encrypts all files with the updated key of the expired user: Step 4: Clean up: Any files that were temporarily copied in the first step so as to not be overwritten can now be copied back and re-encrypted with the blackbox_edit_end command. (Thanks to @chishaku for finding a solution to this problem!) Configure git to show diffs in encrypted files It's possible to tell Git to decrypt versions of the file before running them through git diff or git log. To achieve this do: Add the following to .gitattributes at the top of the git repository: Add the following to .git/config: ` And now commands like git log -p file.gpg will show a nice log of the changes in the encrypted file. Some common errors gpg: filename: skipped: No public key -- Usually this means there is an item in .blackbox/blackbox-admins.txt that is not the name of the key. Either something invalid was inserted (like a filename instead of a username) or a user has left the organization and their key was removed from the keychain, but their name wasn't removed from the blackbox-admins.txt file. gpg: decryption failed: No secret key -- Usually means you forgot to re-encrypt the file with the new key. Error: can't re-encrypt because a key has expired. -- A user's key has expired and can't be used to encrypt any more. Follow the Replace expired keys tip. FYI: Your repo may use keyrings/live instead of .blackbox. See ""Where is the configuration stored?"" Using Blackbox without a repo If the files are copied out of a repo they can still be decrypted and edited. Obviously edits, changes to keys, and such will be lost if they are made outside the repo. Also note that commands are most likely to only work if run from the base directory (i.e. the parent to the .blackbox directory). The following commands have been tested outside a repo: blackbox_postdeploy blackbox_edit_start blackbox_edit_end Some Subversion gotchas The current implementation will store the blackbox in /keyrings at the root of the entire repo. This will create an issue between environments that have different roots (i.e. checking out / on development vs /releases/foo in production). To get around this, you can export BLACKBOX_REPOBASE=/path/to/repo and set a specific base for your repo. This was originally written for git and supports a two-phase commit, in which commit is a local commit and ""push"" sends the change upstream to the version control server when something is registered or deregistered with the system. The current implementation will immediately commit a file (to the upstream subversion server) when you execute a blackbox_* command. Using Blackbox when gpg2 is installed next to gpg In some situations, team members or automated roles need to install gpg 2.x alongside the system gpg version 1.x to catch up with the team's gpg version. On Ubuntu 16, you can which installs the binary gpg2. If you want to use this gpg2 binary, run every blackbox command with GPG=gpg2. For example: How to submit bugs or ask questions? We welcome questions, bug reports and feedback! The best place to start is to join the blackbox-project mailing list and ask there. Bugs are tracked here in Github. Please feel free to report bugs yourself. Developer Info Code submissions are gladly welcomed! The code is fairly easy to read. Get the code: Test your changes: This runs through a number of system tests. It creates a repo, encrypts files, decrypts files, and so on. You can run these tests to verify that the changes you made didn't break anything. You can also use these tests to verify that the system works with a new operating system. Please submit tests with code changes: The best way to change BlackBox is via Test Driven Development. First add a test to tools/confidence.sh. This test should fail, and demonstrate the need for the change you are about to make. Then fix the bug or add the feature you want. When you are done, make confidence should pass all tests. The PR you submit should include your code as well as the new test. This way the confidence tests accumulate as the system grows as we know future changes don't break old features. Note: The tests currently assume ""git"" and have been tested only on CentOS, Mac OS X, and Cygwin. Patches welcome! Alternatives Here are other open source packages that do something similar to BlackBox. If you like them better than BlackBox, please use them. git-crypt Pass Transcrypt Keyringer git-secret git-crypt has the best git integration. Once set up it is nearly transparent to the users. However it only works with git. License This content is released under the MIT License. See the LICENSE.txt file."
733,"RailsAdmin is a Rails engine that provides an easy-to-use interface for managing your dataRailsAdmin RailsAdmin is a Rails engine that provides an easy-to-use interface for managing your data. Announcements [Action required] Security issue RailsAdmin 2.0.1, 2.0.0 and up to 1.4.2 have been reported to have XSS vulnerability. We strongly recommend that you upgrade RailsAdmin to 2.0.2 (and higher) or 1.4.3 as soon as possible, if you are on those versions. See d72090ec for the detail. Getting started Check out the docs. Try the live demo. (Source code) Features CRUD any data with ease Custom actions Automatic form validation Search and filtering Export data to CSV/JSON/XML Authentication (via Devise or other) Authorization (via CanCanCan or Pundit) User action history (via PaperTrail) Supported ORMs ActiveRecord Mongoid Installation On your gemfile: gem 'rails_admin', '~> 2.0' Run bundle install Run rails g rails_admin:install Provide a namespace for the routes when asked Start a server rails s and administer your data at /admin. (if you chose default namespace: /admin) Configuration Global In config/initializers/rails_admin.rb: Details To begin with, you may be interested in setting up Devise, CanCanCan or Papertrail! Per model Details: Models, Groups, Fields Support If you have a question, please check this README, the wiki, and the list of known issues. If you still have a question, you can ask the official RailsAdmin mailing list. If you think you found a bug in RailsAdmin, you can submit an issue. Supported Ruby Versions This library aims to support and is tested against the following Ruby implementations: Ruby 2.2 Ruby 2.3 Ruby 2.4 Ruby 2.5 Ruby 2.6 Ruby 2.7 Ruby 3.0 JRuby"
1181,"Launcher for Windows, an alternative to Alfred and Launchy.WoX WoX is a launcher for Windows that simply works. It's an alternative to Alfred and Launchy. Features Search for everythingapplications, UWP, folders, files and more. Use pinyin to search for programs / wyy / wangyiyun Keyword plugin search g search_term Search youtube, google, twitter and many more Build custom themes at http://www.wox.one/theme/builder Install plugins from http://www.wox.one/plugin Portable mode Auto-complete text suggestion Highlighting of how results are matched during query search Installation Download from releases. Option 1: download Wox-Full-Installer.*.exe, which include all dependency. Option 2: download Wox.*.exe, which only include wox itself. You may install Everything and Python using below instruction. Windows may complain about security due to code not being signed. This will be fixed later. Requirements: .NET >= 4.6.2 or Windows version >= 10 1607 (Anniversary Update) [Optional] Integrate with everything Download .exe installer Use x64 if your windows is x64 Version >= 1.4.1 is supported [Optional] Use Python plugins install python3 add it to %PATH% or set it in WoX settings Usage Launch: Alt+Space Context Menu: Ctrl+O Cancel/Return: Esc Install/Uninstall plugin: type wpm install/uninstall Reset: delete %APPDATA%\Wox Log: %APPDATA%\Wox\Logs Contribution First and most importantly, star it! Send PR to master branch I'd appreciate if you could solve help_wanted labeled issue Build Install Visual Studio 2019 with .NET desktop development and Universal Windows Platform development Documentation Wiki Outdated doc: WoX doc. Just ask questions in issues for now. Thanks I would like to thank Raygun for their free crash reporting account. JetBrains for Open Source licence."
1533,"[]AndroidAndroidAutoLayout [DEPRECATED]Android AndroidAutoSize AndroidAutoSize AndroidAutoLayout 3AndroidAutoSize, , so, pxpx:pxGooglepx ok 768 * 1280 ; 1080 * 1920 dp dimens UI MMdp px ItemFrameLayoutViewmarginLeft,marginTop Android Studio autolayout Eclipse As AndroidManifest ActivityAutoLayoutActivity. sample AutoLayoutActivity LinearLayout -> AutoLinearLayout RelativeLayout -> AutoRelativeLayout FrameLayout -> AutoFrameLayout layout_width layout_height layout_margin(left,top,right,bottom) pading(left,top,right,bottom) textSize maxWidth, minWidth, maxHeight, minHeight ApplicationonCreate: PreView 768 * 1280 PreView UI PreView FrameLayoutLinearLayoutRelativeLayoutCardView""px""issue#21 ListViewRecyclerViewItem sampleListViewRecyclerViewsample ListView ListViewitempxAutoXXXLayoutListView AutoUtils.autoSize(convertView);demo RecyclerView LayoutInflater.from(mContext).inflate 1px app:layout_auto_basewidth=""height""height app:layout_auto_baseheight=""width""width app:layout_auto_basewidth=""height|padding"" |gravity width,height margin,marginLeft,marginTop,marginRight,marginBottom padding,paddingLeft,paddingTop,paddingRight,paddingBottom textSize. TextView textSize=""20px""TextView20pxtextmarginmarginBottom (1)org/gradle/api/publication/maven/internal/DefaultMavenFactory compile 'com.zhy:autolayout:x.x.x'moduleissue#74 (2)RadioGroup,ToolbarView autolayout-widget, PR autolayout-widgetps:copyautolayout-widget (3)java.lang.IllegalStateException: You need to use a Theme.AppCompat theme (or descendant) with this activity. AutoLayoutActivityAppCompatActivity Theme.AppCompattheme FragmentActivityAppCompatActivity MyAutoLayoutActivity extends Activity MyAutoLayoutActivity extends FragmentActivityAutoLayoutActivity MyAutoLayoutActivity psSDKAppCompatActivity. hongyangAndroid android-percent-support-lib-sample android-percent-support-extend Android "
1344,"Web typography at its finest: font-size and line-height based on element width.FlowType.JS Responsive web typography at its finest: font-size ~~and line-height~~ based on element width. Check out the demo site. What does FlowType.JS do? Ideally, the most legible typography contains between 45 and 75 characters per line. This is difficult to accomplish for all screen widths with only CSS media-queries. FlowType.JS eases this difficulty by changing the font-size ~~and line-height~~ based on a specific element's width. This allows for a perfect character count per line at any screen width. Options Thresholds Set minimum and maximum width thresholds to control the FlowType.JS magic within specific element widths. In this example, FlowType.JS will stop resizing text once the element width becomes smaller than 500px or larger than 1200px. Set minimum and maximum font-size thresholds to control the FlowType.JS magic within specific font sizes. In this example, FlowType.JS will stop resizing text once the font-size becomes smaller than 12px or larger than 40px. Font-size Set your own font-size using the fontRatio variable. When using fontRatio, increase the value to make the font smaller (and vice versa). Note: Because each font is different, you will need to ""tweak"" fontSize and ""eye ball"" your final product to make sure that your character count is within the recommended range. ~~Line-height (lineRatio) is set based on the fontRatio size, and defaults to 1.45 (the recommended line-height for maximum legibility).~~ See line-height below. Line-height In v1.0 of FlowType, we made the plugin set a specific line-height in pixels. We received many statements that setting a specific line-height is very dangerous. So, what did we do? We removed support for line-height in v1.1. What do I do now? It's quite simple: use unitless line-height in your CSS. It will automatically make changes based on the font size. Here's an example of what we suggest for line-height: Getting Started Step 1: Install FlowType.JS To use FlowType, you'll need to make sure both the jQuery and FlowType.JS scripts are included. Download FlowType.JS Download the latest release. Clone the repo: git clone https://github.com/simplefocus/FlowType.JS.git. Install with Bower: bower install Flowtype.js. Include jQuery and FlowType.JS scripts Step 2: Set Typography Base Prepare for FlowType.JS by making sure that the typography is flexible. Start with this CSS and make changes as necessary: Note: Setting a specific font-size in your CSS file will make sure that your website remains accessible in case your viewer has JavaScript disabled. These numbers will be overridden as FlowType.JS updates the font-size number inline. Step 3: Call FlowType.JS To begin the magic, simply call FlowType.JS before the close of your body tag: Step 4: Make Changes You will most likely want to change the default settings. To do so, simply include these options in your code and tweak away: Note: When using FlowType.JS, it will only perform it's magic on the element and child elements that are specified in the closing document's call. For example, if you have <p> inside of an <article> and you apply FlowType.JS to <p>, it will only update <p> and not <article>. But, if you apply FlowType.JS to <article>, the entire contents including <p> will be updated. We believe that this can be used to your advantage. So, tweak and change as you feel necessary: Brought to you by... This wonderful piece of magic has been brought to you by the team at Simple Focus. Follow Simple Focus on Twitter: @simplefocus. FlowType.JS is licensed under the MIT License. See the LICENSE.txt file for copy permission."
751," A Scope & Engine based, clean, powerful, customizable and sophisticated paginator for Ruby webappsKaminari A Scope & Engine based, clean, powerful, customizable and sophisticated paginator for modern web app frameworks and ORMs Features Clean Does not globally pollute Array, Hash, Object or AR::Base. Easy to Use Just bundle the gem, then your models are ready to be paginated. No configuration required. Don't have to define anything in your models or helpers. Simple Scope-based API Everything is method chainable with less ""Hasheritis"". You know, that's the modern Rails way. No special collection class or anything for the paginated values, instead using a general AR::Relation instance. So, of course you can chain any other conditions before or after the paginator scope. Customizable Engine-based I18n-aware Helpers As the whole pagination helper is basically just a collection of links and non-links, Kaminari renders each of them through its own partial template inside the Engine. So, you can easily modify their behaviour, style or whatever by overriding partial templates. ORM & Template Engine Agnostic Kaminari supports multiple ORMs (ActiveRecord, DataMapper, Mongoid, MongoMapper) multiple web frameworks (Rails, Sinatra, Grape), and multiple template engines (ERB, Haml, Slim). Modern The pagination helper outputs the HTML5 <nav> tag by default. Plus, the helper supports Rails unobtrusive Ajax. Supported Versions Ruby 2.0.0, 2.1.x, 2.2.x, 2.3.x, 2.4.x, 2.5.x, 2.6.x, 2.7.x, 2.8 Rails 4.1, 4.2, 5.0, 5.1, 5.2, 6.0, 6.1 Sinatra 1.4, 2.0 Haml 3+ Mongoid 3+ MongoMapper 0.9+ DataMapper 1.1.0+ Installation To install kaminari on the default Rails stack, just put this line in your Gemfile: Then bundle: If you're building non-Rails of non-ActiveRecord app and want the pagination feature on it, please take a look at Other Framework/Library Support section. Query Basics The page Scope To fetch the 7th page of users (default per_page is 25) Note: pagination starts at page 1, not at page 0 (page(0) will return the same results as page(1)). You can get page numbers or page conditions by using below methods. The per Scope To show a lot more users per each page (change the per_page value) Note that the per scope is not directly defined on the models but is just a method defined on the page scope. This is absolutely reasonable because you will never actually use per_page without specifying the page number. Keep in mind that per internally utilizes limit and so it will override any limit that was set previously. And if you want to get the size for all request records you can use total_count method: The padding Scope Occasionally you need to pad a number of records that is not a multiple of the page size. Note that the padding scope also is not directly defined on the models. Unscoping If for some reason you need to unscope page and per methods you can call except(:limit, :offset) Configuring Kaminari General Configuration Options You can configure the following default values by overriding these values using Kaminari.configure method. default_per_page # 25 by default max_per_page # nil by default max_pages # nil by default window # 4 by default outer_window # 0 by default left # 0 by default right # 0 by default page_method_name # :page by default param_name # :page by default params_on_first_page # false by default There's a handy generator that generates the default configuration file into config/initializers directory. Run the following generator command, then edit the generated file. Changing page_method_name You can change the method name page to bonzo or plant or whatever you like, in order to play nice with existing page method or association or scope or any other plugin that defines page method on your models. Configuring Default per_page Value for Each Model by paginates_per You can specify default per_page value per each model using the following declarative DSL. Configuring Max per_page Value for Each Model by max_paginates_per You can specify max per_page value per each model using the following declarative DSL. If the variable that specified via per scope is more than this variable, max_paginates_per is used instead of it. Default value is nil, which means you are not imposing any max per_page value. Configuring params_on_first_page when using ransack_memory If you are using the ransack_memory gem and experience problems navigating back to the previous or first page, set the params_on_first_page setting to true. Controllers The Page Parameter Is in params[:page] Typically, your controller code will look like this: Views The Same Old Helper Method Just call the paginate helper: This will render several ?page=N pagination links surrounded by an HTML5 <nav> tag. Helpers The paginate Helper Method This would output several pagination links such as First Prev ... 2 3 4 5 6 7 8 9 10 ... Next Last Specifying the ""inner window"" Size (4 by default) This would output something like ... 5 6 7 8 9 ... when 7 is the current page. Specifying the ""outer window"" Size (0 by default) This would output something like 1 2 3 ...(snip)... 18 19 20 while having 20 pages in total. Outer Window Can Be Separately Specified by left, right (0 by default) This would output something like 1 ...(snip)... 18 19 20 while having 20 pages in total. Changing the Parameter Name (:param_name) for the Links This would modify the query parameter name on each links. Extra Parameters (:params) for the Links This would modify each link's url_option. :controller and :action might be the keys in common. Ajax Links (crazy simple, but works perfectly!) This would add data-remote=""true"" to all the links inside. Specifying an Alternative Views Directory (default is kaminari/) This would search for partials in app/views/templates/kaminari. This option makes it easier to do things like A/B testing pagination templates/themes, using new/old templates at the same time as well as better integration with other gems such as cells. The link_to_next_page and link_to_previous_page (aliased to link_to_prev_page) Helper Methods This simply renders a link to the next page. This would be helpful for creating a Twitter-like pagination feature. The page_entries_info Helper Method This renders a helpful message with numbers of displayed vs. total entries. By default, the message will use the humanized class name of objects in collection: for instance, ""project types"" for ProjectType models. The namespace will be cut out and only the last name will be used. Override this with the :entry_name parameter: The rel_next_prev_link_tags Helper Method This renders the rel next and prev link tags for the head. The path_to_next_page Helper Method This returns the server relative path to the next page. The path_to_prev_page Helper Method This returns the server relative path to the previous page. I18n and Labels The default labels for 'first', 'last', 'previous', '...' and 'next' are stored in the I18n yaml inside the engine, and rendered through I18n API. You can switch the label value per I18n.locale for your internationalized application. Keys and the default values are the following. You can override them by adding to a YAML file in your Rails.root/config/locales directory. If you use non-English localization see i18n rules for changing one_page:display_entries block. Customizing the Pagination Helper Kaminari includes a handy template generator. To Edit Your Paginator Run the generator first, then edit the partials in your app's app/views/kaminari/ directory. For Haml/Slim Users You can use the html2haml gem or the html2slim gem to convert erb templates. The kaminari gem will automatically pick up haml/slim templates if you place them in app/views/kaminari/. Multiple Templates In case you need different templates for your paginator (for example public and admin), you can pass --views-prefix directory like this: that will generate partials in app/views/admin/kaminari/ directory. Themes The generator has the ability to fetch several sample template themes from the external repository (https://github.com/amatsuda/kaminari_themes) in addition to the bundled ""default"" one, which will help you creating a nice looking paginator. To see the full list of available themes, take a look at the themes repository, or just hit the generator without specifying THEME argument. Multiple Themes To utilize multiple themes from within a single application, create a directory within the app/views/kaminari/ and move your custom template files into that directory. Next, reference that directory when calling the paginate method: Customize away! Note: if the theme isn't present or none is specified, kaminari will default back to the views included within the gem. Paginating Without Issuing SELECT COUNT Query Generally the paginator needs to know the total number of records to display the links, but sometimes we don't need the total number of records and just need the ""previous page"" and ""next page"" links. For such use case, Kaminari provides without_count mode that creates a paginatable collection without counting the number of all records. This may be helpful when you're dealing with a very large dataset because counting on a big table tends to become slow on RDBMS. Just add .without_count to your paginated object: In your view file, you can only use simple helpers like the following instead of the full-featured paginate helper: Paginating a Generic Array object Kaminari provides an Array wrapper class that adapts a generic Array object to the paginate view helper. However, the paginate helper doesn't automatically handle your Array object (this is intentional and by design). Kaminari::paginate_array method converts your Array object into a paginatable Array that accepts page method. You can specify the total_count value through options Hash. This would be helpful when handling an Array-ish object that has a different count value from actual count such as RSolr search result or when you need to generate a custom pagination. For example: or, in the case of using an external API to source the page of data: Creating Friendly URLs and Caching Because of the page parameter and Rails routing, you can easily generate SEO and user-friendly URLs. For any resource you'd like to paginate, just add the following to your routes.rb: If you are using Rails 4 or later, you can simplify route definitions by using concern: This will create URLs like /my_resources/page/33 instead of /my_resources?page=33. This is now a friendly URL, but it also has other added benefits... Because the page parameter is now a URL segment, we can leverage on Rails page caching! NOTE: In this example, I've pointed the route to my :index action. You may have defined a custom pagination action in your controller - you should point action: :your_custom_action instead. Other Framework/Library Support The kaminari gem Technically, the kaminari gem consists of 3 individual components: kaminari-core: the core pagination logic kaminari-activerecord: Active Record adapter kaminari-actionview: Action View adapter So, bundling gem 'kaminari' is equivalent to the following 2 lines (kaminari-core is referenced from the adapters): For Other ORM Users If you want to use other supported ORMs instead of ActiveRecord, for example Mongoid, bundle its adapter instead of kaminari-activerecord. Kaminari currently provides adapters for the following ORMs: Active Record: https://github.com/kaminari/kaminari/tree/master/kaminari-activerecord (included in this repo) Mongoid: https://github.com/kaminari/kaminari-mongoid MongoMapper: https://github.com/kaminari/kaminari-mongo_mapper DataMapper: https://github.com/kaminari/kaminari-data_mapper (would not work on kaminari 1.0.x) For Other Web Framework Users If you want to use other web frameworks instead of Rails + Action View, for example Sinatra, bundle its adapter instead of kaminari-actionview. Kaminari currently provides adapters for the following web frameworks: Action View: https://github.com/kaminari/kaminari/tree/master/kaminari-actionview (included in this repo) Sinatra: https://github.com/kaminari/kaminari-sinatra Grape: https://github.com/kaminari/kaminari-grape For More Information Check out Kaminari recipes on the GitHub Wiki for more advanced tips and techniques. https://github.com/kaminari/kaminari/wiki/Kaminari-recipes Questions, Feedback Feel free to message me on Github (amatsuda) or Twitter (@a_matsuda) :) Contributing to Kaminari Fork, fix, then send a pull request. To run the test suite locally against all supported frameworks: To target the test suite against one framework: You can find a list of supported test tasks by running rake -T. You may also find it useful to run a specific test for a specific framework. To do so, you'll have to first make sure you have bundled everything for that configuration, then you can run the specific test: Copyright Copyright (c) 2011- Akira Matsuda. See MIT-LICENSE for further details."
1935,"Add-ons for openHAB 1.xopenHAB 1 Add-ons This repository contains add-ons that are using openHAB 1.x APIs. Earlier branches of this repo also contain the 1.x runtime and designer, which are no longer maintained. Note that all information about openHAB itself, the IDE setup and the contribution processes can be found in the openhab-distro project, so please go there for any further details!"
1255,"Collection of hacks and demos showing capability of HTML5 appsHTML5 Demos and Examples A collection of HTML5 experiments I've created, now open source and on GitHub, so please go ahead and help me hack this resource in to a wealth of demos that other authors can learn from. THIS PROJECT IS NOW RETIRED - YOU WILL FIND WORKING CODE, BUT IT IS NO LONGER LIVE OR MAINTAINED Aim If a user can hit view source on the demo, then we've done our job Where possible browser support should be named (FF3.5, etc) All content is open source and content is Creative Commons Share Alike 2.0 Individual demos, if authored by someone other than @rem can be credited as appropriate Creating new demos If the demo should take the default style - currently grey and dull - but it keeps the focus on the code ;) then follow these instructions. Otherwise, simply create the file in the root directory calling it [yourdemo].html and include it in the index.php. Instructions to creating a new demo: Create a .html in the /demos directory Use the following template (also a sample in /demos/template.html): <title><!-- Title of your demo, note this appears in the document title prefixed with ""HTML5 Demo:"" --></title> <style>/** any custom styles live here **/</style> <article><!-- any demo markup here --></article> <script> // your JavaScript </script> When requesting the demo, use html5demos.com/[yourdemo] and page.php will top and tail your page Any additional JavaScript libraries should be stored in the /js directory, assets, such as video and audio live in the /assets directory. That should be it. By submitting any code, you're also agreeing that your code is covered by the MIT-LICENSE that this project is covered by, and all content is covered by Creative Commons Share Alike 2.0 - as is all of this project: it's all about sharing baby! TODO Demos Required Microdata SVG More audio and video demos More introductions to canvas More event based stuff WebSockets (@rem - have a demo ready, but not the server side) Misc Clearer versioning on the demos, rather than ""All bar Opera"", should include last version to support feature, i.e. Opera 10.10b, Chrome 4 dev, Safari 4.0, etc."
1260,"a tiny and isomorphic URL router for JavaScriptSynopsis Director is a router. Routing is the process of determining what code to run when a URL is requested. Motivation A routing library that works in both the browser and node.js environments with as few differences as possible. Simplifies the development of Single Page Apps and Node.js applications. Dependency free (doesn't require jQuery or Express, etc). Status Features Client-Side Routing Server-Side HTTP Routing Server-Side CLI Routing Usage API Documentation Frequently Asked Questions Building client-side script Run the provided CLI script. Client-side Routing It simply watches the hash of the URL to determine what to do, for example: Client-side routing (aka hash-routing) allows you to specify some information about the state of the application using the URL. So that when the user visits a specific URL, the application can be transformed accordingly. Here is a simple example: Director works great with your favorite DOM library, such as jQuery. You can find a browser-specific build of director here which has all of the server code stripped away. Server-Side HTTP Routing Director handles routing for HTTP requests similar to journey or express: See Also: Auto-generated Node.js API Clients for routers using Director-Reflector RESTful Resource routing using restful HTML / Plain Text views of routers using Director-Explorer Server-Side CLI Routing Director supports Command Line Interface routing. Routes for cli options are based on command line input (i.e. process.argv) instead of a URL. Using the cli router, you can dispatch commands by passing them as a string. For example, if this example is in a file called foo.js: API Documentation Constructor Routing Table Adhoc Routing Scoped Routing Routing Events Configuration URL Matching URL Parameters Wildcard routes Route Recursion Async Routing Resources History API Instance Methods Attach Properties to this HTTP Streaming and Body Parsing Constructor Routing Table An object literal that contains nested route definitions. A potentially nested set of key/value pairs. The keys in the object literal represent each potential part of the URL. The values in the object literal contain references to the functions that should be associated with them. bark and meow are two functions that you have defined in your code. Adhoc Routing When developing large client-side or server-side applications it is not always possible to define routes in one location. Usually individual decoupled components register their own routes with the application router. We refer to this as Adhoc Routing. Lets take a look at the API director exposes for adhoc routing: Client-side Routing HTTP Routing Scoped Routing In large web appliations, both Client-side and Server-side, routes are often scoped within a few individual resources. Director exposes a simple way to do this for Adhoc Routing scenarios: Routing Events In director, a ""routing event"" is a named property in the Routing Table which can be assigned to a function or an Array of functions to be called when a route is matched in a call to router.dispatch(). on: A function or Array of functions to execute when the route is matched. before: A function or Array of functions to execute before calling the on method(s). Client-side only after: A function or Array of functions to execute when leaving a particular route. once: A function or Array of functions to execute only once for a particular route. Configuration Given the flexible nature of director there are several options available for both the Client-side and Server-side. These options can be set using the .configure() method: The options are: recurse: Controls route recursion. Use forward, backward, or false. Default is false Client-side, and backward Server-side. strict: If set to false, then trailing slashes (or other delimiters) are allowed in routes. Default is true. async: Controls async routing. Use true or false. Default is false. delimiter: Character separator between route fragments. Default is /. notfound: A function to call if no route is found on a call to router.dispatch(). on: A function (or list of functions) to call on every call to router.dispatch() when a route is found. before: A function (or list of functions) to call before every call to router.dispatch() when a route is found. Client-side only resource: An object to which string-based routes will be bound. This can be especially useful for late-binding to route functions (such as async client-side requires). after: A function (or list of functions) to call when a given route is no longer the active route. html5history: If set to true and client supports pushState(), then uses HTML5 History API instead of hash fragments. See History API for more information. run_handler_in_init: If html5history is enabled, the route handler by default is executed upon Router.init() since with real URIs the router can not know if it should call a route handler or not. Setting this to false disables the route handler initial execution. convert_hash_in_init: If html5history is enabled, the window.location hash by default is converted to a route upon Router.init() since with canonical URIs the router can not know if it should convert the hash to a route or not. Setting this to false disables the hash conversion on router initialisation. URL Matching Routes can sometimes become very complex, simple/:tokens don't always suffice. Director supports regular expressions inside the route names. The values captured from the regular expressions are passed to your listener function. URL Parameters When you are using the same route fragments it is more descriptive to define these fragments by name and then use them in your Routing Table or Adhoc Routes. Consider a simple example where a userId is used repeatedly. Wildcard routes It is possible to define wildcard routes, so that /foo and /foo/a/b/c routes to the same handler, and gets passed """" and ""a/b/c"" respectively. Route Recursion Can be assigned the value of forward or backward. The recurse option will determine the order in which to fire the listeners that are associated with your routes. If this option is NOT specified or set to null, then only the listeners associated with an exact match will be fired. No recursion, with the URL /dog/angry Recursion set to backward, with the URL /dog/angry Recursion set to forward, with the URL /dog/angry Breaking out of recursion, with the URL /dog/angry Async Routing Before diving into how Director exposes async routing, you should understand Route Recursion. At it's core route recursion is about evaluating a series of functions gathered when traversing the Routing Table. Normally this series of functions is evaluated synchronously. In async routing, these functions are evaluated asynchronously. Async routing can be extremely useful both on the client-side and the server-side: Client-side: To ensure an animation or other async operations (such as HTTP requests for authentication) have completed before continuing evaluation of a route. Server-side: To ensure arbitrary async operations (such as performing authentication) have completed before continuing the evaluation of a route. The method signatures for route functions in synchronous and asynchronous evaluation are different: async route functions take an additional next() callback. Synchronous route functions Asynchronous route functions Resources Available on the Client-side only. An object literal containing functions. If a host object is specified, your route definitions can provide string literals that represent the function names inside the host object. A host object can provide the means for better encapsulation and design. History API Available on the Client-side only. Director supports using HTML5 History API instead of hash fragments for navigation. To use the API, pass {html5history: true} to configure(). Use of the API is enabled only if the client supports pushState(). Using the API gives you cleaner URIs but they come with a cost. Unlike with hash fragments your route URIs must exist. When the client enters a page, say http://foo.com/bar/baz, the web server must respond with something meaningful. Usually this means that your web server checks the URI points to something that, in a sense, exists, and then serves the client the JavaScript application. If you're after a single-page application you can not use plain old <a href=""/bar/baz""> tags for navigation anymore. When such link is clicked, web browsers try to ask for the resource from server which is not of course desired for a single-page application. Instead you need to use e.g. click handlers and call the setRoute() method yourself. Attach Properties To this Available in the http router only. Generally, the this object bound to route handlers, will contain the request in this.req and the response in this.res. One may attach additional properties to this with the router.attach method: This API may be used to attach convenience methods to the this context of route handlers. HTTP Streaming and Body Parsing When you are performing HTTP routing there are two common scenarios: Buffer the request body and parse it according to the Content-Type header (usually application/json or application/x-www-form-urlencoded). Stream the request body by manually calling .pipe or listening to the data and end events. By default director.http.Router() will attempt to parse either the .chunks or .body properties set on the request parameter passed to router.dispatch(request, response, callback). The router instance will also wait for the end event before firing any routes. Default Behavior In flatiron, director is used in conjunction with union which uses a BufferedStream proxy to the raw http.Request instance. union will set the req.chunks property for you and director will automatically parse the body. If you wish to perform this buffering yourself directly with director you can use a simple request handler in your http server: Streaming Support If you wish to get access to the request stream before the end event is fired, you can pass the { stream: true } options to the route. Instance methods configure(options) options {Object}: Options to configure this instance with. Configures the Router instance with the specified options. See Configuration for more documentation. param(token, matcher) token {string}: Named parameter token to set to the specified matcher matcher {string|Regexp}: Matcher for the specified token. Adds a route fragment for the given string token to the specified regex matcher to this Router instance. See URL Parameters for more documentation. on(method, path, route) method {string}: Method to insert within the Routing Table (e.g. on, get, etc.). path {string}: Path within the Routing Table to set the route to. route {function|Array}: Route handler to invoke for the method and path. Adds the route handler for the specified method and path within the Routing Table. path(path, routesFn) path {string|Regexp}: Scope within the Routing Table to invoke the routesFn within. routesFn {function}: Adhoc Routing function with calls to this.on(), this.get() etc. Invokes the routesFn within the scope of the specified path for this Router instance. dispatch(method, path[, callback]) method {string}: Method to invoke handlers for within the Routing Table path {string}: Path within the Routing Table to match callback {function}: Invoked once all route handlers have been called. Dispatches the route handlers matched within the Routing Table for this instance for the specified method and path. mount(routes, path) routes {object}: Partial routing table to insert into this instance. path {string|Regexp}: Path within the Routing Table to insert the routes into. Inserts the partial Routing Table, routes, into the Routing Table for this Router instance at the specified path. Instance methods (Client-side only) init([redirect]) redirect {String}: This value will be used if '/#/' is not found in the URL. (e.g., init('/') will resolve to '/#/', init('foo') will resolve to '/#foo'). Initialize the router, start listening for changes to the URL. getRoute([index]) index {Number}: The hash value is divided by forward slashes, each section then has an index, if this is provided, only that section of the route will be returned. Returns the entire route or just a section of it. setRoute(route) route {String}: Supply a route value, such as home/stats. Set the current route. setRoute(start, length) start {Number} - The position at which to start removing items. length {Number} - The number of items to remove from the route. Remove a segment from the current route. setRoute(index, value) index {Number} - The hash value is divided by forward slashes, each section then has an index. value {String} - The new value to assign the the position indicated by the first parameter. Set a segment of the current route. Frequently Asked Questions What About SEO? Is using a Client-side router a problem for SEO? Yes. If advertising is a requirement, you are probably building a ""Web Page"" and not a ""Web Application"". Director on the client is meant for script-heavy Web Applications. LICENSE: MIT Author: Charlie Robbins Contributors: Paolo Fragomeni"
2164,"A set of Swift extensions for standard types and classes.ExSwift Set of Swift extensions for standard types and classes. Installation Because of Xcode errors it's not possible to integrate this project with Cocoapods or as Embedded Framework. Read more at Dev Forum Use submodule and copy source code Add ExSwift as a submodule Open the ExSwift project folder, and drag ExSwift sub folder with source code into the file navigator of your Xcode project. Make sure you select add to target Use it Contents ExSwift extensions Array Instance Methods Class Methods Operators Int Properties Instance Methods Class Methods Float Instance Methods Class Methods String Properties Instance Methods Class Methods Operators Range Instance Methods Class Methods Operators Dictionary Instance Methods Operators NSArray Instance Methods SequenceOf Instance Methods Double Instance Methods Class Methods NSDate Instance Methods Operators Utilities Class Methods Operators Extensions Array Examples in the Wiki Instance Methods Name | Signature ---- | --------- first|first () -> Element? last|last () -> Element? get|get (index: Int) -> Element? remove|remove <U: Equatable> (element: U) at|at (indexes: Int...) -> Array take|take (n: Int) -> Array takeWhile|takeWhile (condition: (Element) -> Bool) -> Array takeFirst|takeFirst (condition: (Element) -> Bool) -> Element? tail|tail (n: Int) -> Array skip|skip (n: Int) -> Array skipWhile|skipWhile (condition: (Element) -> Bool) -> Array contains|contains <T: Equatable> (item: T...) -> Bool difference|difference <T: Equatable> (values: [T]...) -> [T] intersection|intersection <U: Equatable> (values: [U]...) -> Array union|union <U: Equatable> (values: [U]...) -> Array unique|unique <T: Equatable> () -> [T] indexOf|indexOf <T: Equatable> (item: T) -> Int? indexOf|indexOf (condition: Element -> Bool) -> Int? lastIndexOf|lastIndexOf <T: Equatable> (item: T) -> Int? zip|zip (arrays: Array<Any>...) -> [[Any?]] partition|partition (var n: Int, var step: Int? = nil) -> [Array]partition (var n: Int, var step: Int? = nil, pad: Element[]?) -> [Array] partitionAll|partitionAll (var n: Int, var step: Int? = nil) -> [Array] partitionBy|partitionBy <T: Equatable> (cond: (Element) -> T) -> [Array] shuffle|shuffle () shuffled|shuffled () -> Array sample (random)|sample (size n: Int = 1) -> [T] max|max <T: Comparable> () -> T min|min <T: Comparable> () -> T each|each (call: (Element) -> ())each (call: (Int, Element) -> ()) eachRight|eachRight (call: (Element) -> ())eachRight (call: (Int, Element) -> ()) any|any (call: (Element) -> Bool) -> Bool all|all (call: (Element) -> Bool) -> Bool reject|reject (exclude: (Element -> Bool)) -> Array pop|pop() -> Element push|push(newElement: Element) shift|shift() -> Element unshift|unshift(newElement: Element) insert|insert (newArray: Array, atIndex: Int) groupBy|groupBy <U> (groupingFunction group: (Element) -> (U)) -> [U: Array] countBy|countBy <U> (groupingFunction group: (Element) -> (U)) -> [U: Int] countWhere|countWhere (test: (Element) -> Bool) -> Int reduce|reduce (combine: (Element, Element) -> Element) -> Element? reduceRight|reduceRight <U>(initial: U, combine: (U, Element) -> U) -> U mapFilter|mapFilter <V> (mapFunction map: (Element) -> (V)?) -> [V] implode|implode <C: ExtensibleCollection> (separator: C) -> C? flatten|flatten <OutType> () -> [OutType] flattenAny|flattenAny () -> [AnyObject] toDictionary|toDictionary <U> (keySelector:(Element) -> U) -> [U: Element] toDictionary|toDictionary <K, V> (transform: (Element) -> (key: K, value: V)?) -> [K: V] cycle|cycle (n: Int? = nil, block: (T) -> ()) bSearch|bSearch (block: (T) -> (Bool)) -> T? bSearch|bSearch (block: (T) -> (Int)) -> T? sortUsing|sortUsing<U:Comparable>(block: ((T) -> U)) -> [T] transposition|transposition (array: [[T]]) -> [[T]] permutation|permutation (length: Int) -> [[T]] repeatedPermutation|repeatedPermutation(length: Int) -> [[T]] combination|combination (length: Int) -> [[Element]] repeatedCombination|repeatedCombination (length: Int) -> [[Element]] Class Methods Name | Signatures ---- | ---------- range|range <U: ForwardIndex> (range: Range<U>) -> Array<U> Operators Name | Signature | Function ---- | --------- | -------- -|- <T: Equatable> (first: Array<T>, second: Array<T>) -> Array<T>|Difference -|- <T: Equatable> (first: Array<T>, second: T) -> Array<T>|Element removal &|& <T: Equatable> (first: Array<T>, second: Array<T>) -> Array<T>|Intersection ||| (first: Array, second: Array) -> Array|Union * Int|* <ItemType> (array: ItemType[], n: Int) -> [ItemType]|Returns a new array built by concatenating int copies of self * String|* (array: String[], separator: String) -> String|Equivalent to array.implode(String) [rangeAsArray: x..y][rangeAsArray: x...y]|subscript(#rangeAsArray: Range<Int>) -> Array|Returns the sub-array from index x to index y [x, y, ...]|subscript(first: Int, second: Int, rest: Int...) -> Array|Returns the items at x, y Int Examples in the Wiki Properties Name | ---- | NSTimeIntervalyears| NSTimeIntervalyear| NSTimeIntervaldays| NSTimeIntervalday| NSTimeIntervalhours| NSTimeIntervalhour| NSTimeIntervalminutes| NSTimeIntervalminute| NSTimeIntervalseconds| NSTimeIntervalsecond| Instance Methods Name | Signatures ---- | ---------- times|times <T> (call: (Int) -> T)times <T> (call: () -> T)times (call: () -> ()) isEven|isEven () -> Bool isOdd|idOdd () -> Bool upTo|upTo (limit: Int, call: (Int) -> ()) downTo|downTo (limit: Int, call: (Int) -> ()) clamp|clamp (range: Range<Int>) -> Intclamp (min: Int, max: Int) -> Int isIn|isIn (range: Range<Int>, strict: Bool = false) -> Bool digits|digits () -> Array<Int> abs|abs () -> Int gcd|gcd (n: Int) -> Int lcm|lcm (n: Int) -> Int Class Methods Name | Signatures ---- | ---------- random|random(min: Int = 0, max: Int) -> Int Float Examples in the Wiki Instance Methods Name | Signature ---- | --------- abs|abs () -> Float sqrt|sqrt () -> Float round|round () -> Float ceil|ceil () -> Float floor|floor () -> Float clamp|clamp (min: Float, _ max: Float) -> Float Class Methods Name | Signatures ---- | ---------- random|random(min: Float = 0, max: Float) -> Float String Examples in the Wiki Properties Name | ---- | length| capitalized| Instance Methods Name | Signature ---- | --------- explode|explode (separator: Character) -> [String] at|at (indexes: Int...) -> [String] matches|matches (pattern: String, ignoreCase: Bool = false) -> [NSTextCheckingResult]? insert|insert (index: Int, _ string: String) -> String ltrimmed|ltrimmed () -> String ltrimmed|ltrimmed (set: NSCharacterSet) -> String rtrimmed|rtrimmed () -> String rtrimmed|rtrimmed (set: NSCharacterSet) -> String trimmed|trimmed () -> String rtrimmed|rtrimmed (set: NSCharacterSet) -> String toDouble|toDouble() -> Double? toFloat|toFloat() -> Float? toUInt|toUInt() -> UInt? toBool|toBool() -> Bool? toDate|toDate(format : String? = ""yyyy-MM-dd"") -> NSDate? toDateTime|toDateTime(format : String? = ""yyyy-MM-dd hh-mm-ss"") -> NSDate? Class Methods Name | Signature ---- | --------- random|func random (var length len: Int = 0, charset: String = ""..."") -> String Operators Name | Signature ---- | --------- [x]|subscript(index: Int) -> String? [x..y][x...y]|subscript(range: Range<Int>) -> String [x, y, z]|subscript (indexes: Int...) -> [String] S * n|* (first: String, second: Int) -> String =~|=~ (string: String, pattern: String) -> Bool=~ (string: String, options: (pattern: String, ignoreCase: Bool)) -> Bool=~ (strings: [String], pattern: String) -> Bool=~ (strings: [String], options: (pattern: String, ignoreCase: Bool)) -> Bool |~||~ (string: String, pattern: String) -> Bool|~ (string: String, options: (pattern: String, ignoreCase: Bool)) -> Bool Range Examples in the Wiki Instance Methods Name | Signatures ---- | ---------- times|times (call: (T) -> ())times (call: () -> ()) each|each (call: (T) -> ()) toArray|toArray () -> [T] Class Methods Name | Signature ---- | --------- random|random (from: Int, to: Int) -> Range<Int> Operators Name | Signature|Function ---- | ---------|-------- =|== <U: ForwardIndex> (first: Range<U>, second: Range<U>) -> Bool|Compares 2 ranges Dictionary Examples in the Wiki Instance Methods Name | Signatures ---- | ---------- difference|difference <V: Equatable> (dictionaries: [Key: V]...) -> [Key: V] union|union (dictionaries: [Key: Value]...) -> [Key: Value] intersection|intersection <K, V where K: Equatable, V: Equatable> (dictionaries: [K: V]...) -> [K: V] has|has (key: Key) -> Bool map|map <K, V> (mapFunction map: (Key, Value) -> (K, V)) -> [K: V] mapFilter|mapFilter <K, V> (mapFunction map: (Key, Value) -> (K, V)?) -> [K: V] mapValues|mapValues <V> (mapFunction map: (Key, Value) -> (V)) -> [Key: V] mapFilterValues|mapFilterValues <V> (mapFunction map: (Key, Value) -> V?) -> [Key: V] each|each(eachFunction each: (Key, Value) -> ()) filter|filter(testFunction test: (Key, Value) -> Bool) -> [Key: Value] merge|merge (dictionaries: [Key: Value]...) -> [Key: Value] shift|shift () -> (Key, Value) groupBy|groupBy <T> (groupingFunction group: (Key, Value) -> (T)) -> [T: Array<Value>] countBy|countBy <T> (groupingFunction group: (Key, Value) -> (T)) -> [T: Int] countWhere|countWhere (test: (Key, Value) -> (Bool)) -> Int any|any (test: (Key, Value) -> (Bool)) -> Bool all|all (test: (Key, Value) -> (Bool)) -> Bool reduce|reduce <U> (initial: U, combine: (U, Element) -> U) -> U pick, at|pick (keys: [Key]) -> Dictionarypick (keys: Key...) -> Dictionaryat (keys: Key...) -> Dictionary toArray|toArray <V> (mapFunction map: (Key, Value) -> V) -> [V] Operators Name | Signature | Function ---- | --------- | -------- -|- <K, V: Equatable> (first: Dictionary<K, V>, second: Dictionary<K, V>) -> Dictionary<K, V>|Difference &|& <K, V: Equatable> (first: Dictionary<K, V>, second: Dictionary<K, V>) -> Dictionary<K, V>|Intersection ||| (first: Dictionary, second: Dictionary) -> Dictionary|Union NSArray Examples in the Wiki Instance Methods Name | Signatures ---- | ---------- cast|cast <OutType> () -> [OutType] flatten|flatten <OutType> () -> [OutType] flattenAny|flattenAny () -> [AnyObject] SequenceOf The following operations can be performed on sequences and are evaluated lazily. Each operation only takes the data it requires from the source sequence in order to return its result. The Sequence protocol cannot be extended, hence the following are extensions to SequenceOf. They can be used as follows: Instance Methods Name | Signatures ---- | ---------- first|first () -> T? any|any (call: (T) -> Bool) -> Bool get|get (index: Int) -> T? get|get (range: Range<Int>) -> SequenceOf<T> indexOf|indexOf <U: Equatable> (item: U) -> Int? filter|filter(include: (T) -> Bool) -> SequenceOf<T> reject|reject (exclude: (T -> Bool)) -> SequenceOf<T> skipWhile|skipWhile(condition:(T) -> Bool) -> SequenceOf<T> skip|skip (n:Int) -> SequenceOf<T> contains|contains<T:Equatable> (item: T) -> Bool take|take (n:Int) -> SequenceOf<T> takeWhile|takeWhile (condition:(T?) -> Bool) -> SequenceOf<T> Double Examples in the Wiki Instance Methods Name | Signature ---- | --------- abs|abs () -> Double sqrt|sqrt () -> Double round|round () -> Double ceil|ceil () -> Double floor|floor () -> Double clamp|clamp (min: Double, _ max: Double) -> Double roundToNearest|roundToNearest(increment: Double) -> Double Class Methods Name | Signatures ---- | ---------- random|random(min: Double = 0, max: Double) -> Double NSDate Properties Name | Signatures ---- | ---- year |Int month|Int weekday |Int weekMonth|Int days |Int hours|Int minutes |Int seconds| Int Instance Methods Name | Signatures ---- | ---------- add|add(seconds:Int=0, minutes:Int = 0, hours:Int = 0, days:Int = 0, weeks:Int = 0, months:Int = 0, years:Int = 0) -> NSDate addSeconds|addSeconds (seconds:Int) -> NSDate addMinutes|addMinutes (minute:Int) -> NSDate addHours|addHours(hours:Int) -> NSDate addDays|addDays(days:Int) -> NSDate addWeeks|addWeeks(weeks:Int) -> NSDate addMonths|addMonths(months:Int) -> NSDate addYears|addYears(years:Int) -> NSDate isAfter|isAfter(date: NSDate) -> Bool isBefore|isBefore(date: NSDate) -> Bool getComponent|getComponent (component : NSCalendarUnit) -> Int Operators Name | Signatures ---- | ---------- ==|==(lhs: NSDate, rhs: NSDate) -> Bool <|<(lhs: NSDate, rhs: NSDate) -> Bool >|>(lhs: NSDate, rhs: NSDate) -> Bool <=|<=(lhs: NSDate, rhs: NSDate) -> Bool >=|>=(lhs: NSDate, rhs: NSDate) -> Bool ==|==(lhs: NSDate, rhs: NSDate) -> Bool Utilities Examples in the Wiki Class Methods Name | Signatures ---- | ---------- after|after <P, T> (n: Int, function: P -> T) -> (P -> T?)func after <T> (n: Int, function: () -> T) -> (() -> T?) once|once <P, T> (function: P -> T) -> (P -> T?)once <T> (call: Void -> T) -> (Void -> T?) partial|partial <P, T> (function: (P...) -> T, _ parameters: P...) -> ((P...) -> T?) bind|bind <P, T> (function: (P...) -> T, _ parameters: P...) -> (() -> T) cached|cached <P, R> (function: P -> R) -> (P -> R)cached <P, R> (function: (P...) -> R) -> ((P...) -> R)cached <P, R> (function: (P...) -> R, hash: ((P...) -> P)) -> ((P...) -> R) Operators Name | Signatures ---- | ---------- <=>|<=> <T: Comparable>(lhs: T, rhs: T) -> Int To Do [X] Wiki [X] Xcode project for both iOS & OS X [X] Review code comments [ ] Example project [ ] Installation instructions [ ] Benchmark"
219,"A customizable life embetterment robot.Hubot Hubot is a framework to build chat bots, modeled after GitHub's Campfire bot of the same name, hubot. He's pretty cool. He's extendable with scripts and can work on many different chat services. This repository provides a library that's distributed by npm that you use for building your own bots. See the documentation for details on getting up and running with your very own robot friend. In most cases, you'll probably never have to hack on this repo directly if you are building your own bot. But if you do, check out CONTRIBUTING.md If you'd like to chat with Hubot users and developers, join us on Slack. License See the LICENSE file for license rights and limitations (MIT)."
4006,"Generate files from docker container meta-datadocker-gen docker-gen is a file generator that renders templates using docker container meta-data. It can be used to generate various kinds of files for: Centralized logging - fluentd, logstash or other centralized logging tools that tail the containers JSON log file or files within the container. Log Rotation - logrotate files to rotate container JSON log files Reverse Proxy Configs - nginx, haproxy, etc. reverse proxy configs to route requests from the host to containers Service Discovery - Scripts (python, bash, etc..) to register containers within etcd, hipache, etc.. === Installation There are three common ways to run docker-gen: * on the host * bundled in a container with another application * separate standalone containers Host Install Linux/OSX binaries for release 0.7.6 amd64 i386 alpine-linux Download the version you need, untar, and install to your PATH. Bundled Container Install Docker-gen can be bundled inside of a container along-side applications. jwilder/nginx-proxy trusted build is an example of running docker-gen within a container along-side nginx. jwilder/docker-register is an example of running docker-gen within a container to do service registration with etcd. Separate Container Install It can also be run as two separate containers using the jwilder/docker-gen image, together with virtually any other image. This is how you could run the official nginx image and have docker-gen generate a reverse proxy config in the same way that nginx-proxy works. You may want to do this to prevent having the docker socket bound to a publicly exposed container service. Start nginx with a shared volume: Fetch the template and start the docker-gen container with the shared volume: === Usage If no <dest> file is specified, the output is sent to stdout. Mainly useful for debugging. Configuration file Using the -config flag from above you can tell docker-gen to use the specified config file instead of command-line options. Multiple templates can be defined and they will be executed in the order that they appear in the config file. An example configuration file, docker-gen.cfg can be found in the examples folder. Configuration File Syntax Putting it all together here is an example configuration file. === Templating The templates used by docker-gen are written using the Go text/template language. In addition to the built-in functions supplied by Go, docker-gen provides a number of additional functions to make it simpler (or possible) to generate your desired output. Emit Structure Within the templates, the object emitted by docker-gen will be a structure consisting of following Go structs: For example, this is a JSON version of an emitted RuntimeContainer struct: Functions closest $array $value: Returns the longest matching substring in $array that matches $value coalesce ...: Returns the first non-nil argument. contains $map $key: Returns true if $map contains $key. Takes maps from string to any type. dict $key $value ...: Creates a map from a list of pairs. Each $key value must be a string, but the $value can be any type (or nil). Useful for passing more than one value as a pipeline context to subtemplates. dir $path: Returns an array of filenames in the specified $path. exists $path: Returns true if $path refers to an existing file or directory. Takes a string. first $array: Returns the first value of an array or nil if the arry is nil or empty. groupBy $containers $fieldPath: Groups an array of RuntimeContainer instances based on the values of a field path expression $fieldPath. A field path expression is a dot-delimited list of map keys or struct member names specifying the path from container to a nested value, which must be a string. Returns a map from the value of the field path expression to an array of containers having that value. Containers that do not have a value for the field path in question are omitted. groupByKeys $containers $fieldPath: Returns the same as groupBy but only returns the keys of the map. groupByMulti $containers $fieldPath $sep: Like groupBy, but the string value specified by $fieldPath is first split by $sep into a list of strings. A container whose $fieldPath value contains a list of strings will show up in the map output under each of those strings. groupByLabel $containers $label: Returns the same as groupBy but grouping by the given label's value. hasPrefix $prefix $string: Returns whether $prefix is a prefix of $string. hasSuffix $suffix $string: Returns whether $suffix is a suffix of $string. intersect $slice1 $slice2: Returns the strings that exist in both string slices. json $value: Returns the JSON representation of $value as a string. keys $map: Returns the keys from $map. If $map is nil, a nil is returned. If $map is not a map, an error will be thrown. last $array: Returns the last value of an array. parseBool $string: parseBool returns the boolean value represented by the string. It accepts 1, t, T, TRUE, true, True, 0, f, F, FALSE, false, False. Any other value returns an error. Alias for strconv.ParseBool replace $string $old $new $count: Replaces up to $count occurences of $old with $new in $string. Alias for strings.Replace sha1 $string: Returns the hexadecimal representation of the SHA1 hash of $string. split $string $sep: Splits $string into a slice of substrings delimited by $sep. Alias for strings.Split splitN $string $sep $count: Splits $string into a slice of substrings delimited by $sep, with number of substrings returned determined by $count. Alias for strings.SplitN trimPrefix $prefix $string: If $prefix is a prefix of $string, return $string with $prefix trimmed from the beginning. Otherwise, return $string unchanged. trimSuffix $suffix $string: If $suffix is a suffix of $string, return $string with $suffix trimmed from the end. Otherwise, return $string unchanged. trim $string: Removes whitespace from both sides of $string. when $condition $trueValue $falseValue: Returns the $trueValue when the $condition is true and the $falseValue otherwise where $items $fieldPath $value: Filters an array or slice based on the values of a field path expression $fieldPath. A field path expression is a dot-delimited list of map keys or struct member names specifying the path from container to a nested value. Returns an array of items having that value. whereNot $items $fieldPath $value: Filters an array or slice based on the values of a field path expression $fieldPath. A field path expression is a dot-delimited list of map keys or struct member names specifying the path from container to a nested value. Returns an array of items not having that value. whereExist $items $fieldPath: Like where, but returns only items where $fieldPath exists (is not nil). whereNotExist $items $fieldPath: Like where, but returns only items where $fieldPath does not exist (is nil). whereAny $items $fieldPath $sep $values: Like where, but the string value specified by $fieldPath is first split by $sep into a list of strings. The comparison value is a string slice with possible matches. Returns items which OR intersect these values. whereAll $items $fieldPath $sep $values: Like whereAny, except all $values must exist in the $fieldPath. whereLabelExists $containers $label: Filters a slice of containers based on the existence of the label $label. whereLabelDoesNotExist $containers $label: Filters a slice of containers based on the non-existence of the label $label. whereLabelValueMatches $containers $label $pattern: Filters a slice of containers based on the existence of the label $label with values matching the regular expression $pattern. === Examples Automated Nginx Reverse Proxy for Docker Docker Log Management With Fluentd Docker Service Discovery Using Etcd and Haproxy NGINX Reverse Proxy Config jwilder/nginx-proxy trusted build. Start nginx-proxy: Then start containers with a VIRTUAL_HOST env variable: If you wanted to run docker-gen directly on the host, you could do it with: Fluentd Log Management This template generate a fluentd.conf file used by fluentd. It would then ship log files off the host. Service Discovery in Etcd This template is an example of generating a script that is then executed. This template generates a python script that is then executed which register containers in Etcd using its HTTP API. Development This project uses Go Modules for managing 3rd party dependencies. This means that at least go 1.11 is required. For go 1.11 and go 1.12 it is additionally required to manually enable support by setting GO111MODULE=on. For later versions, this is not required. TODO Add event status for handling start and stop events differently License MIT"
291,"Guide to securing and improving privacy on macOSThis guide is a collection of techniques for improving the security and privacy of a modern Apple Macintosh computer (""MacBook"") running a recent version of macOS (formerly known as ""OS X""). This guide is targeted to power users who wish to adopt enterprise-standard security, but is also suitable for novice users with an interest in improving their privacy and security on a Mac. A system is only as secure as its administrator is capable of making it. There is no one single technology, software, nor technique to guarantee perfect computer security; a modern operating system and computer is very complex, and requires numerous incremental changes to meaningfully improve one's security and privacy posture. This guide is provided on an 'as is' basis without any warranties of any kind. Only you are responsible if you break anything or get in any sort of trouble by following this guide. To suggest an improvement, please send a pull request or open an issue. This guide is also available in . Basics Preparing and installing macOS Verifying installation integrity Creating a bootable USB installer Creating an install image Manual way Target disk mode Creating a recovery partition Virtualization First boot System activation Admin and standard user accounts Caveats Setup Full disk encryption Firmware Firewall Application layer firewall Third party firewalls Kernel level packet filtering Services Spotlight Suggestions Homebrew DNS Hosts file dnscrypt Dnsmasq Test DNSSEC validation Captive portal Certificate authorities OpenSSL Curl Web Privoxy Browser Firefox Chrome Safari Other Web browsers Web browsers and privacy Plugins Tor VPN PGP/GPG OTR Viruses and malware System Integrity Protection Gatekeeper and XProtect Metadata and artifacts Passwords Backup Wi-Fi SSH Physical access System monitoring OpenBSM audit DTrace Execution Network Binary Whitelisting Miscellaneous Related software Additional resources Basics Standard security best practices apply: Create a threat model What are you trying to protect and from whom? Is your adversary a three letter agency (if so, you may want to consider using OpenBSD instead); a nosy eavesdropper on the network; or a determined apt orchestrating a campaign against you? Recognize threats and how to reduce attack surface against them. Keep the system up to date Patch the base operating system and all third party software. macOS system updates can be completed using the App Store application, or the softwareupdate command-line utility - neither requires registering an Apple account. Updates can also be downloaded directly from Apple's support site. Subscribe to announcement mailing lists like Apple security-announce. Encrypt sensitive data at rest In addition to full disk encryption, consider creating one or several encrypted partitions or volumes to store passwords, cryptographic keys, personal documents, etc. at rest. This will mitigate damage in case of compromise and data theft. Assure data availability Create regular backups of your data and be ready to format and re-install the operating system in case of compromise. Always encrypt locally before copying backups to external media or the ""cloud"". Verify backups work by testing them regularly, for example by accessing certain files or performing a hash based comparison. Click carefully Ultimately, the security of a system can be reduced to its administrator. Care should be taken when installing new software. Always prefer free and open source software (which macOS is not). Preparing and installing macOS There are several ways to install macOS. The simplest way is to boot into Recovery Mode by holding Command and R keys at boot. A system image can be downloaded and applied directly from Apple. However, this way exposes the serial number and other identifying information over the network in plain text, which may not be desired for privacy reasons. Packet capture of an unencrypted HTTP conversation during macOS recovery An alternative way to install macOS is to first download macOS Mojave from the App Store or elsewhere, and create a custom installable system image. Verifying installation integrity The macOS installation application is code signed, which should be verified to make sure you received a legitimate copy, using the pkgutil --check-signature or codesign -dvv commands. To verify the code signature and integrity of macOS application bundles: Use the codesign command to examine an application's code signature: Creating a bootable USB installer Instead of booting from the network or using target disk mode, a bootable macOS installer can be made with the createinstallmedia utility included in Contents/Resources folder of the installer application bundle. See Create a bootable installer for macOS, or run the utility without arguments to see how it works. To create a bootable USB installer, mount a USB drive, and erase and partition it, then use the createinstallmedia utility: Creating an install image Note Apple's AutoDMG installer does not appear to work across OS versions. If you want to build a 10.14 image, for example, the following steps must be performed on macOS 10.14! To create a custom install image which can be restored to a Mac (using a USB-C cable and target disk mode, for example), use MagerValp/AutoDMG. Manual way Note The following instructions appear to work only on macOS versions before 10.13. Find InstallESD.dmg which is inside the installation application. Locate it in Terminal or with Finder, right click on the application bundle, select Show Package Contents and navigate to Contents > SharedSupport to find the file InstallESD.dmg Verify file integrity by comparing its SHA-256 hash with others found in InstallESD_Hashes.csv or notpeter/apple-installer-checksums. To determine which macOS versions and builds originally shipped with or are available for a Mac, see HT204319. Mount and install the operating system to a temporary image: The installation will take a while, so be patient. Use tail -F /var/log/install.log in another terminal to monitor progress and check for errors. Once the installation is complete, detach, convert and verify the image: The file sierra.dmg is now ready to be applied over Target Disk Mode, from a bootable USB installer, booting from the network or recovery mode. The image could be further customized to include provisioned users, installed applications, preferences, for example. Target disk mode To use Target Disk Mode, boot up the Mac you wish to image while holding the T key and connect it to another Mac using a USB-C, Thunderbolt or Firewire cable. If you don't have another Mac, boot to a USB installer, with sierra.dmg and other required files copied to it, by holding the Option key at boot. Use the command diskutil list to identify the disk of the connected Mac, usually /dev/disk2 Optionally, securely erase the disk with a single pass (if previously FileVault-encrypted, the disk must first be unlocked and mounted as /dev/disk3s2): $ sudo diskutil secureErase freespace 1 /dev/disk3s2 Partition the disk to Journaled HFS+: Restore the image to the new volume, making sure /dev/disk2 is the disk being erased: The Disk Utility application may also be used to erase the connected disk and restore sierra.dmg to the newly created partition. To transfer any files, copy them to a shared folder like /Users/Shared on the mounted disk image, e.g. cp Xcode_8.0.dmg /Volumes/macOS/Users/Shared Finished restore install from USB recovery boot Creating a recovery partition Unless you have built the image with AutoDMG, or installed macOS to a second partition on the same Mac, you will need to create a recovery partition in order to use full disk encryption. You can do so using MagerValp/Create-Recovery-Partition-Installer or manually by following these steps: Download RecoveryHDUpdate.dmg and verify its integrity: Attach and expand the installer, then run it - again ensuring /Volumes/macOS path is the newly created partition on the connected disk: Run diskutil list again to make sure Recovery HD now exists on /dev/disk2. Eject the disk with hdiutil unmount /Volumes/macOS and power down the target disk mode-booted Mac. Virtualization To install macOS as a virtual machine (VM) using VMware Fusion, follow the instructions above to create an image. You will not need to download and create a recovery partition manually. For the Installation Method, select Install macOS from the recovery partition. Customize any memory or CPU requirements and complete setup. The guest VM should boot into Recovery Mode by default. Note If the virtual machine does not boot due to a kernel panic, adjust the memory and process resource settings. In Recovery Mode, select a language, then select Utilities > Terminal from the menu bar. In the guest VM, type ifconfig | grep inet - you should see a private address like 172.16.34.129 On the host Mac, type ifconfig | grep inet - you should see a private gateway address like 172.16.34.1. From the host Mac, you should be able to ping 172.16.34.129 or the equivalent guest VM address. From the host Mac, serve the installable image to the guest VM by editing /etc/apache2/httpd.conf and adding the following line to the top (using the gateway address assigned to the host Mac and port 80): Listen 172.16.34.1:80 On the host Mac, link the image to the default Apache Web server directory: $ sudo ln ~/sierra.dmg /Library/WebServer/Documents From the host Mac, start Apache in the foreground: $ sudo httpd -X From the guest VM, install the disk image to the volume over the local network using asr: When it's finished, stop the Apache Web server on the host Mac by pressing Control C at the sudo httpd -X window and remove the image copy with sudo rm /Library/WebServer/Documents/sierra.dmg In the guest VM, select Startup Disk from the menubar top-left, select the hard drive and restart. You may wish to disable the Network Adapter in VMware to configure the guest VM initially. Take and Restore from saved guest VM snapshots before and after attempting risky browsing, for example, or use a guest VM to install and operate questionable software. First boot Note Before setting up macOS, consider disconnecting networking and configuring a firewall(s) first. However, late 2016 MacBooks with Touch Bar hardware require online OS activation (also see next section). On first boot, hold Command Option P R keys to clear NVRAM. When macOS first starts, you'll be greeted by Setup Assistant. When creating the first account, use a strong password without a hint. If you enter your real name at the account setup process, be aware that your computer's name and local hostname will comprise that name (e.g., John Appleseed's MacBook) and thus will appear on local networks and in various preference files. Both should be verified and updated as needed in System Preferences > Sharing or with the following commands after installation: $ sudo scutil --set ComputerName MacBook $ sudo scutil --set LocalHostName MacBook System activation A few words on the privacy implications of activating ""Touch Bar"" MacBook devices from your friendly anonymous security researcher: Apple increasingly seems (despite vague claims to the contrary) increasingly interested in merging or ""unifying"" the two OSes, and there are constantly rumors of fundamental changes to macOS that make it far more like iOS than the macOS of old. Apple's introduction of ARM-based coprocessors running iOS/sepOS, first with the T1 processor on the TouchBar MacBook Pros (run the TouchBar, implement NFC/ApplePay, add biometric login using sep, and verify firmware integrity) and the iMac Pro's T2 (implements/verifies embedded device firmware, implements secure boot, etc) seems to cement this concern and basically renders using macOS devices without sending metadata to Apple difficult to impossible. iOS devices have always required ""activation"" on first boot and when the battery has gone dead which initializes sepOS to proceed with verified boot. First boot activation not only initializes sepOS as discussed below, but sends metadata to Apple (and carriers via Apple with cellular devices) to activate the baseband and SIM. In activation processes after first boot, just as with first boot, a long list of highly sensitive metadata are sent hashed (note hashing does not give you any privacy from Apple here since they link this exact metadata to payment information at purchase) to Apple so it can return the personalized response required for secure boot to complete. What is particularly worrying about this process is that it is a network-linked secure boot process where centralized external servers have the power to dictate what the device should boot. Equally there are significant privacy concerns with devices constantly sending metadata (both during activation and other Apple-linked/-hosted activities) and linking IP addresses very strongly with real identities based on purchase payment information and if a cellular device, metadata collected about SIM, etc unless such connections are blocked at the network level (which is only possible on self-managed infrastructure, i.e. not cellular) and doing this basically renders using the device impossible since simply installing an application requires sending device metadata to Apple. That the activation verification mechanism is designed specifically to rely on unique device identifiers that are associated with payment information at purchase and actively associated on a continuing basis by Apple for every Apple-hosted service that the device interacts with (Apple ID-based services, softwareupdate, iMessage, FaceTime, etc.) the ability (and invitation) for Apple to silently send targeted malicious updates to devices matching specific unique ID criteria is a valid concern, and something that should not be dismissed as unlikely, especially given Apple's full compliance with recently implemented Chinese (and other authoritarian and ""non-authoritarian"" countries') national security laws. iOS has from the start been designed with very little end-user control with no way for end-users to configure devices according to their wishes while maintaining security and relies heavily on new, closed source code. While macOS has for most of its history been designed on the surface in a similar fashion, power and enterprise users can (for the moment) still configure their devices relatively securely while maintaining basically zero network interaction with Apple and with the installation of third party software/kernel extensions, completely control the network stack and intercept filesystem events on a per-process basis. macOS, despite having a good deal of closed source code, was designed at a very different period in Apple's history and was designed more in line with open source standards, and designed to be configurable and controllable by enterprise/power users. The introduction of these coprocessors to Mac devices, while increasing security in many ways, brings with it all the issues with iOS discussed above, and means that running mac devices securely with complete user control, and without forced network interaction with the Apple mothership in highly sensitive corporate and other environments problematic and risky. Given this author is unaware of the exact hardware configuration of the coprocessors, the following may be inaccurate. However, given the low-level nature of these coprocessors, it would not surprise the author if these coprocessors, if not already, will eventually have separate network access of their own, independent of the Intel CPU (indications suggest not currently the case for T1; unclear on T2), which leads to concerns similar to those that many have raised around Intel ME/AMT (and of course mac devices also have ME in the Intel CPU...). One could argue that these coprocessors increase security, and in many ways that is the case, but not the user's security against a malicious Apple. The lack of configurability is the key issue. Apple could have introduced secure boot and firmware protection without making it require network access, without making verification linked to device-unique IDs and without introducing an enormous amount of potentially exploitable code to protect against a much smaller, but highly exploitable codebase, while running on a coprocessor with a highly privileged position on the board which gives immense power to an adversary with manufacturer compliance for targeted attacks. This is an ongoing concern and in the worst case scenario could potentially represent the end of macs as independent, end-user controllable and relatively secure systems appropriate for sensitive environments with strict network and security policies. From iOS, The Future Of macOS, Freedom, Security And Privacy In An Increasingly Hostile Global Environment. Admin and standard user accounts The first user account is always an admin account. Admin accounts are members of the admin group and have access to sudo, which allows them to usurp other accounts, in particular root, and gives them effective control over the system. Any program that the admin executes can potentially obtain the same access, making this a security risk. Utilities like sudo have weaknesses that can be exploited by concurrently running programs and many panes in System Preferences are unlocked by default (pdf) (p. 6162) for admin accounts. It is considered a best practice by Apple and others (pdf) (p. 4142) to use a separate standard account for day-to-day work and use the admin account for installations and system configuration. It is not strictly required to ever log into the admin account via the macOS login screen. The system will prompt for authentication when required and Terminal can do the rest. To that end, Apple provides some recommendations for hiding the admin account and its home directory. This can be an elegant solution to avoid having a visible 'ghost' account. The admin account can also be removed from FileVault for additional hardening. Caveats Only administrators can install applications in /Applications (local directory). Finder and Installer will prompt a standard user with an authentication dialog. Many applications can be installed in ~/Applications instead (the directory can be created manually). As a rule of thumb: applications that do not require admin access or do not complain about not being installed in /Applications should be installed in the user directory, the rest in the local directory. Mac App Store applications are still installed in /Applications and require no additional authentication. sudo is not available in shells of the standard user, which requires using su or login to enter a shell of the admin account. This can make some maneuvers trickier and requires some basic experience with command-line interfaces. System Preferences and several system utilities (e.g. Wi-Fi Diagnostics) will require root privileges for full functionality. Many panels in System Preferences are locked and need to be unlocked separately by clicking on the lock icon. Some applications will simply prompt for authentication upon opening, others must be opened by an admin account directly to get access to all functions (e.g. Console). There are third-party applications that will not work correctly because they assume that the user account is an admin. These programs may have to be executed by logging into the admin account, or by using the open utility. See additional discussion in issue #167. Setup Accounts can be created and managed in System Preferences. On settled systems, it is generally easier to create a second admin account and then demote the first account. This avoids data migration. Newly installed systems can also just add a standard account. Demoting an account can be done either from the the new admin account in System Preferences the other account must be logged out or by executing these commands (it may not be necessary to execute both, see issue #179): To find the GeneratedUID of an account: See also this post for more information about how macOS determines group membership. Full disk encryption FileVault provides full disk (technically, full volume) encryption on macOS. FileVault encryption protects data at rest and hardens (but not always prevents) someone with physical access from stealing data or tampering with your Mac. With much of the cryptographic operations happening efficiently in hardware, the performance penalty for FileVault is not noticeable. Like all cryptosystems, the security of FileVault greatly depends on the quality of the pseudo random number generator (PRNG). The random device implements the Yarrow pseudo random number generator algorithm and maintains its entropy pool. Additional entropy is fed to the generator regularly by the SecurityServer daemon from random jitter measurements of the kernel. See man 4 random for more information. Turning on FileVault in System Preferences after installing macOS, rather than creating an encrypted partition for the installation first, is more secure, because more PRNG entropy is available then. Additionally, the PRNG can be manually seeded with entropy by writing to /dev/random before enabling FileVault. This can be done by simply using the Mac for a little while before activating FileVault. It may also be possible to increase entropy with an external source, like OneRNG. See Entropy and Random Number Generators and Fun with encryption and randomness for more information. Enable FileVault with sudo fdesetup enable or through System Preferences > Security & Privacy and reboot. If you can remember the password, there's no reason to save the recovery key. However, all encrypted data will be lost forever if without either the password or recovery key. To learn about how FileVault works, see the paper Infiltrate the Vault: Security Analysis and Decryption of Lion Full Disk Encryption (pdf) and related presentation (pdf). Also see IEEE Std 1619-2007: The XTS-AES Tweakable Block Cipher (pdf). Optional Enforce system hibernation and evict FileVault keys from memory instead of traditional sleep to memory: All computers have firmware of some type - EFI, BIOS - to help in the discovery of hardware components and ultimately to properly bootstrap the computer using the desired OS instance. In the case of Apple hardware and the use of EFI, Apple stores relevant information within EFI to aid in the functionality of macOS. For example, the FileVault key is stored in EFI to transparently come out of standby mode. Organizations especially sensitive to a high-attack environment, or potentially exposed to full device access when the device is in standby mode, should mitigate this risk by destroying the FileVault key in firmware. Doing so doesn't destroy the use of FileVault, but simply requires the user to enter the password in order for the system to come out of standby mode. If you choose to evict FileVault keys in standby mode, you should also modify your standby and power nap settings. Otherwise, your machine may wake while in standby mode and then power off due to the absence of the FileVault key. See issue #124 for more information. These settings can be changed with: For more information, see Best Practices for Deploying FileVault 2 (pdf) and paper Lest We Remember: Cold Boot Attacks on Encryption Keys (pdf) Note APFS may make evicting FileVault keys redundant - see discussion and links in issue #283. Firmware Setting a firmware password prevents a Mac from starting up from any device other than the startup disk. It may also be set to be required on each boot. This may be useful for mitigating some attacks which require physical access to hardware. See How to set a firmware password on your Mac for official documentation. This feature can be helpful if your laptop is lost or stolen, protects against Direct Memory Access (DMA) attacks which can read your FileVault passwords and inject kernel modules such as pcileech, as the only way to reset the firmware password is through an Apple Store, or by using an SPI programmer, such as Bus Pirate or other flash IC programmer. Start up pressing Command and R keys to boot to Recovery Mode mode. When the Recovery window appears, choose Firmware Password Utility from the Utilities menu. In the Firmware Utility window that appears, select Turn On Firmware Password. Enter a new password, then enter the same password in the Verify field. Select Set Password. Select Quit Firmware Utility to close the Firmware Password Utility. Select Restart or Shutdown from the Apple menu in the top-left corner. The firmware password will activate at next boot. To validate the password, hold Alt during boot - you should be prompted to enter the password. The firmware password can also be managed with the firmwarepasswd utility while booted into the OS. For example, to prompt for the firmware password when attempting to boot from a different volume: To verify the firmware password: A firmware password may be bypassed by a determined attacker or Apple, with physical access to the computer. Using a Dediprog SF600 to dump and flash a 2013 MacBook SPI Flash chip to remove a firmware password, sans Apple As of macOS 10.15 Catalina, the firmwarepasswd program has a new option -disable-reset-capability. According to Apple's new Platform Security page, this effectively prevents any firmware password resets, even by Apple themselves: For users who want no one but themselves to remove their Firmware Password by software means, the -disable-reset-capability option has been added to the firmwarepasswd command-line tool in macOS 10.15. Before setting this option, users must to acknowledge that if the password is forgotten and needs removal, the user must bear the cost of the motherboard replacement necessary to achieve this. Newer Mac models (Mac Pro, iMac Pro, Macbook with TouchBar) with Apple T2 chips, which provide a secure enclave for encrypted keys, lessen the risk of EFI firmware attacks. See this blog post for more information. See LongSoft/UEFITool, chipsec/chipsec and discussion in issue #213 for more information. Firewall There are several types of firewalls available for macOS. Application layer firewall Built-in, basic firewall which blocks incoming connections only. This firewall does not have the ability to monitor, nor block outgoing connections. It can be controlled by the Firewall tab of Security & Privacy in System Preferences, or with the following commands. Enable the firewall with logging and stealth mode: Computer hackers scan networks so they can attempt to identify computers to attack. You can prevent your computer from responding to some of these scans by using stealth mode. When stealth mode is enabled, your computer does not respond to ICMP ping requests, and does not answer to connection attempts from a closed TCP or UDP port. This makes it more difficult for attackers to find your computer. To prevent built-in software as well as code-signed, downloaded software from being whitelisted automatically: Applications that are signed by a valid certificate authority are automatically added to the list of allowed apps, rather than prompting the user to authorize them. Apps included in macOS are signed by Apple and are allowed to receive incoming connections when this setting is enabled. For example, since iTunes is already signed by Apple, it is automatically allowed to receive incoming connections through the firewall. If you run an unsigned app that is not listed in the firewall list, a dialog appears with options to Allow or Deny connections for the app. If you choose ""Allow"", macOS signs the application and automatically adds it to the firewall list. If you choose ""Deny"", macOS adds it to the list but denies incoming connections intended for this app. After interacting with socketfilterfw, restart the process by sending a line hangup signal: Third party firewalls Programs such as Little Snitch, Hands Off, Radio Silence, LuLu and Security Growler provide a good balance of usability and security. These programs are capable of monitoring and blocking incoming and outgoing network connections. However, they may require the use of a closed source kernel extension. If the number of choices of allowing/blocking network connections is overwhelming, use Silent Mode with connections allowed, then periodically check the configuration to gain understanding of applications and what they are doing. It is worth noting that these firewalls can be bypassed by programs running as root or through OS vulnerabilities (pdf), but they are still worth having - just don't expect absolute protection. However, some malware actually deletes itself and doesn't execute if Little Snitch, or other security software, is installed. For more on how Little Snitch works, see the Network Kernel Extensions Programming Guide and Shut up snitch! reverse engineering and exploiting a critical Little Snitch vulnerability. Kernel level packet filtering A highly customizable, powerful, but also most complicated firewall exists in the kernel. It can be controlled with pfctl and various configuration files. pf can also be controlled with a GUI application such as IceFloor or Murus. There are many books and articles on the subject of pf firewall. Here's is just one example of blocking traffic by IP address. Add the following into a file called pf.rules: Then use the following commands to manipulate the firewall: sudo pfctl -e -f pf.rules to enable the firewall and load the configuration sudo pfctl -d to disable the firewall sudo pfctl -t blocklist -T add 1.2.3.4 to add an IP address to the blocklist sudo pfctl -t blocklist -T show to view the blocklist sudo ifconfig pflog0 create to create an interface for logging sudo tcpdump -ni pflog0 to view filtered packets Unless you're already familiar with packet filtering, spending too much time configuring pf is not recommended. It is also probably unnecessary if your Mac is behind a NAT on a secure home network. It is possible to use the pf firewall to block network access to entire ranges of network addresses, for example to a whole organization: Query Merit RADb for the list of networks in use by an autonomous system, like Facebook: Copy and paste the list of networks returned into the blocklist command: Confirm the addresses were added: Confirm network traffic is blocked to those addresses (note that DNS requests will still work): Outgoing TCP SYN packets are blocked, so a TCP connection is not established and thus a Web site is effectively blocked at the IP layer. To use pf to audit ""phone home"" behavior of user and system-level processes, see fix-macosx/net-monitor. See drduh/config/scripts/pf-blocklist.sh for more inspiration. Services Note System Integrity Protection does not allow disabling system services on recent macOS versions. Either temporarily disable SIP or disable services from Recovery Mode. See Issue 334 for more information. See fix-macosx/yosemite-phone-home, l1k/osxparanoia and karek314/macOS-home-call-drop for further recommendations. Services on macOS are managed by launchd. See launchd.info, as well as Apple's Daemons and Services Programming Guide and Technical Note TN2083 You can also run KnockKnock that shows more information about startup items. Use launchctl list to view running user agents Use sudo launchctl list to view running system daemons Specify the service name to examine it, e.g. launchctl list com.apple.Maps.mapspushd Use defaults read to examine job plists in /System/Library/LaunchDaemons and /System/Library/LaunchAgents Use man and strings to find out more about what an agent/daemon does For example, to learn what a system launch daemon or agent does, start with: Look at the Program or ProgramArguments section to see which binary is run, in this case apsd. To find more information about that, look at the man page with man apsd For example, if you're not interested in Apple Push Notifications, disable the service: Note Unloading services may break usability of some applications. Read the manual pages and use Google to make sure you understand what you're doing first. Be careful about disabling any system daemons you don't understand, as it may render your system unbootable. If you break your Mac, use single user mode to fix it. Use Console and Activity Monitor applications if you notice your Mac heating up, feeling sluggish, or generally misbehaving, as it may have resulted from your tinkering. To view the status of services: Annotated lists of launch daemons and agents, the respective program executed, and the programs' hash sums are included in this repository. (Optional) Run the read_launch_plists.py script and diff output to check for any discrepancies on your system, e.g.: See also cirrusj.github.io/Yosemite-Stop-Launch for descriptions of services and Provisioning OS X and Disabling Unnecessary Services for another explanation. Persistent login items may also exist in these directories: /Library/LaunchAgents /Library/LaunchDaemons /Library/ScriptingAdditions /Library/StartupItems /System/Library/LaunchAgents /System/Library/LaunchDaemons /System/Library/ScriptingAdditions /System/Library/StartupItems ~/Library/LaunchAgents ~/Library/Preferences/com.apple.loginitems.plist See Mac OSX Startup (pdf) for more information. Spotlight Suggestions Disable Spotlight Suggestions in both the Spotlight preferences and Safari's Search preferences to avoid your search queries being sent to Apple. Also disable Bing Web Searches in the Spotlight preferences to avoid your search queries being sent to Microsoft. See fix-macosx.com for detailed instructions. If you've upgraded to OS X 10.10 ""Yosemite"" and you're using the default settings, each time you start typing in Spotlight (to open an application or search for a file on your computer), your local search terms and location are sent to Apple and third parties (including Microsoft). Note This Web site and instructions may no longer work on macOS Sierra - see issue 164. For comparison to Windows 10, see https://fix10.isleaked.com/ Homebrew Consider using Homebrew to make software installations easier and to update userland tools (see Apple's great GPL purge). Note If you have not already installed Xcode or Command Line Tools, use xcode-select --install to download and install them, or check Apple's developer site. Install Homebrew: Edit PATH in your shell or shell rc file to use ~/homebrew/bin and ~/homebrew/sbin. For example, echo 'PATH=$PATH:~/homebrew/sbin:~/homebrew/bin' >> .zshrc, then change your login shell to Z shell with chsh -s /bin/zsh, open a new Terminal window and run brew update. Homebrew uses SSL/TLS to talk with GitHub and verifies integrity of downloaded packages, so it's fairly secure. Remember to periodically run brew update and brew upgrade on trusted and secure networks to download and install software updates. To get information on a package before installation, run brew info <package> and check its recipe online. According to Homebrew's Anonymous Aggregate User Behaviour Analytics, Homebrew gathers anonymous aggregate user behaviour analytics and reporting these to Google Analytics. To opt out of Homebrew's analytics, you can set export HOMEBREW_NO_ANALYTICS=1 in your environment or shell rc file, or use brew analytics off. You may also wish to enable additional security options, such as HOMEBREW_NO_INSECURE_REDIRECT=1 and HOMEBREW_CASK_OPTS=--require-sha. DNS Hosts file Use the hosts file to block known malware, advertising or otherwise unwanted domains. Edit the hosts file as root, for example with sudo vi /etc/hosts. The hosts file can also be managed with the GUI app 2ndalpha/gasmask. To block a domain by A record, append any one of the following lines to /etc/hosts: Note IPv6 uses the AAAA DNS record type, rather than A record type, so you may also want to block those connections by also including ::1 example.com entries, like shown here. There are many lists of domains available online which you can paste in, just make sure each line starts with 0, 0.0.0.0, 127.0.0.1, and the line 127.0.0.1 localhost is included. Here are some popular and useful hosts lists: jmdugan/blocklists l1k/osxparanoia Sinfonietta/hostfiles StevenBlack/hosts someonewhocares.org Append a list of hosts with the tee command and confirm only non-routable addresses or comments were added: See man hosts and FreeBSD Configuration Files for more information. See the dnsmasq section of this guide for more hosts blocking options. dnscrypt To encrypt outgoing DNS traffic, consider using jedisct1/dnscrypt-proxy. In combination with dnsmasq and DNSSEC, the integrity and authenticity of DNS traffic is greatly improved. JayBrown/DNSCrypt-Menu and jedisct1/bitbar-dnscrypt-proxy-switcher provide a graphical user interface to dnscrypt. Install dnscrypt from Homebrew and follow the instructions to configure and start dnscrypt-proxy: If using in combination with Dnsmasq, find the file homebrew.mxcl.dnscrypt-proxy.plist by running which will show a location like /usr/local/etc/dnscrypt-proxy.toml Open it in a text editor, find the line starting with listen_addresses = and edit that line to use DNScrypt on a port other than 53, like 5355: Start DNSCrypt: Make sure DNSCrypt is running: By default, dnscrypt-proxy runs on localhost (127.0.0.1), port 53, and under the ""nobody"" user using the resolvers specified in https://raw.githubusercontent.com/DNSCrypt/dnscrypt-resolvers/master/v2/public-resolvers.md. If you would like to change these settings, you will have to edit the configuration file (e.g. listen_addresses, user_name, urls, etc.) This can be accomplished by editing /usr/local/etc/dnscrypt-proxy.toml as described above. You can run your own dnscrypt server (see also drduh/Debian-Privacy-Server-Guide#dnscrypt) from a trusted location or use one of many public servers instead. Confirm outgoing DNS traffic is encrypted: dnscrypt-proxy also has the capability to blacklist domains, including the use of wild-cards. See the Sample configuration file for dnscrypt-proxy for the options. Note Applications and programs may resolve DNS using their own provided servers. If dnscrypt-proxy is used, it is possible to disable all other, non-dnscrypt DNS traffic with the following pf rules: See also What is a DNS leak, the mDNSResponder manual page and ipv6-test.com. Dnsmasq Among other features, dnsmasq is able to cache replies, prevent upstream queries for unqualified names, and block entire top-level domain names. Use in combination with DNSCrypt to additionally encrypt outgoing DNS traffic. If you don't wish to use DNSCrypt, you should at least use DNS not provided by your ISP. Two popular alternatives are Google DNS and OpenDNS. (Optional) DNSSEC is a set of extensions to DNS which provide to DNS clients (resolvers) origin authentication of DNS data, authenticated denial of existence, and data integrity. All answers from DNSSEC protected zones are digitally signed. The signed records are authenticated via a chain of trust, starting with a set of verified public keys for the DNS root-zone. The current root-zone trust anchors may be downloaded from IANA website. There are a number of resources on DNSSEC, but probably the best one is dnssec.net website. Install Dnsmasq (DNSSEC is optional): Download drduh/config/dnsmasq.conf: Edit the file and examine all the options. To block entire levels of domains, append drduh/config/domains or your own rules. Install and start the program (sudo is required to bind to privileged port 53): To set Dnsmasq as your local DNS server, open System Preferences > Network and select the active interface, then the DNS tab, select + and add 127.0.0.1, or use: Make sure Dnsmasq is correctly configured: Note Some VPN software overrides DNS settings on connect. See issue #24 and drduh/config/scripts/macos-dns.sh. Test DNSSEC validation Test DNSSEC validation succeeds for signed zones - the reply should have NOERROR status and contain ad flag: Test DNSSEC validation fails for zones that are signed improperly - the reply should have SERVFAIL status: Captive portal When macOS connects to new networks, it checks for Internet connectivity and may launch a Captive Portal assistant utility application. An attacker could trigger the utility and direct a Mac to a site with malware without user interaction, so it's best to disable this feature and log in to captive portals using your regular Web browser by navigating to a non-secure HTTP page and accepting a redirect to the captive portal login interface (after disabling any custom proxy or DNS settings). Also see Apple's secret ""wispr"" request, How to disable the captive portal window in Mac OS Lion and An undocumented change to Captive Network Assistant settings in OS X 10.10 Yosemite. Certificate authorities macOS comes with over 200 root authority certificates installed from for-profit corporations like Apple, Verisign, Thawte, Digicert and government agencies from China, Japan, Netherlands, U.S., and more! These Certificate Authorities (CAs) are capable of issuing SSL/TLS certificates for any domain, code signing certificates, etc. For more information, see Certification Authority Trust Tracker, Analysis of the HTTPS certificate ecosystem (pdf), and You Wont Be Needing These Any More: On Removing Unused Certificates From Trust Stores (pdf). Inspect system root certificates in Keychain Access, under the System Roots tab or by using the security command line tool and /System/Library/Keychains/SystemRootCertificates.keychain file. Disable certificate authorities through Keychain Access by marking them as Never Trust and closing the window: The risk of a man in the middle attack in which a coerced or compromised certificate authority trusted by your system issues a fake/rogue SSL certificate is quite low, but still possible. OpenSSL Note This section may be out of date. The version of OpenSSL in Sierra is 0.9.8zh which is not current. It doesn't support TLS 1.1 or newer, elliptic curve ciphers, and more. Since Apple's official supported TLS library on macOS is Secure Transport, OpenSSL deprecated is considered deprecated (according to the Cryptographic Services Guide. Apple's version of OpenSSL may also have patches which may surprise you. If you're going to use OpenSSL on your Mac, download and install a recent version of OpenSSL with brew install openssl. Note, linking brew to be used in favor of /usr/bin/openssl may interfere with built-in software. See issue #39. Compare the TLS protocol and cipher between the homebrew version and the system version of OpenSSL: See also Comparison of TLS implementations, How's My SSL and Qualys SSL Labs Tools. Curl The version of Curl which comes with macOS uses Secure Transport for SSL/TLS validation. If you prefer to use OpenSSL, install with brew install curl --with-openssl and ensure it's the default with brew link --force curl Download drduh/config/curlrc or see the man page: Web Privoxy Consider using Privoxy as a local proxy to filter Web browsing traffic. Note macOS proxy settings are not universal; apps and services may not honor system proxy settings. Ensure the application you wish to proxy is correctly configured and manually verify connections don't leak. Additionally, it may be possible to configure the pf firewall to transparently proxy all traffic. A signed installation package for privoxy can be downloaded from silvester.org.uk or Sourceforge. The signed package is more secure than the Homebrew version, and attracts full support from the Privoxy project. Alternatively, install and start privoxy using Homebrew: By default, privoxy listens on localhost, TCP port 8118. Set the system HTTP proxy for your active network interface 127.0.0.1 and 8118 (This can be done through System Preferences > Network > Advanced > Proxies): (Optional) Set the system HTTPS proxy, which still allows for domain name filtering, with: Confirm the proxy is set: Visit http://p.p/ in a browser, or with Curl: Privoxy already comes with many good rules, however you can also write your own. Download drduh/config/privoxy/config and drduh/config/privoxy/user.action to get started: Restart Privoxy and verify traffic is blocked or redirected: You can replace ad images with pictures of kittens, for example, by starting a local Web server and redirecting blocked requests to localhost. Browser The Web browser poses the largest security and privacy risk, as its fundamental job is to download and execute untrusted code from the Internet. This is an important statement. The unique use case of Web Browsers of operation in hostile environments, has forced them to adopt certain impressive security features. The cornerstone of Web Browser security is the Same Origin Policy (SOP). In a few words, SOP prevents a malicious script on one page from obtaining access to sensitive data on another web page through that page's Document Object Model (DOM). If SOP is compromised, the security of the whole Web Browser is compromised. The best tip to ensure secure browsing regardless your choice of Web Browser is proper security hygiene. The majority of Web Browser exploits require social engineering attacks to achieve native code execution. Always be mindful of the links you click and be extra careful when websites ask you to download and install software. 99% percent of the time that software is malware. Another important consideration about Web Browser security is Web Extensions. Web Extensions greatly increase the attack surface of the Web Browser. This is an issue that plagues Firefox and Chrome alike. Luckily, Web Extensions can only access specific browser APIs that are being governed by their manifest. That means we can quickly audit their behavior and remove them if they request access to information they shouldn't (why would an Ad blocker require camera access?). In the interest of security, it is best to limit your use of Web Extensions. Mozilla Firefox, Google Chrome, Safari, and Tor Browser are covered in this guide. Each Web Browser offers certain benefits and drawbacks regarding their security and privacy. It is best to make an informed choice and not necessarily commit to only one. Firefox Mozilla Firefox is an excellent browser as well as being completely open source. Currently, Firefox is in a renaissance period. It replaces major parts of its infrastructure and code base under projects Quantum and Photon. Part of the Quantum project is to replace C++ code with Rust. Rust is a systems programming language with a focus on security and thread safety. It is expected that Rust adoption will greatly improve the overall security posture of Firefox. Firefox offers a similar security model to Chrome: it has a bug bounty program, although it is not a lucrative as Chrome's. Firefox follows a six-week release cycle similar to Chrome. See discussion in issues #2 and #90 for more information about certain differences in Firefox and Chrome. Firefox supports user-supplied configuration files. See drduh/config/user.js, pyllyukko/user.js and ghacksuserjs/ghacks-user.js for recommended preferences and hardening measures. Also see NoScript, an extension which allows whitelist-based, pre-emptive script blocking. Firefox is focused on user privacy. It supports tracking protection in Private Browsing mode. The tracking protection can be enabled for the default account, although it may break the browsing experience on some websites. Another feature for added privacy unique to Firefox is Containers, similar to Chrome profiles. Previous versions of Firefox used a Web Extension SDK that was quite invasive and offered immense freedom to developers. Sadly, that freedom also introduced a number of vulnerabilities in Firefox that greatly affected its users. You can find more information about vulnerabilities introduced by Firefox's legacy extensions in this paper (pdf). Currently, Firefox only supports Web Extensions through the Web Extension Api, which is very similar to Chrome's. Submission of Web Extensions in Firefox is free. Web Extensions in Firefox most of the time are open source, although certain Web Extensions are proprietary. Note Similar to Chrome and Safari, Firefox allows account sync across multiple devices. While stored login passwords are encrypted, Firefox does not require a password to reveal their plain text format. Firefox only displays as yes/no prompt. This is an important security issue. Keep that in mind if you sign in to your Firefox account from devices that do not belong to you and leave them unattended. The issue has been raised among the Firefox community and hopefully will be resolved in the coming versions. See drduh/config/firefox.user.js for additional Firefox configuration options to improve security and privacy. Chrome Google Chrome is based on the open source Chromium project with certain proprietary components: Automatic updates with GoogleSoftwareUpdateDaemon. Usage tracking and crash reporting, which can be disabled through Chrome's settings. Chrome Web Store. Adobe Flash Plugin - supports a Pepper API version of Adobe Flash which gets updated automatically with Chrome. Media Codec support - adds support for proprietary codecs. Chrome PDF viewer. Non-optional tracking. Google Chrome installer includes a randomly generated token. The token is sent to Google after the installation completes in order to measure the success rate. The RLZ identifier stores information in the form of encoded strings like the source of chrome download and installation week. It doesnt include any personal information and its used to measure the effectiveness of a promotional campaign. Chrome downloaded from Googles website doesnt have the RLZ identifier. The source code to decode the strings is made open by Google. Chrome offers account sync between multiple devices. Part of the sync data are stored website credentials. The login passwords are encrypted and in order to access them, a user's Google account password is required. You can use your Google account to sign to your Chrome customized settings from other devices while retaining your the security of your passwords. Chrome's Web store for extensions requires a 5 dollar lifetime fee in order to submit extensions. The low cost allows the development of many quality Open Source Web Extensions that do not aim to monetize through usage. Chrome has the largest share of global usage and is the preferred target platform for the majority of developers. Major technologies are based on Chrome's Open Source components, such as node.js which uses Chrome's V8 Engine and the Electron framework, which is based on Chromium and node.js. Chrome's vast user base makes it the most attractive target for threat actors and security researchers. Despite under constants attacks, Chrome has retained an impressive security track record over the years. This is not a small feat. Chrome offers separate profiles, sandboxing, frequent updates (including Flash, although you should disable it - see below), and carries impressive credentials. In addition, Google offers a very lucrative bounty program for reporting vulnerabilities along with its own Project Zero. This means that a large number of highly talented and motivated people are constantly auditing Chrome's code base. Create separate Chrome profiles to reduce XSS risk and compartmentalize cookies/identities. In each profile, either disable Javascript in Chrome settings and manually whitelist allowed origins - or use uBlock Origin to manage Javascript and/or disable third-party scripts/frames. Also install HTTPSEverywhere to upgrade insecure connections. Change the default search engine from Google to reduce additional tracking. Disable DNS prefetching (see also DNS Prefetching and Its Privacy Implications (pdf)). Note that Chrome may attempt to resolve DNS using Google's 8.8.8.8 and 8.8.4.4 public nameservers. Read Chromium Security and Chromium Privacy for more detailed, technical information. Read Google's privacy policy and learn which Google services collect personal information. Users can opt-out of services and see what type of information Google has stored in account settings. Safari Safari is the default Web browser of macOS. It is also the most optimized browser for reducing battery use. Safari, like Chrome, has both Open Source and proprietary components. Safari is based on the open source Web Engine WebKit, which is ubiquitous among the macOS ecosystem. WebKit is used by Apple apps such as Mail, iTunes, iBooks, and the App Store. Chrome's Blink engine is a fork of WebKit and both engines share a number of similarities. Safari supports certain unique features that benefit user security and privacy. Content blockers enables the creation of content blocking rules without using Javascript. This rule based approach greatly improves memory use, security, and privacy. Safari 11 introduced an Intelligent Tracking Prevention system. This feature automatically removes tracking data stored in Safari after a period of non-interaction by the user from the tracker's website. Similar to Chrome and Firefox, Safari offers an invite only bounty program for bug reporting to a select number of security researchers. The bounty program was announced during Apple's presentation at BlackHat 2016. Web Extensions in Safari have an additional option to use native code in the Safari's sandbox environment, in addition to Web Extension APIs. Web Extensions in Safari are also distributed through Apple's App store. App store submission comes with the added benefit of Web Extension code being audited by Apple. On the other hand App store submission comes at a steep cost. Yearly developer subscription fee costs 100 USD (in contrast to Chrome's 5 dollar lifetime fee and Firefox's free submission). The high cost is prohibitive for the majority of Open Source developers. As a result, Safari has very few extensions to choose from. However, you should keep the high cost in mind when installing extensions. It is expected that most Web Extensions will have some way of monetizing usage in order to cover developer costs. Be wary of Web Extensions whose source code is not open. Safari syncs user preferences and saved passwords with iCloud Keychain. In order to be viewed in plain text, a user must input the account password of the current device. This means that users can sync data across devices with added security. Safari follows a slower release cycle than Chrome and Firefox (3-4 minor releases, 1 major release, per year). Newer features are slower to be adopted to the stable channel. Although security updates in Safari are handled independent of the stable release schedule and issued automatically through the App store. The Safari channel that follows a six-week release cycle (similar to as Chrome and Firefox) is called Safari Technology Preview and it is the recommended option instead of the stable channel of Safari. An excellent open source ad blocker for Safari that fully leverages content blockers is dgraham/Ka-Block. See also el1t/uBlock-Safari to disable hyperlink auditing beacons. Other Web browsers Many Chromium-derived browsers are not recommended. They are usually closed source, poorly maintained, have bugs, and make dubious claims to protect privacy. See The Private Life of Chromium Browsers. Other miscellaneous browsers, such as Brave, are not evaluated in this guide, so are neither recommended nor actively discouraged from use. Web browsers and privacy All Web Browsers retain certain information about our browsing habits. That information is used for a number of reasons. One of them is to improve the overall performance of the Web Browser. Most Web Browsers offer prediction services to resolve typos or URL redirections, store analytics data of browsing patterns, crash reports and black listing of known malicious servers. Those options can be turned on and off from each Web browser's settings panel. Since Web browsers execute untrusted code from the server, it is important to understand what type of information can be accessed. The Navigator interface gives access to information about the Web Browser's user agent. Those include information such as the operating system, Web sites' permissions, and the device's battery level. For more information about security conscious browsing and what type of information is being ""leaked"" by your browser, see HowTo: Privacy & Security Conscious Browsing, browserleaks.com and EFF Panopticlick. To hinder third party trackers, it is recommended to disable third-party cookies in Web browser settings. A third party cookie is a cookie associated with a file requested by a different domain than the one the user is currently viewing. Most of the time third-party cookies are used to create browsing profiles by tracking a user's movement on the web. Disabling third-party cookies prevents HTTP responses and scripts from other domains from setting cookies. Moreover, cookies are removed from requests to domains that are not the document origin domain, so cookies are only sent to the current site that is being viewed. Also be aware of WebRTC, which may reveal your local or public (if connected to VPN) IP address(es). In Firefox and Chrome/Chromium this can be disabled with extensions such as uBlock Origin and rentamob/WebRTC-Leak-Prevent. Disabling WebRTC in Safari is only possible with a system hack. Plugins Adobe Flash, Oracle Java, Adobe Reader, Microsoft Silverlight (Netflix now works with HTML5) and other plugins are security risks and should not be installed. If they are necessary, only use them in a disposable virtual machine and subscribe to security announcements to make sure you're always patched. See Hacking Team Flash Zero-Day, Java Trojan BackDoor.Flashback, Acrobat Reader: Security Vulnerabilities, and Angling for Silverlight Exploits for examples. Tor Tor is an anonymizing proxy which can be used for browsing the Web. Download Tor Browser from Tor Project. Do not attempt to configure other browsers or applications to use Tor as you may make a mistake which will compromise anonymity. Download both the dmg and asc signature files, then verify the disk image has been signed by Tor developers: Make sure Good signature from ""Tor Browser Developers (signing key) <torbrowser@torproject.org>"" appears in the output. The warning about the key not being certified is benign, as it has not yet been manually assigned trust. See How to verify signatures for packages for more information. To finish installing Tor Browser, open the disk image and drag the it into the Applications folder, or with: Verify the Tor application's code signature was made by with The Tor Project's Apple developer ID MADPSAYN6T, using the spctl -a -v and/or pkgutil --check-signature commands: You can also use the codesign command to examine an application's code signature: To view full certificate details for a signed application, extract them with codesign and decode it with openssl: Tor traffic is encrypted to the exit node (i.e., cannot be read by a passive network eavesdropper), but Tor use can be identified - for example, TLS handshake ""hostnames"" will show up in plaintext: See Tor Protocol Specification and Tor/TLSHistory for more information. You may wish to additionally obfuscate Tor traffic using a pluggable transport, such as Yawning/obfs4proxy or SRI-CSL/stegotorus. This can be done by setting up your own Tor relay or finding an existing private or public bridge to serve as an obfuscating entry node. For extra security, use Tor inside a VirtualBox or VMware virtualized GNU/Linux or BSD machine. Finally, remember the Tor network provides anonymity, which is not necessarily synonymous with privacy. The Tor network does not guarantee protection against a global observer capable of traffic analysis and correlation. See also Seeking Anonymity in an Internet Panopticon (pdf) and Traffic Correlation on Tor by Realistic Adversaries (pdf). Also see Invisible Internet Project (I2P) and its Tor comparison. VPN Unencrypted network traffic is being actively monitored and possibly tampered with. Encrypted traffic still exposes connection metadata and could be used to infer behavior or specific actions. It is a good idea to use a VPN with outgoing network traffic (not split tunnel) together with a trustworthy provider. drduh/Debian-Privacy-Server-Guide is one of many available guides for setting up a personal VPN server. Don't just blindly sign up for a VPN service without understanding the full implications and how your traffic will be routed. If you don't understand how the VPN works or are not familiar with the software used, you are probably better off without it. When choosing a VPN service or setting up your own, be sure to research the protocols, key exchange algorithms, authentication mechanisms, and type of encryption being used. Some protocols, such as PPTP, should be avoided in favor of OpenVPN or Linux-based Wireguard on a Linux VM or via a set of cross platform tools. Some clients may send traffic over the next available interface when VPN is interrupted or disconnected. See scy/8122924 for an example on how to allow traffic only over VPN. Another set of scripts to lock down your system so it will only access the internet via a VPN can be found as part of the Voodoo Privacy project - sarfata/voodooprivacy and there is an updated guide to setting up an IPSec VPN on a virtual machine (hwdsl2/setup-ipsec-vpn) or a docker container (hwdsl2/docker-ipsec-vpn-server). It may be worthwhile to consider the geographical location of the VPN provider. See further discussion in issue #114. Also see this technical overview of the macOS built-in VPN L2TP/IPSec and IKEv2 client. Other open source OpenVPN clients/GUI: Eddie, Pritunl are not evaluated in this guide, so are neither recommended nor actively discouraged from use. PGP/GPG PGP is a standard for encrypting email end to end. That means only the chosen recipients can decrypt a message, unlike regular email which is read and forever archived by providers. GPG, or GNU Privacy Guard, is a GPL-licensed open source program compliant with the PGP standard. GPG is used to verify signatures of software you download and install, as well as symmetrically or asymmetrically encrypt files and text. Install from Homebrew with brew install gnupg. If you prefer a graphical application, download and install GPG Suite. Download drduh/config/gpg.conf to use recommended settings: See drduh/YubiKey-Guide to securely generate and store GPG keys. Read online guides and practice encrypting and decrypting email to yourself and your friends. Get them interested in this stuff! OTR OTR stands for off-the-record and is a cryptographic protocol for encrypting and authenticating conversations over instant messaging. You can use OTR on top of any existing XMPP chat service, even Google Hangouts (which only encrypts conversations between users and the server using TLS). The first time you start a conversation with someone new, you'll be asked to verify their public key fingerprint. Make sure to do this in person or by some other secure means (e.g. GPG encrypted mail). A popular macOS GUI client for XMPP and other chat protocols is Adium. Other XMPP clients include profanity and agl/xmpp-client. Another relatively new XMPP chat client is CoyIM, it's focused and security and has built-in support for OTR and Tor. If you want to know how OTR works, read the paper Off-the-Record Communication, or, Why Not To Use PGP (pdf) Viruses and malware There is an ever-increasing amount of Mac malware in the wild. Macs aren't immune from viruses and malicious software! Some malware comes bundled with both legitimate software, such as the Java bundling Ask Toolbar, and some with illegitimate software, such as Mac.BackDoor.iWorm bundled with pirated programs. Malwarebytes Anti-Malware for Mac is an excellent program for ridding oneself of ""garden-variety"" malware and other ""crapware"". See Methods of malware persistence on Mac OS X (pdf) and Malware Persistence on OS X Yosemite to learn about how garden-variety malware functions. You could periodically run a tool like Knock Knock to examine persistent applications (e.g. scripts, binaries). But by then, it is probably too late. Maybe applications such as Block Block and Ostiarius will help. See warnings and caveats in issue #90 first, however. An open-source alternative could be maclaunch.sh. Anti-virus programs are a double-edged sword -- not so useful for advanced users and will likely increase attack surface against sophisticated threats; however possibly useful for catching ""garden variety"" malware on novice users' Macs. There is also the additional processing overhead to consider when using ""active"" scanning features. See Sophail: Applied attacks against Antivirus (pdf), Analysis and Exploitation of an ESET Vulnerability, a trivial Avast RCE, Popular Security Software Came Under Relentless NSA and GCHQ Attacks, How Israel Caught Russian Hackers Scouring the World for U.S. Secrets and AVG: ""Web TuneUP"" extension multiple critical vulnerabilities. Therefore, the best anti-virus is Common Sense 2020. See discussion in issue #44. Local privilege escalation bugs are plenty on macOS, so always be careful when downloading and running untrusted programs or trusted programs from third party websites or downloaded over HTTP (example). Subscribe to updates at The Safe Mac and Malwarebytes Blog for current Mac security news. To scan an application with multiple AV products and examine its behavior, upload it to VirusTotal. Also check out Hacking Team malware for macOS: root installation for MacOS, Support driver for Mac Agent and RCS Agent for Mac, which is a good example of advanced malware with capabilities to hide from userland (e.g., ps, ls). For more, see A Brief Analysis of an RCS Implant Installer and reverse.put.as System Integrity Protection System Integrity Protection (SIP) is a security feature since OS X 10.11 ""El Capitan"". It is enabled by default, but can be disabled, which may be necessary to change some system settings, such as deleting root certificate authorities or unloading certain launch daemons. Keep this feature on, as it is by default. From What's New in OS X 10.11: A new security policy that applies to every running process, including privileged code and code that runs out of the sandbox. The policy extends additional protections to components on disk and at run-time, only allowing system binaries to be modified by the system installer and software updates. Code injection and runtime attachments to system binaries are no longer permitted. Also see What is the rootless feature in El Capitan, really? Some MacBook hardware has shipped with SIP disabled. To verify SIP is enabled, use the command csrutil status, which should return: System Integrity Protection status: enabled. Otherwise, enable SIP through Recovery Mode. Gatekeeper and XProtect Gatekeeper and the quarantine system try to prevent unsigned or ""bad"" programs and files from running and opening. XProtect prevents the execution of known bad files and outdated plugin versions, but does nothing to cleanup or stop existing malware. Both offer trivial protection against common risks and are fine at default settings. See also Mac Malware Guide : How does Mac OS X protect me? and Gatekeeper, XProtect and the Quarantine attribute. Note Quarantine stores information about downloaded files in ~/Library/Preferences/com.apple.LaunchServices.QuarantineEventsV2, which may pose a privacy risk. To examine the file, simply use strings or the following command: See here for more information. To permanently disable this feature, clear the file and make it immutable: Metadata and artifacts macOS attaches metadata (HFS+ extended attributes) to downloaded files, which can be viewed with the mdls and xattr commands: Metadata attributes can also be removed with the -d flag: Other metadata and artifacts may be found in the directories including, but not limited to, ~/Library/Preferences/, ~/Library/Containers/<APP>/Data/Library/Preferences, /Library/Preferences, some of which is detailed below. ~/Library/Preferences/com.apple.sidebarlists.plist contains historical list of volumes attached. To clear it, use the command /usr/libexec/PlistBuddy -c ""delete :systemitems:VolumesList"" ~/Library/Preferences/com.apple.sidebarlists.plist /Library/Preferences/com.apple.Bluetooth.plist contains Bluetooth metadata, including device history. If Bluetooth is not used, the metadata can be cleared with: /var/spool/cups contains the CUPS printer job cache. To clear it, use the commands: To clear the list of iOS devices connected, use: Quicklook thumbnail data can be cleared using the qlmanage -r cache command, but this writes to the file resetreason in the Quicklook directories, and states that the Quicklook cache was manually cleared. Disable the thumbnail cache with qlmanage -r disablecache It can also be manually cleared by getting the directory names with getconf DARWIN_USER_CACHE_DIR and sudo getconf DARWIN_USER_CACHE_DIR, then removing them: Similarly, for the root user: Also see 'quicklook' cache may leak encrypted data. To clear Finder preferences: Additional diagnostic files may be found in the following directories - but caution should be taken before removing any, as it may break logging or cause other issues: macOS stored preferred Wi-Fi data (including credentials) in NVRAM. To clear it, use the following commands: macOS may collect sensitive information about what you type, even if user dictionary and suggestions are off. To remove them, and prevent them from being created again, use the following commands: QuickLook application support metadata can be cleared and locked with the following commands: Document revision metadata is stored in /.DocumentRevisions-V100 and can be cleared and locked with the following commands - caution should be taken as this may break some core Apple applications: Saved application state metadata may be cleared and locked with the following commands: Autosave metadata can be cleared and locked with the following commands: The Siri analytics database, which is created even if the Siri launch agent disabled, can be cleared and locked with the following commands: ~/Library/Preferences/com.apple.iTunes.plist contains iTunes metadata. Recent iTunes search data may be cleared with the following command: If you do not use Apple ID-linked services, the following keys may be cleared, too, using the following commands: All media played in QuickTime Player can be found in: Additional metadata may exist in the following files: Passwords Generate strong passwords with several programs or directly from /dev/urandom: You can also generate passwords, even memorable ones, using Keychain Access password assistant, or a command line equivalent like anders/pwgen. Keychains are encrypted with a PBKDF2 derived key and are a pretty safe place to store credentials. See also Breaking into the OS X keychain. Also be aware that Keychain does not encrypt the names corresponding to password entries. Alternatively, you can manage an encrypted passwords file yourself with GnuPG (see drduh/Purse and drduh/pwd.sh for example). In addition to passwords, ensure eligible online accounts, such as GitHub, Google accounts, banking, have two factor authentication enabled. Yubikey offers affordable hardware tokens. See drduh/YubiKey-Guide and trmm.net/Yubikey. One of two Yubikey's slots can also be programmed to emit a long, static password (which can be used in combination with a short, memorized password, for example). In Addition to Login and other PAMs, you can use Yubikey to secure your login and sudo, here is a pdf guide from Yubico. Yubikey are a bit pricey, there is cheaper alternative, but not as capable, U2F Zero. Here is a great guide to set it up Backup Always encrypt files locally before backing them up to external media or online services. One way is to use a symmetric cipher with GPG and a password of your choosing. Files can also be encrypted to a public key with GPG, with the private key stored on YubiKey. To compress and encrypt a directory: To decrypt and decompress the directory: You can also create and use encrypted volumes using Disk Utility or hdiutil: With hdiutil you are also able to add the option -type SPARSE-BUNDLE. With these sparse bundles you may achieve faster backups because after the first run, the updated information and some padding needs to be transferred. A simple way to synchronize this encrypted folder to another server is using rsync: See also the following applications and services: Tresorit, SpiderOak, Arq, Espionage, and restic. Wi-Fi macOS remembers access points it has connected to. Like all wireless devices, the Mac will broadcast all access point names it remembers (e.g., MyHomeNetwork) each time it looks for a network, such as when waking from sleep. This is a privacy risk, so remove networks from the list in System Preferences > Network > Advanced when they are no longer needed. Also see Signals from the Crowd: Uncovering Social Relationships through Smartphone Probes (pdf) and Wi-Fi told me everything about you (pdf). Saved Wi-Fi information (SSID, last connection, etc.) can be found in: /Library/Preferences/SystemConfiguration/com.apple.airport.preferences.plist You may want to spoof the MAC address of the network card before connecting to new and untrusted wireless networks to mitigate passive fingerprinting: macOS stores Wi-Fi SSIDs and passwords in NVRAM in order for Recovery Mode to access the Internet. Be sure to either clear NVRAM or de-authenticate your Mac from your Apple account, which will clear the NVRAM, before passing a Mac along. Resetting the SMC will clear some of the NVRAM, but not all. Note MAC addresses will reset to hardware defaults on each boot. Finally, WEP protection on wireless networks is not secure and you should only connect to WPA2 protected networks when possible. SSH For outgoing SSH connections, use hardware or password-protected keys, set up remote hosts and consider hashing them for added privacy. See drduh/config/ssh_config for recommended client options. You can also use ssh to create an encrypted tunnel to send traffic through, similar to a VPN. For example, to use Privoxy running on a remote host port 8118: Or to use an ssh connection as a SOCKS proxy: By default, macOS does not have sshd or Remote Login enabled. To enable sshd and allow incoming ssh connections: Or use the System Preferences > Sharing menu. If enabling sshd, be sure to disable password authentication and consider further hardening your configuration. See drduh/config/sshd_config for recommended options. Confirm whether sshd is running: Physical access Keep your Mac physically secure at all times. Don't leave it unattended in public spaces, such as hotels. A skilled attacker with unsupervised physical access to your computer can infect the boot ROM to install a keylogger and steal your password, for example - see Thunderstrike. A helpful tool is usbkill, which is an anti-forensic kill-switch that waits for a change on your USB ports and then immediately shuts down your computer. Consider purchasing a privacy filter for your screen to thwart shoulder surfers. Superglues or epoxy resins can also be used to disable physical access to computer ports. Nail polish and tamper-evidence seals can be applied to components to detect tampering. System monitoring OpenBSM audit macOS has a powerful OpenBSM (Basic Security Module) auditing capability. You can use it to monitor process execution, network activity, and much more. To tail audit logs, use the praudit utility: See the manual pages for audit, praudit, audit_control and other files in /etc/security Note although man audit says the -s flag will synchronize the audit configuration, it appears necessary to reboot for changes to take effect. See articles on ilostmynotes.blogspot.com and derflounder.wordpress.com for more information. DTrace Note System Integrity Protection interferes with DTrace, so it is not possible to use it in recent macOS versions without disabling SIP. iosnoop monitors disk I/O opensnoop monitors file opens execsnoop monitors execution of processes errinfo monitors failed system calls dtruss monitors all system calls See man -k dtrace for more information. Execution ps -ef lists information about all running processes. You can also view processes with Activity Monitor. launchctl list and sudo launchctl list list loaded and running user and system launch daemons and agents. Network List open network files: List contents of various network-related data structures: Wireshark can be used from the command line with tshark. Monitor DNS queries and replies: Monitor HTTP requests and responses: Monitor x509 (SSL/TLS) certificates: Also see the simple networking monitoring application BonzaiThePenguin/Loading. Binary Whitelisting google/santa is a security software developed for Google's corporate Macintosh fleet and open sourced. Santa is a binary whitelisting/blacklisting system for macOS. It consists of a kernel extension that monitors for executions, a userland daemon that makes execution decisions based on the contents of a SQLite database, a GUI agent that notifies the user in case of a block decision and a command-line utility for managing the system and synchronizing the database with a server. Santa uses the Kernel Authorization API to monitor and allow/disallow binaries from executing in the kernel. Binaries can be white- or black-listed by unique hash or signing developer certificate. Santa can be used to only allow trusted code execution, or to blacklist known malware from executing on a Mac, similar to Bit9 software for Windows. Note Santa does not currently have a graphical user interface for managing rules. The following instructions are for advanced users only! To install Santa, visit the Releases page and download the latest disk image, the mount it and install the contained package: By default, Santa installs in ""Monitor"" mode (meaning, nothing gets blocked, only logged) and comes with two rules: one for Apple binaries and another for Santa software itself. Verify Santa is running and its kernel module is loaded: Create a blacklist rule to prevent iTunes from executing: Try to launch iTunes - it will be blocked. To remove the rule: Open iTunes: Create a new, example C program: Compile the program with GCC (requires installation of Xcode or command-line tools): Run it: Toggle Santa into ""Lockdown"" mode, which only allows whitelisted binaries to run: $ sudo defaults write /var/db/santa/config.plist ClientMode -int 2 Try to run the unsigned binary: To whitelist a specific binary, determine its SHA-256 sum: Add a whitelist rule: Run it: It's allowed and works! Applications can also be whitelisted by developer certificate (so that new binary versions will not need to be manually whitelisted on each update). For example, download and run Google Chrome - it will be blocked by Santa in ""Lockdown"" mode: Whitelist the application by its developer certificate (first item in the Signing Chain): In this case, 15b8ce88e10f04c88a5542234fbdfc1487e9c2f64058a05027c7c34fc4201153 is the SHA-256 of Googles Apple developer certificate (team ID EQHXZ8M8AV). To whitelist it: Google Chrome should now launch, and subsequent updates to the application will continue to work as long as the code signing certificate doesnt change or expire. To disable ""Lockdown"" mode: See /var/log/santa.log to monitor ALLOW and DENY execution decisions. A log and configuration server for Santa is available in Zentral, an open source event monitoring solution and TLS server for osquery and Santa. Zentral will support Santa in both MONITORING and LOCKDOWN operation mode. Clients need to be enrolled with a TLS connection to sync Santa Rules, all Santa events from endpoints are aggregated and logged back in Zentral. Santa events can trigger actions and notifications from within the Zentral Framework. Note Python, Bash and other interpreters are whitelisted (since they are signed by Apple's developer certificate), so Santa will not be able to block such scripts from executing. Thus, a potential non-binary program which disables Santa is a weakness (not vulnerability, since it is so by design) to take note of. Miscellaneous Disable Diagnostics & Usage Data. If you want to play music or watch videos, use VLC media player which is free and open source. If you want to use torrents, use Transmission which is free and open source (note: like all software, even open source projects, malware may still find its way in). You may also wish to use a block list to avoid peering with known bad hosts - see Which is the best blocklist for Transmission and johntyree/3331662. Manage default file handlers with duti, which can be installed with brew install duti. One reason to manage extensions is to prevent auto-mounting of remote file systems in Finder (see Protecting Yourself From Sparklegate). Here are several recommended file handlers to manage: Monitor system logs with the Console application or syslog -w or /usr/bin/log stream commands. In systems prior to macOS Sierra (10.12), enable the tty_tickets flag in /etc/sudoers to restrict the sudo session to the Terminal window/tab that started it. To do so, use sudo visudo and add the line Defaults tty_tickets. Set your screen to lock as soon as the screensaver starts: Expose hidden files and Library folder in Finder: Show all filename extensions (so that ""Evil.jpg.app"" cannot masquerade easily). Don't default to saving documents to iCloud: Enable Secure Keyboard Entry in Terminal (unless you use YubiKey or applications such as TextExpander). Disable crash reporter (the dialog which appears after an application crashes and prompts to report the problem to Apple): Disable Bonjour multicast advertisements: Disable Handoff and Bluetooth features, if they aren't necessary. Consider sandboxing your applications. See fG! Sandbox Guide (pdf) and s7ephen/OSX-Sandbox--Seatbelt--Profiles. Did you know Apple has not shipped a computer with TPM since 2006? macOS comes with this line in /etc/sudoers: Which stops sudo from changing the HOME variable when you elevate privileges. This means it will execute as root the bash dotfiles in the non-root user's home directory when you run ""sudo bash"". It is advisable to comment this line out to avoid a potentially easy way for malware or a local attacker to escalate privileges to root. If you want to retain the convenience of the root user having a non-root user's home directory, you can append an export line to /var/root/.bashrc, e.g.: Set a custom umask: Reboot, create a file in Finder and verify its permissions (macOS default allows 'group/other' read access): Related software CISOfy/lynis - Cross-platform security auditing tool and assists with compliance testing and system hardening. Dylib Hijack Scanner - Scan for applications that are either susceptible to dylib hijacking or have been hijacked. F-Secure XFENCE (formerly Little Flocker) - ""Little Snitch for files""; prevents applications from accessing files. Lockdown - Audits and remediates security configuration settings. Zentral - A log and configuration server for santa and osquery. Run audit and probes on inventory, events, logfiles, combine with point-in-time alerting. A full Framework and Django web server build on top of the elastic stack (formerly known as ELK stack). facebook/osquery - Can be used to retrieve low level system information. Users can write SQL queries to retrieve system information. google/grr - Incident response framework focused on remote live forensics. jipegit/OSXAuditor - Analyzes artifacts on a running system, such as quarantined files, Safari, Chrome and Firefox history, downloads, HTML5 databases and localstore, social media and email accounts, and Wi-Fi access point names. kristovatlas/osx-config-check - Checks your OSX machine against various hardened configuration settings. libyal/libfvde - Library to access FileVault Drive Encryption (FVDE) (or FileVault2) encrypted volumes. stronghold - Securely and easily configure your Mac from the terminal. Inspired by this guide. yelp/osxcollector - Forensic evidence collection & analysis toolkit for OS X. The Eclectic Light Company - Downloads - A collection of useful diagnostics and control applications and utilities for macOS. Additional resources Apple Open Source Auditing and Exploiting Apple IPC CIS Benchmarks Demystifying the DMG File Format Demystifying the i-Device NVMe NAND (New storage used by Apple) Developing Mac OSX kernel rootkits DoD Security Technical Implementation Guides for Mac OS EFF Surveillance Self-Defense Guide Extracting FileVault 2 Keys with Volatility Fuzzing the macOS WindowServer for Exploitable Vulnerabilities Hacker News discussion 2 Hacker News discussion Harden the World: Mac OSX 10.11 El Capitan Hidden backdoor API to root privileges in Apple OS X How to Switch to the Mac How to make macOS Spotlight fuck the fuck off and do your bidding IOKit kernel code execution exploit IPv6 Hardening Guide for OS X Mac Developer Library: Secure Coding Guide Mac Forensics: Mac OS X and the HFS+ File System (pdf) Mac OS X Forensics - Technical Report (pdf) Mac OS X and iOS Internals: To the Apple's Core by Jonathan Levin MacAdmins on Slack MacOS Hardening Guide - Appendix of *OS Internals: Volume III - Security & Insecurity Internals (pdf) Managing Macs at Google Scale (LISA '13) OS X 10.10 Yosemite: The Ars Technica Review OS X Core Technologies Overview White Paper (pdf) OS X Hardening: Securing a Large Global Mac Fleet (LISA '13) OSX.Pirrit Mac Adware Part III: The DaVinci Code Over The Air - Vol. 2, Pt. 1: Exploiting The Wi-Fi Stack on Apple Devices Patrick Wardle's Objective-See blog Remote code execution, git, and OS X Reverse Engineering Mac OS X blog Reverse Engineering Resources Security Configuration For Mac OS X Version 10.6 Snow Leopard (pdf) The EFI boot process The Great DOM Fuzz-off of 2017 The Intel Mac boot process The macOS Phishing Easy Button: AppleScript Dangers There's a lot of vulnerable OS X applications out there (Sparkle Framework RCE) Userland Persistence on Mac OS X iCloud security and privacy overview iSeeYou: Disabling the MacBook Webcam Indicator LED"
2409,"A modular, extendable, and easy-to-use physics engine for javascriptThis project is no longer maintained It's been many years since writing this library. And I don't have time to dedicate to maintain it. On the up side, Matter.js has really stepped up and taken the spotlight of javascript physics. It has everything PhysicsJS has and more. :) PhysicsJS A modular, extendable, and easy-to-use physics engine for javascript. Latest version: 0.7.0 (beta) Usage Please visit the website for details about installation and usage. Distribution files are in the dist/ directory. Contributing Source code is kept in the src/ directory. After any source code modifications it will be necessary to run the grunt build task to rebuild the source and run unit tests. First install grunt. Next install dev dependencies: $ npm install then run grunt $ grunt The default grunt task will create a _working/ directory with the PhysicsJS development build. You can play around with that. NOTE: the _working/ directory won't be committed (it is in .gitignore). After you run this you can use (Mr.doob's) htmleditor in editor/ to play around. If you want grunt to automatically create the development build when you modify the source in src/ then run: $ grunt watch Note grunt watch won't run unit tests. Pull Requests If you are contributing a bug-fix or a very minor addition, feel free to do a pull request on the master branch. If it is something else create a new (or existing) feature branch (eg: feature/MY_FEAT) and issue a pull request on that. If unsure, create an issue to discuss. Please ensure that: the files in dist/ are unmodified. the features you add are well documented with jsdoc comments if applicable. the code is indented with 4 space characters. License MIT Copyright (c) 2013 Jasper Palfree http://wellcaffeinated.net/PhysicsJS/ Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the ""Software""), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
3898,"config files for zsh, bash, completions, gem, git, irb, railsRyan Bates Dot Files These are config files to set up a system the way I like it. It now uses Oh My ZSH. If you would like to see my old, custom Bash and ZSH config, check out this branch I am running on Mac OS X, but it will likely work on Linux as well. Installation Run the following commands in your terminal. It will prompt you before it does anything destructive. Check out the Rakefile to see exactly what it does. After installing, open a new terminal window to see the effects. Feel free to customize the .zshrc file to match your preference. Features Many of the following features are added through the ""rbates"" Oh My ZSH plugin. I normally place all of my coding projects in ~/code, so this directory can easily be accessed (and tab completed) with the ""c"" command. There is also an ""h"" command which behaves similar, but acts on the home path. Tab completion is also added to rake and cap commands: To speed things up, the results are cached in local .rake_tasks~ and .cap_tasks~. It is smart enough to expire the cache automatically in most cases, but you can simply remove the files to flush the cache. If you're using git, you'll notice the current branch name shows up in the prompt while in a git repository. There are several features enabled in Ruby's irb including history and completion. Many convenience methods are added as well such as ""ri"" which can be used to get inline documentation in IRB. See irbrc file for details. Uninstall To remove the dotfile configs, run the following commands. Be certain to double check the contents of the files before removing so you don't lose custom settings. Then open a new terminal window to see the effects."
1973,"The next web scraper. See through the noise.Installation Features Flexible schema: Supports strings, arrays, arrays of objects, and nested object structures. The schema is not tied to the structure of the page you're scraping, allowing you to pull the data in the structure of your choosing. Composable: The API is entirely composable, giving you great flexibility in how you scrape each page. Pagination support: Paginate through websites, scraping each page. X-ray also supports a request delay and a pagination limit. Scraped pages can be streamed to a file, so if there's an error on one page, you won't lose what you've already scraped. Crawler support: Start on one page and move to the next easily. The flow is predictable, following a breadth-first crawl through each of the pages. Responsible: X-ray has support for concurrency, throttles, delays, timeouts and limits to help you scrape any page responsibly. Pluggable drivers: Swap in different scrapers depending on your needs. Currently supports HTTP and PhantomJS driver drivers. In the future, I'd like to see a Tor driver for requesting pages through the Tor network. Selector API xray(url, selector)(fn) Scrape the url for the following selector, returning an object in the callback fn. The selector takes an enhanced jQuery-like string that is also able to select on attributes. The syntax for selecting on attributes is selector@attribute. If you do not supply an attribute, the default is selecting the innerText. Here are a few examples: Scrape a single tag Scrape a single class Scrape an attribute Scrape innerHTML xray(url, scope, selector) You can also supply a scope to each selector. In jQuery, this would look something like this: $(scope).find(selector). xray(html, scope, selector) Instead of a url, you can also supply raw HTML and all the same semantics apply. API xray.driver(driver) Specify a driver to make requests through. Available drivers include: request - A simple driver built around request. Use this to set headers, cookies or http methods. phantom - A high-level browser automation library. Use this to render pages or when elements need to be interacted with, or when elements are created dynamically using javascript (e.g.: Ajax-calls). xray.stream() Returns Readable Stream of the data. This makes it easy to build APIs around x-ray. Here's an example with Express: xray.write(path) Stream the results to a path. If no path is provided, then the behavior is the same as .stream(). xray.then(cb) Constructs a Promise object and invoke its then function with a callback cb. Be sure to invoke then() at the last step of xray method chaining, since the other methods are not promisified. xray.paginate(selector) Select a url from a selector and visit that page. xray.limit(n) Limit the amount of pagination to n requests. xray.abort(validator) Abort pagination if validator function returns true. The validator function receives two arguments: result: The scrape result object for the current page. nextUrl: The URL of the next page to scrape. xray.delay(from, [to]) Delay the next request between from and to milliseconds. If only from is specified, delay exactly from milliseconds. xray.concurrency(n) Set the request concurrency to n. Defaults to Infinity. xray.throttle(n, ms) Throttle the requests to n requests per ms milliseconds. xray.timeout (ms) Specify a timeout of ms milliseconds for each request. Collections X-ray also has support for selecting collections of tags. While x('ul', 'li') will only select the first list item in an unordered list, x('ul', ['li']) will select all of them. Additionally, X-ray supports ""collections of collections"" allowing you to smartly select all list items in all lists with a command like this: x(['ul'], ['li']). Composition X-ray becomes more powerful when you start composing instances together. Here are a few possibilities: Crawling to another site Scoping a selection Filters Filters can specified when creating a new Xray instance. To apply filters to a value, append them to the selector using |. Examples selector: simple string selector collections: selects an object arrays: selects an array collections of collections: selects an array of objects array of arrays: selects an array of arrays In the Wild Levered Returns: Uses x-ray to pull together financial data from various unstructured sources around the web. Resources Video: https://egghead.io/lessons/node-js-intro-to-web-scraping-with-node-and-x-ray Backers Support us with a monthly donation and help us continue our activities. [Become a backer] Sponsors Become a sponsor and get your logo on our website and on our README on Github with a link to your site. [Become a sponsor] License MIT"
3764,"A high performance caching library for Java Caffeine is a high performance, near optimal caching library. For more details, see our user's guide and browse the API docs for the latest release. Cache Caffeine provides an in-memory cache using a Google Guava inspired API. The improvements draw on our experience designing Guava's cache and ConcurrentLinkedHashMap. Features at a Glance Caffeine provides flexible construction to create a cache with a combination of the following features: * automatic loading of entries into the cache, optionally asynchronously * size-based eviction when a maximum is exceeded based on frequency and recency * time-based expiration of entries, measured since last access or last write * asynchronously refresh when the first stale request for an entry occurs * keys automatically wrapped in weak references * values automatically wrapped in weak or soft references * notification of evicted (or otherwise removed) entries * writes propagated to an external resource * accumulation of cache access statistics In addition, Caffeine offers the following extensions: * JSR-107 JCache * Guava adapters * Simulation Use Caffeine in a community provided integration: * Play Framework: High velocity web framework * Micronaut: A modern, full-stack framework * Spring Cache: As of Spring 4.3 & Boot 1.4 * Akka: Build reactive applications easily * Quarkus: Supersonic Subatomic Java * Scaffeine: Scala wrapper for Caffeine * ScalaCache: Simple caching in Scala * Camel: Routing and mediation engine * JHipster: Generate, develop, deploy Powering infrastructure near you: * Dropwizard: Ops-friendly, high-performance, RESTful APIs * Cassandra: Manage massive amounts of data, fast * Accumulo: A sorted, distributed key/value store * HBase: A distributed, scalable, big data store * Apache Solr: Blazingly fast enterprise search * Infinispan: Distributed in-memory data grid * Redisson: Ultra-fast in-memory data grid * OpenWhisk: Serverless cloud platform * Corfu: A cluster consistency platform * Grails: Groovy-based web framework * Finagle: Extensible RPC system * Neo4j: Graphs for Everyone * Druid: Real-time analytics In the News An in-depth description of Caffeine's architecture. Design of a Modern Cache: part #1, part #2 (slides) at HighScalability Caffeine is presented as part of research papers evaluating its novel eviction policy. TinyLFU: A Highly Efficient Cache Admission Policy by Gil Einziger, Roy Friedman, Ben Manes Adaptive Software Cache Management by Gil Einziger, Ohad Eytan, Roy Friedman, Ben Manes Download Download from Maven Central or depend via Gradle: See the release notes for details of the changes. Snapshots of the development version are available in Sonatype's snapshots repository."
2238,"Self-hosted, easily-deployable monitoring and alerts service - like a lightweight PagerDutyCabot Maintainers wanted Cabot is stable and used by hundreds of companies and individuals in production, but it is not actively maintained. We would like to hand over maintenance of the project to one or more responsible and experienced maintainers. Please email cabot@arachnys.com with some information about yourself (github profile and/or CV) if you are interested. Why choose Cabot Cabot is a free, open-source, self-hosted infrastructure monitoring platform that provides some of the best features of PagerDuty, Server Density, Pingdom and Nagios without their cost and complexity. (Nagios, I'm mainly looking at you.) It provides a web interface that allows you to monitor services (e.g. ""Stage Redis server"", ""Production ElasticSearch cluster"") and send telephone, sms or hipchat/email alerts to your on-duty team if those services start misbehaving or go down - all without writing a line of code. Best of all, you can use data that you're already pushing to Graphite/statsd to generate alerts, rather than implementing and maintaining a whole new system of data collectors. You can alert based on: Metrics from Graphite Status code and response content of web endpoints Jenkins build statuses We built Cabot as a Christmas project at Arachnys because we couldn't wrap our heads around Nagios, and nothing else out there seemed to fit our use case. We're open-sourcing it in the hope that others find it useful. Cabot is written in Python and uses Django, Bootstrap, Font Awesome and a whole host of other goodies under the hood. Screenshots Services dashboard Single service overview Quickstart Using Docker: Deploy in 5 minutes or less using official quickstart guide at cabotapp.com. (See also https://hub.docker.com/r/cabotapp/cabot/) How it works Docs have moved to cabotapp.com Sections: Configuration Deployment Services Graphite checks Jenkins checks HTTP checks Alerting Users Rota For those who want to contribute: Help develop Contribute code FAQ Why ""Cabot""? My dog is called Cabot and he loves monitoring things. Mainly the presence of food in his immediate surroundings, or perhaps the frequency of squirrel visits to our garden. He also barks loudly to alert us on certain events (e.g. the postman coming to the door). It's just a lucky coincidence that his name sounds like he could be an automation tool. API The API has automatically generated documentation available by browsing https://cabot.yourcompany.com/api. The browsable documentation displays example GET requests and lists other allowed HTTP methods. To view individual items, append the item id to the url. For example, to view graphite_check 1, browse: Authentication The API allows HTTP basic auth using standard Django usernames and passwords as well as session authentication (by submitting the login form on the login page). The API similarly uses standard Django permissions to allow and deny API access. All resources are GETable by any authenticated user, but individual permissions must be granted for POST, PUT, and other write methods. As an example, for POST access to all status_check subclasses, add the following permissions: Access the Django admin page at https://cabot.yourcompany.com/admin to add/remove users, change user permissions, add/remove groups for group-based permission control, and change group permissions. Sorting and Filtering Sorting and filtering can be used by both REST clients and on the browsable API. All fields visible in the browsable API can be used for filtering and sorting. Get all jenkins_checks with debounce enabled and CRITICAL importance: Sort graphite_checks by name field, ascending: Sort by name field, descending: Other (non-Cabot specific) examples are available in the Django REST Framework documentation. License See LICENSE file in this repo."
1421,"xhyve, a lightweight OS X virtualization solutionxhyve.xyz About The xhyve hypervisor is a port of bhyve to macOS. It is built on top of Hypervisor.framework in OS X 10.10 Yosemite and higher, runs entirely in userspace, and has no other dependencies. It can run FreeBSD, some Linux distributions, and Windows 10 and may gain support for other guest operating systems in the future. License: BSD-2-Clause Introduction: http://www.pagetable.com/?p=831 Requirements OS X 10.10.3 Yosemite or later a 2010 or later Mac (i.e. a CPU that supports EPT: sysctl kern.hv_support = 1) Installation If you have homebrew, then simply: $ brew update $ brew install --HEAD xhyve The --HEAD in the brew command ensures that you always get the latest changes, even if the homebrew database is not yet updated. If for any reason you don't want that simply do brew install xhyve . If you have MacPorts, then simply: $ sudo port selfupdate $ sudo port install xhyve MacPorts is up to date with the GitHub ref listed in the port info $ port info xhyve xhyve @20170117 (emulators) ... Otherwise: Building $ git clone https://github.com/machyve/xhyve.git $ cd xhyve $ xcodebuild The resulting binary will be in build/Release/xhyve Usage $ xhyve -h See below for steps to boot various OSs What is bhyve? bhyve is the FreeBSD hypervisor, roughly analogous to KVM + QEMU on Linux. It has a focus on simplicity. It exposes the following peripherals to virtual machines: Local x(2)APIC IO-APIC 8259A PIC 8253/8254 PIT HPET PM Timer RTC PS/2 Keyboard and Mouse (via VNC) PCI host bridge passthrough UART AHCI (i.e. HDD and CD) VirtIO block device VirtIO networking VirtIO RNG Intel e1000 (aka e82545) VGA/Framebuffer (exposed with a minimal VNC server) XHCI USB support with one device defined - a tablet for Windows guest support bhyve architecture Linux I/O VM control FreeBSD NetBSD OpenBSD | A | A | | V | V | V V +-------------++-------------++-------------++-------------+ | || || || | | bhyve || bhyvectl || bhyveload || grub2-bhyve | | || || || | | || || || | +-------------++-------------++-------------++-------------+ +----------------------------------------------------------+ | libvmmapi | +----------------------------------------------------------+ A | user ------------------------------------------------------------ | ioctl FreeBSD kernel V +----------------------------+ | VMX/SVM host | | VMX/SVM guest | | VMX/SVM nested paging | | Timers | | Interrupts | +----------------------------+ vmm.ko vmm.ko The bhyve FreeBSD kernel module. Manages VM and vCPU objects, the guest physical address space and handles guest interaction with PIC, PIT, HPET, PM Timer, x(2)APIC and I/O-APIC. Contains a minimal x86 emulator to decode guest MMIO. Executes the two innermost vCPU runloops (VMX/SVM and interrupts/timers/paging). Has backends for Intel VMX and AMD SVM. Provides an ioctl and mmap API to userspace. libvmmapi Thin abstraction layer between the vmm.ko ioctl interface and the userspace C API. bhyve The userspace bhyve component (kind of a very light-weight QEMU) that executes virtual machines. Runs the guest I/O vCPU runloops. Manages ACPI, PCI and all non in-kernel devices. Interacts with vmm.ko through libvmmapi. bhyvectl Somewhat superfluous utility to introspect and manage the life cycle of virtual machines. Virtual machines and vCPUs can exist as kernel objects independently of a bhyve host process. Typically used to delete VM objects after use. Odd architectural choice. bhyveload Userspace port of the FreeBSD bootloader. This is a cumbersome workaround to bootstrap a FreeBSD guest operating system without using firmware. It creates a VM object, loads the FreeBSD kernel into guest memory, sets up the initial vCPU state and then exits. Only then a VM can be executed by bhyve. grub2-bhyve Performs the same function as bhyveload but is a userspace port of GRUB2. It is used to bootstrap guest operating systems other than FreeBSD, i.e. Linux, OpenBSD and NetBSD. xhyve architecture +----------------------------------------------------------+ | xhyve | | | | I/O | | | | | | | |+--------------------------------------------------------+| || vmm VMX guest || || Timers || || Interrupts || |+--------------------------------------------------------+| +----------------------------------------------------------+ +----------------------------------------------------------+ | Hypervisor.framework | +----------------------------------------------------------+ A | user ------------------------------------------------------------ |syscall xnu kernel V VMX host VMX nested paging xhyve shares most of the code with bhyve but is architecturally very different. Hypervisor.framework provides an interface to the VMX VMCS guest state and a safe subset of the VMCS control fields, thus making userspace hypervisors without any additional kernel extensions possible. The VMX host state and all aspects of nested paging are handled by the macOS kernel, you can manage the guest physical address space simply through mapping of regions of your own address space. xhyve is equivalent to the bhyve process but gains a subset of a userspace port of the vmm kernel module. SVM, PCI passthrough and the VMX host and EPT aspects are dropped. The vmm component provides a libvmmapi compatible interface to xhyve. Hypervisor.framework seems to enforce a strict 1:1 relationship between a host process/VM and host thread/vCPU, that means VMs and vCPUs can only be interacted with by the processes and threads that created them. Therefore, unlike bhyve, xhyve needs to adhere to a single process model. Multiple virtual machines can be created by launching multiple instances of xhyve. xhyve retains most of the bhyve command line interface. bhyvectl, bhyveload and grub2-bhyve are incompatible with a single process model and are dropped. xhyve supports the Linux kexec protocol, a very simple and straightforward way to bootstrap a Linux kernel. It takes a bzImage and optionally initrd image and kernel parameter string as input. xhyve can now boot an OS via EFI. The BSD-licensed TianoCore EFI built for bhyve can be used to boot Windows and other OSs. Networking If you want the same IP address across VM reboots, assign a UUID to a particular VM: $ xhyve [-U uuid] Optional: If you need more advanced networking and already have a configured TAP device you can use it with: virtio-tap,tapX instead of: virtio-net Where X is your tap device, i.e. /dev/tapX. Booting TinyCoreLinux Everything needed to boot TinyCoreLinux is included with xhyve. Steps: From Terminal, launch the xhyverun-tinycorelinux.sh script in your xhyve directory. Booting FreeBSD (via userboot) Requirements: A FreeBSD iso image. This can be downloaded from FreeBSD.org Steps: Build xhyve with make (type make in Terminal from your xhyve directory) - this will build an unsigned copy of xhyve mkfile 5g FreeBSD.dmg - Create a blank image to install to Use your favorite text editor to edit the xhyverun-freebsd.sh script and properly set the paths to the iso and disk image Run the script from Terminal with sudo: sudo ./xhyverun-freebsd.sh and enter your admin password Known Issues: - This will only work with an unsigned build of xhyve - See Codesigning/Entitlements in Issues Booting Windows (via EFI) Now that xhyve has support for a framebuffer, EFI and the e1000 NIC, xhyve can now run Windows in a VM. Requirements: A Windows 10 iso image. This can be downloaded from Microsoft: Windows 10 iso A license key for Windows. The bhyve EFI - this can be downloaded in FreeBSD via pkg install bhyve-firmware - the EFI will be named ""BHYVE_UEFI.fd"" and installed into /usr/local/share/uefi-firmware. Copy that file to macOS. A VNC client - these vary greatly in speed and willingness to connect to the fairly minimal VNC server built into the framebuffer code. Steps: mkfile 20g Windows.dmg - Create a blank image to install to Use your favorite text editor to edit the xhyverun-windows.sh script and properly set the paths to the iso, disk image and BHYVE_UEFI.fd From Terminal, launch the modified xhyverun-windows.sh script in your xhyve directory. Connect the VNC client to 127.0.0.1:29000 Known Issues: Windows does not recognize more than one CPU and the CPU device is missing from Device Manager The e1000 emulation works, but is incomplete - network statistics don't appear in Task Manager or Resource Monitor Mouse positioning in VNC is wacky - this is due to the nature of how mouse deltas are passed to the VM and what Windows does to them afterwards. Once Windows is installed, one can enable remote connection and connect with Microsoft Remote Desktop instead of the VNC client. Issues Virtual Box If you are, or were, running any version of VirtualBox, prior to 4.3.30 or 5.0, and attempt to run xhyve, your system will immediately crash as a kernel panic is triggered. This is due to a VirtualBox bug (that got fixed in newest VirtualBox versions) as VirtualBox wasn't playing nice with OSX's Hypervisor.framework used by xhyve. To get around this you either have to update to newest VirtualBox 4.3 or 5.0 or, if you for some reason are unable to update, to reboot your Mac after using VirtualBox and before attempting to use xhyve. (see issues #5 and #9 for the full context) Code signing/Entitlements macOS limits access to the networking API (vmnet) to builds that are code signed and have the appropriate entitlement. The code signing/entitlement requirement can be bypassed by running xhyve as root (via sudo). A code signed build cannot run FreeBSD via the userboot.so bootloader as that requires loading and executing code that is outside the code signature (even as root). Building xhyve via xcodebuild signs the build. Building xhyve via make does not. TODO vmm: enable APIC access page to speed up APIC emulation (performance) enable x2APIC MSRs (even faster) (performance) vmm_callout: is a quick'n'dirty implementation of the FreeBSD kernel callout mechanism seems to be racy fix races or perhaps replace with something better use per vCPU timer event thread (performance)? use hardware VMX preemption timer instead of pthread_cond_wait (performance) some 32-bit guests are broken (support PAE paging in VMCS) PCID guest support (performance) block_if: macOS does not support preadv/pwritev, we need to serialize reads and writes for the time being until we find a better solution. (performance) support block devices other than plain files virtio_net: unify TAP and vmnet backends vmnet: send/receive more than a single packet at a time (performance) virtio_rnd: is untested e1000 is untested beyond basically working with Windows fix missing statistics (see Booting Windows) add support for TAP tune performance (performance) framebuffer is untested beyond basically working with Windows VNC: add support for more modern connections (ssh) to improve security and compatibility with more clients add an option to share the framebuffer with a client UI app (specifics need defining) (performance) UEFI is untested beyond basically working with Windows Needs testing against various OSs figure out why Windows doesn't properly see more than one CPU (might also involve ACPI) XHCI Move XHCI support and the tablet device to xhyve remove explicit state transitions: since only the owning task/thread can modify the VM/vCPUs a lot of the synchronization might be unnecessary (performance) performance, performance and performance remove vestigial code, cleanup"
135,"A javascript library for multi-touch gestures :// You can touch thishammer.js A JavaScript library for detecting touch gestures. Installation NPM or Yarn or CDN https://cdnjs.com/libraries/hammer.js/ Usage hammer.js has a quick start option for gestures it already recognizes. If you want to recognize your own gestures, such as tripletap, then you'll have to use these steps: Examples tap double tap press swipe Documentation For further information regarding hammer.js, please read our documentation. Contributions Feel encouraged to report issues or submit pull requests. When you're ready to do either, read our contribution guidelines. If you're looking for another form of contribution, we love help answering questions on our slack channel. License MIT "
4313,"[NO LONGER MAINTAINED] A JS utility for for parsing URLs and extracting information out of them.Purl (A JavaScript URL parser) v2.3.1 PLEASE NOTE: THIS PACKAGE IS NO LONGER MAINTAINED. There are plenty of great alternatives such as URI.js which I suggest you check out instead. An AMD compatible utility to parse urls and provide easy access to their attributes (such as the protocol, host, port etc), path segments, querystring parameters, fragment parameters and more. The core parser functionality is based on the Regex URI parser by Steven Levithan, and the query string parsing is handled by a modified version of node-querystring. Note this used to have a jQuery dependency - this is now optional. See below for details License: Available for use under a MIT-style license. If you need a different license for any reason please just let me know. To jQuery or not to jQuery, that is the question... This utility can be used in two ways - with jQuery or without. There is just one file (purl.js) for both versions - if jQuery is included on the page before it then it will provide the 'jQuery-style' interface (see examples below), otherwise it will be accessible via the global purl variable. The jQuery version has an additional feature that lets it extract the URL from a jQuery element object, where appropriate. Specifying the URL to parse There are a few different ways to choose what URL to parse: URL attributes The .attr() method is used to return information on various parts of the URL. For example: The attributes available for querying are: sourceThe whole url being parsed protocoleg. http, https, file, etc hosteg. www.mydomain.com, localhost etc porteg. 80 relativeThe relative path to the file including the querystring (eg. /folder/dir/index.html?item=value) pathThe path to the file (eg. /folder/dir/index.html) directoryThe directory part of the path (eg. /folder/dir/) fileThe basename of the file eg. index.html queryThe entire query string if it exists, eg. item=value&item2=value2 fragment or anchorThe entire string after the # symbol There are also a few more obscure ones available too if you want to dig about a bit ;-) If you don't specify an attribute then this method will return an object literal with all the available attribute key:value pairs in it. Query string parameters The .param() method is used to return the values of querystring parameters. Pass in a string to access that parameter's value: If no argument is passed in it will return an object literal containing a key:value map of all the querystring parameters. Note that the .param() method will work on both ampersand-split and semicolon-split querystrings. As of version 2.2 the param method now handles array-style query string params. URL segments The .segment() method is used to return values of individual segments from the URL's path. Pass in an integer value to get the value of that segment - note however that the count is not zero-indexed like an array - i.e. .segment(1) returns the first segment, not the second one. You can also pass in negative values, in which case it will count back from the end of the path rather than forwards from the start. If no argument is passed in it will return an array of all the segments (which will be zero-indexed!). Fragment parameters and/or segments Some sites and apps also use the hash fragment to store querystring-style key value pairs (eg. http://test.com/#sky=blue&grass=green), or slash-delimited paths (eg. http://test.com/#/about/us/). There are two methods available for extracting information from fragments of these types - .fparam() and .fsegment(), both of which behave indentically to their .param() and .segment() counterparts but act on the fragment rather than the main URL. Strict mode and relative URLs Internally this plugin uses Steven Levithan's excellent Regex URI parser, which has two modes - loose and strict. This plugin uses the loose mode by default (i.e. strict mode set to false), which deviates slightly from the specs but can produce more intuitive results in some situations. However, loose mode will not correctly parse relative URLs, so you can optionally enable strict mode when calling the plugin as follows: A note on improperly encoded URLs If you attempt to use this plugin to parse a URL that has an invalid character encoding in it, it will throw a URIError Exception. This will happen if the URL has a percentage sign followed by either a non-numeric character or a numeric value of greater than 80 (i.e. 128 in decimal). If there is a chance you may end up parsing a badly encoded URL you should probably wrap your calls to this plugin in a try/catch block to prevent this causing unforseen problems. Thanks to steve78b for pointing this out. Older versions and compatability Please note that v2.x is not backwards compatible with v1.x of this plugin. v1.1 is still available for download should you need it for some reason. Testing @omarqureshi has kindly contributed some unit tests, which can be run using http://busterjs.org. The tests only currently cover the non-jQuery version. To run you'll need to have Buster installed (requires node and npm); Once it's installed, just do: Buster will then start up a server and give you a url (like http://localhost:8956) which you can navigate to with your browser of choice to see the test results."
2758,"jQuery Plugin for Sticky ObjectsSticky Sticky is a jQuery plugin that gives you the ability to make any element on your page always stay visible. Sticky in brief This is how it works: When the target element is about to be hidden, the plugin will add the class className to it (and to a wrapper added as its parent), set it to position: fixed and calculate its new top, based on the element's height, the page height and the topSpacing and bottomSpacing options. That's it. In some cases you might need to set a fixed width to your element when it is ""sticked"". But by default (widthFromWrapper == true) sticky updates elements's width to the wrapper's width. Check the example-*.html files for some examples. Usage Include jQuery & Sticky. Call Sticky. Edit your css to position the elements (check the examples in example-*.html). To unstick an object Options topSpacing: (default: 0) Pixels between the page top and the element's top. bottomSpacing: (default: 0) Pixels between the page bottom and the element's bottom. className: (default: 'is-sticky') CSS class added to the element's wrapper when ""sticked"". wrapperClassName: (default: 'sticky-wrapper') CSS class added to the wrapper. center: (default: false) Boolean determining whether the sticky element should be horizontally centered in the page. getWidthFrom: (default: '') Selector of element referenced to set fixed width of ""sticky"" element. widthFromWrapper: (default: true) Boolean determining whether width of the ""sticky"" element should be updated to match the wrapper's width. Wrapper is a placeholder for ""sticky"" element while it is fixed (out of static elements flow), and its width depends on the context and CSS rules. Works only as long getWidthForm isn't set. responsiveWidth: (default: false) Boolean determining whether widths will be recalculated on window resize (using getWidthfrom). zIndex: (default: inherit) controls z-index of the sticked element. Methods sticky(options): Initializer. options is optional. sticky('update'): Recalculates the element's position. Events sticky-start: When the element becomes sticky. sticky-end: When the element returns to its original location sticky-update: When the element is sticked but position must be updated for constraints reasons sticky-bottom-reached: When the element reached the bottom space limit sticky-bottom-unreached: When the element unreached the bottom space limit To subscribe to events use jquery:"
621,"An interactive TLS-capable intercepting HTTP proxy for penetration testers and software developers.mitmproxy mitmproxy is an interactive, SSL/TLS-capable intercepting proxy with a console interface for HTTP/1, HTTP/2, and WebSockets. mitmdump is the command-line version of mitmproxy. Think tcpdump for HTTP. mitmweb is a web-based interface for mitmproxy. Installation The installation instructions are here. If you want to install from source, see CONTRIBUTING.md. Documentation & Help General information, tutorials, and precompiled binaries can be found on the mitmproxy website. The documentation for mitmproxy is available on our website: If you have questions on how to use mitmproxy, please ask them on StackOverflow! Contributing As an open source project, mitmproxy welcomes contributions of all forms. Also, please feel free to join our developer Slack!"
977,":european_castle: All the things you didn't know you wanted to know about data structuresWelcome to Itsy Bitsy Data Structures! In here are super simplified examples of many of the common data structures written in easy to read JavaScript. Reading through the guided code will help you learn about what data structures are, what their uses are, and how to discuss them. Want to jump into the code? Click here Also be sure to check out my other code walkthrough: The Super Tiny Compiler Why should I care? Data Structures might not be the juiciest topic in the world, but they are hugely important to growing as an engineer. Knowing data structures don't just make your programs faster and more efficient, but they help you organize your code and your thoughts so that you can build more complicated programs without a ton of mental overhead. But data structures are scary! Yeah, lots of computer science topics are intimidating, and that's largely a fault of how they are taught. In this we're going to do a high level pass over a lot of the key things you need to know in order to dive into them deeper. It's more about introducing you to the shared language of data structures. Okay so where do I begin? Awesome! Head on over to the itsy-bitsy-data-structures.js file. I'm back, that didn't make sense Ouch, I'm really sorry. I'm planning on doing a lot more work on this to add inline annotations. If you want to come back when that's done, you can either watch/star this repo or follow me on twitter for updates."
3565,"A progress wheel for android, intended for use instead of the standard progress bar.Deprecation warning This project is no-longer maintained, and has not been maintained for a few years now. If you're looking for an alternative library, consider the below options: https://github.com/pnikosis/materialish-progress https://github.com/ybq/Android-SpinKit https://github.com/zekapp/Android-ProgressViews If, on the other hand, you'd like to take over maintinance of the project or modernise it, feel free to do so; just send me pull requests or an email (at todd434@gmail.com). Progress Wheel This is a custom component for Android intended for use instead of a progress bar. Compare it side by side with the Android 2x progress wheel: A complete walkthrough of how to use this component in your app XML: To implement the view in your xml layout do the following: Add the following to your attrs.xml file (in res/values): Add the following code to the root view of your layout: xmlns:ProgressWheel=""http://schemas.android.com/apk/res/com.visualdenim.schooltraq"" Add the widget code in the appropriate place in your xml file. Here's a sample implementation: Java: First you need to either get a ProgressWheel from a layout file, or initalise one. Do this by: ProgressWheel pw = new ProgressWheel(myContext, myAttributes); ProgressWheel pw = (ProgressWheel) findViewById(R.id.pw_spinner); To spin the progress wheel, you just call .startSpinning() and to stop it spinning, you call .stopSpinning() Incrementing the progress wheel is slightly more tricky, you call .incrementProgress(). However, this is out of 360, (because a circle has 360 degrees), and will automatically reset once you get past 360. A percentage display is automatically displayed. Using as a dependency Add this to your build.gradle: Using as a library project To use it as a library in Android Studio, please edit build.gradle. Modify: apply plugin: 'android' Into: apply plugin: 'android-library' Since Android SDK Tools revision 17 (released March 2012), this component can be used as a library project. In this case, you do not need to copy anything into your project's attrs.xml, and you must use the following namespace URI, instead of the above: xmlns:ProgressWheel=""http://schemas.android.com/apk/res-auto"" Otherwise, usage should be the same. Todd Davies - @Todd__Davies - 2012"
1842,"Functional css for humansTACHYONS Functional CSS for humans. Quickly build and design new UI without writing CSS. Principles Everything should be 100% responsive Everything should be readable on any device Everything should be as fast as possible Designing in the browser should be easy It should be easy to change any interface or part of an interface without breaking any existing interfaces Doing one thing extremely well promotes reusability and reduces repetition Documentation helps promote reusability and shared knowledge CSS shouldn't impede accessibility or the default functionality of HTML You should send the smallest possible amount of code to the user Features Mobile-first CSS architecture 490 accessible color combinations 8px baseline grid Multiple debugging utilities to reduce layout struggles Single-purpose class structure Optimized for maximum gzip compression Lightweight (~14kB) Usable across projects Growing open source component library Works well with plain HTML, React, Ember, Angular, Rails and more Infinitely nestable responsive grid system Built with PostCSS Getting Started Docs can be found at http://tachyons.io/docs The modules are generally pretty small and thus quick and easy to read. Use the CDN The quickest and easiest way to start using Tachyons is to include a reference to the minified file in the head of your HTML file. Local Setup Clone the repo from Github and install dependencies through npm. Dev If you want to just use everything in tachyons/src as a jumping off point and edit all the code yourself, you can compile all of your wonderful changes by running: This will output both minified and unminified versions of the CSS to the CSS directory and watch the src directory for changes. It's aliased to the command: If you'd like to just build the CSS once without watching the src directory, run: If you want to check that a class hasn't been redefined or 'mutated,' there is a linter to check that all of the classes have only been defined once. This can be useful if you are using another library or have written some of your own CSS and want to make sure there are no naming collisions. To do this run the command: Docs The tachyons docs located at http://tachyons.io are all open source and located at https://github.com/tachyons-css/tachyons-css.github.io You can clone the docs and use them as a template for documenting your own design system / patterns / components. While not everything is automated, the component library generation makes it extremely easy to generate and organize the documentation for components as demonstrated at http://tachyons.io/components Community Resources DWYL Learn Tachyons: Learn how to use Tachyons to craft beautiful, responsive, functional and fast UI with minimal CSS Tachyons TLDR: Quick lookup for Tachyons classes, scales and color palette Tachyons Pro: Fun quiz for memorizing class names Contributing Please read our code of conduct for contributors. Tachyons in Production A longer list of sites that use tachyons in production can be found in sites.md We love letting the community see what people are building. Please add your link to sites.md in a PR or by opening an issue if you're willing to share to your site or project. Featured Sites https://interfacelovers.com https://npmjs.com https://womenwho.design https://friendstalkfrontend.com https://play.webvr.rocks https://gohugo.io https://coralproject.net http://www.philipyoungg.com https://gitpoint.co https://2017.nodeconf.com.ar https://goldenstaterecord.com http://hicuties.com https://urlbox.io https://fontawesome.com https://purple3.herokuapp.com http://blunt.af/tachy.app/ https://fenderdigital.github.io/css-utilities/intro/ https://play.cash https://bitmidi.com And of course... * http://tachyons.io Sponsors Development of Tachyons is supported by Digital Ocean DWYL VTEX Manifold Help If you have a question or need help feel free to open an issue here or jump into the Tachyons slack channel."
3788,"QOR is a set of libraries written in Go that abstracts common features needed for business applications, CMSs, and E-commerce systems.QOR English Chat Room: For security issues, please send us an email to security@getqor.com and give us time to respond BEFORE posting as an issue or reporting on public forums. What is QOR? QOR is a set of libraries written in Go that abstracts common features needed for business applications, CMSs, and E-commerce systems. This is a complete rewrite in Go, of the original QOR, which was a proprietary framework written in Ruby on Rails and used internally at The Plant. QOR 1.0 is the first version to be open sourced and distributed under the MIT license. What QOR is not QOR is not a ""boxed turnkey solution"". You need proper coding skills to use it. It's designed to make the lives of developers easier when building complex EC systems, not providing you one out of the box. Documentation https://doc.getqor.com/ The modules Admin - The core part of QOR system, will generate an admin interface and RESTFul API for you to manage your data Publish - Providing a staging environment for all content changes to be reviewed before being published to the live system Transition - A configurable State Machine: define states, events (eg. pay order), and validation constraints for state transitions Media Library - Asset Management with support for several cloud storage backends and publishing via a CDN Worker (Batch processing) - A process scheduler Exchange - Data exchange with other business applications using CSV or Excel data Internationalization (i18n) - Managing and (inline) editing of translations Localization (l10n) - Manage DB-backed models on per-locale basis, with support for defining/editing localizable attributes, and locale-based querying Roles - Access Control And more https://github.com/qor Live DEMO Live Demo http://demo.getqor.com/admin Source Code of Live Demo https://github.com/qor/qor-example Frontend Development Requires Node.js and Gulp for building frontend files Watch SCSS/JavaScript changes: gulp Build Release files: gulp release License Released under the MIT License."
29,"Parse, validate, manipulate, and display dates in javascript.Moment.js A JavaScript date library for parsing, validating, manipulating, and formatting dates. Project Status Moment.js is a legacy project, now in maintenance mode. In most cases, you should choose a different library. For more details and recommendations, please see Project Status in the docs. Thank you. Resources Documentation Changelog Stack Overflow License Moment.js is freely distributable under the terms of the MIT license."
429,"Drone is a Container-Native, Continuous Delivery PlatformDrone is a Continuous Delivery system built on container technology. Drone uses a simple YAML configuration file, a superset of docker-compose, to define and execute Pipelines inside Docker containers. Sample Pipeline Configuration: Documentation and Other Links: Setup Documentation docs.drone.io/installation Usage Documentation docs.drone.io/getting-started Plugin Index plugins.drone.io Getting Help discourse.drone.io Build the Enterprise Edition BUILDING Build the Community Edition BUILDING_OSS Please note the official Docker images run the Drone Enterprise distribution. If you would like to run the Community Edition you can build from source by following the instructions in BUILDING_OSS."
1874,"Helium - javascript tool to scan your site and show unused CSSHelium is a tool for discovering unused CSS across many pages on a web site. The tool is javascript-based and runs from the browser. Helium accepts a list of URLs for different sections of a site then loads and parses each page to build up a list of all stylesheets. It then visits each page in the URL list and checks if the selectors found in the stylesheets are used on the pages. Finally, it generates a report that details each stylesheet and the selectors that were not found to be used on any of the given pages. Note: You really should only run Helium on a local, development, or otherwise privately accessible version of your site. If you run this on your public site, every visitor will see the Helium test environment. PLEASE READ THE ""IMPORTANT STUFF"" SECTION BELOW!! Installation Add a script element somewhere on your site that is loaded into every page that will be tested. This is typically a header or footer section. The element looks like: Note: path/to/helium.js needs to reflect the path of where you place the javascript file. If you would like to use a CDN hosted version of Helium, checkout https://cdnjs.com/libraries/helium-css. Helium is initiated by calling the method ""helium.init()"". This has to be placed somewhere on the page where it gets called after page load. An example of this is: Note: Depending on the javascript loading strategy your site employs, you may wish to place ""helium.init()"" within a location that executes javascript after page load. Usage Once Helium is setup, when you load your site you will see a box with a textarea where you input your URL list. After you paste your list of links, click Start (lower left) to begin the process. Clicking ""Reset to Beginning"" clears the textarea and stored data. The test will proceed to load and process each url you gave. When it is finished, you are presented with a report window that lists each stylesheet URL that was detected. Under each stylesheet, it will list the CSS selectors that were not detected to be in use on any page. The selectors are color-coded. Green: Unmatched selectors. These are the primary ones that were not detected as in-use. Black: Matched selectors that are grouped with non-matched selectors. Basically this means that multiple selectors were defined together like ""h1,h2,h3{}"". All selectors are tested individually so these are displayed to make them easier to find in the stylesheets later. Red: Malformed selectors. These are likely to be rare. This means that when the browser tried testing for a selector, it can't parse the syntax of how it was written. This could be like "".classname# idname{}"" or a ""CSS hack"" often used for Internet Explorer. Blue: Pseudo-class selector. These are selectors like "".div:hover"" or ""input:focus"". These are selectors that require user interaction to activate. Currently, Helium can't simulate the interactions required to see if these are found or not. It is the developer's responsibility to test for these manually. Browser Support: Any modern browser that supports LocalStorage and document.querySelector. I have decided I will never adapt Helium to support IE6 or 7. IMPORTANT STUFF: No cross-domain stylesheets: Helium has to load the stylesheets on your site via XHR in order to parse out the selectors to test. This means that all stylesheets URLs have to be on the same domain as the pages being tested. There's currently no back-end server to proxy requests, but this might be an option in the future. No javascript errors on your pages: If Helium is run on a page that has one or more javascript errors, it can easily prevent Helium and other scripts from running on the page. This will stop your tests dead in their tracks. Verify ahead of time that all of the URLs you are testing do not generate any javascript errors. If you aren't sure, try running some Helium tests and see what page it stops at. Check out your error consoles on such pages. No sitemap XML support: Right now, the URL list has to be line separated. No CSV or sitemap XML format is currently supported, though it will be in a future release. Running the tests: Helium doesn't have actual unit tests yet. I've been meaning to add them for a while (years) and will soon. To run the test pages, run a local server from the project root directory and hit http://localhost/test/test1.html. For a very simple server example using Ruby (because its on most systems): ruby -run -e httpd . -p 5000"
598,"Javascript Canvas Library, SVG-to-Canvas (& canvas-to-SVG) ParserFabric.js Fabric.js is a framework that makes it easy to work with HTML5 canvas element. It is an interactive object model on top of canvas element. It is also an SVG-to-canvas parser. Using Fabric.js, you can create and populate objects on canvas; objects like simple geometrical shapes rectangles, circles, ellipses, polygons, or more complex shapes consisting of hundreds or thousands of simple paths. You can then scale, move, and rotate these objects with the mouse; modify their properties color, transparency, z-index, etc. You can also manipulate these objects altogether grouping them with a simple mouse selection. Non-Technical Introduction to Fabric Fabric.js allows you to easily create simple shapes like rectangles, circles, triangles and other polygons or more complex shapes made up of many paths, onto the HTML <canvas> element on a webpage using JavaScript. Fabric.js will then allow you to manipulate the size, position and rotation of these objects with a mouse. Its also possible to change some of the attributes of these objects such as their color, transparency, depth position on the webpage or selecting groups of these objects using the Fabric.js library. Fabric.js will also allow you to convert an SVG image into JavaScript data that can be used for putting it onto the <canvas> element. Contributions are very much welcome! Goals Unit tested (1150+ tests at the moment, 79%+ coverage) Modular (~60 small ""classes"", modules, mixins) Cross-browser Fast Encapsulated in one object No browser sniffing for critical functionality Runs under ES5 strict mode Runs on a server under Node.js (active stable releases and latest of current) (see Node.js limitations) Follows Semantic Versioning Supported browsers Firefox 4+ Safari 5+ Opera 9.64+ Chrome (all versions) Edge (chromium based, all versions) IE11 and Edge legacy, supported but deprecated. You can run automated unit tests right in the browser. History Fabric.js started as a foundation for design editor on printio.ru interactive online store with ability to create your own designs. The idea was to create Javascript-based editor, which would make it easy to manipulate vector shapes and images on T-Shirts. Since performance was one of the most critical requirements, we chose canvas over SVG. While SVG is excellent with static shapes, it's not as performant as canvas when it comes to dynamic manipulation of objects (movement, scaling, rotation, etc.). Fabric.js was heavily inspired by Ernest Delgado's canvas experiment. In fact, code from Ernest's experiment was the foundation of an entire framework. Later, Fabric.js grew into a collection of distinct object types and got an SVG-to-canvas parser. Installation Instructions Install with bower $ bower install fabric Install with npm Note: If you are using Fabric.js in a Node.js script, you will depend from node-canvas.node-canvas is an html canvas replacement that works on top of native libraries. Please follow the instructions located here in order to get it up and running. $ npm install fabric --save After this, you can import fabric like so: Or you can use this instead if your build pipeline supports ES6 imports: NOTE: es6 imports won't work in browser or with bundlers which expect es6 module like vite. Use commonjs syntax instead. See the example section for usage examples. Building Install Node.js Build distribution file [~77K minified, ~20K gzipped] $ node build.js 2.1 Or build a custom distribution file, by passing (comma separated) module names to be included. $ node build.js modules=text,serialization,parser // or $ node build.js modules=text // or $ node build.js modules=parser,text // etc. By default (when none of the modules are specified) only basic functionality is included. See the list of modules below for more information on each one of them. Note that default distribution has support for static canvases only. To get minimal distribution with interactivity, make sure to include corresponding module: $ node build.js modules=interaction 2.2 You can also include all modules like so: $ node build.js modules=ALL 2.3 You can exclude a few modules like so: $ node build.js modules=ALL exclude=gestures,image_filters Create a minified distribution file # Using YUICompressor (default option) $ node build.js modules=... minifier=yui # or Google Closure Compiler $ node build.js modules=... minifier=closure Enable AMD support via require.js (requires uglify) $ node build.js requirejs modules=... Create source map file for better productive debugging (requires uglify or google closure compiler).More information about source maps. $ node build.js sourcemap modules=... If you use google closure compiler you have to add sourceMappingURL manually at the end of the minified file all.min.js (see issue https://code.google.com/p/closure-compiler/issues/detail?id=941). //# sourceMappingURL=fabric.min.js.map Ensure code guidelines are met (prerequisite: npm -g install eslint) $ npm run lint && npm run lint_tests Testing Install Node.js Install NPM, if necessary Install NPM packages $ npm install Run test suite Make sure testem is installed $ npm install -g testem Run tests Chrome and Node (by default): $ testem See testem docs for more info: https://github.com/testem/testem Demos Demos Kitchensink demo Benchmarks Who's using Fabric? Documentation Documentation is always available at http://fabricjs.com/docs/. Also see official 4-part intro series, presentation from BK.js and presentation from Falsy Values for an overview of fabric.js, how it works, and its features. Optional modules These are the optional modules that could be specified for inclusion, when building custom version of fabric: text Adds support for static text (fabric.Text) itext Adds support for interactive text (fabric.IText, fabric.Textbox) serialization Adds support for loadFromJSON, loadFromDatalessJSON, and clone methods on fabric.Canvas interaction Adds support for interactive features of fabric selecting/transforming objects/groups via mouse/touch devices. parser Adds support for fabric.parseSVGDocument, fabric.loadSVGFromURL, and fabric.loadSVGFromString image_filters Adds support for image filters, such as grayscale of white removal. easing Adds support for animation easing functions node Adds support for running fabric under node.js, with help of jsdom and node-canvas libraries. freedrawing Adds support for free drawing gestures Adds support for multitouch gestures with help of Event.js object_straightening Adds support for rotating an object to one of 0, 90, 180, 270, etc. depending on which is angle is closer. animation Adds support for animation (fabric.util.animate, fabric.util.requestAnimFrame, fabric.Object#animate, fabric.Canvas#fxCenterObjectH/#fxCenterObjectV/#fxRemove) Additional flags for build script are: requirejs Makes fabric requirejs AMD-compatible in dist/fabric.js. Note: an unminified, requirejs-compatible version is always created in dist/fabric.require.js no-strict Strips ""use strict"" directives from source no-svg-export Removes svg exporting functionality sourcemap - Generates a sourceMap file and adds the sourceMappingURL (only if uglifyjs is used) to dist/fabric.min.js For example: node build.js modules=ALL exclude=json no-strict no-svg-export Examples of use Adding red rectangle to canvas Helping Fabric Fabric on Bountysource Fabric on CodeTriage Staying in touch Follow @fabric.js, @kangax or @AndreaBogazzi on twitter. Questions, suggestions fabric.js on Google Groups. See Fabric questions on Stackoverflow, Fabric snippets on jsfiddle or codepen.io. Fabric on LibKnot. Get help in Fabric's IRC channel irc://irc.freenode.net/#fabric.js Credits Andrea Bogazzi for help with bugs, new features, documentation, GitHub issues Ernest Delgado for the original idea of manipulating images on canvas Maxim ""hakunin"" Chernyak for ideas, and help with various parts of the library throughout its life Sergey Nisnevich for help with geometry logic Stefan Kienzle for help with bugs, features, documentation, GitHub issues Shutterstock for the time and resources invested in using and improving fabric.js And all the other GitHub contributors MIT License Copyright (c) 2008-2015 Printio (Juriy Zaytsev, Maxim Chernyak) Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the ""Software""), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
810,"Super Resolution for images using deep learning.Neural Enhance .. image:: docs/OldStation_example.gif Example #1 Old Station: view comparison <http://enhance.nucl.ai/w/0f5177f4-9ce6-11e6-992c-c86000be451f/view> in 24-bit HD, original photo <https://flic.kr/p/oYhbBv> CC-BY-SA @siv-athens. As seen on TV! <https://www.youtube.com/watch?v=LhF_56SxrGk>_ What if you could increase the resolution of your photos using technology from CSI laboratories? Thanks to deep learning and #NeuralEnhance, it's now possible to train a neural network to zoom in to your images at 2x or even 4x. You'll get even better results by increasing the number of neurons or training with a dataset similar to your low resolution image. The catch? The neural network is hallucinating details based on its training from example images. It's not reconstructing your photo exactly as it would have been if it was HD. That's only possible in Hollywood but using deep learning as ""Creative AI"" works and it is just as cool! Here's how you can get started... Examples & Usage <#1-examples--usage>_ Installation <#2-installation--setup>_ Background & Research <#3-background--research>_ Troubleshooting <#4-troubleshooting-problems>_ Frequent Questions <#5-frequent-questions>_ |Python Version| |License Type| |Project Stars| .. image:: docs/EnhanceCSI_example.png :target: http://enhance.nucl.ai/w/8581db92-9d61-11e6-990b-c86000be451f/view 1. Examples & Usage The main script is called enhance.py, which you can run with Python 3.4+ once it's setup <#2-installation--setup>_ as below. The --device argument that lets you specify which GPU or CPU to use. For the samples above, here are the performance results: GPU Rendering HQ Assuming you have CUDA setup and enough on-board RAM to fit the image and neural network, generating 1080p output should complete in 5 seconds, or 2s per image if multiple at the same time. CPU Rendering HQ This will take roughly 20 to 60 seconds for 1080p output, however on most machines you can run 4-8 processes simultaneously given enough system RAM. Runtime depends on the neural network size. The default is to use --device=cpu, if you have NVIDIA card setup with CUDA already try --device=gpu0. On the CPU, you can also set environment variable to OMP_NUM_THREADS=4, which is most useful when running the script multiple times in parallel. 1.a) Enhancing Images A list of example command lines you can use with the pre-trained models provided in the GitHub releases: .. code:: bash # Run the super-resolution script to repair JPEG artefacts, zoom factor 1:1. python3 enhance.py --type=photo --model=repair --zoom=1 broken.jpg # Process multiple good quality images with a single run, zoom factor 2:1. python3 enhance.py --type=photo --zoom=2 file1.jpg file2.jpg # Display output images that were given `_ne?x.png` suffix. open *_ne?x.png Here's a list of currently supported models, image types, and zoom levels in one table. ================== ===================== ==================== ===================== ==================== FEATURES --model=default --model=repair --model=denoise --model=deblur ================== ===================== ==================== ===================== ==================== --type=photo 2x 1x ================== ===================== ==================== ===================== ==================== 1.b) Training Super-Resolution Pre-trained models are provided in the GitHub releases. Training your own is a delicate process that may require you to pick parameters based on your image dataset. .. code:: bash # Remove the model file as don't want to reload the data to fine-tune it. rm -f ne?x*.pkl.bz2 # Pre-train the model using perceptual loss from paper [1] below. python3.4 enhance.py --train ""data/*.jpg"" --model custom --scales=2 --epochs=50 \ --perceptual-layer=conv2_2 --smoothness-weight=1e7 --adversary-weight=0.0 \ --generator-blocks=4 --generator-filters=64 # Train the model using an adversarial setup based on [4] below. python3.4 enhance.py --train ""data/*.jpg"" --model custom --scales=2 --epochs=250 \ --perceptual-layer=conv5_2 --smoothness-weight=2e4 --adversary-weight=1e3 \ --generator-start=5 --discriminator-start=0 --adversarial-start=5 \ --discriminator-size=64 # The newly trained model is output into this file... ls ne?x-custom-*.pkl.bz2 .. image:: docs/BankLobby_example.gif Example #2 Bank Lobby: view comparison <http://enhance.nucl.ai/w/38d10880-9ce6-11e6-becb-c86000be451f/view> in 24-bit HD, original photo <https://flic.kr/p/6a8cwm> CC-BY-SA @benarent. 2. Installation & Setup 2.a) Using Docker Image recommended The easiest way to get up-and-running is to install Docker <https://www.docker.com/>. Then, you should be able to download and run the pre-built image using the docker command line tool. Find out more about the alexjc/neural-enhance image on its Docker Hub <https://hub.docker.com/r/alexjc/neural-enhance/> page. Here's the simplest way you can call the script using docker, assuming you're familiar with using -v argument to mount folders you can use this directly to specify files to enhance: .. code:: bash # Download the Docker image and show the help text to make sure it works. docker run --rm -v `pwd`:/ne/input -it alexjc/neural-enhance --help Single Image In practice, we suggest you setup an alias called enhance to automatically expose the folder containing your specified image, so the script can read it and store results where you can access them. This is how you can do it in your terminal console on OSX or Linux: .. code:: bash # Setup the alias. Put this in your .bashrc or .zshrc file so it's available at startup. alias enhance='function ne() { docker run --rm -v ""$(pwd)/`dirname ${@:$#}`"":/ne/input -it alexjc/neural-enhance ${@:1:$#-1} ""input/`basename ${@:$#}`""; }; ne' # Now run any of the examples above using this alias, without the `.py` extension. enhance --zoom=1 --model=repair images/broken.jpg Multiple Images To enhance multiple images in a row (faster) from a folder or wildcard specification, make sure to quote the argument to the alias command: .. code:: bash # Process multiple images, make sure to quote the argument! enhance --zoom=2 ""images/*.jpg"" If you want to run on your NVIDIA GPU, you can instead change the alias to use the image alexjc/neural-enhance:gpu which comes with CUDA and CUDNN pre-installed. Then run it within nvidia-docker <https://github.com/NVIDIA/nvidia-docker>_ and it should use your physical hardware! 2.b) Manual Installation [developers] This project requires Python 3.4+ and you'll also need numpy and scipy (numerical computing libraries) as well as python3-dev installed system-wide. If you want more detailed instructions, follow these: Linux Installation of Lasagne <https://github.com/Lasagne/Lasagne/wiki/From-Zero-to-Lasagne-on-Ubuntu-14.04>_ (intermediate) Mac OSX Installation of Lasagne <http://deeplearning.net/software/theano/install.html#mac-os>_ (advanced) Windows Installation of Lasagne <https://github.com/Lasagne/Lasagne/wiki/From-Zero-to-Lasagne-on-Windows-7-%2864-bit%29>_ (expert) Afterward fetching the repository, you can run the following commands from your terminal to setup a local environment: .. code:: bash # Create a local environment for Python 3.x to install dependencies here. python3 -m venv pyvenv --system-site-packages # If you're using bash, make this the active version of Python. source pyvenv/bin/activate # Setup the required dependencies simply using the PIP module. python3 -m pip install --ignore-installed -r requirements.txt After this, you should have pillow, theano and lasagne installed in your virtual environment. You'll also need to download this pre-trained neural network <https://github.com/alexjc/neural-doodle/releases/download/v0.0/vgg19_conv.pkl.bz2>_ (VGG19, 80Mb) and put it in the same folder as the script to run. To de-install everything, you can just delete the #/pyvenv/ folder. .. image:: docs/Faces_example.png Example #3 Specialized super-resolution for faces, trained on HD examples of celebrity faces only. The quality is significantly higher when narrowing the domain from ""photos"" in general. 3. Background & Research This code uses a combination of techniques from the following papers, as well as some minor improvements yet to be documented (watch this repository for updates): Perceptual Losses for Real-Time Style Transfer and Super-Resolution <http://arxiv.org/abs/1603.08155>_ Real-Time Super-Resolution Using Efficient Sub-Pixel Convolution <https://arxiv.org/abs/1609.05158>_ Deeply-Recursive Convolutional Network for Image Super-Resolution <https://arxiv.org/abs/1511.04491>_ Photo-Realistic Super-Resolution Using a Generative Adversarial Network <https://arxiv.org/abs/1609.04802>_ Special thanks for their help and support in various ways: Eder Santana Discussions, encouragement, and his ideas on sub-pixel deconvolution <https://github.com/Tetrachrome/subpixel>_. Andrew Brock This sub-pixel layer code is based on his project repository <https://github.com/ajbrock/Neural-Photo-Editor>_ using Lasagne. Casper Kaae Snderby For suggesting a more stable alternative to sigmoid + log as GAN loss functions. 4. Troubleshooting Problems Can't install or Unable to find pgen, not compiling formal grammar. There's a Python extension compiler called Cython, and it's missing or improperly installed. Try getting it directly from the system package manager rather than PIP. FIX: sudo apt-get install cython3 NotImplementedError: AbstractConv2d theano optimization failed. This happens when you're running without a GPU, and the CPU libraries were not found (e.g. libblas). The neural network expressions cannot be evaluated by Theano and it's raising an exception. FIX: sudo apt-get install libblas-dev libopenblas-dev TypeError: max_pool_2d() got an unexpected keyword argument 'mode' You need to install Lasagne and Theano directly from the versions specified in requirements.txt, rather than from the PIP versions. These alternatives are older and don't have the required features. FIX: python3 -m pip install -r requirements.txt ValueError: unknown locale: UTF-8 It seems your terminal is misconfigured and not compatible with the way Python treats locales. You may need to change this in your .bashrc or other startup script. Alternatively, this command will fix it once for this shell instance. FIX: export LC_ALL=en_US.UTF-8 .. image:: docs/StreetView_example.gif Example #4 Street View: view comparison <http://enhance.nucl.ai/w/3b3c8054-9d00-11e6-9558-c86000be451f/view> in 24-bit HD, original photo <https://flic.kr/p/gnxcXH> CC-BY-SA @cyalex. |Python Version| |License Type| |Project Stars| .. |Python Version| image:: http://aigamedev.github.io/scikit-neuralnetwork/badge_python.svg :target: https://www.python.org/ .. |License Type| image:: https://img.shields.io/badge/license-AGPL-blue.svg :target: https://github.com/alexjc/neural-enhance/blob/master/LICENSE .. |Project Stars| image:: https://img.shields.io/github/stars/alexjc/neural-enhance.svg?style=flat :target: https://github.com/alexjc/neural-enhance/stargazers"
1618,"A vintage 1980s DOS inspired Twitter Bootstrap themeSee A Demo By Clicking Here Download for your favorite bootstrap version with all the necessary JS and CSS to get started right away: BOOTSTRA/386 ][ (from 2013) 144KB BOOTSTRA/386 iii (from 2015) 423KB BOOTSTRA/386 4 (2020 - in progress) - demo - remaining issues - current build Bootstrap/386 is a Twitter bootstrap v2/31/4 theme to make webpages look like they are from the gentler, less distracting time of the 1980s. ____ ____ ____ _____________________ ___ ____ __ _____ ____ _____ / __ )/ __ \/ __ \/_ __/ ___/_ __/ __ \/ | / __ \ _/_/ |__ /( __ )/ ___/ / __ / / / / / / / / / \__ \ / / / /_/ / /| | / /_/ / _/_/ /_ </ __ / __ \ / /_/ / /_/ / /_/ / / / ___/ // / / _, _/ ___ |/ ____/ _/_/ ___/ / /_/ / /_/ / /_____/\____/\____/ /_/ /____//_/ /_/ |_/_/ |_/_/ /_/ /____/\____/\____/ The Definitive All-in-one Graphical Tool-Kit for Micros and Terminals. - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - There's a lot of micros and a lot of this future has arrived. graphics modes. Today there's CGA, Hercules, MDA, and EGA. And that's only Use primitives like buttons, ""toolbars"" on the IBM-PC. and various ""widgets"" that will control your application. We handle rendering What about Tandy, CDC, Honeywell, these abstractions on screen for you. DEC, and Zenith? That's a different problem. How about the portables on Think of your software in terms of tomorrows' horizon? Plan to ignore the Windows, Icons, Menus, and Pull-Downs. Compaq-1? Your customers won't. Even a WIMP can do it (TM). Such incompatibilities shouldn't be That's the new paradigm of full-screen your concern. You focus on making interactive applications. Give your great microcomputer applications. We customers the rich interface that are focus on making your application work easy to use and also, easy to create. on tomorrow's computer. Give yourself that one-leg up on your competition. GUI is Good. GUI is God. It's called a ""Graphical User Interface"" They've been in development for years Just look at how beautiful at places like XEROX Parc in Palo Alto your application can look with and Carnegie Mellon. And now, finally BOOTSTRAP/386: Configuration Javascript settings are set via a global _386 object. Animation The loading animation can be configured through the following values: fastLoad [bool] (default: false) - disable all animation. onePass [bool] (default: false) - when set, this will disable the second flyby cursor speedFactor [float] (default: 1.0) - This controls how fast the animation happens. Higher values mean faster animation. Example: _386 = { onePass: true, speedFactor: 1.25 }; Note: For the progressive animation to work you may need to set this stanza in your regular CSS: body { visibility: hidden }. Accomodating users without javascript During a 2018 April fools' prank, a user pointed out that this theme doesn't work without javascript. This is a valid concern, however it cannot be addressed without a user manually doing something since this is just a bootstrap theme. Luckily, HTML5 permits noscript in the head section which means that style can be put in the noscript section. This means that putting this in the header would permit people without JS on to see the site: Distractions While you're here, let me plug another fun project I have. This one includes a 1990's style ""made for tv"" infomercial I made. It's a better way to search manpages called mansnip. At least watch the youtube video, that took me days. Let's make software fun again, remember those days? Oh you're too young? Well trust me, it used to be a blast! Let's do that again, it was a good time. Also you can give me money, as little as $1/month ... Click on that heart sponsor thing at the top ... I'm a sponsorer as well! Bugs and Stuff Check out the contribution doc - it's easy, I swear. Contact Mailing list Also try my github username on your messaging platform of choice See the wiki for more documentation. Attributions The font for the v4 is by VileR, used under Creative Commons Share-Alike, which can be found at int10h.org. Notes 1 The v3 version kinda sucked. You don't want that, do you? Brooks' 2nd system effect, not just the musings of 1975. Anyway, v4 is coming ..."
3862,Public facing notes pageNotes and assignments for Stanford CS class CS231n: Convolutional Neural Networks for Visual Recognition
1126,"Tiny vanilla JS plugin to display large data sets easilyClusterize.js Tiny vanilla JS plugin to display large data sets easily Demo, usage, etc"
1870,"An autocompletion daemon for the Go programming languageAn autocompletion daemon for the Go programming language VERY IMPORTANT: this project is not maintained anymore, look for alternatives or forks if you need Go autocompletion tool IMPORTANT: consider switching to https://github.com/mdempsky/gocode if you have problems starting with Go version 1.10, due to changes in binary packages architecture (introduction of package cache) I'm not going to adjust gocode for it for quite some time. There is a higher chance that fork under the given link will have some solution to the problem sooner or later. Gocode is a helper tool which is intended to be integrated with your source code editor, like vim, neovim and emacs. It provides several advanced capabilities, which currently includes: Context-sensitive autocompletion It is called daemon, because it uses client/server architecture for caching purposes. In particular, it makes autocompletions very fast. Typical autocompletion time with warm cache is 30ms, which is barely noticeable. Also watch the demo screencast. Setup You should have a correctly installed Go compiler environment and your personal workspace ($GOPATH). If you have no idea what $GOPATH is, take a look here. Please make sure that your $GOPATH/bin is available in your $PATH. This is important, because most editors assume that gocode binary is available in one of the directories, specified by your $PATH environment variable. Otherwise manually copy the gocode binary from $GOPATH/bin to a location which is part of your $PATH after getting it in step 2. Do these steps only if you understand why you need to do them: export GOPATH=$HOME/goprojects export PATH=$PATH:$GOPATH/bin Then you need to get the appropriate version of the gocode, for 6g/8g/5g compiler you can do this: go get -u github.com/nsf/gocode (-u flag for ""update"") Windows users should consider doing this instead: go get -u -ldflags -H=windowsgui github.com/nsf/gocode That way on the Windows OS gocode will be built as a GUI application and doing so solves hanging window issues with some of the editors. Next steps are editor specific. See below. Vim setup Vim manual installation Note: As of go 1.5 there is no $GOROOT/misc/vim script. Suggested installation is via vim-go plugin. In order to install vim scripts, you need to fulfill the following steps: Install official Go vim scripts from $GOROOT/misc/vim. If you did that already, proceed to the step 2. Install gocode vim scripts. Usually it's enough to do the following: 2.1. vim/update.sh update.sh script does the following: #!/bin/sh mkdir -p ""$HOME/.vim/autoload"" mkdir -p ""$HOME/.vim/ftplugin/go"" cp ""${0%/*}/autoload/gocomplete.vim"" ""$HOME/.vim/autoload"" cp ""${0%/*}/ftplugin/go/gocomplete.vim"" ""$HOME/.vim/ftplugin/go"" 2.2. Alternatively, you can create symlinks using symlink.sh script in order to avoid running update.sh after every gocode update. symlink.sh script does the following: #!/bin/sh cd ""${0%/*}"" ROOTDIR=`pwd` mkdir -p ""$HOME/.vim/autoload"" mkdir -p ""$HOME/.vim/ftplugin/go"" ln -s ""$ROOTDIR/autoload/gocomplete.vim"" ""$HOME/.vim/autoload/"" ln -s ""$ROOTDIR/ftplugin/go/gocomplete.vim"" ""$HOME/.vim/ftplugin/go/"" Make sure vim has filetype plugin enabled. Simply add that to your .vimrc: filetype plugin on Autocompletion should work now. Use <C-x><C-o> for autocompletion (omnifunc autocompletion). Using Vundle in Vim Add the following line to your .vimrc: Plugin 'nsf/gocode', {'rtp': 'vim/'} And then update your packages by running :PluginInstall. Using vim-plug in Vim Add the following line to your .vimrc: Plug 'nsf/gocode', { 'rtp': 'vim', 'do': '~/.vim/plugged/gocode/vim/symlink.sh' } And then update your packages by running :PlugInstall. Other Alternatively take a look at the vundle/pathogen friendly repo: https://github.com/Blackrush/vim-gocode. Neovim setup Neovim manual installation Neovim users should also follow Vim manual installation, except that you should goto gocode/nvim in step 2, and remember that, the Neovim configuration file is ~/.config/nvim/init.vim. Using Vundle in Neovim Add the following line to your init.vim: Plugin 'nsf/gocode', {'rtp': 'nvim/'} And then update your packages by running :PluginInstall. Using vim-plug in Neovim Add the following line to your init.vim: Plug 'nsf/gocode', { 'rtp': 'nvim', 'do': '~/.config/nvim/plugged/gocode/nvim/symlink.sh' } And then update your packages by running :PlugInstall. Emacs setup In order to install emacs script, you need to fulfill the following steps: Install auto-complete-mode Copy emacs/go-autocomplete.el file from the gocode source distribution to a directory which is in your 'load-path' in emacs. Add these lines to your .emacs: (require 'go-autocomplete) (require 'auto-complete-config) (ac-config-default) Also, there is an alternative plugin for emacs using company-mode. See emacs-company/README for installation instructions. If you're a MacOSX user, you may find that script useful: https://github.com/purcell/exec-path-from-shell. It helps you with setting up the right environment variables as Go and gocode require it. By default it pulls the PATH, but don't forget to add the GOPATH as well, e.g.: Options You can change all available options using gocode set command. The config file uses json format and is usually stored somewhere in ~/.config/gocode directory. On windows it's stored in the appropriate AppData folder. It's suggested to avoid modifying config file manually, do that using the gocode set command. gocode set lists all options and their values. gocode set <option> shows the value of that option. gocode set <option> <value> sets the new value for that option. propose-builtins A boolean option. If true, gocode will add built-in types, functions and constants to autocompletion proposals. Default: false. lib-path A string option. Allows you to add search paths for packages. By default, gocode only searches $GOPATH/pkg/$GOOS_$GOARCH and $GOROOT/pkg/$GOOS_$GOARCH in terms of previously existed environment variables. Also you can specify multiple paths using ':' (colon) as a separator (on Windows use semicolon ';'). The paths specified by lib-path are prepended to the default ones. autobuild A boolean option. If true, gocode will try to automatically build out-of-date packages when their source files are modified, in order to obtain the freshest autocomplete results for them. This feature is experimental. Default: false. force-debug-output A string option. If is not empty, gocode will forcefully redirect the logging into that file. Also forces enabling of the debug mode on the server side. Default: """" (empty). package-lookup-mode A string option. If go, use standard Go package lookup rules. If gb, use gb-specific lookup rules. See https://github.com/constabulary/gb for details. Default: go. close-timeout An integer option. If there have been no completion requests after this number of seconds, the gocode process will terminate. Defaults to 1800 (30 minutes). unimported-packages A boolean option. If set to true, gocode will try to import certain known packages automatically for identifiers which cannot be resolved otherwise. Currently only a limited set of standard library packages are supported. Default: false. partials A boolean option. If set to false, gocode will not filter autocompletion results based on entered prefix before the cursor. Instead it will return all available autocompletion results viable for a given context. Whether this option is set to true or false, gocode will return a valid prefix length for output formats which support it. Setting this option to a non-default value may result in editor misbehaviour. Default: true. ignore-case A boolean option. If set to true, gocode will perform case-insensitive matching when doing prefix-based filtering. Default: false. class-filtering A boolean option. Enables or disables gocode's feature where it performs class-based filtering if partial input matches corresponding class keyword: const, var, type, func, package. Default: true. Debugging If something went wrong, the first thing you may want to do is manually start the gocode daemon with a debug mode enabled and in a separate terminal window. It will show you all the stack traces, panics if any and additional info about autocompletion requests. Shutdown the daemon if it was already started and run a new one explicitly with a debug mode enabled: gocode close gocode -s -debug Please, report bugs, feature suggestions and other rants to the github issue tracker of this project. Developing There is Guide for IDE/editor plugin developers. If you have troubles, please, contact me and I will try to do my best answering your questions. You can contact me via email. Or for short question find me on IRC: #go-nuts @ freenode. Misc It's a good idea to use the latest git version always. I'm trying to keep it in a working state. Use go install (not go build) for building a local source tree. The objects in pkg/ are needed for Gocode to work."
2388,"Lightweight and powerful data binding.Rivets.js Rivets.js is a lightweight data binding and templating system that facilitates building data-driven views. It is agnostic about every aspect of a front-end MV(C|VM|P) stack, making it easy to introduce it into your current workflow or to use it as part of your own custom front-end stack comprised of other libraries. Usage Getting Started and Documentation Documentation is available on the homepage. Learn by reading the Guide and refer to the Binder Reference to see what binders are available to you out-of-the-box. Building and Testing First install any development dependencies. Building Rivets.js uses gulp as its build tool. Run the following task to compile + minify the source into dist/. Testing Rivets.js uses mocha as its testing framework, alongside should for expectations and sinon for spies, stubs and mocks. Run the following to run the full test suite. Contributing Bug Reporting Ensure the bug can be reproduced on the latest master. Open an issue on GitHub and include an isolated JSFiddle demonstration of the bug. The more information you provide, the easier it will be to validate and fix. Pull Requests Fork the repository and create a topic branch. Make sure not to commit any changes under dist/ as they will surely cause conflicts for others later. Files under dist/ are only committed when a new build is released. Include tests that cover any changes or additions that you've made. Push your topic branch to your fork and submit a pull request. Include details about the changes as well as a reference to related issue(s)."
3859,"The Clojure Interactive Development Environment that Rocks for Emacs CIDER is the Clojure(Script) Interactive Development Environment that Rocks! CIDER extends Emacs with support for interactive programming in Clojure. The features are centered around cider-mode, an Emacs minor-mode that complements clojure-mode. While clojure-mode supports editing Clojure source files, cider-mode adds support for interacting with a running Clojure process for compilation, code completion, debugging, definition and documentation lookup, running tests and so on. Bozhidar (a.k.a. Bug, CIDER's primary author/maintainer) has spent countless hours working on CIDER and the numerous related projects. That's a lot of work and not all of it is fun! Please consider supporting financially CIDER's ongoing development. Quickstart The instructions that follow are meant to get you from zero to a running CIDER REPL in under 5 minutes. See the user manual for (way) more details. Installation The recommended way to install CIDER is via package.el - the built-in package manager in Emacs. CIDER is available on the two major package.el community maintained repos - MELPA Stable and MELPA. Provided you've enabled one of them in your Emacs setup, you can install CIDER with the following command: M-x package-install RET cider RET Launch an nREPL server and client from Emacs Simply open in Emacs a file belonging to your lein, tools.deps or boot project (like foo.clj) and type M-x cider-jack-in. This will start an nREPL server with all the project dependencies loaded in and CIDER will automatically connect to it. Alternatively you can use C-u M-x cider-jack-in to specify the path to a Clojure project, without having to visit any file in it. Tip: In Clojure(Script) buffers the command cider-jack-in is bound to C-c C-x (C-)j. Connect to a running nREPL server You can go to your project's directory in a terminal and type there (assuming you're using Leiningen that is): Or with Boot: Alternatively you can start nREPL either manually or by the facilities provided by your project's build tool (tools.deps, Gradle, Maven, etc). After you get your nREPL server running go back to Emacs. Typing there M-x cider-connect will allow you to connect to the running nREPL server. Tip: In Clojure(Script) buffers the command cider-connect is bound to C-c C-x (C-)c (C-)j and the command cider-connect-cljs is bound to C-c C-x (C-)c (C-)s. Diving Deeper CIDER packs a ton of functionality and you really want to be familiar with it, so you can fully empower your workflow. The best way to get acquainted with all available features is to go over the entire CIDER manual. If you're into video lessons, you might also check out this intro to CIDER demo as well. Get Help Start with CIDER's discussions board. If it doesn't get the job done consider some of the other available support channels. Changelog An extensive changelog is available here. Team The Core Team The direction of the project is being stewarded by the CIDER core team. This group of long-term contributors manage releases, evaluate pull-requests, and does a lot of the groundwork on major new features. Bozhidar Batsov (author & head maintainer) Vitalie Spinu Michael Griffiths Lars Andersen CIDER Alumni In addition, we'd like to extend a special thanks the following retired CIDER core team members. Lovingly known as The Alumni: Tim King (original author) Phil Hagelberg Hugo Duncan Steve Purcell Artur Malabarba Jeff Valk Release policy Were following SemVer. You can read more on the subject here. Logo CIDER's logo was created by @tapeinosyne. You can find the logo in various formats here. The logo is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License. Homepage CIDER's homepage https://cider.mx is in the gh-pages branch of this repository and is deployed automatically when changes are made to it. It's just a single index.html file and a bit of Bootstrap 4. Contributions to it are very welcome! Funding While CIDER is free software and will always be, the project would benefit immensely from some funding. Raising a monthly budget of a couple of thousand dollars would make it possible to pay people to work on certain complex features, fund other development related stuff (e.g. hardware, conference trips) and so on. Raising a monthly budget of over $5000 would open the possibility of someone working full-time on the project which would speed up the pace of development significantly. We welcome both individual and corporate sponsors! We also offer a wide array of funding channels to account for your preferences (although currently Open Collective is our preferred funding platform). If you're working in a company that's making significant use of CIDER we'd appreciate it if you suggest to your company to become a CIDER sponsor. You can support the development of CIDER, clojure-mode and inf-clojure via Open Collective, GitHub Sponsors, Patreon and PayPal. Open Collective Backers Open Collective Sponsors Become a sponsor and get your logo on our README on Github with a link to your site. [Become a sponsor] License CIDER is distributed under the GNU General Public License, version 3. Copyright 2012-2021 Bozhidar Batsov, Artur Malabarba, Tim King, Phil Hagelberg and contributors."
776,"modest natural-language processing compromise modest natural language processing npm install compromise by Spencer Kelly and many contributors isn't it weird how we can write text, but not parse it? - and how we can't get the information back out? it's like we've agreed that text is a dead-end. and the knowledge in it should not really be used. compromise tries its best to parse text. it is small, quick, and often good-enough. it is not as smart as you'd think. .match(): interpret and match text: match docs .verbs(): conjugate and negate verbs in any tense: verb docs .nouns(): play between plural, singular and possessive forms: noun docs .numbers(): interpret plain-text numbers number docs .topics(): names/places/orgs, tldr: topics docs .contractions(): handle implicit terms: contraction docs Use it on the client-side: as an es-module: compromise is 180kb (minified): it's pretty fast. It can run on keypress: it works mainly by conjugating all forms of a basic word list. The final lexicon is ~14,000 words: you can read more about how it works, here. it's weird. .extend(): decide how words get interpreted: or make heavier changes with a compromise-plugin. .extend() docs Docs: gentle introduction: #1) Input output #2) Match & transform #3) Making a chat-bot Documentation: | Concepts | API | Plugins | | ------------------------------------------------------------------------------------- | :---------------------------------------------------------------------------------------------: | -------------------------------------------------------------------------------------: | | Accuracy | Accessors | Adjectives | | Caching | Constructor-methods | Dates | | Case | Contractions | Export | | Filesize | Insert | Hash | | Internals | Json | Html | | Justification | Lists | Keypress | | Lexicon | Loops | Ngrams | | Match-syntax | Match | Numbers | | Performance | Nouns | Paragraphs | | Plugins | Output | Scan | | Projects | Selections | Sentences | | Tagger | Sorting | Syllables | | Tags | Split | Pronounce | | | Tokenization | Text | Strict | | Named-Entities | Utils | Penn-tags | | Whitespace | Verbs | Typeahead | | World data | Normalization | | | Fuzzy-matching | Typescript | | Talks: Language as an Interface - by Spencer Kelly Coding Chat Bots - by KahWee Teng On Typing and data - by Spencer Kelly Articles: Geocoding Social Conversations with NLP and JavaScript - by Microsoft Microservice Recipe - by Eventn Adventure Game Sentence Parsing with Compromise Building Text-Based Games - by Matt Eland Fun with javascript in BigQuery - by Felipe Hoffa Natural Language Processing... in the Browser? - by Charles Landau Some fun Applications: Chat dialogue framework - by Rob Ellis Automated Bechdel Test - by The Guardian Story generation framework - by Jose Phrocca Tumbler blog of lists - horse-ebooks-like lists - by Michael Paulukonis Video Editing from Transcription - by New Theory Browser extension Fact-checking - by Alexander Kidd Siri shortcut - by Michael Byrns Amazon skill - by Tajddin Maghni Tasking Slack-bot - by Kevin Suh [see more] API: Constructor (these methods are on the nlp object) .tokenize() - parse text without running POS-tagging .extend() - mix in a compromise-plugin .fromJSON() - load a compromise object from .json() result .verbose() - log our decision-making for debugging .version() - current semver version of the library .world() - grab all current linguistic data .parseMatch() - pre-parse any match statements for faster lookups Utils .all() - return the whole original document ('zoom out') .found [getter] - is this document empty? .parent() - return the previous result .parents() - return all of the previous results .tagger() - (re-)run the part-of-speech tagger on this document .wordCount() - count the # of terms in the document .length [getter] - count the # of characters in the document (string length) .clone() - deep-copy the document, so that no references remain .cache({}) - freeze the current state of the document, for speed-purposes .uncache() - un-freezes the current state of the document, so it may be transformed Accessors .first(n) - use only the first result(s) .last(n) - use only the last result(s) .slice(n,n) - grab a subset of the results .eq(n) - use only the nth result .terms() - split-up results by each individual term .firstTerms() - get the first word in each match .lastTerms() - get the end word in each match .sentences() - get the whole sentence for each match .termList() - return a flat list of all Term objects in match .groups('') - grab any named capture-groups from a match Match (all match methods use the match-syntax.) .match('') - return a new Doc, with this one as a parent .not('') - return all results except for this .matchOne('') - return only the first match .if('') - return each current phrase, only if it contains this match ('only') .ifNo('') - Filter-out any current phrases that have this match ('notIf') .has('') - Return a boolean if this match exists .lookBehind('') - search through earlier terms, in the sentence .lookAhead('') - search through following terms, in the sentence .before('') - return all terms before a match, in each phrase .after('') - return all terms after a match, in each phrase .lookup([]) - quick find for an array of string matches Case .toLowerCase() - turn every letter of every term to lower-cse .toUpperCase() - turn every letter of every term to upper case .toTitleCase() - upper-case the first letter of each term .toCamelCase() - remove whitespace and title-case each term Whitespace .pre('') - add this punctuation or whitespace before each match .post('') - add this punctuation or whitespace after each match .trim() - remove start and end whitespace .hyphenate() - connect words with hyphen, and remove whitespace .dehyphenate() - remove hyphens between words, and set whitespace .toQuotations() - add quotation marks around these matches .toParentheses() - add brackets around these matches Tag .tag('') - Give all terms the given tag .tagSafe('') - Only apply tag to terms if it is consistent with current tags .unTag('') - Remove this term from the given terms .canBe('') - return only the terms that can be this tag Loops .map(fn) - run each phrase through a function, and create a new document .forEach(fn) - run a function on each phrase, as an individual document .filter(fn) - return only the phrases that return true .find(fn) - return a document with only the first phrase that matches .some(fn) - return true or false if there is one matching phrase .random(fn) - sample a subset of the results Insert .replace(match, replace) - search and replace match with new content .replaceWith(replace) - substitute-in new text .delete() - fully remove these terms from the document .append(str) - add these new terms to the end (insertAfter) .prepend(str) - add these new terms to the front (insertBefore) .concat() - add these new things to the end Transform .sort('method') - re-arrange the order of the matches (in place) .reverse() - reverse the order of the matches, but not the words .normalize({}) - clean-up the text in various ways .unique() - remove any duplicate matches .split('') - return a Document with three parts for every match ('splitOn') .splitBefore('') - partition a phrase before each matching segment .splitAfter('') - partition a phrase after each matching segment .segment({}) - split a document into labeled sections .join('') - make all phrases into one phrase Output .text('method') - return the document as text .json({}) - pull out desired metadata from the document .out('array|offset|terms') - some named output formats (deprecated) .debug() - pretty-print the current document and its tags Selections .clauses() - split-up sentences into multi-term phrases .hyphenated() - all terms connected with a hyphen or dash like 'wash-out' .phoneNumbers() - things like '(939) 555-0113' .hashTags() - things like '#nlp' .emails() - things like 'hi@compromise.cool' .emoticons() - things like :) .emojis() - things like .atMentions() - things like '@nlp_compromise' .urls() - things like 'compromise.cool' .adverbs() - things like 'quickly' .pronouns() - things like 'he' .conjunctions() - things like 'but' .prepositions() - things like 'of' .abbreviations() - things like 'Mrs.' .people() - names like 'John F. Kennedy' .places() - like 'Paris, France' .organizations() - like 'Google, Inc' .topics() - people() + places() + `organizations Subsets .contractions() - things like ""didn't"" .contractions().expand() - things like ""didn't"" .contract() - ""she would"" -> ""she'd"" .parentheses() - return anything inside (parentheses) .possessives() - things like ""Spencer's"" .quotations() - return any terms inside quotation marks .acronyms() - things like 'FBI' .lists() - things like 'eats, shoots, and leaves' .lists().items() - return the partitioned things in the list .lists().add() - put a new item in the list .nouns() - return any subsequent terms tagged as a Noun .nouns().json() - overloaded output with noun metadata .nouns().adjectives() - get any adjectives describing this noun .nouns().toPlural() - 'football captain' 'football captains' .nouns().toSingular() - 'turnovers' 'turnover' .nouns().isPlural() - return only plural nouns .nouns().isSingular() - return only singular nouns .nouns().hasPlural() - return only nouns that can be inflected as plural .nouns().toPossessive() - add a 's to the end, in a safe manner. .verbs() - return any subsequent terms tagged as a Verb .verbs().json() - overloaded output with verb metadata .verbs().conjugate() - return all forms of these verbs .verbs().toPastTense() - 'will go' 'went' .verbs().toPresentTense() - 'walked' 'walks' .verbs().toFutureTense() - 'walked' 'will walk' .verbs().toInfinitive() - 'walks' 'walk' .verbs().toGerund() - 'walks' 'walking' .verbs().toParticiple() - 'drive' 'driven' - otherwise simple-past ('walked') .verbs().toNegative() - 'went' 'did not go' .verbs().toPositive() - ""didn't study"" 'studied' .verbs().isNegative() - return verbs with 'not' .verbs().isPositive() - only verbs without 'not' .verbs().isPlural() - return plural verbs like 'we walk' .verbs().isSingular() - return singular verbs like 'spencer walks' .verbs().adverbs() - return the adverbs describing this verb. .verbs().isImperative() - only instruction verbs like 'eat it!' Plugins: These are some helpful extensions: Adjectives npm install compromise-adjectives .adjectives() - like quick .adjectives().json() - overloaded output with adjective metadata .adjectives().conjugate() - return all conjugated forms of this adjective .adjectives().toSuperlative() - convert quick to quickest .adjectives().toComparative() - convert quick to quicker .adjectives().toAdverb() - convert quick to quickly .adjectives().toVerb() - convert quick to quicken .adjectives().toNoun() - convert quick to quickness Dates npm install compromise-dates .dates() - find dates like June 8th or 03/03/18 .dates().get() - simple start/end json result .dates().json() - overloaded output with date metadata .dates().format('') - convert the dates to specific formats .dates().toShortForm() - convert 'Wednesday' to 'Wed', etc .dates().toLongForm() - convert 'Feb' to 'February', etc .durations() - 2 weeks or 5mins .durations().get() - return simple json for duration .durations().json() - overloaded output with duration metadata .times() - 4:30pm or half past five .durations().get() - return simple json for times .times().json() - overloaded output with time metadata Numbers npm install compromise-numbers .numbers() - grab all written and numeric values .numbers().get() - retrieve the parsed number(s) .numbers().json() - overloaded output with number metadata .numbers().units() - grab 'kilos' from 25 kilos' .numbers().fractions() - things like 1/3rd .numbers().toText() - convert number to five or fifth .numbers().toNumber() - convert number to 5 or 5th .numbers().toOrdinal() - convert number to fifth or 5th .numbers().toCardinal() - convert number to five or 5 .numbers().set(n) - set number to n .numbers().add(n) - increase number by n .numbers().subtract(n) - decrease number by n .numbers().increment() - increase number by 1 .numbers().decrement() - decrease number by 1 .numbers().isEqual(n) - return numbers with this value .numbers().greaterThan(min) - return numbers bigger than n .numbers().lessThan(max) - return numbers smaller than n .numbers().between(min, max) - return numbers between min and max .numbers().isOrdinal() - return only ordinal numbers .numbers().isCardinal() - return only cardinal numbers .numbers().toLocaleString() - add commas, or nicer formatting for numbers .money() - things like '$2.50' .money().get() - retrieve the parsed amount(s) of money .money().json() - currency + number info .money().currency() - which currency the money is in .fractions() - like '2/3rds' or 'one out of five' .fractions().get() - simple numerator, denomenator data .fractions().json() - json method overloaded with fractions data .fractions().toDecimal() - '2/3' -> '0.66' .fractions().normalize() - 'four out of 10' -> '4/10' .fractions().toText() - '4/10' -> 'four tenths' .fractions().toPercentage() - '4/10' -> '40%' .percentages() - like '2.5%' .fractions().get() - return the percentage number / 100 .fractions().json() - json overloaded with percentage information .fractions().toFraction() - '80%' -> '8/10' Export npm install compromise-export .export() - store a parsed document for later use nlp.load() - re-generate a Doc object from .export() results Html npm install compromise-html .html({}) - generate sanitized html from the document Hash npm install compromise-hash .hash() - generate an md5 hash from the document+tags .isEqual(doc) - compare the hash of two documents for semantic-equality Keypress npm install compromise-keypress nlp.keypress('') - generate an md5 hash from the document+tags nlp.clear('') - clean-up any cached sentences from memory Ngrams npm install compromise-ngrams .ngrams({}) - list all repeating sub-phrases, by word-count .unigrams() - n-grams with one word .bigrams() - n-grams with two words .trigrams() - n-grams with three words .startgrams() - n-grams including the first term of a phrase .endgrams() - n-grams including the last term of a phrase .edgegrams() - n-grams including the first or last term of a phrase Paragraphs npm install compromise-paragraphs this plugin creates a wrapper around the default sentence objects. .paragraphs() - return groups of sentences .paragraphs().json() - output metadata for each paragraph .paragraphs().sentences() - go back to a regular Doc object .paragraphs().terms() - return all individual terms .paragraphs().eq() - get the nth paragraph .paragraphs().first() - get the first n paragraphs .paragraphs().last() - get the last n paragraphs .paragraphs().match() - .paragraphs().not() - .paragraphs().if() - .paragraphs().ifNo() - .paragraphs().has() - .paragraphs().forEach() - .paragraphs().map() - .paragraphs().filter() - Sentences npm install compromise-sentences .sentences() - return a sentence class with additional methods .sentences().json() - overloaded output with sentence metadata .sentences().subjects() - return the main noun of each sentence .sentences().toPastTense() - he walks -> he walked .sentences().toPresentTense() - he walked -> he walks .sentences().toFutureTense() -- he walks -> he will walk .sentences().toNegative() - - he walks -> he didn't walk .sentences().toPositive() - he doesn't walk -> he walks .sentences().isPassive() - return only sentences with a passive-voice .sentences().isQuestion() - return questions with a ? .sentences().isExclamation() - return sentences with a ! .sentences().isStatement() - return sentences without ? or ! .sentences().prepend() - smarter prepend that repairs whitespace + titlecasing .sentences().append() - smarter append that repairs sentence punctuation .sentences().toExclamation() - end sentence with a ! .sentences().toQuestion() - end sentence with a ? .sentences().toStatement() - end sentence with a . Strict-match npm install compromise-strict .strictMatch() - perform a compromise match using a formal parser Syllables npm install compromise-syllables .syllables() - split each term by its typical pronounciation Penn-tags npm install compromise-penn-tags .pennTags() - return POS tags from the Penn Tagset Typescript we're committed to typescript/deno support, both in main and in the official-plugins: typescript docs Partial-builds or if you don't care about POS-tagging, you can use the tokenize-only build: (90kb!) Limitations: slash-support: We currently split slashes up as different words, like we do for hyphens. so things like this don't work: nlp('the koala eats/shoots/leaves').has('koala leaves') //false inter-sentence match: By default, sentences are the top-level abstraction. Inter-sentence, or multi-sentence matches aren't supported without a plugin: nlp(""that's it. Back to Winnipeg!"").has('it back')//false nested match syntax: the danger beauty of regex is that you can recurse indefinitely. Our match syntax is much weaker. Things like this are not (yet) possible: doc.match('(modern (major|minor))? general') complex matches must be achieved with successive .match() statements. dependency parsing: Proper sentence transformation requires understanding the syntax tree of a sentence, which we don't currently do. We should! Help wanted with this. FAQ Isn't javascript too... yeah it is! it wasn't built to compete with NLTK, and may not fit every project. string processing is synchronous too, and parallelizing node processes is weird. See here for information about speed & performance, and here for project motivations Can it run on my arduino-watch? Only if it's water-proof! Read quick start for running compromise in workers, mobile apps, and all sorts of funny environments. Compromise in other Languages? we've got work-in-progress forks for German and French, in the same philosophy. and need some help. Partial builds? we do offer a compromise-tokenize build, which has the POS-tagger pulled-out. but otherwise, compromise isn't easily tree-shaken. the tagging methods are competitive, and greedy, so it's not recommended to pull things out. Note that without a full POS-tagging, the contraction-parser won't work perfectly. ((spencer's cool) vs. (spencer's house)) It's recommended to run the library fully. See Also: en-pos - very clever javascript pos-tagger by Alex Corvi naturalNode - fancier statistical nlp in javascript compendium-js - POS and sentiment analysis in javascript nodeBox linguistics - conjugation, inflection in javascript reText - very impressive text utilities in javascript superScript - conversation engine in js jsPos - javascript build of the time-tested Brill-tagger spaCy - speedy, multilingual tagger in C/python Prose - quick tagger in Go by Joseph Kato MIT"
4343,"The IRC Client For Developers Komanda http://komanda.io Komanda is a IRC client built with node-webkit, javascript, html and css for people who write code. The project goal is to build the best client for developers that use IRC for their projects, follow others or getting help on a new language or framework. Download (prebuilt binaries) http://komanda.io The Plan (in progress) Themeable and extensible with plugins. Load code snippets from gist.github.com, pastie, jsfiddle etc. (gist/jsfiddle added already) Search github/bitbucket for a repo based on the channel name. Import issues, wiki articles etc. [insert your ideas here] - Open an issue and i'll get to work. WTF are script codes? Not a developer? No worries, it's still a great client! Themeable Clean & Simple UI Performant (pretty much - still working on making this better) BETA Komanda is currently in beta. Things may not be perfect but it's pretty solid on the IRC side of things. GUI TODO add todo items Build npm install grunt build[:<target>] where <target> is all || [win,osx,linux32,linux64]. Defaults to the current platform. dev npm install grunt run Self-Promotion Like Komanda? Follow the repository on GitHub and if you would like to stalk me, follow mephux on Twitter and GitHub. MIT LICENSE The MIT License (MIT) Copyright (c) 2014 Dustin Willis Webber Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the ""Software""), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
2925,"play pokemon go safely or at unavailable areaPokemon-Go-Controller iOS device as game controller Clone this xcode project and run on your iphone / ipad, this app actually perform a web server that tells your chosen location, your location will be wherever the poke ball is, so you may drag the map of press the buttons. This is what the app response via port 80 by http, so be sure to connect the iphone / ipad to your wifi network in order to gain access. Get controller message Edit readAndChangeXML.py ,change the urlopen address to your controller's ip and write to somewhere your gpx file you want to put. Be sure you remember where the gpx you put :) If running normal, at console you should see something like this when your drag the map or press the buttons on your game controller. Simulate location to target device Create a blank single page app with your Xcode. Remember where you put the gpx file? Import the gpx file to your project without copying it, just referencing. Run this project on your iOS device that will actually run the Pokemon Go game, when running, at Xcode you will see a button to simulate location, so you see the option of your gpx file. Our next step is to constantly press this two buttons to simulate your location constantly and automatically. http://stackoverflow.com/questions/4230867/how-do-i-simulate-a-mouse-click-through-the-mac-terminal/26687223 By this, we can simulate a / some / lot of click(s) programmatically compile the autoClicker.m with gcc at terminal. So change the x,y location of your xcode's simulate button. LOL don't ask me your x,y, find it and test it by yourself, to have it easy when adjusting your x,y, you may set the sleep time longer among loops :) more tip: the loop will stop if you close the game controller as it looks for the active state on game controller, so please change the urlopen address here too with your game controller's ip. Overall flow you provide location data on game controller receive it and generate gpx file constantly when you move blank project referencing the gpx and simulate on your playing device auto click the xcode buttons constantly Have Fun!"
3366,"[OUTDATED] Starter template for React with webpack. Doesn't focus on simplicity! NOT FOR BEGINNERS!webpack/react-starter Starter template for react and webpack. Features Compilation with webpack React and jsx react-router Stylesheets can be CSS, LESS, SASS, Stylus or mixed Embedded resources like images or fonts use DataUrls if appropriate A simple flag loads a react component (and dependencies) on demand. Development Development server Optionally Hot Module Replacement development server (LiveReload for Stylesheets and React components enabled) Uses SourceUrl for performance, but you may switch to SourceMaps easily Production Server example for prerendering for React components Initial data inlined in page Long Term Caching through file hashes enabled Generate separate css file to avoid FOUC Minimized CSS and javascript Also supports coffee-script files if you are more a coffee-script person. You can also require markdown or text files for your content. Local Installation Install node.js or io.js Just clone this repo and change the origin git remote. Installation via Vagrant Install vagrant Development server The configuration is webpack-dev-server.config.js. It automatically recompiles and refreshes the page when files are changed. Also check the webpack-dev-server documentation. Hot Module Replacement development server The configuration is webpack-hot-dev-server.config.js. It automatically recompiles when files are changed. When a hot-replacement-enabled file is changed (i. e. stylesheets or React components) the module is hot-replaced. If Hot Replacement is not possible the page is refreshed. Hot Module Replacement has a performance impact on compilation. Production compilation and server The configuration is webpack-production.config.js. The server is at lib/server.js The production setting builds two configurations: one for the client (build/public) and one for the serverside prerendering (build/prerender). Legacy static assets Assets in public are also served. Build visualization After a production build you may want to visualize your modules and chunks tree. Use the analyse tool with the file at build/stats.json. Loaders and file types Many file types are preconfigured, but not every loader is installed. If you get an error like Cannot find module ""xxx-loader"", you'll need to install the loader with npm install xxx-loader --save and restart the compilation. Common changes to the configuration Add more entry points (for a multi page app) Add an entry point to make-webpack-config.js (var entry). Add a new top-level react component in app (xxxRoutes.js, xxxStoreDescriptions.js, xxxStores.js). (Optional) Enable commonsChunk in webpack-production.config.js and add <script src=""COMMONS_URL""></script> to app/prerender.html. Modify the server code to require, serve and prerender the other entry point. Restart compilation. Switch devtool to SourceMaps Change devtool property in webpack-dev-server.config.js and webpack-hot-dev-server.config.js to ""source-map"" (better module names) or ""eval-source-map"" (faster compilation). SourceMaps have a performance impact on compilation. Enable SourceMaps in production Uncomment the devtool line in webpack-production.config.js. Make sure that the folder build\public\debugging is access controlled, i. e. by password. SourceMaps have a performance impact on compilation. SourceMaps contains your unminimized source code, so you need to restrict access to build\public\debugging. Coffeescript Coffeescript is not installed/enabled by default to not disturb non-coffee developer, but you can install it easily: npm install coffee-redux-loader --save In make-webpack-config.js add "".coffee"" to the var extensions = ... line. License Copyright (c) 2012-2015 Tobias Koppers MIT (http://www.opensource.org/licenses/mit-license.php)"
4046,"JavaScript documentation generator for node using markdown and jsdocDox Dox is a JavaScript documentation generator written with node. Dox no longer generates an opinionated structure or style for your docs, it simply gives you a JSON representation, allowing you to use markdown and JSDoc-style tags. Installation Install from npm: $ npm install -g dox Usage Examples dox(1) operates over stdio: $ dox < utils.js ...JSON... to inspect the generated data you can use the --debug flag, which is easier to read than the JSON output: $ dox --debug < utils.js utils.js: output: This output can then be passed to a template for rendering. Look below at the ""Properties"" section for details. Usage Programmatic Usage Properties A ""comment"" is comprised of the following detailed properties: - tags - description - isPrivate - isEvent - isConstructor - line - ignore - code - ctx Description A dox description is comprised of three parts, the ""full"" description, the ""summary"", and the ""body"". The following example has only a ""summary"", as it consists of a single paragraph only, therefore the ""full"" property has only this value as well. yields: Large descriptions might look something like the following, where the ""summary"" is still the first paragraph, the remaining description becomes the ""body"". Keep in mind this is markdown, so you can indent code, use lists, links, etc. Dox also augments markdown, allowing ""Some Title:\n"" to form a header. yields: Tags Dox also supports JSdoc-style tags. Currently only @api is special-cased, providing the comment.isPrivate boolean so you may omit ""private"" utilities etc. yields: Complex jsdoc tags dox supports all jsdoc type strings specified in the jsdoc documentation. You can specify complex object types including optional flag =, nullable ?, non-nullable ! and variable arguments .... Additionally you can use typesDescription which contains formatted HTML for displaying complex types. yields: Code The .code property is the code following the comment block, in our previous examples: Ctx The .ctx object indicates the context of the code block, is it a method, a function, a variable etc. Below are some examples: yields: yields: yields: Extending Context Matching Context matching in dox is done by performing pattern matching against the code following a comment block. dox.contextPatternMatchers is an array of all pattern matching functions, which dox will iterate over until one of them returns a result. If none return a result, then the comment block does not receive a ctx value. This array is exposed to allow for extension of unsupported context patterns by adding more functions. Each function is passed the code following the comment block and (if detected) the parent context if the block. Ignore Comments and their associated bodies of code may be flagged with ""!"" to be considered worth ignoring, these are typically things like file comments containing copyright etc, however you of course can output them in your templates if you want. vs You may use -S, --skipSingleStar or {skipSingleStar: true} to ignore /* ... */ comments. Running tests Install dev dependencies and execute make test: $ npm install -d $ make test License (The MIT License) Copyright (c) 2011 TJ Holowaychuk <tj@vision-media.ca> Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the 'Software'), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED 'AS IS', WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
3560,"The lightweight, distributed relational database built on SQLite rqlite is a lightweight, distributed relational database, which uses SQLite as its storage engine. Forming a cluster is very straightforward, it gracefully handles leader elections, and tolerates failures of machines, including the leader. rqlite is available for Linux, macOS, and Microsoft Windows. Check out the rqlite FAQ. Why? rqlite gives you the functionality of a rock solid, fault-tolerant, replicated relational database, but with very easy installation, deployment, and operation. With it you've got a lightweight and reliable distributed relational data store. Think etcd or Consul, but with relational data modelling also available. You could use rqlite as part of a larger system, as a central store for some critical relational data, without having to run larger, more complex distributed databases. Finally, if you're interested in understanding how distributed systems actually work, rqlite is a good example to study. Much thought has gone into its design and implementation, with clear separation between the various components, including storage, distributed consensus, and API. How? rqlite uses Raft to achieve consensus across all the instances of the SQLite databases, ensuring that every change made to the system is made to a quorum of SQLite databases, or none at all. You can learn more about the design here. Key features Trivially easy to deploy, with no need to separately install SQLite. Fully replicated production-grade SQL database. Production-grade distributed consensus system. An easy-to-use HTTP(S) API, including leader-redirection and bulk-update support. A command-line interface is also available, as are various client libraries. Discovery Service support, allowing clusters to be dynamically created. Extensive security and encryption support, including node-to-node encryption. Choice of read consistency levels. Optional read-only (non-voting) nodes, which can add read scalability to the system. A form of transaction support. Hot backups. Quick Start Detailed documentation is available. You may also wish to check out the rqlite Google Group. The quickest way to get running on macOS and Linux is to download a pre-built release binary. You can find these binaries on the Github releases page. If you prefer Windows you can download the latest build here. Once installed, you can start a single rqlite node like so: Setting -node-id isn't strictly necessary at this time, but highly recommended. It makes cluster management much clearer. This single node automatically becomes the leader. You can pass -h to rqlited to list all configuration options. Docker Alternatively you can pull the latest release via docker pull rqlite/rqlite. Forming a cluster While not strictly necessary to run rqlite, running multiple nodes means you'll have a fault-tolerant cluster. Start two more nodes, allowing the cluster to tolerate failure of a single node, like so: This demonstration shows all 3 nodes running on the same host. In reality you probably wouldn't do this, and then you wouldn't need to select different -http-addr and -raft-addr ports for each rqlite node. With just these few steps you've now got a fault-tolerant, distributed relational database. For full details on creating and managing real clusters, including running read-only nodes, check out this documentation. Cluster Discovery There is also a rqlite Discovery Service, allowing nodes to automatically connect and form a cluster. This can be much more convenient, allowing clusters to be dynamically created. Check out the documentation for more details. Inserting records Let's insert some records via the rqlite CLI, using standard SQLite commands. Once inserted, these records will be replicated across the cluster, in a durable and fault-tolerant manner. Your 3-node cluster can suffer the failure of a single node without any loss of functionality or data. Data API rqlite has a rich HTTP API, allowing full control over writing to, and querying from, rqlite. Check out the documentation for full details. There are also client libraries available. Performance rqlite replicates SQLite for fault-tolerance. It does not replicate it for performance. In fact performance is reduced somewhat due to the network round-trips. Depending on your machine (particularly its IO performance) and network, individual INSERT performance could be anything from 10 operations per second to more than 200 operations per second. However, by using the bulk API, transactions, or both, throughput will increase significantly, often by 2 orders of magnitude. This speed-up is due to the way Raft and SQLite work. So for high throughput, execute as many operations as possible within a single transaction. In-memory databases By default rqlite uses an in-memory SQLite database to maximise performance. In this mode no actual SQLite file is created and the entire database is stored in memory. If you wish rqlite to use an actual file-based SQLite database, pass -on-disk to rqlite on start-up. Does using an in-memory database put my data at risk? No. Since the Raft log is the authoritative store for all data, and it is written to disk by each node, an in-memory database can be fully recreated on start-up. Using an in-memory database does not put your data at risk. Limitations Only SQL statements that are deterministic are safe to use with rqlite, because statements are committed to the Raft log before they are sent to each node. In other words, rqlite performs statement-based replication. For example, the following statement could result in a different SQLite database under each node: Technically this is not supported, but you can directly read the SQLite under any node at anytime, assuming you run in ""on-disk"" mode. However there is no guarantee that the SQLite file reflects all the changes that have taken place on the cluster unless you are sure the host node itself has received and applied all changes. In case it isn't obvious, rqlite does not replicate any changes made directly to any underlying SQLite file, when run in ""on disk"" mode. If you change the SQLite file directly, you will cause rqlite to fail. Only modify the database via the HTTP API. SQLite dot-commands such as .schema or .tables are not directly supported by the API, but the rqlite CLI supports some very similar functionality. This is because those commands are features of the sqlite3 command, not SQLite itself. Status and Diagnostics You can learn how to check status and diagnostics here. Backup and restore Learn how to hot backup your rqlite cluster here. You can also load data directly from a SQLite dump file. Security You can learn about securing access, and restricting users' access, to rqlite here. Google Group There is a Google Group dedicated to discussion of rqlite. Pronunciation? How do I pronounce rqlite? For what it's worth I try to pronounce it ""ree-qwell-lite"". But it seems most people, including me, often pronouce it ""R Q lite""."
4421,"Simple parallax scrolling effect inspired by Spotify.com implemented as a jQuery pluginParallax.js Simple parallax scrolling implemented as a jQuery plugin. http://pixelcog.com/parallax.js/ Please also check our v2.0.0-alpha! We'd be happy to receive your feedback! ATTENTION: please use the issue tracker for bug reports and feature requests ONLY! For questions and topics which go along the lines ""I cannot get this to work"" please turn to stackoverflow.com for help and use the tag parallax.js. Thank you for your understanding! Installation NPM Yarn Bower Please note that although Bower is still maintained, they recommend Yarn for new projects. Setup Include parallax.min.js in your document after including jQuery (compatible with jQuery >= 1.7). Use these CDN links, provided by jsDelivr.com Usage Please note, that <!DOCTYPE html> on top of your document is required! Simple version via data attributes Note: for more complex requirements we recommend using the inner HTML markup below! With that it's possible to use the parallax effect with almost any HTML content To easily add a parallax effect behind an element, add data-parallax=""scroll"" to the element you want to use, and specify an image with data-image-src=""/path/to/image.jpg"". Via JavaScript To call the parallax plugin manually, simply select your target element with jQuery and do the following: Notes What parallax.js will do is create a fixed-position element for each parallax image at the start of the document's body (or another configurable container). This mirror element will sit behind the other elements and match the position and dimensions of its target object. Due to the nature of this implementation, you must ensure that these parallax objects and any layers below them are transparent so that you can see the parallax effect underneath. Also, if there is no other content in this element, you will need to ensure that it has some fixed dimensions otherwise you won't see anything. Also, keep in mind that once initialized, the parallax plugin presumes a fixed page layout unless it encounters a scroll or resize event. If you have a dynamic page in which another javascript method may alter the DOM, you must manually refresh the parallax effect with the following commands: Using inner HTML for complex content You can use the following syntax to enable complex content for the parallax: Please note, that the div with class ""parallax-slider"" is essential here. You then need to initialize it through JS and provide the naturalWidth and naturalHeight options in order to be rendered correctly. This also makes it possible to use responsive images in the slider: Options Options can be passed in via data attributes of JavaScript. For data attributes, append the option name to data-, as in data-image-src="""". Note that when specifying these options as html data-attributes, you should convert ""camelCased"" variable names into ""dash-separated"" lower-case names (e.g. zIndex would be data-z-index=""""). Name type default description imageSrc path null You must provide a path to the image you wish to apply to the parallax effect. naturalWidth number auto You can provide the natural width and natural height of an image to speed up loading and reduce error when determining the correct aspect ratio of the image. naturalHeight number auto position xPos yPos center center This is analogous to the background-position css property. Specify coordinates as top, bottom, right, left, center, or pixel values (e.g. -10px 0px). The parallax image will be positioned as close to these values as possible while still covering the target element. positionX xPos center positionY yPos center speed float 0.2 The speed at which the parallax effect runs. 0.0 means the image will appear fixed in place, and 1.0 the image will flow at the same speed as the page content. zIndex number -100 The z-index value of the fixed-position elements. By default these will be behind everything else on the page. bleed number 0 You can optionally set the parallax mirror element to extend a few pixels above and below the mirrored element. This can hide slow or stuttering scroll events in certain browsers. iosFix boolean true iOS devices are incompatable with this plugin. If true, this option will set the parallax image as a static, centered background image whenever it detects an iOS user agent. Disable this if you wish to implement your own graceful degradation. androidFix boolean true If true, this option will set the parallax image as a static, centered background image whenever it detects an Android user agent. Disable this if you wish to enable the parallax scrolling effect on Android devices. overScrollFix boolean false (Experimental) If true, will freeze the parallax effect when ""over scrolling"" in browsers like Safari to prevent unexpected gaps caused by negative scroll positions. mirrorContainer jQuery Selector body The parallax mirror will be prepended into this container. Contributing If you have a pull request you would like to submit, please ensure that you update the minified version of the library along with your code changes. This project uses uglifyjs to perform code compression. Please use the following command: uglifyjs parallax.js --comments -m -c -o parallax.min.js LICENSE The MIT License (MIT) Copyright (c) 2016 PixelCog Inc. Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the ""Software""), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
841,ClojureScript interface to Facebook's ReactOm NOTE: This project is no longer under active development. If you'd like to use a library that's well maintained that was inspired by some of the ideas presented here see Fulcro A ClojureScript UI framework and client/server architecture over Facebook's React. Om UIs are out of the box snapshotable and undoable and these operations have no implementation complexity and little overhead. Om borrows ideas liberally from Facebook's Relay and Netflix's Falcor with a dash of inspiration from Datomic pull syntax to avoid the typical incidental complexity that arises from client/server state management. Dependency Information Latest release: 1.0.0-beta1 Leiningen and Boot dependency information: Maven dependency information: Example Tutorials There is an Quick Start tutorial that will introduce you to the core concepts of Om here. There are also a variety of other guides here. Documentation There is documentation here Contributing Please contact me via email to request an electronic Contributor Agreement. Once your electronic CA has been signed and returned to me I will accept pull requests. Community If you are looking for help please get in touch either on the clojurians.slack.com #om channel or the om-cljs Google Group. References Worlds: Controlling the Scope of Side Effects A Functional I/O System Directness and Liveness in the Morphic User Interface Construction Environment Learnable Programming Relay Falcor GraphQL Datomic pull syntax Copyright and license Copyright 2013-2017 David Nolen Licensed under the EPL (see the file epl.html).
2899,"AngularJS directives for the Google Maps Javascript APIProject No longer actively maintained This repo is heavily outdated and there are no maintainers. Therefore issue tracking has been disabled. With angular 2 and other competing projects we have decided to announce that this project is no longer activley maintained. If someone desires to take over the project please contact any of the admins. As a warning this project is not activley watched by the admins and is checked here and there to fix any major issues. Therefore if something is major, contact someone directly via mentioning a users name/alias (will notify the user/admin). Alternatives: angularjs-google-maps angular2-google-maps angular-google-maps AngularJS directives for Google Maps Builds: - Master (2.3.X): 2.2.X: 2.1.X: 2.0.X: task board: Getting started This is a set of directives and services for AngularJS ~1.0.7+, ^1.2.2+. Dependencies Please always be checking the package.json and bower.json. They are the spoken word and will usually be more up to date than this readme. Tip use some library which will always pull in your dependencies (no matter what the changes are) to your vendor.js. IE: main-bower-files Current Dependencies: - lodash - angular - angular-simple-logger as of 2.2.X - google maps sdk, loaded for you by this directives services Development and or Running the Build If you plan to hack on the directives or want to run the example, first thing to do is to install NPM dependencies: Installing for Meteor application: Installing for Meteor 1.3+ application: Building To build the library after you made changes, simply run grunt: If you get errors from jshint or specs, just add the --force argument. Generating SourceMap(s) This will generate source maps for development (angular-google-maps_dev_mapped.js) (non minified) and source maps to minified (angular-google-maps_dev_mapped.min.js) files. They each have their own corresponding map files. To get the coinciding source files you will need to copy the generated /tmp directory (currently not under scc). Running the example To run the example page, just run and open your browser on http://localhost:3000/example.html. Documentation The various directives are documented at official site. Contributing Filing issues: Prior to submitting an issue: - Search open/closed issues, src examples (./examples), gitter, and then google plus community! Again please search! - issues w/ plnkrs get attention quicker Pull Requests (PR) more than welcome! If you're adding new features, it would be appreciated if you would provide some docs about the feature. This can be done either by adding a card to our Waffle.io board, forking the website branch and issuing a PR with the updated documentation page, or by opening an issue for us to add the documentation to the site. PR's should follow angular git commit conventions. Branching Scheme PRS to master are for 2.3.X only. If you want it rolled into a older release then target your PR to that respective branching name like 2.1.X. Note: many fixes relevant to 2.0.X can be rolled up into 2.1.X, 2.2.X and 2.3.X master: points to the active targeted next release branch (2.3.X) 2.2.X: latest of 2.2.X 2.1.X: """" 2.0.X: """" ... etc"
497,"Style guides for Google-originated open-source projectsGoogle Style Guides Every major open-source project has its own style guide: a set of conventions (sometimes arbitrary) about how to write code for that project. It is much easier to understand a large codebase when all the code in it is in a consistent style. Style covers a lot of ground, from use camelCase for variable names to never use global variables to never use exceptions. This project (google/styleguide) links to the style guidelines we use for Google code. If you are modifying a project that originated at Google, you may be pointed to this page to see the style guides that apply to that project. This project holds the C++ Style Guide, C# Style Guide, Swift Style Guide, Objective-C Style Guide, Java Style Guide, Python Style Guide, R Style Guide, Shell Style Guide, HTML/CSS Style Guide, JavaScript Style Guide, TypeScript Style Guide, AngularJS Style Guide, Common Lisp Style Guide, and Vimscript Style Guide. This project also contains cpplint, a tool to assist with style guide compliance, and google-c-style.el, an Emacs settings file for Google style. If your project requires that you create a new XML document format, the XML Document Format Style Guide may be helpful. In addition to actual style rules, it also contains advice on designing your own vs. adapting an existing format, on XML instance document formatting, and on elements vs. attributes. The style guides in this project are licensed under the CC-By 3.0 License, which encourages you to share these documents. See https://creativecommons.org/licenses/by/3.0/ for more details. The following Google style guides live outside of this project: Go Code Review Comments and Effective Dart. Contributing With few exceptions, these style guides are copies of Google's internal style guides to assist developers working on Google owned and originated open source projects. Changes to the style guides are made to the internal style guides first and eventually copied into the versions found here. External contributions are not accepted. Pull requests are regularly closed without comment. Issues that raise questions, justify changes on technical merits, or point out obvious mistakes may get some engagement and could in theory lead to changes, but we are primarily optimizing for Google's internal needs. "
1412,"BOOTFLAT is an open source Flat UI KIT based on Bootstrap 3.3.0 CSS framework. It provides a faster, easier and less repetitive way for web developers to create elegant web apps.__________ __ _____.__ __ \______ \ ____ _____/ |__/ ____\ | _____ _/ |_ | | _// _ \ / _ \ __\ __\| | \__ \\ __\ | | ( <_> | <_> ) | | | | |__/ __ \| | |______ /\____/ \____/|__| |__| |____(____ /__| \/ \/ What is Bootflat? BOOTFLAT is an open source Flat UI KIT based on Bootstrap 3.3.0 CSS framework. It provides a faster, easier and less repetitive way for web developers to create elegant web apps. Bootflat is built on the foundations of Bootstrap, visioned in a stunning flat design. Bootstrap itself is a trusted, reliable and proven tool for developers. Built with Sass 3.4.9. Bootflat is compatible with the following browsers: IE8, IE9, IE10, IE11, Firefox, Safari, Opera, Chrome. Thanks for supporting our framework, and enjoy! Preview For the designers, we offer a free PSD file for you, it including a set of beautiful and pure components, which you can use to create startup projects, websites or iOS/Android Apps. Features: 1. Bootstrap 3.3.0 Bootflat is built on Bootstrap 3.3.0: the sleek, intuitive, and powerful mobile-first front-end framework for faster and easier web development. 2. HTML5 & CSS3 Bootflat's components are built with HTML5 and CSS3. The pages use header, nav and section to build the layout. Bootflat also comes with several splendid color schemes built-in, and allows for easy customization. 3. Lightweight Bootflat uses lightweight high-function plugins for maximum performance, keeping CSS and JS file sizes down. 4. Mobile first Bootflat is fully responsive, built for mobile-first in mind. It provides off screen navigation, and almost all the widgets are compatible with all screen sizes. Quick start Clone the repo: git clone https://github.com/bootflat/bootflat.github.io.git Install with npm npm install bootflat Install with bower bower install Bootflat The source files are in the bootflat/ folder. You can just grab the bootflat/css/, bootflat/scss/,bootflat/js/ and bootflat/img/ folders and you'll be good to go. <!doctype html> <html> <head> <title>Minimal Bootflat example</title> <link rel=""stylesheet"" href=""https://netdna.bootstrapcdn.com/bootstrap/3.3.0/css/bootstrap.min.css""> <link rel=""stylesheet"" href=""https://bootflat.github.io/bootflat/css/bootflat.css""> </head> <body> <h1>Test bootflat</h1> <a class=""btn btn-primary"">Flat button</a> <!-- Bootstrap --> <script src=""https://code.jquery.com/jquery-1.11.0.min.js""></script> <script src=""https://netdna.bootstrapcdn.com/bootstrap/3.3.0/js/bootstrap.min.js""></script> <!-- Bootflat's JS files.--> <script src=""https://bootflat.github.io/bootflat/js/icheck.min.js""></script> <script src=""https://bootflat.github.io/bootflat/js/jquery.fs.selecter.min.js""></script> <script src=""https://bootflat.github.io/bootflat/js/jquery.fs.stepper.min.js""></script> </body> </html> Table of contents: Home page Getting Started Documentation Flat UI Color Picker Free PSD Free Sketch Changelog: 2014/11/4 version 2.0.4 support bootstrap 3.3.0 2014/9/3 version 2.0.4 add widget: TimeLine 2014/8/26 add color picker, you can make a flat design with it 2014/7/9 version 2.0.3 support bootstrap 3.2.0 and Sass 3.3.9, add wigets: Calendar, Pricing 2014/6/5 version 2.0.2 add wigets: Toggle, Selecter, Stepper 2014/4/3 version 2.0.1 support bootstrap 3.1.1 2014/3/6 version 2.0.0 support bootstrap 3.0.1 Community Follow @flathemes on Twitter. Have a feature request or find a bug? Submit an issue. LICENSE Bootflat is licensed under the MIT Open Source license. For more information, please see the LICENSE file in this repository."
2099,"Learn and understand Docker technologies, with real DevOps practice!Docker v1.3.0 | | - | | :------------- | :--- | | | | Docker Docker Docker Linux Docker Docker 7 ~ 9 10 ~ 12 1314 Docker EtcdFedora CoreOSKubernetes docker-practice.comGitBookGithub $ docker run -it --rm -p 4000:80 ccr.ccs.tencentyun.com/dockerpracticesig/docker_practice:vuepress Docker Docker ~ ~ dpsigs Docker QQ Docker Docker QQ I 341410255 QQ II 419042067 QQ III 210028779 QQ IV 483702734 QQ V 460598761 QQ VI 581983671 QQ VII 252403484 QQ VIII544818750 QQ IX 571502246 QQ X 145983035 Issues Docker China-Pub coffee~"
4545," The friendly full-stack language Imba is a friendly full-stack programming language for the web that compiles to performant JavaScript. It has language level support for defining, extending, subclassing, instantiating and rendering DOM nodes. Get started Documentation To get started with Imba, we recommend reading through the official guide. Community Imba Community Meeting Everyone is welcome! This is a great place to report your issues, hangout and talk about your project using Imba. If you have an open pull request which has not seen attention, you can ping during the meeting. For the exact meeting times please use the Meetup group Imba Oslo Meetup, this is where you can see the timezone, cancellations, etc. You can join us remotely via Zoom. Did you miss a meeting? No worries, catch up via the meeting notes or video recordings. Chat For questions and support please use our community chat on Discord. License MIT Copyright (c) 2015-present, Sindre Aarsaether"
1117,"Iconic fonts scissorsFontello - icon font scissors website: fontello.com, help: wiki This tool lets you combine icon webfonts for your own project. With fontello you can: shrink glyph collections, minimizing font size merge symbols from several fonts into a single file access large sets of professional-grade open source icons Developers API Fontello allows easy scripting, to implement different convenient features: Open site from command line, with your configuration, and import edited project Makefile example. That's a live working code, used for development of fontello itself. Writing website plugins, to import/export icons via admin panel. When more examples available, those will be added here. API methods POST https://fontello.com/ creates a session with your config and return you session_id. You can use it later to open fontello with your configuration and to automatically download your font. Session is stored for 24h. POST params (form-encoded): config - (Required) content of config.json for your font url - (Optional) if used, download button will link to your admin panel, where you can run importing script. https://fontello.com/[session_id] - opening fontello with your config preloaded. When you edit font, your config is automatically sent to server https://fontello.com/[session_id]/get - download your font. Note. When you open site via API url, download button will have another text. Examples Makefile - quick load iconic font from your project via CLI & save result back. fontello-cli - the same, as above, but written in node.js. If you don't like make utility, then fontello-cli is for you :) fontello_rails_converter - Ruby CLI gem for interacting with the API. Additional features (Sass conversion) for Rails integration, but should work for every project. grunt-fontello - lightweight integration with grunt Authors Roman Shmelev (shmelev). Vitaly Puzrin (puzrin). Aleksey Zapparov (ixti). Evgeny Shkuropat (shkuropat). Vladimir Zapparov (dervus). Alex Kocharin (rlidwka). Thanks to: Werner Lemberg for help with ttfautohint. Hermanto Lim for the image. License Fontello's code (all files, except fonts) is distributed under MIT license. See LICENSE file for details. Embedded fonts are distributed under their primary licenses (SIL OFL / CC BY / CC BY-SA). See fonts info on fontello website for credits & links to homepages. This info is also included in generated font archives for your convenience (see LICENSE.txt file). Generated fonts are intended for web usage, and should not be considered/distributed as independent artwork. Consider fontello a ""font archiver"" and credit original font creators according to their respective license. Crediting fontello is not required :)"
3167,"commandline chromecast playercastnow Castnow is a command-line utility that can be used to play back media files on your Chromecast device. It supports playback of local video files, videos on the web and torrents. You can also re-attach a running playback session (this sentence should belong somewhere else). Interested in being a castnow maintainer? I currently don't have that much time to maintain this project and have also lost some interest (to be honest). Main reason is that we have had a new TV for a few months that supports casting directly to it using DLNA (you may wanna checkout dlnacast). Feel free to contact me ( simon@sope.io ) if you want to be added as a maintainer to castnow. Install sudo npm install castnow -g Usage Options --tomp4 Transcode a video file to mp4 during playback. This option requires ffmpeg to be installed on your computer. The play / pause controls are currently not supported in transcode mode. --device ""my chromecast"" If you have more than one Chromecast on your network, use the --device option to specify the device on which you want to start casting. Otherwise, castnow will just use the first device it finds in the network. --address 192.168.1.4 The IP address or hostname of your chromecast. This will skip the MDNS scan. --subtitles <path/URL> This can be a path or URL to a vtt or srt file that contains subtitles. --subtitle-scale 1.5 Scaling factor for the size of the subtitle font. Default is 1.0. --subtitle-color #FFFFFFFF Foreground RGBA color of the subtitle font. --myip 192.168.1.8 Your main IP address (useful if you have multiple network adapters) --quiet Hide the player timeline. --peerflix-<option> <argument> Pass options to peerflix. --ffmpeg-<option> <argument> Pass options to ffmpeg. --type <type> Explicity set the mime-type of the first item in the playlist (e.g. 'video/mp4'). --seek <hh:mm:ss> Seek to the specified time on start using the format hh:mm:ss or mm:ss. --bypass-srt-encoding Disable automatic UTF-8 encoding of SRT subtitles. --loop Play the list of files over and over in a loop, forever. --shuffle Play the list of files in random order. --recursive List all files in directories recursively. --volume-step Step at which the volume changes. Helpful for speakers that are softer or louder than normal. Value ranges from 0 to 1. Default is 0.05. --command <key1>,<key2>,... Execute key command(s) (where each <key> is one of the keys listed under player controls, below). --exit Exit when playback begins or --command <key> completes. --help Display help message. Optionally, options can be preset by storing them in a file named .castnowrc in the current user's home directory. For example: Player Controls YouTube Support We had to drop direct YouTube support for now since google changed the chromecast YouTube API. However, there is a nice workaround in combination with the tool youtube-dl: youtube-dl -o - https://youtu.be/BaW_jenozKc | castnow --quiet - Thanks to trulex for pointing that out. Non-Interactive Castnow can also be used in cron jobs or via window-manager bindings; for example: Usage via screen command To avoid starting a new castnow command every time (which takes long time) you should use background sessions. reporting bugs/issues Please include the debug output in your issues. You can enable the debug messages by setting the DEBUG environment variable before running the castnow command like this: DEBUG=castnow* castnow ./myvideo.mp4. Some problems have already been addressed in our wiki https://github.com/xat/castnow/wiki. contributors tooryx przemyslawpluta License Copyright (c) 2015 Simon Kusterer Licensed under the MIT license."
1413,"Speech and Vision Based Intelligent Personal AssistantLucida Lucida is a speech and vision based intelligent personal assistant inspired by Sirius. Visit our website for tutorial, and Lucida-users for help. The project is released under BSD license, except certain submodules contain their own specific licensing information. We would love to have your help on improving Lucida, and see CONTRIBUTING for more details. Overview lucida: back-end services and command center (CMD). Currently, there are 7 categories of back-end services: ""ASR"" (automatic speech recognition), ""IMM"" (image matching), ""QA"" (question answering), ""CA"" (calendar events retrieval), ""IMC"" (image classification), ""FACE"" (facial recognition), and ""DIG"" (digit recognition). You can delete or replace these services with your own, or you can simply add a new service. For example, if you know some better ASR implementation, have an interesting image captioning end-to-end system, or have access to a quality machine translation algorithm, please read the section ""How to Add Your Own Service into Lucida?"" below. The command center determines which services are needed based on the user input, sends requests to them, and returns response to the user. In the following diagram, the user asks a query that needs the following three services: ASR, IMM, and QA. The ""cloud"" behind each box means the Docker container(s) running on the host machine(s). tools: dependencies necessary for compiling Lucida. Due to the fact that services share some common dependencies, all services should be compiled after these dependencies are installed. The advantage of a central point of dependencies is that the total size of compiled services is minimized; the disadvantage is that it makes deleting a service from Lucida non-trivial -- you have to remove its dependencies in tools. Lucida Local Development If you want to make contributions to Lucida, please build it locally: From this directory, type: make local. This will run scripts in tools/ to install all the required dependencies. After that, it will compile back-end services in lucida/. Important note for Ubuntu 16.04 users: please read note #1. If for some reason you need to compile part of it (e.g. one back-end service), make sure to set the following environment variable as set in Makefile: You can add it permanently to your bash profile. Start all services: This will spawn a terminal window (gnome-terminal) for each service as well as the command center. Once they all start running, open your browser and visit http://localhost:3000/. Check out the tutorial for usage and sample questions. Currently, the command center receives the user input in the form of HTTP requests sent from your browser, but in future we can support other forms of input. Lucida Docker Deployment If you want to use Lucida as a web application, please deploy using Docker and Kubernetes: Install Docker: refer to https://docs.docker.com/engine/installation/. Navigate to tools/deploy/ and follow the instructions there. Once done, check out the tutorial for usage and sample questions. REST API for command center The REST API is in active development and may change drastically. It currently supports only infer and learn. Other features may be added later. An example client for botframework is available. Information on how to use the API can be found in the wiki Design Notes -- How to Add Your Own Service into Lucida? Back-end Communication Thrift is an RPC framework with the advantages of being efficient and language-neutral. It was originally developed by Facebook and now developed by both the open-source community (Apache Thrift) and Facebook. We use both Apache Thrift and Facebook Thrift because Facebook Thrift has a fully asynchronous C++ server but does not support Java very well. Also, Apache Thrift seems to be more popular. Therefore, we recommend using Apache Thrift for services written in Python and Java, and Facebook Thrift for services written in C++. However, you can choose either one for your own service as long as you follow the steps below. One disadvantage about Thrift is that the interface has to be pre-defined and implemented by each service. If the interface changes, all services have to re-implement the interface. We try to avoid changing the interface by careful design, but if you really need to adapt the interface for your need, feel free to modify, but make sure that all services implement and use the new interface. Detailed Instructions You need to configure the command center (CMD) besides implementing the Thrift interface in order to add your own service into Lucida. Let's break it down into two steps: Implement the Thrift interface jointly defined in lucida/lucidaservice.thrift and lucida/lucidatypes.thrift. lucida/lucidaservice.thrift The basic functionalities that your service needs to provide are called create, learn, and infer. They all take in the same type of parameters, a string representing the Lucida user ID (LUCID), and a QuerySpec defined in lucida/lucidatypes.thrift. The command center invokes these three procedures implemented by your service, and services can also invoke these procedures on each other to achieve communication. Thus the typical data flow looks like this: But it also can be like this: In this scenario, make sure to implement the asynchronous Thrift interface. If YOS0 implements the asynchronous Thrift interface, it won't block on waiting for the response from YOS1. If YOS0 implements the synchronous Thrift interface, it cannot make progress until YOS1 returns the response, so the operating system will perform a thread context switch, and let the current thread sleep until YOS1 returns. See section 3 of step 1 for implementation details. create: create an intelligent instance based on supplied LUCID. It gives services a chance to warm up the pipeline, but our current services do not need that. Therefore, the command center does not send create request at this point. If your service needs to warm up for each user, make sure to modify the command center which is detailed in step 2. learn: tell the intelligent instance to learn new knowledge based on data supplied in the query, which usually means the training process. Although it has be implemented, you can choose to do nothing in the function body if your service cannot learn new knowledge. For example, it may be hard to retrain a DNN model, so the facial recognition service simply prints a message when it receives a learn request. Otherwise, consider using a database system to store the new knowledge. Currently, we use MongoDB to store the text and image knowledge. You need to tell the command center whether to send a learn request to your service or not, which is detailed in step 2. infer: ask the intelligence to infer using the data supplied in the query, which usually means the predicting process. Notice all the three functions take in QuerySpec as their second parameters, so let's see what QuerySpec means for each function. lucida/lucidatypes.thrift: A QuerySpec has a name, which is create for create, knowledge for learn, and query for infer. A QuerySpec also has a list of QueryInput called content, which is the data payload. A QueryInput consists of a type, a list of data, and a list of tags. If the function call is learn: One QueryInput is constructed by the command center currently, but you should still iterate through all QueryInputs in case for change in future. For QueryInput, type can be text for plain text, url for url address to extract text from, image for image, or unlearn (undo learn) for the reverse process of learn. Here is our assumptions: a service can handle either text or image, and if it can handle text, the types your service should handle are text, url, and unlearn, and if it can handle image, the types your service should handle are image and unlearn. See step 2 for details on how to specify the type of knowledge that your service can learn. If type is text or url, data[i] is the ith piece of text or url as new knowledge and tags[i] is the id of the ith piece of text generated by a hash function in the command center; if type is image, data[i] is the ith image as new knowledge (notice that it is the actual string representation of an image and thus can very long), and tags[i] is the label/name of the ith image received from the front end; if type is unlearn, data should be ignored by your service (usually a list of an empty string), and tags[i] is the ith id of the text or the image label to delete, based on whether the service can handle text or image. If the function call is infer: Each QueryInput in content corresponds to one service (CMD is not considered to be a service) in the service graph, a connected directed acyclic graph (DAG) describing all services that are needed for the query. Thus, for the following service graph, two QueryInputs are present in content, each being a node in the graph: For QueryInput, type can be text for plain text, or image for image (no url for infer). See step 2 for details on how to specify the type of query that your service can process. If type is text, data[0] is the 0th piece of text; if type is image, data[0] is the 0th image. There is only one string in data. tags have different meanings from learn and are of the following format: . tags in the ith QueryInput in content describe the location of the ith node and its relation to other nodes. By location, we mean that the host:port specifies the location of the ith node. By relation to other nodes, we mean that the list of integers specifies the indices of nodes that the ith node points to. Therefore, the above service graph results in a QuerySpec that looks like this: . We can define arbitrarily complicated service graphs. For example, for the following service graph: , the resulting QuerySpec may look like this, assuming YOSX is running at 909X: . Notice that if the order of QueryInput in content is rearranged, the resulting QuerySpec still corresponds to the same graph. In fact, there are 2^(N) valid QuerySpecs for a given graph, and you need to define only one of them in the configuration file of the command center. Notice that the starting nodes, YOS0 and YOS1, need to be specified separately, so that the command center knows where to send the request(s) to. If more than one starting nodes are specified, the command center simply concatenates the results returned from all of them. See step 2 for more details on how to specify service graphs and starting nodes. The command center guarantees to send a valid QuerySpec, but your service is responsible for parsing the graph, further sending the request(s) to other service(s), and returning the response(s) to the service(s) it is pointed to by. tags simply provide the information of all nodes involved in the service graph. That being said, suppose YOS0 deliberately does not send the request to YOS2, and YOS2 is written in a way that it cannot return to YOS1 without processing requests from both YOS0 and YOS1. Then YOS2 is stalled, which leads to YOS1 waiting for YOS2, and the command center waiting for YOS1. Each service is also allowed to ignore or modify the graph if that is necessary, but that should be done with caution. Although the service graph can be very complicated, it is usually very simple. At least for the current services, the most complicated graph looks like this: . Thus, some services can ignore the tags given the fact that they know they are always the only node in the graph. Here are the code examples that you can use for your own service: If it is written in C++, refer to the code in [lucida/imagematching/opencv_imm/server/] (lucida/imagematching/opencv_imm/server/). Look at Makefile for how to generate Thrift stubs which are the abstract base classes your handlers need to inherit. Notice that the interface is implemented in IMMHandler.h and IMMHandler.cpp, and the entry point (which uses a multi-threaded server provided by Thrift) is in IMMServer.cpp. If it is written in Java, refer to the code in [lucida/calendar/src/main/java/calendar/] (lucida/calendar/src/main/java/calendar/) and lucida/calendar/. Look at Makefile for how to generate Thrift stubs which are the interfaces your handlers need to implement. Notice that the interface is implemented in CAServiceHandler.java, and the entry point (which uses a multi-threaded server provided by Thrift) is in CalendarDaemon.java. If it is written in other programming languages, please refer to the official tutorial. Here is a list of what you need to do for step 1: Add a thrift wrapper which typically consists of a Thrift handler implementing the Thrift interfaces, and a daemon program which is the entry point of your service. Refer to the code examples mentioned above. Modify your Makefile so that it uses the Thrift compiler to generate Thrift stubs code. Following the style of the existing Makefiles is recommended. Test your service. (optional) Modify tools if you choose to put the dependencies of your service in this central point. (Local development) Modify the top-level Makefile and lucida/Makefile so that make local and make start_all include your service. (Docker deployment) Create a Dockerfile image for your service, or merge it into the top-level Dockerfile and add Kubernetes yaml scripts for your service into tools/deploy/. Configure the command center. lucida/commandcenter/controllers/Config.py is the only file you must modify, but you may also need to add sample queries to lucida/commandcenter/data/ as training data for the query classifier. Modify the configuration file lucida/commandcenter/controllers/Config.py. SERVICES SERVICES is a dictionary from service name to service object. A service object is constructed this way: , where name is the name of the service, port is the port number, input_type is the type of query that the service can handle which is either text or image, and learn_type is the type of knowledge that the service can learn which is eithertext, image, or None. Recall from step 1 that if learn_type is specified as text, your service will receive type of text, url, and unlearn, and if learn_type is specified as image, your service will receive type of image and unlearn. Notice that you do not need to specify the IP address of your service. By default it is localhost, but if you use Kubernetes and run each service behind a Kubernetes Service, Kubernetes dynamically assigns an IP address to the Service and sets an environment variable <SERVICE_NAME>_PORT_<PORT>_TCP_ADDR for each running container in the cluster. This implies that the Kubernetes Service defined in the yaml file should have the same name as the service defined in this Python file. All of the current Kubernetes scripts in tools/deploy/ follow this naming convention. For example, if you create a Kubernetes Service called imm and run your IMM container behind it, the command center in the same cluster has the following environment variable set to something like 10.0.0.92. This IP address will be tags[0] in the QueryInput as described in step 1. Notice that ASR (automatic speech recognition) is not listed here. The reason is that we currently use [kaldi gstremer server] (https://github.com/alumae/kaldi-gstreamer-server) which directly receives real-time voice query from the front end through web socket in the Docker mode. CLASSIFIER_DESCRIPTIONS CLASSIFIER_DESCRIPTIONS is a dictionary from input type to possible prediction results. Internally, the command center uses a query classifier that predicts the needed services based on both the input type (transcription text, image, or both) and the content of transcription text if present. In the above example, if the user only gives voice input without image, the input type is text, and the prediction result can be either class_QA or class_CA. If the query is classified as class_QA which means generic QA style questions whose training data is in lucida/commandcenter/data/class_QA.txt, the services are needed are represented in a Graph with one Node, i.e. service QA. If you want to replace the current QA implementation with your own, you can still use the training data, and only modify the service graph to be: However, if you need to define another set of questions that a user can ask, e.g. questions about image captioning, refer to the next section on how to add training data. Notice that a service Graph object is constructed with a list of Node Each Node is constructed with the service name and an optional list of node indices in the list that the current node points to. By default, it is an empty list. For example, 'class_IMM_QA' : Graph([Node('IMM', [1]), Node('QA')]) means that the prediction result class_IMM_QA needs the following services: Notice that we do not define which nodes the current node is pointed to by, so we do not know which node is pointed to by the command center. Thus, we need to specify the starting nodes separately. This is done by an optional second parameter in the constructor of Graph: As you see, by default, the command center assumes the 0th node in the node list is the starting node. Thus, a QuerySpec like the following will be sent to the IMM service: The IMM service receives this QuerySpec along with LUCID, and is responsible for further sending the request to the QA service. The IMM service is allowed to modify the QuerySpec and send a reconstructed QuerySpec to QA, but as long as IMM finally returns a string to the command center, it is fine. This degree of flexibility opens up opportunities for complicated communication between your services. Usually, a graph with one node suffices, because that one node may be an entry point to a cluster of your services, which may have complicated feedback loops and use a different communication mechanism. Notice that there is only one possible prediction result if the user only gives image input: class_IMM, because the query classifier only works on text input. However, you can still send the image to multiple services like this: Be aware that there are other parameters that you can change in this configuration file, which are pretty self-explanatory in their names and comments. Add training data for your own query class. We already prepare some sample training data in lucida/commandcenter/data/, but if you need to define a custom type of query that your service can handle, you should create the following file in the above directory: , and have at least 40 pieces of text in it, each being one way to ask about the same question."
4883,"JavaScript Client-Side Cookie Manipulation LibraryCookies.js Cookies.js is a small client-side javascript library that makes managing cookies easy. Features Browser Compatibility Getting the Library Use in CommonJS/Node Environments Without window A Note About Encoding API Reference Features RFC6265 compliant Cross browser Lightweight No dependencies Public domain Supports AMD / CommonJS loaders Browser Compatibility The following browsers have passed all of the automated Cookies.js tests: - Chrome - Firefox 3+ - Safari 4+ - Opera 10+ - Internet Explorer 6+ Getting the Library Direct downloads v1.2.3 Minified (~1.2 KB gzipped) v1.2.3 Unminified (~1.9 KB gzipped) Node Package Manager npm install cookies-js Bower bower install cookies-js Use in CommonJS/Node Environments Without window In environments where there is no native window object, Cookies.js will export a factory method that accepts a window instance. For example, using jsdom, you might do something like: A Note About Encoding RFC6265 defines a strict set of allowed characters for cookie keys and values. In order to effectively allow any character to be used in a key or value, Cookies.js will URI encode disallowed characters in their UTF-8 representation. As such, Cookies.js also expects cookie keys and values to already be URI encoded in a UTF-8 representation when it accesses cookies. Keep this in mind when working with cookies on the server side. .NET Users Do not use HttpUtility.UrlEncode and HttpUtility.UrlDecode on cookie keys or values. HttpUtility.UrlEncode will improperly escape space characters to '+' and lower case every escape sequence. HttpUtility.UrlDecode will improperly unescape every '+' to a space character. Instead, use System.Uri.EscapeDataString and System.Uri.UnescapeDataString. API Reference Methods Cookies.set(key, value [, options]) Cookies.get(key) Cookies.expire(key [, options]) Properties Cookies.enabled Cookies.defaults Methods Cookies.set(key, value [, options]) Alias: Cookies(key, value [, options]) Sets a cookie in the document. If the cookie does not already exist, it will be created. Returns the Cookies object. | Option | Description | Default | | --------: | ------------------------------------------------------------------------------------------------ | ----------- | | path | A string value of the path of the cookie | ""/"" | | domain | A string value of the domain of the cookie | undefined | | expires | A number (of seconds), a date parsable string, or a Date object of when the cookie will expire | undefined | | secure | A boolean value of whether or not the cookie should only be available over SSL | false | A default value for any option may be set in the Cookies.defaults object. Example Usage Cookies.get(key) Alias: Cookies(key) Returns the value of the most locally scoped cookie with the specified key. Example Usage Cookies.expire(key [, options]) Alias: Cookies(key, undefined [, options]) Expires a cookie, removing it from the document. Returns the Cookies object. | Option | Description | Default | | --------: | ------------------------------------------------------------------------------------------------ | ----------- | | path | A string value of the path of the cookie | ""/"" | | domain | A string value of the domain of the cookie | undefined | A default value for any option may be set in the Cookies.defaults object. Example Usage Properties Cookies.enabled A boolean value of whether or not the browser has cookies enabled. Example Usage Cookies.defaults An object representing default options to be used when setting and expiring cookie values. | Option | Description | Default | | --------: | ------------------------------------------------------------------------------------------------ | ----------- | | path | A string value of the path of the cookie | ""/"" | | domain | A string value of the domain of the cookie | undefined | | expires | A number (of seconds), a date parsable string, or a Date object of when the cookie will expire | undefined | | secure | A boolean value of whether or not the cookie should only be available over SSL | false | Example Usage"
4427,"OpenID Connect Provider and OAuth 2.0 Authorization Server Framework for ASP.NET 4.x/KatanaIdentityServer3 Note: This repository is no longer in active development or maintenance, other than reported security vulnerabilities. We highly encourage you to consider IdentityServer4 instead. If you have questions and are seeking free support, see here for more details. If you require commercial support, see here for more details. Dev build: Certified OpenID Connect implementation. Overview IdentityServer is a .NET/Katana-based framework and hostable component that allows implementing single sign-on and access control for modern web applications and APIs using protocols like OpenID Connect and OAuth2. It supports a wide range of clients like mobile, web, SPAs and desktop applications and is extensible to allow integration in new and existing architectures. Watch this for the big picture: Introduction to OpenID Connect, OAuth2 and IdentityServer - and An Introduction to IdentityServer for a more code-centric talk. Go to the documentation site. OpenID Connect specification / OAuth2 specification Getting started IdentityServer is designed as an OWIN/Katana component. By referencing the library or nuget you get a UseIdentityServer extension method for IAppBuilder that allows setting up IdentityServer in your OWIN host: Note: If you're hosting in IIS, make sure you enable RAMMFAR in your web.config file. For more information, e.g. support for MembershipReboot and ASP.NET Identity based user stores support for additional Katana authentication middleware (e.g. Google, Twitter, Facebook etc) support for EntityFramework based persistence of configuration support for WS-Federation extensibility check out the documentation and the samples. Related repositories Access Token Validation EntityFramework support MembershipReboot support ASP.Net Identity support WS-Federation plugin Samples Credits IdentityServer is built using the following great open source projects: ASP.NET Web API Autofac Json.Net LibLog Katana Web Protection Library XUnit License Header Manager ..and is supported by the following open source friendly companies: JetBrains Gitter Huboard AppVeyor MyGet ...and last but not least thanks to all contributors! IdentityServer is a .NET Foundation project "
4810,"A modal built with pure CSS, enhanced with JavaScriptCSS Modals Modals built out of pure CSS Please visit the website to read more about this project and refer to the FAQ in case of a question. What is it Built with pure CSS: CSS Modal is built out of pure CSS. JavaScript is only for sugar. This makes them perfectly accessible. Optimized for mobile: The modals are designed using responsive web design methods. They work on all screen sizes from a small mobile phone up to high resolution screens. Use as Sass plugin: You can use CSS Modal as Sass plugin and apply it to your custom classes. No need to understand all the code. A few other advantages: Accessible, cross-browser, media-adaptive, small and fast! How to use Please be aware that modals get stacked above each other if you open one modal from within another. You can add a data-attribute data-stackable=""false"" to the modal in order to make it non-stackable. Markup You need to include the markup and content for modals in your website. This has a positive effect on SEO. The example code: The id attribute is the one which identifies the modal. You can link to this ID from everywhere. Please note that the ID cannot include the / character since this one is needed for identifying stacked modals. Using header and footer is optional. Just remove the tags if you don't want them in a modal. You should leave the link's href attribute that way to close the modal in order to prevent the page from scrolling to top when clicking on it. Please remember to set a unique ID for the header and change the aria-labelledby attribute to the same value. You link to a modal by simply setting the ID to a link element's href like this: If you want to decouple the modal call from the location's hash you need to add data-cssmodal-nohash to the link. JavaScript As stated above you don't need JavaScript to get a good experience out of CSS Modals. But there are some issues where JavaScript helps: IE 8 compatibility (please include jQuery if you need full compatibility). Pressing escape: If you press ESC on your keyboard while the modal is visible it closes itself. This behavior cannot be achieved with CSS only. Preventing background page from scrolling: If you scroll within the modal and you reach the end you don't want the page in the background to scroll. To prevent this JavaScript pushes a CSS class selector to the body element. Being accessible: To get the browser's focus to the modal and back after closing. Firing events: When a modal opens a custom event is fired called cssmodal:show. When the modal is hidden, an event called cssmodal:hide is triggered. To add this behavior to your website, please include the JavaScript file modal.js right before the closing body-tag: Browser Support This modal is designed to work on all modern browsers. Unfortunately this does not include Internet Explorer 7 or lower. But we deal with IE 8 well, at least it works. On mobile Safari for iOS and Android 4+ it is tested pretty well, while Android 2.3 has some problems (biggest issue is scrolling). It's also working on Windows Phone 8. In numbers: Chrome Firefox Safari 6.x Opera 12+ Internet Explorer 8 (functional, include jQuery if you want support for events) Internet Explorer 9+ iOS 6 Android 2.3 (functional) Android 4.x Windows Phone 8 Media Please be aware that you need to stop playing videos or audio manually after hiding the modal. We have a plugin for this though. Events There is an event cssmodal:show fired on the modal itself after the modal is shown. Another event cssmodal:hide is fired after the modal is hidden. You can use the events by subscribing to them as if they were click events or something. Here is an example using jQuery: There events are not fired in IE8. Please be aware of that and use jQuery or something else to create custom events. Plugins We have a couple for the modal to enhance it: Resize - Resizes modal to size of input elements Gallery - A lightbox plugin (in connection with resize) HTML5 Video - Load videos within the modal Maximum Width - Set a custom maximum width on a per-modal basis Bug reports and feature requests If you got something that's worth including into the project please open an issue for further discussion. Please see the section on contributing on the website. Contributors This is a project by Hans Christian Reinl. Thanks goes out to all other contributors."
683,":octocat: RAMAnimatedTabBarController is a Swift UI module library for adding animation to iOS tabbar items and icons. iOS library made by @Ramotion ANIMATED TAB BAR Swift UI module library for adding animation to iOS tabbar items and icons. We specialize in the designing and coding of custom UI for Mobile Apps and Websites. Stay tuned for the latest updates: Requirements iOS 9.0+ Xcode 10.2 Installation Just add the RAMAnimatedTabBarController folder to your project. or use CocoaPods with Podfile: or Carthage users can simply add to their Cartfile: or Swift Package Manager Usage Create a new UITabBarController in your storyboard or nib. Set the class of the UITabBarController to RAMAnimatedTabBarController in your Storyboard or nib. For each UITabBarItem, set the class to RAMAnimatedTabBarItem. Add a custom image icon for each RAMAnimatedTabBarItem Add animation for each RAMAnimatedTabBarItem : drag and drop an NSObject item into your ViewController set its class to ANIMATION_CLASS (where ANIMATION_CLASS is the class name of the animation you want to use) connect the outlet animation in RAMAnimatedTabBarItem to your ANIMATION_CLASS Demonstration video for step 5 Included Animations RAMBounceAnimation RAMLeftRotationAnimation RAMRightRotationAnimation RAMFlipLeftTransitionItemAnimations RAMFlipRightTransitionItemAnimations RAMFlipTopTransitionItemAnimations RAMFlipBottomTransitionItemAnimations RAMFrameItemAnimation RAMFumeAnimation Creating Custom Animations Create a new class which inherits from RAMItemAnimation: Implement the methods in RAMItemAnimationProtocol: Example: License Animated Tab Bar is released under the MIT license. See LICENSE for details. This library is a part of a selection of our best UI open-source projects. If you use the open-source library in your project, please make sure to credit and backlink to www.ramotion.com Get the Showroom App for iOS to give it a try Try this UI component and more like this in our iOS app. Contact us if interested. "
530,"Screenshots with JavaScripthtml2canvas Homepage | Downloads | Questions JavaScript HTML renderer The script allows you to take ""screenshots"" of webpages or parts of it, directly on the users browser. The screenshot is based on the DOM and as such may not be 100% accurate to the real representation as it does not make an actual screenshot, but builds the screenshot based on the information available on the page. How does it work? The script renders the current page as a canvas image, by reading the DOM and the different styles applied to the elements. It does not require any rendering from the server, as the whole image is created on the client's browser. However, as it is heavily dependent on the browser, this library is not suitable to be used in nodejs. It doesn't magically circumvent any browser content policy restrictions either, so rendering cross-origin content will require a proxy to get the content to the same origin. The script is still in a very experimental state, so I don't recommend using it in a production environment nor start building applications with it yet, as there will be still major changes made. Browser compatibility The library should work fine on the following browsers (with Promise polyfill): Firefox 3.5+ Google Chrome Opera 12+ IE9+ Safari 6+ As each CSS property needs to be manually built to be supported, there are a number of properties that are not yet supported. Usage The html2canvas library utilizes Promises and expects them to be available in the global context. If you wish to support older browsers that do not natively support Promises, please include a polyfill such as es6-promise before including html2canvas. To render an element with html2canvas, simply call: html2canvas(element[, options]); The function returns a Promise containing the <canvas> element. Simply add a promise fulfillment handler to the promise using then: html2canvas(document.body).then(function(canvas) { document.body.appendChild(canvas); }); Building You can download ready builds here. Clone git repository: $ git clone git://github.com/niklasvh/html2canvas.git Install dependencies: $ npm install Build browser bundle $ npm run build Examples For more information and examples, please visit the homepage or try the test console. Contributing If you wish to contribute to the project, please send the pull requests to the develop branch. Before submitting any changes, try and test that the changes work with all the support browsers. If some CSS property isn't supported or is incomplete, please create appropriate tests for it as well before submitting any code changes."
3176,"BCC - Tools for BPF-based Linux IO analysis, networking, monitoring, and moreBPF Compiler Collection (BCC) BCC is a toolkit for creating efficient kernel tracing and manipulation programs, and includes several useful tools and examples. It makes use of extended BPF (Berkeley Packet Filters), formally known as eBPF, a new feature that was first added to Linux 3.15. Much of what BCC uses requires Linux 4.1 and above. eBPF was described by Ingo Molnr as: One of the more interesting features in this cycle is the ability to attach eBPF programs (user-defined, sandboxed bytecode executed by the kernel) to kprobes. This allows user-defined instrumentation on a live kernel image that can never crash, hang or interfere with the kernel negatively. BCC makes BPF programs easier to write, with kernel instrumentation in C (and includes a C wrapper around LLVM), and front-ends in Python and lua. It is suited for many tasks, including performance analysis and network traffic control. Screenshot This example traces a disk I/O kernel function, and populates an in-kernel power-of-2 histogram of the I/O size. For efficiency, only the histogram summary is returned to user-level. The above output shows a bimodal distribution, where the largest mode of 800 I/O was between 128 and 255 Kbytes in size. See the source: bitehist.py. What this traces, what this stores, and how the data is presented, can be entirely customized. This shows only some of many possible capabilities. Installing See INSTALL.md for installation steps on your platform. FAQ See FAQ.txt for the most common troubleshoot questions. Reference guide See docs/reference_guide.md for the reference guide to the bcc and bcc/BPF APIs. Contents Some of these are single files that contain both C and Python, others have a pair of .c and .py files, and some are directories of files. Tracing Examples: examples/tracing/bitehist.py: Block I/O size histogram. Examples. examples/tracing/disksnoop.py: Trace block device I/O latency. Examples. examples/hello_world.py: Prints ""Hello, World!"" for new processes. examples/tracing/mysqld_query.py: Trace MySQL server queries using USDT probes. Examples. examples/tracing/nodejs_http_server.py: Trace Node.js HTTP server requests using USDT probes. Examples. examples/tracing/stacksnoop: Trace a kernel function and print all kernel stack traces. Examples. tools/statsnoop: Trace stat() syscalls. Examples. examples/tracing/task_switch.py: Count task switches with from and to PIDs. examples/tracing/tcpv4connect.py: Trace TCP IPv4 active connections. Examples. examples/tracing/trace_fields.py: Simple example of printing fields from traced events. examples/tracing/urandomread.py: A kernel tracepoint example, which traces random:urandom_read. Examples. examples/tracing/vfsreadlat.py examples/tracing/vfsreadlat.c: VFS read latency distribution. Examples. examples/tracing/kvm_hypercall.py: Conditional static kernel tracepoints for KVM entry, exit and hypercall Examples. Tools: tools/argdist: Display function parameter values as a histogram or frequency count. Examples. tools/bashreadline: Print entered bash commands system wide. Examples. tools/bindsnoop: Trace IPv4 and IPv6 bind() system calls (bind()). Examples. tools/biolatency: Summarize block device I/O latency as a histogram. Examples. tools/biotop: Top for disks: Summarize block device I/O by process. Examples. tools/biosnoop: Trace block device I/O with PID and latency. Examples. tools/bitesize: Show per process I/O size histogram. Examples. tools/bpflist: Display processes with active BPF programs and maps. Examples. tools/btrfsdist: Summarize btrfs operation latency distribution as a histogram. Examples. tools/btrfsslower: Trace slow btrfs operations. Examples. tools/capable: Trace security capability checks. Examples. tools/cachestat: Trace page cache hit/miss ratio. Examples. tools/cachetop: Trace page cache hit/miss ratio by processes. Examples. tools/compactsnoop: Trace compact zone events with PID and latency. Examples. tools/cpudist: Summarize on- and off-CPU time per task as a histogram. Examples tools/cpuunclaimed: Sample CPU run queues and calculate unclaimed idle CPU. Examples tools/criticalstat: Trace and report long atomic critical sections in the kernel. Examples tools/dbslower: Trace MySQL/PostgreSQL queries slower than a threshold. Examples. tools/dbstat: Summarize MySQL/PostgreSQL query latency as a histogram. Examples. tools/dcsnoop: Trace directory entry cache (dcache) lookups. Examples. tools/dcstat: Directory entry cache (dcache) stats. Examples. tools/deadlock: Detect potential deadlocks on a running process. Examples. tools/dirtop: File reads and writes by directory. Top for directories. Examples. tools/drsnoop: Trace direct reclaim events with PID and latency. Examples. tools/execsnoop: Trace new processes via exec() syscalls. Examples. tools/exitsnoop: Trace process termination (exit and fatal signals). Examples. tools/ext4dist: Summarize ext4 operation latency distribution as a histogram. Examples. tools/ext4slower: Trace slow ext4 operations. Examples. tools/filelife: Trace the lifespan of short-lived files. Examples. tools/fileslower: Trace slow synchronous file reads and writes. Examples. tools/filetop: File reads and writes by filename and process. Top for files. Examples. tools/funccount: Count kernel function calls. Examples. tools/funcinterval: Time interval between the same function as a histogram. Examples. tools/funclatency: Time functions and show their latency distribution. Examples. tools/funcslower: Trace slow kernel or user function calls. Examples. tools/gethostlatency: Show latency for getaddrinfo/gethostbyname2 calls. Examples. tools/hardirqs: Measure hard IRQ (hard interrupt) event time. Examples. tools/inject: Targeted error injection with call chain and predicates Examples. tools/killsnoop: Trace signals issued by the kill() syscall. Examples. tools/klockstat: Traces kernel mutex lock events and display locks statistics. Examples. tools/llcstat: Summarize CPU cache references and misses by process. Examples. tools/mdflush: Trace md flush events. Examples. tools/memleak: Display outstanding memory allocations to find memory leaks. Examples. tools/mountsnoop: Trace mount and umount syscalls system-wide. Examples. tools/mysqld_qslower: Trace MySQL server queries slower than a threshold. Examples. tools/netqtop tools/netqtop.c: Trace and display packets distribution on NIC queues. Examples. tools/nfsslower: Trace slow NFS operations. Examples. tools/nfsdist: Summarize NFS operation latency distribution as a histogram. Examples. tools/offcputime: Summarize off-CPU time by kernel stack trace. Examples. tools/offwaketime: Summarize blocked time by kernel off-CPU stack and waker stack. Examples. tools/oomkill: Trace the out-of-memory (OOM) killer. Examples. tools/opensnoop: Trace open() syscalls. Examples. tools/pidpersec: Count new processes (via fork). Examples. tools/profile: Profile CPU usage by sampling stack traces at a timed interval. Examples. tools/readahead: Show performance of read-ahead cache Examples. tools/reset-trace: Reset the state of tracing. Maintenance tool only. Examples. tools/runqlat: Run queue (scheduler) latency as a histogram. Examples. tools/runqlen: Run queue length as a histogram. Examples. tools/runqslower: Trace long process scheduling delays. Examples. tools/shmsnoop: Trace System V shared memory syscalls. Examples. tools/sofdsnoop: Trace FDs passed through unix sockets. Examples. tools/slabratetop: Kernel SLAB/SLUB memory cache allocation rate top. Examples. tools/softirqs: Measure soft IRQ (soft interrupt) event time. Examples. tools/solisten: Trace TCP socket listen. Examples. tools/sslsniff: Sniff OpenSSL written and readed data. Examples. tools/stackcount: Count kernel function calls and their stack traces. Examples. tools/syncsnoop: Trace sync() syscall. Examples. tools/syscount: Summarize syscall counts and latencies. Examples. tools/tcpaccept: Trace TCP passive connections (accept()). Examples. tools/tcpconnect: Trace TCP active connections (connect()). Examples. tools/tcpconnlat: Trace TCP active connection latency (connect()). Examples. tools/tcpdrop: Trace kernel-based TCP packet drops with details. Examples. tools/tcplife: Trace TCP sessions and summarize lifespan. Examples. tools/tcpretrans: Trace TCP retransmits and TLPs. Examples. tools/tcprtt: Trace TCP round trip time. Examples. tools/tcpstates: Trace TCP session state changes with durations. Examples. tools/tcpsubnet: Summarize and aggregate TCP send by subnet. Examples. tools/tcpsynbl: Show TCP SYN backlog. Examples. tools/tcptop: Summarize TCP send/recv throughput by host. Top for TCP. Examples. tools/tcptracer: Trace TCP established connections (connect(), accept(), close()). Examples. tools/threadsnoop: List new thread creation. Examples. tools/tplist: Display kernel tracepoints or USDT probes and their formats. Examples. tools/trace: Trace arbitrary functions, with filters. Examples. tools/ttysnoop: Watch live output from a tty or pts device. Examples. tools/ucalls: Summarize method calls or Linux syscalls in high-level languages. Examples. tools/uflow: Print a method flow graph in high-level languages. Examples. tools/ugc: Trace garbage collection events in high-level languages. Examples. tools/uobjnew: Summarize object allocation events by object type and number of bytes allocated. Examples. tools/ustat: Collect events such as GCs, thread creations, object allocations, exceptions and more in high-level languages. Examples. tools/uthreads: Trace thread creation events in Java and raw pthreads. Examples. tools/vfscount: Count VFS calls. Examples. tools/vfsstat: Count some VFS calls, with column output. Examples. tools/virtiostat: Show VIRTIO device IO statistics. Examples. tools/wakeuptime: Summarize sleep to wakeup time by waker kernel stack. Examples. tools/xfsdist: Summarize XFS operation latency distribution as a histogram. Examples. tools/xfsslower: Trace slow XFS operations. Examples. tools/zfsdist: Summarize ZFS operation latency distribution as a histogram. Examples. tools/zfsslower: Trace slow ZFS operations. Examples. Networking Examples: examples/networking/distributed_bridge/: Distributed bridge example. examples/networking/http_filter/: Simple HTTP filter example. examples/networking/simple_tc.py: Simple traffic control example. examples/networking/simulation.py: Simulation helper. examples/networking/neighbor_sharing/tc_neighbor_sharing.py examples/networking/neighbor_sharing/tc_neighbor_sharing.c: Per-IP classification and rate limiting. examples/networking/tunnel_monitor/: Efficiently monitor traffic flows. examples/networking/vlan_learning/vlan_learning.py examples/vlan_learning.c: Demux Ethernet traffic into worker veth+namespaces. BPF Introspection: Tools that help to introspect BPF programs. introspection/bps.c: List all BPF programs loaded into the kernel. 'ps' for BPF programs. Examples. Motivation BPF guarantees that the programs loaded into the kernel cannot crash, and cannot run forever, but yet BPF is general purpose enough to perform many arbitrary types of computation. Currently, it is possible to write a program in C that will compile into a valid BPF program, yet it is vastly easier to write a C program that will compile into invalid BPF (C is like that). The user won't know until trying to run the program whether it was valid or not. With a BPF-specific frontend, one should be able to write in a language and receive feedback from the compiler on the validity as it pertains to a BPF backend. This toolkit aims to provide a frontend that can only create valid BPF programs while still harnessing its full flexibility. Furthermore, current integrations with BPF have a kludgy workflow, sometimes involving compiling directly in a linux kernel source tree. This toolchain aims to minimize the time that a developer spends getting BPF compiled, and instead focus on the applications that can be written and the problems that can be solved with BPF. The features of this toolkit include: * End-to-end BPF workflow in a shared library * A modified C language for BPF backends * Integration with llvm-bpf backend for JIT * Dynamic (un)loading of JITed programs * Support for BPF kernel hooks: socket filters, tc classifiers, tc actions, and kprobes * Bindings for Python * Examples for socket filters, tc classifiers, and kprobes * Self-contained tools for tracing a running system In the future, more bindings besides python will likely be supported. Feel free to add support for the language of your choice and send a pull request! Tutorials docs/tutorial.md: Using bcc tools to solve performance, troubleshooting, and networking issues. docs/tutorial_bcc_python_developer.md: Developing new bcc programs using the Python interface. Networking At Red Hat Summit 2015, BCC was presented as part of a session on BPF. A multi-host vxlan environment is simulated and a BPF program used to monitor one of the physical interfaces. The BPF program keeps statistics on the inner and outer IP addresses traversing the interface, and the userspace component turns those statistics into a graph showing the traffic distribution at multiple granularities. See the code here. Contributing Already pumped up to commit some code? Here are some resources to join the discussions in the IOVisor community and see what you want to work on. Mailing List: https://lists.iovisor.org/mailman/listinfo/iovisor-dev IRC: #iovisor at irc.oftc.net BCC Issue Tracker: Github Issues A guide for contributing scripts: CONTRIBUTING-SCRIPTS.md External links Looking for more information on BCC and how it's being used? You can find links to other BCC content on the web in LINKS.md."
4181,"An attempt to tame Rails' default policy to log everything.Lograge - Taming Rails' Default Request Logging Lograge is an attempt to bring sanity to Rails' noisy and unusable, unparsable and, in the context of running multiple processes and servers, unreadable default logging output. Rails' default approach to log everything is great during development, it's terrible when running it in production. It pretty much renders Rails logs useless to me. Lograge is a work in progress. I appreciate constructive feedback and criticism. My main goal is to improve Rails' logging and to show people that they don't need to stick with its defaults anymore if they don't want to. Instead of trying solving the problem of having multiple lines per request by switching Rails' logger for something that outputs syslog lines or adds a request token, Lograge replaces Rails' request logging entirely, reducing the output per request to a single line with all the important information, removing all that clutter Rails likes to include and that gets mingled up so nicely when multiple processes dump their output into a single file. Instead of having an unparsable amount of logging output like this: you get a single line with all the important information, like this: The second line is easy to grasp with a single glance and still includes all the relevant information as simple key-value pairs. The syntax is heavily inspired by the log output of the Heroku router. It doesn't include any timestamp by default, instead it assumes you use a proper log formatter instead. Installation In your Gemfile Enable it in an initializer or the relevant environment config: If you're using Rails 5's API-only mode and inherit from ActionController::API, you must define it as the controller base class which lograge will patch: If you use multiple base controller classes in your application, specify an array: You can also add a hook for own custom data Or you can add a timestamp: You can also keep the original (and verbose) Rails logger by following this configuration: You can then add custom variables to the event to be used in custom_options (available via the event.payload hash, which has to be processed in custom_options method to be included in log output, see above): Alternatively, you can add a hook for accessing controller methods directly (e.g. request and current_user). This hash is merged into the log data automatically. To further clean up your logging, you can also tell Lograge to skip log messages meeting given criteria. You can skip log messages generated from certain controller actions, or you can write a custom handler to skip messages based on data in the log event: Lograge supports multiple output formats. The most common is the default lograge key-value format described above. Alternatively, you can also generate JSON logs in the json_event format used by Logstash. Note: When using the logstash output, you need to add the additional gem logstash-event. You can simply add it to your Gemfile like this Done. The available formatters are: In addition to the formatters, you can manipulate the data yourself by passing an object which responds to #call: Internals Thanks to the notification system that was introduced in Rails 3, replacing the logging is easy. Lograge unhooks all subscriptions from ActionController::LogSubscriber and ActionView::LogSubscriber, and hooks in its own log subscription, but only listening for two events: process_action and redirect_to (in case of standard controller logs). It makes sure that only subscriptions from those two classes are removed. If you happened to hook in your own, they'll be safe. Unfortunately, when a redirect is triggered by your application's code, ActionController fires two events. One for the redirect itself, and another one when the request is finished. Unfortunately the final event doesn't include the redirect, so Lograge stores the redirect URL as a thread-local attribute and refers to it in process_action. The event itself contains most of the relevant information to build up the log line, including view processing and database access times. While the LogSubscribers encapsulate most logging pretty nicely, there are still two lines that show up no matter what. The first line that's output for every Rails request, you know, this one: And the verbose output coming from rack-cache: Both are independent of the LogSubscribers, and both need to be shut up using different means. For the first one, the starting line of every Rails request log, Lograge replaces code in Rails::Rack::Logger to remove that particular log line. It's not great, but it's just another unnecessary output and would still clutter the log files. Maybe a future version of Rails will make this log line an event as well. To remove rack-cache's output (which is only enabled if caching in Rails is enabled), Lograge disables verbosity for rack-cache, which is unfortunately enabled by default. There, a single line per request. Beautiful. Action Cable Starting with version 0.11.0, Lograge introduced support for Action Cable logs. This proved to be a particular challenge since the framework code is littered with multiple (and seemingly random) logger calls in a number of internal classes. In order to deal with it, the default Action Cable logger was silenced. As a consequence, calling logger e.g. in user-defined Connection or Channel classes has no effect - Rails.logger (or any other logger instance) has to be used instead. Additionally, while standard controller logs rely on process_action and redirect_to instrumentations only, Action Cable messages are generated from multiple events: perform_action, subscribe, unsubscribe, connect, and disconnect. perform_action is the only one included in the actual Action Cable code and others have been added by monkey patching ActionCable::Channel::Base and ActionCable::Connection::Base classes. What it doesn't do Lograge is opinionated, very opinionated. If the stuff below doesn't suit your needs, it may not be for you. Lograge removes ActionView logging, which also includes rendering times for partials. If you're into those, Lograge is probably not for you. In my honest opinion, those rendering times don't belong in the log file, they should be collected in a system like New Relic, Librato Metrics or some other metrics service that allows graphing rendering percentiles. I assume this for everything that represents a moving target. That kind of data is better off being visualized in graphs than dumped (and ignored) in a log file. Lograge doesn't yet log the request parameters. This is something I'm actively contemplating, mainly because I want to find a good way to include them, a way that fits in with the general spirit of the log output generated by Lograge. However, the payload does already contain the params hash, so you can easily add it in manually using custom_options: FAQ Logging errors / exceptions Our first recommendation is that you use exception tracking services built for purpose ;) If you absolutely must log exceptions in the single-line format, you can do something similar to this example: The :exception is just the basic class and message whereas the :exception_object is the actual exception instance. You can use both / either. Be mindful when including this, you will probably want to cherry-pick particular attributes and almost definitely want to join the backtrace into something without newline characters. Handle ActionController::RoutingError Add a get '*unmatched_route', to: 'application#route_not_found' rule to the end of your routes.rb Then add a new controller action in your application_controller.rb. #146 Contributing See the CONTRIBUTING.md file for further information. License MIT. Code extracted from Travis CI. (c) 2014 Mathias Meyer See LICENSE.txt for details."
2369,"Real time web analytics using node.js and web socketsHUMMINGBIRD Site tracking and analytics storage Description Hummingbird serves a 1x1 tracking pixel to users. In the browser's GET request it sends back tracking data generated by javascript. Requirements node.js v0.8.0 or higher Installation git clone git://github.com/mnutt/hummingbird.git cd hummingbird # Use npm to install the dependencies npm install # To use the map, download MaxMind's GeoIP database and extract to the root directory: wget http://geolite.maxmind.com/download/geoip/database/GeoLiteCity.dat.gz gunzip GeoLiteCity.dat.gz Running Hummingbird To start the analytics server, run the following: node server.js By default a dashboard will be run on port 8080. You can disable it for production use in config/config.js. The dashboard is just html served out of public/; you can serve it using any webserver. Deployment Make sure to properly secure the dashboard if you don't want outside people to see it. This typically means putting the dashboard behind nginx or apache using basic auth. The dashboard's 'listen' function takes a second argument that is the interface to bind; typically you would choose ""127.0.0.1"" to only allow access from localhost, or ""0.0.0.0"" to listen on all interfaces. You should then run the tracking pixel on a different port so that it is accessible to the outside world. Setting Up Tracking The file client/hummingbird.js contains a small script to trigger a hummingbird event. You can either paste the contents of the file into the body of your webpage or you can upload it to your server as a .js file and reference it with a <script> tag. Once you have done so, in the footer of your page you can call HummingbirdTracker.track(); Called with no arguments, it will send over some standard parameters such as the page URL. You can also pass arbitrary data with the event: HummingbirdTracker.track({logged_in: true}); The data can be used within Hummingbird's metrics to filter events on the backend. Architecture Overview Hummingbird is organized into two parts: a node.js-based tracking server that records user activity via a tracking pixel, and a collection of javascript-based widgets that display that activity. The server broadcasts all activity to the clients using Websockets if possible, and falls back to Flash sockets or long polling if necessary. The Hummingbird.WebSocket object receives websocket events from the server in the form of JSON objects. Individual widgets subscribe to a metric and register handler functions to be called whenever that metric is present. Logging Customization Metrics are stored in lib/metrics and auto-loaded. Each metric contains a handler function that is called every time a new user event occurs. Metrics store data in the data object property which gets emitted to clients in intervals specified by the metric. A basic example can be found in lib/metrics/total_views.js. An example of how a metric can filter based on query params is in lib/metric/cart_adds.js. Display Customization Hummingbird comes with some stock widgets (Counter, Logger, Graph) that demonstrate how to hook into the data provided by the node.js server. For the minimum amount required to create a widget, see public/js/widgets/logger.js. A widget is an object whose prototype extends Hummingbird.Base and implements onMessage. Tips To run the UI locally but stream data from your production server, use the url http://localhost:8080/?ws_server=your-host.com&ws_port=12345 Contributors Michael Nutt michael@nuttnet.net Benny Wong benny@bwong.net mikecampo caphrim007 brianjriddle lbosque robertjwhitney Dan Thurman thinkroth markwillis82 ochronus dannyakakong xinbenlv License Hummingbird is licensed under the MIT License. (See LICENSE)"
3435,"Build sites fast from MarkdownFlatdoc Flatdoc is a small JavaScript file that fetches Markdown files and renders them as full pages. Essentially, it's the easiest way to make open source documentation from Readme files. No server-side components No build process needed Deployable via GitHub Pages Can fetch GitHub Readme files Gorgeous default theme (and it's responsive) Just create an HTML file and deploy! Current version: v0.9.0 Getting started Create a file based on the template, which has a bare DOM, link to the scripts, and a link to a theme. It will look something like this (not exact). For GitHub projects, simply place this file in your GitHub pages branch and you're all good to go. In short: just download this file and upload it somewhere. The main JS and CSS files are also available in npm and bower. Default theme template > Blank template > Via GitHub To fetch a Github Repository's readme file, use the Flatdoc.github fetcher. This will fetch the Readme file of the repository's default branch. You may also fetch another file other than the Readme file, just specify it as the 2nd parameter. After you've done this, you probably want to deploy it via GitHub Pages. GitHub Pages guide > Via a file You may also fetch a file. In this example, this fetches the file Readme.md in the same folder as the HTML file. You may actually supply any URL here. It will be fetched via AJAX. This is useful for local testing. How it works Flatdoc is a hosted .js file (along with a theme and its assets) that you can add into any page hosted anywhere. All client-side There are no build scripts or 3rd-party services involved. Everything is done in the browser. Worried about performance? Oh, It's pretty fast. Flatdoc utilizes the GitHub API to fetch your project's Readme files. You may also configure it to fetch any arbitrary URL via AJAX. Lightning-fast parsing Next, it uses marked, an extremely fast Markdown parser that has support for GitHub flavored Markdown. Flatdoc then simply renders menu and content DOM elements to your HTML document. Flatdoc also comes with a default theme to style your page for you, or you may opt to create your own styles. Markdown extras Flatdoc offers a few harmless, unobtrusive extras that come in handy in building documentation sites. Code highlighting You can use Markdown code fences to make syntax-highlighted text. Simply surround your text with three backticks. This works in GitHub as well. See GitHub Syntax Highlighting for more info. Blockquotes Blockquotes show up as side figures. This is useful for providing side information or non-code examples. Blockquotes are blocks that begin with >. Smart quotes Single quotes, double quotes, and double-hyphens are automatically replaced to their typographically-accurate equivalent. This, of course, does not apply to <code> and <pre> blocks to leave code alone. ""From a certain point onward there is no longer any turning back. That is the point that must be reached."" --Franz Kafka Buttons If your link text has a > at the end (for instance: Continue >), they show up as buttons. View in GitHub > Customizing Basic Theme options For the default theme (theme-white), You can set theme options by adding classes to the <body> element. The available options are: big-h3 Makes 3rd-level headings bigger. no-literate Disables ""literate"" mode, where code appears on the right and content text appear on the left. large-brief Makes the opening paragraph large. Adding more markup You have full control over the HTML file, just add markup wherever you see fit. As long as you leave role='flatdoc-content' and role='flatdoc-menu' empty as they are, you'll be fine. Here are some ideas to get you started. Add a CSS file to make your own CSS adjustments. Add a 'Tweet' button on top. Add Google Analytics. Use CSS to style the IDs in menus (#acknowledgements + p). JavaScript hooks Flatdoc emits the events flatdoc:loading and flatdoc:ready to help you make custom behavior when the document loads. Full customization You don't have to be restricted to the given theme. Flatdoc is just really one .js file that expects 2 HTML elements (for menu and content). Start with the blank template and customize as you see fit. Get blank template > Misc Inspirations The following projects have inspired Flatdoc. Backbone.js - Jeremy's projects have always adopted this ""one page documentation"" approach which I really love. Docco - Jeremy's Docco introduced me to the world of literate programming, and side-by-side documentation in general. Stripe - Flatdoc took inspiration on the look of their API documentation. DocumentUp - This service has the same idea but does a hosted readme parsing approach. Attributions Photo taken from Flickr, licensed under Creative Commons. Acknowledgements 2013, 2014, Rico Sta. Cruz. Released under the MIT License. Flatdoc is authored and maintained by Rico Sta. Cruz with help from its contributors. My website (ricostacruz.com) Github (@rstacruz) Twitter (@rstacruz)"
252,"This repo is used for servicing PR's for .NET Core 2.1 and 3.1. Please visit us at https://github.com/dotnet/runtimeGoing forward, the .NET team is using https://github.com/dotnet/runtime to develop the code and issues formerly in this repository. Please see the following for more context: dotnet/announcements#119 ""Consolidating .NET GitHub repos"""
3097,"Official Sketch Plugin directorySketch Plugin Directory A list of Sketch plugins hosted at GitHub, in alphabetical order. Note: if you want to add yours, just send a pull request, or use skpm to develop it (skpm takes care of publishing automatically). Once your plugin is added here, it will appear on the website as soon as we make a new deploy (that can take anywhere from a few minutes to a few days) 2o3t Tools, by Zyao89: Easy Tools, batch rename layers and artboards, etc. Above the Fold by Visualeyes, by VisualEyes: Mark your designs with a layer that indicates where is the Above the Fold portion. Abstract Notebooks, by Abstract: Seamlessly share designs to your Abstract Notebooks Abstract Versions, by Abstract: Abstract Versions is a file management and version control tool for Sketch files Add Colors to Palette, by johnmcclumpha: Quickly and easily add colors from the fills of selected layers in a Sketch file to the document palette. Add Trailing Space, by tgfjt: add trailing space into selected text layers Adeeapp Sketch Plugin, by AdeeApp.com: Design for all. The most comprehensive free accessibility testing tool for inclusive design! AEIconizer, by Marko Tadi: iOS icon generator plugin for Bohemian Coding Sketch app. AEUX, by Battle Axe: Transfer layer to After Effects Align To Padding, by Jonathan Tran: Align layers in a group with padding applied Android Res Export, by Ashung Hung: Export Android resouces in Sketch, include PNG assets, app icon, nine-patch image and vector drawable. Angle, by MengTo: Apply perspective transforms on screen mockups. Auto-detect screens by resolution and works on shapes and symbols. Super fast. AnimateMate, by Sakari Niittymaa: Create your animations directly in Sketch Annotations, by Baguette Engineering: Hide/show layer groups named 'Annotations'. Anto, by CanisMinor: Sketch Tools for AFX Designers areanow, by norman-woz: Get the total area of selected rectangle layers. Artboard History, by Jan Schneider: A Sketch plugin to switch faster between your latest artboards. Artboard Manager, by Ale Muoz: Because moving artboards manually is so 2016. Artboard Presets for Social Media Images, by herrhelms: This is a Plugin for Sketch App that adds artboard presets for the most common image dimensions of different social media platforms. Artboard Tricks, by Roman Nurik: Artboard Tricks plugin for Sketch Atlassian Vendor Sketch Plugin, by Atlassian Design: Design your next Atlassian app with our component libraries and suite of Sketch tools Attention Insight, by Attention Insight: Generate attention heatmaps and instantly know where users look when engaging with your designs Attention Prediction Plugin, by fixate-ai: Attention prediction - know what your users see as they view you design Auto Arrange Artboards, by Saurabh Singh: Automatically arrange the order of your artboards in the layer list according to their position on the canvas. Auto Layout, by Anima Team: Responsive design inside Sketch. Design for all screen sizes on one artboard. Auto PDF Exporter nSlicer, by KhY: A Sketch Plugin to auto-export all 'S' Prefix artboards to a single pdf. AutoFixiOSTextLineHeight, by youngxkk: Auto Fix iOS Text Line Height, so that the font restoration degree of iOS design draft reaches 100%. Automate Sketch, by Ashung Hung: Make Sketch more efficient. A lot of useful plugins in one. Avocode Sketch Plugin, by Avocode Inc.: Sync Sketch designs to Avocode. Awesome Ipsums, by Aurlien Grimaud: Generate ipsums from an external Google spreadsheet. Make these datas collaborative! Axure for Sketch, by Axure Software Solutions Inc.: Easily copy design elements to Axure RP or publish artboards directly to Axure Cloud. babelfish, by BilousAlexandr: babelfish plugin Banking Data, by Kent Yang: A DataSupplier plugin Base64 PNG Export, by james yang: sketch plugin for Export Data URI Baseline Offsetter, by Ozgur Gunes: Raise, lower, set or reset the baseline of multiple text layers with a single command. Batch Create Symbols, by Paul Demers: A plugin for Sketch to convert selected layers to individual symbols. betterTypePanel, by Kevin Gutowski: A sketch plugin to help manage common OpenType properties BillUI, by Carl Albertsson & Simon Takman: Interactive artificial evolutionary tool in order to help you come up with design suggestions that are similar to your initial design. Blender, by bunnieabc: A sketch plugin to create awesome gradient layers BlobMaker, by Federico Vitale: Generate blobs with ease Blush, by Blush Design, Inc.: Create and customize illustrations in your designs with Blush. Just choose a collection, pick a composition, and place it on the canvas. Bold It, by ysjn: Bold-it is a super simple plugin that bolds user-specified keyword in selected text layers. Bootstrap Helpers, by Konstantin Demblin: A plugin to help working with bootstrap grids and grids in general. It allows to create (Bootstrap) grids and align and de-/increase width of layers accordingly. Brandfetch, by Brandfetch: Pull brand assets into Sketch Brandfolder, by brandfolder: Easily use your digital assets from Brandfolder right within your favorite platform for digital design! BRData, by Jnathas Souza: Gerador de dados contextualizados com a realidade brasileira. Browser Preview, by Lukas Oppermann: Quickly preview an artboard in your browser. Case Converter, by zgr Gne: Convert text layers, symbols or all instances of a symbol. chart, by Pavel Kuligin: Create the most popular types of charts by real or random data Check Contrast, by Michael Le: Allows you to select layers in Sketch and get realtime feedback about the contrast ratio Chemfill, by Alexander Hadik: A Chemical Structure data supplier plugin. Chippen Charts, by Martin von Lupin: Bar chart creator for your mockups using random data. Change the size of selected rectangles. Works for both horizontal and vertical bar charts. Made with love in Chippendale. Chromata, by Vladimir Ionia: Find rogue colors Click Thru Prototype, by Mark Horgan: Generates a HTML click-through prototype of your responsive website design. Cloudinary Plugin, by Maya Shavin: Cloudinary plugin for Sketch projects Cluse, by Yana Gevorgyan: A Sketch plugin to check color contrast for web accessibility based on WCAG 2.0. Fitting seamlessly into your team's workflow, Cluse allows you to remotely change your design and see the updated WCAG score live. Coding Toolkit, by tankxu: A series of commands for CODING designers. Collapse All Artboards And Groups, by littlebusters: Collapse all artboards and groups in the current document. Color Blindless, by Youran You: Simulate design in different types of color vision deficiency Color Contrast Analyser, by Florian Schulz: A Sketch plugin that calculates the color contrast of two selected layers and evaluates it against the WCAG2.0. Color Copy Paste, by Sonny Lazuardi Hermawan: Color Variables Migrator, by Sketch: Migrate your Layers and Styles to use Color Variables Colormate, by The Main Ingredient: Colormate is a kickass sketch plugin that will help you figure out how in the hell you ended up with 457 different greys, instead of the 1 grey Mandy gave you in the handover. Oops :flushed: Colors Code, by Sugarcode: Export Colors as organized Stylesheets for Android, CSS, Less, SCSS, Sass, React, ReactNative, Stylus, PostCSS and CSS Crush. ColorVariablesExporter, by griffin-stewie: Export Color Variables for development Compo, by Roman Shamin: Makes it easier to work with interface components in Sketch Component8, by Groot Xu: Component8 stores 1000+ crafted components. Use them in Sketch by drag & drop. Connection Flow Arrows, by Farid Sabitov: Plugin for generating easy to use connection flow arrows in Sketch Context, by Afnizar Nur Ghifari: Count character, words, and paragraphs from a text layer easily inside Sketch! Context for Sketch, by @dannyow: Add to your document pins linking to prototypes, inspirations, examples or anything else on the web. Contrast, by Roman Nurik: A Sketch plugin to show a pass/fail type contrast report. CoolHue, by Webkul, Nitish Khagwal: Coolest handpicked Gradient Palette for super amazing stuff Copy Framer Code, by Giles Perry: A Sketch plugin that copies any selected layer to the clipboard as code that can be pasted straight into a Framer prototype. Copy Optimized SVG Code, by chenxsan: Sketch plugin to copy optimized svg code Copy Paste Position & Size, by Andre Jilderda: A Sketch plugin that lets you easily copy & paste width, height, x & y values from and to objects Copy Updater, by Li Zheng: A Sketch plugin that updates copy based on selected JSON copycat, by Ashar Setiawan: sketch plugin Cracker9 Sketch Plugin, by Cracker9: cracker9 codesnippet sketch plugin Crafttor, by Crafttor: Illustrations For Everyone Create New Styles, by Jonathan Tran: A Sketch plugin to create multiple layer styles or text styles Crowdin for Sketch, by Crowdin: Localize the UI before programming starts. Translate and preview any design with ease css to Shadow Style, by Oliver Pitsch: CSS box-shadow to Layer Style Converter Csv Mail Merge, by JD Wolk: A lightweight Sketch plugin for importing data from .csv files using ""{}"" text sections. Custom Zoom, by Alexander Kner: Zoom your document to a custom zoom level. Dad Jokes, by Dom Habersack: Replace your text with dad jokes. Dapollo, by Alipay Design: Design and Development Platform() Dark Side, by Recep Tiryaki: Design light and dark themes easily. Switch between themes. Export color assets for Xcode and Android Studio. DarkModeSystem, by BDiogo: Apply a Dark Theme to your Project Data From Clipboard, by Saint-loup: A DataSupplier plugin Datazier Lens, by Victor Enriquez: Inspect and sort your local font book DatesFromNow, by Leon Berenschot: Simple data plugin to fill dates from now Decimal Number Generator, by vaexperience: Generate anbd override text fields with decimal number values and custom character content Design System Validator, by Matthew Talebi: Check consistency of text layers. Design Systems, by Ashung Hung: Help you find out popular design systems and download official Sketch UI kit. Design Token Exporter, by Herkko Huttunen: Simple Design Token Exporter Design Tokens, by Andreas Koutsoukos: A Sketch plugin that exports design Tokens to JSON format. You can export colors, typography, icons and utilis. A must-have tool for design system project. Detach Out of Sync Text Styles, by Tijmen van Gurp: Detach all out of sync text styles from a chosen sketch library. Disconnector, by Nathan Crowther: Quickly disconnect all symbols from a selection Drafta, by Fragment: Export designs directly to Drafta Drake, by Sean Coker: Sketch app plugin for generating dummy Drake content such as photos and lyrics. Dribbble, by Dribbble Holdings Ltd.: Share your creative process directly to the Dribbble community from within Sketch. DuplicateLater, by Kevin Gutowski: Duplicate layers in the same direction after duplicating (like in Figma). Efficient Images Export, by BinLia: efficient images export for image sketch Elem Export, by Joey: This plugin will export all assets of the SELECTED layer Elevation Shadows, by Yiting Liu: A Sketch Plugin to apply consistent Elevation Shadows Emoji Autocomplete Sketch Plugin, by Zeplin: While editing Sketch text layers, type : followed by the first few letters to autocomplete emojis. Envato Elements, by envato: Envato Elements Sketch plugin makes it easy to import a select range of Web and Mobile UI Kits from Envato Elements! Excel Content Sync, by Wouter Bron: Export Flat Svgs, by Kevin Gutowski: Flatten text within SVGs on export. Export King Plugin, by hecflores: A Sketch Plugin that provides exporting for any scenario Export to Proto.io, by Proto.io: Give life to your Sketch designs! Export all or selected artboards to Proto.io screens, preserving layer positioning and hierarchy. By exporting to Proto.io you can link screens together, add interactions and animations. Fake News, by The Washington Post: Auto-populate Washington Post news content Fast Text Transfer, by Jesper Bentzen: Lightning fast copying, pasting and swapping text. File Cleaner, by Monzo: Keep your Sketch files immaculately clean and in order. Fill Updater, by Li Zheng: Fill shapes or symbols with content of selected artboards. Find And Replace, by Martin Steven. Maintained by Thierry Charbonnel: Sketch 3 plugin to do a simple find and replace on text within layers Find Dirty Styles, by Kevin Gutowski: A Sketch plugin to easily find layers that are out of sync with their shared styles. Fix Sketch Trackpad Speed, by Pravdomil: Speed up your scrolling across all artboards Flat Export, by Adam Thompson: Use this plugin to batch export layers to a single folder. Flow Exporter, by Roman Nurik: A Sketch plugin that exports prototype flows built with Sketch 49+ to HTML. Font Buddy, by Anima Team: Install missing fonts & free fonts directly from Sketch. Font Packer, by Big XiXi: A Sketch plugin to collect font files you used in your sketch file. FontFinder, by Tatsuya Uchida: Sketch Plugin to find and select font items in a current page Fontily, by partyka1: Sketch plugin for finding & replacing fonts for Sketch 3+ foodreau, by Max David: Data supplier plugin for populating designs with real food recipes. Format Symbol Names, by Giles Perry: A Sketch plugin to nicely format the names of all artboards or symbol masters on the current page FreeFlow, by Francesco Bertocci: Speed up common tasks and boost your productivity. Freeman Finchart Sketchplugin, by freeman990: Draw financial chart like candle-stick or line chart like a boss. Frontify Plugin, by Frontify: Connecting your brand and design worlds FS_StockSummaryFiller, by Freeman Sun: / Gallery, by Google LLC: Quickly upload and sync Sketch artboards to Gallery collections. Genus, by Kepler Lab: A sketch plugin for exporting prototype website (static html css) from your sketch designs Gifmock, by Gifmock: Gifmock helps you create high-quality GIFs from static images and mockups. Git Sketch Plugin, by Mathieu Dutour: A Git client generating pretty diffs built right into Sketch. Google Sheets Content Sync, by David Williames: Edit and collaborate on your content in Google Sheets, then sync in back to your sketch files. Gradient Matrix Generator, by CarlosCabo: Plugin that generates a matrix of gradient combinations from a selection of colors Gretel, by Suyeol Jeon: A Sketch plugin that flattens files after exporting. Grid Layer, by Jonathan Tran: Create columns or gutters as layers. Useful if you need a grid on a component level. GxDesignOps, by Gastn Milano: Sketch Plugin For GeneXus internal use Handy Menu, by Sergey Dmitriev: Gives quick access to your plugins through context menu Hatseflats for Sketch, by Kevin van Breemaat: An experiment to get some form of generative design into the UI wireframe design process. Helpify, by Lucky Fox Design: Plugin with simple actions: Generate random numbers helpweb, by caorukang: web html css image Homey, by Athom B.V.: Insert Homey App icons directly into your Sketch projects. Hubble Sketch Plugin, by inthepocket: A Sketch plugin to extract assets and primitives and send them to Hubble.app Iban Generator, by idix: Generate random International Bank Account Numbers (IBAN) IcanIcon, by Sugarcode: icanicon.io allows you to keep your icon libraries in sync with your Design System. Icondrop, by Iconscout: Get access to 300,000+ icons right into Sketch App Iconfont Webview, by Kerem Sevencan: New and easy way of using Icons in Sketch Iconify, by Vjacheslav Trushkin: Iconify integration. Import MDI, FontAwesome, Jam, EmojiOne and many other icons to Sketch document. Iconly V2.0.0, by Piqo design: 500+ Free icons for your next project in 5 styles (Light, Bold, Bulk, Two-tone, Broken) Icons Code, by Sugarcode: Export Icons as vector-perfect code components for Android, React, ReactNative, Angular, Vue, TTF, EPS, PDF, Custom components and more. ImageCodeExporter, by funfungo: A Plugin that export your sketch layer for code usage ImageOptim Sketch Plugin, by ImageOptim: ImageOptim plugin for the Sketch app Img Pal Gen, by Arth K. Gajjar: Generates Color Palette from Image Layer imgcook, by Taobao FED: A cook who can transform design to code Import SVG as Artboards, by mathieudutour: Import SVG files as Artboards. Import Colors, by Ashung: Import colors from swatches file to Sketch. Import Shadows, by Cozy: Import CSS shadows Indigo.Design, by Infragistics: Create, edit, and apply themes to your Indigo.Design UI Kit based designs and publish them as prototypes to the Indigo.Design cloud. Install Library Bundle, by Ale Muoz: Installs a bunch of shared Sketch Libraries at once, because life is too short for clicking links. Inter Letter Spacing, by Giliam Verheide: Sketch plugin that dynamically sets letter spacing of layers using the Inter font. Inter UI Character Spacing, by Michael Nissen: Package to correct the character spacing for the InterUI font in Sketch Isometry, by Max Konovalov: Create isometric projections from layers json Color Palette Importer, by Ziya Fenn: Create shared layer styles by importing JSON color palettes Justinmind Sketch, by Justinmind: You can export artboards, layers and pages youve made in Sketch to Justinmind and turn them into interactive shareable prototypes. Keygaroo, by I&CO: Keygaroo helps you learn keyboard shortcuts for the actions you use the most. Kitchen, by Ant-Design: Make your design work delicious Label Layers, by Jonathan Tran: A Sketch plugin that labels selected layers labelizer, by Maxime Peeters: Extract, replace and download labels from Sketch file. Last Updated Indicator, by Bram van Mensvoort: Mark your designs with a version indicator which automatically changes as you update. LaTeX Sketch Plugin, by heytitle: This plugin brings LaTeX functionalities to Sketch, and allows us to directly write mathematical formulas Launchpad, by Anima Team: Export your Sketch design into HTML website. Layer Renamer, by Leonard Pauli: Find or rename multiple layers at once using RegEx and flags in Sketch (v.45 tested) Layer Styles Manager, by Jaer Pollux: A fast and easy way to manage all your layer styles. No more hassle with long and complex style names, or renaming tons of styles because you misspelled a folder name. Layers to X, by Andrew S. Parnell: Quickly turn layers into groups, artboards, and symbols. lazyboards, by Adam Bruzon: Artboard tools to help you with tedious batch tasks. Library Replacer, by Sketch: Quickly replace instances of shared Symbols and Styles. Library Inventory, by Gurp, Tijmen van: List all symbols that a selected document is using from an external library Light Switch, by Samuel Berriman: Toggle between Light or Dark symbols and text/layer styles. Light/dark Switch, by Tudor Teisanu: Switch artboards' theme lippy, by Aby Nimbalkar: An interactive lorem ipsum generator plugin for Sketch Live Planet Sketch Datasupplier, by Craig Tuttle: Supply's real data from Live Planet's API to Sketch for testing designs Logo Fetcher, by Tobi Kremer: Place logos from either the Logos API (SVG format) or Clearbit API (PNG format) Lokalise Plugin, by Lokalise: Deliver multilingual assets faster and smarter. Share context with your linguists, get early feedback about each market and preview the design in all languages. Magic Aligner, by Hugo Lispector: Align objects by their centers of mass Magic Mirror, by James Tang: Perspective Transformation for Sketch Artboards Mail Merge, by Robert Clarke: Sketch plugin that allows you to duplicate a layer/artboard and replace text with CSV data. MarginSymbols, by griffin-stewie: Memsource Translation Plugin, by Memsource: Start translating at the design phase and reduce time to market with the Memsource Translation Plugin. Merge Duplicate Symbols, by oodesign: Merge symbols or styles, replacing all instances and keeping overrides. Mesh Gradients, by oodesign: Create awesome mesh gradients, right inside of Sketch. Metaball, by mheesakkers: A simple plugin to draw shapes based on inner and outer tangents between two circles. Method, by KikeSz: Tool to apply your methodology systems microwave, by arvinxx: ~ Miro Plugin for Sketch, by Miro: Add, share and discuss your Sketch artboards with the team in Miro. The plugin allow to sync the artboards with the boards in one click Mise En Place, by Carlos Madrigal: Mise En Place is a Sketch plug-in that helps you prep before you start cooking your designs. Mktgoo Data, by Oscar Otero: A data supplier plugin for copies, by marketgoo MockingBot, by MockingBot: MockingBot Sketch Plugin, Your sweet Sketch companion making your handoff process more efficient than ever Mockup, by ls.graphics: Perspective transformation plugin for devices mockups Move It, by Dawid Woniak: Sketch plugin that let's you move selected layers verticaly and horizontaly. Mugsy, by jan-patrick: Mupixa, by www.mupixa.com: Mupixa allows you to leverage the full potential of your prototypes by conducting usability research fast and effortlessly. Name My Color, by Carlos Flores: Give your colors unique names. Generates labels for the Color Name, Hexcode and changes the name of the selected layer. NeoPreview, by Alan Francis: A plugin to create HTML based preview and gallery straight from sketch artboards Nudge, Push, Shove., by Michael Fouquet: Change the big and small nudge settings right within Sketch. Plus, get access to an even bigger nudge setting. Nudged, by Kevin Woodhouse: A Sketch plugin to easily edit your nudge distance settings. Omnis Skeleton Generator, by taohsu: Generate skeleton/placeholder UI from the selected components Orbison, by ilikescience: A Sketch plugin for Bitly's product design system Organize Layers, by Eunice J. Son: A plugin that allows short key commands to move layers up, down and reverse positions Origami Export, by Facebook, Inc.: Copy/Paste from Sketch into Origami Studio. Overflow, by proto.io: Overflow is the worlds first user flow diagramming tool tailored for designers. It empowers designers to design, present and share beautiful user flow diagrams that tell a story. Overlay, by Overlay: Overlay transforms your Sketch symbols into clean and reusable code in ReactJS, Vue.js and Vanilla HTML. Overrides Manager, by Ozgur Gunes: A Sketch plugin which makes managing overrides easier. P5 Sketchplugin, by Jacopo Col: A plugin for using p5.js code inside Sketch Paddit, by Jonathan Tran: Inspired by Falkeyn's Modulizer, a Sketch plugin that adjusts a group's background to the content with padding. Page Export, by Charlie Chao: A simple Sketch plugin for exporting page(s). PaintCode Code Generator, by PixelCut: Convert your Sketch drawings into Swift or Objective-C Palette Cleanser, by Protean Studio: Get a full rundown of the colors you're using in your Sketch document. Paste Paddings, by simonlidesign: Allows you to copy the paddings of one element and apply them to another Paste to Fill, by tgfjt: Paste your image from clipboard, to fill layer. Perfect Type, by Raunak Trikha: PersianSupplier, by Hirad Arshadi: Sketch Plugin for supplying dynamic persian data. Photo Grid, by Giles Perry: A Sketch plugin that can size layers to common photo dimensions and scale them to fit in a row. Phrase Sketch Plugin, by Phrase: Sync your design content from Sketch with Phrase picasso, by huangwencun: Picasso58sketchsketch pickle, by billychasen: Pickle lets you get quick feedback on anything you design. By integrating research early in your design process, you'll be more confident in your final designs. PinIt, by Anthony Collurafici: A collection of Resizing Shortcuts. Pixel Perfect, by Mattias Eriksson: Plugin for Sketch for handling layout and sizing of layers automatically based on their names. Pixel Perfecter, by Jakub wiadek: Pixel Perfecter helps you find pixel imperfect layers in your documents. Pixelworm, by Pixelworm: Upload your artboards to Pixelworm with one click. Plant, by Plant: Version control for designers Plugin List, by griffin-stewie: Sketch Plugin that gives you list of plugins you enabled as several text formats. Plugin Reloader, by Wes Byrne: A simple plugin to reload another plugins Potrace, by Giles Perry: Convert bitmaps to vector graphics Primary Sync, by Primary: Sync your Sketch designs with Primary's user flows and design documents. Prism, by Lalo Mrtnz: Creates a beautiful artboard color palette with all your 'Document Colors' and their respective color label in a variety of formats. Prism2ColorVariables, by griffin-stewie: Migrate your Prism named color to Color Variables projecthuddle, by Andre Gagnon: Protopie for Sketch, by ProtoPie: Export your designs and add powerful interactionsconditional logic, text input, camera, voice, and more. Prototypes Invision Sketch, by mathieudutour: Translate your prototyping links back and forth between Sketch and Invision Puzzle Publisher, by Ingram Micro: Exports Sketch artboards into linked HTML files and publish it on external site using SFTP. Puzzle Tokens, by Ingram Micro: Sketch.app plugin to apply design tokens to Sketch layers Quest Ai, by Quest AI: Convert Sketch to live websites instantly. Export artboards of different sizes and Quest automatically creates responsive pages. Using Quest AIs no-code editor, you can add timeline-based actions, videos, music and animations to build rich and interactive experiences without writing any code. Build multi-page web sites, landing pages, demo modules, etc. Add custom fonts, input fields, button components, custom methods or libraries easily. One-click build delivers responsive experience across all devices. Analytics and CDN hosting are built-in - so your experience is ready for your audience instantly. QuickColor, by Cole Perkins: Sketch plugin that lets you quickly apply colors from the color palette to selected elements- QuickTextOverride, by Dmitri Bilyk: Use a key command to target the first text override of a symbol. Quopi, by Luke Finch: Fetches copy from the comments on your Abstract branch Random Sizing, by Long Zheng: Sketch plugin to randomly resize selected elements. Randomcolors, by Avadh: Sketch App Plugin For Applying Random Colors To A Selection Of Objects. Remove All Guides, by Vadim Mikhnov: Removes all the guides from selected artboards. Remove Fills and Borders, by Seb Jachec: Remove a layer's fills and borders in Sketch. Remove.bg, by Mathieu Dutour: Remove image background in a single click Rename It, by Rodrigo Soares: Keep your Sketch files organized, batch rename layers and artboards. Rename Layers Based On Textstyle, by Thomas Brasington: Renames text layers in the current page based on their text style name Rename Text Layers by Style, by Alexander Gerund: Rename all text layers based on the name of the text style assigned. Replace Images, by shakemno: Sketch 3 plugin to replace (as in update) existing images by name in a sketch document. represent., by Swipe Circus: Present your UX/UI Designs lightning fast on client's devices without leaving Sketch. Reselect, by Michael Fouquet: Reselect allows you to restore a previous selection or save selections for later use (even after you close the document). Reset Image Aspect Ratio, by Giles Perry: A Sketch plugin that resets the aspect ratio of selected images. Roller by Toybox, by Jono Kolnik: Roller is the first Linter for Designers. It works just like spell-check but within your Sketch files. Rough, by mathieudutour: Transform your shapes in a sketchy, scribbly, hand-drawn-like, style. Search Sketch, by Candy Tsai: Search Sketch searches text in any language Select 'n' Slice, by Kevin Tpfer: A Sketch plugin to create a slice around anything you've selected. Select Similar Layers, by Wessley Roche: A plugin that selects layers with similar attributes to those of the layer currently selected. Sequence Artboard Names, by Thomas Brasington: Simple sequencing of all artboards within a Sketch Document Set Line Height, by Florian Schulz: Plugin that allows you to set the line height of a text layer as a multiple of the font size. Set Min Max, by Jonathan Tran: This plugin will resize a layer by height or width to a base max or min value Shadows Utilities, by iarthstar: Plugin to copy paste shadows across layers Shared Styles Hierarchy, by Mathieu Dutour: Organize your shared styles using the layers list, create a hierarchy where children inherit properties from their parent. Sketch a Sketch, by Mathieu Dutour: Bringing the iconic knobs from the famous toy to Sketch. Sketch Action, by Khoa Pham: Spotlight in Sketch Sketch Align To Grid, by Pravdomil: Let's align selection to grid Sketch Artboard Notes, by Aby Nimbalkar: A minimal plugin to add notes to artboards in Sketch Sketch Auto Translate, by Friedrich Schultheiss: Plugin to translate Sketch files into via Google Translate. Sketch Cats, by pravdomil: Render layers in Sketch as various images of cats Sketch Chat, by Mathieu Dutour: A Sketch plugin to chat in Sketch Cloud files Sketch Color Manager, by hecflores: Sketch Plugin to manage all rogue colors in the sketch, along with other styling properties Sketch Copy Paste Layout Settings, by Francis: Copy layout settings from one artboard and paste into multiples artboards. Sketch Copy Text Only, by Cristian: Sketch plugin to copy only the text from selected artboard(s) or layer(s) Sketch Dark Mode, by Eduardo Gmez: Generate a dark mode version of any document, the right way. Sketch Data Faker, by paintedbicycle: A Sketch data plugin providing data for you mockups from Faker.js Sketch Data Populator, by precious design studio: A Sketch App plugin to populate your documents with meaningful data. Goodbye Lorem Ipsum. Hello JSON. Sketch DevTools, by skpm: See your plugin logs, inspect the state of Sketch documents, explore actions, and more Sketch Export Preferences, by Kevin Gutowski: Import and Save Sketch Export Preferences Sketch Find All Instances of Symbol, by Logan McAnsh: Find all instances of a symbol in Sketch Sketch Flow, by hite: Make Icon Slicing simple for app developers! Sketch Groupie, by Aparajita Fishman: Sketch plugin providing commands to align layers with their parent group Sketch Guides, by Pratik Shah: Quickly generate Guides for a selected element in Sketch Sketch Hyphenator, by Aleksander Golmakov: Sketch plugin that hyphenates text Sketch Icons, by AMoreaux: Import your icons, apply a color mask and create a dynamic icons library. Sketch Iconscope, by ziven27: Wrap the Icon with a square(4n) scope. Sketch Image Average Color, by Antonio J. Martinez: A plugin to save and use the average color of an image. Sketch Image Replaste, by Misha: A simple Sketch plugin for replacing images with your copied image of your clipboard. Sketch Ipsum, by Sketch: A DataSupplier plugin that fills your text layers with random Lorem Ipsum Sketch Isometric, by Sures Kumar: Generate Isometric views from Artboards and Rectangles. Sketch Layer Comps, by zgr Gne: A plugin which saves and applies layer states to create different compositions of current page. Sketch Library Unlinker, by Giles Perry: Unlink symbols linked to a specific library, or unlink symbols that have been deleted in their libraries. Sketch Map, by Akash Shetye: Get a bird's eye views of your prototype flows. Sketch Map Generator, by Eduardo Gmez Vsquez: Plugin to fill a layer with a map generated from a location (Powered by Google Maps) Sketch Material, by Siddhartha Gudipati: Sketch material is a sketch plugin that will help you generate complex material components like tables, chips, forms etc Sketch Measure, by utom: Make it a fun to create spec for developers and teammates! Automatically generating html page with one click, inspect all the design details including CSS Styles on it offline. Sketch Meaxure, by utom & jebbs: Make it a fun to create spec for developers and teammates Sketch Minimap, by Aby Nimbalkar: Navigate large pages with ease Sketch Notebook, by Marcos Vidal: Sketch Plugin to make documenting design easier. Sketch Palettes, by Andrew Fiorillo: Sketch plugin that lets you save and load colors in the color picker Sketch Pexels, by Pexels: A Pexels plugin for Sketch Sketch Pixel Cleanup, by Stackdevelopment: A plugin for Sketch to fix all of those partial pixels Sketch Plugin Manager , by Mel Ludowise: Keeping your Sketch plugins up to date with the power of Git. Sketch Plugin Snap to 8pt Grid, by Misha: A Sketch plugin which helps with snapping layer properties to the 8 point grid. Sketch QR Code, by Lerte Smith: A Plugin for generate SVG QR Code in Sketch app. Sketch Retain Text Color, by johnmcclumpha: Retain the original color of text layers when applying a Text Style. Sketch RTL, by Devin Mancuso: Automatically create RTL layouts of your designs with this plugin for Bohemian Coding's Sketch 3 Sketch Runner, by Sketch Runner: Speed up your Sketch workflow Sketch Search Everywhere, by : Search layer and select it, by matching textValue, name or ObjectID. Sketch Select, by Canis Minor: Make it much more convenient to select layers with similar attributes. Sketch Selective Upload, by Aby Nimbalkar: Exclude Artboards and Pages when uploading your Document to Sketch Cloud Sketch Show Bounding Boxes, by Pravdomil: Sketch plugin that shows bounding boxes of all layers Sketch Snap, by Charlie Chao: A Sketch plugin that lets you snap layers below, above, left of or right of selected layer to one of its edges. Sketch Split Shape, by kupe517: Sketch plugin to split up a rectangle evenly by a user generated value Sketch Style Master, by Aparajita Fishman: Sketch plugin for renaming shared styles Sketch Styler, by oodesign: Assigns styles automatically to all of your unstyled layers. Sketch Sync, by Sensive: Create a collaboration hub for your Sketch files. Sketch Times, by Luuk Lamers: A DataSupplier plugin to get Times Sketch Tinypng Compressor, by Alex D: A Plugin that compresses bitmap assets using TinyPNG API. This Plugin requires Sketch 3.8. Sketch To View, by kiranpuppala: Generate android views from sketch Sketch Topographic, by ziven27: Display Topographic Information Sketch Translation, by Hoai Nguyen: A Sketch plugin for easy multi-language design Sketch Variables, by murilo_campaner: Create text variables inside sketch to use file as template Sketch Wakatime, by WakaTime: A Plugin to update your WakaTime stats automatically from Sketch. Sketch Easing Gradients, by larsenwork: Supercharge your gradients in Sketch with no-linear color mix and custom color spaces Sketch Export to, by Marco Cardoso: Export an artboard layers to json or markdown Sketch Foundation, by Alan Languirand: Toggle layer visibility for all matching layer names on any artboard to create foundational layers like notes and guides more manageable. Sketch Ignore, by Ryan The: s Sketch json, by arvinxx: a plugin to transfer sketch JSON into sketch Object Sketch Kodika Plugin, by Kodika Team: Export your designs to Kodika.io No Code App Builder and create your iOS apps with Drag and Drop! Sketch Multi Lingual Plugin, by Sebastian Gtte: A plugin that allowes the user to switch between languages to visualize how the webpage or app will look in the given language. The text fragments can be loaded as csv file. Sketch Notes, by Daxit Agarwal: A Sketch plugin that lets you add notes that become part of your Artboard and can be exported to a PDF or other Sketch formats. Sketch Share, by Rob Flaherty: Sketch plugin that exports artboards and generates an HTML file linking to each one Sketch Table Builder, by Eric Kramp: Quickly and easily use a single symbol and a CSV to create a data table. Sketch Tailwind, by Jan D'Hollander: Export your design to a theme-file you can use in your Tailwind Css config. Sketch Webgl, by endswithak: SketchContentSync, by ContentSync: Sync sketch files with google docs. SketchTurbo, by Satori Maru: A plugin for Sketch that adjusts scroll speed on a canvas. Slazzer for Sketch, by Slazzer: Remove image background in just few seconds 100% automatic. Slint, by Johannes Nanninga: A linter for Sketch files Smart Truncate, by Ozgur Gunes: Truncates text in selected layers, symbol overrides or even all overrides of all instances of a symbol to given length. Smart Design Export, by 7revor: transform sketch to smart-design template Smartling, by Smartling: Plugin for Sketch that allows to translate and pseudo-localize designs using the Smartling platform. Sort Me, by Roman Shamin: Sort artboards and layers by name Sort Selected Layers, by Ludovic Loridan: A handy plugin to sort layers or artboards by Y or by X position. Specify (alpha), by Specify SAS: Export styles and assets to your Specify Libraries. Spelly, by Spelly Team: Spell checker by Spelly with auto-scanner, suggestions, and other powerful features Squash, by Logan McAnsh logan@mcan.sh (https://mcan.sh): Export and optimize images with Realmac Squash Sr Measure, by Erik Myers: A sketch plugin to export your designs as react applications. Quickly share design specs, css, and assets. Stark, by Stark Lab, Inc.: Ensure your design is accessible and high contrast for every type of color blindness. Stickers, by Roman Nurik: A Sketch plugin that lets you browse and quickly drag+drop stickers (specially tagged layers) in your Sketch Libraries. Storyboard Export, by Crank Software Inc.: Export Sketch based designs to be used within Crank Software's Storyboard Suite stuffing, by Ashung: A DataSupplier plugin which supplies chinese data. Style Inventory, by Florian Schulz: Generate a visual style sheet with all colors and text styles that you are using in Sketch. SVG Bem, by mLihs: A Plugin for SVG export to convert IDs to Classes, create BEM Styled Naming Based on Layers. Uses SVGO to compresse and Clean up SVGs, right when you export them. Based on the SVGO Compressor Plugin SVGO Compressor, by Sketch BV: A Plugin that compresses SVG assets using SVGO, right when you export them. This Plugin requires Sketch 3.8. svgToKeyshape, by Cyril Siman: Plugin used to convert SVG filter into CSS Swap Color Libraries, by Kevin Gutowski: Change all your colors in a document to point to a different library using the same color variable names. Swap It, by Shaina Hantsis: A sketch plugin to replace symbols across multiple artboards easily from libraries or a local document. Symbol and Artboard Organizer, by Myrronth: Organize your symbols and artboards. Symbol Browser, by Pratik Shah: A new way to browse your symbols. Make the most of your Design System by bringing symbols and UI Sticker sheet together. Symbol Finder, by afifkhaidir: Finder-like interface for browsing and inserting local symbols in Sketch Symbol Instance Locator, by Jason Burns: Locate all instances of a selected symbol or instance. Symbol Master Renamer, by Miguel Angel Narvaez: Simple plugin to rename and organizing the master symbols with '/'. Symbol Namer, by Giles Perry: A plugin to help you rename symbols. Save default values, use override text, and do powerful, pattern-based renaming. Symbol Organizer, by Jason Burns: Organize your symbols page and layer list, based on the symbol names. Symbol Override Padding, by Jonathan Tran: Add bottom padding to a symbol override Symbol States, by Ozgur Gunes: A Sketch plugin which saves overrides of a symbol instance as states to be applyable on another instance of that symbol later. Symbol Swapper, by Jason Burns: Swap the selected symbols and/or symbol instances to a master of the same name in a library. Symbol Insert, by Michael Le: Simple plugin to insert Sketch symbols Symbol Merger, by Jonathan Tran: A Sketch plugin that merges duplicate symbols Symbol Overlay Toggle, by uxcourt: A Sketch plug-in to seek specific style names in library-sourced symbols and toggle the styles. SymbolNameAutocomplete, by griffin-stewie: This plugin gives you autocompletion of symbol names when creating a symbol. SymbolNameSync, by griffin-stewie: This plugin gives you syncing names between Symbol masters and its instances. Symbols Manager, by Jaer Pollux: A fast and easy way to manage all your symbols. No more hassle with long and complex symbols name, or renaming tons of symbols because you misspelled a folder name. Sympli Handoff, by Sympli: Well prepared redlines, assets, components and specs for developer handoff Sympli Versions, by Sympli: Version control and collaboration for Sketch. Sync Text Layer Name, by Creatide: Sketch plugin to rename text layers based on their text box values. It will automatically update the Text Layer name as the text box values change. Sync with Library, by oodesign: Easily replace local symbols and layer & text styles with library ones. Table of Contents, by You-Wen Liang (Mark): Sketch plugin for generating table of contents for documentations Tabula Rasa, by Arthur Klepchukov: Add blank backgrounds to transparent artboards Text Styles Manager, by Jaer Pollux: A fast and easy way to manage all your Text Styles. No more hassle with long and complex names, or renaming tons of styles because you misspelled a folder name. Text to Styles, by Thomas Brasington: Generates Sketch type styles programmatically from Artboards Tiled for Sketch, by Tiled Inc.: Sync screens, hotspots, and feedback directly from Sketch to Tiled to create interactive microapps without code. Tin Drum, by VitskyDs: Tinty, by chewbecca: Sketch Plugin that lets you create tints and shades of any color as shared styles and document colors. Toggle Greyscale, by Kevin Gutowski: A Sketch plugin that adds a layer to your artboard so that you can preview your mocks in greyscale. Toggle Pixel Fitting, by KevinGutowski: A simple plugin to change your pixel fitting preference. Translate From JSON, by kbirgoren: A Sketch plugin lets you use variables for texts in your designs. Trim Artboard, by Jonathan Tran: A Sketch plugin to trim the bottom of an artboard Truncat, by Kevin Gutowski: A Sketch plugin to truncate text. Turkish Data, by zgr Gne: Turkish data supplier plugin. Twilio Ipsum, by Paste: A realistic fake data populator for Sketch. typex, by reinvanoyen: Highly configurable text styles to web (css, sass, html, json, ...) export plugin Typograph, by Dmitry Gerasimov: Typograph Sketch plugin and js-library Typographie Frenchy, by Saint-loup: Sketch plugin to automatically add typographic french conventions and non-breaking spaces UI House, by Jarek Ostrowski & David Diefenderfer: Import resources directly to Sketch, from the web. uiLogos, by vijay verma: Insert professionally designed dummy logos of companies. Units, by Dennis Ploeger: A Sketch plugin for working with print units (inch, cm, mm) in Sketch's pixel world. Unsplash, by Sketch BV: Unsplash Data Provider plugin, for Sketch 52+. Use Icon Fonts in Sketch, by Kerem Sevencan: Use icon fonts in sketch User Flows, by Aby Nimbalkar: Generate user walkthroughs from Artboards in Sketch. Vectary 3d, by Vectary: Place your Sketch design into a predefined 3D mockup or your custom 3D element. Set your desired perspective in 3D and place the result into the scene with one click. ViewController for Framer, by Andreas Wahlstrm: Multi step user flows in Framer.js Viewfinder Sketchplugin, by Ahmed Genaidy: Easy access anywhere in you project file VisualEyes, by Loceye: Your professional AI design assistant. VK Data, by VKCOM: Plugin for using data from your account at vk.com WeTransfer, by WeTransfer: Share artboards and pages via WeTransfer Whale Kit, by jingwhale: wireframr, by chewbecca: Sketch Plugin to change your high-fidelity screendesign to simple wireframes. WtDesign, by Yoshinori Kawasaki: Sketch plugin for Wantedly Design System Xd2sketch Converter, by XD2Sketch: Convert and import XD files in Sketch with one click. Zeplin, by Zeplin: Zeplin Sketch Plugin. zeroheight, by zeroheight: Document your design system using beautifully simple styleguides synced with Sketch and code Sketch SelectPlus, by Sabarinathan Masilamani: Helps you select different type of layers, specific Shapes like Rectangle, Ovals, Triangles, Lines, Arrows, Paths, etc. Pan, by arvinxx: Tieba Colorpool, by Shen,Yan: This is read color pool name plugin only for tieba UE & RD , by lanhuapp.com: Automatic generate specs, share assets, auto-sync Sketch Guides, by Pratik Shah: Quickly generate Guides for a selected element in Sketch Find and Replace Text, by Chris Wetterman: Find and replace text throughout your Sketch document Undraw.co Illustrations for Sketch, by Martin Galovic: A Lion, by Kevin Gutowski: Align your layers to a key layer. Xscape!, by Wooh: hi Sorted by last update (newest on top) Disconnector, by Nathan Crowther: Quickly disconnect all symbols from a selection LaTeX Sketch Plugin, by heytitle: This plugin brings LaTeX functionalities to Sketch, and allows us to directly write mathematical formulas Sketch DevTools, by skpm: See your plugin logs, inspect the state of Sketch documents, explore actions, and more Git Sketch Plugin, by Mathieu Dutour: A Git client generating pretty diffs built right into Sketch. QuickTextOverride, by Dmitri Bilyk: Use a key command to target the first text override of a symbol. Symbol Overlay Toggle, by uxcourt: A Sketch plug-in to seek specific style names in library-sourced symbols and toggle the styles. Cloudinary Plugin, by Maya Shavin: Cloudinary plugin for Sketch projects PersianSupplier, by Hirad Arshadi: Sketch Plugin for supplying dynamic persian data. Remove.bg, by Mathieu Dutour: Remove image background in a single click Colormate, by The Main Ingredient: Colormate is a kickass sketch plugin that will help you figure out how in the hell you ended up with 457 different greys, instead of the 1 grey Mandy gave you in the handover. Oops :flushed: Prototypes Invision Sketch, by mathieudutour: Translate your prototyping links back and forth between Sketch and Invision Sequence Artboard Names, by Thomas Brasington: Simple sequencing of all artboards within a Sketch Document Import SVG as Artboards, by mathieudutour: Import SVG files as Artboards. Automate Sketch, by Ashung Hung: Make Sketch more efficient. A lot of useful plugins in one. Find and Replace Text, by Chris Wetterman: Find and replace text throughout your Sketch document Install Library Bundle, by Ale Muoz: Installs a bunch of shared Sketch Libraries at once, because life is too short for clicking links. foodreau, by Max David: Data supplier plugin for populating designs with real food recipes. Artboard History, by Jan Schneider: A Sketch plugin to switch faster between your latest artboards. Sketch Material, by Siddhartha Gudipati: Sketch material is a sketch plugin that will help you generate complex material components like tables, chips, forms etc Turkish Data, by zgr Gne: Turkish data supplier plugin. Symbol States, by Ozgur Gunes: A Sketch plugin which saves overrides of a symbol instance as states to be applyable on another instance of that symbol later. Smart Truncate, by Ozgur Gunes: Truncates text in selected layers, symbol overrides or even all overrides of all instances of a symbol to given length. Sketch Layer Comps, by zgr Gne: A plugin which saves and applies layer states to create different compositions of current page. Case Converter, by zgr Gne: Convert text layers, symbols or all instances of a symbol. Baseline Offsetter, by Ozgur Gunes: Raise, lower, set or reset the baseline of multiple text layers with a single command. Flat Export, by Adam Thompson: Use this plugin to batch export layers to a single folder. Add Colors to Palette, by johnmcclumpha: Quickly and easily add colors from the fills of selected layers in a Sketch file to the document palette. areanow, by norman-woz: Get the total area of selected rectangle layers. Sketch Data Populator, by precious design studio: A Sketch App plugin to populate your documents with meaningful data. Goodbye Lorem Ipsum. Hello JSON. Chemfill, by Alexander Hadik: A Chemical Structure data supplier plugin. labelizer, by Maxime Peeters: Extract, replace and download labels from Sketch file. Atlassian Vendor Sketch Plugin, by Atlassian Design: Design your next Atlassian app with our component libraries and suite of Sketch tools Library Replacer, by Sketch: Quickly replace instances of shared Symbols and Styles. Sketch Library Unlinker, by Giles Perry: Unlink symbols linked to a specific library, or unlink symbols that have been deleted in their libraries. Mise En Place, by Carlos Madrigal: Mise En Place is a Sketch plug-in that helps you prep before you start cooking your designs. Iban Generator, by idix: Generate random International Bank Account Numbers (IBAN) Sketch a Sketch, by Mathieu Dutour: Bringing the iconic knobs from the famous toy to Sketch. Sketch Flow, by hite: Make Icon Slicing simple for app developers! Plugin Reloader, by Wes Byrne: A simple plugin to reload another plugins Shared Styles Hierarchy, by Mathieu Dutour: Organize your shared styles using the layers list, create a hierarchy where children inherit properties from their parent. Symbol Namer, by Giles Perry: A plugin to help you rename symbols. Save default values, use override text, and do powerful, pattern-based renaming. BillUI, by Carl Albertsson & Simon Takman: Interactive artificial evolutionary tool in order to help you come up with design suggestions that are similar to your initial design. Sketch Tailwind, by Jan D'Hollander: Export your design to a theme-file you can use in your Tailwind Css config. betterTypePanel, by Kevin Gutowski: A sketch plugin to help manage common OpenType properties stuffing, by Ashung: A DataSupplier plugin which supplies chinese data. Connection Flow Arrows, by Farid Sabitov: Plugin for generating easy to use connection flow arrows in Sketch File Cleaner, by Monzo: Keep your Sketch files immaculately clean and in order. Chippen Charts, by Martin von Lupin: Bar chart creator for your mockups using random data. Change the size of selected rectangles. Works for both horizontal and vertical bar charts. Made with love in Chippendale. Sketch Data Faker, by paintedbicycle: A Sketch data plugin providing data for you mockups from Faker.js Sketch Export to, by Marco Cardoso: Export an artboard layers to json or markdown Bold It, by ysjn: Bold-it is a super simple plugin that bolds user-specified keyword in selected text layers. lazyboards, by Adam Bruzon: Artboard tools to help you with tedious batch tasks. Hubble Sketch Plugin, by inthepocket: A Sketch plugin to extract assets and primitives and send them to Hubble.app Unsplash, by Sketch BV: Unsplash Data Provider plugin, for Sketch 52+. Elevation Shadows, by Yiting Liu: A Sketch Plugin to apply consistent Elevation Shadows Contrast, by Roman Nurik: A Sketch plugin to show a pass/fail type contrast report. Sketch Sync, by Sensive: Create a collaboration hub for your Sketch files. Text to Styles, by Thomas Brasington: Generates Sketch type styles programmatically from Artboards typex, by reinvanoyen: Highly configurable text styles to web (css, sass, html, json, ...) export plugin Logo Fetcher, by Tobi Kremer: Place logos from either the Logos API (SVG format) or Clearbit API (PNG format) Artboard Tricks, by Roman Nurik: Artboard Tricks plugin for Sketch Rename Layers Based On Textstyle, by Thomas Brasington: Renames text layers in the current page based on their text style name Lokalise Plugin, by Lokalise: Deliver multilingual assets faster and smarter. Share context with your linguists, get early feedback about each market and preview the design in all languages. Artboard Manager, by Ale Muoz: Because moving artboards manually is so 2016. Typographie Frenchy, by Saint-loup: Sketch plugin to automatically add typographic french conventions and non-breaking spaces Sketch Iconscope, by ziven27: Wrap the Icon with a square(4n) scope. Cracker9 Sketch Plugin, by Cracker9: cracker9 codesnippet sketch plugin Rename It, by Rodrigo Soares: Keep your Sketch files organized, batch rename layers and artboards. MarginSymbols, by griffin-stewie: SymbolNameSync, by griffin-stewie: This plugin gives you syncing names between Symbol masters and its instances. SVGO Compressor, by Sketch BV: A Plugin that compresses SVG assets using SVGO, right when you export them. This Plugin requires Sketch 3.8. Rough, by mathieudutour: Transform your shapes in a sketchy, scribbly, hand-drawn-like, style. Reset Image Aspect Ratio, by Giles Perry: A Sketch plugin that resets the aspect ratio of selected images. Stickers, by Roman Nurik: A Sketch plugin that lets you browse and quickly drag+drop stickers (specially tagged layers) in your Sketch Libraries. Photo Grid, by Giles Perry: A Sketch plugin that can size layers to common photo dimensions and scale them to fit in a row. Inter UI Character Spacing, by Michael Nissen: Package to correct the character spacing for the InterUI font in Sketch Browser Preview, by Lukas Oppermann: Quickly preview an artboard in your browser. Sketch Topographic, by ziven27: Display Topographic Information Flow Exporter, by Roman Nurik: A Sketch plugin that exports prototype flows built with Sketch 49+ to HTML. Crowdin for Sketch, by Crowdin: Localize the UI before programming starts. Translate and preview any design with ease Sketch Styler, by oodesign: Assigns styles automatically to all of your unstyled layers. Mesh Gradients, by oodesign: Create awesome mesh gradients, right inside of Sketch. Merge Duplicate Symbols, by oodesign: Merge symbols or styles, replacing all instances and keeping overrides. AEIconizer, by Marko Tadi: iOS icon generator plugin for Bohemian Coding Sketch app. Mktgoo Data, by Oscar Otero: A data supplier plugin for copies, by marketgoo Plugin List, by griffin-stewie: Sketch Plugin that gives you list of plugins you enabled as several text formats. Sketch Share, by Rob Flaherty: Sketch plugin that exports artboards and generates an HTML file linking to each one Sketch Map Generator, by Eduardo Gmez Vsquez: Plugin to fill a layer with a map generated from a location (Powered by Google Maps) Sketch Dark Mode, by Eduardo Gmez: Generate a dark mode version of any document, the right way. Iconfont Webview, by Kerem Sevencan: New and easy way of using Icons in Sketch Xscape!, by Wooh: hi Collapse All Artboards And Groups, by littlebusters: Collapse all artboards and groups in the current document. Copy Paste Position & Size, by Andre Jilderda: A Sketch plugin that lets you easily copy & paste width, height, x & y values from and to objects BlobMaker, by Federico Vitale: Generate blobs with ease DuplicateLater, by Kevin Gutowski: Duplicate layers in the same direction after duplicating (like in Figma). Layers to X, by Andrew S. Parnell: Quickly turn layers into groups, artboards, and symbols. Batch Create Symbols, by Paul Demers: A plugin for Sketch to convert selected layers to individual symbols. Perfect Type, by Raunak Trikha: wireframr, by chewbecca: Sketch Plugin to change your high-fidelity screendesign to simple wireframes. Library Inventory, by Gurp, Tijmen van: List all symbols that a selected document is using from an external library Colors Code, by Sugarcode: Export Colors as organized Stylesheets for Android, CSS, Less, SCSS, Sass, React, ReactNative, Stylus, PostCSS and CSS Crush. Icons Code, by Sugarcode: Export Icons as vector-perfect code components for Android, React, ReactNative, Angular, Vue, TTF, EPS, PDF, Custom components and more. Detach Out of Sync Text Styles, by Tijmen van Gurp: Detach all out of sync text styles from a chosen sketch library. Genus, by Kepler Lab: A sketch plugin for exporting prototype website (static html css) from your sketch designs Slint, by Johannes Nanninga: A linter for Sketch files Color Copy Paste, by Sonny Lazuardi Hermawan: Export Flat Svgs, by Kevin Gutowski: Flatten text within SVGs on export. Copy Framer Code, by Giles Perry: A Sketch plugin that copies any selected layer to the clipboard as code that can be pasted straight into a Framer prototype. Sync with Library, by oodesign: Easily replace local symbols and layer & text styles with library ones. Isometry, by Max Konovalov: Create isometric projections from layers Coding Toolkit, by tankxu: A series of commands for CODING designers. Sketch Foundation, by Alan Languirand: Toggle layer visibility for all matching layer names on any artboard to create foundational layers like notes and guides more manageable. Rename Text Layers by Style, by Alexander Gerund: Rename all text layers based on the name of the text style assigned. DarkModeSystem, by BDiogo: Apply a Dark Theme to your Project Sketch Ignore, by Ryan The: s Sketch Webgl, by endswithak: Toggle Pixel Fitting, by KevinGutowski: A simple plugin to change your pixel fitting preference. IcanIcon, by Sugarcode: icanicon.io allows you to keep your icon libraries in sync with your Design System. Sketch Plugin Snap to 8pt Grid, by Misha: A Sketch plugin which helps with snapping layer properties to the 8 point grid. Toggle Greyscale, by Kevin Gutowski: A Sketch plugin that adds a layer to your artboard so that you can preview your mocks in greyscale. Copy Optimized SVG Code, by chenxsan: Sketch plugin to copy optimized svg code DatesFromNow, by Leon Berenschot: Simple data plugin to fill dates from now Find Dirty Styles, by Kevin Gutowski: A Sketch plugin to easily find layers that are out of sync with their shared styles. Potrace, by Giles Perry: Convert bitmaps to vector graphics css to Shadow Style, by Oliver Pitsch: CSS box-shadow to Layer Style Converter Dark Side, by Recep Tiryaki: Design light and dark themes easily. Switch between themes. Export color assets for Xcode and Android Studio. copycat, by Ashar Setiawan: sketch plugin Sketch Export Preferences, by Kevin Gutowski: Import and Save Sketch Export Preferences Paste to Fill, by tgfjt: Paste your image from clipboard, to fill layer. Sketch Color Manager, by hecflores: Sketch Plugin to manage all rogue colors in the sketch, along with other styling properties Paste Paddings, by simonlidesign: Allows you to copy the paddings of one element and apply them to another Export King Plugin, by hecflores: A Sketch Plugin that provides exporting for any scenario Inter Letter Spacing, by Giliam Verheide: Sketch plugin that dynamically sets letter spacing of layers using the Inter font. Helpify, by Lucky Fox Design: Plugin with simple actions: Generate random numbers Tinty, by chewbecca: Sketch Plugin that lets you create tints and shades of any color as shared styles and document colors. Metaball, by mheesakkers: A simple plugin to draw shapes based on inner and outer tangents between two circles. Sketch Snap, by Charlie Chao: A Sketch plugin that lets you snap layers below, above, left of or right of selected layer to one of its edges. Sketch Chat, by Mathieu Dutour: A Sketch plugin to chat in Sketch Cloud files Light Switch, by Samuel Berriman: Toggle between Light or Dark symbols and text/layer styles. represent., by Swipe Circus: Present your UX/UI Designs lightning fast on client's devices without leaving Sketch. Puzzle Publisher, by Ingram Micro: Exports Sketch artboards into linked HTML files and publish it on external site using SFTP. FreeFlow, by Francesco Bertocci: Speed up common tasks and boost your productivity. FS_StockSummaryFiller, by Freeman Sun: / Sketch Pexels, by Pexels: A Pexels plugin for Sketch Symbol Finder, by afifkhaidir: Finder-like interface for browsing and inserting local symbols in Sketch Fill Updater, by Li Zheng: Fill shapes or symbols with content of selected artboards. Sketch Retain Text Color, by johnmcclumpha: Retain the original color of text layers when applying a Text Style. Awesome Ipsums, by Aurlien Grimaud: Generate ipsums from an external Google spreadsheet. Make these datas collaborative! Symbol Master Renamer, by Miguel Angel Narvaez: Simple plugin to rename and organizing the master symbols with '/'. projecthuddle, by Andre Gagnon: Gretel, by Suyeol Jeon: A Sketch plugin that flattens files after exporting. Truncat, by Kevin Gutowski: A Sketch plugin to truncate text. Organize Layers, by Eunice J. Son: A plugin that allows short key commands to move layers up, down and reverse positions Sketch Copy Text Only, by Cristian: Sketch plugin to copy only the text from selected artboard(s) or layer(s) Context, by Afnizar Nur Ghifari: Count character, words, and paragraphs from a text layer easily inside Sketch! Sketch Ipsum, by Sketch: A DataSupplier plugin that fills your text layers with random Lorem Ipsum Envato Elements, by envato: Envato Elements Sketch plugin makes it easy to import a select range of Web and Mobile UI Kits from Envato Elements! Mupixa, by www.mupixa.com: Mupixa allows you to leverage the full potential of your prototypes by conducting usability research fast and effortlessly. Design Token Exporter, by Herkko Huttunen: Simple Design Token Exporter Mugsy, by jan-patrick: SVG Bem, by mLihs: A Plugin for SVG export to convert IDs to Classes, create BEM Styled Naming Based on Layers. Uses SVGO to compresse and Clean up SVGs, right when you export them. Based on the SVGO Compressor Plugin Memsource Translation Plugin, by Memsource: Start translating at the design phase and reduce time to market with the Memsource Translation Plugin. Attention Prediction Plugin, by fixate-ai: Attention prediction - know what your users see as they view you design Overflow, by proto.io: Overflow is the worlds first user flow diagramming tool tailored for designers. It empowers designers to design, present and share beautiful user flow diagrams that tell a story. Slazzer for Sketch, by Slazzer: Remove image background in just few seconds 100% automatic. Select 'n' Slice, by Kevin Tpfer: A Sketch plugin to create a slice around anything you've selected. Spelly, by Spelly Team: Spell checker by Spelly with auto-scanner, suggestions, and other powerful features picasso, by huangwencun: Picasso58sketchsketch User Flows, by Aby Nimbalkar: Generate user walkthroughs from Artboards in Sketch. AEUX, by Battle Axe: Transfer layer to After Effects GxDesignOps, by Gastn Milano: Sketch Plugin For GeneXus internal use Copy Updater, by Li Zheng: A Sketch plugin that updates copy based on selected JSON imgcook, by Taobao FED: A cook who can transform design to code Units, by Dennis Ploeger: A Sketch plugin for working with print units (inch, cm, mm) in Sketch's pixel world. Add Trailing Space, by tgfjt: add trailing space into selected text layers Find And Replace, by Martin Steven. Maintained by Thierry Charbonnel: Sketch 3 plugin to do a simple find and replace on text within layers SketchTurbo, by Satori Maru: A plugin for Sketch that adjusts scroll speed on a canvas. Tiled for Sketch, by Tiled Inc.: Sync screens, hotspots, and feedback directly from Sketch to Tiled to create interactive microapps without code. Sketch Find All Instances of Symbol, by Logan McAnsh: Find all instances of a symbol in Sketch Import Colors, by Ashung: Import colors from swatches file to Sketch. Phrase Sketch Plugin, by Phrase: Sync your design content from Sketch with Phrase Color Blindless, by Youran You: Simulate design in different types of color vision deficiency Protopie for Sketch, by ProtoPie: Export your designs and add powerful interactionsconditional logic, text input, camera, voice, and more. Mockup, by ls.graphics: Perspective transformation plugin for devices mockups Sketch Hyphenator, by Aleksander Golmakov: Sketch plugin that hyphenates text Sketch Meaxure, by utom & jebbs: Make it a fun to create spec for developers and teammates Sketch Selective Upload, by Aby Nimbalkar: Exclude Artboards and Pages when uploading your Document to Sketch Cloud Annotations, by Baguette Engineering: Hide/show layer groups named 'Annotations'. Reselect, by Michael Fouquet: Reselect allows you to restore a previous selection or save selections for later use (even after you close the document). Nudge, Push, Shove., by Michael Fouquet: Change the big and small nudge settings right within Sketch. Plus, get access to an even bigger nudge setting. Smart Design Export, by 7revor: transform sketch to smart-design template Light/dark Switch, by Tudor Teisanu: Switch artboards' theme Banking Data, by Kent Yang: A DataSupplier plugin Sketch Times, by Luuk Lamers: A DataSupplier plugin to get Times Design Tokens, by Andreas Koutsoukos: A Sketch plugin that exports design Tokens to JSON format. You can export colors, typography, icons and utilis. A must-have tool for design system project. Dad Jokes, by Dom Habersack: Replace your text with dad jokes. Orbison, by ilikescience: A Sketch plugin for Bitly's product design system Puzzle Tokens, by Ingram Micro: Sketch.app plugin to apply design tokens to Sketch layers ImageCodeExporter, by funfungo: A Plugin that export your sketch layer for code usage Abstract Notebooks, by Abstract: Seamlessly share designs to your Abstract Notebooks Brandfolder, by brandfolder: Easily use your digital assets from Brandfolder right within your favorite platform for digital design! BRData, by Jnathas Souza: Gerador de dados contextualizados com a realidade brasileira. Datazier Lens, by Victor Enriquez: Inspect and sort your local font book Pixel Perfect, by Mattias Eriksson: Plugin for Sketch for handling layout and sizing of layers automatically based on their names. Zeplin, by Zeplin: Zeplin Sketch Plugin. Replace Images, by shakemno: Sketch 3 plugin to replace (as in update) existing images by name in a sketch document. Stark, by Stark Lab, Inc.: Ensure your design is accessible and high contrast for every type of color blindness. Attention Insight, by Attention Insight: Generate attention heatmaps and instantly know where users look when engaging with your designs Csv Mail Merge, by JD Wolk: A lightweight Sketch plugin for importing data from .csv files using ""{}"" text sections. svgToKeyshape, by Cyril Siman: Plugin used to convert SVG filter into CSS AnimateMate, by Sakari Niittymaa: Create your animations directly in Sketch Align To Padding, by Jonathan Tran: Align layers in a group with padding applied Create New Styles, by Jonathan Tran: A Sketch plugin to create multiple layer styles or text styles Grid Layer, by Jonathan Tran: Create columns or gutters as layers. Useful if you need a grid on a component level. Label Layers, by Jonathan Tran: A Sketch plugin that labels selected layers Trim Artboard, by Jonathan Tran: A Sketch plugin to trim the bottom of an artboard Set Min Max, by Jonathan Tran: This plugin will resize a layer by height or width to a base max or min value Paddit, by Jonathan Tran: Inspired by Falkeyn's Modulizer, a Sketch plugin that adjusts a group's background to the content with padding. Symbol Merger, by Jonathan Tran: A Sketch plugin that merges duplicate symbols Palette Cleanser, by Protean Studio: Get a full rundown of the colors you're using in your Sketch document. lippy, by Aby Nimbalkar: An interactive lorem ipsum generator plugin for Sketch Check Contrast, by Michael Le: Allows you to select layers in Sketch and get realtime feedback about the contrast ratio Symbol Insert, by Michael Le: Simple plugin to insert Sketch symbols Sketch QR Code, by Lerte Smith: A Plugin for generate SVG QR Code in Sketch app. Sketch Easing Gradients, by larsenwork: Supercharge your gradients in Sketch with no-linear color mix and custom color spaces Live Planet Sketch Datasupplier, by Craig Tuttle: Supply's real data from Live Planet's API to Sketch for testing designs Symbol Override Padding, by Jonathan Tran: Add bottom padding to a symbol override Frontify Plugin, by Frontify: Connecting your brand and design worlds Sketch Kodika Plugin, by Kodika Team: Export your designs to Kodika.io No Code App Builder and create your iOS apps with Drag and Drop! Use Icon Fonts in Sketch, by Kerem Sevencan: Use icon fonts in sketch Last Updated Indicator, by Bram van Mensvoort: Mark your designs with a version indicator which automatically changes as you update. Fake News, by The Washington Post: Auto-populate Washington Post news content Sketch Measure, by utom: Make it a fun to create spec for developers and teammates! Automatically generating html page with one click, inspect all the design details including CSS Styles on it offline. Symbol and Artboard Organizer, by Myrronth: Organize your symbols and artboards. Pan, by arvinxx: Sketch Copy Paste Layout Settings, by Francis: Copy layout settings from one artboard and paste into multiples artboards. Sort Selected Layers, by Ludovic Loridan: A handy plugin to sort layers or artboards by Y or by X position. Sketch Variables, by murilo_campaner: Create text variables inside sketch to use file as template Data From Clipboard, by Saint-loup: A DataSupplier plugin pickle, by billychasen: Pickle lets you get quick feedback on anything you design. By integrating research early in your design process, you'll be more confident in your final designs. Roller by Toybox, by Jono Kolnik: Roller is the first Linter for Designers. It works just like spell-check but within your Sketch files. Sketch Pixel Cleanup, by Stackdevelopment: A plugin for Sketch to fix all of those partial pixels Adeeapp Sketch Plugin, by AdeeApp.com: Design for all. The most comprehensive free accessibility testing tool for inclusive design! Sketch Auto Translate, by Friedrich Schultheiss: Plugin to translate Sketch files into via Google Translate. Sketch Multi Lingual Plugin, by Sebastian Gtte: A plugin that allowes the user to switch between languages to visualize how the webpage or app will look in the given language. The text fragments can be loaded as csv file. json Color Palette Importer, by Ziya Fenn: Create shared layer styles by importing JSON color palettes Icondrop, by Iconscout: Get access to 300,000+ icons right into Sketch App ColorVariablesExporter, by griffin-stewie: Export Color Variables for development Translate From JSON, by kbirgoren: A Sketch plugin lets you use variables for texts in your designs. Crafttor, by Crafttor: Illustrations For Everyone Remove All Guides, by Vadim Mikhnov: Removes all the guides from selected artboards. Prism2ColorVariables, by griffin-stewie: Migrate your Prism named color to Color Variables Iconify, by Vjacheslav Trushkin: Iconify integration. Import MDI, FontAwesome, Jam, EmojiOne and many other icons to Sketch document. Import Shadows, by Cozy: Import CSS shadows Auto Arrange Artboards, by Saurabh Singh: Automatically arrange the order of your artboards in the layer list according to their position on the canvas. Android Res Export, by Ashung Hung: Export Android resouces in Sketch, include PNG assets, app icon, nine-patch image and vector drawable. babelfish, by BilousAlexandr: babelfish plugin Quest Ai, by Quest AI: Convert Sketch to live websites instantly. Export artboards of different sizes and Quest automatically creates responsive pages. Using Quest AIs no-code editor, you can add timeline-based actions, videos, music and animations to build rich and interactive experiences without writing any code. Build multi-page web sites, landing pages, demo modules, etc. Add custom fonts, input fields, button components, custom methods or libraries easily. One-click build delivers responsive experience across all devices. Analytics and CDN hosting are built-in - so your experience is ready for your audience instantly. uiLogos, by vijay verma: Insert professionally designed dummy logos of companies. Sketch Split Shape, by kupe517: Sketch plugin to split up a rectangle evenly by a user generated value Drake, by Sean Coker: Sketch app plugin for generating dummy Drake content such as photos and lyrics. WeTransfer, by WeTransfer: Share artboards and pages via WeTransfer Shadows Utilities, by iarthstar: Plugin to copy paste shadows across layers SketchContentSync, by ContentSync: Sync sketch files with google docs. Base64 PNG Export, by james yang: sketch plugin for Export Data URI Gifmock, by Gifmock: Gifmock helps you create high-quality GIFs from static images and mockups. Drafta, by Fragment: Export designs directly to Drafta Artboard Presets for Social Media Images, by herrhelms: This is a Plugin for Sketch App that adds artboard presets for the most common image dimensions of different social media platforms. Miro Plugin for Sketch, by Miro: Add, share and discuss your Sketch artboards with the team in Miro. The plugin allow to sync the artboards with the boards in one click Color Variables Migrator, by Sketch: Migrate your Layers and Styles to use Color Variables Custom Zoom, by Alexander Kner: Zoom your document to a custom zoom level. Sketch Table Builder, by Eric Kramp: Quickly and easily use a single symbol and a CSV to create a data table. Swap Color Libraries, by Kevin Gutowski: Change all your colors in a document to point to a different library using the same color variable names. Omnis Skeleton Generator, by taohsu: Generate skeleton/placeholder UI from the selected components Homey, by Athom B.V.: Insert Homey App icons directly into your Sketch projects. Set Line Height, by Florian Schulz: Plugin that allows you to set the line height of a text layer as a multiple of the font size. Brandfetch, by Brandfetch: Pull brand assets into Sketch P5 Sketchplugin, by Jacopo Col: A plugin for using p5.js code inside Sketch Angle, by MengTo: Apply perspective transforms on screen mockups. Auto-detect screens by resolution and works on shapes and symbols. Super fast. WtDesign, by Yoshinori Kawasaki: Sketch plugin for Wantedly Design System Search Sketch, by Candy Tsai: Search Sketch searches text in any language Click Thru Prototype, by Mark Horgan: Generates a HTML click-through prototype of your responsive website design. Launchpad, by Anima Team: Export your Sketch design into HTML website. chart, by Pavel Kuligin: Create the most popular types of charts by real or random data Sketch json, by arvinxx: a plugin to transfer sketch JSON into sketch Object Chromata, by Vladimir Ionia: Find rogue colors Iconly V2.0.0, by Piqo design: 500+ Free icons for your next project in 5 styles (Light, Bold, Bulk, Two-tone, Broken) Sketch Style Master, by Aparajita Fishman: Sketch plugin for renaming shared styles Squash, by Logan McAnsh logan@mcan.sh (https://mcan.sh): Export and optimize images with Realmac Squash Sketch Groupie, by Aparajita Fishman: Sketch plugin providing commands to align layers with their parent group Randomcolors, by Avadh: Sketch App Plugin For Applying Random Colors To A Selection Of Objects. Magic Mirror, by James Tang: Perspective Transformation for Sketch Artboards QuickColor, by Cole Perkins: Sketch plugin that lets you quickly apply colors from the color palette to selected elements- Elem Export, by Joey: This plugin will export all assets of the SELECTED layer Sketch Notes, by Daxit Agarwal: A Sketch plugin that lets you add notes that become part of your Artboard and can be exported to a PDF or other Sketch formats. microwave, by arvinxx: ~ Select Similar Layers, by Wessley Roche: A plugin that selects layers with similar attributes to those of the layer currently selected. Typograph, by Dmitry Gerasimov: Typograph Sketch plugin and js-library Sketch Map, by Akash Shetye: Get a bird's eye views of your prototype flows. Overrides Manager, by Ozgur Gunes: A Sketch plugin which makes managing overrides easier. 2o3t Tools, by Zyao89: Easy Tools, batch rename layers and artboards, etc. Magic Aligner, by Hugo Lispector: Align objects by their centers of mass Random Sizing, by Long Zheng: Sketch plugin to randomly resize selected elements. Hatseflats for Sketch, by Kevin van Breemaat: An experiment to get some form of generative design into the UI wireframe design process. Tabula Rasa, by Arthur Klepchukov: Add blank backgrounds to transparent artboards Export to Proto.io, by Proto.io: Give life to your Sketch designs! Export all or selected artboards to Proto.io screens, preserving layer positioning and hierarchy. By exporting to Proto.io you can link screens together, add interactions and animations. Gradient Matrix Generator, by CarlosCabo: Plugin that generates a matrix of gradient combinations from a selection of colors Sketch Notebook, by Marcos Vidal: Sketch Plugin to make documenting design easier. Plant, by Plant: Version control for designers Avocode Sketch Plugin, by Avocode Inc.: Sync Sketch designs to Avocode. Sketch Runner, by Sketch Runner: Speed up your Sketch workflow zeroheight, by zeroheight: Document your design system using beautifully simple styleguides synced with Sketch and code Handy Menu, by Sergey Dmitriev: Gives quick access to your plugins through context menu , by lanhuapp.com: Automatic generate specs, share assets, auto-sync Blender, by bunnieabc: A sketch plugin to create awesome gradient layers Storyboard Export, by Crank Software Inc.: Export Sketch based designs to be used within Crank Software's Storyboard Suite Nudged, by Kevin Woodhouse: A Sketch plugin to easily edit your nudge distance settings. Abstract Versions, by Abstract: Abstract Versions is a file management and version control tool for Sketch files Remove Fills and Borders, by Seb Jachec: Remove a layer's fills and borders in Sketch. Sympli Versions, by Sympli: Version control and collaboration for Sketch. Cluse, by Yana Gevorgyan: A Sketch plugin to check color contrast for web accessibility based on WCAG 2.0. Fitting seamlessly into your team's workflow, Cluse allows you to remotely change your design and see the updated WCAG score live. FontFinder, by Tatsuya Uchida: Sketch Plugin to find and select font items in a current page VisualEyes, by Loceye: Your professional AI design assistant. Smartling, by Smartling: Plugin for Sketch that allows to translate and pseudo-localize designs using the Smartling platform. Sketch Search Everywhere, by : Search layer and select it, by matching textValue, name or ObjectID. Justinmind Sketch, by Justinmind: You can export artboards, layers and pages youve made in Sketch to Justinmind and turn them into interactive shareable prototypes. NeoPreview, by Alan Francis: A plugin to create HTML based preview and gallery straight from sketch artboards Font Packer, by Big XiXi: A Sketch plugin to collect font files you used in your sketch file. Sketch Image Average Color, by Antonio J. Martinez: A plugin to save and use the average color of an image. Sketch Icons, by AMoreaux: Import your icons, apply a color mask and create a dynamic icons library. A Lion, by Kevin Gutowski: Align your layers to a key layer. Prism, by Lalo Mrtnz: Creates a beautiful artboard color palette with all your 'Document Colors' and their respective color label in a variety of formats. Symbol Browser, by Pratik Shah: A new way to browse your symbols. Make the most of your Design System by bringing symbols and UI Sticker sheet together. Axure for Sketch, by Axure Software Solutions Inc.: Easily copy design elements to Axure RP or publish artboards directly to Axure Cloud. MockingBot, by MockingBot: MockingBot Sketch Plugin, Your sweet Sketch companion making your handoff process more efficient than ever Above the Fold by Visualeyes, by VisualEyes: Mark your designs with a layer that indicates where is the Above the Fold portion. Design Systems, by Ashung Hung: Help you find out popular design systems and download official Sketch UI kit. Whale Kit, by jingwhale: Primary Sync, by Primary: Sync your Sketch designs with Primary's user flows and design documents. Pixel Perfecter, by Jakub wiadek: Pixel Perfecter helps you find pixel imperfect layers in your documents. Symbol Organizer, by Jason Burns: Organize your symbols page and layer list, based on the symbol names. Symbol Swapper, by Jason Burns: Swap the selected symbols and/or symbol instances to a master of the same name in a library. Sketch Action, by Khoa Pham: Spotlight in Sketch Kitchen, by Ant-Design: Make your design work delicious Sympli Handoff, by Sympli: Well prepared redlines, assets, components and specs for developer handoff Dribbble, by Dribbble Holdings Ltd.: Share your creative process directly to the Dribbble community from within Sketch. UI House, by Jarek Ostrowski & David Diefenderfer: Import resources directly to Sketch, from the web. Origami Export, by Facebook, Inc.: Copy/Paste from Sketch into Origami Studio. Sketch Image Replaste, by Misha: A simple Sketch plugin for replacing images with your copied image of your clipboard. AutoFixiOSTextLineHeight, by youngxkk: Auto Fix iOS Text Line Height, so that the font restoration degree of iOS design draft reaches 100%. Swap It, by Shaina Hantsis: A sketch plugin to replace symbols across multiple artboards easily from libraries or a local document. Dapollo, by Alipay Design: Design and Development Platform() Specify (alpha), by Specify SAS: Export styles and assets to your Specify Libraries. Gallery, by Google LLC: Quickly upload and sync Sketch artboards to Gallery collections. Efficient Images Export, by BinLia: efficient images export for image sketch Sketch SelectPlus, by Sabarinathan Masilamani: Helps you select different type of layers, specific Shapes like Rectangle, Ovals, Triangles, Lines, Arrows, Paths, etc. Sketch Align To Grid, by Pravdomil: Let's align selection to grid Sketch Cats, by pravdomil: Render layers in Sketch as various images of cats Fix Sketch Trackpad Speed, by Pravdomil: Speed up your scrolling across all artboards Sketch Show Bounding Boxes, by Pravdomil: Sketch plugin that shows bounding boxes of all layers Sketch Guides, by Pratik Shah: Quickly generate Guides for a selected element in Sketch Sketch Guides, by Pratik Shah: Quickly generate Guides for a selected element in Sketch Context for Sketch, by @dannyow: Add to your document pins linking to prototypes, inspirations, examples or anything else on the web. Twilio Ipsum, by Paste: A realistic fake data populator for Sketch. Sketch Translation, by Hoai Nguyen: A Sketch plugin for easy multi-language design Format Symbol Names, by Giles Perry: A Sketch plugin to nicely format the names of all artboards or symbol masters on the current page Sketch Artboard Notes, by Aby Nimbalkar: A minimal plugin to add notes to artboards in Sketch Symbol Instance Locator, by Jason Burns: Locate all instances of a selected symbol or instance. Color Contrast Analyser, by Florian Schulz: A Sketch plugin that calculates the color contrast of two selected layers and evaluates it against the WCAG2.0. Auto PDF Exporter nSlicer, by KhY: A Sketch Plugin to auto-export all 'S' Prefix artboards to a single pdf. Google Sheets Content Sync, by David Williames: Edit and collaborate on your content in Google Sheets, then sync in back to your sketch files. CoolHue, by Webkul, Nitish Khagwal: Coolest handpicked Gradient Palette for super amazing stuff Layer Styles Manager, by Jaer Pollux: A fast and easy way to manage all your layer styles. No more hassle with long and complex style names, or renaming tons of styles because you misspelled a folder name. Text Styles Manager, by Jaer Pollux: A fast and easy way to manage all your Text Styles. No more hassle with long and complex names, or renaming tons of styles because you misspelled a folder name. Symbols Manager, by Jaer Pollux: A fast and easy way to manage all your symbols. No more hassle with long and complex symbols name, or renaming tons of symbols because you misspelled a folder name. Sr Measure, by Erik Myers: A sketch plugin to export your designs as react applications. Quickly share design specs, css, and assets. Viewfinder Sketchplugin, by Ahmed Genaidy: Easy access anywhere in you project file Name My Color, by Carlos Flores: Give your colors unique names. Generates labels for the Color Name, Hexcode and changes the name of the selected layer. Pixelworm, by Pixelworm: Upload your artboards to Pixelworm with one click. Vectary 3d, by Vectary: Place your Sketch design into a predefined 3D mockup or your custom 3D element. Set your desired perspective in 3D and place the result into the scene with one click. Xd2sketch Converter, by XD2Sketch: Convert and import XD files in Sketch with one click. Sketch RTL, by Devin Mancuso: Automatically create RTL layouts of your designs with this plugin for Bohemian Coding's Sketch 3 Decimal Number Generator, by vaexperience: Generate anbd override text fields with decimal number values and custom character content Undraw.co Illustrations for Sketch, by Martin Galovic: SymbolNameAutocomplete, by griffin-stewie: This plugin gives you autocompletion of symbol names when creating a symbol. VK Data, by VKCOM: Plugin for using data from your account at vk.com Sketch Minimap, by Aby Nimbalkar: Navigate large pages with ease Fontily, by partyka1: Sketch plugin for finding & replacing fonts for Sketch 3+ Mail Merge, by Robert Clarke: Sketch plugin that allows you to duplicate a layer/artboard and replace text with CSV data. PaintCode Code Generator, by PixelCut: Convert your Sketch drawings into Swift or Objective-C Sketch Wakatime, by WakaTime: A Plugin to update your WakaTime stats automatically from Sketch. Design System Validator, by Matthew Talebi: Check consistency of text layers. Bootstrap Helpers, by Konstantin Demblin: A plugin to help working with bootstrap grids and grids in general. It allows to create (Bootstrap) grids and align and de-/increase width of layers accordingly. Font Buddy, by Anima Team: Install missing fonts & free fonts directly from Sketch. Layer Renamer, by Leonard Pauli: Find or rename multiple layers at once using RegEx and flags in Sketch (v.45 tested) Tin Drum, by VitskyDs: Sketch Palettes, by Andrew Fiorillo: Sketch plugin that lets you save and load colors in the color picker Anto, by CanisMinor: Sketch Tools for AFX Designers Keygaroo, by I&CO: Keygaroo helps you learn keyboard shortcuts for the actions you use the most. Sketch Plugin Manager , by Mel Ludowise: Keeping your Sketch plugins up to date with the power of Git. Img Pal Gen, by Arth K. Gajjar: Generates Color Palette from Image Layer Page Export, by Charlie Chao: A simple Sketch plugin for exporting page(s). Sync Text Layer Name, by Creatide: Sketch plugin to rename text layers based on their text box values. It will automatically update the Text Layer name as the text box values change. Auto Layout, by Anima Team: Responsive design inside Sketch. Design for all screen sizes on one artboard. Table of Contents, by You-Wen Liang (Mark): Sketch plugin for generating table of contents for documentations Sketch To View, by kiranpuppala: Generate android views from sketch Excel Content Sync, by Wouter Bron: Fast Text Transfer, by Jesper Bentzen: Lightning fast copying, pasting and swapping text. Sketch Select, by Canis Minor: Make it much more convenient to select layers with similar attributes. Style Inventory, by Florian Schulz: Generate a visual style sheet with all colors and text styles that you are using in Sketch. Method, by KikeSz: Tool to apply your methodology systems Freeman Finchart Sketchplugin, by freeman990: Draw financial chart like candle-stick or line chart like a boss. Move It, by Dawid Woniak: Sketch plugin that let's you move selected layers verticaly and horizontaly. Quopi, by Luke Finch: Fetches copy from the comments on your Abstract branch Sketch Isometric, by Sures Kumar: Generate Isometric views from Artboards and Rectangles. PinIt, by Anthony Collurafici: A collection of Resizing Shortcuts. ViewController for Framer, by Andreas Wahlstrm: Multi step user flows in Framer.js ImageOptim Sketch Plugin, by ImageOptim: ImageOptim plugin for the Sketch app Emoji Autocomplete Sketch Plugin, by Zeplin: While editing Sketch text layers, type : followed by the first few letters to autocomplete emojis. Indigo.Design, by Infragistics: Create, edit, and apply themes to your Indigo.Design UI Kit based designs and publish them as prototypes to the Indigo.Design cloud. Compo, by Roman Shamin: Makes it easier to work with interface components in Sketch Sort Me, by Roman Shamin: Sort artboards and layers by name Sketch Tinypng Compressor, by Alex D: A Plugin that compresses bitmap assets using TinyPNG API. This Plugin requires Sketch 3.8."
4099,"Drag & drop hierarchical list with mouse and touch compatibility (jQuery plugin)Nestable PLEASE NOTE I cannot provide any support or guidance beyond this README. If this code helps you that's great but I have no plans to develop Nestable beyond this demo (it's not a final product and has limited functionality). I cannot reply to any requests for help. Drag & drop hierarchical list with mouse and touch compatibility (jQuery / Zepto plugin) Try Nestable Demo Nestable is an experimental example and not under active development. If it suits your requirements feel free to expand upon it! Usage Write your nested HTML lists like so: <div class=""dd""> <ol class=""dd-list""> <li class=""dd-item"" data-id=""1""> <div class=""dd-handle"">Item 1</div> </li> <li class=""dd-item"" data-id=""2""> <div class=""dd-handle"">Item 2</div> </li> <li class=""dd-item"" data-id=""3""> <div class=""dd-handle"">Item 3</div> <ol class=""dd-list""> <li class=""dd-item"" data-id=""4""> <div class=""dd-handle"">Item 4</div> </li> <li class=""dd-item"" data-id=""5""> <div class=""dd-handle"">Item 5</div> </li> </ol> </li> </ol> </div> Then activate with jQuery like so: $('.dd').nestable({ /* config options */ }); Events The change event is fired when items are reordered. $('.dd').on('change', function() { /* on change event */ }); Methods You can get a serialised object with all data-* attributes for each item. $('.dd').nestable('serialize'); The serialised JSON for the example above would be: [{""id"":1},{""id"":2},{""id"":3,""children"":[{""id"":4},{""id"":5}]}] Configuration You can change the follow options: maxDepth number of levels an item can be nested (default 5) group group ID to allow dragging between lists (default 0) These advanced config options are also available: listNodeName The HTML element to create for lists (default 'ol') itemNodeName The HTML element to create for list items (default 'li') rootClass The class of the root element .nestable() was used on (default 'dd') listClass The class of all list elements (default 'dd-list') itemClass The class of all list item elements (default 'dd-item') dragClass The class applied to the list element that is being dragged (default 'dd-dragel') handleClass The class of the content element inside each list item (default 'dd-handle') collapsedClass The class applied to lists that have been collapsed (default 'dd-collapsed') placeClass The class of the placeholder element (default 'dd-placeholder') emptyClass The class used for empty list placeholder elements (default 'dd-empty') expandBtnHTML The HTML text used to generate a list item expand button (default '<button data-action=""expand"">Expand></button>') collapseBtnHTML The HTML text used to generate a list item collapse button (default '<button data-action=""collapse"">Collapse</button>') Inspect the Nestable Demo for guidance. Change Log 15th October 2012 Merge for Zepto.js support Merge fix for remove/detach items 27th June 2012 Added maxDepth option (default to 5) Added empty placeholder Updated CSS class structure with options for listClass and itemClass. Fixed to allow drag and drop between multiple Nestable instances (off by default). Added group option to enabled the above. Author: David Bushell http://dbushell.com @dbushell Copyright 2012 David Bushell | BSD & MIT license"
3233,"JSONExport is a desktop application for Mac OS X which enables you to export JSON objects as model classes with their associated constructors, utility methods, setters and getters in your favorite language.JSONExport JSONExport is a desktop application for Mac OS X written in Swift. Using JSONExport you will be able to: * Convert any valid JSON object to a class of one of the currently supported languages. * Preview the generated content before saving it. * Include constructors only, utility methods only, both or none. * Change the root class name. * Set a class name prefix for the generated classes. * Set package name for Java files. Generated Files Each generated file, besid the getters and setters (for Java) can include: * A constructor wich accepts an instance of NSDictionary, JSON, JSONObject instance depending on the file language, and the class will use this object to fill its properties data. * A utility method which converts the class data into a dictionary again. Currently supported languages Currently you can convert your JSON object to one of the following languages: Java for Android. Java for Realm Android. GSON for Android Swift Classes. Swift Classes for SwiftyJSON library. Swift Classes for Realm. Swift - CoreData. Swift Structures. Swift Structures for Gloss Swift Mappable Classes for (Swift 3) ObjectMapper Swift Structures for Unbox Objective-C - iOS. Objective-C - MAC. Objective-C - CoreData. Objective-C for Realm iOS. Screenshot shows JSONExport used for a snippet from Twitter timeline JSON and converting it to Swift-CoreData. Installation Kindly clone the project, and build it using xCode 8 and above. To Do ~~Support Objective-C~~ Done ~~Sync multible classes with the same name or have the same exact properties~~ Done ~~Support to parse JSON arrays of objects~~ Done Load JSON data from web ~~Open .json files from JSONExport~~ Supported languages management editor. Beside raw JSON, load the model raw data from plist files as well. Known Limitations: When exporting to subclasses of NSManagedObject, some data types can not be exported. For example core data does not have data type for ""array of strings""; in turn, if your JSON contains an array of strings, the exported file will not compile without you fixing the type mismatch. When exporting subclasses of RLMObject, you will have to enter the default values of premitive types manually. This is because of dynamic properties limition that prevents you from having an optional premitive type. When exporting to CoreData or Realm and you want to use the utility methods, you will need to manually watch for deep relation cycle calls; that is, when you convert an object to dictionary, this object try to convert one of its relation to a dictionary and the relation tries to convert the original object to a dictionary, that will cause a kind of cycle where each object involved calls the other object's toDictionary method infenitly... Avoid attempt to model a JSON object with empty values, because JSONExport does not understand empty values and can not guess their types. Deep nesting of arrays and objects will not be exported in a proper model files. Final Note The application still in its early stage. Please report any issue so I can improve it. License JSONExport is available under custom version of MIT license."
1212,"Android Library to build a UI CardCard Library Travis master: Travis dev: Card Library provides an easy way to display a UI Card using the Official Google CardView in your Android app. Before using this library I recommend that you check out the new Google Material Guidelines.Don't over cardify your UI. Examples Sample application: The demo is a showcase of the functionality of the library. Extras application: The demo-extras contains some examples of integration with other libraries Support Join the Google+ Community: a place to discuss the library, share screenshots, ask for tips, talk with the author.... If you would like, you can support my work, donating through the demo app. Doc See the Card Library Guide to know all card library features and all customizations. The Guide provides an extensive doc, with all tips and full examples. Don't miss it. Setup Card Library is pushed to Maven Central as an AAR, so you just need to add the following dependency to your build.gradle. dependencies { //Core compile 'com.github.gabrielemariotti.cards:cardslib-core:2.1.0' //Optional for built-in cards compile 'com.github.gabrielemariotti.cards:cardslib-cards:2.1.0' //Optional for RecyclerView compile 'com.github.gabrielemariotti.cards:cardslib-recyclerview:2.1.0' //Optional for staggered grid view compile 'com.github.gabrielemariotti.cards:cardslib-extra-staggeredgrid:2.1.0' //Optional for drag and drop compile 'com.github.gabrielemariotti.cards:cardslib-extra-dragdrop:2.1.0' //Optional for twoway (coming soon) //compile 'com.github.gabrielemariotti.cards:cardslib-extra-twoway:2.1.0' } If you would like to use the last v1 stable version you can use: dependencies { //Core card library compile 'com.github.gabrielemariotti.cards:library:1.9.1' //Extra card library, it is required only if you want to use integrations with other libraries compile 'com.github.gabrielemariotti.cards:library-extra:1.9.1' } ChangeLog Changelog: A complete changelog Acknowledgements Thanks to Roman Nurik for Android-SwipeToDismiss classes and UndoBarController classes. Thanks to Niek Haarman for some ideas and code taken from his ListViewAnimations. Thanks to Chris Banes for ForegroundLinearLayout class (See this post for more info). Thanks to Taylor Ling for drag and drop icon. Thanks to Frankie Sardo for some ideas and code taken from his LinearListView Thanks to Google for code and idea from Google IO 14 Credits Author: Gabriele Mariotti (gabri.mariotti@gmail.com) License Copyright 2013-2014 Gabriele Mariotti Licensed under the Apache License, Version 2.0 (the ""License""); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License. Google and the Google Maps logo are registered trademarks of Google Inc., used with permission."
61,"The 1.x line is frozen - features and bugfixes now happen on https://github.com/yarnpkg/berry Fast, reliable, and secure dependency management. Fast: Yarn caches every package it has downloaded, so it never needs to download the same package again. It also does almost everything concurrently to maximize resource utilization. This means even faster installs. Reliable: Using a detailed but concise lockfile format and a deterministic algorithm for install operations, Yarn is able to guarantee that any installation that works on one system will work exactly the same on another system. Secure: Yarn uses checksums to verify the integrity of every installed package before its code is executed. Features Offline Mode. If you've installed a package before,thenyou can install it again withoutaninternet connection. Deterministic. The same dependencies will be installed in the same exact way on any machine, regardless ofinstallationorder. Network Performance. Yarn efficiently queuesrequests andavoids request waterfalls in order to maximize network utilization. Network Resilience. A single request that fails will not cause the entire installation to fail. Requests are automatically retried upon failure. Flat Mode. Yarn resolves mismatched versions of dependencies to a single version to avoid creating duplicates. More emojis. Installing Yarn Read the Installation Guide on our website for detailed instructions on how to install Yarn. Using Yarn Read the Usage Guide on our website for detailed instructions on how to use Yarn. Contributing to Yarn Contributions are always welcome, no matter how large or small. Substantial feature requests should be proposed as an RFC. Before contributing, please read the code of conduct. See Contributing. Prior art Yarn wouldn't exist if it wasn't for excellent prior art. Yarn has been inspired by the following projects: Bundler Cargo npm Credits Thanks to Sam Holmes for donating the npm package name!"
240,"The Ruby Programming Language [mirror]What's Ruby Ruby is an interpreted object-oriented programming language often used for web development. It also offers many scripting features to process plain text and serialized files, or manage system tasks. It is simple, straightforward, and extensible. Features of Ruby Simple Syntax Normal Object-oriented Features (e.g. class, method calls) Advanced Object-oriented Features (e.g. mix-in, singleton-method) Operator Overloading Exception Handling Iterators and Closures Garbage Collection Dynamic Loading of Object Files (on some architectures) Highly Portable (works on many Unix-like/POSIX compatible platforms as well as Windows, macOS, etc.) cf. https://github.com/ruby/ruby/blob/master/doc/contributing.rdoc#label-Platform+Maintainers How to get Ruby For a complete list of ways to install Ruby, including using third-party tools like rvm, see: https://www.ruby-lang.org/en/downloads/ Git The mirror of the Ruby source tree can be checked out with the following command: $ git clone https://github.com/ruby/ruby.git There are some other branches under development. Try the following command to see the list of branches: $ git ls-remote https://github.com/ruby/ruby.git You may also want to use https://git.ruby-lang.org/ruby.git (actual master of Ruby source) if you are a committer. Subversion Stable branches for older Ruby versions can be checked out with also the following command: $ svn co https://svn.ruby-lang.org/repos/ruby/branches/ruby_2_6/ ruby Try the following command to see the list of branches: $ svn ls https://svn.ruby-lang.org/repos/ruby/branches/ Ruby home page https://www.ruby-lang.org/ Mailing list There is a mailing list to discuss Ruby. To subscribe to this list, please send the following phrase: subscribe in the mail body (not subject) to the address ruby-talk-request@ruby-lang.org. How to compile and install If you want to use Microsoft Visual C++ to compile Ruby, read win32/README.win32 instead of this document. Run ./autogen.sh to generate configure, when you build the source checked out from the Git repository. Run ./configure, which will generate config.h and Makefile. Some C compiler flags may be added by default depending on your environment. Specify optflags=.. and warnflags=.. as necessary to override them. Edit include/ruby/defines.h if you need. Usually this step will not be needed. Optional: Remove comment mark(#) before the module names from ext/Setup. This step is only necessary if you want to link modules statically. If you don't want to compile dynamic extensions (probably on architectures which do not allow dynamic loading), remove comment mark from the line ""#option nodynamic"" in ext/Setup. Usually this step will not be needed. Run make. On Mac, set RUBY_CODESIGN environment variable with a signing identity. It uses the identity to sign ruby binary. See also codesign(1). Optionally, run 'make check' to check whether the compiled Ruby interpreter works well. If you see the message ""check succeeded"", your Ruby works as it should (hopefully). Run 'make install'. This command will create the following directories and install files into them. ${DESTDIR}${prefix}/bin ${DESTDIR}${prefix}/include/ruby-${MAJOR}.${MINOR}.${TEENY} ${DESTDIR}${prefix}/include/ruby-${MAJOR}.${MINOR}.${TEENY}/${PLATFORM} ${DESTDIR}${prefix}/lib ${DESTDIR}${prefix}/lib/ruby ${DESTDIR}${prefix}/lib/ruby/${MAJOR}.${MINOR}.${TEENY} ${DESTDIR}${prefix}/lib/ruby/${MAJOR}.${MINOR}.${TEENY}/${PLATFORM} ${DESTDIR}${prefix}/lib/ruby/site_ruby ${DESTDIR}${prefix}/lib/ruby/site_ruby/${MAJOR}.${MINOR}.${TEENY} ${DESTDIR}${prefix}/lib/ruby/site_ruby/${MAJOR}.${MINOR}.${TEENY}/${PLATFORM} ${DESTDIR}${prefix}/lib/ruby/vendor_ruby ${DESTDIR}${prefix}/lib/ruby/vendor_ruby/${MAJOR}.${MINOR}.${TEENY} ${DESTDIR}${prefix}/lib/ruby/vendor_ruby/${MAJOR}.${MINOR}.${TEENY}/${PLATFORM} ${DESTDIR}${prefix}/lib/ruby/gems/${MAJOR}.${MINOR}.${TEENY} ${DESTDIR}${prefix}/share/man/man1 ${DESTDIR}${prefix}/share/ri/${MAJOR}.${MINOR}.${TEENY}/system If Ruby's API version is 'x.y.z', the ${MAJOR} is 'x', the ${MINOR} is 'y', and the ${TEENY} is 'z'. NOTE: teeny of the API version may be different from one of Ruby's program version You may have to be a super user to install Ruby. If you fail to compile Ruby, please send the detailed error report with the error log and machine/OS type, to help others. Some extension libraries may not get compiled because of lack of necessary external libraries and/or headers, then you will need to run 'make distclean-ext' to remove old configuration after installing them in such case. Copying See the file COPYING. Feedback Questions about the Ruby language can be asked on the Ruby-Talk mailing list (https://www.ruby-lang.org/en/community/mailing-lists) or on websites like (https://stackoverflow.com). Bugs should be reported at https://bugs.ruby-lang.org. Read HowToReport for more information. Contributing See the file CONTRIBUTING.md The Author Ruby was originally designed and developed by Yukihiro Matsumoto (Matz) in 1995. matz@ruby-lang.org"
4098,"PHP Regular expressions made easyPHPVerbalExpressions ported from VerbalExpressions VerbalExpressions is a PHP library that helps to construct hard regular expressions. Installation The project supports Composer so you have to install Composer first, before project setup. Examples More examples are available in the following files: Example.php VerbalExpressionsTest.php Business readable language expression definition Methods list Name|Description|Usage :---|:---|:--- add| add values to the expression| add('abc') startOfLine| mark expression with ^| startOfLine(false) endOfLine| mark the expression with $|endOfLine() then|add a string to the expression| add('foo') find| alias for then| find('foo') maybe| define a string that might appear once or not| maybe('.com') anything| accept any string| anything() anythingBut| accept any string but the specified char| anythingBut(',') something| accept any non-empty string| something() somethingBut| anything non-empty except for these chars| somethingBut('a') replace| shorthand for preg_replace()| replace($source, $val) lineBreak| match \r \n|lineBreak() br|shorthand for lineBreak| br() tab|match tabs \t |tab() word|match \w+|word() anyOf| any of the listed chars| anyOf('abc') any| shorthand for anyOf| any('abc') range| adds a range to the expression|range(a,z,0,9) withAnyCase| match case default case sensitive|withAnyCase() stopAtFirst|toggles the g modifiers|stopAtFirst() addModifier| add a modifier|addModifier('g') removeModifier| remove a mofier|removeModifier('g') searchOneLine| Toggles m modifier|searchOneLine() multiple|adds the multiple modifier| multiple('*') _or|wraps the expression in an or with the provided value|_or('bar') limit|adds char limit|limit(1,3) test| performs a preg_match| test('valid@email.com') For all the above method (except test) you could use the VerbalExpressionsScenario. Other Implementations You can see an up to date list of all ports on VerbalExpressions.github.io. - Javascript - Ruby - C# - Python - Java - C++ Building the project and running the tests The project supports Composer so you have to install Composer first before project setup. curl -sS https://getcomposer.org/installer | php php composer.phar install --dev ln -s vendor/phpunit/phpunit/phpunit.php phpunit ./phpunit"
718,":snowman: Possibly the smallest compiler everWelcome to The Super Tiny Compiler! This is an ultra-simplified example of all the major pieces of a modern compiler written in easy to read JavaScript. Reading through the guided code will help you learn about how most compilers work from end to end. Want to jump into the code? Click here You can also check it out on Glitch Why should I care? That's fair, most people don't really have to think about compilers in their day jobs. However, compilers are all around you, tons of the tools you use are based on concepts borrowed from compilers. But compilers are scary! Yes, they are. But that's our fault (the people who write compilers), we've taken something that is reasonably straightforward and made it so scary that most think of it as this totally unapproachable thing that only the nerdiest of the nerds are able to understand. Okay so where do I begin? Awesome! Head on over to the the-super-tiny-compiler.js file. I'm back, that didn't make sense Ouch, I'm really sorry. Let me know how it can be improved. Tests Run with node test.js"
4800,"Simple Regex LanguageSimple Regex Language We all know Regular Expressions are hard to read. Once written you're happy if you never ever have to touch this line of code again because you're going to have a hard time understanding what you've written there. Before we get started, a short note on how to use SRL: You can either use this project directly, or, if you're not into PHP or including a library like that, you can build your query online and use the generated Regular Expression elsewhere: https://simple-regex.com/build An Example Regular Expressions don't have to be bulky? - No, they don't! Just have a look at this: Or, if you like, a implementation in code itself: Yes, indeed, both examples are definitely longer than the corresponding regular expression: But, however, the above is quite better to read and definitely better to maintain, isn't it? And to top that off: It's much harder to forget to escape something like a dot in SRL. Let's go through it real quick: First, we require the matching string to start. This way, we make sure the match won't begin in the middle of something. Now, we're matching either a digit, a letter, or one of the literal characters ., _, %, + or -. We expect there to be one or more of them. We now expect exactly one @ - Looks like an email address. Again, either digits, letters or . or -, once or multiple times. A dot. Seems to be the end of the TLDs name To the end, we'll expect two or more letters, for the TLD. We require the string to end now, to avoid matching stuff like invalid@email.com123. And of course, all of that should be case insensitive, since it's an email address. Features Using the Language Above you can see two examples. The first one uses the language itself, the second one the Query Builder. Since using a language is more fluent than a builder, we wanted to make things as easy as possible for you. Everything below applies to both, the SRL itself and the Query Builder. Matching SRL is as simple as the example above states. To retrieve the built Regular Expression which can be used by external tools like preg_match, either use the ->get() method, or just let it cast to a string: Of course, you may use the builtin match methods for an even easier approach: Capture Groups Since regular expressions aren't only used for validation, capturing groups is supported by SRL as well. After defining the Regular Expression just like before, simply add a capture-group which will match the query defined in the lambda function. Optionally, a name for that capture group (color) can be set as well: Each match will be passed to a SRL\Match object, which will return the matches found. Additional PCRE functions Feel free to use all the available PCRE PHP functions in combination with SRL. Although, why bother? We've got wrappers for all common functions with additional features. Just like above, just apply one of the following methods directly on the SRL or Builder: isMatching() - Validate if the expression matches the given string. getMatches() - Get all matches for supplied capture groups. getMatch() - Get first match for supplied capture groups. replace() - Replace data using the expression. split() - Split string into array through expression. filter() - Filter items using the expression. Lookarounds In case you want some regular expressions to only apply in certain conditions, lookarounds are probably what you're searching for. With queries like: you can easily capture 'foo', but only if this match is followed by 'bar'. But to be honest, the Query Builder version is quite much code for such a simple thing, right? No problem! Not only are we supporting anonymous functions for sub-expressions, strings and Builder objects are supported as well. Isn't that great? Just have a look at one possible example: If desired, lookbehinds are possible as well. Using ifAlreadyHad() you can validate a certain condition only if the previous string contained a specific pattern. Performance The built Regular Expression will be cached, so you don't have to worry about it being created every time you call the match-method. And, since it's a normal Regular Expression under the hood, performance won't be an issue. Of course, building the expression may take some time, but in real life applications this shouldn't be noticeable. But if you like, you can build the expression somewhere else and just use the result in your app. If you do that, please keep the code for that query somewhere and link to it, otherwise the Regular Expression will be unreadable just as before. Usage Add the package to your require section in the composer.json-file and update your project. Things to do We're definitely not done yet. There's much to come. A short list of stuff that's planned would contain: More functionality More documentation Variable support Rule the world License SRL is published under the MIT license. See LICENSE for more information. Contribution Like this project? Want to contribute? Awesome! Feel free to open some pull requests or just open an issue."
478,"WordPress starter theme with a modern development workflow WordPress starter theme with a modern development workflow Built with Official Website | Documentation | Change Log Supporting Sage is an open source project and completely free to use. However, the amount of effort needed to maintain and develop new features and products within the Roots ecosystem is not sustainable without proper financial backing. If you have the capability, please consider donating using the links below: [![Sponsor on GitHub](https://img.shields.io/static/v1?label=sponsor&message=%E2%9D%A4&logo=GitHub)](https://github.com/sponsors/roots) [![Sponsor on Patreon](https://img.shields.io/badge/sponsor-patreon-orange.svg?style=flat-square&logo=patreon"")](https://www.patreon.com/rootsdev) [![Donate via PayPal](https://img.shields.io/badge/donate-paypal-blue.svg?style=flat-square&logo=paypal)](https://www.paypal.me/rootsdev) About Sage Sage is a productivity-driven WordPress starter theme with a modern development workflow. The master branch currently tracks Sage 10 which is in active development. Looking for Sage 9? See releases. Features Harness the power of Laravel and its available packages thanks to Acorn. Clean, efficient theme templating utilizing Laravel Blade. Easy Browsersync support alongside asset compilation, concatenating, and minification powered by Laravel Mix. Out of the box support for TailwindCSS and jQuery. A clean starting point for theme styles using Sass. See a working example at roots-example-project.com. Requirements Make sure all dependencies have been installed before moving on: WordPress >= 5.4 PHP >= 7.3.0 (with php-mbstring enabled) Composer Node.js >= 12.14.0 Yarn Theme installation Install Sage using Composer from your WordPress themes directory (replace your-theme-name below with the name of your theme): To install the latest development version of Sage, add dev-master to the end of the command: Theme structure Theme setup Edit app/setup.php to enable or disable theme features, setup navigation menus, post thumbnail sizes, and sidebars. Theme development Run yarn from the theme directory to install dependencies Update webpack.mix.js with your local dev URL Build commands yarn start Compile assets when file changes are made, start Browsersync session yarn build Compile and optimize the files in your assets directory yarn build:production Compile assets for production Documentation Sage documentation Contributing Contributions are welcome from everyone. We have contributing guidelines to help you get started. Sage sponsors Help support our open-source development efforts by becoming a sponsor. Community Keep track of development and community news. Participate on the Roots Discourse Follow @rootswp on Twitter Read and subscribe to the Roots Blog Subscribe to the Roots Newsletter Listen to the Roots Radio podcast"
2186,"Customizable Windows terminal with tabs, splits, quake-style, hotkeys and moreAbout ConEmu ConEmu-Maximus5 is a Windows console emulator with tabs, which represents multiple consoles as one customizable GUI window with various features. Initially, the program was created as a companion to Far Manager, my favorite shell replacement - file and archive management, command history and completion, powerful editor. Today, ConEmu can be used with any other console application or simple GUI tools (like PuTTY for example). ConEmu is an active project, open to suggestions. Take a look at screencast about ConEmu. This fork grew up from ConEmu by Zoin. License (BSD 3-clause) THIS SOFTWARE IS PROVIDED BY THE AUTHOR ''AS IS'' AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. See Release/ConEmu/License.txt for the full license text. Some links Wiki: https://conemu.github.io/en/TableOfContents.html What's new: https://conemu.github.io/en/Whats_New.html Release stages: https://conemu.github.io/en/StableVsPreview.html Donate this project: https://conemu.github.io/donate.html Description ConEmu starts a console program in hidden console window and provides an alternative customizable GUI window with various features: smooth window resizing; tabs and splits (panes); easy run old DOS applications (games) in Windows 7 or 64bit OS (DosBox required); quake-style, normal, maximized and full screen window graphic modes; window font anti-aliasing: standard, clear type, disabled; window fonts: family, height, width, bold, italic, etc.; using normal/bold/italic fonts for different parts of console simultaneously; cursor: standard console (horizontal) or GUI (vertical); and more, and more... Far Manager related features tabs for editors, viewers, panels and consoles; thumbnails and tiles; show full output (1K+ lines) of last command in editor/viewer; customizable right click behaviour (long click opens context menu); drag and drop (explorer style); and more, and more... All settings are read from the registry or ConEmu.xml file, after which the command line parameters are applied. You may easily use several named configurations (for different PCs for example). Requirements Windows XP or later for 32-bit. Windows Vista or later for 64-bit. Installation In general, ConEmu installation is easy. Just unpack or install to any folder and run ConEmu.exe. Read Installation wiki about release stages, distro packets, some warnings and much more... Building from sources https://github.com/Maximus5/ConEmu/blob/master/src/HowToBuild.md Screenshots More screenshots"
2086,"CommonMark spec, with reference implementations in C and JavaScriptCommonMark CommonMark is a rationalized version of Markdown syntax, with a spec and BSD-licensed reference implementations in C and JavaScript. Try it now! For more details, see http://commonmark.org. This repository contains the spec itself, along with tools for running tests against the spec, and for creating HTML and PDF versions of the spec. The reference implementations live in separate repositories: https://github.com/commonmark/cmark (C) https://github.com/commonmark/commonmark.js (JavaScript) There is a list of third-party libraries in a dozen different languages here. Running tests against the spec The spec contains over 500 embedded examples which serve as conformance tests. To run the tests using an executable $PROG: python3 test/spec_tests.py --program $PROG If you want to extract the raw test data from the spec without actually running the tests, you can do: python3 test/spec_tests.py --dump-tests and you'll get all the tests in JSON format. JavaScript developers may find it more convenient to use the [commonmark-spec npm package], which is published from this repository. It exports an array tests of JSON objects with the format The spec The source of the spec is spec.txt. This is basically a Markdown file, with code examples written in a shorthand form: `` example Markdown source . expected HTML output `` To build an HTML version of the spec, do make spec.html. To build a PDF version, do make spec.pdf. For both versions, you must have the lua rock lcmark installed: after installing lua and lua rocks, luarocks install lcmark. For the PDF you must also have xelatex installed. The spec is written from the point of view of the human writer, not the computer reader. It is not an algorithm---an English translation of a computer program---but a declarative description of what counts as a block quote, a code block, and each of the other structural elements that can make up a Markdown document. Because John Gruber's canonical syntax description leaves many aspects of the syntax undetermined, writing a precise spec requires making a large number of decisions, many of them somewhat arbitrary. In making them, we have appealed to existing conventions and considerations of simplicity, readability, expressive power, and consistency. We have tried to ensure that ""normal"" documents in the many incompatible existing implementations of Markdown will render, as far as possible, as their authors intended. And we have tried to make the rules for different elements work together harmoniously. In places where different decisions could have been made (for example, the rules governing list indentation), we have explained the rationale for our choices. In a few cases, we have departed slightly from the canonical syntax description, in ways that we think further the goals of Markdown as stated in that description. For the most part, we have limited ourselves to the basic elements described in Gruber's canonical syntax description, eschewing extensions like footnotes and definition lists. It is important to get the core right before considering such things. However, we have included a visible syntax for line breaks and fenced code blocks. Differences from original Markdown There are only a few places where this spec says things that contradict the canonical syntax description: It allows all punctuation symbols to be backslash-escaped, not just the symbols with special meanings in Markdown. We found that it was just too hard to remember which symbols could be escaped. It introduces an alternative syntax for hard line breaks, a backslash at the end of the line, supplementing the two-spaces-at-the-end-of-line rule. This is motivated by persistent complaints about the invisible nature of the two-space rule. Link syntax has been made a bit more predictable (in a backwards-compatible way). For example, Markdown.pl allows single quotes around a title in inline links, but not in reference links. This kind of difference is really hard for users to remember, so the spec allows single quotes in both contexts. The rule for HTML blocks differs, though in most real cases it shouldn't make a difference. (See the section on HTML Blocks for details.) The spec's proposal makes it easy to include Markdown inside HTML block-level tags, if you want to, but also allows you to exclude this. It also makes parsing much easier, avoiding expensive backtracking. It does not collapse adjacent bird-track blocks into a single blockquote: > this is two > blockquotes > this is a single > > blockquote with two paragraphs Rules for content in lists differ in a few respects, though (as with HTML blocks), most lists in existing documents should render as intended. There is some discussion of the choice points and differences in the subsection of List Items entitled Motivation. We think that the spec's proposal does better than any existing implementation in rendering lists the way a human writer or reader would intuitively understand them. (We could give numerous examples of perfectly natural looking lists that nearly every existing implementation flubs up.) Changing bullet characters, or changing from bullets to numbers or vice versa, starts a new list. We think that is almost always going to be the writer's intent. The number that begins an ordered list item may be followed by either . or ). Changing the delimiter style starts a new list. The start number of an ordered list is significant. Fenced code blocks are supported, delimited by either backticks ( ```) or tildes ( ~~~ `). Contributing There is a forum for discussing CommonMark; you should use it instead of github issues for questions and possibly open-ended discussions. Use the github issue tracker only for simple, clear, actionable issues. Authors The spec was written by John MacFarlane, drawing on his experience writing and maintaining Markdown implementations in several languages, including the first Markdown parser not based on regular expression substitutions (pandoc) and the first markdown parsers based on PEG grammars (peg-markdown, lunamark) a detailed examination of the differences between existing Markdown implementations using BabelMark 2, and extensive discussions with David Greenspan, Jeff Atwood, Vicent Marti, Neil Williams, and Benjamin Dumke-von der Ehe. Since the first announcement, many people have contributed ideas. Krlis Gais was especially helpful in refining the rules for emphasis, strong emphasis, links, and images."
3934,"Heres a flowchart to make you happy again!react-makes-you-sad Heres a flowchart to make you happy again! Open in a new tab Credits Based on and inspired by https://github.com/petehunt/react-howto Links If you are confused by the React ecosystem and dont know where to start, read Pete Hunts react-howto guide. If you are using a Flux library (or Redux) and it adds a lot of boilerplate for no obvious gain, remove it and learn state management in vanilla React with the official Thinking in React guide. If you dont feel comfortable using ES2015 features (e.g. classes and fat arrows) and you feel like updating your JavaScript knowledge, Understanding ECMAScript 6 is an amazing guide. Use Babel to verify your assumptions. If you are just learning React, and a JavaScript bundler like Webpack confuses you, copy jarsbe/react-simple and start hacking with no build step. After youve learned React itself you can begin learning good deployment practices such as using JavaScript bundlers. Use Google Page Speed to assess how well your app delivers the client code. Contributing Edit the .dot file with https://atom.io/packages/graphviz-preview Install dot from http://www.graphviz.org/Download.php Install dot, a part of Graphviz. On OSX with Homebrew, merely do brew install graphviz. Otherwise, it's probably in your OS's package repositories as simply graphviz. You can also get an installer from the Graphviz downloads page. Generate the .svg with dot -Tsvg fatigue.dot > fatigue.svg Send a PR! Translation Franais Portuguese Spanish Ting Vit License CC0"
3194,"Go Relational Persistence - an ORM-ish library for GoGo Relational Persistence Update 2016-11-13: Future versions As many of the maintainers have become busy with other projects, progress toward the ever-elusive v2 has slowed to the point that we're only occasionally making progress outside of merging pull requests. In the interest of continuing to release, I'd like to lean toward a more maintainable path forward. For the moment, I am releasing a v2 tag with the current feature set from master, as some of those features have been actively used and relied on by more than one project. Our next goal is to continue cleaning up the code base with non-breaking changes as much as possible, but if/when a breaking change is needed, we'll just release new versions. This allows us to continue development at whatever pace we're capable of, without delaying the release of features or refusing PRs. Introduction I hesitate to call gorp an ORM. Go doesn't really have objects, at least not in the classic Smalltalk/Java sense. There goes the ""O"". gorp doesn't know anything about the relationships between your structs (at least not yet). So the ""R"" is questionable too (but I use it in the name because, well, it seemed more clever). The ""M"" is alive and well. Given some Go structs and a database, gorp should remove a fair amount of boilerplate busy-work from your code. I hope that gorp saves you time, minimizes the drudgery of getting data in and out of your database, and helps your code focus on algorithms, not infrastructure. Bind struct fields to table columns via API or tag Support for embedded structs Support for transactions Forward engineer db schema from structs (great for unit tests) Pre/post insert/update/delete hooks Automatically generate insert/update/delete statements for a struct Automatic binding of auto increment PKs back to struct after insert Delete by primary key(s) Select by primary key(s) Optional trace sql logging Bind arbitrary SQL queries to a struct Bind slice to SELECT query results without type assertions Use positional or named bind parameters in custom SELECT queries Optional optimistic locking using a version column (for update/deletes) Installation Use go get or your favorite vendoring tool, using whichever import path you'd like. Versioning We use semantic version tags. Feel free to import through gopkg.in (e.g. gopkg.in/gorp.v2) to get the latest tag for a major version, or check out the tag using your favorite vendoring tool. Development is not very active right now, but we have plans to restructure gorp as we continue to move toward a more extensible system. Whenever a breaking change is needed, the major version will be bumped. The master branch is where all development is done, and breaking changes may happen from time to time. That said, if you want to live on the bleeding edge and are comfortable updating your code when we make a breaking change, you may use github.com/go-gorp/gorp as your import path. Check the version tags to see what's available. We'll make a good faith effort to add badges for new versions, but we make no guarantees. Supported Go versions This package is guaranteed to be compatible with the latest 2 major versions of Go. Any earlier versions are only supported on a best effort basis and can be dropped any time. Go has a great compatibility promise. Upgrading your program to a newer version of Go should never really be a problem. Migration guide Pre-v2 to v2 Automatic mapping of the version column used in optimistic locking has been removed as it could cause problems if the type was not int. The version column must now explicitly be set with tablemap.SetVersionCol(). Help/Support Use our gitter channel. We used to use IRC, but with most of us being pulled in many directions, we often need the email notifications from gitter to yell at us to sign in. Quickstart Examples Mapping structs to tables First define some types: Then create a mapper, typically you'd do this one time at app startup: Struct Embedding gorp supports embedding structs. For example: See the TestWithEmbeddedStruct function in gorp_test.go for a full example. Create/Drop Tables Automatically create / drop registered tables. This is useful for unit tests but is entirely optional. You can of course use gorp with tables created manually, or with a separate migration tool (like sql-migrate, goose or migrate). SQL Logging Optionally you can pass in a logger to trace all SQL statements. I recommend enabling this initially while you're getting the feel for what gorp is doing on your behalf. Gorp defines a GorpLogger interface that Go's built in log.Logger satisfies. However, you can write your own GorpLogger implementation, or use a package such as glog if you want more control over how statements are logged. Insert Update Continuing the above example, use the Update method to modify an Invoice: Delete If you have primary key(s) defined for a struct, you can use the Delete method to remove rows: Select by Key Use the Get method to fetch a single row by primary key. It returns nil if no row is found. Ad Hoc SQL SELECT Select() and SelectOne() provide a simple way to bind arbitrary queries to a slice or a single struct. Want to do joins? Just write the SQL and the struct. gorp will bind them: SELECT string or int64 gorp provides a few convenience methods for selecting a single string or int64. Named bind parameters You may use a map or struct to bind parameters by name. This is currently only supported in SELECT queries. UPDATE / DELETE You can execute raw SQL if you wish. Particularly good for batch operations. Transactions You can batch operations into a transaction: Hooks Use hooks to update data before/after saving to the db. Good for timestamps: Full list of hooks that you can implement: PostGet PreInsert PostInsert PreUpdate PostUpdate PreDelete PostDelete All have the same signature. for example: func (p *MyStruct) PostUpdate(s gorp.SqlExecutor) error Optimistic Locking Note that this behaviour has changed in v2. See Migration Guide. gorp provides a simple optimistic locking feature, similar to Java's JPA, that will raise an error if you try to update/delete a row whose version column has a value different than the one in memory. This provides a safe way to do ""select then update"" style operations without explicit read and write locks. Adding INDEX(es) on column(s) beyond the primary key Indexes are frequently critical for performance. Here is how to add them to your tables. NB: SqlServer and Oracle need testing and possible adjustment to the CreateIndexSuffix() and DropIndexSuffix() methods to make AddIndex() work for them. In the example below we put an index both on the Id field, and on the AcctId field. Check the effect of the CreateIndex() call in mysql: Database Drivers gorp uses the Go 1 database/sql package. A full list of compliant drivers is available here: http://code.google.com/p/go-wiki/wiki/SQLDrivers Sadly, SQL databases differ on various issues. gorp provides a Dialect interface that should be implemented per database vendor. Dialects are provided for: MySQL PostgreSQL sqlite3 Each of these three databases pass the test suite. See gorp_test.go for example DSNs for these three databases. Support is also provided for: Oracle (contributed by @klaidliadon) SQL Server (contributed by @qrawl) - use driver: github.com/denisenkom/go-mssqldb Note that these databases are not covered by CI and I (@coopernurse) have no good way to test them locally. So please try them and send patches as needed, but expect a bit more unpredicability. Sqlite3 Extensions In order to use sqlite3 extensions you need to first register a custom driver: Known Issues SQL placeholder portability Different databases use different strings to indicate variable placeholders in prepared SQL statements. Unlike some database abstraction layers (such as JDBC), Go's database/sql does not standardize this. SQL generated by gorp in the Insert, Update, Delete, and Get methods delegates to a Dialect implementation for each database, and will generate portable SQL. Raw SQL strings passed to Exec, Select, SelectOne, SelectInt, etc will not be parsed. Consequently you may have portability issues if you write a query like this: In Select and SelectOne you can use named parameters to work around this. The following is portable: Additionally, when using Postgres as your database, you should utilize $1 instead of ? placeholders as utilizing ? placeholders when querying Postgres will result in pq: operator does not exist errors. Alternatively, use dbMap.Dialect.BindVar(varIdx) to get the proper variable binding for your dialect. time.Time and time zones gorp will pass time.Time fields through to the database/sql driver, but note that the behavior of this type varies across database drivers. MySQL users should be especially cautious. See: https://github.com/ziutek/mymysql/pull/77 To avoid any potential issues with timezone/DST, consider: Using an integer field for time data and storing UNIX time. Using a custom time type that implements some SQL types: ""database/sql"".Scanner ""database/sql/driver"".Valuer Running the tests The included tests may be run against MySQL, Postgresql, or sqlite3. You must set two environment variables so the test code knows which driver to use, and how to connect to your database. Valid GORP_TEST_DIALECT values are: ""mysql""(for mymysql), ""gomysql""(for go-sql-driver), ""postgres"", ""sqlite"" See the test_all.sh script for examples of all 3 databases. This is the script I run locally to test the library. Performance gorp uses reflection to construct SQL queries and bind parameters. See the BenchmarkNativeCrud vs BenchmarkGorpCrud in gorp_test.go for a simple perf test. On my MacBook Pro gorp is about 2-3% slower than hand written SQL. Contributors matthias-margush - column aliasing via tags Rob Figueiredo - @robfig Quinn Slack - @sqs"
2305,"A simple and easy jQuery plugin for CSS animated page transitions.Animsition A simple and easy jQuery plugin for CSS animated page transitions. Demo & Installation http://git.blivesta.com/animsition/ Development Install : nodejs npm gulp Build Build -> Watch CDN cdnjs dist/css/animsition.css dist/css/animsition.min.css dist/js/animsition.js dist/js/animsition.min.js Contributing To contribute to animsition, clone this repo locally and commit your code. Please check that everything works before opening a pull-request. Contributors @blivesta (Maintainer) @ungki (Maintainer) @gauravpadia (Maintainer) @munsonbh @triq6 @shgtkshruch @vburlak @wpexplorer @armbull @kkirsche @justbartlett @brianmontanaweb @Superpencil @tegansnyder @nvartolomei License Released under the MIT license. WordPress plugin Page Transition @numixtech @gauravpadia @asalamwp"
4405,"Parse log files, generate metrics for Graphite and GangliaLogster - generate metrics from logfiles Logster is a utility for reading log files and generating metrics to configurable outputs. It is ideal for visualizing trends of events that are occurring in your application/system/error logs. For example, you might use logster to graph the number of occurrences of HTTP response code that appears in your web server logs. Logster maintains a cursor, via a tailer, on each log file that it reads so that each successive execution only inspects new log entries. In other words, a 1 minute crontab entry for logster would allow you to generate near real-time trends in the configured output for anything you want to measure from your logs. This tool is made up of a framework script, logster, and parsing classes that are written to accommodate your specific log format. Sample parsers are included in this distribution. The parser classes essentially read a log file line by line, apply a regular expression to extract useful data from the lines you are interested in, and then aggregate that data into metrics that will be submitted to the configured output. The sample parsers should give you some idea of how to get started writing your own. A list of available parsers can be found on the Parsers page. Graphite, Ganglia, Amazon CloudWatch, Nagios, StatsD and stdout outputs are provided, and Logster also supports the use of third-party output classes. A list of available output classes can be found on the Outputs page. History The logster project was created at Etsy as a fork of ganglia-logtailer (https://bitbucket.org/maplebed/ganglia-logtailer). We made the decision to fork ganglia-logtailer because we were removing daemon-mode from the original framework. We only make use of cron-mode, and supporting both cron- and daemon-modes makes for more work when creating parsing scripts. We care strongly about simplicity in writing parsing scripts -- which enables more of our engineers to write log parsers quickly. Installation Logster supports two methods for gathering data from a logfile: By default, Logster uses the ""logtail"" utility that can be obtained from the logcheck package, either from a Debian package manager or from source: http://packages.debian.org/source/sid/logcheck RPMs for logcheck can be found here: http://rpmfind.net/linux/rpm2html/search.php?query=logcheck Optionally, Logster can use the ""Pygtail"" Python module instead of logtail. You can install Pygtail using pip To use Pygtail, supply the option on the Logster commandline. Also, Logster supports two methods for locking files (which it has to do): By default, Logster uses . Optionally, Logster can use the ""Portalocker"" Python module instead of fcntl (which is not available on Windows). You can install Portalocker using pip, similar to Pygtail above. To use Portalocker, supply the option on the Logster commandline. Once you have logtail or Pygtail installed, install Logster using the setup.py file: $ sudo python setup.py install Usage You can test logster from the command line. The --dry-run option will allow you to see the metrics being generated on stdout rather than sending them to your configured output. $ sudo /usr/bin/logster --dry-run --output=ganglia SampleLogster /var/log/httpd/access_log $ sudo /usr/bin/logster --dry-run --output=graphite --graphite-host=graphite.example.com:2003 SampleLogster /var/log/httpd/access_log You can use the provided parsers, or you can use your own parsers by passing the complete module and parser name. In this case, the name of the parser does not have to match the name of the module (you can have a logster.py file with a MyCustomParser parser). Just make sure the module is in your Python path - via a virtualenv, for example. $ /env/my_org/bin/logster --dry-run --output=stdout my_org_package.logster.MyCustomParser /var/log/my_custom_log Additional usage details can be found with the -h option: $ logster -h Usage: logster [options] parser logfile Tail a log file and filter each line to generate metrics that can be sent to common monitoring packages. Options: -h, --help show this help message and exit -t TAILER, --tailer=TAILER Specify which tailer to use. Options are logtail and pygtail. Default is ""logtail"". --logtail=LOGTAIL Specify location of logtail. Default ""/usr/sbin/logtail2"" -p METRIC_PREFIX, --metric-prefix=METRIC_PREFIX Add prefix to all published metrics. This is for people that may multiple instances of same service on same host. -x METRIC_SUFFIX, --metric-suffix=METRIC_SUFFIX Add suffix to all published metrics. This is for people that may add suffix at the end of their metrics. --parser-help Print usage and options for the selected parser --parser-options=PARSER_OPTIONS Options to pass to the logster parser such as ""-o VALUE --option2 VALUE"". These are parser-specific and passed directly to the parser. -s STATE_DIR, --state-dir=STATE_DIR Where to store the tailer state file. Default location /var/run -l LOG_DIR, --log-dir=LOG_DIR Where to store the logster logfile. Default location /var/log/logster --log-conf=LOG_CONF Logging configuration file. None by default -o OUTPUT, --output=OUTPUT Where to send metrics (can specify multiple times). Choices are statsd, stdout, cloudwatch, graphite, ganglia, nsca or a fully qualified Python class name -d, --dry-run Parse the log file but send stats to standard output. -D, --debug Provide more verbose logging for debugging. Contributing Fork the project Add your feature If you are adding new functionality, document it in the README Verify your code by running the test suite, and adding additional tests if able. Push the branch up to GitHub (bonus points for topic branches) Send a pull request to the etsy/logster project. If you have questions, you can find us on IRC in the #codeascraft channel on Freenode."
4192,"PyMongo - the Python driver for MongoDB======= PyMongo ======= :Info: See the mongo site <http://www.mongodb.org> for more information. See GitHub <http://github.com/mongodb/mongo-python-driver> for the latest source. :Documentation: Available at pymongo.readthedocs.io <https://pymongo.readthedocs.io/en/stable/>_ :Author: Mike Dirolf :Maintainer: Bernie Hackett bernie@mongodb.com About The PyMongo distribution contains tools for interacting with MongoDB database from Python. The bson package is an implementation of the BSON format <http://bsonspec.org> for Python. The pymongo package is a native Python driver for MongoDB. The gridfs package is a gridfs <http://www.mongodb.org/display/DOCS/GridFS+Specification> implementation on top of pymongo. PyMongo supports MongoDB 2.6, 3.0, 3.2, 3.4, 3.6, 4.0, 4.2, and 4.4. Support / Feedback For issues with, questions about, or feedback for PyMongo, please look into our support channels <https://support.mongodb.com/welcome>. Please do not email any of the PyMongo developers directly with issues or questions - you're more likely to get an answer on the MongoDB Community Forums <https://developer.mongodb.com/community/forums/tag/python-driver>. Bugs / Feature Requests Think youve found a bug? Want to see a new feature in PyMongo? Please open a case in our issue management tool, JIRA: Create an account and login <https://jira.mongodb.org>_. Navigate to the PYTHON project <https://jira.mongodb.org/browse/PYTHON>_. Click Create Issue - Please provide as much information as possible about the issue type and how to reproduce it. Bug reports in JIRA for all driver projects (i.e. PYTHON, CSHARP, JAVA) and the Core Server (i.e. SERVER) project are public. How To Ask For Help Please include all of the following information when opening an issue: Detailed steps to reproduce the problem, including full traceback, if possible. The exact python version used, with patch level:: $ python -c ""import sys; print(sys.version)"" The exact version of PyMongo used, with patch level:: $ python -c ""import pymongo; print(pymongo.version); print(pymongo.has_c())"" The operating system and version (e.g. Windows 7, OSX 10.8, ...) Web framework or asynchronous network library used, if any, with version (e.g. Django 1.7, mod_wsgi 4.3.0, gevent 1.0.1, Tornado 4.0.2, ...) Security Vulnerabilities If youve identified a security vulnerability in a driver or any other MongoDB project, please report it according to the instructions here <http://docs.mongodb.org/manual/tutorial/create-a-vulnerability-report>_. Installation PyMongo can be installed with pip <http://pypi.python.org/pypi/pip>_:: $ python -m pip install pymongo Or easy_install from setuptools <http://pypi.python.org/pypi/setuptools>_:: $ python -m easy_install pymongo You can also download the project source and do:: $ python setup.py install Do not install the ""bson"" package from pypi. PyMongo comes with its own bson package; doing ""easy_install bson"" installs a third-party package that is incompatible with PyMongo. Dependencies PyMongo supports CPython 3.6+ and PyPy3.6+. Optional dependencies: GSSAPI authentication requires pykerberos <https://pypi.python.org/pypi/pykerberos> on Unix or WinKerberos <https://pypi.python.org/pypi/winkerberos> on Windows. The correct dependency can be installed automatically along with PyMongo:: $ python -m pip install pymongo[gssapi] MONGODB-AWS authentication requires pymongo-auth-aws <https://pypi.org/project/pymongo-auth-aws/>_:: $ python -m pip install pymongoaws Support for mongodb+srv:// URIs requires dnspython <https://pypi.python.org/pypi/dnspython>_:: $ python -m pip install pymongo[srv] OCSP (Online Certificate Status Protocol) requires PyOpenSSL <https://pypi.org/project/pyOpenSSL/>, requests <https://pypi.org/project/requests/>, service_identity <https://pypi.org/project/service_identity/> and may require certifi <https://pypi.python.org/pypi/certifi>:: $ python -m pip install pymongo[ocsp] Wire protocol compression with snappy requires python-snappy <https://pypi.org/project/python-snappy>_:: $ python -m pip install pymongo[snappy] Wire protocol compression with zstandard requires zstandard <https://pypi.org/project/zstandard>_:: $ python -m pip install pymongo[zstd] Client-Side Field Level Encryption requires pymongocrypt <https://pypi.org/project/pymongocrypt/>_:: $ python -m pip install pymongo[encryption] You can install all dependencies automatically with the following command:: $ python -m pip install pymongo[gssapi,aws,ocsp,snappy,srv,tls,zstd,encryption] Additional dependencies are: (to generate documentation) sphinx_ Examples Here's a basic example (for more see the examples section of the docs): .. code-block:: python import pymongo client = pymongo.MongoClient(""localhost"", 27017) db = client.test db.name 'test' db.my_collection Collection(Database(MongoClient('localhost', 27017), 'test'), 'my_collection') db.my_collection.insert_one({""x"": 10}).inserted_id ObjectId('4aba15ebe23f6b53b0000000') db.my_collection.insert_one({""x"": 8}).inserted_id ObjectId('4aba160ee23f6b543e000000') db.my_collection.insert_one({""x"": 11}).inserted_id ObjectId('4aba160ee23f6b543e000002') db.my_collection.find_one() {'x': 10, '_id': ObjectId('4aba15ebe23f6b53b0000000')} for item in db.my_collection.find(): ... print(item[""x""]) ... 10 8 11 db.my_collection.create_index(""x"") 'x_1' for item in db.my_collection.find().sort(""x"", pymongo.ASCENDING): ... print(item[""x""]) ... 8 10 11 [item[""x""] for item in db.my_collection.find().limit(2).skip(1)] [8, 11] Documentation Documentation is available at pymongo.readthedocs.io <https://pymongo.readthedocs.io/en/stable/>_. To build the documentation, you will need to install sphinx_. Documentation can be generated by running python setup.py doc. Generated documentation can be found in the doc/build/html/ directory. Testing The easiest way to run the tests is to run python setup.py test in the root of the distribution. To verify that PyMongo works with Gevent's monkey-patching:: $ python green_framework_test.py gevent Or with Eventlet's:: $ python green_framework_test.py eventlet .. _sphinx: https://www.sphinx-doc.org/en/master/"
70,"Scriptable Headless BrowserPhantomJS - Scriptable Headless WebKit PhantomJS (phantomjs.org) is a headless WebKit scriptable with JavaScript. The latest stable release is version 2.1. Important: PhantomJS development is suspended until further notice (see #15344 for more details). Use Cases Headless web testing. Lightning-fast testing without the browser is now possible! Page automation. Access and manipulate web pages with the standard DOM API, or with usual libraries like jQuery. Screen capture. Programmatically capture web contents, including CSS, SVG and Canvas. Build server-side web graphics apps, from a screenshot service to a vector chart rasterizer. Network monitoring. Automate performance analysis, track page loading and export as standard HAR format. Features Multiplatform, available on major operating systems: Windows, Mac OS X, Linux, and other Unices. Fast and native implementation of web standards: DOM, CSS, JavaScript, Canvas, and SVG. No emulation! Pure headless (no X11) on Linux, ideal for continuous integration systems. Also runs on Amazon EC2, Heroku, and Iron.io. Easy to install: Download, unpack, and start having fun in just 5 minutes. Questions? Explore the complete documentation. Read tons of user articles on using PhantomJS. Join the mailing-list and discuss with other PhantomJS fans. PhantomJS is free software/open source, and is distributed under the BSD license. It contains third-party code, see the included third-party.txt file for the license information on third-party code. PhantomJS is created and maintained by @ariyahidayat, with the help of many contributors."
1477,"JavaScript, SCSS, Sass, Less, and Stylus helpers for rendering high-resolution image variantsretina.js JavaScript, Sass, Less, and Stylus helpers for rendering high-resolution image variants retina.js makes it easy to serve high-resolution images to devices with displays that support them. You can prepare images for as many levels of pixel density as you want and let retina.js dynamically serve the right image to the user. How it works There are 4 ways to use retina.js: Automatically swapping out src paths on img tags. Automatically swapping out background image URLs in inline styles. Manually specifying the location of a high-res image variant (works for src attributes and inline styles). Automatically creating media queries for CSS background images. Img Tags retina.js assumes you are using Apple's prescribed high-resolution modifiers (@2x, @3x, etc) to denote high-res image variants on your server. It also assumes that if you have prepared a variant for a given high-res environment, that you have also prepared variants for each environment below it. For example, if you have prepared 3x variants, retina.js will assume that you have also prepared 2x variants. With this in mind, you'll specify your highest environment level with the data-rjs attribute and let retina.js take it from there. Let's say you have an image on your page that looks like this: In this case, we've set our resolution cap at ""3"", denoting that we've prepared 3x and 2x image variants. When the page loads, retina.js will check the actual resolution of the device environment to decide whether it should really serve up a 3x image. If the user happens to be in a 2x environment, retina.js will serve up the 2x image instead, assuming it will find the image at /images/my_image@2x.png. If the environment does have 3x capabilities, retina.js will serve up the 3x image. It will expect that url to be /images/my_image@3x.png. If the environment has the ability to display images at higher densities than 3x, retina.js will serve up the image of the highest resolution that you've provided, in this case 3x. Inline Styles Previous versions of retina.js were unable to target background images set via inline styles. Now, if you apply a data-rjs attribute to any kind of element other than an img, the script will target inline background images instead of src attributes. So if you created an element like this: retina.js would convert it to something like this: The logic behind image swapping is exactly the same when dealing with background images as it is when dealing with src attributes. If the user's environment only supports 2x variants, retina.js will load the 2x variant instead of the 3x. Note that it is up to you in a case like this to correctly apply background sizing and any other necessary background-related styles to the element. retina.js will not affect these. Manually Specifying a High-Res URL In previous versions, you could tell the script where to find your high-res file by using the data-at2x attribute. Now, if you pass a URL to the data-rjs attribute, retina.js will use the image at the path you specify for all high-resolution environments instead of trying to dynamically serve an auto-suffixed image path based on the environment's capabilities. This will work for both src attributes on img tags and inline background images on all other tags. For example, you might write something like this: If the user then loads the page in any kind of high-resolution environment, they'll get the following: Media Queries retina.js comes with mixins for SCSS, Sass, Less, and Stylus. These mixins work similarly to the JavaScript version in that they will dynamically serve images for as many high-res environments as you've prepared image variants for. Previously, these mixins were named ""at2x"" but because they now serve images for multiple environments, they have been renamed ""retina"". In each language, the retina mixin allows 4 parameters: path - The path to your standard resolution image. cap - Optional. The highest resolution level for which you have prepared images. Defaults to 2. size- Optional. A value to be applied to the background-size property. Defaults to auto auto. extras- Optional. Any other values to be added to the background property. Defaults to nothing. Here is an example wherein we are specifying that we have prepared images for both 2x and 3x environments: SCSS Sass Less Stylus Regardless of the dialect, the output is effectively the same: Compatibility retina.js is compatible with all modern browsers and should not throw errors in old browsers all the way back through IE6. Installing & Launching JavaScript There are 2 ways to use the JavaScript version of retina.js: The old-school way (manually dropping the script into an html file). The new-school way (importing it into a larger JavaScript build process). Old-School To use retina.js the old-school way, download retina.min.js and put it on your server. Then, include the script in your html file at the bottom of your template, before your closing \ tag. Using this technique, retina.js will run automatically on page load. It will also create a globally available function called retinajs. Whenever you'd like to manually re-initialize the script, simply call window.retinajs(). If you don't pass any arguments to the retinajs function, it will only attempt to process images that have not previously been processed by the script. Optionally, you can pass a collection of HTML elements to the script, in which case it will only attempt to process elements in that collection, specifically the ones that have not been processed before. Your collection may take the form of an Array, NodeList, or jQuery selection. New-School To use retina.js the new-school way, you'll want to require it (or import it if you're using ES6) into your Gulp/Webpack/Grunt/CommonJS/etc application. In this case, the script won't run automatically. Instead, it'll let you determine when you'd like it to run. Notice that the retina function can be called as often as you need in order to re-initialize the image swapping. If you don't pass any arguments to the retina function, it will only attempt to process images that have not previously been processed by the script. Optionally, you can pass a collection of HTML elements to the script, in which case it will only attempt to process elements in that collection, specifically the ones that have not been processed before. Your collection may take the form of an Array, NodeList, or jQuery selection. CSS Preprocessors The process for including the CSS mixins is relatively straightforward. Here is a breakdown for each: SCSS Add the @mixin retina( ... ) mixin from _retina.scss to your SCSS stylesheet (or reference it in an @import). In your stylesheet, call the mixin using @include retina( ... ) anywhere instead of using background or background-image. Sass Add the =retina( ... ) mixin from _retina.sass to your Sass stylesheet (or reference it in an @import). In your stylesheet, call the mixin using +retina( ... ) anywhere instead of using background or background-image. Less Add the .retina( ... ) mixin from retina.less to your Less stylesheet (or reference it in an @import). In your stylesheet, call the mixin using .retina( ... ) anywhere instead of using background or background-image. Stylus Add the retina( ... ) mixin from retina.styl to your Stylus stylesheet (or reference it in an @import). In your stylesheet, call the mixin using retina( ... ) anywhere instead of using background or background-image. Considerations for Ruby on Rails 3+ ...or any framework that embeds some digest/hash to the asset URLs based on the contents, e.g. /images/image-{hash1}.jpg. The problem with this is that the high-resolution version would have a different hash, and would not conform to the usual pattern, i.e. /images/image@2x-{hash2}.jpg. So automatic detection would fail because retina.js would check the existence of /images/image-{hash1}@2x.jpg. There's no way for retina.js to know beforehand what the high-resolution image's hash would be without some sort of help from the server side. So in this case, there are a couple of options for handling it: Bypass Digesting One potential method is to bypass digesting altogether by implementing a process like team-umlaut's asset compile rake file which will generate non-digested asset files as necessary. Use Manual Paths Although it's not quite as fancy as dynamically serving up files based on the resolution of the user's environment, this may be a good time to pass a URL string to the data-rjs attribute so that you can manually tell retina.js exactly where to look for a high-resolution variant of your image."
1175,"A workflow for building Backbone applications.Backbone Boilerplate This boilerplate is the product of much research and frustration. Existing boilerplates freely modify Backbone core, lack a build process, and are very prescriptive; Backbone Boilerplate changes that. The Backbone Boilerplate is a way of organizing a web application with some opinionated defaults, such as: Backbone, jQuery, Lodash, Grunt, Babel, Combyne, Karma, Mocha, and PureCSS for styles. Organize your application with a logical file structure, develop your Models/Collections/Views/Routers inside modules, and build knowing you have efficient code that will not bottleneck your users. Thanks to our Contributors! Special Thanks to: cowboy, iros, nimbupani, wookiehangover, and jugglinmike for helping me create this project. Extra Special Thanks to: Paul Guinan for giving me usage rights to his fantastic Boilerplate character. Documentation Backbone Boilerplate Wiki Getting started The easiest way to get started is to install Git and clone the repository: You will need to download and install Node to fetch the dependencies and use the build tools. Updating dependencies Third party packages may update independently from this main repo, so it's a good idea to update after fetching. Build process The build process consists of numerous Grunt plugin tasks that work together to optimize your application. Working with tests Create an ES6 module in the test/tests directory and add an import in the test/runner.js file. You'll see existing examples in there to make it easy to follow. Run the tests with: If you want to continuously test, run npm start and open the test/index.html file in your browser. The tests will re-run whenever you change source files. By default, the test runner is BDD Mocha and uses Node's assert. License Copyright 2015 Tim Branyen (@tbranyen) Licensed under the MIT license."
2138,":warning: :warning: Currently Unmaintained :warning: :warning: - fast, beautiful, and painless social shares:Share Button An Introduction Simple, light, flexible, and good-looking share button. See it in action! Why Should You Use This? All major social networks have their own share widgets you can put on your page, but this isn't ideal for a variety of reasons: They tend to be slow-loading. They inject extra javascript and DOM elements into your page making it slower. They generally aren't customizable enough to fit the design of your site. Managing each provider's code snippets etc is repetitive and needless. Additionally, they can make your front-end code quite messy. The buttons themselves take up a lot of space (especially the Facebook share button). Let's take a quick look at the alternative, using this little plugin: It doesn't load any iframes or extra javascript making the overall load time much faster. It looks simple and clean by default, and can be customized in any and every way. All you have to do to use it is include the script and call new ShareButton on a share-button element. That's two lines of code total, the script link and the share call. It's tiny and compact, expanding only when the user actually wants to share something. Getting Started Download the latest script & stylesheet and include it on your page. Make a share-button element on your page In your javascript, call new ShareButton() Pass options to the share call if you want (details below) Profit! NPM installation npm i --save-dev share-button Make a share-button element on your page In your javascript, var ShareButton = require('share-button'); Pass options to the share call if you want (details below) Profit! Customization Configuration Options The share button is extremely flexible. As such we provide the ability to pass a wide array of options for additional configuration. All configuration options are available here: Configuration Options Styles Additionally, you're able to customize the look and feel of the button and animations though CSS. All CSS styles and how to modify them are available here: CSS Styles Hooks You are able to set before and after hooks when a user clicks a network. This allows you to dynamically change attributes for that button. For more information: click here Public API The share button also returns a simple API that can be used to control it should you need to. Example shown below: Fonts As of version 1.0.0 we completely removed the Entypo font set! Inspiration This project was inspired by this dribbble shot and this cssdeck experiment - huge props to these two guys for some incredible ideas and work. Contributing and License Contributing Guidelines can be found here Licensed under MIT - details here"
2111,"The source code that powers readthedocs.orgWelcome to Read the Docs |build-status| |docs| |coverage| Purpose Read the Docs hosts documentation for the open source community. It supports Sphinx docs written with reStructuredText_, and can pull from your Subversion_, Bazaar_, Git_, and Mercurial_ repositories. Then we build documentation and host it for you. Think of it as Continuous Documentation. .. _Read the docs: https://readthedocs.org/ .. _Sphinx: http://www.sphinx-doc.org/ .. _reStructuredText: http://www.sphinx-doc.org/en/master/usage/restructuredtext/basics.html .. _Subversion: http://subversion.tigris.org/ .. _Bazaar: http://bazaar.canonical.com/ .. _Git: http://git-scm.com/ .. _Mercurial: https://www.mercurial-scm.org/ Documentation for RTD You will find complete documentation for setting up your project at the Read the Docs site_. .. _the Read the Docs site: https://docs.readthedocs.io/ Get in touch You can find information about getting in touch with Read the Docs at our Contribution page <https://docs.readthedocs.io/en/latest/contribute.html#get-in-touch>_. Contributing You can find information about contributing to Read the Docs at our Contribution page <https://docs.readthedocs.io/en/latest/contribute.html>_. Quickstart for GitHub-Hosted Projects By the end of this quickstart, you will have a new project automatically updated when you push to GitHub. . Create an account on Read the Docs_. You will get an email verifying your email address which you should accept within 7 days. . Log in and click on ""Import a Project"". . Click ""Connect to GitHub"" in order to connect your account's repositories to GitHub. . When prompted on GitHub, give access to your account. . Click ""Import a Repository"" and select any desired repository. . Change any information if desired and click ""Next"". . All done. Commit away and your project will auto-update. .. |build-status| image:: https://circleci.com/gh/readthedocs/readthedocs.org.svg?style=svg :alt: build status :target: https://circleci.com/gh/readthedocs/readthedocs.org .. |docs| image:: https://readthedocs.org/projects/docs/badge/?version=latest :alt: Documentation Status :scale: 100% :target: https://docs.readthedocs.io/en/latest/?badge=latest .. |coverage| image:: https://codecov.io/gh/readthedocs/readthedocs.org/branch/master/graph/badge.svg :alt: Test coverage :scale: 100% :target: https://codecov.io/gh/readthedocs/readthedocs.org License MIT_ 2010-2021 Read the Docs, Inc. & contributors .. _MIT: LICENSE"
4466,"Full Stack Python source with Pelican, Bootstrap and Markdown.This repository contains the source code for Full Stack Python."
505,"An independent, student-led replication of DeepMind's 2016 Nature publication, ""Mastering the game of Go with deep neural networks and tree search"" (Nature 529, 484-489, 28 Jan 2016), details of which can be found on their website https://deepmind.com/publications.html.RocAlphaGo (Previously known just as ""AlphaGo,"" renamed to clarify that we are not affiliated with DeepMind) This project is a student-led replication/reference implementation of DeepMind's 2016 Nature publication, ""Mastering the game of Go with deep neural networks and tree search,"" details of which can be found on their website. This implementation uses Python and Keras - a decision to prioritize code clarity, at least in the early stages. Documentation See the project wiki. Current project status This is not yet a full implementation of AlphaGo. Development is being carried out on the develop branch. The current emphasis is on speed optimizations, which are necessary to complete training of the value-network and to create feasible tree-search. See the cython-optimization branch for more. Selected data (i.e. trained models) are released in our data repository. This project has primarily focused on the neural network training aspect of DeepMind's AlphaGo. We also have a simple single-threaded implementation of their tree search algorithm, though it is not fast enough to be competitive yet. See the wiki page on the training pipeline for information on how to run the training commands. How to contribute See the 'Contributing' document and join the Gitter chat."
